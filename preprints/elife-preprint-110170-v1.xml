<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">110170</article-id>
<article-id pub-id-type="doi">10.7554/eLife.110170</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.110170.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Efficient and reproducible pipelines for spike sorting large-scale electrophysiology data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3661-527X</contrib-id>
<name>
<surname>Buccino</surname>
<given-names>Alessio P</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>alessio.buccino@alleninstitute.org</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0000-9152-9863</contrib-id>
<name>
<surname>Sridhar</surname>
<given-names>Arjun</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4920-8123</contrib-id>
<name>
<surname>Feng</surname>
<given-names>David</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6670-7362</contrib-id>
<name>
<surname>Svoboda</surname>
<given-names>Karel</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7736-4844</contrib-id>
<name>
<surname>Siegle</surname>
<given-names>Joshua H</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>joshs@alleninstitute.org</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04szwah67</institution-id><institution>Allen Institute for Neural Dynamics</institution></institution-wrap>, <city>Seattle</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Giocomo</surname>
<given-names>Lisa M</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Stanford School of Medicine</institution>
</institution-wrap>
<city>Stanford</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01gzszr18</institution-id><institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country country="GR">Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2026-02-03">
<day>03</day>
<month>02</month>
<year>2026</year>
</pub-date>
<volume>15</volume>
<elocation-id>RP110170</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-12-13">
<day>13</day>
<month>12</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-11-13">
<day>13</day>
<month>11</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.11.12.687966"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2026, Buccino et al</copyright-statement>
<copyright-year>2026</copyright-year>
<copyright-holder>Buccino et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-110170-v1.pdf"/>
<abstract>
<p>The scale of <italic>in vivo</italic> electrophysiology has expanded in recent years, with simultaneous recordings across thousands of electrodes now becoming routine. These advances have enabled a wide range of discoveries, but they also impose substantial computational demands. Spike sorting, the procedure that extracts spikes from extracellular voltage measurements, remains a major bottleneck: a dataset collected in a few hours can take days to spike sort on a single machine, and the field lacks rigorous validation of the many spike sorting algorithms and preprocessing steps that are in use. Advancing the speed and accuracy of spike sorting is essential to fully realize the potential of large-scale electrophysiology. Here, we present an end-to-end spike sorting pipeline that leverages parallelization to scale to large datasets. The same workflow can run reproducibly on individual workstations, high-performance computing clusters, or cloud environments, with computing resources tailored to each processing step to reduce costs and execution times. In addition, we introduce a benchmarking pipeline, also optimized for parallel processing, that enables systematic comparison of multiple sorting pipelines. Using this framework, we show that <monospace>Kilosort4</monospace>, a widely used spike sorting algorithm, outperforms <monospace>Kilosort2.5</monospace> (<xref ref-type="bibr" rid="c49">Pachitariu et al. 2024</xref>). We also show that 7× lossy compression, which substantially reduces the cost of data storage, has minimal impact on spike sorting performance. Together, these pipelines address the urgent need for scalable and transparent spike sorting of electrophysiology data, preparing the field for the coming flood of multi-thousand-channel experiments.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>electrophysiology</kwd>
<kwd>spike sorting</kwd>
<kwd>processing pipeline</kwd>
<kwd>open source</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>A central goal of systems neuroscience is to connect the spikes of populations of individual neurons to the flow of information across neural circuits and ultimately to behavior (<xref ref-type="bibr" rid="c1">Abbott &amp; Svoboda 2020</xref>). Extracellular electrophysiology with implanted electrode arrays is the most widely used method for establishing this link. This approach requires a processing step known as “spike sorting”, in which spikes are separated from noise and assigned to individual neurons (<xref ref-type="bibr" rid="c48">Obien et al. 2015</xref>; <xref ref-type="bibr" rid="c25">Harris et al. 2016</xref>). Spike sorting is difficult, because spikes last for around a millisecond, their amplitudes attenuate over tens of µm, and they occur in densely packed neural tissue (<xref ref-type="bibr" rid="c16">Einevoll et al. 2012</xref>; <xref ref-type="bibr" rid="c23">Gold et al. 2006</xref>). Spikes from an individual neuron may be readily distinguished from those of its neighbors within a small radius from the soma, but they become increasingly difficult to identify at greater distances (<xref ref-type="bibr" rid="c26">Henze et al. 2000</xref>; <xref ref-type="bibr" rid="c9">Buzsáki 2004</xref>). Despite these inherent challenges, accurate spike sorting is essential for uncovering the mechanisms that shape brain-wide patterns of activity.</p>
<p>Scaling up electrophysiology entails adding electrodes with spacing matched to neuron densities (~20 µm spacing), while maintaining sampling rates high enough to capture the details of spike waveforms (~30 kHz) (<xref ref-type="bibr" rid="c41">Marblestone et al. 2013</xref>; <xref ref-type="bibr" rid="c33">Kleinfeld et al. 2019</xref>) (<xref rid="fig1" ref-type="fig">Figure 1a</xref>). Thus, the overall size of an electrophysiology dataset increases roughly in proportion to the number of simultaneously recorded neurons. Even with modern hardware acceleration, processing these datasets remains computationally intensive, often taking much longer than the recording itself (<xref rid="fig1" ref-type="fig">Figure 1b</xref>). As experiments expand to include more probes and recordings over many days of natural behavior (<xref ref-type="bibr" rid="c10">Campagner et al. 2025</xref>; <xref ref-type="bibr" rid="c14">Dhawale et al. 2017</xref>; <xref ref-type="bibr" rid="c47">Newman et al. 2025</xref>), spike sorting becomes impossible to sustain without large-scale parallelization.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Challenges of scaling electrophysiological recordings.</title>
<p><bold>a</bold>, Multi-shank Neuropixels probe overlaid on a mouse brain, with zoomed-in region showing the spatial footprint of a typical spike waveform (from <xref rid="c56" ref-type="bibr">Steinmetz &amp; Ye 2022</xref>). Waveforms from individual electrodes and spatiotemporal footprint (sampled by a hypothetical Neuropixels 2.0 probe) are shown on the right. The approximate scale of the spike (50 µm x 2 ms) necessitates dense sampling in both space and time. Scaling up the number of recorded neurons requires increasing the number of electrodes that are in close physical proximity to neurons. <bold>b</bold>, Times required to run preprocessing, spike sorting, and automated curation on two-hour recordings with different probe configurations. Assuming no parallelization across machines, a recording with six Neuropixels 1.0 probes (384 channels each) would take more than two days to process. A recording with six Neuropixels 2.0 Quad Base probes (1,536 channels each), which recently became commercially available, would take over one week. Parallelization is essential to complete processing in under 24 hours after data collection.</p></caption>
<graphic xlink:href="687966v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Because spike sorting is computationally intensive, benchmarking sorter performance is even more demanding, as it requires running multiple algorithms on the same underlying data. Many spike sorting algorithms have been optimized for large-scale electrophysiology data (<xref ref-type="bibr" rid="c49">Pachitariu et al. 2024</xref>; <xref ref-type="bibr" rid="c64">Yger et al. 2018</xref>; <xref ref-type="bibr" rid="c13">Chung et al. 2017</xref>; <xref ref-type="bibr" rid="c4">Boussard et al. 2023</xref>; <xref ref-type="bibr" rid="c45">Meyer et al. 2024</xref>), yet systematic comparisons of their suitability across brain regions, species, and electrode types remain scarce (<xref ref-type="bibr" rid="c11">Carlson &amp; Carin 2019</xref>). Given the enormous investment in electrode technology, each step in the spike sorting process should be benchmarked to ensure we can extract the maximum value from our data.</p>
<p>To address the scaling challenge, we developed a core spike sorting pipeline designed for distribution across many workstations, either locally or in the cloud. This pipeline improves the efficiency of spike sorting individual experiments, reducing the estimated processing time for a hypothetical experiment with six Neuropixels “Quad Base” probes (1,536 channels each) from over a week to just ten hours, a speedup of more than 20-fold. To enable more rigorous evaluation of spike sorter accuracy, we developed a benchmarking pipeline that runs variations of the core pipeline on real data with injected ground-truth spikes. Together, these pipelines are prepared to handle the coming onslaught of data from current and future electrophysiology device.</p>
<p>The implementation of our pipelines was facilitated by three established technologies: <monospace>Nextflow</monospace> (<xref ref-type="bibr" rid="c15">Di Tommaso et al. 2017</xref>), <monospace>SpikeInterface</monospace> (<xref ref-type="bibr" rid="c5">Buccino et al. 2020</xref>), and <monospace>Code Ocean</monospace> (<xref ref-type="bibr" rid="c12">Cheifet 2021</xref>). <monospace>Nextflow</monospace> provides an abstraction layer between the data processing steps and the specific resources needed to execute them, meaning there are minimal modifications required to run the pipeline on a single machine, a high-performance computing cluster, or the public cloud. <monospace>Nextflow</monospace> also enables modularity by allowing processing steps with unique hardware or software dependencies to be seamlessly integrated into the same workflow. <monospace>SpikeInterface</monospace> is a Python package that makes a wide range of validated algorithms for data preprocessing, spike sorting, and curation available via a unified API. <monospace>SpikeInterface</monospace> encapsulates each processing step into its own module, allowing users to mix and match different algorithms to suit their needs. <monospace>Code Ocean</monospace> is a cloud platform for reproducible scientific computing. It is not required for running our pielines, but it greatly simplifies the process of deploying them in the cloud and streamlines the transition to downstream analysis in a scientist-friendly development environment.</p>
<p><bold>Reproducibility</bold> is critical for spike sorting, as small differences in software versions or parameters can lead to widely divergent results. Cloud deployment addresses this by running code in containerized environments, ensuring identical processing across datasets. Prior attempts to improve reproducibility by migrating spike sorting to the cloud have important shortcomings. SpyGlass (<xref ref-type="bibr" rid="c35">Lee et al. 2024</xref>) is a data management and analysis framework built on top of DataJoint (<xref ref-type="bibr" rid="c63">Yatsenko et al. 2018</xref>) that includes spike sorting capabilities. Although it is designed to be run in the cloud, it does not manage parallelization, which limits its <bold>scalability</bold> as channel counts increase. NeuroCAAS (<xref ref-type="bibr" rid="c2">Abe et al. 2022</xref>) allows neuroscientists to run predefined analyses in the cloud by dragging and dropping data files into a browser window. While this approach makes the barrier to entry extremely low, it lacks the <bold>modularity</bold> needed to readily swap in new algorithms or chain together different combinations of processing steps. Geng and colleagues recently described a cloud-based pipeline optimized for high-density multielectrode arrays (<xref ref-type="bibr" rid="c22">Geng et al. 2024</xref>). Its reliance on custom Kubernetes infrastructure constrains <bold>portability</bold> and prevents straightforward deployment on alternative backends that are critical for most research groups.</p>
<p>Previous efforts to benchmark spike sorting algorithms have mainly relied on simulations of extracellular spikes, which are computationally intensive and often fail to capture the complexities of real data (<xref ref-type="bibr" rid="c43">Martinez et al. 2009</xref>; <xref ref-type="bibr" rid="c5">Buccino et al. 2020</xref>; <xref ref-type="bibr" rid="c34">Laquitaine et al. 2024</xref>; <xref ref-type="bibr" rid="c24">Hagen et al. 2015</xref>; <xref ref-type="bibr" rid="c8">Buccino &amp; Einevoll 2021</xref>). Benchmarking with genuine ground truth data obtained from simultaneous intracellular and extracellular recordings provides the most realistic form of evaluation, but such datasets remain exceptionally scarce. SpikeForest (<xref ref-type="bibr" rid="c38">Magland et al. 2020</xref>) was a noteworthy attempt to aggregate and standardize benchmarking across available ground truth datasets, but it has not been updated to include more recent algorithms and therefore provides a limited and outdated view of the spike sorting landscape. An alternative strategy relies on hybrid benchmarking, in which groundtruth spikes are injected into real recordings. The paper describing <monospace>Kilosort4</monospace> used hybrid data to compare this algorithm to ten others (<xref ref-type="bibr" rid="c49">Pachitariu et al. 2024</xref>). However, the benchmarking framework they developed was not intended for extension to diverse recording conditions. SHYBRID (<xref ref-type="bibr" rid="c62">Wouters et al. 2021</xref>) offers a graphical interface for hybrid benchmarking and integrates with <monospace>SpikeInterface</monospace>, but does not incorporate cloud-based parallelization. Our approach integrates the innovations of our core spike sorting pipeline to enable practical benchmarking of hybrid large-scale electrophysiology datasets. Given the time-consuming nature of individual pipeline steps, parallelization allows us to systematically compare algorithms over the span of hours, rather than weeks.</p>
<p>In the sections that follow, we first describe the three underlying technologies that enabled us to build spike sorting pipelines that meet our requirements of reproducibility, scalability, modularity, and portability. We then provide an overview of our core spike sorting pipeline, which has already processed data from more than 1,000 multi-probe recordings. We then present our benchmarking pipeline, which we use to compare the performance of <monospace>Kilosort4</monospace> and <monospace>Kilosort2.5</monospace> and to assess the impact of lossy compression—a strategy that could greatly reduce data volumes but may compromise sorting accuracy. Taken together, these pipelines support our overarching aim: to more accurately and efficiently connect the activity of individual neurons with population-level dynamics that span the brain.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Enabling technologies</title>
<p>Three existing software tools form the foundation for our pipelines:</p>
<p><monospace>Nextflow</monospace> (<xref ref-type="bibr" rid="c15">Di Tommaso et al. 2017</xref>) is a domain-specific language for orchestrating scientific data processing pipelines. In <monospace>Nextflow</monospace>, a <italic>process</italic> is a self-contained unit that performs a specific task. Processes are linked together through <italic>channels</italic>, which handle data flow between tasks, ensuring clear input/output relationships.</p>
<p><monospace>SpikeInterface</monospace> is an open-source Python package for processing extracellular electrophysiology data (<xref ref-type="bibr" rid="c5">Buccino et al. 2020</xref>). It includes several modules that encompass all aspects of extracellular electrophysiology data analysis, including reading data (from more than 30 file formats), preprocessing, spike sorting (with at least 10 different spike sorters), postprocessing, curation, visualization, and more.</p>
<p><monospace>Code Ocean</monospace> (<xref ref-type="bibr" rid="c12">Cheifet 2021</xref>) is a cloud platform for reproducible scientific computing. <monospace>Code Ocean</monospace> was originally developed to support reliable regeneration of figures and analyses in journal publications using open source tools. The platform introduces the concept of the <italic>capsule</italic>, which integrates the three components necessary to fully reproduce a result: immutable data, a fully specified execution environment, and version-controlled code that can be run with a single command. <monospace>Code Ocean</monospace> has native support for <monospace>Nextflow</monospace> pipelines and makes them easy build and operate using scalable cloud resources. More generally, <monospace>Code Ocean</monospace> eases the transition to working with data in the cloud, providing a variety of familiar development environments (Visual Studio Code, JupyterLab, RStudio, MATLAB, and Ubuntu virtual desktops) with file-based access to data. Many scientific software tools only support traditional file-based data access patterns and would otherwise require extensive customization to handle cloud object storage APIs.</p>
<p>Leveraging these technologies was essential for meeting our design requirements of <bold>reproducibility, scalability, modularity</bold>, and <bold>portability</bold>:</p>
<list list-type="bullet">
<list-item><p><bold>Reproducibility</bold> is a cornerstone of our pipelines. Each <monospace>Nextflow</monospace> process points to a specific image of a Docker or Singularity container, which guarantees that the software environment remains consistent across different computational backends. Each spike sorter supported by <monospace>SpikeInterface</monospace> ships with a container image available on <monospace>DockerHub</monospace>). This ensures the same version of the sorter can always be re-run, eliminates installation headaches, and simplifies deployment on cloud infrastructure. <monospace>Code Ocean</monospace> adds an additional layer of reproducibility by tracking all processing steps that happen upstream or downstream of our spike sorting pipeline. This feature is helpful when preparing figures for publication, when the details of the entire analysis chain (not just the spike sorting outputs) must be transparently shared.</p></list-item>
<list-item><p><bold>Scalability</bold> is achieved by leveraging distributed computing to support parallelization over multiple probes. Since each <monospace>Nextflow</monospace> process runs independently and communicates through channels, it enables seamless parallel execution of processes, making the workflow highly scalable. Furthermore, <monospace>Nextflow</monospace> can provision custom resources for each process, meaning that more expensive cloud instances with GPUs do not need to be deployed beyond the spike sorting step. This adaptability allows users to tailor their computational resources to the complexity and size of their datasets. In addition, <monospace>SpikeInterface</monospace> makes use of parallelization wherever possible, e.g. for filtering, compression, waveform extraction, and a range of other processing steps.</p></list-item>
<list-item><p><bold>Modularity</bold> is enforced by encapsulating each pipeline step into <monospace>Nextflow</monospace> processes and channels. This makes it simple to swap out algorithms or incorporate novel pre- and post-processing steps without changing the overall workflow. <monospace>SpikeInterface</monospace> also promotes modularity by defining standard formats for transferring data between processing steps.</p></list-item>
<list-item><p><bold>Portability</bold> is enabled by <monospace>Nextflow</monospace> <italic>executors</italic> that are compatible with a variety of backends. To simplify deployment on commonly used backends for academic institutions, such as multi-processor workstations and SLURM HPC systems, we provide pre-configured scripts, configuration files, and detailed documentation. For scientists interested in using our pipeline in the cloud, <monospace>Code Ocean</monospace> is by far the easiest way to get up and running, since it natively supports <monospace>Nextflow</monospace> over an Amazon Web Services (AWS) Batch backend. However, <monospace>Nextflow</monospace> workflows can also run on major cloud providers (including AWS, Google Cloud, and Microsoft Azure) with minimal configuration changes.</p></list-item>
</list>
</sec>
<sec id="s2b">
<title>An end-to-end pipeline for spike sorting large-scale electrophysiology data</title>
<p>We designed a pipeline for spike sorting electrophysiology data, ensuring reproducibility, scalability, modularity, and portability. The pipeline addresses critical aspects of data processing, from ingestion of raw data to the curation of spike sorting outputs. The spike sorting pipeline is publicly available on <monospace>GitHub</monospace> (AllenNeuralDynamics/aind-ephys-pipeline) and detailed documentation is hosted on <monospace>ReadTheDocs</monospace> (<ext-link ext-link-type="uri" xlink:href="https://aind-ephys-pipeline.readthedocs.io/en/latest/">aind-ephys-pipeline.readthedocs.io</ext-link>).</p>
<p>The pipeline encompasses eight major steps (<xref rid="fig2" ref-type="fig">Figure 2</xref>):</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Spike sorting pipeline overview.</title>
<p>Raw electrophysiology data from multiple probes (top) is ingested by the Job Dispatch step, which coordinates parallelization of downstream processing. All steps are run in parallel until Result Collection. Pipeline outputs (including <monospace>Figurl</monospace> interactive visualizations, metrics stored in JSON format, PNG-formatted images, and a Neurodata Without Borders file) are shown at the bottom. Each step includes an estimate of run time (per hour of recording) and required computing resources (CPU, GPU, and RAM). The pipeline is encapsulated in a <monospace>Nextflow</monospace> workflow (green background), and individual steps are implemented in <monospace>SpikeInterface</monospace> (action potential logo). Interlocking brick icons indicate processing algorithms that can be easily substituted. For the spike sorting step, run time is calculated for <monospace>Kilosort4</monospace>. See <xref rid="tbl1" ref-type="table">Table 1</xref> for detailed run times and cost estimates.</p></caption>
<graphic xlink:href="687966v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s2b1">
<label>1.</label>
<title>Job dispatch</title>
<p>The entry point of the pipeline is a <italic>job dispatch</italic> step, which handles data ingestion and orchestration of parallelization. This step parses the input folder containing data from one recording session, which may include an unlimited number of probes. It outputs a set of configuration files containing key metadata about each session and recording, as well as the information to instruct <monospace>SpikeInterface</monospace> how to reload the recording. A parallel instance of downstream processing is launched for each configuration file. Parallelization is performed across <italic>streams</italic> (e.g., individual probes), <italic>groups</italic> (e.g., shanks of the same probe), and <italic>recordings</italic> (e.g., segments of continuous data). As an example, for a session with data from three Neuropixels 2.0 multi-shank probes with three recordings each, the job dispatch will output 36 configuration files (3 probes × 4 shanks × 3 recordings), which will spawn 36 parallel downstream processes.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption>
<title>Resources, run time, and cost for all steps in the spike sorting pipeline.</title>
<p>Values are based on a one-hour recording with six Neuropixels probes. Values for non-parallel steps (Job Dispatch, NWB Packaging, Result Collection) are normalized by the number of probes. For steps that run in parallel, run times and estimated cost are reported as the mean ± standard deviation for probes in the same session. *Run Time per hour of recording with one 384-channel probe. **Cost per hour of recording with one 384-channel probe. Costs are estimated using the prices of the reported instance from <ext-link ext-link-type="uri" xlink:href="https://aws.amazon.com/ec2/pricing/on-demand/">https://aws.amazon.com/ec2/pricing/on-demand/</ext-link> as of April 30, 2025.</p>
</caption>
<graphic xlink:href="687966v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s2b2">
<label>2.</label>
<title>Preprocessing</title>
<p>The <italic>preprocessing</italic> step prepares raw electrophysiology signals for spike sorting. Four computations are applied in sequence:</p>
<list list-type="bullet">
<list-item><p><bold>Phase-shift correction</bold>: Some high-density recording devices, such as Neuropixels, have fewer analog-to-digital converters (ADCs) than recording channels. During each sampling period, each ADC digitizes voltages from multiple electrodes, a process known as “multiplexing.” As a result, different groups of channels are sampled asynchronously. The phase shift algorithm uses a fast Fourier transform to make the signals appear as though they were sampled simultaneously across all channels. This correction increases the effectiveness of the subsequent denoising step (<xref ref-type="bibr" rid="c27">International Brain Laboratory 2024</xref>). If the input recording does not require phase shift correction, this step is skipped.</p></list-item>
<list-item><p><bold>Filtering</bold>: By default, a highpass filter with cutoff frequency of 300 Hz is applied, to preserve high-frequency information in spike waveforms. Users can opt for a bandpass filter to better remove high-frequency noise.</p></list-item>
<list-item><p><bold>Denoising</bold>: This step first masks out noisy or dead channels, then applies a Common Median Reference (CMR) or a highpass spatial filter (also referred to as <italic>destriping</italic>). By default, CMR is used, since destriping can create artifacts in spike waveforms (<xref ref-type="bibr" rid="c27">International Brain Laboratory 2024</xref>).</p></list-item>
<list-item><p><bold>Motion estimation/correction</bold>: Drift of the electrodes relative to the brain tissue is common issue in recordings with long, needle-like probes. Among the several methods are available for estimating and correcting drift, <monospace>DREDge</monospace> is used by default (<xref ref-type="bibr" rid="c61">Windolf et al. 2025</xref>). The estimated motion signal is used for visual assessment of the severity of drift throughout the recording. It is also possible to use the estimated motion to correct the traces via interpolation. However, since the spike sorting step may also include its own motion correction algorithm, interpolation is not performed by default.</p></list-item>
</list>
</sec>
<sec id="s2b3">
<label>3.</label>
<title>Spike Sorting</title>
<p><italic>Spike sorting</italic> identifies discrete spike times in continuously sampled voltage traces and assigns each one to a “unit,” which may include spikes from one or more neurons. Currently, three spike sorting algorithms are available within the pipeline: <monospace>Kilosort4</monospace>, <monospace>Kilosort2.5</monospace> (<xref ref-type="bibr" rid="c49">Pachitariu et al. 2024</xref>), and <monospace>SpyKING-CIRCUS2</monospace> (<xref ref-type="bibr" rid="c64">Yger et al. 2018</xref>) (a new version of this algorithm fully implemented within <monospace>SpikeInterface</monospace>). User can modify any sorter parameters via a configuration file.</p>
</sec>
<sec id="s2b4">
<label>4.</label>
<title>Postprocessing</title>
<p><italic>Postprocessing</italic> combines the preprocessing and spike sorting outputs to perform additional computations relevant for visualization, curation, and downstream analysis. This step begins by estimating each unit’s <italic>template</italic> (average extracellular waveform) and <italic>sparsity</italic> (the set of channels the template is defined on). Next, duplicate units are removed based on the fraction of overlapping spikes.</p>
<p>Several additional postprocessing <italic>extensions</italic> are computed and saved to the results, including:</p>
<list list-type="bullet">
<list-item><p><italic>waveforms</italic>: a set of subsampled spike waveforms (maximum 500 per unit)</p></list-item>
<list-item><p><italic>spike amplitudes</italic>: peak-to-peak amplitudes of each spike in µV</p></list-item>
<list-item><p><italic>template similarity</italic>: pairwise template similarity across units</p></list-item>
<list-item><p><italic>correlograms</italic>: auto- and cross-correlograms for all units</p></list-item>
<list-item><p><italic>ISI histograms</italic>: inter-spike-interval histograms</p></list-item>
<list-item><p><italic>unit locations</italic>: estimated unit locations via monopolar triangulation</p></list-item>
<list-item><p><italic>spike locations</italic>: estimated spike locations via grid convolution</p></list-item>
<list-item><p><italic>template metrics</italic>: a set of metrics describing the spatial and temporal profile of each template</p></list-item>
<list-item><p><italic>quality metrics</italic>: a set of metrics for assessing the completeness and contamination of each unit</p></list-item>
</list>
<p>A comprehensive explanation for these extensions can be found in the <bold>Methods</bold> section.</p>
</sec>
<sec id="s2b5">
<label>5.</label>
<title>Curation</title>
<p>The <italic>curation</italic> step applies labels to sorted units to automate, or at least speed up, unit inspection and curation. Two set of labels are applied. The first is based on a set of quality metric thresholds (<xref ref-type="bibr" rid="c54">Siegle et al. 2021</xref>). Units are tagged as passing a <italic>default_qc</italic> when they satisfy the following criteria:</p>
<list list-type="bullet">
<list-item><p>ISI violation ratio &lt; 0.5 (places an upper bound on spike train contamination)</p></list-item>
<list-item><p>Amplitude cutoff &lt; 0.1 (removes units with a large fraction of spikes below the detection threshold)</p></list-item>
<list-item><p>Presence ratio &gt; 0.8 (removes units that were not detected for more than 20% of the recording duration)</p></list-item>
</list>
<p>The second set of labels is based on <monospace>UnitRefine</monospace> (<xref ref-type="bibr" rid="c30">Jain et al. 2025</xref>), which uses two pre-trained random forest classifiers to label units as noise, single-unit activity (SUA), or multi-unit activity (MUA).</p>
</sec>
<sec id="s2b6">
<label>6.</label>
<title>Visualization and quality control</title>
<p>The visualization step creates interactive views using <monospace>Figurl</monospace> (<xref ref-type="bibr" rid="c39">Magland &amp; Soules 2025a</xref>) and <monospace>sortingview</monospace> (<xref ref-type="bibr" rid="c40">Magland &amp; Soules 2025b</xref>). This technology, integrated into <monospace>SpikeInterface</monospace>, generates shareable links that can be viewed from any device. Our pipeline includes one link for visualizing the raw/preprocessed traces, drift maps, and estimated motion (<xref rid="fig3" ref-type="fig">Figure 3a</xref>) and one link for visualizing and curating the spike sorting results (<xref rid="fig3" ref-type="fig">Figure 3b</xref>). While we expect that machine learning tools will eventually automate the entire spike sorting process, we recognize that some manual curation may be beneficial in the present day. Therefore, the <monospace>sortingview</monospace> link can be used for merging and labeling units, the outputs of which can be incorporated into downstream analysis.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Outputs of the visualization and quality control step.</title>
<p><bold>a</bold>, Screenshot of interactive visualization of raw and preprocessed data (view on web). <bold>b</bold>, Screenshot of <monospace>SortingView</monospace> GUI, used for inspecting and curating spike sorting outputs (view on web). <bold>c-d-e</bold>, Examples of static quality control plots generated by the pipeline: power spectral density (<bold>c</bold>), drift (<bold>d</bold>) and unit yield (<bold>e</bold>).</p></caption>
<graphic xlink:href="687966v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In addition to these shareable web-based visualization, the pipeline implements a quality control step that produces a series of static plots and metrics designed to asses the raw and processed data.</p>
<list list-type="bullet">
<list-item><p>Raw data: snippets of AP and LFP traces at multiple points over the session</p></list-item>
<list-item><p>PSD: Power Spectrum Density of wide, high-frequency and low-frequency bands of each channel (<xref rid="fig3" ref-type="fig">Figure 3c</xref>)</p></list-item>
<list-item><p>Noise: RMS channel values of raw data and preprocessed data</p></list-item>
<list-item><p>Drift: raster map and estimated drift (<xref rid="fig3" ref-type="fig">Figure 3d</xref>)</p></list-item>
<list-item><p>Saturation: count of positive/negative saturation events</p></list-item>
<list-item><p>Unit Yield: distributions of unit metrics, amplitudes, and firing rates, along with a unit classification summary (<xref rid="fig3" ref-type="fig">Figure 3e</xref>)</p></list-item>
<list-item><p>Firing Rate: population firing rate over the session</p></list-item>
</list>
</sec>
<sec id="s2b7">
<label>7.</label>
<title>Result Collection</title>
<p>Once all upstream processing steps are finished, the <italic>result collection</italic> step aggregates results from different probes into structured outputs, organizing them for downstream analysis and ensuring data integrity.</p>
</sec>
<sec id="s2b8">
<label>8.</label>
<title>NWB Packaging</title>
<p>The final step exports results into the widely used Neurodata Without Borders (NWB) format (<xref ref-type="bibr" rid="c53">Rübel et al. 2022</xref>). Each NWB file includes data from all probes that were recorded simultaneously. Prior to being shared, NWB files generated by this pipeline will need to be extended with subject metadata and behavioral information. We chose not to require these elements to generate the output files, so that the pipeline would only require raw electrophysiology data as input. However, if desired, subject and session information can be specified using additional input metadata files (following the Allen Institute for Neural Dynamics (AIND) Data Schema specification, see <bold>AIND Data Schema</bold>).</p>
<p>The pipeline supports multiple input data formats, including those from the most widely used applications for Neuropixels data acquisition (<monospace>SpikeGLX</monospace>, <monospace>Open Ephys</monospace>). Although the present work focuses on Neuropixels, our pipeline is not limited to them: the input layer supports any of the readers supported by <monospace>SpikeInterface</monospace> (over 30 file formats). We also provide the ability to read directly from an NWB file, for cases where raw data has been shared in this format.</p>
<p>The pipeline saves the outputs of all steps, which can be easily reloaded by <monospace>SpikeInterface</monospace> if additional processing is needed. In addition, the pipeline produces NWB files with spike times, waveforms, and metrics for all units. See <bold>Spike sorting pipeline output</bold> for more details.</p>
<p>Each step of the pipeline can be configured with several parameters. We provide a detailed list and description of parameters associated with each step as part of the pipeline documentation. Parameters can be passed to the pipeline either via a configuration file or via command line arguments. For example, the user can choose the type of filter (highpass/bandpass) or denoising strategy (CMR/destriping) or fine-tune individual spike sorting parameters, which are all exposed in the parameter file.</p>
</sec>
<sec id="s2b9">
<title>Cost-effective and robust spike sorting</title>
<p><xref rid="tbl1" ref-type="table">Table 1</xref> reports the resources, run time, and estimated cost of each pipeline step. The effective run time for a specific input datasets can be calculated as the sum of non-parallel steps × duration × number of probes, plus the run time of the parallelized steps × duration. The cost is the total cost × duration × number of probes.</p>
<p>To provide a concrete example, for a two-hour session with six Neuropixels 1.0 probes and a total of 4563 spike sorted units, the effective run time is 18.40 hours (Total Run Time = [Non-Parallel] + [Parallel] = [(0.05 + 0.38 + 0.16) × 6 (probes) × 2 (hours)] + [(0.84 + 2-7 + 1. + 0.1 + 1.02) × 2 (hours)] = 18.40 hours) and the total cost is 66.65 USD (Total Run Time = 5.554 USD × 6 (probes) × 2 (hours) = 66.65 USD). Although this may seem like a high cost for spike sorting a single experiment, it is negligible in comparison to the price of purchasing, installing, and maintaining a computing cluster with at least 6 GPU nodes. To appreciate the value of parallelization and targeted resource allocation, if the same spike sorting job ran sequentially on a single GPU-capable cloud workstation (<monospace>g4dn.4xlarge</monospace>), it would take approximately 75 hours and cost over 90 USD. Therefore, job orchestration and parallelization not only reduce the overall run time by more than 4x, they also reduce the price by 27% (given the higher cost of GPU instances).</p>
<p>Our spike sorting pipeline was first deployed on Code Ocean in February 2024, running <monospace>Kilosort2.5</monospace> as the default sorter. Since its initial deployment, it has processed an average of 17.2 sessions per week (<xref rid="fig4" ref-type="fig">Figure 4a</xref>). In November 2024, <monospace>Kilosort4</monospace> became the default spike sorter given its better performance (see <bold>Benchmarking Application 1: Comparing</bold> <monospace><bold>Kilosort2.5</bold></monospace> <bold>and</bold> <monospace><bold>Kilosort4</bold></monospace>). Several projects continued using <monospace>Kilosort2.5</monospace> for consistency. As of August 2025, the pipeline has processed a total of 1,287 sessions: 789 with <monospace>Kilosort2.5</monospace> and 468 with <monospace>Kilosort4</monospace> (<xref rid="fig4" ref-type="fig">Figure 4b</xref>). It is quite common in our sessions to record from more than one probe. The spike sorting pipeline has processed 3,126 individual probes (<xref rid="fig4" ref-type="fig">Figure 4c</xref>), yielding over 1 million individual units that were labeled as <italic>neural</italic> (<xref rid="fig4" ref-type="fig">Figure 4d</xref>; see <bold>Curation</bold> section for more details).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Spike sorting pipeline usage at the Allen Institute for Neural Dynamics.</title>
<p><bold>a</bold>, Sessions processed by the pipeline each week between February 2024 and August 2025. Color indicates the spike sorter used for each pipeline run. <bold>b</bold>, Cumulative sessions processed by the pipeline, split by spike sorter. <bold>c</bold>, Cumulative probes processed by the pipeline (many sessions include data from multiple probes). <bold>d</bold>, Cumulative units detected by the pipeline, with the subset of neural units indicated in yellow and units passing default quality metric thresholds in green. Units are considered neural if the <monospace>UnitRefine</monospace> classifier does not label them as “noise”.</p></caption>
<graphic xlink:href="687966v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2b10">
<title>A pipeline for rapid benchmarking of spike sorting algorithms and data processing steps</title>
<p>The same principles and technologies behind our spike sorting pipeline were used to develop a versatile pipeline for spike sorting evaluation. Evaluating spike sorting results requires access to ground truth spike times, so one can estimate what fraction of spikes are missed or improperly labeled. Real ground truth data, in which one has access to the actual spike times of a neuron recorded with an extracellular electrode, is limited to a few hard-won datasets, encompassing no more than a few dozen neurons (<xref ref-type="bibr" rid="c26">Henze et al. 2000</xref>; <xref ref-type="bibr" rid="c46">Neto et al. 2016</xref>; <xref ref-type="bibr" rid="c64">Yger et al. 2018</xref>; <xref ref-type="bibr" rid="c3">Allen et al. 2018</xref>; <xref ref-type="bibr" rid="c42">Marques-Smith et al. 2018</xref>). Therefore, we chose to base our evaluation pipeline on hybrid data, in which known spike templates are superimposed on real recordings. Hybrid data is a powerful tool for evaluating spike sorting options, since it maintains the inherent complexities of the data (e.g., spike correlations, noise statistics, and drift) (<xref ref-type="bibr" rid="c52">Rossant et al. 2016</xref>; <xref ref-type="bibr" rid="c50">Pachitariu et al. 2016</xref>; <xref ref-type="bibr" rid="c49">Pachitariu et al. 2024</xref>), while still providing the ground truth spike times needed to assess sorter accuracy. However, to avoid unwanted changes to the properties of the underlying data, a limited number of artificial spike trains should be superimposed on each original recording. This means that many iterations of spike sorting may be required to uncover statistically significant differences between processing steps.</p>
<p>We used the recently developed hybrid data generation framework in <monospace>SpikeInterface</monospace> to construct a <monospace>Nextflow</monospace> pipeline for evaluating spike sorting options. As with the core spike sorting pipeline, <monospace>Nextflow</monospace> enabled straightforward parallelization of pipeline steps, reducing the effective run times by over two orders of magnitude in comparison to serial execution (<xref rid="tbl2" ref-type="table">Table 2</xref>). The full pipeline is available on <monospace>GitHub</monospace> (<ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-hybrid-benchmark">https://github.com/AllenNeuralDynamics/aind-ephys-hybrid-benchmark</ext-link>).</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><title>Benchmarking pipeline run times.</title>
<p>The number of jobs and effective run time in hours for the two benchmarking applications (<monospace>Kilosort2.5</monospace> vs <monospace>Kilosort4</monospace>, Lossless vs Lossy) on data from two types of Neuropixels probes (NP1, NP2). The “distributed” execution refers to our <monospace>Nextflow</monospace> implementation, while the “serial” execution has all jobs running sequentially on an individual workstation. The run time for serial execution is extrapolated from the distributed run times, and was not actually measured.</p></caption>
<graphic xlink:href="687966v1_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>As input to the pipeline, we used recordings from commercially available single-shank Neuropixels 1.0 (<xref ref-type="bibr" rid="c32">Jun et al. 2017</xref>) and four-shank Neuropixels 2.0 (<xref ref-type="bibr" rid="c55">Steinmetz et al. 2021</xref>) probes. These probes not only differ in their site geometry, but also in their signal bandwidth and bit depth. Neuropixels 1.0 probes have a built-in 300 Hz high-pass filter, and use 10-bit analog-to-digital Converters (ADCs), while Neuropixels 2.0 probes acquire wideband signals with 12-bit ADCs. We processed each shank separately, for a total of × 6 sessions 6 probes = 36 Neuropixels 1.0 recordings and 15 insertions × 4 shanks = 60 Neuropixels 2.0 recordings. For each recording, we randomly injected 10 hybrid units across 5 instances, generating a grand total of 1,800 ground truth units for Neuropixels 1.0 and 3,000 for Neuropixels 2.0.</p>
<p>For all results, we perform spike train comparisons and compute performance metrics as defined in (<xref ref-type="bibr" rid="c5">Buccino et al. 2020</xref>). In brief, we match sorted spike trains to ground-truth ones based on their agreement (fraction of matched spikes within 0.2 ms). For each matched pair, we count the number of true positives (#TP: ground-truth spikes found by the sorter), false negatives (#FN: ground-truth spikes not found by the sorter), and false positives (#FP: sorted spikes not found in the ground truth). We then evaluated each matched pair based on the following metrics:
<disp-formula id="eqn1">
<graphic xlink:href="687966v1_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn2">
<graphic xlink:href="687966v1_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn3">
<graphic xlink:href="687966v1_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s2b11">
<title>Pipeline steps</title>
<p>The benchmarking pipeline includes four major steps (<xref rid="fig5" ref-type="fig">Figure 5</xref>):</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Benchmarking pipeline overview.</title>
<p>The Job Dispatch step accepts <italic>N</italic> sessions as input, each of which may contain data from multiple probes. Next, the Hybrid Generation step injects <italic>T</italic> ground truth spike templates for each session and probe (default = 10), with <italic>IT</italic> randomized iterations (default = 5). Hybrid data are then processed in parallel through <italic>M</italic> Spike Sorting Cases, each of which sorts data using a different set of algorithms or parameters. The sorting results are then collected and compared by the Hybrid Evaluation step, which outputs figures and metrics for analyzing the performance of each case.</p></caption>
<graphic xlink:href="687966v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<list list-type="order">
<list-item><p>Job Dispatch. The first step of the benchmarking pipeline is the same as that of the spike sorting pipeline: data ingestion and parallelization. The same input data formats are supported, but the benchmarking pipeline is capable of processing multiple sessions at a time to facilitate rapid evaluation across many input datasets in parallel.</p></list-item>
<list-item><p>Hybrid Generation. For each input dataset, multiple hybrid recordings are generated by randomly sampling templates from a library available through <monospace>SpikeInterface</monospace>. The template library includes both Neuropixels 1.0 templates from the International Brain Laboratory (IBL) Brain-Wide Map (<xref rid="c27" ref-type="bibr">International Brain Laboratory et al. 2024</xref>; <xref rid="c28" ref-type="bibr">International Brain Laboratory et al. 2025</xref>) and high-density Neuropixels Ultra templates from (<xref ref-type="bibr" rid="c56">Steinmetz &amp; Ye 2022</xref>). Here, we selected IBL templates for Neuropixels 1.0 probes and Neuropixels Ultra ones for Neuropixels 2.0, which were interpolated to the Neuropixels 2.0 geometry and relocated to cover the entire length of each shank. By default, 10 hybrid units are added to each probe or shank, after rescaling to match a user-defined range (e.g., 50-200 µV). It is important for injected spikes to follow a recording’s natural drift profiles so that they smoothly blend in with the original spikes. The hybrid data generation step estimates non-rigid motion using <monospace>DREDge</monospace> (<xref ref-type="bibr" rid="c61">Windolf et al. 2025</xref>) and uses the motion signals to interpolate the selected templates in space during spike injection.</p></list-item>
<list-item><p>Spike Sorting Cases. The generated hybrid recordings are processed in parallel through two or more <italic>spike sorting cases</italic> which can be specific to different applications. The spike sorting case is a subworkflow that can include multiple processes. Spike sorting cases can be used to compare different spike sorting tools, parameter sets of the same spike sorter, pre-processing options, or data compression algorithms.</p></list-item>
<list-item><p>Hybrid Evaluation. The final step of the pipeline collects the spike sorting results of all spike sorting cases for each input session, evaluates their performance against hybrid ground-truth, and generates reports and tables for additional downstream analysis. In addition, results from all sessions are also aggregated into global results and plots.</p></list-item>
</list>
<p>The benchmarking pipeline accepts the same input types as the spike sorting pipeline, but it can take multiple sessions as input. This makes it straightforward to run the pipeline across many recordings without the need to modify the pipeline script or configuration. When using multiple input sessions, the evaluation step will aggregate outputs from all sessions into coherent results and visualizations.</p>
<p>The benchmarking pipeline outputs figures (as PNG images) and tables (as CSV files). In addition, all computed spike sorting outputs and comparisons are stored and can be reloaded by <monospace>SpikeInterface</monospace> if needed. More details can be found in the <bold>Evaluation pipeline output</bold> section.</p>
<p>The benchmarking pipeline reuses several capsules from the spike sorting pipeline. The supported input data formats and preprocessing parameters are therefore the same and can be specified similarly to the spike sorting pipeline presented above. The step that generates hybrid recordings takes the number of hybrid units per recording (default = 10) and the number of random iterations for each recording (default = 5) as additional inputs.</p>
</sec>
<sec id="s2b12">
<title>Benchmarking Application 1: Comparing <monospace>Kilosort2.5</monospace> and <monospace>Kilosort4</monospace></title>
<p>Our first application of the benchmarking pipeline was comparing the performance of different spike sorting algorithms. We focused on <monospace>Kilosort</monospace>, the most widely used spike sorter for Neuropixels probes. The <monospace>Kilosort</monospace> algorithm has evolved alongside Neuropixels technology, with the initial version developed to efficiently sort data from Neuropixels 1.0 probes (<xref ref-type="bibr" rid="c50">Pachitariu et al. 2016</xref>). <monospace>Kilosort2.5</monospace> was introduced in the publication describing Neuropixels 2.0 probes (<xref ref-type="bibr" rid="c55">Steinmetz et al. 2021</xref>), and was incorporated into the original version of our spike sorting pipeline. <monospace>Kilosort3</monospace> included a new clustering algorithm, but for various reasons did not become as widely adopted as <monospace>Kilosort2.5</monospace>. <monospace>Kilosort4</monospace> was launched in February 2024 alongside benchmarking results showing that it outperformed all previous versions of <monospace>Kilosort</monospace> on hybrid datasets generated with Neuropixels 1.0 templates (<xref ref-type="bibr" rid="c49">Pachitariu et al. 2024</xref>). <monospace>Kilosort4</monospace> has many methodological and implementation differences with respect to <monospace>Kilosort2.5</monospace> (including being written in Python, rather than Matlab), so here we consider them two different spike sorters, rather than two versions of the same sorter.</p>
<p>For this application, the pipeline included two spike sorting cases:</p>
<list list-type="order">
<list-item><p>preprocessing → <monospace>Kilosort2.5</monospace></p></list-item>
<list-item><p>preprocessing → <monospace>Kilosort4</monospace></p></list-item>
</list>
<p><xref rid="fig6" ref-type="fig">Figure 6</xref> provides an interpretable visual representation of the results for one Neuropixels 1.0 dataset. <xref rid="fig6" ref-type="fig">Figure 6a</xref> displays a zoomed in 100 ms snippet of traces with highlighted hybrid spikes. The red and purple spikes are found only by <monospace>Kilosort2.5</monospace> and <monospace>Kilosort4</monospace>, respectively. The blue spikes are found by both sorters. When we extend the view to the entire recording in the form of a spike raster (<xref rid="fig6" ref-type="fig">Figure 6b</xref>), it is clear that <monospace>Kilosort4</monospace> finds a higher proportion of hybrid spikes, with only a small number of spikes detected exclusively by <monospace>Kilosort2.5</monospace>. There was no clear degradation in terms of false positive (<xref rid="fig6" ref-type="fig">Figure 6c</xref>) and false negative rates (<xref rid="fig6" ref-type="fig">Figure 6d</xref>) for <monospace>Kilosort4</monospace>.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Example hybrid evaluation.</title>
<p><bold>a</bold>, 100 ms snippet of traces, showing ground-truth hybrid spikes and respective waveforms in <italic>blue</italic> if found by both sorters, <italic>red</italic> if found by <monospace>Kilosort2.5</monospace> only, and <italic>purple</italic> if found by <monospace>Kilosort4</monospace> only. <bold>b</bold>, Spike rasters of all hybrid spikes in the recording with same color scheme as panel a. Gray spikes are those from the original recording. <bold>c</bold>, Fraction of false positive spikes found by either sorter (a.u. = arbitrary units). <bold>d</bold>, Fraction of false negative spikes. False positive and false negative spikes are calculated using 10 s time bins.</p></caption>
<graphic xlink:href="687966v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Across all recordings with both probe types, <monospace>Kilosort4</monospace> is able to find hybrid units with significantly greater accuracy (NP1: <italic>P</italic> &lt; 1×10<sup>−10</sup>, effect size = 0.276; NP2: <italic>P</italic> &lt; 1×10<sup>−10</sup>, effect size = 0.408), precision (NP1: <italic>P</italic> &lt; 1 × 10<sup>−7</sup>, effect size = 0.272; NP2: <italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.232), and recall n(NP1: <italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.319; NP2: <italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.415) (<xref rid="fig7" ref-type="fig">Figure 7a</xref>). These differences are most pronounced for units with signal-to-noise ratios below 10, which are generally more difficult to detect (<xref rid="figS1" ref-type="fig">Figure S1</xref>). When comparing individual ground truth units, <monospace>Kilosort4</monospace> tends to have higher accuracy and recall, at the expense of a slight degradation of precision (<xref rid="fig7" ref-type="fig">Figure 7b</xref>). This suggests that <monospace>Kilosort4</monospace> recovers more complete spike trains, but also finds more false positive spikes in the process. This can also be seen when looking at the distributions of the refractory period contamination (<xref ref-type="bibr" rid="c37">Llobet et al. 2022</xref>) for ground truth units detected by each sorter: <monospace>Kilosort4</monospace> has slightly higher values than <monospace>Kilosort2.5</monospace> (<italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.013)(<xref rid="fig7" ref-type="fig">Figure 7c</xref>). When looking at presence ratio, <monospace>Kilosort4</monospace> finds significantly more units which are active throughout the entire recording (<italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.193) (<xref rid="fig7" ref-type="fig">Figure 7d</xref>). This could be due to a more effective merging strategy implemented in <monospace>Kilosort4</monospace> (<xref ref-type="bibr" rid="c49">Pachitariu et al. 2024</xref>). Overall, these results demonstrate a clear superiority of <monospace>Kilosort4</monospace> in terms of spike sorting performance, although it does take <monospace>Kilosort4</monospace> almost twice as long to run as <monospace>Kilosort2.5</monospace> (<xref rid="figS2" ref-type="fig">Figure S2</xref>).</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7:</label>
<caption><title>Benchmarking spike sorting algorithms.</title>
<p><bold>a</bold>, Accuracy, precision, and recall for all ground truth units for <monospace>Kilosort2.5</monospace> (red) and <monospace>Kilosort4</monospace> (purple) for Neuropixels 1.0 (top panels) and 2.0 (bottom panels) probes. <bold>b</bold>, Scatter plots for accuracy, precision, and recall for ground-truth units matched by both <monospace>Kilosort2.5</monospace> (x axis) and <monospace>Kilosort4</monospace> (y axis) for Neuropixels 1.0 (top panels) and 2.0 (bottom panels) probes. <bold>c</bold>, Distributions of refractory period contamination for all units found by both sorters. <bold>d</bold>, Histograms of presence ratio values for all units found by both sorters. In panels c and d, data from both probes are combined and include all units that were matched to a ground-truth hybrid unit (accuracy≥0.2 - <monospace>Kilosort2.5</monospace>: 3,046 matches; <monospace>Kilosort4</monospace>: 3,652 matches).</p></caption>
<graphic xlink:href="687966v1_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref rid="tbl2" ref-type="table">Table 2</xref> displays the total number of jobs for this benchmark application and compares the estimated run times for a single workstation and our distributed <monospace>Nextflow</monospace> implementation. The Neuropixels 1.0 benchmark ran 398 jobs, with a distributed effective run time of around 14 hours. For the</p>
<p>Neuropixels 2.0 benchmark, the number of jobs increased to 662 (as individual shanks are processed separately) and the run time was of 12 hours. Running the same benchmarks on single workstations would have taken 870 hours (~ 36 days) for Neuropixels 1.0 and 846 hours (~35 days) for Neuropixels 2.0, highlighting the need for distributed pipelines for efficient evaluations.</p>
</sec>
<sec id="s2b13">
<title>Benchmarking Application 2: Comparing lossless and lossy compression</title>
<p>We used our benchmarking pipeline to investigate whether lossy compression degrades spike sorter performance. In a previous study, we evaluated a wide range of compression algorithms and found that <monospace>WavPack</monospace>, a widely used audio compressor, is the best option for lossless compression of extracellular electrophysiology data (<xref ref-type="bibr" rid="c7">Buccino et al. 2023</xref>). <monospace>WavPack</monospace> also comes with a lossy mode, which compresses data down to a target average number of bits per sample (BPS). While we previously found no spike sorting degradation after lossy compression using simulated datasets (<xref ref-type="bibr" rid="c8">Buccino &amp; Einevoll 2021</xref>), here we extended the analysis to hybrid datasets.</p>
<p>We compared lossless compression with <monospace>WavPack</monospace> against three different bits per sample values (from less to more lossy): BPS=3 (~18.75% original file size, 5.33× compression ratio), BPS=2.5 (~15.6% original file size, 6.4× compression ratio), and BPS=2.25 (~14.06% original file size, 7.1× compression ratio, and the lowest supported BPS value). For comparison, the lossless compression ratio for Neuropixels 1.0 data was 3.53× (28.39 ± 1.02% original file size, <italic>N</italic> = 36 insertions); the lossless compression ratio for Neuropixels 2.0 data was 3.51× (28.51 ± 0.93% original files size, <italic>N</italic> = 15 insertions). Lossy compression thus cuts file sizes roughly in half, which has the potential to greatly reduce data storage costs (see <xref ref-type="bibr" rid="c7">Buccino et al. 2023</xref> for an in-depth cost analysis).</p>
<p>For this application, the evaluation pipeline included four spike sorting cases:</p>
<list list-type="order">
<list-item><p>original data (lossless) → preprocessing → <monospace>Kilosort4</monospace></p></list-item>
<list-item><p><monospace>WavPack</monospace> compression (BPS=3) → preprocessing → <monospace>Kilosort4</monospace></p></list-item>
<list-item><p><monospace>WavPack</monospace> compression (BPS=2.5) → preprocessing → <monospace>Kilosort4</monospace></p></list-item>
<list-item><p><monospace>WavPack</monospace> compression (BPS=2.25) → preprocessing → <monospace>Kilosort4</monospace></p></list-item>
</list>
<p>For Neuropixels 1.0 data, we observed no significant changes in the performance curves across the four compression cases (<xref rid="fig8" ref-type="fig">Figure 8a</xref>, top). Median accuracy, precision, and recall across all hybrid units stay roughly constant as compression ratio increases (<xref rid="fig8" ref-type="fig">Figure 8b</xref>, top). When looking at the unit-wise difference in performance between the lossless result and the BPS=3 case (<xref rid="fig8" ref-type="fig">Figure 8c</xref>, top), it is clear that units from the lossless sorting case tend to have slightly higher accuracy and recall, but these differences are typically small.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8:</label>
<caption><title>Lossy compression benchmarks</title>
<p><bold>a</bold>, Accuracy, precision, and recall for all ground truth units for lossless, and lossy (dark green) <monospace>WavPack</monospace> compression (lighter greens as BPS decreases, i.e., compression ratio increases) for Neuropixels 1.0 (top panels) and 2.0 (bottom panels) probes. The dashed red line shows the curves for <monospace>Kilosort2.5</monospace> for reference. <bold>b</bold>, Median accuracy, precision, and recall as a function of compression ratio, for both probe types (top row: Neuropixels 1.0; bottom row: Neuropixels 2.0). <bold>c</bold>, Scatter plots for accuracy, precision, and recall for ground-truth units matched by both the lossless (x axis) and BPS=3 (y axis), for both probe types. <bold>d</bold>, Distributions of refractory period contamination for all units found at each compression ratio. <bold>e</bold>, Histograms of presence ratio values for all units found at each compression ratio. In panels d and e, data from both probes are combined and include all units that were matched with accuracy ≥0.2 to a ground-truth hybrid unit (Lossless: 3,612 matches; BPS=3: 3,513 matches; BPS=2.5: 3,475 matches; BPS=2.25: 3,405 matches).</p></caption>
<graphic xlink:href="687966v1_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The results for Neuropixels 2.0 show slightly more degradation of spike sorting accuracy with respect to the lossless compression results (lossless vs. BPS=3: <italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.08; lossless vs. BPS=2.5: <italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.1; lossless vs. BPS=2.25: <italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.13), precision (lossless vs. BPS=3: <italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.06; lossless vs. BPS=2.5: <italic>P</italic> &lt; 1 × 10<sup>−5</sup>, effect size = 0.08; lossless vs. BPS=2.25: <italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.11), and recall (lossless vs. BPS=3: <italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.08; lossless vs. BPS=2.5: <italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.1; lossless vs. BPS=2.25: <italic>P</italic> &lt; 1 × 10<sup>−10</sup>, effect size = 0.13) (<xref rid="fig8" ref-type="fig">Figure 8a</xref> - bottom). For reference, <xref rid="fig8" ref-type="fig">Figure 8a</xref> also displays the <monospace>Kilosort2.5</monospace> performance curves in dashed red lines. This demonstrates that running <monospace>Kilosort4</monospace> on data with the highest level of lossy compression (BPS=2.25) still outperforms its predecessor on lossless data (he hybrid data for <monospace>Kilosort2.5</monospace> were generated with a different random seed, but with the exact same parameters). For all well-detected units across both probe types, there were minimal differences in the refractory period contamination (<xref rid="fig8" ref-type="fig">Figure 8d</xref>, <italic>P</italic> = 0.044) and presence ratio (<xref rid="fig8" ref-type="fig">Figure 8e</xref>, <italic>P</italic> = 0.65). This indicates that, even for the highest compression settings, the overall quality of the detected units remains the same.</p>
<p>This benchmarking application had an effective run time of 18 hours for Neuropixels 1.0 and 16 hours for Neuropixels 2.0 (<xref rid="tbl2" ref-type="table">Table 2</xref>). Without distributed computing, the same evaluations would have taken 1590 hours (over 66 days) for Neuropixels 1.0 and 1684 hours (over 70 days) for Neuropixels 2.0.</p>
</sec>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We developed two pipelines for spike sorting large-scale electrophysiology data. The first encompasses all steps needed to extract spiking information from raw voltage traces and package them in a format that can be ingested for downstream analysis. The second is designed for rapidly evaluating the performance of different spike sorting algorithms, or measuring the impact of particular preprocessing steps on spike sorting accuracy. Both pipelines can run in the cloud, making it straightforward to parallelize almost every data processing step across multiple machines. When used in conjunction with <monospace>Code Ocean</monospace>, cloud resources can be provisioned via a user-friendly graphical interface, greatly lowering the barrier for entry for scientists who may have no prior experience with cloud computing. Importantly, though, the use of <monospace>Nextflow</monospace> for workflow orchestration means the same pipeline can also be deployed on local workstations or high-performance computing clusters in cases where these are preferred.</p>
<p>The pipelines balance the often competing demands of flexibility and reproducibility. The pipeline components are from <monospace>SpikeInterface</monospace>, because this package defines standardized Python objects for passing data between modules, making it straightforward to add, remove, or modify processing steps on demand. <monospace>SpikeInterface</monospace> (in conjunction with the <monospace>Neo</monospace> library) ensures the pipelines support input data from with virtually any acquisition device and recording apparatus used in the field. As new spike sorting tools and/or processing techniques are added to the <monospace>SpikeInterface</monospace> package, they will require minimal effort to be incorporated into our pipeline. As an example, the pipeline already supports two motion correction algorithms, DREDge (<xref ref-type="bibr" rid="c61">Windolf et al. 2025</xref>) and MEDiCINe (<xref ref-type="bibr" rid="c60">Watters et al. 2025</xref>), which were released in 2025. Maintaining this level of flexibility does not compromise reproducibility, as all code used in the pipeline can be traced to a specific commit in a <monospace>GitHub</monospace> repository, and all functions are executed inside standardized Docker or Singularity containers. This ensures that the exact same steps can be re-run in a reproducible manner, even if the hardware backend changes.</p>
<p>The spike sorting pipeline has been in use by all electrophysiology projects at the Allen Institute for Neural Dynamics for over a year. It has been used to sort data from over 1,000 sessions, finding over 1 million putatively neural units. This operational experience has helped refine the pipeline’s performance, robustness, and usability, positioning it as a mature and reliable tool for other research groups. The spike sorting pipeline is already being used by around 50 researchers at the Kempner Institute at Harvard University, and it is being adopted by other institutes as an end-to-end standardized spike sorting solution.</p>
<p>The results of the benchmarking pipeline Application #1 motivated our decision to replace <monospace>Kilosort2.5</monospace> with <monospace>Kilosort4</monospace> as the default spike sorter in our spike sorting pipeline. We found that <monospace>Kilosort4</monospace> could more accurately identify ground truth spikes (<xref rid="fig7" ref-type="fig">Figure 7</xref>), which corroborated the results of the original paper describing this algorithm (<xref ref-type="bibr" rid="c49">Pachitariu et al. 2024</xref>). We extended this result to data with the same noise characteristics and spiking statistics as what we were actively collecting, as well as to data from Neuropixels 2.0, which differs in its signal bandwidth and bit depth from Neuropixels 1.0.</p>
<p>We also used the benchmarking pipeline to test the impact of lossy compression on spike sorting accuracy (using <monospace>Kilosort4</monospace>). We previously showed that the <monospace>WavPack</monospace> audio compression algorithm, operating in lossless mode, achieved higher compression ratios for electrophysiology data than any general-purpose codecs (<xref ref-type="bibr" rid="c7">Buccino et al. 2023</xref>). In lossy mode, <monospace>WavPack</monospace> could reduce file sizes by more than 2x the lossless versions, with minimal distortion of spike waveform shapes. Such a decrease in file size has the potential to save many thousands of dollars in data storage costs, so there was a strong impetus to determine whether lossy compression has any adverse effects on downstream data processing. Here, we observe no impact on spike sorting performance after applying lossy compression to Neuropixels 1.0 data, and a slight degradation for Neuropixels 2.0 data. Even for Neuropixels 2.0, the overall impact on spike sorting quality is quite small, such that at the highest compression setting spikes are still detected more accurately by <monospace>Kilosort4</monospace> than by <monospace>Kilosort2.5</monospace> operating on lossless data (<xref rid="fig8" ref-type="fig">Figure 8a</xref>). The minimal impact of 7× compression ratios on sorter performance (<xref rid="fig8" ref-type="fig">Figure 8b</xref>) makes lossy compression with <monospace>WavPack</monospace> an attractive option as electrophysiology datasets expand to thousands of channels and across many days of continuous recording.</p>
</sec>
<sec id="s4">
<title>Limitations of our approach</title>
<p>The majority of laboratories performing large-scale electrophysiology typically insert one or two probes per experiment. Therefore, when running spike sorting on local workstations with a single GPU, they will experience minimal speedup from using our pipeline in comparison to calling <monospace>SpikeInterface</monospace> directly. In addition, <monospace>SpikeInterface</monospace> is implemented in pure Python, whereas <monospace>Nextflow</monospace> depends on a Java installation (no longer available by default on most operating systems), and requires Windows Subsystem for Linux to run in a Windows environment. That said, for many scientists, the benefits of standardization and reproducibility offered by our pipeline will more than justify the additional setup and run time. The ability to trace the exact code and parameters used to generate a spike sorting result represents an important step toward transparent and publishable analyses. Moreover, access to a wide range of visualization tools and quality metrics enables rigorous data validation and facilitates meaningful comparisons across labs.</p>
<p>Another limitation is related to integration with tools for manually inspecting spike sorting outputs. Currently, the spike sorting pipeline creates <monospace>sortingview</monospace> links that can be used to remotely view and curate spike sorting outputs. However, many users may prefer to perform curation on a local workstation with tools such as <monospace>phy</monospace> (<xref rid="c51" ref-type="bibr">Rossant et al. 2025</xref>) or <monospace>JRClust GUI</monospace> (<xref rid="c31" ref-type="bibr">Jun et al. 2025</xref>), which are fast and provide access to the raw data. While <monospace>SpikeInterface</monospace> does provide the ability to export data into <monospace>phy</monospace> format, our pipeline does not natively support <monospace>phy</monospace> or other desktop visualization tools. To mitigate this issue, we are taking a two-pronged approach. First, <monospace>SpikeInterface</monospace> should integrate the latest tools for automated curation, such as cluster labeling and merging/splitting. In many cases, existing tools such as <monospace>UnitRefine</monospace> already do most of the labeling that was previously done manually. LLM-based tools could also provide guidance for automated curation (<xref ref-type="bibr" rid="c36">Lin et al. 2025</xref>). Secondly, we are developing <monospace>SpikeInterface-GUI</monospace> (<xref ref-type="bibr" rid="c18">Garcia &amp; Buccino 2025</xref>), a desktop- and web-based curation interface with full access to raw data, which would further enhance usability and encourage broader adoption. <monospace>SpikeInterface-GUI</monospace> can readily open the postprocessed data generated by the spike sorting pipeline, and already includes many of the features of the previously mentioned tools.</p>
</sec>
<sec id="s5">
<title>Future directions</title>
<p>Looking ahead, we plan to expand our spike sorting pipeline’s capabilities with advanced curation workflows, broader support for emerging spike sorting methods, and streamlined deployment across diverse backends. The benchmarking pipeline will continue to develop as an open evaluation framework, enabling transparent and reproducible comparisons of spike sorting and preprocessing methods across the community. As growing datasets make manual curation increasingly impractical, such automated and standardized evaluation will become even more essential.</p>
<p>Although we ultimately view full automation of spike sorting as necessary for reproducibility, the field is not yet at that point. For this reason, we include interfaces for manual curation as part of our core pipeline. We anticipate that machine learning–based approaches will soon eliminate the need for human intervention, and the flexibility of our framework will allow these methods (as well as new spike sorting algorithms) to be readily incorporated. Importantly, our benchmarking tools can be used to evaluate and compare the accuracy of different curation strategies that operate without a human in the loop.</p>
<p>By providing an open, transparent, and well-documented framework, we aim to advance reproducibility and efficiency in the analysis of large-scale electrophysiology data. We hope our pipelines will accelerate community-driven improvements in spike sorting algorithms and lower technical barriers to adopting the most up-to-date approaches. As the field moves toward even more comprehensive and integrative views of brain function, a robust spike sorting ecosystem is just as critical to progress as scaling up the number of channels on each recording device.</p>
</sec>
<sec id="s6">
<title>Methods</title>
<sec id="s6a">
<title>Spike sorting pipeline steps</title>
<sec id="s6a1">
<title>Job Dispatch</title>
<p>The job dispatch step scans an input directory containing raw electrophysiology data from one session and creates a list of <italic>job</italic> JSON files that control parallelization. Each JSON file contains a <monospace>recording_dict</monospace>, a dictionary representation of the <monospace>SpikeInterface Recording</monospace> (<ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.core.BaseRecording">https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.core.BaseRecording</ext-link>) object. Each <monospace>Recording</monospace> represents data from one contiguously sampled interval and one device, also known as a “stream.” The JSON file allows downstream processes to easily reload the <monospace>Recording</monospace> (using the <monospace>spikeinterface.load()</monospace> (<ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.core.load">https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.core.load</ext-link>) function) while keeping the size of data passed through different processes minimal. For probes that acquire separate high-frequency (AP) and low-frequency (LFP) streams (e.g., Neuropixels 1.0), a link to both data files is stored in the JSON file, as this information is used at the NWB Packaging step. The JSON file also contains a <monospace>session_name</monospace> and <monospace>recording_name</monospace> that are used throughout the pipeline to track the session and recording identity.</p>
<p>The <monospace>input</monospace> parameter allows the user to specify one of five formats for the input data:</p>
<list list-type="order">
<list-item><p><monospace>spikeglx</monospace></p></list-item>
<list-item><p><monospace>openephys</monospace></p></list-item>
<list-item><p><monospace>nwb</monospace></p></list-item>
<list-item><p><monospace>aind</monospace></p></list-item>
<list-item><p><monospace>spikeinterface</monospace></p></list-item>
</list>
<p>(<monospace>aind</monospace> is an internal format used at AIND which includes an <monospace>Open Ephys</monospace> folder with clipped binary files, <monospace>Zarr</monospace>-compressed traces, and metadata files.)</p>
<p>For the <monospace>spikeinterface</monospace> input, the <monospace>spikeinterface_info</monospace> field provides further information on how to read the data and attach the required probe information. For example, here is a sample <monospace>spikeinterface_info</monospace> for a dataset recorded by a data acquisition system from Intan Technologies:</p>
<fig id="ufig1" position="float" fig-type="figure">
<graphic xlink:href="687966v1_ufig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As a subset of stream may not contain neural data, the <monospace>keep/skip_stream_substrings</monospace> fields enable users to filter which streams to process with the full spike sorting pipeline (in the example above, streams with names containing the string “EVENTS” would be ignored). The <monospace>probe_paths</monospace> field allows users to specify paths to JSON files represented in <monospace>ProbeInterface</monospace> format to attach probe information to each recording (<xref ref-type="bibr" rid="c20">Garcia et al. 2022</xref>).</p>
<p>The input data folder can contain multiple <italic>blocks</italic> and <italic>segments</italic>, as defined in the <monospace>Neo</monospace> data model (<ext-link ext-link-type="uri" xlink:href="https://neo.readthedocs.io/en/stable/">https://neo.readthedocs.io/en/stable/</ext-link>, <xref ref-type="bibr" rid="c19">Garcia et al. 2014</xref>). These concepts are inherited in <monospace>SpikeInterface</monospace>. A block typically refers to data from a single session or experiment (i.e., from one subject on one day). A segment represents data recorded contiguously within a block. For example, an <monospace>Open Ephys</monospace> input folder could contain multiple “experiments” (blocks) each with multiple “recordings” (segments) (a new recording is started whenever the experimenter pauses and then resumes the acquisition. A new experiment is made when the experimenter stops and restarts acquisition) or an <monospace>NWB</monospace> file could contain several electrical series in its acquisition field. If the input data contains multiple blocks, each block will always be processed separately. For blocks with multiple segments, the user can choose whether to concatenate them (one JSON file is produced for the concatenated segments) or keep them separate (one JSON file is produced for each segment). The <monospace>split_segments</monospace> parameter controls this behavior.</p>
<p>In addition to producing multiple JSON files for each block (and optionally segment), this step also provides the option to split the channels of a recording into groups (e.g., individual shanks) that will be sorted independently. Channel groups are loaded automatically in the case of Neuropixels input data (recorded with <monospace>Open Ephys</monospace> or <monospace>SpikeGLX</monospace>) and also for <monospace>NWB</monospace> files (where this information is stored in the <monospace>electrodes</monospace> table). For input data loaded in <monospace>spikeinterface</monospace> format, the channel groups can be specified in the probe JSON file.</p>
<p>In addition, the job JSON files also include a <italic>debug</italic> flag, to communicate that the pipeline was started in debug mode, and a <italic>skip times</italic> flag that is set to true if the timestamps are corrupted and non-monotonically increasing, which is used to inform the NWB packaging step to reset the timestamp information.</p>
<p>The GitHub repository associated with this step can be found at: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-job-dispatch">https://github.com/AllenNeuralDynamics/aind-ephys-job-dispatch</ext-link></p>
</sec>
<sec id="s6a2">
<title>Preprocessing</title>
<p>The preprocessing step is the first step that runs in parallel. A separate preprocessing instance is spawned for each JSON file produced by the job dispatch step. First, the preprocessing step reloads the <monospace>Recording</monospace> object from the JSON file. The recording then undergoes four transformations: phase shift, filtering, denoising, and motion estimation/correction.</p>
<p>The <monospace>phase_shift</monospace> (<ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.preprocessing.phase_shift">https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.preprocessing.phase_shift</ext-link>) function was originally developed by the International Brain Laboratory (IBL) (<xref ref-type="bibr" rid="c27">International Brain Laboratory 2024</xref>). The correction for these channel-wise “delays” is performed in the frequency domain, where a time delay corresponds to a phase shift rotation. The signal is therefore first FFT-transformed, then the delay is applied by rotating the phase of the signal in the frequency domain by <inline-formula id="inline-eqn-1"><inline-graphic xlink:href="687966v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> where <italic>t</italic><sub><italic>c</italic></sub> is the inter sample shift for channel <italic>c</italic>, which represents the relative delay within the sampling period (between 0 and 1). Finally the FFT transform is inverted to return to the time domain. For Neuropixels data, the <italic>inter sample shift</italic> property is loaded automatically from the probe metadata. For other probe types, this property must be explicitly specified.</p>
<p>For the filtering step, a 5th order Butterworth <monospace>highpass_filter</monospace> with cutoff frequency at 300 Hz is applied by default. Users can optionally select <monospace>bandpass_filter</monospace> with cutoffs at 300 Hz and 6 kHz. The filter type, cutoff frequencies, and filter orders can be modified by the user. Internally, the <monospace>SpikeInterface</monospace> functions use the <monospace>scipy.filtfilt</monospace> function that applies a forward and a backward pass to maintain zero phase.</p>
<p>The denoising step performs channel masking followed by global denoising. The <monospace>detect_bad_ channels</monospace> (<ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.preprocessing.detect_bad_channels">https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.preprocessing.detect_bad_channels</ext-link>) function is run using the <monospace>coherence+psd</monospace> method, which is ported from IBL (<xref ref-type="bibr" rid="c27">International Brain Laboratory 2024</xref>). “Dead” channels are detected based on a low similarity with surrounding neighbor channels. “Noise” channels are those whose power between 80% and 100% of the Nyquist frequency is above a certain threshold (default = 0.02 µV<sup>2</sup> / Hz) and have a high coherence (&gt;1) with nearby channels (normal channels have coherence around 0, see <xref ref-type="bibr" rid="c27">International Brain Laboratory 2024</xref>). “Out” channels are channels at the top of the probe with low similarity to other non-neighboring channels, and are assumed to be outside the brain. The final channel labels are obtained as a majority vote on labels from 100 300-ms chunks randomly sampled throughout the recording. All three types of channels (<italic>dead, noise, out</italic>) are removed from the recording by default. Optionally, the user can choose to keep <italic>out</italic> channels (<monospace>remove_out_channels</monospace> parameter) or to keep <italic>dead</italic>/<italic>noise</italic> channels (<monospace>remove_out_channels</monospace> parameter). If more than 50% of channels are removed from a given stream, further processing (including spike sorting) is skipped. Downstream processing is also skipped if the recording duration is too small (by default &lt; 120 seconds). Both the fraction of remaining channels required to skip further processing and the minimum recording duration can be adjusted by the user. After removing channels, a global denoising step is performed via Common Median Reference (CMR) or highpass spatial filtering, also referred to as destriping (<xref ref-type="bibr" rid="c27">International Brain Laboratory 2024</xref>).</p>
<p>Finally, motion is estimated and optionally corrected for. The motion correction step uses the <monospace>compute_motion</monospace> (<ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.preprocessing.compute_motion">https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.preprocessing.compute_motion</ext-link>) function, which can estimate the motion from the recording using several presets. By default, the <monospace>dredge_fast</monospace> preset is used, which uses the <monospace>grid_convolution</monospace> method to speed up spike depth estimation and <monospace>DREDge</monospace> for motion estimation (<xref ref-type="bibr" rid="c61">Windolf et al. 2025</xref>). The <monospace>grid_convolution</monospace> method for spike localization, introduced by (<xref ref-type="bibr" rid="c49">Pachitariu et al. 2024</xref>), uses an exhaustive catalog of artificial templates at known positions to estimate the position of a given spike as the weighted average of the spike waveform projected onto the templates in this catalog. For more details on spike localization and motion correction methods in general, we refer the reader to (<xref ref-type="bibr" rid="c21">Garcia et al. 2024</xref>). By default, motion is only estimated and not “applied” to the traces. This is done to let the spike sorter perform its own motion correction. However, the user can opt to also apply motion correction (setting <monospace>preprocessing.motion</monospace> parameter to <monospace>apply</monospace>) or to skip this step entirely (setting <monospace>preprocessing.motion</monospace> parameter to <monospace>skip</monospace>). When motion is applied, the traces are interpolated in space using <italic>kriging</italic> interpolation depending on the motion signals (<xref ref-type="bibr" rid="c21">Garcia et al. 2024</xref>).</p>
<p>After preprocessing, the recording is saved to a temporary binary file to speed up downstream steps. This is done in parallel using 1-second chunks. To minimize artifacts at boundaries, especially due to filtering, each chunk is padded with 5 ms from adjacent chunks. Alongside the binary file, this step also produces JSON files that represent the <italic>lazy</italic> preprocessing chain applied before and after motion correction, to enable <monospace>SpikeInterface</monospace> to reload the preprocessed recording from the raw data.</p>
<p>The GitHub repository associated with this step can be found at: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-preprocessing">https://github.com/AllenNeuralDynamics/aind-ephys-preprocessing</ext-link></p>
</sec>
<sec id="s6a3">
<title>Spike sorting</title>
<p>The spike sorting step first reloads the preprocessed recording saved to the temporary binary file. If the recording is multi-segment and the spike sorter doesn’t support multi-segment recordings, the segments are concatenated. The spike sorter (loaded from a versioned <monospace>DockerHub</monospace> container image) is then run on the input data. After spike sorting is complete, the output is re-split into multiple segments and any units with no spikes are removed. Spikes exceeding the number of samples of the recording, if any, are also removed (with the <monospace>remove_excess_spikes</monospace> (<ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.curation.remove_excess_spikes">https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.curation.remove_excess_spikes</ext-link>) function). The spike sorting output (a <monospace>Sorting</monospace> (<ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.core.BaseSorting">https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.core.BaseSorting</ext-link>) object) is saved to a <monospace>SpikeInterface</monospace> folder with the <monospace>sorting.save(folder=“…”)</monospace> function, so that it can be easily reloaded.</p>
<p>There is a separate GitHub repository for the spike sorting step associated with each sorter currently supported by the pipeline:</p>
<list list-type="bullet">
<list-item><p>Kilosort4: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-spikesort-kilosort4">https://github.com/AllenNeuralDynamics/aind-ephys-spikesort-kilosort4</ext-link></p></list-item>
<list-item><p>SpyKING CIRCUS2: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-spikesort-spykingcircus2">https://github.com/AllenNeuralDynamics/aind-ephys-spikesort-spykingcircus2</ext-link></p></list-item>
<list-item><p>Kilosort2.5: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-spikesort-kilosort25">https://github.com/AllenNeuralDynamics/aind-ephys-spikesort-kilosort25</ext-link></p></list-item>
</list>
</sec>
<sec id="s6a4">
<title>Postprocessing</title>
<p>The postprocessing step takes the preprocessed recording and the spike sorting output as inputs. These are combined into a <monospace>SortingAnalyzer</monospace> (<ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.core.SortingAnalyzer">https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.core.SortingAnalyzer</ext-link>), which is the central object for performing additional computations. At instantiation, the <italic>sparsity</italic> of each unit, i.e., the set of channels the unit is defined on, is calculated via a fast template estimation using 100 uniformly sampled spikes per unit. The sparsity includes the channels within a 100 µm radius from the channel with the largest amplitude (<italic>extremum</italic> channel). A first <monospace>SortingAnalyzer</monospace> object is created and used only to remove duplicated units (<monospace>remove_duplicated_units</monospace> (<ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.curation.remove_duplicated_units">https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.curation.remove_duplicated_units</ext-link>) function), which are pairs of units that share over 90% of their spikes. We retain the unit whose spike times are best aligned to the template peak (knowing the cutouts used to compute the template). After duplicated units are removed, a new <monospace>SortingAnalyzer</monospace> runs the following <italic>extensions</italic>:</p>
<list list-type="order">
<list-item><p><monospace>random_spikes</monospace>: Uniformly samples a certain number of spike for all units (default = 500).</p></list-item>
<list-item><p><monospace>noise_levels</monospace>: Randomly samples snippets of the preprocessed recording (default = 20 snippets of 500 ms each) and computes the median absolute deviation as a proxy of noise level for each channel.</p></list-item>
<list-item><p><monospace>waveforms</monospace>: Retrieves and saves sparse waveforms for the randomly sampled spikes (scaled to µV) and saves them as a 3D array with dimensions (<monospace>n_spikes</monospace>, <monospace>n_samples</monospace>, <monospace>n_max_sparse_channels</monospace>). The default cutout is −3 ms/+4 ms (i.e, 140 samples for a 30 kHz recording). Note that it might happen that some units, especially at the border of the probe, have fewer sparse channels than others: in this case, the waveforms array is padded with <monospace>NaN</monospace> values.</p></list-item>
<list-item><p><monospace>templates</monospace>: Computes each unit’s template as the mean of the sampled waveforms (when <monospace>waveforms</monospace> are available). In addition, it also computes the median and standard deviation of the waveforms.</p></list-item>
<list-item><p><monospace>template_similarity</monospace>: Computes the pairwise template similarity using L1 distance. This metric is preferred over other similarity metrics, such as cosine similarity, because the latter is not sensitive to amplitude differences.</p></list-item>
<list-item><p><monospace>correlograms</monospace>: Computes auto- and cross-correlograms for each pair of units using a bin size of 1 ms and a window of ±50 ms.</p></list-item>
<list-item><p><monospace>isi_histograms</monospace>: Computes inter-spike-interval histograms for each unit using a bin size of 5 ms and a window of 100 ms.</p></list-item>
<list-item><p><monospace>unit_locations</monospace>: Uses the unit templates to estimate the x, y, and z location with respect to the probe. This is done using the monopolar triangulation method, which models the peak-to-peak amplitudes of the templates on each channel as being generated by a current monopole:
<disp-formula id="ueqn1">
<graphic xlink:href="687966v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>ptp</italic><sub><italic>c</italic></sub> is the peak-to-peak amplitude of channel <italic>c</italic>; <italic>x</italic><sub><italic>c</italic></sub>, <italic>y</italic><sub><italic>c</italic></sub>, and <italic>z</italic><sub><italic>c</italic></sub> are the x, y, and z position of channel <italic>c, x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>, and <italic>z</italic><sub><italic>i</italic></sub> are the x, y, and z position of the unit <italic>i</italic>; and <italic>k</italic> is a term that includes the magnitude of the current and propagation properties of the tissue (see <xref ref-type="bibr" rid="c6">Buccino et al. 2018</xref> and <xref ref-type="bibr" rid="c21">Garcia et al. 2024</xref> for more details). The method finds the <italic>k, x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>, and <italic>z</italic><sub><italic>i</italic></sub> that minimize the error between the observed and reconstructed <italic>ptp</italic><sub><italic>c</italic></sub> on the sparse channels.</p></list-item>
<list-item><p><monospace>spike_amplitudes</monospace>: Retrieves the voltage value for each spike, sampling the traces at the extremum channel for each unit.</p></list-item>
<list-item><p><monospace>spike_locations</monospace>: Calculates a location for each spike using the grid convolution method, as explained in the <bold>Preprocessing</bold> section.</p></list-item>
<list-item><p><monospace>principal_components</monospace>: Uses the randomly sampled spikes for each unit to fit PCA (principal component analysis) models for each channel. This is done by incrementally fitting the waveforms from each unit on the channels they are defined on. After fitting the models, each of the randomly sampled waveform is projected on its sparse channels, so that the output is a 3D array with dimensions (<monospace>n_spikes</monospace>, <monospace>n_components</monospace>, <monospace>n_max_sparse_channels</monospace>).</p></list-item>
<list-item><p><monospace>template_metrics</monospace>: Computes several features that characterizes the templates. Prior to the computation, templates are upsampled by a factor of 10.</p>
<p>These metrics are computed from the extremum channel:</p>
<list list-type="bullet">
<list-item><p><monospace>peak_to_valley</monospace>: spike duration between negative and positive peaks</p></list-item>
<list-item><p><monospace>halfwidth</monospace>: spike duration at 50% of the amplitude during the negative peak</p></list-item>
<list-item><p><monospace>peak_to_trough_ratio</monospace>: ratio between negative and positive peaks</p></list-item>
<list-item><p><monospace>recovery_slope</monospace>: spike slope between the negative peak and the next zero-crossing</p></list-item>
<list-item><p><monospace>repolarization_slope</monospace>: spike slope between the positive peak and the next zero-crossing</p></list-item>
<list-item><p><monospace>num_positive_peaks</monospace>: the number of positive peaks in the template</p></list-item>
<list-item><p><monospace>num_positive_peaks</monospace>: the number of negative peaks in the template</p>
<p>All durations are in seconds and slopes in µV / s.</p>
<p>In addition to these one-dimensional metrics (that use the template on a single channel), this extension also computes the following multi-channel metrics:</p></list-item>
<list-item><p><monospace>velocity_above</monospace>: the propagation velocity above the extremum channel of the template (over the probe depth direction)</p></list-item>
<list-item><p><monospace>velocity_below</monospace>: the propagation velocity below the extremum channel of the template (over the probe depth direction)</p></list-item>
<list-item><p><monospace>exp_decay</monospace>: the exponential decay of the template amplitudes over distance from the extremum channel</p></list-item>
<list-item><p><monospace>spread</monospace>: the spread of the template, computed as the distance of the Gaussian-filtered peak-to-peak amplitudes over depth (default smooth factor: 20 µm) which are above 20% of the maximum peak-to-peak amplitude.</p>
<p>Velocities are in µm / s, and spread and exponential decay are in µm. For more information on template metrics, we refer the reader to the <monospace>SpikeInterface</monospace> documentation <ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/stable/modules/postprocessing.html#template-metrics">https://spikeinterface.readthedocs.io/en/stable/modules/postprocessing.html#template-metrics</ext-link>.</p></list-item>
</list>
</list-item>
<list-item><p><monospace>quality_metrics</monospace>: this extension computes the following quality metrics for each unit: <italic>num spikes, firing rate, presence ratio, SNR, ISI violation, RP violation, sliding RP violation, amplitude cutoff, amplitude median, amplitude CV, synchrony, firing range, drift, isolation distance, l-ratio, d-prime, nearest neighbor, silhouette</italic>.</p></list-item>
</list>
<p>For a detailed description of each quality metric, we refer the reader to the <monospace>SpikeInterface</monospace> documentation <ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/latest/modules/qualitymetrics.html">https://spikeinterface.readthedocs.io/en/latest/modules/qualitymetrics.html</ext-link>.</p>
<p>All parameters that control the computation of any extensions can be modified via the input parameter file. After all extension computations, the <monospace>SortingAnalyzer</monospace> object is saved in <monospace>Zarr</monospace> format.</p>
<p>The GitHub repository associated with this step can be found at: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-postprocessing">https://github.com/AllenNeuralDynamics/aind-ephys-postprocessing</ext-link>.</p>
</sec>
<sec id="s6a5">
<title>Curation</title>
<p>The curation step uses the postprocessed data to apply labels to each unit. There are two set of labels, one based on quality metrics filters (<monospace>default_qc</monospace>), and another based on pre-trained classifiers (<monospace>decoder_label</monospace>). For <monospace>default_qc</monospace>, the user can input a <monospace>pandas.query</monospace> and use any combination of quality metrics computed at the postprocessing steps. The default query is:</p>
<p><italic>isi</italic>_<italic>violations</italic>_<italic>ratio</italic> &lt; 0.5 <italic>and presence</italic>_<italic>ratio</italic> &gt; 0.8 <italic>and amplitude</italic>_<italic>cutoff</italic> &lt; 0.1</p>
<p>Units that satisfy this condition will have the <monospace>default_qc</monospace> value set to <monospace>True</monospace>.</p>
<p>The second set of labels come from <monospace>UnitRefine</monospace> (<xref ref-type="bibr" rid="c30">Jain et al. 2025</xref>), a set of pre-trained classifiers for labeling units after spike sorting. The classifiers were trained on hand-curated labels using quality and template metrics as input. The first classification is between <italic>noise</italic> and <italic>neural</italic> (<ext-link ext-link-type="uri" xlink:href="https://huggingface.co/SpikeInterface/UnitRefine_noise_neural_classifier">SpikeInterface/U-nitRefine_noise_neural_classifier</ext-link>). For the units labeled as <italic>neural</italic>, a second classifier labels them as single versus multi-unit activity (SUA/MUA) (<ext-link ext-link-type="uri" xlink:href="https://huggingface.co/SpikeInterface/UnitRefine_sua_mua_classifier">SpikeInterface/UnitRefine_sua_mua_classifier</ext-link>). <monospace>UnitRefine</monospace> labels are applied to the units using the <monospace>auto_label_units</monospace> (<ext-link ext-link-type="uri" xlink:href="https://spikeinterface.readthedocs.io/en/latest/api.html#spikeinterface.curation.auto_label_units">https://spikeinterface.readthedocs.io/en/latest/api.html#spikeinterface.curation.auto_label_units</ext-link>) function.</p>
<p>The GitHub repository associated with this step can be found at: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-curation">https://github.com/AllenNeuralDynamics/aind-ephys-curation</ext-link>.</p>
</sec>
<sec id="s6a6">
<title>Visualization</title>
<p>The visualization step uses <monospace>Figurl</monospace> and <monospace>sortingview</monospace> to produce shareable links that can be accessed by any device connected to the internet. This technology, integrated into <monospace>SpikeInterface</monospace>, pushes data needed for visualization to an accessible cloud location, whose Uniform Resource Identifier (URI) is embedded in the link itself. When following the generated links, the visualization plugin uses the URI to fetch the data from the cloud and provides rich and interactive tools to browse them. A simple installation step is required to set up this web visualization capability. We recommend creating a custom “zone” (i.e., providing one’s own cloud resources) if heavy usage is expected. More information can be found on the <monospace>Figurl</monospace> documentation page <ext-link ext-link-type="uri" xlink:href="https://github.com/flatironinstitute/figurl/blob/main/README.md">https://github.com/flatironinstitute/figurl/blob/main/README.md</ext-link>.</p>
<p>The visualization step generates two visualization links for each stream. The first link contains snippets of raw traces at different preprocessing stages, a raster plot of the complete session, and a visualization of the estimated motion signals. The second link includes two tabs: one with a web GUI for spike sorting visualization and curation, the second for exploring quality metric distribution and values for each units. Screenshots and links for example visualizations are available in <xref rid="fig3" ref-type="fig">Figure 3</xref>.</p>
<p>The GitHub repository associated with this step can be found at: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-visualization">https://github.com/AllenNeuralDynamics/aind-ephys-visualization</ext-link>.</p>
</sec>
<sec id="s6a7">
<title>Quality control</title>
<p>The quality control step parallelizes over streams from the output of the Result Collection. For each stream, it produces the following metrics and figures:</p>
<sec id="s6a7a">
<title>Raw data</title>
<p>Plots 0.1 s AP and LFP traces at three points uniformly distributed over the recording duration. In case of wide-band input data, a 300 Hz highpass filter is used to extract the AP band, and a 0.1-500 Hz bandpass filter for the LFP band. These plots are used to inspect raw traces for artifacts, noise, and spiking activity.</p>
</sec>
<sec id="s6a7b">
<title>PSD</title>
<p>Displays the Power Spectral Density of all channels both as a line plot and as a map, with the power over channel depth. The PSD is computed at three points uniformly distributed over the recording duration from 1 s snippets of traces. Three figures are generated for each stream: the first uses the unfiltered raw signal, the second focuses on the low-frequency (showing the 0.1-100 Hz band after applying a 0.1-500 Hz bandpass filter), and the third focuses on high frequency (showing the 5-15 kHz band after applying a 3 kHz highpass filter). These plots can be used to identify localized noise sources, such as 50 or 60 Hz line contamination.</p>
</sec>
<sec id="s6a7c">
<title>Noise</title>
<p>Computes the root mean squared (RMS) values of each channel from the raw data and preprocessed data (using 20 chunks of 500 ms randomly sampled across the recording). The RMS values are plotted as lines over depths and can be useful for spotting abnormal channels, confirming the presence of channels outside of the brain, and checking that denoising resulted in lower noise levels than the raw data.</p>
</sec>
<sec id="s6a7d">
<title>Drift</title>
<p>Uses the preprocessed data and pre-computed motion estimation to plot a raster map with overlaid estimated motion signals. This can be used to assess the overall drift in the recording and whether motion correction methods accurately estimated it. (<xref rid="fig3" ref-type="fig">Figure 3c</xref>).</p>
</sec>
<sec id="s6a7e">
<title>Saturation</title>
<p>Detects events in the raw data where the signal reaches to the maximum or minimum voltage that the acquisition system can record. It produces a raster plot of positive and negative saturation events over time and a count of such events. These plots are used to assess the presence and extent of artifacts that result in ADC saturation, assuming the threshold voltage is known.</p>
</sec>
<sec id="s6a7f">
<title>Unit Yield</title>
<p>Summarizes the output of the spike sorting, postprocessing, and curation steps by plotting histograms of selected quality metrics and scatter plots of unit amplitudes and firing rates over depth. It also displays a summary of the number of units in each category detected by curation step (# noise, # SUA, # MUA, and # units passing default QC) (<xref rid="fig3" ref-type="fig">Figure 3e</xref>). These plots are used to assess the overall yield and quality of the spike sorting.</p>
</sec>
<sec id="s6a7g">
<title>Firing Rate</title>
<p>Produces a plot with the population firing rate (all units pooled together) over time, which is used to assess whether there are intervals with abnormally high or low activity during the recording (e.g., due to seizure-like events).</p>
<p>All figures are saved as <monospace>.png</monospace> files in the <monospace>quality_control</monospace> folder in the results and organized into a <monospace>quality_control.json</monospace> file following the AIND Data Schema <monospace>QualityControl</monospace> specification (see <bold>AIND Data Schema</bold>).</p>
<p>The quality control step includes two processes: one for computing metrics and plotting (run in parallel for each stream), and a second one to collect and organize the QC for different streams.</p>
<p>The GitHub repositories associated with this step can be found at:</p>
<list list-type="bullet">
<list-item><p><ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-processing-qc">https://github.com/AllenNeuralDynamics/aind-ephys-processing-qc</ext-link></p></list-item>
<list-item><p><ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-qc-collector">https://github.com/AllenNeuralDynamics/aind-ephys-qc-collector</ext-link></p></list-item>
</list>
</sec>
</sec>
<sec id="s6a8">
<title>Result collection</title>
<p>The result collection step gathers the output from all streams and re-organizes it into the folders described in <bold>Spike sorting pipeline output</bold>. Importantly, this step propagates any labels computed by the curation step to the <monospace>SortingAnalyzer Zarr</monospace> folders, so that these objects include all the information and computation outputs from the pipeline.</p>
<p>The GitHub repository associated with this step can be found at: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-results-collector">https://github.com/AllenNeuralDynamics/aind-ephys-results-collector</ext-link>.</p>
</sec>
<sec id="s6a9">
<title>NWB Packaging</title>
<p>The <monospace>SpikeInterface</monospace> objects generated throughout the pipeline are converted to NWB using functions from <monospace>neuroconv</monospace> (<xref ref-type="bibr" rid="c44">Mayorquin et al. 2025</xref>). Each NWB file includes the following data:</p>
<list list-type="bullet">
<list-item><p>Device/Electrodes/Electrode groups: Relevant probe metadata is automatically fetched from the input data, including probe serial number, manufacturer, name, electrode locations, and channel groups (e.g., for multi-shank probes).</p></list-item>
<list-item><p>LFP: By default, LFP traces are downsampled in space and time.</p></list-item>
<list-item><p>Units: All units from different probes are combined into one table that stores spike times, wave-forms, and quality/template metrics.</p></list-item>
<list-item><p>Raw traces (<italic>optional</italic>): Raw traces are not stored by default, as doing so would greatly increase the size of the NWB file.</p></list-item>
</list>
<p>When the pipeline input data is not already in <monospace>NWB</monospace> format, it is recommended to add <monospace>subject.json</monospace> and <monospace>data_description.json</monospace> files following the AIND Data Schema specification (Subject <ext-link ext-link-type="uri" xlink:href="https://aind-data-schema.readthedocs.io/en/stable/subject.html">https://aind-data-schema.readthedocs.io/en/stable/subject.html</ext-link>; <ext-link ext-link-type="uri" xlink:href="https://aind-data-schema.readthedocs.io/en/stable/data_description.html">DataDescription</ext-link>) to the input data folder, so that this information can be used to instantiate NWB files with the correct metadata. In case these files are missing, NWB files with mock metadata will be created instead.</p>
<p>Both LFP and raw traces (if saved) are compressed using the <monospace>Zstandard</monospace> codec (<xref ref-type="bibr" rid="c17">Facebook 2025</xref>) implemented via Blosc (<xref ref-type="bibr" rid="c58">The Blosc Development Team 2025</xref>), which showed the best performance among natively supported codecs in <monospace>Zarr</monospace> (<xref ref-type="bibr" rid="c7">Buccino et al. 2023</xref>).</p>
<p>The NWB export step is carried out by two separate processes. The first one generates base NWB files with session and subject information and adds data from the raw <italic>ecephys</italic> input folder (Device/Electrodes/Electrode groups, LFP and optionally raw traces); the second one adds the post-spike sorting and curation data (Units table).</p>
<p>The GitHub repositories associated with these two processes are:</p>
<list list-type="bullet">
<list-item><p><ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ecephys-nwb">https://github.com/AllenNeuralDynamics/aind-ecephys-nwb</ext-link></p></list-item>
<list-item><p><ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-units-nwb">https://github.com/AllenNeuralDynamics/aind-units-nwb</ext-link></p></list-item>
</list>
</sec>
</sec>
<sec id="s6b">
<title>Spike sorting pipeline output</title>
<p>The spike sorting pipeline output is organized into a single “results” folder with following sub-directories:</p>
<list list-type="bullet">
<list-item><p><monospace><bold>preprocessed/</bold></monospace>: JSON files with preprocessed data for each recording stream, alongside subdirectories containing motion estimation results.</p></list-item>
<list-item><p><monospace><bold>spikesorted/</bold></monospace>: Raw spike sorting outputs.</p></list-item>
<list-item><p><monospace><bold>postprocessed/</bold></monospace>: <monospace>Zarr</monospace>-format <monospace>SortingAnalyzer</monospace> outputs with computed extensions.</p></list-item>
<list-item><p><monospace><bold>curated/</bold></monospace>: Information about unit deduplication and classification (e.g., noise, multi-unit activity, single-unit activity) labels. Properties such as <monospace>default_qc</monospace> and <monospace>decoder_label</monospace> are available for downstream analysis and validation.</p></list-item>
<list-item><p><monospace><bold>visualization_output.json</bold></monospace>: <monospace>Figurl</monospace> links for interactive visualization of each stream.</p></list-item>
<list-item><p><monospace><bold>quality_control/ and quality_control.json</bold></monospace>: QC visualizations and a JSON file following the <monospace>QualityControl</monospace> schema from the AIND Data Schema (see <bold>AIND Data Schema</bold>).</p></list-item>
<list-item><p><monospace><bold>nwb/</bold></monospace>: Neurodata Without Borders (NWB) files, with one file per block or segment. Each NWB file includes curated spike times and unit IDs, electrode metadata, and (optionally) local field potential (LFP) signals.</p></list-item>
<list-item><p><monospace><bold>nextflow/</bold></monospace>: Workflow metadata, provenance information, timeline, and execution logs.</p></list-item>
<list-item><p><monospace><bold>processing.json</bold></monospace>: Logs processing steps, parameters, and execution times, following the <monospace>Processing</monospace> schema from the AIND Data Schema specification (see <bold>AIND Data Schema</bold>).</p></list-item>
</list>
</sec>
<sec id="s6c">
<title>Evaluation pipeline steps</title>
<p>The evaluation pipeline re-uses the Job Dispatch and Spike Sorting (<monospace>Kilosort2.5</monospace> and <monospace>Kilosort4</monospace>) steps of the spike sorting pipeline. The three steps unique to the evaluation pipeline are described below:</p>
<sec id="s6c1">
<title>Hybrid generation</title>
<p>The hybrid generation step begins by estimating motion of the input recording using <monospace>DREDge</monospace>, after light preprocessing (highpass and common median reference). Depending on the probe attached to the recording, which is part of the <monospace>Recording</monospace> metadata, the templates available through the <monospace>SpikeInterface</monospace> template library are fetched (with the <monospace>fetch_templates_database_info()</monospace> function) and pre-filtered by probe type.</p>
<p>For Neuropixels 1.0 recordings, templates from the International Brain Lab (IBL) Brain-Wide Map (<xref rid="c27" ref-type="bibr">International Brain Laboratory et al. 2024</xref>; <xref rid="c28" ref-type="bibr">International Brain Laboratory et al. 2025</xref>) are selected (2,183 templates from 37 different insertions). For other types of probes, including Neuropixels 2.0, high-density Neuropixels Ultra templates from <xref ref-type="bibr" rid="c56">Steinmetz &amp; Ye 2022</xref> are used (5,694 templates).</p>
<p>Next, we randomly select <italic>T</italic> templates out of the pre-filtered templates by probe type (<italic>T</italic> = 10 by default). For probes other than Neuropixels 1.0, which use the Neuropixels Ultra templates, an additional step is added to interpolate the templates (using <italic>kriging</italic>) to the target probe geometry, and to randomly relocate them between the 5<sup><italic>th</italic></sup> and 95<sup><italic>th</italic></sup> percentiles of the distribution of detected peak depths (detected during the motion estimation process). This is to ensure that hybrid units and spikes fall within an active probe region. For Neuropixels 1.0, neither interpolation nor relocation is performed, since templates cover the entire probe span. In this case, the template selection is performed so that the selected templates are between the 5<sup><italic>th</italic></sup> and 95<sup><italic>th</italic></sup> percentiles of the peak depth distribution. Once templates are selected (and interpolated/relocated for Neuropixels Ultra), they are finally scaled to a user-defined range, which is [50, 200]µV by default. These steps are repeated such that <italic>IT</italic> random iterations of hybrid recordings (<italic>IT</italic> = 5 by default) are generated for the same input dataset.</p>
<p>The GitHub repository associated with this step can be found at: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-hybrid-generation">https://github.com/AllenNeuralDynamics/aind-ephys-hybrid-generation</ext-link></p>
</sec>
<sec id="s6c2">
<title>Hybrid evaluation</title>
<p>The hybrid evaluation step collects and reorganizes all generated hybrid data and spike sorting results from the different spike sorting cases. The output files for each session are organized to mimic a <monospace>spikeinterface.benchmarks.SorterStudy</monospace> -generated folder, in order to exploit all its comparison and plotting capabilities. In doing so, the spike sorting output of each spike sorting case is compared against its hybrid ground-truth. The <monospace>SorterStudy</monospace> object then generates several <monospace>pandas.DataFrames</monospace> for performance, run times, unit classification counts (well detected, redundant, overmerged, false positive; see <xref ref-type="bibr" rid="c5">Buccino et al. 2020</xref>) that are saved as CSV files and plotted. Finally, all CSV from all sessions are combined to generate aggregated plots using comparison data from all sessions (e.g, <xref rid="fig7" ref-type="fig">Figure 7</xref>, <xref rid="fig8" ref-type="fig">Figure 8a</xref>).</p>
<p>The GitHub repository associated with this step can be found at: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-hybrid-evaluation">https://github.com/AllenNeuralDynamics/aind-ephys-hybrid-evaluation</ext-link></p>
</sec>
<sec id="s6c3">
<title>Compression</title>
<p>For the lossy compression application, the spike sorting cases include lossy compression at various levels, preprocessing (described above), and spike sorting with <monospace>Kilosort4</monospace> (described above).</p>
<p>The compression step simply loads the recording and saves it to <monospace>Zarr</monospace> using the <monospace>SpikeInterface</monospace> compression framework. The <monospace>Zarr</monospace> compressor is <monospace>WavPack</monospace> from the <monospace>wavpack-numcodecs</monospace> package (<ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/wavpack-numcodecs">https://github.com/AllenNeuralDynamics/wavpack-numcodecs</ext-link>), instantiated with different <monospace>bps</monospace> levels for each spike sorting case (3, 2.5, 2.25) (<xref ref-type="bibr" rid="c7">Buccino et al. 2023</xref>). The GitHub repository associated with this step can be found at: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-compress">https://github.com/AllenNeuralDynamics/aind-ephys-compress</ext-link></p>
</sec>
</sec>
<sec id="s6d">
<title>Evaluation pipeline output</title>
<p>The evaluation pipeline output includes the following files and folders. All of the folders are organized per session, except for the <monospace>aggregated/</monospace> folder which aggregates all the results and plots from all input sessions.</p>
<list list-type="bullet">
<list-item><p><monospace><bold>figures/</bold></monospace>: Visualizations of the various steps of the pipeline:</p>
<list list-type="bullet">
<list-item><p><monospace>benchmarks/</monospace>: Figures to display the performance of the different spike sorting cases, including overall performance curves (accuracy, precision, and recall) ordered by performance and by signal-to-noise ratio, run times, and unit classification counts.</p></list-item>
<list-item><p><monospace>templates/</monospace>: Figures to show all selected and interpolated hybrid templates, to assess the quality of the hybrid units.</p></list-item>
<list-item><p><monospace>rasters/</monospace>: Figures with raster maps of the original recording, with overlaid rasters of hybrid spikes and motion estimates.</p></list-item>
<list-item><p><monospace>motion/</monospace>: Figures with summary motion signals.</p></list-item>
</list>
</list-item>
<list-item><p><monospace><bold>dataframes/</bold></monospace>: CSV files with unit-level performance (accuracy, precision, recall), unit counts (well-detected, false positive, redundant, etc.), pre-computed quality metrics, and run times</p></list-item>
<list-item><p><monospace><bold>motion/</bold></monospace>: Estimated motion data from <monospace>SpikeInterface</monospace>.</p></list-item>
<list-item><p><monospace><bold>gt_studies/</bold></monospace>: <monospace>SpikeInterface SorterStudy</monospace> folders, used to reload the comparison objects and perform further analysis.</p></list-item>
<list-item><p><monospace><bold>aggregated/</bold></monospace>: Aggregated dataframes and summary figures pulling all results from all sessions.</p></list-item>
<list-item><p><monospace><bold>nextflow/</bold></monospace>: Workflow metadata, provenance information, timeline, and execution logs.</p></list-item>
</list>
<sec id="s6d1">
<title>Statistical analysis</title>
<p>We used the non-parametric tests for all comparisons, given that all tested distributions were not normal. We used the Wilcoxon signed-rank test for paired samples (<xref rid="fig7" ref-type="fig">Figure 7a</xref>, <xref rid="fig8" ref-type="fig">Figure 8a</xref>) and Mann–Whitney U test for unpaired samples (<xref rid="fig7" ref-type="fig">Figure 7c-d</xref>, <xref rid="fig8" ref-type="fig">Figure 8c-d</xref>). For population tests (more than two samples), we used the non-parametric Kruskal–Wallis test. Post-hoc tests were run with Mann–Whitney U test for independent samples, and Wilcoxon signed-rank tests for paired samples with Holm’s correction for <italic>P</italic>-values.</p>
<p>Tests were performed using <monospace>scipy</monospace> (<xref ref-type="bibr" rid="c59">Virtanen et al. 2020</xref>) and <monospace>scikit-posthocs</monospace> (<xref ref-type="bibr" rid="c57">Terpilowski 2019</xref>). In addition to reporting <italic>P</italic>-values for two-sample tests, we also report the Cohen’s <italic>d</italic> coefficient as a proxy for the effect size.</p>
</sec>
<sec id="s6d2">
<title>Software versions</title>
<p>We list here the software versions used to run and generate the results. We refer the reader to the software documentation for updated supported versions.</p>
<p><monospace><bold>SpikeInterface</bold></monospace> : v0.102.3</p>
<p><monospace><bold>Kilosort2.5</bold></monospace> : v2.5.1</p>
<p><monospace><bold>Kilosort4</bold></monospace> : v4.0.30</p>
<p><monospace><bold>WavPack</bold></monospace> : v5.7.0</p>
</sec>
</sec>
</sec>
</body>
<back>
<sec id="s8">
<title>Author contribution matrix</title>
<fig id="ufig2" position="float" fig-type="figure">
<graphic xlink:href="687966v1_ufig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="das" sec-type="data-availability">
<title>Data availability</title>
<p>Hybrid data for evaluating spike sorters and lossy compression are available at the following URL: <ext-link ext-link-type="uri" xlink:href="https://registry.opendata.aws/allen-nd-ephys-evaluation/">https://registry.opendata.aws/allen-nd-ephys-evaluation/</ext-link></p>
<p>The code for the presented pipelines is available on GitHub:</p>
<list list-type="bullet">
<list-item><p>Spike sorting pipeline: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-pipeline">https://github.com/AllenNeuralDynamics/aind-ephys-pipeline</ext-link></p></list-item>
<list-item><p>Evaluation pipeline: <ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-ephys-hybrid-benchmark">https://github.com/AllenNeuralDynamics/aind-ephys-hybrid-benchmark</ext-link></p></list-item>
</list>
<p>The figures from the results section can have been generated with the following Code Ocean capsule: <ext-link ext-link-type="uri" xlink:href="https://codeocean.allenneuraldynamics.org/capsule/9554286/tree/v4">https://codeocean.allenneuraldynamics.org/capsule/9554286/tree/v4</ext-link>. The spike sorting pipeline is also available in the Code Ocean Public Collections: <ext-link ext-link-type="uri" xlink:href="https://codeocean.allenneuraldynamics.org/capsule/4364160/tree/v4">https://codeocean.allenneuraldynamics.org/capsule/4364160/tree/v4</ext-link>.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Heberto Mayorquin, Pierre Yger, Samuel Garcia, and Ben Dichter for the contributions to the development of the hybrid recording generation framework in <monospace>SpikeInterface</monospace>. We thank Zhiwen Ye, Nick Steinmetz, and the International Brain Laboratory for collecting and packaging the single unit templates. We thank Dan Birman and Carter Peene for their contributions to the AIND quality control portal. We thank Corbett Bennett, Hannah Cabasco, Jackie Kuyat, Vayle LaFehr, Ethan McBride, Ben Hardcastle, Sam Gale, Shawn Olsen, and Xinxin Yin for providing the raw data used to generate hybrid recordings. We thank members of the Allen Institute for Neural Dynamics for using the sorting pipeline to process their datasets and providing feedback on pipeline outputs and visualizations. We thank Bala Desinghu, Max Shad, Janet Wallace, and Bernardo Sabatini at the Kempner Institute at Harvard University for testing the sorting pipeline and providing statistics on their internal usage.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abbott</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><given-names>K.</given-names> <surname>Svoboda</surname></string-name></person-group>. <year>2020</year>. “<article-title>Brain-wide interactions between neural circuits</article-title>.” <source>Current Opinion in Neurobiology</source> <volume>65</volume>: <fpage>iii</fpage>–<lpage>v</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abe</surname>, <given-names>T.</given-names></string-name>, <string-name><given-names>I.</given-names> <surname>Kinsella</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Saxena</surname></string-name>, <string-name><given-names>E. K.</given-names> <surname>Buchanan</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Couto</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Briggs</surname></string-name>, <string-name><given-names>S. L.</given-names> <surname>Kitt</surname></string-name>, <etal>et al.</etal></person-group> <year>2022</year>. “<article-title>Neuroscience Cloud Analysis As a Service: An open-source platform for scalable, reproducible data analysis</article-title>.” <source>Neuron</source> <volume>110</volume>: <fpage>2771</fpage>–<lpage>2789</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Allen</surname>, <given-names>B. D.</given-names></string-name>, <string-name><given-names>C.</given-names> <surname>Moore-Kochlacs</surname></string-name>, <string-name><given-names>J. G.</given-names> <surname>Bernstein</surname></string-name>, <string-name><given-names>J. P.</given-names> <surname>Kinney</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Scholvin</surname></string-name>, <string-name><given-names>L. F.</given-names> <surname>Seoane</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Chronopoulos</surname></string-name>, <etal>et al.</etal></person-group> <year>2018</year>. “<article-title>Automated in vivo patch-clamp evaluation of extracellular multielectrode array spike recording capability</article-title>.” <source>Journal of Neurophysiology</source> <volume>120</volume>: <fpage>2182</fpage>–<lpage>2200</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Boussard</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>C.</given-names> <surname>Windolf</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Hurwitz</surname></string-name>, <string-name><given-names>H. D.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Yu</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Winter</surname></string-name>, &amp; <string-name><given-names>L.</given-names> <surname>Paninski</surname></string-name></person-group>. <year>2023</year>. <article-title>DARTsort: A modular drift tracking spike sorter for high-density multi-electrode probes</article-title> <source>bioRxiv</source></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buccino</surname>, <given-names>A. P.</given-names></string-name>, <string-name><given-names>C. L.</given-names> <surname>Hurwitz</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Garcia</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Magland</surname></string-name>, <string-name><given-names>J. H.</given-names> <surname>Siegle</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Hurwitz</surname></string-name>, &amp; <string-name><given-names>M. H.</given-names> <surname>Hennig</surname></string-name></person-group>. <year>2020</year>. “<article-title>SpikeInterface, a unified framework for spike sorting</article-title>.” <source>eLife</source> <volume>9</volume>: <elocation-id>e61834</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.61834</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buccino</surname>, <given-names>A. P.</given-names></string-name>, <string-name><given-names>M.</given-names> <surname>Kordovan</surname></string-name>, <string-name><given-names>T. V.</given-names> <surname>Ness</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Merkt</surname></string-name>, <string-name><given-names>P. D.</given-names> <surname>Häfliger</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Fyhn</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Cauwenberghs</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Rotter</surname></string-name>, &amp; <string-name><given-names>G. T.</given-names> <surname>Einevoll</surname></string-name></person-group>. <year>2018</year>. “<article-title>Combining biophysical modeling and deep learning for multielectrode array neuron localization and classification</article-title>.” <source>Journal of Neurophysiology</source> <volume>120</volume>: <fpage>1212</fpage>– <lpage>1232</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buccino</surname>, <given-names>A. P.</given-names></string-name>, <string-name><given-names>O.</given-names> <surname>Winter</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Bryant</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Feng</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Svoboda</surname></string-name>, &amp; <string-name><given-names>J. H.</given-names> <surname>Siegle</surname></string-name></person-group>. <year>2023</year>. “<article-title>Compression strategies for large-scale electrophysiology data</article-title>.” <source>Journal of Neural Engineering</source> <volume>20</volume>: <fpage>056009</fpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buccino</surname>, <given-names>A. P.</given-names></string-name>, &amp; <string-name><given-names>G. T.</given-names> <surname>Einevoll</surname></string-name></person-group>. <year>2021</year>. “<article-title>MEArec: a fast and customizable testbench simulator for ground-truth extracellular spiking activity</article-title>.” <source>Neuroinformatics</source> <volume>19</volume>: <fpage>185</fpage>–<lpage>204</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buzsáki</surname>, <given-names>G.</given-names></string-name></person-group> <year>2004</year>. “<article-title>Large-scale recording of neuronal ensembles</article-title>.” <source>Nature Neuroscience</source> <volume>7</volume>: <fpage>446</fpage>–<lpage>451</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Campagner</surname>, <given-names>D.</given-names></string-name>, <string-name><given-names>J.</given-names> <surname>Bhagat</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Lopes</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Calcaterra</surname></string-name>, <string-name><given-names>A. G.</given-names> <surname>Pouget</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Almeida</surname></string-name>, <string-name><given-names>T. T.</given-names> <surname>Nguyen</surname></string-name>, <etal>et al.</etal></person-group> <year>2025</year>. “<article-title>Aeon: an open-source platform to study the neural basis of ethological behaviours over naturalistic timescales</article-title>.” <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carlson</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><given-names>L.</given-names> <surname>Carin</surname></string-name></person-group>. <year>2019</year>. “<article-title>Continuing progress of spike sorting in the era of big data</article-title>.” <source>Current Opinion in Neurobiology</source> <volume>55</volume>: <fpage>90</fpage>–<lpage>96</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheifet</surname>, <given-names>B.</given-names></string-name></person-group> <year>2021</year>. “<article-title>Promoting reproducibility with Code Ocean</article-title>.” <source>Genome Biology</source> <volume>22</volume>: <fpage>65</fpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chung</surname>, <given-names>J. E.</given-names></string-name>, <string-name><given-names>J. F.</given-names> <surname>Magland</surname></string-name>, <string-name><given-names>A. H.</given-names> <surname>Barnett</surname></string-name>, <string-name><given-names>V. M.</given-names> <surname>Tolosa</surname></string-name>, <string-name><given-names>A. C.</given-names> <surname>Tooker</surname></string-name>, <string-name><given-names>K. Y.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>K. G.</given-names> <surname>Shah</surname></string-name>, <etal>et al.</etal></person-group> <year>2017</year>. “<article-title>A fully automated approach to spike sorting</article-title>.” <source>Neuron</source> <volume>95</volume>: <fpage>1381</fpage>–<lpage>1394.e6</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dhawale</surname>, <given-names>A. K.</given-names></string-name>, <string-name><given-names>R.</given-names> <surname>Poddar</surname></string-name>, <string-name><given-names>S. B.</given-names> <surname>Wolff</surname></string-name>, <string-name><given-names>V. A.</given-names> <surname>Normand</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Kopelowitz</surname></string-name>, &amp; <string-name><given-names>B.P.</given-names> <surname>Ölveczky</surname></string-name></person-group>. <year>2017</year>. <article-title>Automated longterm recording and analysis of neural activity in behaving animals</article-title>. <source>eLife</source> <volume>6</volume>: <elocation-id>e27702</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.27702</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Di Tommaso</surname>, <given-names>P.</given-names></string-name>, <string-name><given-names>M.</given-names> <surname>Chatzou</surname></string-name>, <string-name><given-names>E. W.</given-names> <surname>Floden</surname></string-name>, <string-name><given-names>P. P.</given-names> <surname>Barja</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Palumbo</surname></string-name>, &amp; <string-name><given-names>C.</given-names> <surname>Notredame</surname></string-name></person-group>. <year>2017</year>. “<article-title>Nextflow enables reproducible computational workflows</article-title>.” <source>Nature Biotechnology</source> <volume>35</volume>: <fpage>316</fpage>–<lpage>319</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Einevoll</surname>, <given-names>G. T.</given-names></string-name>, <string-name><given-names>F.</given-names> <surname>Franke</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Hagen</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Pouzat</surname></string-name>, &amp; <string-name><given-names>K. D.</given-names> <surname>Harris</surname></string-name></person-group>. <year>2012</year>. “<article-title>Towards reliable spike-train recordings from thousands of neurons with multielectrodes</article-title>.” <source>Current Opinion in Neurobiology</source> <volume>22</volume>: <fpage>11</fpage>–<lpage>17</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="web"><person-group person-group-type="author"><collab>Facebook</collab></person-group>. <year>2025</year>. <source>“ZStandard,”</source> <ext-link ext-link-type="uri" xlink:href="http://facebook.github.io/zstd/">http://facebook.github.io/zstd/</ext-link> [accessed <date-in-citation content-type="access-date">28 July 2025</date-in-citation>].</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Garcia</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><given-names>A. P.</given-names> <surname>Buccino</surname></string-name></person-group>. <year>2025</year>. <source>“SpikeInterface-GUI,”</source> <ext-link ext-link-type="uri" xlink:href="https://github.com/SpikeInterface/spikeinterface\bibrangedashgui">https://github.com/SpikeInterface/spikeinterface\bibrangedashgui</ext-link> [accessed <date-in-citation content-type="access-date">28 July 2025</date-in-citation>].</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garcia</surname>, <given-names>S.</given-names></string-name>, <string-name><given-names>D.</given-names> <surname>Guarino</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Jaillet</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Jennings</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Pröpper</surname></string-name>, <string-name><given-names>P. L.</given-names> <surname>Rautenberg</surname></string-name>, <string-name><given-names>C. C.</given-names> <surname>Rodgers</surname></string-name>, <etal>et al.</etal></person-group> <year>2014</year>. “<article-title>Neo: an object model for handling electrophysiology data in multiple formats</article-title>.” <source>Frontiers in Neuroinformatics</source> <volume>8</volume>: <fpage>10</fpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garcia</surname>, <given-names>S.</given-names></string-name>, <string-name><given-names>J.</given-names> <surname>Sprenger</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Holtzman</surname></string-name>, &amp; <string-name><given-names>A. P.</given-names> <surname>Buccino</surname></string-name></person-group>. <year>2022</year>. “<article-title>ProbeInterface: A unified framework for probe handling in extracellular electrophysiology</article-title>.” <source>Frontiers in Neuroinformatics</source> <volume>16</volume>: <fpage>823056</fpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garcia</surname>, <given-names>S.</given-names></string-name>, <string-name><given-names>C.</given-names> <surname>Windolf</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Boussard</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Dichter</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Buccino</surname></string-name>, &amp; <string-name><given-names>P.</given-names> <surname>Yger</surname></string-name></person-group>. <year>2024</year>. “<article-title>A modular implementation to handle and benchmark drift correction for high-density extracellular recordings</article-title>.” <source>eNeuro</source> <volume>11</volume>: <elocation-id>ENEURO.0229–23.2023</elocation-id>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Geng</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>K.</given-names> <surname>Voitiuk</surname></string-name>, <string-name><given-names>D. F.</given-names> <surname>Parks</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Robbins</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Spaeth</surname></string-name>, <string-name><given-names>J. L.</given-names> <surname>Sevetson</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Hernandez</surname></string-name>, <etal>et al.</etal></person-group> <year>2024</year>. “<article-title>Multiscale cloud-based pipeline for neuronal electrophysiology analysis and visualization</article-title>.” <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gold</surname>, <given-names>C.</given-names></string-name>, <string-name><given-names>D. A.</given-names> <surname>Henze</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Koch</surname></string-name>, &amp; <string-name><given-names>G.</given-names> <surname>Buzsáki</surname></string-name></person-group>. <year>2006</year>. “<article-title>On the origin of the extracellular action potential waveform: a modeling study</article-title>.” <source>Journal of Neurophysiology</source> <volume>95</volume>: <fpage>3113</fpage>–<lpage>3128</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hagen</surname>, <given-names>E.</given-names></string-name>, <string-name><given-names>T. V.</given-names> <surname>Ness</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Khosrowshahi</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Sørensen</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Fyhn</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Hafting</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Franke</surname></string-name>, &amp; <string-name><given-names>G. T.</given-names> <surname>Einevoll</surname></string-name></person-group>. <year>2015</year>. “<article-title>ViSAPy: A Python tool for biophysics-based generation of virtual spiking activity for evaluation of spike-sorting algorithms</article-title>.” <source>Journal of Neuroscience Methods</source> <volume>245</volume>: <fpage>182</fpage>–<lpage>204</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harris</surname>, <given-names>K. D.</given-names></string-name>, <string-name><given-names>R. Q.</given-names> <surname>Quiroga</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Freeman</surname></string-name>, &amp; <string-name><given-names>S. L.</given-names> <surname>Smith</surname></string-name></person-group>. <year>2016</year>. “<article-title>Improving data quality in neuronal population recordings</article-title>.” <source>Nature Neuroscience</source> <volume>19</volume>: <fpage>1165</fpage>–<lpage>1174</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Henze</surname>, <given-names>D. A.</given-names></string-name>, <string-name><given-names>Z.</given-names> <surname>Borhegyi</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Csicsvari</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Mamiya</surname></string-name>, <string-name><given-names>K. D.</given-names> <surname>Harris</surname></string-name>, &amp; <string-name><given-names>G.</given-names> <surname>Buzsaki</surname></string-name></person-group>. <year>2000</year>. “<article-title>Intracellular features predicted by extracellular recordings in the hippocampus in vivo</article-title>.” <source>Journal of Neurophysiology</source> <volume>84</volume>: <fpage>390</fpage>–<lpage>400</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="software"><person-group person-group-type="author"><collab>International Brain Laboratory</collab></person-group>. <year>2024</year>. <source>Spike sorting pipeline for the International Brain Laboratory - Version 2</source></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>International Brain Laboratory</collab>, <string-name><given-names>D.</given-names> <surname>Angelaki</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Benson</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Benson</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Birman</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Arlandis</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Bonacchi</surname></string-name>, <etal>et al.</etal></person-group> <year>2025</year>. “<article-title>A brain-wide map of neural activity during complex behaviour</article-title>.” <source>Nature</source> <volume>645</volume>: <fpage>177</fpage>–<lpage>191</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="data"><person-group person-group-type="author"><collab>International Brain Laboratory</collab>, <string-name><given-names>B.</given-names> <surname>Benson</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Benson</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Birman</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Bonacchi</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Carandini</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Catarino</surname></string-name>, <etal>et al.</etal></person-group> <year>2024</year>. “<article-title>IBL - Brain Wide Map (Version draft)</article-title>.” <source>DANDI Archive</source>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Jain</surname>, <given-names>A.</given-names></string-name>, <string-name><given-names>R.</given-names> <surname>Greene</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Halcrow</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Swann</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Kleinjohann</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Spurio</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Graff</surname></string-name>, <etal>et al.</etal></person-group> <year>2025</year>. “<article-title>UnitRefine: A community toolbox for automated spike sorting curation</article-title>.” <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Jun</surname>, <given-names>J.</given-names></string-name>, <etal>et al.</etal></person-group> <year>2025</year>. <source>“JRClust,”</source> <ext-link ext-link-type="uri" xlink:href="https://github.com/vidriotech/JRCLUST">https://github.com/vidriotech/JRCLUST</ext-link> [accessed <date-in-citation content-type="access-date">28 July 2025</date-in-citation>].</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jun</surname>, <given-names>J. J.</given-names></string-name>, <string-name><given-names>N. A.</given-names> <surname>Steinmetz</surname></string-name>, <string-name><given-names>J. H.</given-names> <surname>Siegle</surname></string-name>, <string-name><given-names>D. J.</given-names> <surname>Denman</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Bauza</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Barbarits</surname></string-name>, <string-name><given-names>A. K.</given-names> <surname>Lee</surname></string-name>, <etal>et al.</etal></person-group> <year>2017</year>. “<article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title>.” <source>Nature</source> <volume>551</volume>: <fpage>232</fpage>–<lpage>236</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kleinfeld</surname>, <given-names>D.</given-names></string-name>, <string-name><given-names>L.</given-names> <surname>Luan</surname></string-name>, <string-name><given-names>P. P.</given-names> <surname>Mitra</surname></string-name>, <string-name><given-names>J. T.</given-names> <surname>Robinson</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Sarpeshkar</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Shepard</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Xie</surname></string-name>, &amp; <string-name><given-names>T. D.</given-names> <surname>Harris</surname></string-name></person-group>. <year>2019</year>. “<article-title>Can one concurrently record electrical spikes from every neuron in a mammalian brain?</article-title>” <source>Neuron</source> <volume>103</volume>: <fpage>1005</fpage>–<lpage>1015</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Laquitaine</surname>, <given-names>S.</given-names></string-name>, <string-name><given-names>M.</given-names> <surname>Imbeni</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Tharayil</surname></string-name>, <string-name><given-names>J. B.</given-names> <surname>Isbister</surname></string-name>, &amp; <string-name><given-names>M. W.</given-names> <surname>Reimann</surname></string-name></person-group>. <year>2024</year>. <article-title>Spike sorting biases and information loss in a detailed cortical model</article-title> <source>bioRxiv</source></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Lee</surname>, <given-names>K. H.</given-names></string-name>, <string-name><given-names>E. L.</given-names> <surname>Denovellis</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Ly</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Magland</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Soules</surname></string-name>, <string-name><given-names>A. E.</given-names> <surname>Comrie</surname></string-name>, <string-name><given-names>D. P.</given-names> <surname>Gramling</surname></string-name>, <etal>et al.</etal></person-group> <year>2024</year>. “<article-title>Spyglass: a framework for reproducible and shareable neuroscience research</article-title>.” <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Lin</surname>, <given-names>Z.</given-names></string-name>, <string-name><given-names>A.</given-names> <surname>Marin-Llobet</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Baek</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>He</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Zhang</surname></string-name>, <etal>et al.</etal></person-group> <year>2025</year>. “<article-title>Spike sorting AI agent</article-title>.” <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Llobet</surname>, <given-names>V.</given-names></string-name>, <string-name><given-names>A.</given-names> <surname>Wyngaard</surname></string-name>, &amp; <string-name><given-names>B.</given-names> <surname>Barbour</surname></string-name></person-group>. <year>2022</year>. “<article-title>Lussac: a fullyautomated consensus method that increases the yield and quality of spike-sorting analyses</article-title>.” <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Magland</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>J. J.</given-names> <surname>Jun</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Lovero</surname></string-name>, <string-name><given-names>A. J.</given-names> <surname>Morley</surname></string-name>, <string-name><given-names>C. L.</given-names> <surname>Hurwitz</surname></string-name>, <string-name><given-names>A. P.</given-names> <surname>Buccino</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Garcia</surname></string-name>, &amp; <string-name><given-names>A. H.</given-names> <surname>Barnett</surname></string-name></person-group>. <year>2020</year>. “<article-title>Spike-Forest, reproducible web-facing ground-truth validation of automated neural spike sorters</article-title>.” <source>eLife</source> <volume>9</volume>: <elocation-id>e55167</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.55167</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Magland</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><given-names>J.</given-names> <surname>Soules</surname></string-name></person-group>. <year>2025a</year>. <source>“Figurl,”</source> <ext-link ext-link-type="uri" xlink:href="https://github.com/flatironinstitute/figurl">https://github.com/flatironinstitute/figurl</ext-link> [accessed <date-in-citation content-type="access-date">28 July 2025</date-in-citation>].</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Magland</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><given-names>J.</given-names> <surname>Soules</surname></string-name></person-group>. <year>2025b</year>. <source>“SortingView,”</source> <ext-link ext-link-type="uri" xlink:href="https://github.com/magland/sortingview">https://github.com/magland/sortingview</ext-link> [accessed <date-in-citation content-type="access-date">28 July 2025</date-in-citation>].</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marblestone</surname>, <given-names>A. H.</given-names></string-name>, <string-name><given-names>B. M.</given-names> <surname>Zamft</surname></string-name>, <string-name><given-names>Y. G.</given-names> <surname>Maguire</surname></string-name>, <string-name><given-names>M. G.</given-names> <surname>Shapiro</surname></string-name>, <string-name><given-names>T. R.</given-names> <surname>Cybulski</surname></string-name>, <string-name><given-names>J. I.</given-names> <surname>Glaser</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Amodei</surname></string-name>, <etal>et al.</etal></person-group> <year>2013</year>. “<article-title>Physical principles for scalable neural recording</article-title>.” <source>Frontiers in Computational Neuroscience</source> <volume>7</volume>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Marques-Smith</surname>, <given-names>A.</given-names></string-name>, <string-name><given-names>J. P.</given-names> <surname>Neto</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Lopes</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Nogueira</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Calcaterra</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Frazão</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Kim</surname></string-name>, <etal>et al.</etal></person-group> <year>2018</year>. “<article-title>Recording from the same neuron with high-density CMOS probes and patch-clamp: a ground-truth dataset and an experiment in collaboration</article-title>.” <source>bioRxiv</source>, <fpage>370080</fpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Martinez</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>C.</given-names> <surname>Pedreira</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Ison</surname></string-name>, &amp; <string-name><given-names>R. Quian</given-names> <surname>Quiroga</surname></string-name></person-group>. <year>2009</year>. “<article-title>Realistic simulation of extracellular recordings</article-title>.” <source>Journal of Neuroscience Methods</source> <volume>184</volume>: <fpage>285</fpage>–<lpage>293</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Mayorquin</surname>, <given-names>H.</given-names></string-name>, <string-name><given-names>C.</given-names> <surname>Baker</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Adkisson-Floro</surname></string-name>, <string-name><given-names>S. W.</given-names> <surname>Weigl</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Trapani</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Tauffer</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Rübel</surname></string-name>, &amp; <string-name><given-names>B.</given-names> <surname>Dichter</surname></string-name></person-group>. <year>2025</year>. “<article-title>NeuroConv: Streamlining Neurophysiology Data Conversion to the NWB Standard</article-title>.” <conf-name>SciPy Proceedings</conf-name>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meyer</surname>, <given-names>L. M.</given-names></string-name>, <string-name><given-names>M.</given-names> <surname>Zamani</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Rokai</surname></string-name>, &amp; <string-name><given-names>A.</given-names> <surname>Demosthenous</surname></string-name></person-group>. <year>2024</year>. “<article-title>Deep learning-based spike sorting: a survey</article-title>.” <source>Journal of Neural Engineering</source> <volume>21</volume>: <fpage>061003</fpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Neto</surname>, <given-names>J. P.</given-names></string-name>, <string-name><given-names>G.</given-names> <surname>Lopes</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Frazão</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Nogueira</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Lacerda</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Baião</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Aarts</surname></string-name>, <etal>et al.</etal></person-group> <year>2016</year>. “<article-title>Validating silicon polytrodes with paired juxtacellular recordings: method and dataset</article-title>.” <source>Journal of Neurophysiology</source> <volume>116</volume>: <fpage>892</fpage>–<lpage>903</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Newman</surname>, <given-names>J. P.</given-names></string-name>, <string-name><given-names>J.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Cuevas-López</surname></string-name>, <string-name><given-names>N. J.</given-names> <surname>Miller</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Honda</surname></string-name>, <string-name><given-names>M.-S. H.</given-names> <surname>van der Goes</surname></string-name>, <string-name><given-names>A. H.</given-names> <surname>Leighton</surname></string-name>, <etal>et al.</etal></person-group> <year>2025</year>. “<article-title>ONIX: a unified open-source platform for multimodal neural recording and perturbation during naturalistic behavior</article-title>.” <source>Nature Methods</source> <volume>22</volume>: <fpage>187</fpage>–<lpage>192</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Obien</surname>, <given-names>M. E. J.</given-names></string-name>, <string-name><given-names>K.</given-names> <surname>Deligkaris</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Bullmann</surname></string-name>, <string-name><given-names>D. J.</given-names> <surname>Bakkum</surname></string-name>, &amp; <string-name><given-names>U.</given-names> <surname>Frey</surname></string-name></person-group>. <year>2015</year>. “<article-title>Revealing neuronal function through microelectrode array recordings</article-title>.” <source>Frontiers in Neuroscience</source> <volume>8</volume>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pachitariu</surname>, <given-names>M.</given-names></string-name>, <string-name><given-names>S.</given-names> <surname>Sridhar</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Pennington</surname></string-name>, &amp; <string-name><given-names>C.</given-names> <surname>Stringer</surname></string-name></person-group>. <year>2024</year>. “<article-title>Spike sorting with Kilosort4</article-title>.” <source>Nature Methods</source> <volume>21</volume>: <fpage>914</fpage>–<lpage>921</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Pachitariu</surname>, <given-names>M.</given-names></string-name>, <string-name><given-names>N.</given-names> <surname>Steinmetz</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Kadir</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Carandini</surname></string-name>, &amp; <string-name><given-names>K. D.</given-names> <surname>Harris</surname></string-name></person-group>. <year>2016</year>. “<article-title>Kilosort: realtime spike-sorting for extracellular electrophysiology with hundreds of channels</article-title>.” <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Rossant</surname>, <given-names>C.</given-names></string-name>, <etal>et al.</etal></person-group> <year>2025</year>. <source>“Phy,”</source> <ext-link ext-link-type="uri" xlink:href="https://github.com/cortex\bibrangedashlab/phy">https://github.com/cortex\bibrangedashlab/phy</ext-link> [accessed <date-in-citation content-type="access-date">28 July 2025</date-in-citation>].</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rossant</surname>, <given-names>C.</given-names></string-name>, <string-name><given-names>S. N.</given-names> <surname>Kadir</surname></string-name>, <string-name><given-names>D. F.</given-names> <surname>Goodman</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Schulman</surname></string-name>, <string-name><given-names>M. L.</given-names> <surname>Hunter</surname></string-name>, <string-name><given-names>A. B.</given-names> <surname>Saleem</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Grosmark</surname></string-name>, <etal>et al.</etal></person-group> <year>2016</year>. “<article-title>Spike sorting for large, dense electrode arrays</article-title>.” <source>Nature Neuroscience</source> <volume>19</volume>: <fpage>634</fpage>–<lpage>641</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rübel</surname>, <given-names>O.</given-names></string-name>, <string-name><given-names>A.</given-names> <surname>Tritt</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Ly</surname></string-name>, <string-name><given-names>B. K.</given-names> <surname>Dichter</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Ghosh</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Niu</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Baker</surname></string-name>, <etal>et al.</etal></person-group> <year>2022</year>. “<article-title>The Neurodata Without Borders ecosystem for neurophysiological data science</article-title>.” <source>eLife</source> <volume>11</volume>: <elocation-id>e78362</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.78362</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Siegle</surname>, <given-names>J. H.</given-names></string-name>, <string-name><given-names>X.</given-names> <surname>Jia</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Durand</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Gale</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Bennett</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Graddis</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Heller</surname></string-name>, <etal>et al.</etal></person-group> <year>2021</year>. “<article-title>Survey of spiking in the mouse visual system reveals functional hierarchy</article-title>.” <source>Nature</source> <volume>592</volume>: <fpage>86</fpage>– <lpage>92</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Steinmetz</surname>, <given-names>N. A.</given-names></string-name>, <string-name><given-names>C.</given-names> <surname>Aydin</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Lebedeva</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Okun</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Pachitariu</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Bauza</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Beau</surname></string-name>, <etal>et al.</etal></person-group> <year>2021</year>. “<article-title>Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings</article-title>.” <source>Science</source> <volume>372</volume>: <fpage>eabf4588</fpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Steinmetz</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><given-names>Z.</given-names> <surname>Ye</surname></string-name></person-group>. <year>2022</year>. <source>Detailed neuronal waveforms across brain regions recorded with Neuropixels ‘Ultra’</source></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Terpilowski</surname>, <given-names>M.</given-names></string-name></person-group> <year>2019</year>. “<article-title>scikit-posthocs: Pairwise multiple comparison tests in Python</article-title>.” <source>The Journal of Open Source Software</source> <volume>4</volume>: <fpage>1169</fpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="web"><person-group person-group-type="author"><collab>The Blosc Development Team</collab></person-group>. <year>2025</year>. <source>“BLOSC,”</source> <ext-link ext-link-type="uri" xlink:href="https://www.blosc.org/">https://www.blosc.org/</ext-link> [accessed <date-in-citation content-type="access-date">28th July 2025</date-in-citation>].</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Virtanen</surname>, <given-names>P.</given-names></string-name>, <string-name><given-names>R.</given-names> <surname>Gommers</surname></string-name>, <string-name><given-names>T. E.</given-names> <surname>Oliphant</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Haberland</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Reddy</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Cournapeau</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Burovski</surname></string-name>, <etal>et al.</etal></person-group> <year>2020</year>. “<article-title>SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python</article-title>.” <source>Nature Methods</source> <volume>17</volume>: <fpage>261</fpage>–<lpage>272</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Watters</surname>, <given-names>N.</given-names></string-name>, <string-name><given-names>A.</given-names> <surname>Buccino</surname></string-name>, &amp; <string-name><given-names>M.</given-names> <surname>Jazayeri</surname></string-name></person-group>. <year>2025</year>. “<article-title>MEDiCINe: Motion Correction for Neural Electrophysiology Recordings</article-title>.” <source>eNeuro</source> <volume>12</volume>:<elocation-id>ENEURO.0529–24.2025</elocation-id>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Windolf</surname>, <given-names>C.</given-names></string-name>, <string-name><given-names>H.</given-names> <surname>Yu</surname></string-name>, <string-name><given-names>A. C.</given-names> <surname>Paulk</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Meszéna</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Muñoz</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Boussard</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Hardstone</surname></string-name>, <etal>et al.</etal></person-group> <year>2025</year>. “<article-title>DREDge: robust motion correction for high-density extracellular recordings across species</article-title>.” <source>Nature Methods</source>, <volume>22</volume><fpage>788</fpage>–<lpage>800</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wouters</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>F.</given-names> <surname>Kloosterman</surname></string-name>, &amp; <string-name><given-names>A.</given-names> <surname>Bertrand</surname></string-name></person-group>. <year>2021</year>. “<article-title>SHYBRID: A Graphical Tool for Generating Hybrid Ground-Truth Spiking Data for Evaluating Spike Sorting Performance</article-title>.” <source>Neuroinformatics</source> <volume>19</volume>: <fpage>141</fpage>–<lpage>158</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Yatsenko</surname>, <given-names>D.</given-names></string-name>, <string-name><given-names>E. Y.</given-names> <surname>Walker</surname></string-name>, &amp; <string-name><given-names>A. S.</given-names> <surname>Tolias</surname></string-name></person-group>. <year>2018</year>. “<article-title>Data-Joint: a simpler relational data model</article-title>.” <source>arXiv</source> <pub-id pub-id-type="arxiv">1807.11104</pub-id>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yger</surname>, <given-names>P.</given-names></string-name>, <string-name><given-names>G. L.</given-names> <surname>Spampinato</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Esposito</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Lefebvre</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Deny</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Gardella</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Stimberg</surname></string-name>, <etal>et al.</etal></person-group> <year>2018</year>. “<article-title>A spike sorting toolbox for up to thousands of electrodes validated with ground truth recordings in vitro and in vivo</article-title>.” <source>eLife</source> <volume>7</volume>: <elocation-id>e34518</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.34518</pub-id></mixed-citation></ref>
</ref-list>
<app-group>
<app id="app1">
<label>Appendix 1.</label>
<title>AIND Data Schema</title>
<p>The <ext-link ext-link-type="uri" xlink:href="https://aind-data-schema.readthedocs.io/en/stable/">AIND Data Schema</ext-link> defines the specification for metadata that accompanies all data produced by the Allen Institute for Neural Dynamics. The goal of the schema is is to make all data consistently findable and understandable. The schema supports standard descriptions of the following categories of information:</p>
<list list-type="bullet">
<list-item><p><bold>Data Description</bold>: administrative metadata about the source of the data, funding, relevant licenses, and restrictions on use.</p></list-item>
<list-item><p><bold>Subject</bold>: Species, genotype, age, sex, and source.</p></list-item>
<list-item><p><bold>Procedure</bold>s: descriptions of any procedures performed prior to data acquisition, including subject procedures (surgeries, behavior training, etc.) and specimen procedures (tissue preparation, staining, etc.).</p></list-item>
<list-item><p><bold>Instrument</bold>: descriptions of the equipment used to acquire data, including part names and serial numbers.</p></list-item>
<list-item><p><bold>Acquisition</bold>: how devices were configured during active data acquisition.</p></list-item>
<list-item><p><bold>Processing</bold>: descriptions of how data has been processed and analyzed into derived data assets, including information on the software and parameters used.</p></list-item>
<list-item><p><bold>Quality Control</bold>: Metrics and figures describing the quality of a data asset.</p></list-item>
<list-item><p><bold>Model</bold>: Metadata describing machine learning models created from or used to analyze data assets.</p></list-item>
</list>
<p>AIND Data Schema is written as a semantically versioned Python library. AIND Data Schema utilizes Pydantic (<ext-link ext-link-type="uri" xlink:href="https://docs.pydantic.dev/latest/">https://docs.pydantic.dev/latest/</ext-link>), a common data validation library that integrates well with large variety of tools in the Python ecosystem. Pydantic is able to render AIND Data Schema to JSONSchema (<ext-link ext-link-type="uri" xlink:href="https://json-schema.org/">https://json-schema.org/</ext-link>) to support data validation outside of Python. Basic controlled vocabularies (list of organizations, instrument manufacturers, etc) are stored in a separate library called <monospace>aind-data-schema-models</monospace> (<ext-link ext-link-type="uri" xlink:href="https://github.com/AllenNeuralDynamics/aind-data-schema-models">https://github.com/AllenNeuralDynamics/aind-data-schema-models</ext-link>).</p>
<p>For reference, a subject described in AIND Data Schema 2.0 looks like this:</p>
<fig id="ufig3" position="float" fig-type="figure">
<graphic xlink:href="687966v1_ufig3.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="687966v1_ufig3a.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>This produces <monospace>subject.json</monospace> in the script’s current working directory. Should there be validation errors (missing required information, improperly formatted data), AIND Data Schema will report these automatically.</p>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1:</label>
<caption><title>Spike sorter performance as a function of unit signal-to-noise ratio.</title>
<p><bold>a</bold>, Accuracy, precision, and recall for every hybrid units added to the Neuropixels 1.0. Lines indicate the average value at each signal-to-noise level. <bold>b</bold>, Same as a, but for Neuropixels 2.0 datasets.</p></caption>
<graphic xlink:href="687966v1_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2:</label>
<caption><title>Kilosort run times.</title>
<p><bold>a</bold>, Run times of <monospace>Kilosort2.5</monospace> (red) and <monospace>Kilosort4</monospace> (purple) on Neuropixels 1.0 datasets. Run times are relative to real-time (xRT). b, Same as a, but for Neuropixels 2.0 datasets. Note that for Neuropixels 1.0, spike sorting was run on the full 384-channel recording, while it was split by shank (96 channels each) for Neuropixels 2.0, which is why the latter probe has faster execution times.</p></caption>
<graphic xlink:href="687966v1_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</app>
</app-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.110170.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Giocomo</surname>
<given-names>Lisa M</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Stanford School of Medicine</institution>
</institution-wrap>
<city>Stanford</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents a <bold>valuable</bold> and well-documented computational pipeline for the scalable analysis and spike sorting of large extracellular electrophysiology datasets, with particular relevance for high-density recordings such as Neuropixels. The authors demonstrate the pipeline's utility for benchmarking spike sorter performance and evaluating the effects of data compression, supported by thorough testing, clear figures, and openly available code. The workflow is reproducible, portable, and practical, providing concrete guidance on computational cost and runtime. Overall, the evidence supporting the pipeline's performance and output quality is <bold>compelling</bold>, and this work will be of broad interest to the systems neuroscience community.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.110170.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Extracellular electrophysiology datasets are growing in both number and size, and recordings with thousands of sites per animal are now commonplace. Analyzing these datasets to extract the activity of single neurons (spike sorting) is challenging: signal-to-noise is low, the analysis is computationally expensive, and small changes in analysis parameters and code can alter the output. The authors address the problem of volume by packaging the well-characterized SpikeInterface pipeline in a framework that can distribute individual sorting jobs across many workers in a compute cluster or cloud environment. Reproducibility is ensured by running containerized versions of the processing components.</p>
<p>The authors apply the pipeline in two important examples. The first is a thorough study comparing the performance of two widely used spike-sorting algorithms (Kilosort 2.5 and Kilosort 4). They use hybrid datasets created by injecting measured spike waveforms (templates) into existing recordings, adjusting those waveforms according to the measured drift in the recording. These hybrid ground truth datasets preserve the complex noise and background of the original recording. Similar to the original Kilosort 4 paper, which uses a different method for creating ground truth datasets that include drift, the authors find Kilosort 4 significantly outperforms Kilosort 2.5. The second example measures the impact of compression of raw data on spike sorting with Kilosort 4, showing that accuracy, precision, and recall of the ground truth units are not significantly impacted even by lossy compression. As important as the individual results, these studies provide good models for measuring the impact of particular processing steps on the output of spike sorting.</p>
<p>Strengths:</p>
<p>The pipeline uses the Nextflow framework, which makes it adaptable to different job schedulers and environments. The high-level documentation is useful, and the GitHub code is well organized. The two example studies are thorough and well-designed, and address important questions in the analysis of extracellular electrophysiology data.</p>
<p>Weaknesses:</p>
<p>The pipeline is very complete, but also complex. Workflows - the optimal artifact removal, best curation for data from a particular brain area or species - will vary according to experiment. Therefore, a discussion of the adaptability of the pipeline in the &quot;Limitations&quot; section would be helpful for readers.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.110170.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work presents a reproducible, scalable workflow for spike sorting that leverages parallelization to handle large neural recording datasets. The authors introduce both a processing pipeline and a benchmarking framework that can run across different computing environments (workstations, HPC clusters, cloud). Key findings include demonstrating that Kilosort4 outperforms Kilosort2.5 and that 7× lossy compression has minimal impact on spike sorting performance while substantially reducing storage costs.</p>
<p>Strengths:</p>
<p>(1) Extremely high-quality figures with clear captions that effectively communicate complex workflow information.</p>
<p>(2) Very detailed, well-written methods section providing thorough documentation.</p>
<p>(3) Strong focus on reproducibility, scalability, modularity, and portability using established technologies (Nextflow, SpikeInterface, Code Ocean).</p>
<p>(4) Pipeline publicly available on GitHub with documentation.</p>
<p>(5) Clear cost analysis showing ~$5/hour for AWS processing with transparent breakdown.</p>
<p>(6) Good overview of previous spike sorting benchmarking attempts in the introduction.</p>
<p>(7) Practical value for the community by lowering barriers to processing large datasets.</p>
<p>Weaknesses:</p>
<p>No significant weaknesses were identified, although it is noted that the limitations section of the discussion could be expanded.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.110170.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors provide a highly valuable and thoroughly documented pipeline to accelerate the processing and spike sorting of high-density electrophysiology data, particularly from Neuropixels probes. The scale of data collection is increasing across the field, and processing times and data storage are growing concerns. This pipeline provides parallelization and benchmarking of performance after data compression that helps address these concerns. The authors also use their pipeline to benchmark different spike sorting algorithms, providing useful evidence that Kilosort4 performs the best out of the tested options. This work, and the ability to implement this pipeline with minimal effort to standardize and speed up data processing across the field, will be of great interest to many researchers in systems neuroscience.</p>
<p>Strengths:</p>
<p>The paper is very well written and clear in most places. The accompanying GitHub and ReadTheDocs are well organized and thorough. The authors provide many benchmarking metrics to support their claims, and it is clear that the pipeline has been very thoroughly tested and optimized by users at the Allen Institute for Neural Dynamics. The pipeline incorporates existing software and platforms that have also been thoroughly tested (such as SpikeInterface), so the authors are not reinventing the wheel, but rather putting together the best of many worlds. This is a great contribution to the field, and it is clear that the authors have put a lot of thought into making the pipeline as accessible as possible.</p>
<p>Weaknesses:</p>
<p>There are no major weaknesses. I have only a handful of very minor questions and suggestions that could clarify/generalize aspects of the pipeline or make the text more understandable to non-specialists.</p>
<p>(1) Could the authors please expand on the statement on line 274, that processing their test dataset serially &quot;on a single GPU-capable cloud workstation... would take approximately 75 hours and cost over 90 USD.&quot; How were these values calculated? I was a bit surprised that this is a &gt;4-fold slow-down from their pipeline, but only increases the cost by ~1.35x, if I understood correctly. More context on why this is, and maybe some context on what a g4dn.4xlarge is compared to the other instances, might help readers who are less familiar with AWS and cloud computing.</p>
<p>(2) One of the most commonly used preprocessing pipelines for Neuropixels data is the CatGT/ecephys pipeline from the developers of SpikeGLX at Janelia. It may be worth commenting very briefly, either in the preprocessing section or in the discussion, on how the preprocessing steps available in this pipeline compare to the steps available in CatGT. For example, is &quot;destriping&quot; similar to the &quot;-gfix&quot; option in catGT to remove high-amplitude artifacts?</p>
<p>(3) Why are there duplicate units (line 194), and how often is this an issue? I understand that this is likely more of a spike sorter issue than an issue with this pipeline, but 1-2 sentences elaborating why might be helpful for readers.</p>
<p>(4) It seems from the parameter files on GitHub that the cluster curation parameters are customizable - correct? If so, it may be worth explicitly saying so in the curation section of the text, as the presented recipe will not always be appropriate. A presence ratio of &gt;0.8 could be particularly problematic for some recordings, for example, if a cell is only active during a specific part of the behavior, that may be a feature of the experiment, or the animal could be transitioning between sleep and wake states, in which different units may become active at different times.</p>
<p>(5) The axis labels in Figures 3d-e are too small to see, and Figure 3d would benefit from a brief description of what is shown.</p>
<p>(6) What is the difference between &quot;neural&quot; and &quot;passing QC&quot; in Figure 4?</p>
<p>(7) I understand the current paper is focused on spike data, so there may not be an answer to this, but I am curious about the NP2.0 probes that save data in wideband. Does the lossy compression negatively affect the LFP data? Is software filtering applied for the spike band before or after compression?</p>
</body>
</sub-article>
</article>