<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">109530</article-id>
<article-id pub-id-type="doi">10.7554/eLife.109530</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.109530.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Neural Traces of Forgotten Memories Persist in Humans and are Behaviorally Relevant</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9872-0724</contrib-id>
<name>
<surname>Willems</surname>
<given-names>Tom</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>tom.willems@unibe.ch</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0006-3939-0757</contrib-id>
<name>
<surname>Zervas</surname>
<given-names>Konstantinos</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8727-9240</contrib-id>
<name>
<surname>Brogli</surname>
<given-names>Luzius</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0007-2897-5204</contrib-id>
<name>
<surname>Rabe</surname>
<given-names>Finn</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3211-2675</contrib-id>
<name>
<surname>Federspiel</surname>
<given-names>Andrea</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7895-044X</contrib-id>
<name>
<surname>Henke</surname>
<given-names>Katharina</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
    <aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02k7v4d05</institution-id><institution>University of Bern, Institute of Psychology</institution></institution-wrap>, <city>Bern</city>, <country country="CH">Switzerland</country></aff>
    <aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02k7v4d05</institution-id><institution>Department of Diagnostic and Interventional Neuroradiology, Inselspital, University Hospital Bern, University of Bern</institution></institution-wrap>, <city>Bern</city>, <country country="CH">Switzerland</country></aff>
    <aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02k7v4d05</institution-id><institution>Translational Imaging Center Bern, Swiss Institute for Translational and Entrepreneurial Medicine, University of Bern</institution></institution-wrap>, <city>Bern</city>, <country country="CH">Switzerland</country></aff>
    <aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02crff812</institution-id><institution>Department of Adult Psychiatry and Psychotherapy, University of Zurich</institution></institution-wrap>, <city>Zurich</city>, <country country="CH">Switzerland</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Ryan</surname>
<given-names>Tomás J</given-names>
</name>
<contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0121-8514</contrib-id><role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/02tyrky19</institution-id><institution>Trinity College Dublin</institution>
</institution-wrap>
<city>Dublin</city>
<country country="IE">Ireland</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8451-0523</contrib-id><role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2026-01-14">
<day>14</day>
<month>01</month>
<year>2026</year>
</pub-date>
<volume>15</volume>
<elocation-id>RP109530</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-10-23">
<day>23</day>
<month>10</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-10-10">
<day>10</day>
<month>10</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.06.02.656652"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2026, Willems et al</copyright-statement>
<copyright-year>2026</copyright-year>
<copyright-holder>Willems et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-109530-v1.pdf"/>
<abstract><p>For a long time, forgetting has been taken as the dissipation of the neural memory traces (engrams). However, recent engram research in mice suggests that the engrams of forgotten memories do persist. This raises the question of whether engrams underlying human episodic memories also persist despite forgetting? And do forgotten memories influence human behavior implicitly? To address these questions, we used high-resolution functional magnetic resonance imaging at 7 Tesla to map the fate of 96 associative memories at the systems level from learning to a 30-minute and onward to a 24-hour memory test. Upon each retrieval attempt, participants indicated whether they remembered or forgot the memory. Univariate and multivariate analyses of the functional brain data revealed that the engrams of forgotten memories remain implemented in the episodic memory network and continue to influence the accuracy of guessing responses at the memory test. Overnight, the engrams of forgotten memories became implemented more deeply within bilateral hippocampus, while consciously accessible memories were neocorticalized overnight. The engrams of both consciously accessible and inaccessible (forgotten) memories shifted from the 30-minute to the 24-hour memory test within the right hippocampus and anterior cingulate gyrus as evidenced by the occurrence of pattern dissimilarities that supported correct retrieval responses at 24 hours. Hence, forgotten human episodic memories remain implemented in the episodic memory system and continue to influence decisions.</p>
</abstract>
<funding-group>
<award-group id="par-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009068</institution-id>
<institution>University of Bern (UB)</institution>
</institution-wrap>
</funding-source>
<award-id>SISF 2019</award-id>
<principal-award-recipient>
<name>
<surname>Henke</surname>
<given-names>Katharina</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-2">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001711</institution-id>
<institution>Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung (SNF)</institution>
</institution-wrap>
</funding-source>
<award-id>Advanced Grant TMAG-1_209374</award-id>
<principal-award-recipient>
<name>
<surname>Henke</surname>
<given-names>Katharina</given-names>
</name>
</principal-award-recipient>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>- Added type-2 d' analysis
- Revised several paragraphs for clarity
- Improved clarity in usage of core concepts
- Added Luzius Brogli as author to better reflect contributions to data analysis
- Figure 1 has been adapted to show immediate retrieval
- Changed layout to reflect journal submission demands
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Most neuroscientific research focuses on learning and remembering, while the nature of forgetting has been largely overlooked. Here, we define forgetting as the insight that the retrieval of a previously accessible memory has failed (<xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c7">7</xref>). Indeed, healthy, adult participants are very sensitive to retrieval failures(<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c2">2</xref>). Here, we investigate whether forgetting in episodic memory is merely a failure of conscious access to a memory or reflects the loss of the neural trace of a memory. Learning involves the strengthening of connections between coactivated neurons that are part of a neuronal ensemble (memory trace or engram), which is associated with a particular memory (<xref ref-type="bibr" rid="c3">3</xref>). Memories are encoded in sparse neural ensembles distributed across the entire brain (<xref ref-type="bibr" rid="c4">4</xref>). Following learning, engram cells that were active during learning are reactivated, which supports the strengthening (consolidation) of the memory. Forgetting is the flip side of memory consolidation. A common view is that forgetting is due to the dissipation of the entire engram due to neurogenesis, interference, and due to the brain’s tendency to degrade molecular and cellular memory traces leading to the disconnection of engram cells from the engram circuit (<xref ref-type="bibr" rid="c5">5</xref>). Recent engram research in rodents, however, suggests that it is unlikely that the engram of forgotten memories vanishes completely (<xref ref-type="bibr" rid="c4">4</xref>). Instead, forgetting may occur due to a reduced accessibility of engrams that silently persist.</p>
<p>Engram accessibility may depend on the intactness of the engram itself, on the systemic state of the individual, and on the quality of the retrieval cues (<xref ref-type="bibr" rid="c6">6</xref>). For example, Guskjolen and colleagues (<xref ref-type="bibr" rid="c7">7</xref>) found in young mice with natural infantile amnesia that optogenetic stimulation of hippocampal neurons tagged during contextual fear learning could recover forgotten memories for up to 3 months. Also, Yates et al. (<xref ref-type="bibr" rid="c8">8</xref>) found that human infantile amnesia is not a failure of encoding, but rather a failure of conscious retrieval of the memories that turn inaccessible due to post-encoding processes. Bolsius et al. (<xref ref-type="bibr" rid="c9">9</xref>) found that sleep-deprivation-induced amnesia in mice could be reversed by both optogenetic stimulation and the drug roflumilast, which acts by preventing the breakdown of enzymes involved in long-term potentiation. In adult mice, Autore and colleagues (<xref ref-type="bibr" rid="c10">10</xref>) showed that although natural retroactive interference during learning resulted in forgetting and decreased engram cell reactivation in the retrieval situation, optogenetic stimulation of previously labeled engram cells enabled memory expression. These discoveries beg the question of whether hippocampal and neocortical engram components underlying adult, human episodic memories would also persist despite forgetting and – if so – whether the forgotten memories associated with a persistent engram would continue to influence human behavior implicitly. Here, we tested these hypotheses making use of anterograde and retrograde interference during learning to increase forgetting rates in healthy young men and women. Indeed, much forgetting is likely due to interference – i.e., multiple memories encoded closely in time creating competition during consolidation (<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>). But why should the traces of forgotten memories remain implemented in the brain? Perhaps because the forgotten memories may regain importance for behavioral adjustment and survival when anticipating or being confronted with a similar situation later in life.</p>
<p>On a cellular level, the degree of reinstatement is dependent on the strength of connectivity between engram cells (<xref ref-type="bibr" rid="c13">13</xref>). Synaptic consolidation provides for an active strengthening of the connectivity between engram neurons within an engram component via cellular mechanisms like long-term-potentiation (<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>). Systems consolidation describes a time-dependent change of episodic memory representation. These changes are characterized by a strengthening of neocortical, mostly medial prefrontal, engram components (<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>). Over time, retrieval tends to (but not always does) become independent from the hippocampal engram component (<xref ref-type="bibr" rid="c18">18</xref>–<xref ref-type="bibr" rid="c20">20</xref>). Because engrams undergo changes at multiple levels of neural organization from synapses to cells to neuronal ensembles, it is possible to study engrams at the systems level in humans with high-resolution functional magnetic resonance imaging (fMRI) and multivariate analyses (<xref ref-type="bibr" rid="c21">21</xref>). The degree of engram reinstatement within human neocortex and hippocampus has been found to predict retrieval success and the amount of information retrieved (<xref ref-type="bibr" rid="c22">22</xref>–<xref ref-type="bibr" rid="c24">24</xref>). Besides reinstatement-related similarity, memory accuracy might also be linked to a transformation of the trace reflected by distinct activation patterns within the hippocampus and dissimilarity between the learning and retrieval events (<xref ref-type="bibr" rid="c25">25</xref>–<xref ref-type="bibr" rid="c27">27</xref>). This dissimilarity of learning- and retrieval-related activation patterns may be caused by the rapid transformation of cell-ensemble dynamics in the hippocampus (<xref ref-type="bibr" rid="c28">28</xref>–<xref ref-type="bibr" rid="c30">30</xref>), by the reconsolidation of memories following a reactivation (<xref ref-type="bibr" rid="c31">31</xref>), and by pattern separation processes that provide for an orthogonal representation of similar memories to prevent interference (<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c32">32</xref>).</p>
<p>Learning- and retrieval-related activation patterns that underlie forgotten rather than remembered adult human episodic memories have not yet been examined to our knowledge. The reason for this neglect might be conceptual and definitional in nature: If forgetting from episodic memory were associated with persisting engrams that continue to influence behavior implicitly and are located in the same neural circuits that underlie consciously accessible memories, this would entail that episodic retrieval is not all (conscious) or none (absent). Yet, unconscious episodic memory retrieval does not exist in the framework of traditional models of human memory because these models link episodic memory to consciousness (<xref ref-type="bibr" rid="c33">33</xref>–<xref ref-type="bibr" rid="c35">35</xref>). Note that the literature on episodic-autobiographical memory retrieval describes direct and involuntary forms of autobiographical memory retrieval, which can occur without conscious effort and may in fact be elicited by unconscious processes (<xref ref-type="bibr" rid="c36">36</xref>–<xref ref-type="bibr" rid="c38">38</xref>). However, the act of retrieval can always be reported, meaning it is conscious. This links both direct and involuntary autobiographical memory retrieval to consciousness, in line with traditional models of human memory. Accordingly, forgetting/remembering is all or none. Newer views of episodic memory allow for unconscious episodic memory formation and retrieval (<xref ref-type="bibr" rid="c39">39</xref>–<xref ref-type="bibr" rid="c41">41</xref>). These views open the field conceptually to studying all shades of forgetting from losing conscious access to finally also losing unconscious access to an episodic memory. The finding of persistent neural engrams of once consciously acquired episodic memories, which subsequently lost conscious accessibility, would therefore inform traditional models of human episodic memory.</p>
<p>There is some animal and human evidence indicating that memory traces of forgotten episodic memories might indeed influence behavior implicitly. For example, mice that had learned a Morris water maze as infants forget the location of the platform as they grow. Nevertheless, they are significantly quicker at relearning the location of the platform than naive adult mice (<xref ref-type="bibr" rid="c42">42</xref>). Furthermore, previously learned and then forgotten images were still retrieved implicitly at 24 hours following learning and yielded fMRI-measured brain activation changes in regions that partly overlapped with regions activated during successful conscious image retrieval (<xref ref-type="bibr" rid="c43">43</xref>). In addition, there is substantial evidence for the feasibility of an unconscious retrieval of subliminally encoded and sleep-encoded associative memories in humans (<xref ref-type="bibr" rid="c44">44</xref>–<xref ref-type="bibr" rid="c48">48</xref>), bolstering the claim that episodic learning and retrieval can proceed outside of conscious awareness. In the current experiment, we therefore expected to observe behavioral evidence of episodic memory expression even when participants indicated that they had forgotten the memory and therefore needed to guess (i.e., above-chance guessing).</p>
<p>In this translational endeavor, we measured blood-oxygenation-level dependent (BOLD) brain activity in 40 healthy young adults with high-resolution fMRI at 7 Tesla. The increased signal-to-noise ratio of 7 Tesla fMRI improves the spatial resolution, which enhances the measurement of the (dis)similarity of activity patterns for individual memory traces over time (<xref ref-type="bibr" rid="c21">21</xref>). The large number of associations, which needed to be learned rapidly, was intended to maximize forgetting by anterograde and retrograde interference (<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c50">50</xref>). Participants were imaged during learning, an immediate retrieval, a 30-minute retrieval, and a 24-hour retrieval. Most forgetting from episodic memory occurs during the first 24 hours following learning (<xref ref-type="bibr" rid="c51">51</xref>–<xref ref-type="bibr" rid="c53">53</xref>). Half of participants (N = 20) were examined with a small field-of-view (FOV) fMRI sequence that focused on the bilateral medial temporal lobe (MTL; 0.8 mm isotropic voxel size) to target the hippocampal engram components, and other half (N = 20) with a whole-brain fMRI sequence (1.1 mm isotropic voxel size) that targeted neocortical engram components. Engram components were revealed using univariate and multivariate (representational similarity) fMRI analyses. Remembered and forgotten memories were probed separately and in conjunction to each other.</p>
<p>While learning, we presented a series of 96 face-object combinations, each combination being shown only once for one-shot learning (<xref rid="fig1" ref-type="fig">Figure 1</xref>). The presented objects were sampled from two categories, organic (e.g., kiwi) and inorganic (e.g., stapler). Memories were prompted with two retrievals: Cued by the image of a previously presented face, participants indicated whether the face-associated object was organic or inorganic (category retrieval) and cued by the same face plus the original object and a foil object, participants chose the object that was originally presented with the face (2-alternative forced-choice recognition). The foil object had been presented with another face during learning. Category retrieval followed the learning of a face-object combination immediately to ensure that learning was successful, and it was repeated 30 minutes and 24 hours following learning to track forgetting. The recognition task was only given at 24 hours after learning and it always followed category retrieval. Following each retrieval/recognition response, participants indicated whether their just given response was 1) a pure guess because they had forgotten the memory, 2) an unsure response because the memory was neither fully forgotten nor fully accessible, or 3) a sure response because the memory was consciously accessible. We evaluated only the extremes, i.e., the guess responses (forgotten) and the sure responses (consciously accessible) comparing their underlying brain activations.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption>
<title>Experimental design.</title>
<p>A) Overall procedure. Forty participants were randomly assigned to one of the two functional magnetic resonance imaging (fMRI) sequences, one fMRI sequence covering the whole brain and the other covering only the medial temporal lobe. Participants took part in two (f)MRI sessions, separated by 24 hours including one night of sleep. B) Day 1 procedure. Participants learned naturalistic face-object pairs (shown here as pictograms for illustration) and immediately retrieved the pairs with the category retrieval (imm. retrieval: immediate category retrieval) to assess whether successful learning occurred. Next, participants had a short pause of 5 minutes, during which they remained in the scanner and performed an odd-even task preventing them from actively rehearsing the face-object pairs. Following the short pause, participants took the 30-minute category retrieval. They chose the face-associated object category (organic or inorganic) and rated the confidence of their response (sure, unsure, guess). Due to the short pause and the pseudo-random shuffling of the face-object pairs, the interval between the one-trial learning and the 30-minute category retrieval was constant at 30 minutes for each pair. C) Day 2 procedure. Repetition of the category retrieval at 24 hours including the confidence rating, followed by an object recognition task and another confidence rating.</p>
</caption>
<graphic xlink:href="656652v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Behavioral results</title>
<p>Because the sample consisted of young and healthy men and women, there were almost no false memories in the sense of incorrect sure responses. On the immediate category retrieval, which was done to ensure correct memory formation, participants retrieved the object categories with a mean accuracy of 98% (SD = 2%). All responses were rated ‘sure’ (consciously retrieved). Those few trials that yielded an incorrect response were excluded from the subsequent analyses. Behavioral data of all 40 participants are summarized in <xref rid="fig2" ref-type="fig">Figure 2</xref> and Table S1.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption>
<title>Behavioral results.</title>
<p>A) Relative frequencies (bar sections) of confidence judgements across retrievals. Frequency of sure responses drops at the 24-hour category retrieval and rises again during recognition. Frequency of guess responses shows the opposite pattern of change. Frequency of unsure responses drops at the 24-hour category retrieval and remains constant between the 24-hour category retrieval and recognition. B) Guessing accuracy (percentage correct of all guess responses) on the category retrievals and the recognition. Above-chance accuracy was observed only for guess responses given on the recognition task (p = 0.005). These results include all 40 participants. Abbreviations: ret = category retrieval; recog = recognition. Note: dotted line represents chance level of 0.5</p>
</caption>
<graphic xlink:href="656652v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Paired-sample, two-tailed t-tests revealed a significant drop in the frequency of sure responses from 30-minute (<italic>M</italic> = 27.1%, <italic>SD</italic> = 14.2%) to 24-hour (<italic>M</italic> = 21.6%, <italic>SD</italic> = 15.3%) retrieval (<italic>t</italic>(39) = 5.41, p &lt; 0.001). In contrast, the frequency of guess responses rose from 30-minute (<italic>M</italic> = 39.8%, <italic>SD</italic> = 15.6%) to 24-hour (<italic>M</italic> = 50.8%, <italic>SD</italic> = 20.07%) category retrieval (paired t-test, two-tailed, <italic>t</italic>(39) = −5.36, p &lt; 0.001). The frequency of unsure responses decreased between these retrieval time-points (paired t-test, two-tailed, <italic>M</italic><sub>30min</sub> = 33.1%, <italic>SD</italic><sub>30min</sub> = 13.4%, <italic>M</italic><sub>24h</sub> = 27.6% <italic>SD</italic><sub>24h</sub> = 15.8%, <italic>t</italic>(39) = 3.07, p = 0.003). On the recognition task given at 24 hours following the category retrieval, paired t-tests revealed that the frequency of sure responses almost doubled from the category retrieval at 24-hours to the recognition task (<italic>M</italic><sub>recog</sub> = 44.9%, <italic>SD</italic><sub>recog</sub> = 22.9%, <italic>M</italic><sub>24h</sub> = 21.6%, <italic>SD</italic><sub>24h</sub> = 15.3%, paired t-test, two-tailed, <italic>t</italic>(39) = −10.778, p &lt; 0.001). This suggests that many of the face-object combinations that were no longer consciously accessible on the category retrieval regained conscious access with the additional object cue. Conversely, the number of guess responses decreased by half (paired t-test, two-tailed, <italic>M</italic><sub>24h</sub> = 50.8% <italic>SD</italic><sub>24h</sub> = 20.07%, <italic>M</italic><sub>recog</sub> = 27.1%, <italic>SD</italic><sub>recog</sub> = 17.3%, <italic>t</italic>(39) = 9.63, p &lt; 0.001), while the number of unsure responses remained unchanged (paired t-test, two-tailed, <italic>M</italic><sub>24h</sub> = 27.6% <italic>SD</italic><sub>24h</sub> = 15.8%, <italic>M</italic><sub>recog</sub> = 28.0%, <italic>SD</italic><sub>recog</sub> = 15.2% <italic>t</italic>(39) = −0.15, p = 0.88). For a graphical illustration of the relative frequencies of response categories, see <xref rid="fig2" ref-type="fig">Figure 2A</xref>.</p>
<p>The retrieval accuracy on the 30-minute and 24-hour category retrieval was almost at ceiling level for the sure responses (<italic>M</italic><sub>30min</sub> = 87.8%, <italic>SD</italic><sub>30min</sub> = 10.1%; <italic>M</italic><sub>24h</sub> = 89.6%, <italic>SD</italic><sub>24h</sub> = 13.5%) but not better than chance for the guess responses (<italic>M</italic><sub>30min</sub> = 50.1 %, <italic>SD</italic><sub>30min</sub> = 10%; <italic>μ</italic> = 50%, one-sample, two tailed t-test, <italic>t</italic>(39) = 0.05, p = 0.95; <italic>M</italic><sub>24h</sub> = 49.4%, <italic>SD</italic><sub>24h</sub> = 7.1%; <italic>μ</italic> = 50%, one-sample, two tailed t-test, <italic>t</italic>(39) = −0.4, p = 0.64, see <xref rid="fig2" ref-type="fig">Figure 2B</xref>). The unsure responses yielded an accuracy above chance level at the 30-minute category retrieval (<italic>M</italic><sub>30min</sub> = 56.8%, <italic>SD</italic><sub>30min</sub> = 10.3%; <italic>μ</italic> = 50%, one-sample, two tailed t-test, <italic>t</italic>(39) = 4.13, p = 0.0002) and at the 24-hour category retrieval (<italic>M</italic><sub>24h</sub> = 54.1%, <italic>SD</italic><sub>24h</sub> = 9.5%; <italic>μ</italic> = 50%, one-sample, two tailed t-test, <italic>t</italic>(39) = 2.7, p = 0.01). The recognition accuracy for sure responses was at ceiling level (<italic>M</italic><sub>recog</sub> = 94%, <italic>SD</italic><sub>recog</sub> = 12.9%), significantly better than chance for the unsure responses (<italic>M</italic><sub>recog</sub> = 77.2%, <italic>SD</italic><sub>recog</sub> = 12.5%; one-sample, two tailed t-test, <italic>μ</italic> = 50%, <italic>t</italic>(39) = 14.1, p &lt; 0.0001), and significantly better than chance for the guess responses (<italic>M</italic><sub>recog</sub> = 57.5%, <italic>SD</italic><sub>recog</sub> = 14.1%; one-sample, two tailed t-test, <italic>μ</italic> = 50%, <italic>t</italic>(39) = 3.35, p = 0.005, see <xref rid="fig2" ref-type="fig">Figure 2B</xref>). The Bayes Factor provided moderate evidence in favor of the alternative model for the guess responses (BF<sub>10</sub> = 7.4). Hence, even when participants were only guessing which of two objects was presented along with the face during learning, their intuition guided them with a better-than-chance accuracy. These analyses included all 40 participants.</p>
</sec>
<sec id="s2b">
<title>fMRI results from univariate analyses</title>
<p>For the fMRI analyses, the correct guess responses were contrasted to the incorrect guess responses based on the hypothesis that a reactivation of the putative memory trace underlying a forgotten memory (therefore a guess response) would more often occur in trials that yield a correct than incorrect response. Because sure responses were almost always correct, remembered trials were also contrasted with incorrect guess responses. For brain-behavior correlations, we used the z-scored percentage correct of all guess responses (guessing accuracy) for contrasts of guess responses and the z-scored absolute number of correct sure responses (sure accuracy) for contrasts of sure responses.</p>
</sec>
<sec id="s2c">
<title>Common hippocampal areas mediated correct sure and correct guess responses at the 30-minute and 24-hour category retrieval</title>
<p>We asked whether forgotten memories, i.e., guess responses, were accompanied by activity increases within the episodic memory network like consciously accessible memories, i.e., sure responses (<xref ref-type="bibr" rid="c54">54</xref>–<xref ref-type="bibr" rid="c58">58</xref>). This was indeed the case, as revealed by the following analyses. We isolated activity increases underlying associative retrieval from activity increases underlying mere face recognition and retrieval effort by computing the contrast correct sure responses versus incorrect guess responses and the contrast correct guess responses versus incorrect guess responses. These contrasts were then statistically conjugated to find common brain activation underlying correct sure and correct guess responses.</p>
<p>For the 30-minute category retrieval, the conjunction analysis using the data from the small FOV fMRI sequence yielded results in the right hippocampus (right hippocampus: p<sub>uncor</sub> &lt; 0.001, <italic>T(285)</italic> = 4.05, peak at coordinates based on the Montreal Neurological Institute (MNI) [30,−32,−9], see <xref rid="fig3" ref-type="fig">Figure 3A</xref> and Table S2). Further significant conjunctive results were located in the left posterior cingulate gyrus. These results were not replicated in the whole-brain fMRI sequence that had a slightly worse spatial resolution: the same conjunction analysis with data from the whole-brain fMRI sequence yielded no significant result at p &lt; 0.001 uncorrected and k = 10 voxel extent.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption>
<title>Right hippocampal activity increased for both correct sure and correct guess responses at the 30-minute and the 24-hour category retrieval and correlated for guess responses with guessing accuracy at both testing time points.</title>
<p>A) Common right hippocampal activity increases underlying correct sure and correct guess responses at the 30-minute category retrieval. We isolated activity increases underlying associative retrieval from activity increases underlying mere face recognition, task characteristics, and retrieval effort by computing the contrast correct sure responses &gt; incorrect guess responses and the contrast correct guess responses &gt; incorrect guess responses. These contrasts were then statistically conjugated to find common brain activation underlying correct sure and correct guess responses. For a table of cluster sizes and t-values, see Table S2. Results presented in this panel stem from the small FOV fMRI sequence. B) Common right hippocampal activity rises underlying correct sure and correct guess responses at the 24-hour category retrieval. Statistical analysis analogous to 3A. For a table of cluster sizes and t-values, see Table S3. Results presented in this panel stem from the small FOV fMRI sequence. C) Right hippocampal activity underlying correct guess responses on the category retrieval correlated with the guessing accuracy on the category retrieval at 30 minutes and at 24 hours. Upper panel: positive brain-behavior correlation in the right hippocampus. We show the contrast of correct guess &gt; incorrect guess responses correlated with the guessing accuracy on the category retrieval at 30 minutes (for cluster sizes and t-values, see Table S4). Lower panel: positive brain-behavior correlation in the right hippocampus. We show the contrast of correct guess &gt; incorrect guess responses correlated with the guessing accuracy on the category retrieval at 24-hours (for cluster sizes and t-values, see Table S5). Outliers (above absolute z-value of 3) were removed. Results presented in this panel stem from the small FOV fMRI sequence.</p>
</caption>
<graphic xlink:href="656652v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>For the 24-hour category retrieval, the conjunction analysis using the data from the small FOV fMRI sequence yielded also a result in the right hippocampus, albeit slightly below our chosen threshold of p &lt; 0.001 uncorrected (right hippocampus: p<sub>uncor</sub> = 0.0012, <italic>T(285)</italic> = 3.07, peak at MNI [26,−18,−17]). For illustrative purposes, see <xref rid="fig3" ref-type="fig">Figure 3B</xref> at p &lt; 0.005 uncorrected. Significant results (at p &lt; 0.001) were located in the left lingual gyrus and bilateral posterior cingulate gyrus (see Table S3). The same conjunction analysis computed with data from the whole-brain fMRI sequence yielded no significant result. The lower power of conjunctive activity in the right hippocampus head at 24 hours might be due to a distinct overnight consolidation for consciously accessible versus consciously inaccessible memories, see below.</p>
<p>Hence, the hippocampus and other relevant structures of the episodic memory retrieval network were involved in the reactivation of both consciously accessible and consciously inaccessible associative memories at the 30-minute and at the 24-hour category retrieval.</p>
</sec>
<sec id="s2d">
<title>Hippocampal activity underlying correct guess responses correlated with the guessing accuracy on the category retrievalat 30 minutes and at 24 hours</title>
<p>Given that correct guess responses and correct sure responses were accompanied by activations in the same right hippocampal region, we then examined whether right hippocampal activity underlying correct guess responses versus incorrect guess responses would correlate with guessing accuracy across participants. Using the small FOV fMRI sequence for this analysis, a cluster in the right hippocampus head correlated with the guessing accuracy and even survived family-wise error correction (peak at MNI [27,−8,−25], cluster-level p<sub>FWE</sub> = 0.019, T(18) = 6.31, R = 0.72, see <xref rid="fig3" ref-type="fig">Figure 3C</xref>, upper panel and Table S4 for all correlation results). Besides the right hippocampus, significant correlations were located in multiple bilateral inferior and middle temporal regions putatively supporting the reactivation of semantic object-related information and the precuneus and the posterior cingulate gyrus related to visual imagery.</p>
<p>The same correlation computed for the 24-hour category retrieval using the small FOV fMRI sequence yielded a significant cluster in the same area within the right hippocampus head (peak at MNI [28, −10,−28], p<sub>uncor</sub> &gt; 0.001, T(18) = 4.70, R = 0.70, see <xref rid="fig3" ref-type="fig">Figure 3C</xref>, lower panel) besides multiple further clusters located in the right and left hippocampus (see Table S5). This result suggests that the bilateral hippocampus is involved in the retrieval of consciously inaccessible memories at 24 hours following learning, probably due to over-night memory consolidation, as detailed in a section below (see also <xref rid="fig5" ref-type="fig">Fig. 5</xref>). Besides bilateral hippocampal areas, significant correlations were located in several bilateral middle temporal regions probably supporting the reactivation of semantic object-related information.</p>
</sec>
<sec id="s2e">
<title>Hippocampal functional connectivity during learning and 30-minute category retrieval correlated with the 30-minute guessing accuracy for forgotten associations</title>
<p>We next asked which neural circuits would interact with the right hippocampus when forming new associative memories that would later be forgotten. To this end, we computed a general psycho-physiological interaction analysis (gPPI) with the right hippocampus head as the seed region (based on the correlative results above) using the data of the whole-brain fMRI sequence. The comparison of learning trials that would yield correct versus incorrect guess responses at the 30-minute category retrieval (subsequent memory analysis) revealed that seed-based connectivity estimates correlated between-subjects with guessing accuracy. This was true for the right hippocampus head-to-bilateral anterior cingulate/medial superior frontal gyrus connectivity (peak at MNI [12,42,−4], peak-level p<sub>FWE</sub> &lt; 0.05, <italic>T(18)</italic> = 7.8, R = 0.92, see <xref rid="fig4" ref-type="fig">Figure 4A</xref>) and right hippocampus head-to-left hippocampus, right hippocampus head-to-bilateral lingual gyrus, and right hippocampus head-to-bilateral cuneus/precuneus connectivity (all results listed in Table S6). When computing this same correlation analysis with data collected during the 30-minute category retrieval, the right hippocampus-to-medial superior frontal gyrus connectivity again correlated with guessing accuracy (peak at MNI [12,46,28], cluster-level p<sub>FWE</sub> &lt; 0.001, <italic>T(18)</italic> = 6.25, R = 0.85, see <xref rid="fig4" ref-type="fig">Figure 4B</xref>). Connectivity from right hippocampus to bilateral lingual gyrus, right cuneus and bilateral precuneus no longer correlated at the 30-minute category retrieval. However, right hippocampus-to-various prefrontal regions and right hippocampus-to-left inferior temporal gyrus connectivity correlated between-subjects with retrieval accuracy at the 30-minute category retrieval (all results listed in Table S7). No significant correlations were found between seed-based connectivity and guessing accuracy at 24-hour category retrieval. The reason for this lack of significant results at 24 hours might be the overnight consolidation of forgotten memories that provided for a deeper rooting of forgotten memories in the hippocampus rather than the neocortex (this will be detailed below).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption>
<title>Hippocampal functional connectivity measured during learning and during the 30-minute category retrieval correlated with the 30-minute category retrieval guessing accuracy.</title>
<p>A) Hippocampal-medial prefrontal functional connectivity during learning correlated with the later recorded 30-minute category retrieval guessing accuracy. We computed the functional connectivity between the seed region in the right hippocampus head (see box inlet) with neocortical regions during learning using a gPPI. In participants with a higher guessing accuracy on the 30-minute category retrieval, the functional connectivity was stronger between the right hippocampus head and the right anterior cingulate gyrus and the right medial prefrontal cortex. Outliers (above absolute z-value of 3) were removed. For a table of cluster sizes and t values see Table S6. Results presented in this panel stem from the whole-brain fMRI sequence. B) Hippocampal-medial prefrontal functional connectivity during the 30-minute category retrieval correlated with the 30-minute category retrieval guessing accuracy. We computed the functional connectivity between the seed region in the right whole hippocampus (see box inlet) with neocortical regions during the 30-minute category retrieval using a gPPI. Participants with a higher guessing accuracy on the 30-minute category retrieval, exhibited a stronger functional connectivity between the right hippocampus and the right medial prefrontal cortex. Outliers (above absolute z-value of 3) removed. For cluster sizes and t-values see Table S7. Results presented in this panel stem from the whole-brain fMRI sequence.</p>
</caption>
<graphic xlink:href="656652v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2f">
<title>Overnight consolidation brought a neocorticalization for sure responses and a deeper/broader hippocampal implementation for guess responses</title>
<p>Following the first visit to the MR Center, the learned face-object associations underwent overnight consolidation before participants reactivated the associations again during the category retrieval on day 2. Following overnight consolidation, memory traces underlying sure versus guess responses became implemented more strongly in the neocortex as the standard model of memory consolidation predicts. This was the result of the stacked contrast (24-hour category retrieval: correct sure &gt; correct guess) &gt; (30-minute category retrieval: correct sure &gt; correct guess responses) computed with the whole-brain fMRI data. It revealed strong overnight increases in activity in many bilateral fronto-parietal, temporal and occipital regions (all results in Table S8). The same computation with data from the small FOV fMRI sequence did not yield significant results.</p>
<p>In contrast, memory traces underlying correct guess responses on the category retrieval were implemented more broadly and more strongly within bilateral hippocampus on the second versus the first day. This was the result of the comparison of correct guess responses given at the 24-hour category retrieval versus correct guess responses given at the 30-minute category retrieval using the data of the small FOV fMRI sequence. The result revealed overnight activity increases in bilateral hippocampus head (left hippocampus: peak at MNI [−27, −16, −14], p<sub>uncor</sub> &lt; 0.001, <italic>T(18)</italic> = 4.62, right hippocampus: peak at MNI [39,−22,−12], p<sub>uncor</sub> &lt; 0.001, <italic>T(18)</italic> = 3.91, see Table S9 for all results). The reverse contrast did not yield significant results in the hippocampus but results in the left-hemisphere: entorhinal area and middle temporal gyrus (see Table S10). Repeating this analysis using the data from the whole-brain fMRI sequence yielded merely one cluster in the inferior occipital gyrus for correct guess responses at 24 hours versus correct guess responses at 30 minutes (peak at MNI [−30 −90 −12], p<sub>uncor</sub> &lt; 0.001, <italic>T(18)</italic> = 3.81).</p>
<p>Next, we computed a gPPI analysis with the seed region in the right hippocampus head using the small FOV fMRI sequence to examine overnight changes in the functional connectivity within the medial temporal lobe underlying correct guess responses. Contrasting the functional connectivity underlying the correct guess responses given at the 24-hour category retrieval with the functional connectivity underlying correct guess responses given at the 30-minute category retrieval and correlating the results with the 24-hours guessing accuracy, we see an overnight increase in the behaviorally relevant functional connectivity of the right hippocampus head with left hippocampal regions (peak at MNI [−26,−30,−4], cluster-level p<sub>FWE</sub> = 0.011, <italic>T(18)</italic> = 5.37, R = 0.61), with right entorhinal cortex, and with several regions within the right lateral temporal lobe (<xref rid="fig5" ref-type="fig">Figure 5</xref>; for all results, see Table S11). Hence, the overnight consolidation left the memory traces underlying guess responses implemented more broadly and deeply in bilateral hippocampus, which benefitted the accuracy of the guess responses given at 24 hours.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption>
<title>Overnight right-left hippocampal functional connectivity increases improved guessing accuracy at the 24-hour category retrieval.</title>
<p>We computed a gPPI analysis with the seed region in the right hippocampus head (see box inlet) using the small FOV fMRI sequence to examine overnight changes in the functional connectivity within the medial temporal lobe underlying correct guess responses on the category retrieval. We contrasted the functional connectivity underlying the correct guess responses given on the 24-hour category retrieval with the functional connectivity underlying correct guess responses given on the 30-minute category retrieval and then correlated the result with the 24-hour guessing accuracy on the category retrieval. Connectivity estimates and guessing accuracy were z-scored. Outliers (above absolute z-value of 3) removed. See Table S11 for all results.</p>
</caption>
<graphic xlink:href="656652v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2g">
<title>Medial prefrontal cortex activation during guess responses given at the 24-hour category retrieval predicted the subsequent regain of conscious access to the memories</title>
<p>As mentioned in the behavioral results section, the mean guessing accuracy on the 24-hour category retrieval was at chance level but then rose significantly above chance level on the immediately following recognition task, where the face plus two objects (original object and foil object) were presented along with the face cue as additional retrieval cues. Hence, the addition of a valid object retrieval cue to the face retrieval cue (which was also present for category retrieval) improved the guessing accuracy and sometimes even allowed participants to regain conscious access to the previously inaccessible memories (see <xref rid="fig2" ref-type="fig">Figure 2A</xref>). Because the recognition task immediately followed the 24-hour category retrieval, we were wondering which brain regions elevated activation levels during the 24-hour category retrieval and whether these activation elevations would predict the subsequent regain of conscious access during the recognition. To this end, we contrasted the guess responses on the 24-hour category retrieval that would subsequently yield correct sure responses (i.e., conscious access) on the recognition task with those other guess responses given on the 24-hour category retrieval that would yield correct guess responses (i.e., no conscious access) on the recognition. We used the data from the whole-brain fMRI sequence. The medial prefrontal cortex was strongly activated for later correct sure versus correct guess responses given on the recognition task (peak at MNI [0 30 −16], p<sub>uncor</sub> &lt; 0.001, <italic>T(18)</italic> = 4.19, see Figure S1A and Table S12). This suggests that consciously inaccessible memories (guesses) on the 24-hour category retrieval that possess (versus not) a medial prefrontal engram component, tend to become consciously accessible again when given an additional retrieval cue (the object).</p>
</sec>
<sec id="s2h">
<title>Additional object cues given on the recognition task permitted the reactivation of engram components in the episodic memory network underlying sure responses and guess responses</title>
<p>Because the right hippocampus head was involved in both guess and sure responses during the category retrieval, we asked which neural circuits the right hippocampus head would engage in for successful face-object recognition. We computed a gPPI analysis with the seed region in the right hippocampus head using the whole-brain fMRI sequence to examine the functional connectivity underlying guess and sure responses given during recognition. Like in earlier analyses, we subtracted the functional connectivity for incorrect guess responses from the functional connectivity for correct sure and for correct guess responses given during recognition. The results were correlated with the sure and guess recognition accuracy, respectively. Then, we computed a conjunction analysis on the two gPPI results to determine commonly activated and behaviorally relevant neural circuits underlying recognition. The functional connectivity of the right hippocampus head with bilateral lingual gyrus and bilateral calcarine cortex was crucial for recognition success (peak at MNI [−4 −82 −2], p<sub>uncor</sub> &lt; 0.001, <italic>T(18)</italic> = 3.53, note that this was the only cluster found for this conjunction analysis). Hence, the functional connectivity of the right hippocampus with areas of the visual cortex was relevant for the explicit (remembered associations) and implicit (forgotten associations) recognition of the previously learned face-object combinations.</p>
<p>Zooming in on the forgotten associations, we were wondering about the difference in the behaviorally relevant functional connectivity of the right hippocampus head for those forgotten memories that still yielded correct versus incorrect guess responses on the recognition. We computed a gPPI analysis with data from the whole-brain fMRI sequence for the seed region in the right hippocampus head comparing correct versus incorrect guess responses on the recognition task and correlated the results between-subjects with the individual accuracy of the guess responses. The accuracy of the guessed recognition responses increased with a connectivity increase between the right hippocampus head and the left hippocampus tail, between the right hippocampus head and bilateral lingual gyrus, between the right hippocampus head and the left middle temporal gyrus as well as between the right hippocampus head and a large bilateral fronto-parietal network (all results in Table S13).</p>
<p>Unlike face-cued relational retrieval during the category retrieval, relational (face-object) recognition may in principle be mediated by at least three distinct memory mechanisms: episodic memory, priming, and familiarity. While the feeling of familiarity is consciously accessible and therefore cannot have influenced guess responses, priming is unconscious and might have added to the correct guess responses given on the recognition task (<xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c60">60</xref>). Hence, perceptual and/or semantic associative priming may have contributed to the above chance guessing result on the recognition. Nevertheless, guessing accuracy on the recognition task was mediated by bilateral hippocampal connectivity, which suggests that guessing accuracy was also driven by episodic memory.</p>
<p>Zooming in on the consciously accessible associations, we computed the same gPPI analysis for correct sure versus incorrect guess responses given on the recognition task and correlated the result between-subjects with the individual accuracy of the sure responses. The result was a similar connectivity of the right hippocampus head with bilateral lingual gyrus, with the right middle temporal gyrus as well as a large bilateral fronto-parietal network, but no connectivity with the left hippocampus tail (see Table S14 for all results).</p>
<p>Hence, response accuracy during guessing was mediated by bilateral hippocampal connectivity. Response accuracy during both guessing and sure responses was mediated by the connectivity of the right hippocampus head with visual cortices and a large bilateral fronto-parietal network. It thus appears that the addition of the relevant object cue during recognition allowed for a better reactivation of engram components in the episodic memory network underlying both sure and guess responses. Note that the right hippocampus head-to-left hippocampus tail connectivity result for guess responses was not replicated when using the small FOV fMRI sequence. The cause might be participant differences because of the between-subjects design in implicit retrieval or a poor signal in this very posterior left hippocampal region.</p>
</sec>
<sec id="s2i">
<title>fMRI results from representational similarity analyses</title>
<p>We asked whether more fine-grained engram components, namely individual voxel patterns, would reactivate during distinct memory stages and reflect the persistence or shift regarding certain engram components over time. We expected the repetition of voxel patterns underlying memories in those brain areas that yielded significant results in the above reported univariate analyses. Therefore, we chose a region-of-interest approach deriving the regions-of-interest from the above reported univariate results and from the priori hypothesis that the hippocampal engram components would persist when a memory becomes consciously inaccessible. Of particular interest regarding the trajectory of episodic memories were recurring or shifting voxel patterns in the hippocampus. We computed representational similarity analyses (RSA), i.e., pair-wise comparisons of voxel patterns, comparing encoding – retrieval similarity (ERS) for the 30-minute and 24-hour category retrieval, encoding – recognition (at 24 hours) similarity, and retrieval (30 minutes) – retrieval (24 hours) similarity (RRS) for the category retrieval. We separated trials into guess and sure responses to compare the trajectory of engram components for consciously accessible and consciously inaccessible memories. By subtracting RSA values underlying incorrect guess responses from RSA values underlying correct guess and correct sure responses, we isolated estimates due to associative retrieval success by eliminating estimates that originate from the mere repetition of face cues (yielding face recognition) and by eliminating estimates that originate from shared task requirements (STAR Methods). Thus, the below reported similarity estimates underly successful associative encoding and associative retrieval operations. The height threshold in all RSA analyses was set to p &lt; 0.05, uncorrected for multiple comparisons. We report a Bayes factor for each t-test and Pearson correlation.</p>
</sec>
<sec id="s2j">
<title>Similarity of voxel patterns between encoding and the 30-minute category retrieval were relevant for retrieval accuracy</title>
<p>Using data from the small FOV fMRI sequence, voxel pattern similarity in the left hippocampal body between encoding and the 30-minute category retrieval for correct sure responses tended towards a significant correlation with the sure accuracy across subjects (p = 0.086, R = 0.39, BF<sub>10</sub> = 1.1). The same computation yielded neither a tendency nor a significant result in the medial temporal lobe for correct guess responses.</p>
<p>Within neocortex (using data from the whole-brain fMRI sequence), voxel patterns were significantly similar in the bilateral inferior temporal gyrus for correct sure responses (<italic>t(16</italic>) = 2.3, p = 0.035, BF<sub>10</sub> = 1.9, see Figure S2), with no significant between-subjects correlation of the similarity values with the sure accuracy. For correct guess responses, this computation revealed non-significant mean value comparisons but a significant between-subjects correlation between the degree of similarity of voxel patterns in the bilateral middle temporal gyrus and guessing accuracy (p = 0.022, R = 0.55, BF<sub>10</sub> = 3.3, see <xref rid="fig6" ref-type="fig">Figure 6A</xref>). It thus appears that the reactivation of engram components in the inferior and middle temporal gyrus contributed to the conscious and unconscious reactivation of memories at 30 minutes following encoding.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption>
<title>Encoding – retrieval and retrieval – retrieval similarity.</title>
<p>A) Left panel: Similarity of voxel patterns between encoding and the 30-minute category retrieval were relevant for retrieval success. Significant between-subjects correlation of encoding-retrieval similarity values with guessing accuracy on the 30-minute category retrieval in bilateral middle temporal gyrus. Results presented in this panel were acquired with the whole-brain fMRI sequence. Right panel: small FOV ROI overview for B) and C) B) Similarity of voxel patterns between encoding and the 24-hour category retrieval were relevant for retrieval success. Encoding-retrieval similarity values were significant in left parahippocampal gyrus for both correct guess responses (left) and correct sure responses (right) (t(19) = 2.65, p = 0.015, BF<sub>10</sub> = 3.5; t(19) = 2.35, p = 0.029, BF<sub>10</sub> = 2.1, respectively). Results presented in this panel were acquired with the small FOV fMRI sequence. C) Dissimilarity of voxel patterns between the 30-minute and the 24-hour category retrieval were relevant for retrieval success. Left panel: 30-minute – 24-hours category retrieval dissimilarity in the right hippocampus head for correct sure responses. Results presented in this panel were acquired with the small FOV fMRI sequence. Right panel: 30-minute – 24-hours category retrieval dissimilarity values correlated between-subjects with the delta of correct sure responses (24-hours sure accuracy minus 30-minute sure accuracy) in bilateral anterior cingulate gyrus (B. ant. cing. g.). Results presented in this panel were acquired with the whole-brain fMRI sequence. *p &lt; 0.05, **p &lt; 0.01 by Student’s t test. Abbreviations: ROI, region of interest; R., right; L., left; hipp., hippocampus; parahipp., parahippocampus; g., gyrus.</p>
</caption>
<graphic xlink:href="656652v3_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2k">
<title>Similarity of voxel patterns between encoding and the 24-hour category retrieval were relevant for retrieval success</title>
<p>Following the first visit at the MR Center, the encoded face-object associations underwent overnight consolidation before participants reactivated the associations again during their second visit at the MR Center on day 2. Overnight memory consolidation may have stabilized the activated voxel patterns from their inception to their 24-hour reactivation during the category retrieval. For both correct guess (p = 0.029, <italic>t(19)</italic> = 2.35, BF<sub>10</sub> = 2.1) and correct sure (p = 0.015, <italic>t(19)</italic> = 2.65, BF<sub>10</sub> = 3.5) responses, voxel patterns were significantly similar between encoding and the 24-hour category retrieval within the left parahippocampal gyrus (see <xref rid="fig6" ref-type="fig">Figure 6B</xref>). Moreover, the degree of this left parahippocampal pattern similarity for sure responses tended to correlate between-subjects with the sure accuracy on the 24-hour category retrieval (p = 0.058, R = 0.43, BF<sub>10</sub> = 1.5); the same was true for the left hippocampal body (p = 0.059, R = 0.44, BF<sub>10</sub> = 1.5). Note that the pattern similarity in the left hippocampal body had already correlated between subjects with the sure accuracy for the encoding – 30-minute comparison. Hence, medial temporal pattern reinstatements were behaviorally relevant for the conscious retrieval at both time-points. For correct guess responses, however, correlations between medial temporal encoding-retrieval pattern reinstatements and retrieval success did not reach significance. A potential reason could be consolidation: the time after encoding appeared to have strengthened and transformed the medial temporal engram components of forgotten memories. Results from this paragraph are based on data from the small FOV fMRI sequence.</p>
<p>Within neocortex, the similarity of voxel patterns between encoding and the 24-hour category retrieval underlying correct sure responses revealed non-significant mean value comparisons but a significant between-subjects correlation of the similarity values with the sure accuracy within the bilateral middle temporal gyrus (p = 0.006, R = 0.64, BF<sub>10</sub> = 10.4, see Figure S3) as previously seen for the correctly guessed trials for the encoding – 30-minute category retrieval comparison. The similarity of voxel patterns between encoding and 24-hour category retrieval also revealed non-significant mean value comparisons for correct guess responses but a significant between-subjects correlation with guessing accuracy in bilateral cuneus (p = 0.049, R = 0.48, BF<sub>10</sub> = 1.8) plus non-significant correlations within bilateral inferior temporal sulcus (p = 0.099, R = −0.41, BF<sub>10</sub> = 1.0) and bilateral anterior cingulate gyrus (p = 0.100, R = −0.41, BF<sub>10</sub> = 1.0).</p>
</sec>
<sec id="s2l">
<title>(Dis)similarity of voxel patterns between the 30-minute and the 24-hour category retrieval were relevant for retrieval success</title>
<p>The retrieval-retrieval comparison of voxel patterns, i.e., the comparison between the 30-minute and the 24-hour category retrieval, for correct sure responses yielded a significant dissimilarity for the right hippocampus head (p = 0.035, <italic>t(19)</italic> = −2.26, BF<sub>10</sub> = 1.8, see <xref rid="fig6" ref-type="fig">Figure 6C</xref>, left panel). The same analysis for correct guess responses revealed also a significant dissimilarity in the right hippocampus, however in its tail region (p = 0.046, <italic>t(19)</italic> = −2.12, BF<sub>10</sub> = 1.5, not displayed). On the other hand, there was a retrieval-retrieval similarity (not dissimilarity) of voxel patterns in the right hippocampus head underlying correct guess responses that correlated significantly (p = 0.018, R = 0.52, BF<sub>10</sub> = 3.7, see Figure S4) between-subjects with the delta of correct guess responses (i.e., guessing accuracy at 24 hours minus the guessing accuracy at 30 minutes). Hence, participants exhibiting a similar right hippocampal retrieval-retrieval voxel pattern yielded a better retrieval accuracy at 24 hours versus 30 minutes. Although a right hippocampal pattern dissimilarity hallmarked correct retrieval responses at 24 hours versus 30 minutes for both sure and guess responses, a pattern similarity within the right hippocampus head still aided a few participants, who lacked conscious access to memories at both retrieval time-points. Results from this paragraph are based on data from the small FOV fMRI sequence.</p>
<p>Within neocortex, the (dis)similarity of voxel patterns between the 30-minute and the 24-hour category retrieval underlying correct sure responses revealed non-significant mean value comparisons but a significant between-subjects correlation of pattern dissimilarity with the delta of correct sure responses within bilateral anterior cingulate gyrus (p = 0.021, R = −0.55, BF<sub>10</sub> = 3.4, see <xref rid="fig6" ref-type="fig">Figure 6C</xref>, right panel). Thus, the overnight memory consolidation may have also changed the anterior cingulate engram components – and not just the right hippocampal engram components – such that a pattern dissimilarity supported a successful retrieval on the next day. For correct guess responses, the (dis)similarity of voxel pattern between the 30-minute and the 24-hour category retrieval revealed also non-significant mean value comparisons, yet a significantly positive between-subjects correlation of pattern similarity with the delta of guessing accuracy within bilateral cuneus (p = 0.005, R = 0.64, BF<sub>10</sub> = 10.8, not displayed). Hence, participants with a similar cuneal retrieval-retrieval voxel pattern yielded a better retrieval accuracy at 24 hours versus 30 minutes. Therefore, also the cuneal pattern similarity appears to have aided a few participants, who lacked conscious access to memories at both retrieval time-points. Overall, these results show that, especially for dynamic engram components such as the hippocampus and anterior cingulate gyrus, behaviorally relevant dissimilarity can occur.</p>
</sec>
<sec id="s2m">
<title>Encoding – recognition pattern similarity</title>
<p>Unlike the retrieval-retrieval dissimilarity results presented above, there was not a single pattern dissimilarity result for the encoding-recognition comparison. For correct sure responses on the recognition task, voxel patterns were significantly similar between encoding and recognition within the right hippocampal body (p = 0.001, <italic>t(19)</italic> = 3.9, BF<sub>10</sub> = 34.0) and the right parahippocampal gyrus (p = 0.048, <italic>t(19)</italic> = 2.12, BF<sub>10</sub> = 1.5, <xref rid="fig7" ref-type="fig">Figure 7A</xref>), with no significant between-subjects correlations of pattern similarity with recognition accuracy. For correct guess responses on the recognition task, neither mean value comparisons nor correlations between pattern reinstatements and recognition accuracy reached significance. Results from this paragraph are based on data from the small FOV fMRI sequence.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption>
<title>Encoding – recognition pattern similarity.</title>
<p>A) Encoding-recognition pattern similarity in the right hippocampal body and right parahippocampal gyrus for correct sure responses on the recognition task (t(19) = 3.91, p = 0.001, BF<sub>10</sub> = 34.0; t(19) = 2.11, p = 0.048, BF<sub>10</sub> = 1.5, respectively). Results presented in this panel were acquired with the small FOV fMRI sequence. B) Encoding-recognition pattern similarity in bilateral inferior temporal gyrus for correct guess responses on the recognition task (p = 0.038, t(17) = 2.25, BF<sub>10</sub> = 1.8). Results presented in this panel were acquired with the whole-brain fMRI sequence. Right panels: ROI overview. *p &lt; 0.05, **p &lt; 0.01 by Student’s t test. Abbreviations: R., right; L., left; B., bilateral; parahipp., parahippocampus; hipp., hippocampus; entorh., entorhinal; inf., inferior; mid., middle; ant., anterior; cing., cingulate; sup., superior; front., frontal; s., sulcus, g., gyrus c., cortex.</p>
</caption>
<graphic xlink:href="656652v3_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Within neocortex, the similarity of voxel patterns between encoding and recognition underlying correct sure responses on the recognition task revealed a significant mean value comparison in the bilateral inferior temporal sulcus (p = 0.020, <italic>t(17)</italic> = 2.55, BF<sub>10</sub> = 2.9, see Figure S5). The degree of this inferior temporal pattern similarity did not correlate with recognition success. Moreover, a pattern similarity in bilateral anterior cingulate gyrus correlated significantly between-subjects with recognition accuracy (p = 0.042, R = 0.48, BF<sub>10</sub> = 2.0, see Figure S6) but was insignificant in terms of mean value comparison. Also, the similarity of voxel patterns between encoding and recognition for correct guess responses revealed a significant mean value comparison in the bilateral inferior temporal gyrus (p = 0.038, <italic>t(17)</italic> = 2.25, BF<sub>10</sub> = 1.8, see <xref rid="fig7" ref-type="fig">Figure 7B</xref>). The degree of this inferior temporal pattern similarity did not correlate with accuracy of guess responses given on the recognition. Overall, these results show that correct sure responses were accompanied by encoding – recognition voxel pattern similarity in the medial temporal lobe, consistent with an episodic reinstatement, while for guess trials, the encoding-recognition reinstatement of neocortical voxel patterns seems to be relevant for retrieval. A potential reason for the lack of encoding-recognition medial temporal similarity results for correct guess responses could be consolidation: the time after encoding appeared to have strengthened and transformed the medial temporal engram components of forgotten memories.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Inspired by recent engram research in mice suggesting that the engrams of forgotten memories remain implemented in the brain, we asked whether engrams underlying human episodic memories would also persist and whether they influence human behavior implicitly? We mapped the fate of 96 new engrams at the systems level using high-resolution fMRI at 7 Tesla during learning, an immediate, a 30-minute, and a 24-hour category retrieval. Participants indicated on each retrieval trial, whether they remembered or forgot the memory. Almost all 96 associative memories could be formed during the one-trial learning event, and they were consciously retrieved at the immediately given category retrieval. Hence, encoding was successful. Univariate and multivariate analyses of the fMRI data revealed that the engrams of subsequently forgotten memories remained implemented in the episodic memory network and continued to influence the accuracy of guess responses at later stages of category retrieval. The engrams of forgotten memories became deeper implemented within bilateral hippocampus overnight, while consciously accessible memories were neocorticalized overnight. For consciously accessible and inaccessible (forgotten) memories, engram components within right hippocampus and anterior cingulate cortex shifted from the 30-minute to the 24-hour category retrieval. Hence, forgotten episodic memories appear to remain implemented in the episodic memory network and continue to influence human behavior implicitly.</p>
<sec id="s3a">
<title>Traces of consciously inaccessible memories remained in the hippocampus and continued to guide retrieval choices</title>
<p>Although the 30-minute and the 24-hour guessing accuracies on the category retrieval were not above chance level on average, brain activity in the right hippocampus head – an essential brain region for episodic memory (<xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c39">39</xref>) – underlying correct versus incorrect guess responses correlated with guessing accuracy across participants at both time-points. This strongly suggests that the episodic memory traces persisted in the brain despite loss of conscious access to the memories and that the traces continued to influence the participants’ choice behavior at test. Memory traces underlying consciously accessible (sure responses) and consciously inaccessible (guess responses) memories overlapped in the episodic memory retrieval network. The engram-related activity was generally a bit weaker and more circumscribed for forgotten versus remembered memories, although these differences were not significant statistically. The rather weak activity underlying forgotten memories nevertheless influenced the participants’ choice behavior at retrieval (<xref ref-type="bibr" rid="c47">47</xref>, <xref ref-type="bibr" rid="c48">48</xref>, <xref ref-type="bibr" rid="c61">61</xref>).</p>
</sec>
<sec id="s3b">
<title>Distinct consolidation trajectories for consciously accessible and inaccessible memories</title>
<p>Interestingly, consciously accessible and consciously inaccessible memories underwent distinct consolidation trajectories overnight. Consciously accessible memories relied on neocortical structures immediately following encoding and became even more broadly neocorticalized following overnight consolidation, which is typical for systems consolidation of episodic memories. Goto and colleagues (<xref ref-type="bibr" rid="c20">20</xref>) had previously demonstrated that a first wave of long-term potentiation acts locally in the hippocampus during the minutes following learning, a second wave of hippocampal long-term potentiation-dependent consolidation occurs during the first sleep phase following learning; and a third wave of long-term potentiation occurs in the anterior cingulate gyrus on the second day following learning and supports the strengthening of neocortical engram components. It appears that the strong, consciously accessible memories soon underwent the third wave of memory consolidation because they became quickly represented in anterior cingulate gyrus and medial prefrontal cortex. At the behavioral level, the consciously accessible memories remained relatively stable overnight: virtually all consciously accessible memories at the 24-hour category retrieval were already consciously accessible at the 30-minute category retrieval.</p>
<p>The consciously inaccessible (forgotten) memories recruited fewer neocortical areas immediately following encoding and following overnight consolidation, rather they became more broadly implemented in bilateral hippocampus: the left and right hippocampus were more strongly activated during guess responses given at the 24-hour relative to the 30-minute category retrieval. Moreover, the inter-hippocampal connectivity became stronger overnight and correlated with the 24-hour category guessing accuracy. Therefore, overnight memory consolidation may have compensated for a weaker representational status of forgotten memories with the purpose of rescuing these memories from degradation by implementing them deeper in the medial temporal lobe and only later into the neocortex. This compensation appears to have occurred during the first two waves of memory consolidation according to Goto (<xref ref-type="bibr" rid="c20">20</xref>) and colleagues, which act within the hippocampus. Hence, the consolidation of forgotten memories proceeded slower than described by Goto et al. and was much slower than the consolidation of the consciously accessible memories in this study. Interestingly though, the stronger memories among the forgotten memories also activated the anterior cingulate gyrus at the 24-hour category retrieval, like the consciously accessible memories did, and this subgroup of forgotten memories regained conscious access during the recognition. The recognition task was easier than the category retrieval because both the face and the associated object were presented as retrieval cues.</p>
</sec>
<sec id="s3c">
<title>Transformation of engram representations revealed by pattern dissimilarity</title>
<p>A common notion in neuroscience is that neurons that encode information also retain the information and are reactivated in the retrieval process (<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c62">62</xref>, <xref ref-type="bibr" rid="c63">63</xref>). Accordingly, we expected to observe retrieval-related activation within the same voxels that had been activated during encoding. Indeed, voxel patterns repeated from encoding to 30-minute category retrieval within medial temporal and neocortical areas. Yet, the voxel patterns in the hippocampus and anterior cingulate gyrus became dissimilar from the 30-minute to the 24-hour category retrieval for both consciously accessible and inaccessible memories. Hence the retrieval and ensuing re-encoding process at the 30-minute retrieval may have shifted activated voxels within these two key areas of episodic memory, as was observed in the animal model: Neurophysiological studies in animals have shown that hippocampal memory traces can change significantly across time as well as depending on the retrieval demands (<xref ref-type="bibr" rid="c28">28</xref>–<xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c64">64</xref>, <xref ref-type="bibr" rid="c65">65</xref>). Lei and colleagues (<xref ref-type="bibr" rid="c31">31</xref>) recently reported that hippocampal engrams underlying contextual fear memories in mice shift with repeated retrieval. Memory recall can trigger a change in the hippocampal engram leading to the formation of a new, updated hippocampal engram. Ko and colleagues (<xref ref-type="bibr" rid="c66">66</xref>) also found that the time-dependent transformation of contextual fear memories involves a reorganization of hippocampal engram circuits. For our study, we assume that re-encoding and reconsolidation processes have caused the shift in voxel patterns from the 30-minute to the 24-hour category retrieval. There was no systematic reinstatement or shift of hippocampal engram components from encoding to the 30-minute category retrieval or to the 24-hour category retrieval. However, from encoding to the recognition, where the face and object displayed during encoding were re-presented, a right hippocampal engram component reinstated for sure responses possibly due to visual recollection.</p>
<p>A pattern shift from the 30-minute to the 24-hour category retrieval was not just seen in the right hippocampus but also within bilateral anterior cingulate gyrus. The anterior cingulate gyrus is strongly connected to the hippocampus, heavily involved in early consolidation processes (<xref ref-type="bibr" rid="c20">20</xref>), shares cell dynamics with the hippocampus (<xref ref-type="bibr" rid="c67">67</xref>) and even harbors place cells (<xref ref-type="bibr" rid="c68">68</xref>). The anterior cingulate gyrus is also involved in storing novel information into already established knowledge (<xref ref-type="bibr" rid="c69">69</xref>). Its prominent role in early memory consolidation, its connectivity with the hippocampus, and its high plasticity may explain why also the anterior cingulate cortex displays a re-encoding and reconsolidation driven retrieval-retrieval dissimilarity.</p>
</sec>
<sec id="s3d">
<title>Theoretical implications</title>
<p>This research was inspired by experiments in rodents, which suggest that interference-based forgetting is an adaptive form of forgetting, which is reversible and updateable and thus in favor of an inaccessible rather than unavailable engram (<xref ref-type="bibr" rid="c10">10</xref>). For example, Autore and colleagues (<xref ref-type="bibr" rid="c10">10</xref>) showed that although natural retroactive interference during learning resulted in forgetting and decreased engram cell reactivation in the retrieval situation, optogenetic stimulation of previously labeled engram cells enabled memory expression. Hence, engram components remained implemented in the brain despite forgetting. In the consciously inaccessible state, as we have shown here, episodic memories can still be reactivated, they can still guide behavior, and they are still subject to active consolidation processes. Hence, they are far from gone. This informs traditional models of memory that distinguish between memory systems based on whether learning and retrieval occur consciously or unconsciously (<xref ref-type="bibr" rid="c33">33</xref>–<xref ref-type="bibr" rid="c35">35</xref>). These models posit that episodic memories are strictly dependent on consciousness, i.e., one needs to have a conscious experience to relive an episode from one’s life. An alternative model suggests that a separation between memory systems based on processing modes is more plausible and is better supported by memory data (<xref ref-type="bibr" rid="c39">39</xref>). According to this newer model, consciousness modulates memories within each memory system in a quantitative way (i.e., memory strength) but does not qualitatively define memory systems. The current findings provide evidence in favor of this processing-based memory model (<xref ref-type="bibr" rid="c39">39</xref>) because initially consciously accessible episodic memories can lose conscious accessibility and may regain it when given sufficient retrieval cues. Even those memories that never re-emerge to conscious access remain implemented in the episodic memory network including the hippocampus. These unconscious memories are also subject to active consolidation processes and continue to influence the choice behavior implicitly. A future line of research might examine how long consciously inaccessible memories remain implemented in the brain and whether they can be reinforced brain stimulation to bring them back to conscious access.</p>
</sec>
</sec>
<sec id="s4">
<title>Material and methods</title>
<sec id="s4a">
    <title>Experimental design</title>
<sec id="s4a1">
<title>Human Participants</title>
<p>Forty healthy, right-handed participants were randomly assigned to two groups. Both groups underwent the same procedures but underwent distinct functional MRI sequences. Twenty participants were examined with a functional MRI sequence with limited FOV covering the medial temporal lobe and adjacent structures (age: 24.30 ± 3.87 (mean ± SD); 10 women). The remaining 20 participants were examined with a whole-brain fMRI sequence (age: 23.8 ± 3.41 (mean ± SD); 11 women). Participants were recruited through advertisements on university- and social-media-platforms. All participants underwent a telephone screening. They reported normal or corrected-to-normal vision, no previous or current neurological or psychiatric diseases, no claustrophobia, and no non-removable metals in or on the body. All participants provided written informed consent for the experiment. Note that the participants’ consent was semi-informed. Participants were left unaware of the 24-hour category retrieval of the face-object combinations learned on the first day. We did not inform them of a 24-hour category retrieval to prevent their active rehearsing of the learning material. Instead, we informed participants that they are reinvited to the second MRI session for them to learn and retrieve another set of face-object combinations. Participants were fully debriefed at the end of the study. Participants were compensated with a reimbursement of 150 Swiss Francs and digital copies of the anatomical scans of their own brains. The study was approved by the ethics committee of the Canton of Berne (ID: 50008).</p>
</sec>
<sec id="s4a2">
<title>Stimuli</title>
<p>The stimulus set selected for this experiment consisted of 96 combinations of faces and objects. Face stimuli were selected from the Flickr-Faces-HQ Dataset (FFHQ, <ext-link ext-link-type="uri" xlink:href="https://github.com/NVlabs/ffhq-dataset">https://github.com/NVlabs/ffhq-dataset</ext-link>). Selection was restricted to Caucasian faces to reduce bias. Faces were neither standardized nor clipped, and paraphernalia (e.g., a hat or glasses) and the background (e.g., a forest or an office scene) were not removed from the pictures to preserve the stimuli’s naturalistic appearance and to allow for better discriminability of faces. We selected images of everyday objects on white backgrounds from two categories: organic (e.g. an apple, a bird) and inorganic (e.g. a hammer, a couch). The set of 96 faces consisted of 48 male and 48 female faces. Half of the male faces were paired with an organic object and the other half with an inorganic object. The same pairing scheme was applied to the female faces.</p>
<sec id="s4a2a">
<title>Stimulus groups</title>
<p>Groups of four stimuli were created because of the constraints of the recognition: During recognition, participants were presented with a face plus two object stimuli (the target object and a foil object). Their task was to recognize the object that was paired with the face during learning. All foil objects had been presented with different face stimuli during learning and were thus familiar. Recognition required participants to remember which familiar object had been presented with the current face during learning (associative recognition). For stimulus preparation, we created groups of two face and two object stimuli. The two face stimuli of a certain group would be presented with the same two objects from their group during the recognition task, one object being the target and the other the foil for the initially presented face and vice versa for the subsequently presented face. To exclude object bias in the groups, we collected data in a pilot study using an online survey. In this survey, 63 students decided which of two objects would fit better to either one of the two face stimuli using a rating scale from 0-100. Based on this survey, we included those groups in the main experiment with the least amount of object bias, i.e., groups that yielded a mean rating score close to 50. Table S19 shows the mean scores for each of the 48 groups used in the main experiment. The 48 groups provided 96 face-object pairs.</p>
</sec>
<sec id="s4a2b">
<title>Randomization</title>
<p>Target and foil objects were randomly assigned to face stimuli within each group. The presentation order and the interval between the two face-object combinations belonging to a group were semi-randomized such that the time interval is maximal between the two combinations that belong to one group. A maximal temporal distance between the two face-object combinations belonging to one group was important for participants’ accuracy on the recognition task because on the recognition task the same two objects from each group were presented with each of the two faces from the group. Maximizing the distance between subsequent presentations increased the likelihood that participants would make their decision of which object was paired with a given face during learning solely based on memory and not based on their previous choice of an object. The order, in which the 96 face-object pairs were presented during learning, was randomized with a windowed shuffle for the 30-minute and the 24-hour category retrieval and for the recognition. The windowed shuffle shuffled 4 list entries before moving the window to the next 4 entries. This ensured that the study-test retention interval was comparable for the 96 memories. Moreover, the shuffling also preserved the distance between the two face-objects pairs from the same group.</p>
</sec>
</sec>
<sec id="s4a3">
<title>Experimental tasks</title>
<p>For all tasks, presentations of stimuli were separated by a jittered interstimulus-interval (ISI) of 500 – 2500 ms. A black fixation cross on a white background was presented during the ISI in the center of the screen. Participants were asked to focus on the fixation cross.</p>
<sec id="s4a3a">
<title>Associative learning task</title>
<p>First, the face stimulus was presented in the center of the screen for 1000 ms. Participants were instructed to look closely at the face and memorize it. Thereafter, the same face was presented again, this time for 2500 ms paired with an object that was drawn from one of two categories: organic or inorganic. Participants were asked to form an association between the presented face and the object. No instructions were given on how to form an association. Following associative learning, the face was presented in the center of the screen for 2750 ms for participants to indicate by button press whether the object the face had just been paired with was organic or inorganic. This immediate category retrieval served to identify trials with successful learning. Only these trials entered the analysis of the fate of engrams underlying subsequently forgotten memories.</p>
</sec>
<sec id="s4a3b">
<title>Consolidation Task</title>
<p>A 5-minute pause was given following the immediate retrieval to allow for memory consolidation. During this pause we kept participants busy with a simple attention task (odd-even task) to avoid active rehearsal. We presented numbers between 0 and 100 on the screen for participants to indicate whether a number was odd or even. Corrective feedback was provided by a color cue: the number changed to green for correct and to red for incorrect odd-even responses.</p>
</sec>
<sec id="s4a3c">
<title>Category Retrieval Task</title>
<p>Each of the 96 face stimuli was presented in the center of the white screen as a retrieval cue for 1000 ms. Then, the face appeared on the screen again, this time for 2750 ms combined with the written instruction to indicate by button press whether the associated object was organic or inorganic. The index finger was assigned to the response button for inorganic, and the middle finger was assigned to the response button for organic. Each retrieval trial was followed by a confidence rating regarding the just provided retrieval response. Participants were given 2500 ms to provide their confidence response using a 3-point scale (sure, unsure, guess). The unsure option was the conceptually largest category including all responses that were neither completely sure nor pure guesses. We evaluated only the extremes, i.e., the sure and the guess responses because we were interested in contrasting consciously remembered associations (sure responses) with forgotten associations (guess responses). The cued associative 2-alternative forced-choice category retrieval is referred to as category retrieval throughout the manuscript.</p>
</sec>
<sec id="s4a3d">
<title>Recognition Task</title>
<p>Each face was presented with the two objects from its group. The presentation duration was 3500 ms. One of the two objects was the target that had been presented along with the face during learning, and the other was a familiar foil object that was presented with another face during learning. Participants were required to indicate which of the two objects had been presented with the face during learning. The two objects were presented twice (though paired with two distinct faces) during the recognition. Each object was once the target and once the foil. Following each recognition trial, participants gave their confidence assessment on a 3-point scale (sure, unsure, guess). The cued associative 2-alternative forced-choice recognition task is referred to as recognition task throughout the manuscript.</p>
</sec>
<sec id="s4a3e">
<title>Confidence rating</title>
<p>After each retrieval (except the immediate category retrieval) and the recognition task, participants were asked to rate their level of confidence using a 3-point scale. Participants were instructed to rate a retrieval response as “sure” if they could vividly remember the face-object combination. Participants were instructed to rate a retrieval response as “guess” if they had forgotten the face-object combination, forgetting meaning no sense of familiarity, no intuition, no “gut feeling” regarding the face-object combination. Participants were instructed to rate a retrieval as “unsure” if their retrieval experience fell anywhere between “sure” and “guess”. We implemented this broad “unsure” category to sort out all responses with varying grades of conscious access to analyze clearly consciously accessible memories with totally forgotten memories. This procedure ensured that any above-chance performance in the ‘guess’ category was due to unconscious processes alone. We included aggregated type-2 d’ scores in Table S16, which shows that participants used the metacognitive confidence scale as instructed. Type-2 d’ were calculated as described by Fleming and Lau (<xref ref-type="bibr" rid="c70">70</xref>).</p>
</sec>
</sec>
<sec id="s4a4">
<title>Technical Setup</title>
<p>The paradigm was presented with a Hyperion projector from Psychology Software Tools (Sharpsburg, USA) with a resolution of 1920 x 1080p Full HD, a refresh rate of 60 Hz, and dimensions of the projected image being set at 30 cm x 54 cm and a screen diagonal of 62cm. The distance between the participants’ eyes and the projection screen was 1.5 m. The experiment was performed using Presentation® software (Version 23.0, Neurobehavioral Systems, Inc., Berkeley, CA) on a Windows computer. Responses were recorded in the MRI scanner with a hand sleeve with a wrist strap and a Response unit for response registration in the MRI scanner named “Celeritas Fiber Optic Response Unit - Right hand, 5 buttons” from Psychology Software Tools (Sharpsburg, USA). Participants used their index, middle, and ring finger of their right hand to submit responses during the task.</p>
</sec>
<sec id="s4a5">
<title>Experimental Procedure</title>
<p>The study was conducted on two consecutive days. All participants underwent the same protocol. Whenever participants were required to perform a behavioral task in the scanner, BOLD signal was recorded. The study consisted of 4 behavioral tasks, and 4 BOLD fMRI runs. Between runs, fMRI data acquisition was paused. The first three runs were performed consecutively on the first day and the fourth run was performed on the following day. Between the two MRI sessions there was a 24-hour interval, during which participants were free to follow their usual routines. The experiment would usually start between midday and afternoon. The first MRI session lasted about 1 hour, and the second MRI session lasted about 45 minutes.</p>
<sec id="s4a5a">
<title>Day 1</title>
<p>On the first day, participants completed an online training at home to establish familiarity with the behavioral tasks. After arriving at and entering the MRI scanner, a t1-weighted anatomical image was recorded. During the anatomical scan participants rehearsed the behavioral tasks and the button press responses. Then, participants completed the associative learning of 96 face-object pairs, carried out the immediate category retrieval and then took the odd-even task during the 5-minute pause. Finally, they performed the 30-minute category retrieval, which marked the end of the first day of experimentation. To prevent active rehearsal of the learned material, participants were misinformed that they would learn another set of face-object pairs on the next day. Participants were asked not to perform cognitively demanding tasks between the two MRI sessions. At the end of the first experimentation day, participants received an e-mail which included a reminder for the second experimentation day as well as a link to a survey to assess sleep duration and sleep quality (Stanford Sleepiness Scale (SSS) and Stanford Sleepiness Test (SST)). Participants were asked to fill out the survey the next morning.</p>
</sec>
<sec id="s4a5b">
<title>Day 2</title>
<p>When participants arrived at the MR center, they received a debriefing in written form, where we explained that they would not learn a new set of face-object combinations but retrieve the face-object pairs learned on the previous day. When asked about their expectations for the second day, 32.5% of participants reported that they had expected a repeated retrieval of the face-object pairs learned on the previous day. But none of participants reported to have actively rehearsed the face-object pairs. Participants entered the scanner again on the second day and we recorded a whole-brain anatomical t1-weighted scan. Next, participants performed the category retrieval and then the recognition task for the face-object associations that they had learned on the previous day. Each category retrieval trial was immediately followed by its corresponding recognition trial.</p>
</sec>
</sec>
<sec id="s4a6">
<title>MRI data acquisition</title>
<p>Both anatomical and functional MRI sequences were recorded on a 7T Siemens Magnetom Terra whole body MRI scanner (Siemens Medical Solutions, Erlangen, Deutschland) with a 32-channel head coil. The anatomical t1-weighted image acquisition followed a magnetization-prepared two rapid gradient echo (MP2RAGE) sequence with a time of repetition (TR) of 6000 ms; echo time (TE) 2.06 ms; flip angle (FA) = 0°; field of view (FOV) = 384 x 384 mm<sup>2</sup>, spatial resolution of 0.63 x 0.63 x 0.63 mm<sup>3</sup>, 256 sagittal slices, matrix points = 610. For the t2*-weighted functional MRI scans, we used two distinct sequences. The small field-of-view (FOV) fMRI sequence covered the bilateral medial temporal lobe with 0.8 mm isotropic voxel size to target hippocampal engram components, and the other fMRI sequence covered the entire brain with a 1.1 mm isotropic voxel size to target neocortical engram components.</p>
<sec id="s4a6a">
<title>Small FOV fMRI sequence</title>
<p>Isotropic functional T2* weighted blood oxygen level dependent (BOLD) sensitive multiple interleaved slice acquisition sequence with a TR = 2120 ms; TE = 24 ms; FA = 70°; FOV = 210 x 210 mm<sup>2</sup>, spatial resolution of 0.8 x 0.8 x 0.8 mm<sup>3</sup>, 28 transversal slices, matrix points = 263. We acquired a total of 2100 volumes per participant. Day 1: associative learning, 5-minute pause with odd-even task, and associative category retrieval: 510, 150, 515; day 2: associative category retrieval and associative recognition: 925.</p>
</sec>
<sec id="s4a6b">
<title>Whole-brain fMRI sequence</title>
<p>Isotropic functional T2* weighted blood oxygen level dependent (BOLD) sensitive multiple interleaved slice acquisition sequence with a TR = 2700 ms; TE = 50 ms; FA = 90°; FOV = 210 x 210 mm<sup>2</sup>, spatial resolution of 1.1 x 1.1 x 1.1 mm<sup>3</sup>, 96 transversal slices; matrix points = 191. A total of 1650 volumes were collected per participant. Day 1: associative learning, 5-minute pause with odd-even task, and associative category retrieval: 400, 119, 405, day 2: associative category retrieval and associative recognition: 726.</p>
</sec>
</sec>
</sec>
<sec id="s4b">
<title>Quantification and statistical analysis</title>
<sec id="s4b1">
<title>Sample size justification</title>
<p>Studies using 3T MRI scanners usually achieve a sample size of around N = 40 (<xref ref-type="bibr" rid="c71">71</xref>–<xref ref-type="bibr" rid="c74">74</xref>). Like other studies employing ultra-high field fMRI (<xref ref-type="bibr" rid="c75">75</xref>–<xref ref-type="bibr" rid="c77">77</xref>), we implemented a sample size of 20 participants per fMRI sequence, leveraging the superior signal-to-noise ratio of 7T MRI scanners compared to 3T MRI scanners (<xref ref-type="bibr" rid="c21">21</xref>).. This enabled us to employ the same behavioral paradigm in two distinct participant groups with two distinct fMRI sequences – a high-resolution hippocampal fMRI sequence and a lower resolution whole-brain fMRI sequence.</p>
</sec>
<sec id="s4b2">
<title>Statistical analysis of behavioral data</title>
<p>Behavioral data were preprocessed and analyzed with custom R scripts using RStudio and the tidyverse package on a MacBook Pro. Face-object pairs were removed from the analysis if participants answered incorrectly during immediate category retrieval, answered incorrectly but with high confidence (sure response) or if they pressed the wrong button. The significance threshold was set to p &lt; 0.05, if not indicated otherwise. The Bayes factor was calculated using the “BayesFactor” R-library which makes use of the function described by Rouder (<xref ref-type="bibr" rid="c78">78</xref>) and colleagues, with default prior distributions for all parameters.</p>
</sec>
<sec id="s4b3">
<title>Preprocessing of fMRI data</title>
    <p>Whole-brain fMRI sequence: Results included in this manuscript for the whole-brain fMRI sequence come from preprocessing performed using fMRIPrep 20.2.3 (<xref ref-type="bibr" rid="c79">79</xref>) (<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_016216">RRID:SCR_016216</ext-link>), which is based on Nipype 1.6.1 (<xref ref-type="bibr" rid="c80">80</xref>, <xref ref-type="bibr" rid="c81">81</xref>) (<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_002502">RRID:SCR_002502</ext-link>).</p>
</sec>
<sec id="s4b4">
<title>Anatomical data preprocessing</title>
    <p>A total of 2 T1-weighted (T1w) images were acquired per participant within the input BIDS dataset. All of them were corrected for intensity non-uniformity (INU) with N4Bias FieldCorrection (<xref ref-type="bibr" rid="c82">82</xref>), distributed with ANTs 2.3.3 (<xref ref-type="bibr" rid="c83">83</xref>), (<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_004757">RRID:SCR_004757</ext-link>). The T1w-reference was then skull-stripped with a Nipype implementation of the antsBrainExtraction.sh workflow (from ANTs), using OASIS30ANTs as target template. Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and gray-matter (GM) was performed on the brain-extracted T1w using fast (<xref ref-type="bibr" rid="c84">84</xref>) (FSL 5.0.9, <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_002823">RRID:SCR_002823</ext-link>). A T1w-reference map was computed after registration of 2 T1w images (after INU-correction) using mri_robust _template (<xref ref-type="bibr" rid="c85">85</xref>) (FreeSurfer 6.0.1). Brain surfaces were reconstructed using recon-all(<xref ref-type="bibr" rid="c86">86</xref>) (FreeSurfer 6.0.1, <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_001847">RRID:SCR_001847</ext-link>), and the brain mask estimated previously was refined with a custom variation of the method to reconcile ANTs-derived and FreeSurfer-derived segmentations of the cortical gray-matter of Mindboggle (<xref ref-type="bibr" rid="c87">87</xref>) (<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_002438">RRID:SCR_002438</ext-link>). Volume-based spatial normalization to two standard spaces (MNI152NLin2009cAsym, MNI152NLin6Asym) was performed through nonlinear registration with antsRegistration (ANTs 2.3.3), using brain-extracted versions of both T1w reference and the T1w template. The following templates were selected for spatial normalization: ICBM 152 Nonlinear Asymmetrical template version 2009c (<xref ref-type="bibr" rid="c88">88</xref>) [<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_008796">RRID:SCR_008796</ext-link>; TemplateFlow ID: MNI152NLin2009cAsym], FSL’s MNI ICBM 152 non-linear 6<sup>th</sup> Generation Asymmetric Average Brain Stereotaxic Registration Model (<xref ref-type="bibr" rid="c89">89</xref>) [<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_002823">RRID:SCR_002823</ext-link>; TemplateFlow ID: MNI152NLin6Asym].</p>
</sec>
<sec id="s4b5">
<title>Functional data preprocessing (whole-brain fMRI sequence)</title>
    <p>For each of the 4 BOLD runs acquired per participant (across all tasks and sessions), the following preprocessing was performed. First, a reference volume and its skull-stripped version were generated using a custom methodology of fMRIPrep. Susceptibility distortion correction (SDC) was omitted. The BOLD reference was then co-registered to the T1w reference using bbregister (FreeSurfer) which implements boundary-based registration.(<xref ref-type="bibr" rid="c90">90</xref>) Co-registration was configured with six degrees of freedom. Head-motion parameters with respect to the BOLD reference (transformation matrices, and six corresponding rotation and translation parameters) are estimated before any spatiotemporal filtering using mcflirt (<xref ref-type="bibr" rid="c91">91</xref>) (FSL 5.0.9). BOLD runs were slice-time corrected using 3dTshift from AFNI 20160207(<xref ref-type="bibr" rid="c92">92</xref>) (<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_005927">RRID:SCR_005927</ext-link>). The BOLD time-series were resampled onto the following surfaces (FreeSurfer reconstruction nomenclature): fsnative, fsaverage5. The BOLD time-series (including slice-timing correction when applied) were resampled onto their original, native space by applying the transforms to correct for headmotion. These resampled BOLD time-series will be referred to as preprocessed BOLD in original space, or just preprocessed BOLD. The BOLD time-series were resampled into standard space, generating a preprocessed BOLD run in MNI152NLin2009cAsym space. First, a reference volume and its skull-stripped version were generated using a custom methodology of fMRIPrep. Automatic removal of motion artifacts using independent component analysis (ICA-AROMA (<xref ref-type="bibr" rid="c93">93</xref>)) was performed on the preprocessed BOLD on MNI space after removal of non-steady state volumes and spatial smoothing with an isotropic Gaussian kernel of 6 mm FWHM (full-width half-maximum). Corresponding “non-aggresively” denoised runs were produced after such smoothing. Additionally, the “aggressive” noise-regressors were collected and placed in the corresponding confounds file. Several confounding time-series were calculated based on the preprocessed BOLD: framewise displacement (FD), DVARS and three region-wise global signals. FD was computed using two formulations following Power (<xref ref-type="bibr" rid="c94">94</xref>) (absolute sum of relative motions) and Jenkinson (<xref ref-type="bibr" rid="c91">91</xref>) (relative root mean square displacement between affines). FD and DVARS are calculated for each functional run, both using their implementations in Nipype (following the definitions by Power (<xref ref-type="bibr" rid="c94">94</xref>) and colleagues). The three global signals are extracted within the CSF, the WM, and the whole-brain masks. Additionally, a set of physiological regressors were extracted to allow for component-based noise correction (CompCor (<xref ref-type="bibr" rid="c95">95</xref>)). Principal components are estimated after high-pass filtering the preprocessed BOLD time-series (using a discrete cosine filter with 128s cut-off) for the two CompCor variants: temporal (tCompCor) and anatomical (aCompCor). tCompCor components are then calculated from the top 2% variable voxels within the brain mask. For aCompCor, three probabilistic masks (CSF, WM and combined CSF+WM) are generated in anatomical space. The implementation differs from that of Behzadi and colleagues in that insteadof eroding the masks by 2 pixels on BOLD space, the aCompCor masks are subtracted a mask of pixels that likely contain a volume fraction of GM. This mask is obtained by dilating a GM mask extracted from the FreeSurfer’s aseg segmentation, and it ensures components are not extracted from voxels containing a minimal fraction of GM. Finally, these masks are resampled into BOLD space and binarized by thresholding at 0.99 (as in the original implementation). Components are also calculated separately within the WM and CSF masks.</p>
<p>For each CompCor decomposition, the k components with the largest singular values are retained, such that the retained components’ time series are sufficient to explain 50 percent of variance across the nuisance mask (CSF, WM, combined, or temporal). The remaining components are dropped from consideration. The head-motion estimates calculated in the correction step were also placed within the corresponding confounds file. The confound time series derived from head motion estimates and global signals were expanded with the inclusion of temporal derivatives and quadratic terms for each (<xref ref-type="bibr" rid="c96">96</xref>). Frames that exceeded a threshold of 0.5 mm FD or 1.5 standardised DVARS were annotated as motion outliers. All resamplings can be performed with a single interpolation step by composing all the pertinent transformations (i.e. head-motion transform matrices, susceptibility distortion correction when available, and co-registrations to anatomical and output spaces). Gridded (volumetric) resamplings were performed using antsApplyTransforms (ANTs), configured with Lanczos interpolation to minimize the smoothing effects of other kernels (<xref ref-type="bibr" rid="c97">97</xref>). Non-gridded (surface) resamplings were performed using mri_vol2surf (FreeSurfer).</p>
<p>Many internal operations of fMRIPrep use Nilearn 0.8.189(<xref ref-type="bibr" rid="c98">98</xref>) (<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_001362">RRID:SCR_001362</ext-link>), mostly within the functional processing workflow. For more details of the pipeline, see the section corresponding to workflows in fMRIPrep’s documentation.</p>
<sec id="s4b5a">
<title>Copyright waiver</title>
<p>The above boilerplate text was automatically generated by fMRIPrep with the express intention that users should copy and paste this text into their manuscripts unchanged. It is released under the CC0 license.</p>
</sec>
</sec>
<sec id="s4b6">
<title>Functional data preprocessing (small FOV sequence)</title>
<p>Due to the small FOV of the sequence the use of fMRIprep was not recommended. Preprocessing was done with SPM12 (Welcome Department of Cognitive Neurology, London, UK). The functional volumes were slice-time corrected and realigned to the mean functional volume image. Coregistration to the participants anatomical volume was carried out with a non-skull-stripped structural volume. The latter allowed for a more reliable coregistration because the skull provided for more anatomical information to properly match the small FOV with the anatomical template. Volumes were segmented and spatially normalized to the MNI/ICBM AVG152 Template provided by SPM. Functional volumes were smoothed with a 6 mm (FWHM) isotropic Gaussian Kernel.</p>
</sec>
<sec id="s4b7">
<title>Freesurfer segmentations</title>
<p>We created subject-specific ROIs for both the functional connectivity analyses as well as the RSA analyses with freesurfer. FMRIprep already applies <italic>recon_all</italic> during its workflow which computes ROIs for the neocortex. Hippocampal ROIs were created with freesurfers <italic>segmentHA_T1</italic> function. The creation of neocortical masks failed for 3 participants from the whole-brain fMRI group. They were thus excluded from the representational similarity analysis which used the masks for region of interest analyses.</p>
</sec>
<sec id="s4b8">
<title>GLM</title>
<p>In the following, both fMRI sequences (small FOV and whole-brain sequence) were always treated identically unless stated otherwise.</p>
<sec id="s4b8a">
<title>First Level</title>
<p>First-level analysis was performed using a general linear model (GLM) that modeled the BOLD-time-series using the sequence of event onsets convolved with the default hemodynamic response function (HRF) provided by SPM12. Events were modeled at a duration of zero. For each participant, 4 timeseries were estimated in the same first-level model. All stimulus presentations were modeled as events, the confidence ratings were modeled as events, and the button presses given during the category retrieval and during recognition were modeled as events. These events were categorized into 5 conditions depending on the responses given during the category retrieval: responses to every trial could be categorized as correct sure responses, incorrect unsure responses, correct unsure responses, incorrect guess responses or correct guess responses. For example, the 30-minute category retrieval responses were used for the categorization of corresponding trials during the encoding time-series, to investigate subsequent memory effects: the presentation of the face stimulus during encoding was modeled as an event and categorized based on the response during the retrieval of said face. Sure but incorrect answers were not estimated because their rate was too low for a robust estimate. Six movement regressors (x, y, z, pitch, yaw, roll) were added to the model for every session as well as a session constant which resulted in 129 estimated beta maps for every participant. Implicit masking with the default SPM threshold of 0.8 resulted in the exclusion of signal from the center of the brain, mainly in the whole-brain fMRI sequence. In both sequences, we used a binary brain mask, generated by SPMs segmentation algorithm, as an explicit mask and set SPM’s masking threshold to [−inf], to include all voxels within the mask in the first level estimation. Note that all events were used for first level specification, including trials that were excluded during the behavioral analysis (e.g. false memories, see above), to allow for a better baseline estimation of the general linear model.</p>
</sec>
<sec id="s4b8b">
<title>Second Level</title>
<p>Second-level, random-effects analyses for group statistics were computed using a full factorial model with two factors. The first factor modeled 5 events of interest: the first presentation of the face stimulus during the learning task, the associative learning event, the presentation of the face stimulus during the 30-minute as well as the 24-hour category retrieval, and the recognition. The second factor modeled the retrieval quality for 3 different levels, correct sure responses, correct guessing responses, and incorrect guessing responses. This resulted in a 5 x 3 second-level full factorial design. The height threshold for the calculation of the t-contrasts was set to p &lt; 0.001, uncorrected for multiple comparisons, with a cluster extent threshold of k = 10 voxels, if not indicated otherwise. Note that for the purpose of preserving transparency about sub-threshold results (<xref ref-type="bibr" rid="c99">99</xref>), some figures are presented at a height threshold of p = 0.005.</p>
</sec>
</sec>
<sec id="s4b9">
<title>Brain-behavior correlations</title>
<p>To isolate brain activity that was associated with task accuracy we used a multiple regression design within SPM. For all the models calculated we included the estimation of an intercept. The generated SPM contrast images were combined with a between-subjects behavioral covariate in a multiple-regression model. The behavioral covariate used for contrasts of guess responses was the z-scored percentage correct of all guess responses (guessing accuracy), for contrasts of sure responses the z-scored absolute number of correct sure responses (sure accuracy), because of a ceiling effect for sure responses, i.e. very few incorrect sure responses. For all second-level models we calculated both positive and negative brain-behavior correlations. The significance level set to p&lt;0.001, uncorrected, with a cluster extent threshold of k = 10 voxels, if not indicated otherwise.</p>
</sec>
<sec id="s4b10">
<title>Stacked contrasts</title>
<p>To uncover both differences between retrieval quality (sure &gt; guess) as well as retrieval timepoints (24-hour &gt; 30-minute category retrieval), we calculated stacked contrasts by contrasting 4 parameter estimates of the corresponding retrieval timepoints and qualities within SPM12s result interface. The significance threshold was set to p &lt; 0.001, uncorrected, with a cluster extent threshold of k = 10 voxels, if not indicated otherwise.</p>
</sec>
<sec id="s4b11">
<title>Conjunction analyses</title>
<p>To uncover commonalities of brain-behavior correlations for consciously accessible and for forgotten memories, we calculated conjunction analyses. We used the above generated second level multiple regression models and extracted a binary mask of all the voxels that were significant under the threshold of p&lt;0.001 and an extent of k =10 voxels. Then we took these maps as inclusive masks in another second level model of interest and set the threshold again to p&lt;0.001 with a cluster extent of k = 10. The significant clusters in the resulting t-maps only revealed the overlay of all the voxels that would be significant in both models independently of each other. To uncover commonalities of contrast analyses, we used the contrast maps produced by the second level full factorial model to calculate commonalities between activation patterns using SPM12. The significance threshold was set to p &lt; 0.001, uncorrected, with a cluster extent threshold of k = 10 voxels, if not indicated otherwise.</p>
</sec>
<sec id="s4b12">
<title>Functional connectivity analyses</title>
<p>To uncover task-related connectivity changes between the hippocampus and the neocortex we calculated general psycho-physiological interactions (gPPI) analyses. We used the conn toolbox (version 22a). Unlike the standard PPI analyses provided by SPM12, the conn toolbox (using a gPPI approach) can model effects of more than two conditions, to allow for interactions between conditions, and to make no assumptions how these conditions are related to the baseline condition. First level specifications were imported from SPM to the conn toolbox. Behavioral measures (sure and guessing accuracy) served as second-level covariates. We defined seed regions within the subdivided left and right hippocampus. More precisely, we used grey matter masks of the hippocampus head, body and tail generated by freesurfer. These seed regions were integrated as participant-specific ROIs. Conn’s integrated setup and denoising pipeline was applied to the data with a bandpass filter between 0.008 – 0.09 and linear detrending but no despiking. We also included the second-level covariates to be able to correlate task related changes in connectivity with behavioral parameters like the accuracy of the guess responses given at the 30-minute and 24-hour category retrieval. We included this in a seed-to-voxel analysis with an underlying multivariate regression model. For conjunctions of multivariate regression functional connectivity analyses, we made use of the shared architecture of the two toolboxes, conn and SPM12. We used the contrast files created by the multivariate regression functional connectivity analyses to calculate commonalities between them using SPM12.</p>
</sec>
<sec id="s4b13">
<title>Representational similarity analysis</title>
<p>Methodology was modeled after the protocol described by Hebscher and colleagues (<xref ref-type="bibr" rid="c63">63</xref>). One notable difference was how single-trial beta estimates were created. While Hebscher and colleagues used a least-squares-single (LSS, individual GLMs for each trial), we used a least-squares-all (LSA, one GLM with one condition per trial). We examined reinstatement of memory-specific patterns of neural activity by conducting a series of RSAs on patterns of estimated neural activity within ROIs. RSAs measured encoding-retrieval (or encoding-recognition) similarity by computing the Pearson correlation between patterns for all pairs of trials for each ROI. Pairwise correlation values were Fisher transformed. We then subtracted the mean of all correlations calculated for non-matching trial-pairs from the mean correlation of matching trial-pairs. Matching trials refers to trials containing a presentation of the same face during encoding and retrieval. This metric was z-scored against a null distribution of correlation difference scores, calculated by randomly shuffling trials over 1000 permutations. Group-level statistics were performed on these z-scored pattern similarity scores. Finally, to correct for similarity based on face re-presentation and based on the mere task characteristics or encoding/retrieval effort, we subtracted the similarity values of encoding-retrieval pairs that yielded incorrect guess responses from the similarity values of encoding-retrieval pairs that yielded correct sure responses and correct guess responses. This way, we came up with similarity scores that reflected encoding-retrieval or retrieval-retrieval voxel pattern reinstatements. Pair-wise representational similarity analysis (RSA) was conducted with custom python scripts making use of the software package Nilearn (<xref ref-type="bibr" rid="c100">100</xref>). Correlation values were calculated with the <italic>pairwise_distances</italic> function of the software package scikit-learn (<xref ref-type="bibr" rid="c101">101</xref>). To assess the significance of voxel pattern reinstatement, we computed one-sample two-tailed t-tests on the z-scored pattern similarity values for each ROI. Similarity estimates were also correlated across subjects with retrieval accuracy. Results below a threshold of p &lt; 0.05 were considered significant. In addition, we computed the Bayes Factor for all t-tests and across-subjects Pearson correlation using the “pingouin” python package, which computes Wetzels (<xref ref-type="bibr" rid="c102">102</xref>) Bayes factor. We used default prior distributions for all parameters.</p>
</sec>
</sec>
</sec>

</body>
<back>
<sec id="s6" sec-type="data-availability">
<title>Data availability</title>
<p>The magnetic resonance imaging data have been deposited at “OpenNeuro” and are publicly available.</p>
<list list-type="bullet">
<list-item><p>Small FOV fMRI group: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.18112/openneuro.ds006265.v1.0.1">https://doi.org/10.18112/openneuro.ds006265.v1.0.1</ext-link></p></list-item>
<list-item><p>Whole-brain fMRI group: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.18112/openneuro.ds006266.v1.0.1">https://doi.org/10.18112/openneuro.ds006266.v1.0.1</ext-link></p></list-item>
</list>
<p>Custom MATLAB, R, and python analysis scripts as well as the behavioral data are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/TomW92/TOAM-fMRI">https://github.com/TomW92/TOAM-fMRI</ext-link>.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>This work was supported by Sitem-Insel Support Funds SISF 2019 to K. Henke and by the SNFS Advanced Grant TMAG-1_209374 to K. Henke. The authors thank Mirco Bristle Brogli for his support during data analysis. Calculations were performed on UBELIX (<ext-link ext-link-type="uri" xlink:href="https://www.id.unibe.ch/hpc">https://www.id.unibe.ch/hpc</ext-link>), the HPC cluster at the University of Bern.</p>
</ack>
<sec id="additional-info" sec-type="additional-information">
<title>Additional information</title>
<sec id="s5">
<title>Author Contributions</title>
<p>Conceptualization: T.W., K.H.; Methodology: T.W., A.F., K.H.; Analysis: T.W., K.Z., F.R., A.F.; Writing - original draft: T.W.; Writing - review &amp; editing: T.W., K.Z., K.H.; Visualization: T.W.; Supervision: K.H.; Project administration: K.H.; Funding acquisition: K.H.</p>
</sec>
<sec id="s8">
<title>Declaration of generative AI and AI-assisted technologies</title>
<p>During the preparation of this work, the author(s) used AI-assisted technologies for the reformatting of tables, to create pictograms for <xref rid="fig1" ref-type="fig">Figure 1</xref>, and to generate abbreviations from lists of brain regions and for checking grammar. Thereafter, the author(s) reviewed and edited the content and take(s) full responsibility for the content of the publication.</p>
</sec>
</sec>
<sec id="additional-files" sec-type="supplementary-material">
<title>Additional files</title>
<supplementary-material id="supp1">
<label>Supplementary Figures and Tables</label>
<media xlink:href="supplements/656652_file03.pdf"/>
</supplementary-material>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. C.</given-names> <surname>Zakrzewski</surname></string-name>, <string-name><given-names>E. C.</given-names> <surname>Sanders</surname></string-name>, <string-name><given-names>J. M.</given-names> <surname>Berry</surname></string-name></person-group>, <article-title>Evidence for Age-Equivalent and Task-Dissociative Metacognition in the Memory Domain</article-title>. <source>Front. Psychol.</source> <volume>12</volume>, <fpage>630143</fpage> (<year>2021</year>).</mixed-citation></ref>
    <ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>McGillivray</surname></string-name>, <string-name><given-names>A. D.</given-names> <surname>Castel</surname></string-name></person-group>, <article-title>Older and younger adults’ strategic control of metacognitive monitoring: the role of consequences, task experience, and prior knowledge</article-title>. <source>Exp. Aging Res.</source> <volume>43</volume>, <fpage>233</fpage>–<lpage>256</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. A.</given-names> <surname>Josselyn</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Köhler</surname></string-name>, <string-name><given-names>P. W.</given-names> <surname>Frankland</surname></string-name></person-group>, <article-title>Finding the engram</article-title>. <source>Nat. Rev. Neurosci.</source> <volume>16</volume>, <fpage>521</fpage>–<lpage>534</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. A.</given-names> <surname>Josselyn</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Tonegawa</surname></string-name></person-group>, <article-title>Memory engrams: Recalling the past and imagining the future</article-title>. <source>Science</source> <volume>367</volume>, <fpage>eaaw4325</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. L.</given-names> <surname>Davis</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Zhong</surname></string-name></person-group>, <article-title>The Biology of Forgetting—A Perspective</article-title>. <source>Neuron</source> <volume>95</volume>, <fpage>490</fpage>–<lpage>503</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. L.</given-names> <surname>De Snoo</surname></string-name>, <string-name><given-names>P. W.</given-names> <surname>Frankland</surname></string-name></person-group>, <article-title>Neurobiological mechanisms of forgetting across timescales</article-title>. <source>Curr. Opin. Neurobiol.</source> <volume>90</volume>, <fpage>102972</fpage> (<year>2025</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Guskjolen</surname></string-name>, <string-name><given-names>J. W.</given-names> <surname>Kenney</surname></string-name>, <string-name><given-names>J.</given-names> <surname>de la Parra</surname></string-name>, <string-name><given-names>B. ru A.</given-names> <surname>Yeung</surname></string-name>, <string-name><given-names>S. A.</given-names> <surname>Josselyn</surname></string-name>, <string-name><given-names>P. W.</given-names> <surname>Frankland</surname></string-name></person-group>, <article-title>Recovery of “Lost” Infant Memories in Mice</article-title>. <source>Curr. Biol.</source> <volume>28</volume>, <fpage>2283</fpage>–<lpage>2290.e3</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T. S.</given-names> <surname>Yates</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Fel</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Choi</surname></string-name>, <string-name><given-names>J. E.</given-names> <surname>Trach</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Behm</surname></string-name>, <string-name><given-names>C. T.</given-names> <surname>Ellis</surname></string-name>, <string-name><given-names>N. B.</given-names> <surname>Turk-Browne</surname></string-name></person-group>, <article-title>Hippocampal encoding of memories in human infants</article-title>. <source>Science</source> <volume>387</volume>, <fpage>1316</fpage>–<lpage>1320</lpage> (<year>2025</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y. G.</given-names> <surname>Bolsius</surname></string-name>, <string-name><given-names>P. R. A.</given-names> <surname>Heckman</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Paraciani</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Wilhelm</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Raven</surname></string-name>, <string-name><given-names>E. L.</given-names> <surname>Meijer</surname></string-name>, <string-name><given-names>M. J. H.</given-names> <surname>Kas</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Ramirez</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Meerlo</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Havekes</surname></string-name></person-group>, <article-title>Recovering object-location memories after sleep deprivation-induced amnesia</article-title>. <source>Curr. Biol.</source> <volume>33</volume>, <fpage>298</fpage>–<lpage>308.e5</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L.</given-names> <surname>Autore</surname></string-name>, <string-name><given-names>J. D.</given-names> <surname>O’Leary</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Ortega-de San Luis</surname></string-name>, <string-name><given-names>T. J.</given-names> <surname>Ryan</surname></string-name></person-group>, <article-title>Adaptive expression of engrams by retroactive interference</article-title>. <source>Cell Rep.</source> <volume>42</volume>, <fpage>112999</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. T.</given-names> <surname>Wixted</surname></string-name></person-group>, <article-title>The Psychology and Neuroscience of Forgetting</article-title>. <source>Annu. Rev. Psychol.</source> <volume>55</volume>, <fpage>235</fpage>–<lpage>269</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. C.</given-names> <surname>Anderson</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Hanslmayr</surname></string-name></person-group>, <article-title>Neural mechanisms of motivated forgetting</article-title>. <source>Trends Cogn. Sci.</source> <volume>18</volume>, <fpage>279</fpage>–<lpage>92</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. S.</given-names> <surname>Roy</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Arons</surname></string-name>, <string-name><given-names>T. I.</given-names> <surname>Mitchell</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Pignatelli</surname></string-name>, <string-name><given-names>T. J.</given-names> <surname>Ryan</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Tonegawa</surname></string-name></person-group>, <article-title>Memory retrieval by activating engram cells in mouse models of early Alzheimer’s disease</article-title>. <source>Nature</source> <volume>531</volume>, <fpage>508</fpage>–<lpage>512</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W. C.</given-names> <surname>Abraham</surname></string-name>, <string-name><given-names>O. D.</given-names> <surname>Jones</surname></string-name>, <string-name><given-names>D. L.</given-names> <surname>Glanzman</surname></string-name></person-group>, <article-title>Is plasticity of synapses the mechanism of long-term memory storage?</article-title> <source>Npj Sci Learn</source> <volume>4</volume>, <fpage>9</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>C.</given-names> <surname>Clopath</surname></string-name></person-group>, <article-title>Synaptic consolidation: an approach to long-term learning</article-title>. <source>Cogn. Neurodyn.</source> <volume>6</volume>, <fpage>251</fpage>–<lpage>257</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Aleman-Zapata</surname></string-name>, <string-name><given-names>R. G. M.</given-names> <surname>Morris</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Genzel</surname></string-name></person-group>, <article-title>Sleep deprivation and hippocampal ripple disruption after one-session learning eliminate memory expression the next day</article-title>. <source>Proc. Natl. Acad. Sci.</source> <volume>119</volume>, <elocation-id>e2123424119</elocation-id> (<year>2022</year>).</mixed-citation></ref>
    <ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Refaeli</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Kreisel</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Groysman</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Adamsky</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Goshen</surname></string-name></person-group>, <article-title>Engram stability and maturation during systems consolidation</article-title>. <source>Curr. Biol.</source>, <volume>33</volume> <fpage>3942</fpage>-<lpage>3950.e3</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Brodt</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Gais</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Beck</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Erb</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Scheffler</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Schönauer</surname></string-name></person-group>, <article-title>Fast track to the neocortex: A memory engram in the posterior parietal cortex</article-title>. <source>Science</source> <volume>362</volume>, <fpage>1045</fpage>–<lpage>1048</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L.</given-names> <surname>Folvik</surname></string-name>, <string-name><given-names>M. H.</given-names> <surname>Sneve</surname></string-name>, <string-name><given-names>H. T.</given-names> <surname>Ness</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Vidal-Piñeiro</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Raud</surname></string-name>, <string-name><given-names>O. M.</given-names> <surname>Geier</surname></string-name>, <string-name><given-names>K. B.</given-names> <surname>Walhovd</surname></string-name>, <string-name><given-names>A. M.</given-names> <surname>Fjell</surname></string-name></person-group>, <article-title>Sustained upregulation of widespread hippocampal–neocortical coupling following memory encoding</article-title>. <source>Cereb. Cortex</source> <volume>33</volume>, <fpage>4844</fpage>–<lpage>4858</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Goto</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Bota</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Miya</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Tsukamoto</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Jiang</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Hirai</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Murayama</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Matsuda</surname></string-name>, <string-name><given-names>T. J.</given-names> <surname>McHugh</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Nagai</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Hayashi</surname></string-name></person-group>, <article-title>Stepwise synaptic plasticity events drive the early phase of memory consolidation</article-title>. <source>Science</source> <volume>374</volume>, <fpage>857</fpage>–<lpage>863</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names> <surname>Willems</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Henke</surname></string-name></person-group>, <article-title>Imaging human engrams using 7 Tesla magnetic resonance imaging</article-title>. <source>Hippocampus</source> <volume>31</volume>, <fpage>1257</fpage>–<lpage>1270</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E. K.</given-names> <surname>Leiker</surname></string-name>, <string-name><given-names>J. D.</given-names> <surname>Johnson</surname></string-name></person-group>, <article-title>Neural reinstatement and the amount of information recollected</article-title>. <source>Brain Res.</source> <volume>1582</volume>, <fpage>125</fpage>–<lpage>138</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. P.</given-names> <surname>Staresina</surname></string-name>, <string-name><given-names>R. N. A.</given-names> <surname>Henson</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Kriegeskorte</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Alink</surname></string-name></person-group>, <article-title>Episodic Reinstatement in the Medial Temporal Lobe</article-title>. <source>J. Neurosci.</source> <volume>32</volume>, <fpage>18150</fpage>–<lpage>18156</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E. A.</given-names> <surname>Wing</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Ritchey</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Cabeza</surname></string-name></person-group>, <article-title>Reinstatement of Individual Past Events Revealed by the Similarity of Distributed Activation Patterns during Encoding and Retrieval</article-title>. <source>J. Cogn. Neurosci.</source> <volume>27</volume>, <fpage>679</fpage>–<lpage>691</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Xue</surname></string-name></person-group>, <article-title>The Neural Representations Underlying Human Episodic Memory</article-title>. <source>Trends Cogn. Sci.</source> <volume>22</volume>, <fpage>544</fpage>–<lpage>561</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.-L.</given-names> <surname>Lim</surname></string-name>, <string-name><given-names>D. J.</given-names> <surname>Lang</surname></string-name>, <string-name><given-names>R. A.</given-names> <surname>Diana</surname></string-name></person-group>, <article-title>Cognitive tasks affect the relationship between representational pattern similarity and subsequent item memory in the hippocampus</article-title>. <source>NeuroImage</source> <volume>277</volume>, <elocation-id>e120241</elocation-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. F.</given-names> <surname>LaRocque</surname></string-name>, <string-name><given-names>M. E.</given-names> <surname>Smith</surname></string-name>, <string-name><given-names>V. A.</given-names> <surname>Carr</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Witthoft</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Grill-Spector</surname></string-name>, <string-name><given-names>A. D.</given-names> <surname>Wagner</surname></string-name></person-group>, <article-title>Global Similarity and Pattern Separation in the Human Medial Temporal Lobe Predict Subsequent Memory</article-title>. <source>J. Neurosci.</source> <volume>33</volume>, <fpage>5466</fpage>–<lpage>5474</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.-H.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>D. J.</given-names> <surname>Kravitz</surname></string-name>, <string-name><given-names>C. I.</given-names> <surname>Baker</surname></string-name></person-group>, <article-title>Differential Representations of Perceived and Retrieved Visual Information in Hippocampus and Cortex</article-title>. <source>Cereb. Cortex</source> <volume>29</volume>, <fpage>4452</fpage>–<lpage>4461</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Yu</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Ren</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Ni</surname></string-name>, <string-name><given-names>Q.</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Lu</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Axmacher</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Xue</surname></string-name></person-group>, <article-title>Transformative neural representations support long-term episodic memory</article-title>. <source>Sci. Adv.</source> <volume>7</volume>, <elocation-id>eabg9715</elocation-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>X.</given-names> <surname>Xiao</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Zhou</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Z.</given-names> <surname>Ye</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Yao</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Xue</surname></string-name></person-group>, <article-title>Individual-specific and shared representations during episodic memory encoding and retrieval</article-title>. <source>NeuroImage</source> <volume>217</volume>, <elocation-id>e116909</elocation-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.</given-names> <surname>Lei</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Kang</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Hao</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>Z.</given-names> <surname>Zhong</surname></string-name>, <string-name><given-names>Z.</given-names> <surname>Zhai</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Zhong</surname></string-name></person-group>, <article-title>Reconstructing a new hippocampal engram for systems reconsolidation and remote memory updating</article-title>. <source>Neuron</source> <volume>113</volume>, <fpage>471</fpage>–<lpage>485.e6</lpage> (<year>2025</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. A.</given-names> <surname>Yassa</surname></string-name>, <string-name><given-names>C. E. L.</given-names> <surname>Stark</surname></string-name></person-group>, <article-title>Pattern separation in the hippocampus</article-title>. <source>Trends Neurosci.</source> <volume>34</volume>, <fpage>515</fpage>–<lpage>525</lpage> (<year>2011</year>).</mixed-citation></ref>
    <ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. D. E.</given-names> <surname>Gabrieli</surname></string-name></person-group>, <article-title>Cognitive neuroscience of human memory</article-title>. <source>Annu. Rev. Psychol.</source> <volume>49</volume>, <fpage>87</fpage>–<lpage>115</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Tulving</surname></string-name></person-group>, <article-title>Episodic Memory: From Mind to Brain</article-title>. <source>Annu. Rev. Psychol.</source> <volume>53</volume>, <fpage>1</fpage>–<lpage>25</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. R.</given-names> <surname>Squire</surname></string-name>, <string-name><given-names>A. J. O.</given-names> <surname>Dede</surname></string-name></person-group>, <article-title>Conscious and unconscious memory systems</article-title>. <source>Cold Spring Harb Perspect Med</source> <volume>5</volume>, <fpage>a021667</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Daviddi</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Yaya</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Sperduti</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Santangelo</surname></string-name></person-group>, <article-title>A Systematic Review and Meta-analysis of the Neural Correlates of Direct vs. Generative Retrieval of Episodic Autobiographical Memory</article-title>. <source>Neuropsychol Rev</source>, doi: <pub-id pub-id-type="doi">10.1007/s11065-024-09653-3</pub-id> (<year>2024</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Berntsen</surname></string-name></person-group>, <article-title>Involuntary autobiographical memories and their relation to other forms of spontaneous thoughts</article-title>. <source>Philos. Trans. R. Soc. B Biol. Sci.</source> <volume>376</volume>, <fpage>20190693</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Berntsen</surname></string-name></person-group>, <article-title>Direct retrieval as a theory of involuntary autobiographical memories: evaluation and future directions</article-title>. <source>Memory</source> <volume>32</volume>, <fpage>709</fpage>–<lpage>722</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Henke</surname></string-name></person-group>, <article-title>A model for memory systems based on processing modes rather than consciousness</article-title>. <source>Nat. Rev. Neurosci.</source> <volume>11</volume>, <fpage>523</fpage>–<lpage>532</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. E.</given-names> <surname>Hannula</surname></string-name></person-group>, <article-title>Worth a glance: using eye movements to investigate the cognitive neuroscience of memory</article-title>. <source>Front. Hum. Neurosci.</source> <volume>4</volume> (<year>2010</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. M.</given-names> <surname>Reder</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Park</surname></string-name>, <string-name><given-names>P. D.</given-names> <surname>Kieffaber</surname></string-name></person-group>, <article-title>Memory Systems Do Not Divide on Consciousness: Reinterpreting Memory in Terms of Activation and Binding</article-title>. <source>Psychol. Bull.</source> <volume>135</volume>, <fpage>23</fpage>–<lpage>49</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Guskjolen</surname></string-name>, <string-name><given-names>S. A.</given-names> <surname>Josselyn</surname></string-name>, <string-name><given-names>P. W.</given-names> <surname>Frankland</surname></string-name></person-group>, <article-title>Age-dependent changes in spatial memory retention and flexibility in mice</article-title>. <source>Neurobiol. Learn. Mem.</source> <volume>143</volume>, <fpage>59</fpage>–<lpage>66</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. M.</given-names> <surname>Kark</surname></string-name>, <string-name><given-names>S. D.</given-names> <surname>Slotnick</surname></string-name>, <string-name><given-names>E. A.</given-names> <surname>Kensinger</surname></string-name></person-group>, <article-title>Forgotten but not gone: FMRI evidence of implicit memory for negative stimuli 24 hours after the initial study episode</article-title>. <source>Neuropsychologia</source> <volume>136</volume>, <elocation-id>e107277</elocation-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T. P.</given-names> <surname>Reber</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Luechinger</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Boesiger</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Henke</surname></string-name></person-group>, <article-title>Unconscious Relational Inference Recruits the Hippocampus</article-title>. <source>J. Neurosci.</source> <volume>32</volume>, <fpage>6138</fpage>–<lpage>6148</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. B.</given-names> <surname>Duss</surname></string-name>, <string-name><given-names>T. P.</given-names> <surname>Reber</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Hänggi</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Schwab</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Wiest</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Müri</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Brugger</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Gutbrod</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Henke</surname></string-name></person-group>, <article-title>Unconscious relational encoding depends on hippocampus</article-title>. <source>Brain</source> <volume>137</volume>, <fpage>3355</fpage>–<lpage>3370</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L.</given-names> <surname>Pacozzi</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Knüsel</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Ruch</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Henke</surname></string-name></person-group>, <article-title>Inverse forgetting in unconscious episodic memory</article-title>. <source>Sci. Rep.</source> <volume>12</volume>, <fpage>20595</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Schneider</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>Züst</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Wuethrich</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Schmidig</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Klöppel</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Wiest</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Ruch</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Henke</surname></string-name></person-group>, <article-title>Larger capacity for unconscious versus conscious episodic memory</article-title>. <source>Curr. Biol.</source> <volume>31</volume>, <fpage>3551</fpage>–<lpage>3563.e9</lpage> (<year>2021</year>).</mixed-citation></ref>
    <ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F.</given-names> <surname>Schmidig</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Ruch</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Henke</surname></string-name></person-group>, <article-title>Episodic long-term memory formation during slow-wave sleep</article-title>. <source>eLife</source>  doi: <pub-id pub-id-type="doi">10.7554/elife.89601</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Anderson</surname></string-name></person-group>, <article-title>Rethinking interference theory: Executive control and the mechanisms of forgetting</article-title>. <source>J. Mem. Lang.</source> <volume>49</volume>, <fpage>415</fpage>–<lpage>445</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Baddeley</surname></string-name>, <string-name><given-names>M. W.</given-names> <surname>Eysenck</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Anderson</surname></string-name></person-group>, <source>Memory</source> (<publisher-name>Taylor &amp; Francis</publisher-name>, <year>2015</year>; <ext-link ext-link-type="uri" xlink:href="https://books.google.ch/books?id=xxRWBQAAQBAJ">https://books.google.ch/books?id=xxRWBQAAQBAJ</ext-link>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Ebbinghaus</surname></string-name></person-group>, <source>Über Das Gedächtnis: Untersuchungen Zur Experimentellen Psychologie</source> (<publisher-name>Duncker &amp; Humblot</publisher-name>, <year>1885</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. M. J.</given-names> <surname>Murre</surname></string-name>, <string-name><given-names>A. G.</given-names> <surname>Chessa</surname></string-name></person-group>, <article-title>Why Ebbinghaus’ savings method from 1885 is a very ‘pure’ measure of memory performance</article-title>. <source>Psychon. Bull. Rev.</source> <volume>30</volume>, <fpage>303</fpage>–<lpage>307</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. M. J.</given-names> <surname>Murre</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Dros</surname></string-name></person-group>, <article-title>Replication and Analysis of Ebbinghaus’ Forgetting Curve</article-title>. <source>PLOS One</source> <volume>10</volume>, <elocation-id>e0120644</elocation-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F.</given-names> <surname>Lu</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Qiu</surname></string-name></person-group>, <article-title>Neural bases of motivated forgetting of autobiographical memories</article-title>. <source>Cogn. Neurosci.</source> <volume>14</volume>, <fpage>15</fpage>–<lpage>24</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Danieli</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Guyon</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Bethus</surname></string-name></person-group>, <article-title>Episodic Memory formation: A review of complex Hippocampus input pathways</article-title>. <source>Prog. Neuropsychopharmacol. Biol. Psychiatry</source> <volume>126</volume>, <fpage>110757</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>C.</given-names> <surname>Bogler</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Zangrossi</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Miller</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Sartori</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Haynes</surname></string-name></person-group>, <article-title>Have you been there before? Decoding recognition of spatial scenes from FMRI signals in precuneus</article-title>. <source>Hum. Brain Mapp.</source> <volume>45</volume>, <elocation-id>e26690</elocation-id> (<year>2024</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Spaniol</surname></string-name>, <string-name><given-names>P. S. R.</given-names> <surname>Davidson</surname></string-name>, <string-name><given-names>A. S. N.</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Han</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Moscovitch</surname></string-name>, <string-name><given-names>C. L.</given-names> <surname>Grady</surname></string-name></person-group>, <article-title>Event-related fMRI studies of episodic encoding and retrieval: Meta-analyses using activation likelihood estimation</article-title>. <source>Neuropsychologia</source> <volume>47</volume>, <fpage>1765</fpage>–<lpage>1779</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Cabeza</surname></string-name>, <string-name><given-names>S. E.</given-names> <surname>Prince</surname></string-name>, <string-name><given-names>S. M.</given-names> <surname>Daselaar</surname></string-name>, <string-name><given-names>D. L.</given-names> <surname>Greenberg</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Budde</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Dolcos</surname></string-name>, <string-name><given-names>K. S.</given-names> <surname>LaBar</surname></string-name>, <string-name><given-names>D. C.</given-names> <surname>Rubin</surname></string-name></person-group>, <article-title>Brain Activity during Episodic Retrieval of Autobiographical and Laboratory Events: An fMRI Study using a Novel Photo Paradigm</article-title>. <source>J. Cogn. Neurosci.</source> <volume>16</volume>, <fpage>1583</fpage>–<lpage>1594</lpage> (<year>2004</year>).</mixed-citation></ref>
    <ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. L.</given-names> <surname>Jacoby</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Dallas</surname></string-name></person-group>, <article-title>On the Relationship Between Autobiographical Memory and Perceptual Learning</article-title>. <source>J Exp Psychol Gen</source> <year>1981</year></mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. W. A.</given-names> <surname>Whittlesea</surname></string-name>, <string-name><given-names>L. L.</given-names> <surname>Jacoby</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Girard</surname></string-name></person-group>, <article-title>Illusions of immediate memory: Evidence of an attributional basis for feelings of familiarity and perceptual quality</article-title>. <source>J. Mem. Lang.</source> <volume>29</volume>, <fpage>716</fpage>–<lpage>732</lpage> (<year>1990</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Wuethrich</surname></string-name>, <string-name><given-names>D. E.</given-names> <surname>Hannula</surname></string-name>, <string-name><given-names>F. W.</given-names> <surname>Mast</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Henke</surname></string-name></person-group>, <article-title>Subliminal encoding and flexible retrieval of objects in scenes</article-title>. <source>Hippocampus</source> <volume>28</volume>, <fpage>633</fpage>–<lpage>643</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T. J.</given-names> <surname>Ryan</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Ortega-de San Luis</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Pezzoli</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Sen</surname></string-name></person-group>, <article-title>Engram cell connectivity: an evolving substrate for information storage</article-title>. <source>Curr. Opin. Neurobiol.</source> <volume>67</volume>, <fpage>215</fpage>–<lpage>225</lpage> (<year>2021</year>).</mixed-citation></ref>
    <ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Hebscher</surname></string-name> <etal>et al</etal></person-group>, <article-title>Enhanced reinstatement of naturalistic event memories due to hippocampal-network-targeted stimulation</article-title>. <source>Curr Biol</source> <volume>31</volume>. <year>2021</year></mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>I. K.</given-names> <surname>Brunec</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Robin</surname></string-name>, <string-name><given-names>R. K.</given-names> <surname>Olsen</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Moscovitch</surname></string-name>, <string-name><given-names>M. D.</given-names> <surname>Barense</surname></string-name></person-group>, <article-title>Integration and differentiation of hippocampal memory traces</article-title>. <source>Neurosci. Biobehav. Rev.</source> <volume>118</volume>, <fpage>196</fpage>–<lpage>208</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>C. B.</given-names> <surname>Kirwan</surname></string-name>, <string-name><given-names>S. R.</given-names> <surname>Ashby</surname></string-name>, <string-name><given-names>M. I.</given-names> <surname>Nash</surname></string-name></person-group>, <article-title>Remembering and imagining differentially engage the hippocampus: A multivariate fMRI investigation</article-title>. <source>Cogn. Neurosci.</source> <volume>5</volume>, <fpage>177</fpage>–<lpage>185</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. Y.</given-names> <surname>Ko</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Rong</surname></string-name>, <string-name><given-names>A. I.</given-names> <surname>Ramsaran</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>A. J.</given-names> <surname>Rashid</surname></string-name>, <string-name><given-names>A. J.</given-names> <surname>Mocle</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Dhaliwal</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Awasthi</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Guskjolen</surname></string-name>, <string-name><given-names>S. A.</given-names> <surname>Josselyn</surname></string-name>, <string-name><given-names>P. W.</given-names> <surname>Frankland</surname></string-name></person-group>, <article-title>Systems consolidation reorganizes hippocampal engram circuitry</article-title>. <source>Nature</source>, doi: <pub-id pub-id-type="doi">10.1038/s41586-025-08993-1</pub-id> (<year>2025</year>).</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Goto</surname></string-name></person-group>, <article-title>Synaptic plasticity during systems memory consolidation</article-title>. <source>Neurosci. Res.</source> <volume>183</volume>, <fpage>1</fpage>–<lpage>6</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Bota</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Goto</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Tsukamoto</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Schmidt</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Wolf</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Luchetti</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Nakai</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Hirase</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Hayashi</surname></string-name></person-group>, <article-title>Shared and unique properties of place cells in anterior cingulate cortex and hippocampus</article-title>. <source>bioRxiv</source> (<year>2021</year>). <pub-id pub-id-type="doi">10.1101/2021.03.29.437441</pub-id>.</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Tse</surname></string-name>, <string-name><given-names>R. F.</given-names> <surname>Langston</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Kakeyama</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Bethus</surname></string-name>, <string-name><given-names>P. A.</given-names> <surname>Spooner</surname></string-name>, <string-name><given-names>E. R.</given-names> <surname>Wood</surname></string-name>, <string-name><given-names>M. P.</given-names> <surname>Witter</surname></string-name>, <string-name><given-names>R. G. M.</given-names> <surname>Morris</surname></string-name></person-group>, <article-title>Schemas and Memory Consolidation</article-title>. <source>Science</source> <volume>316</volume>, <fpage>76</fpage>–<lpage>82</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. M.</given-names> <surname>Fleming</surname></string-name>, <string-name><given-names>H. C.</given-names> <surname>Lau</surname></string-name></person-group>, <article-title>How to measure metacognition</article-title>. <source>Front. Hum. Neurosci.</source> <volume>8</volume> (<year>2014</year>).</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Meliss</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Pascua-Martin</surname></string-name>, <string-name><given-names>J. I.</given-names> <surname>Skipper</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Murayama</surname></string-name></person-group>, <article-title>The magic, memory, and curiosity fMRI dataset of people viewing magic tricks</article-title>. <source>Sci. Data</source> <volume>11</volume>, <fpage>1063</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V. R.</given-names> <surname>Steele</surname></string-name>, <string-name><given-names>N. E.</given-names> <surname>Anderson</surname></string-name>, <string-name><given-names>E. D.</given-names> <surname>Claus</surname></string-name>, <string-name><given-names>E. M.</given-names> <surname>Bernat</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Rao</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Assaf</surname></string-name>, <string-name><given-names>G. D.</given-names> <surname>Pearlson</surname></string-name>, <string-name><given-names>V. D.</given-names> <surname>Calhoun</surname></string-name>, <string-name><given-names>K. A.</given-names> <surname>Kiehl</surname></string-name></person-group>, <article-title>Neuroimaging measures of error-processing: Extracting reliable signals from event-related potentials and functional magnetic resonance imaging</article-title>. <source>NeuroImage</source> <volume>132</volume>, <fpage>247</fpage>–<lpage>260</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. A.</given-names> <surname>Trivedi</surname></string-name>, <string-name><given-names>C. M.</given-names> <surname>Murphy</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Goetz</surname></string-name>, <string-name><given-names>R. C.</given-names> <surname>Shah</surname></string-name>, <string-name><given-names>J. D. E.</given-names> <surname>Gabrieli</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Whitfield-Gabrieli</surname></string-name>, <string-name><given-names>D. A.</given-names> <surname>Turner</surname></string-name>, <string-name><given-names>G. T.</given-names> <surname>Stebbins</surname></string-name></person-group>, <article-title>fMRI Activation Changes during Successful Episodic Memory Encoding and Recognition in Amnestic Mild Cognitive Impairment Relative to Cognitively Healthy Older Adults</article-title>. <source>Dement Geriatr Cogn Disord.</source> <volume>26</volume>, <fpage>123</fpage>–<lpage>137</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. E.</given-names> <surname>Sherman</surname></string-name>, <string-name><given-names>N. B.</given-names> <surname>Turk-Browne</surname></string-name></person-group>, <article-title>Statistical prediction of the future impairs episodic encoding of the present</article-title>. <source>Proc. Natl. Acad. Sci.</source> <volume>117</volume>, <fpage>22760</fpage>–<lpage>22770</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names> <surname>Donoshita</surname></string-name>, <string-name><given-names>U.-S.</given-names> <surname>Choi</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Ban</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Kida</surname></string-name></person-group>, <article-title>Assessment of olfactory information in the human brain using 7-Tesla functional magnetic resonance imaging</article-title>. <source>NeuroImage</source> <volume>236</volume>, <fpage>118212</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Castaldi</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Piazza</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Dehaene</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Vignaud</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Eger</surname></string-name></person-group>, <article-title>Attentional amplification of neural codes for number independent of other quantities along the dorsal visual stream</article-title>. <source>eLife</source> <volume>8</volume>, <elocation-id>e45160</elocation-id> (<year>2019</year>). <pub-id pub-id-type="doi">10.7554/eLife.45160</pub-id></mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Lankinen</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Ahveninen</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Uluç</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Daneshzand</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Mareyam</surname></string-name>, <string-name><given-names>J. E.</given-names> <surname>Kirsch</surname></string-name>, <string-name><given-names>J. R.</given-names> <surname>Polimeni</surname></string-name>, <string-name><given-names>B. C.</given-names> <surname>Healy</surname></string-name>, <string-name><given-names>Q.</given-names> <surname>Tian</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Khan</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Nummenmaa</surname></string-name>, <string-name><given-names>Q. M.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>J. R.</given-names> <surname>Green</surname></string-name>, <string-name><given-names>T. J.</given-names> <surname>Kimberley</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Li</surname></string-name></person-group>, <article-title>Role of articulatory motor networks in perceptual categorization of speech signals: a 7T fMRI study</article-title>. <source>Cereb. Cortex</source> <volume>33</volume>, <fpage>11517</fpage>–<lpage>11525</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. N.</given-names> <surname>Rouder</surname></string-name>, <string-name><given-names>P. L.</given-names> <surname>Speckman</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Sun</surname></string-name>, <string-name><given-names>R. D.</given-names> <surname>Morey</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Iverson</surname></string-name></person-group>, <article-title>Bayesian t tests for accepting and rejecting the null hypothesis</article-title>. <source>Psychon. Bull. Rev.</source> <volume>16</volume>, <fpage>225</fpage>–<lpage>237</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. S.</given-names> <surname>Ghosh</surname></string-name>, <string-name><given-names>J. D.</given-names> <surname>Kent</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Erramuzpe</surname></string-name>, <string-name><given-names>E.</given-names> <surname>DuPre</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Snyder</surname></string-name>, <string-name><given-names>R. W.</given-names> <surname>Blair</surname></string-name>, <string-name><given-names>C. A.</given-names> <surname>Moodie</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Esteban</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Durnez</surname></string-name>, <string-name><given-names>A. I.</given-names> <surname>Isik</surname></string-name>, <string-name><given-names>R. A.</given-names> <surname>Poldrack</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Goncalves</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Wright</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Oya</surname></string-name>, <string-name><given-names>K. J.</given-names> <surname>Gorgolewski</surname></string-name>, <string-name><given-names>C. J.</given-names> <surname>Markiewicz</surname></string-name></person-group>, <article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nat. Methods</source> <volume>16</volume>, <fpage>111</fpage>– <lpage>116</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Gorgolewski</surname></string-name>, <string-name><given-names>C. D.</given-names> <surname>Burns</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Madison</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Clark</surname></string-name>, <string-name><given-names>Y. O.</given-names> <surname>Halchenko</surname></string-name>, <string-name><given-names>M. L.</given-names> <surname>Waskom</surname></string-name>, <string-name><given-names>S. S.</given-names> <surname>Ghosh</surname></string-name></person-group>, <article-title>Nipype: A Flexible, Lightweight and Extensible Neuroimaging Data Processing Framework in Python</article-title>. <source>Front. Neuroinformatics</source> <volume>5</volume> (<year>2011</year>).</mixed-citation></ref>
    <ref id="c81"><label>81.</label><mixed-citation publication-type="software"><person-group person-group-type="author"><string-name><given-names>K. J.</given-names> <surname>Gorgolewski</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Esteban</surname></string-name>, <string-name><given-names>C. J.</given-names> <surname>Markiewicz</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Ziegler</surname></string-name>, <string-name><given-names>D. G.</given-names> <surname>Ellis</surname></string-name>, <string-name><given-names>M. P.</given-names> <surname>Notter</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Jarecka</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Johnson</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Burns</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Manhães-Savio</surname></string-name> <etal>et al</etal></person-group>,. <source>Nipype</source> (<year>2018</year>).</mixed-citation></ref>
<ref id="c82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N. J.</given-names> <surname>Tustison</surname></string-name>, <string-name><given-names>B. B.</given-names> <surname>Avants</surname></string-name>, <string-name><given-names>P. A.</given-names> <surname>Cook</surname></string-name>, <string-name><given-names>Yuanjie</given-names> <surname>Zheng</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Egan</surname></string-name>, <string-name><given-names>P. A.</given-names> <surname>Yushkevich</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Gee</surname></string-name></person-group>, <article-title>N4ITK: Improved N3 Bias Correction</article-title>. <source>IEEE Trans. Med. Imaging</source> <volume>29</volume>, <fpage>1310</fpage>–<lpage>1320</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.</given-names> <surname>Avants</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Epstein</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Grossman</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Gee</surname></string-name></person-group>, <article-title>Symmetric diffeomorphic image registration with cross-correlation: Evaluating automated labeling of elderly and neurodegenerative brain</article-title>. <source>Med. Image Anal.</source> <volume>12</volume>, <fpage>26</fpage>–<lpage>41</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c84"><label>84.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Brady</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Smith</surname></string-name></person-group>, <article-title>Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm</article-title>. <source>IEEE Trans. Med. Imaging</source> <volume>20</volume>, <fpage>45</fpage>–<lpage>57</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c85"><label>85.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Reuter</surname></string-name>, <string-name><given-names>H. D.</given-names> <surname>Rosas</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Fischl</surname></string-name></person-group>, <article-title>Highly accurate inverse consistent registration: A robust approach</article-title>. <source>NeuroImage</source> <volume>53</volume>, <fpage>1181</fpage>–<lpage>1196</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c86"><label>86.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. M.</given-names> <surname>Dale</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Fischl</surname></string-name>, <string-name><given-names>M. I.</given-names> <surname>Sereno</surname></string-name></person-group>, <article-title>Cortical Surface-Based Analysis: I. Segmentation and Surface Reconstruction</article-title>. <source>NeuroImage</source> <volume>9</volume>, <fpage>179</fpage>–<lpage>194</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c87"><label>87.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Klein</surname></string-name>, <string-name><given-names>S. S.</given-names> <surname>Ghosh</surname></string-name>, <string-name><given-names>F. S.</given-names> <surname>Bao</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Giard</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Häme</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Stavsky</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Rossa</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Reuter</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Chaibub Neto</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Keshavan</surname></string-name></person-group>, <article-title>Mindboggling morphometry of human brains</article-title>. <source>PLOS Comput. Biol.</source> <volume>13</volume>, <elocation-id>e1005350</elocation-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c88"><label>88.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V. S.</given-names> <surname>Fonov</surname></string-name>, <string-name><given-names>A. C.</given-names> <surname>Evans</surname></string-name>, <string-name><given-names>R. C.</given-names> <surname>McKinstry</surname></string-name>, <string-name><given-names>C. R.</given-names> <surname>Almli</surname></string-name>, <string-name><given-names>D. L.</given-names> <surname>Collins</surname></string-name></person-group>, <article-title>Unbiased nonlinear average age-appropriate brain templates from birth to adulthood</article-title>. <source>NeuroImage</source> <volume>47</volume>, <fpage>S102</fpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c89"><label>89.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. C.</given-names> <surname>Evans</surname></string-name>, <string-name><given-names>A. L.</given-names> <surname>Janke</surname></string-name>, <string-name><given-names>D. L.</given-names> <surname>Collins</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Baillet</surname></string-name></person-group>, <article-title>Brain templates and atlases</article-title>. <source>NeuroImage</source> <volume>62</volume>, <fpage>911</fpage>– <lpage>922</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c90"><label>90.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. N.</given-names> <surname>Greve</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Fischl</surname></string-name></person-group>, <article-title>Accurate and robust brain image alignment using boundary-based registration</article-title>. <source>NeuroImage</source> <volume>48</volume>, <fpage>63</fpage>–<lpage>72</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c91"><label>91.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Jenkinson</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Bannister</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Brady</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Smith</surname></string-name></person-group>, <article-title>Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images</article-title>. <source>NeuroImage</source> <volume>17</volume>, <fpage>825</fpage>–<lpage>841</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c92"><label>92.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. W.</given-names> <surname>Cox</surname></string-name>, <string-name><given-names>J. S.</given-names> <surname>Hyde</surname></string-name></person-group>, <article-title>Software tools for analysis and visualization of fMRI data</article-title>. <source>NMR Biomed.</source> <volume>10</volume>, <fpage>171</fpage>–<lpage>178</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c93"><label>93.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. H. R.</given-names> <surname>Pruim</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Mennes</surname></string-name>, <string-name><given-names>D.</given-names> <surname>van Rooij</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Llera</surname></string-name>, <string-name><given-names>J. K.</given-names> <surname>Buitelaar</surname></string-name>, <string-name><given-names>C. F.</given-names> <surname>Beckmann</surname></string-name></person-group>, <article-title>ICA-AROMA: A robust ICA-based strategy for removing motion artifacts from fMRI data</article-title>. <source>NeuroImage</source> <volume>112</volume>, <fpage>267</fpage>–<lpage>277</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c94"><label>94.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. D.</given-names> <surname>Power</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Mitra</surname></string-name>, <string-name><given-names>T. O.</given-names> <surname>Laumann</surname></string-name>, <string-name><given-names>A. Z.</given-names> <surname>Snyder</surname></string-name>, <string-name><given-names>B. L.</given-names> <surname>Schlaggar</surname></string-name>, <string-name><given-names>S. E.</given-names> <surname>Petersen</surname></string-name></person-group>, <article-title>Methods to detect, characterize, and remove motion artifact in resting state fMRI</article-title>. <source>NeuroImage</source> <volume>84</volume>, <fpage>320</fpage>–<lpage>341</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c95"><label>95.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names> <surname>Behzadi</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Restom</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Liau</surname></string-name>, <string-name><given-names>T. T.</given-names> <surname>Liu</surname></string-name></person-group>, <article-title>A component based noise correction method (CompCor) for BOLD and perfusion based fMRI</article-title>. <source>NeuroImage</source> <volume>37</volume>, <fpage>90</fpage>–<lpage>101</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c96"><label>96.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T. D.</given-names> <surname>Satterthwaite</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>Elliott</surname></string-name>, <string-name><given-names>R. T.</given-names> <surname>Gerraty</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Ruparel</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Loughead</surname></string-name>, <string-name><given-names>M. E.</given-names> <surname>Calkins</surname></string-name>, <string-name><given-names>S. B.</given-names> <surname>Eickhoff</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Hakonarson</surname></string-name>, <string-name><given-names>R. C.</given-names> <surname>Gur</surname></string-name>, <string-name><given-names>R. E.</given-names> <surname>Gur</surname></string-name>, <string-name><given-names>D. H.</given-names> <surname>Wolf</surname></string-name></person-group>, <article-title>An improved framework for confound regression and filtering for control of motion artifact in the preprocessing of resting-state functional connectivity data</article-title>. <source>NeuroImage</source> <volume>64</volume>, <fpage>240</fpage>–<lpage>256</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c97"><label>97.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>C.</given-names> <surname>Lanczos</surname></string-name></person-group>, <article-title>Evaluation of Noisy Data</article-title>. <source>J. Soc. Ind. Appl. Math. Ser. B Numer. Anal.</source> <volume>1</volume>, <fpage>76</fpage>–<lpage>85</lpage> (<year>1964</year>).</mixed-citation></ref>
    <ref id="c98"><label>98.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Abraham</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Pedregosa</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Eickenberg</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Gervais</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Mueller</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Kossaifi</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Gramfort</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Thirion</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Varoquaux</surname></string-name></person-group>, <article-title>Machine learning for neuroimaging with scikit-learn</article-title>. <source>Front Neuroinformatics</source> <volume>8</volume> (<year>2014</year>).</mixed-citation></ref>
    <ref id="c99"><label>99.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>P. A.</given-names> <surname>Taylor</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Aggarwal</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Bandettini</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Barilari</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Bright</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Caballero-Gaudes</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Calhoun</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Chakravarty</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Devenyi</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Evans</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Garza-Villarreal</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Rasgado-Toledo</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Gau</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Glen</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Goebel</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Gonzalez-Castillo</surname></string-name>, <string-name><given-names>O. F.</given-names> <surname>Gulban</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Halchenko</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Handwerker</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Hanayik</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Lauren</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Leopold</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Lerch</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Mathys</surname></string-name>, <string-name><given-names>P.</given-names> <surname>McCarthy</surname></string-name>, <string-name><given-names>A.</given-names> <surname>McLeod</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Mejia</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Moia</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Nichols</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Pernet</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Pessoa</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Pfleiderer</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Rajendra</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Reyes</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Reynolds</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Roopchansingh</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Rorden</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Russ</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Sundermann</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Thirion</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Torrisi</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Chen</surname></string-name></person-group>, <article-title>Go Figure: Transparency in neuroscience images preserves context and clarifies interpretation</article-title> (<year>2025</year>).<source>arXiv</source> <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2504.07824">https://arxiv.org/abs/2504.07824</ext-link>.</mixed-citation></ref>
    <ref id="c100"><label>100.</label><mixed-citation publication-type="software"><person-group person-group-type="author"><collab>Nilearn</collab></person-group>, <article-title>nilearn</article-title> <source>Zenodo</source> <pub-id pub-id-type="doi">10.5281/zenodo.8397156</pub-id>. <year>no date</year></mixed-citation></ref>
<ref id="c101"><label>101.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F.</given-names> <surname>Pedregosa</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Varoquaux</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Gramfort</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Michel</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Thirion</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Grisel</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Blondel</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Prettenhofer</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Weiss</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Dubourg</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Vanderplas</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Passos</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Cournapeau</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Brucher</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Perrot</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Duchesnay</surname></string-name></person-group>, <article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>J. Mach. Learn. Res.</source> <volume>12</volume>, <fpage>2825</fpage>– <lpage>2830</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c102"><label>102.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Wetzels</surname></string-name>, <string-name><given-names>E.-J.</given-names> <surname>Wagenmakers</surname></string-name></person-group>, <article-title>A default Bayesian hypothesis test for correlations and partial correlations</article-title>. <source>Psychon. Bull. Rev.</source> <volume>19</volume>, <fpage>1057</fpage>–<lpage>1064</lpage> (<year>2012</year>).</mixed-citation></ref>
    <ref id="dataref1"><mixed-citation publication-type="data" specific-use="generated"><person-group person-group-type="author"><string-name><surname>Tom Willems</surname></string-name>, <string-name><surname>Konstantinos Zervas</surname></string-name>, <string-name><surname>Andrea Federspiel</surname></string-name>, <string-name><surname>Katharina Henke</surname></string-name></person-group> (<year iso-8601-date="2025">2025</year>) <article-title>TOAM - Trajectory of a Memory Trace. Human episodic memory 7T fMRI dataset</article-title>. <source>OpenNeuro</source>. <pub-id pub-id-type="accession">10.18112/openneuro.ds006265.v1.0.2</pub-id> <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds006265/versions/1.0.2">https://openneuro.org/datasets/ds006265/versions/1.0.2</ext-link></mixed-citation></ref>
    <ref id="dataref2"><mixed-citation publication-type="data" specific-use="generated"><person-group person-group-type="author"><string-name><surname>Tom Willems</surname></string-name>, <string-name><surname>Konstantinos Zervas</surname></string-name>, <string-name><surname>Andrea Federspiel</surname></string-name>, <string-name><surname>Katharina Henke</surname></string-name></person-group> (<year iso-8601-date="2025">2025</year>) <article-title>TOAM - Trajectory of a Memory Trace. Human episodic memory 7T fMRI dataset</article-title>. <source>OpenNeuro</source>. <pub-id pub-id-type="accession">10.18112/openneuro.ds006266.v1.0.2</pub-id> <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds006266/versions/1.0.2">https://openneuro.org/datasets/ds006266/versions/1.0.2</ext-link></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109530.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ryan</surname>
<given-names>Tomás J</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0121-8514</contrib-id>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/02tyrky19</institution-id><institution>Trinity College Dublin</institution>
</institution-wrap>
<city>Dublin</city>
<country>Ireland</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
</front-stub>
<body>
<p>This is a potentially <bold>important</bold> paper attempting to identify neutral correlates of memory engram expression in humans, and how they change during forgetting. The questions posed are clear and novel. The methods employed, namely behavioral analysis, high-resolution functional magnetic resonance imaging, and representational similarity analysis, are advanced, integrative, and appropriate. The experiments are well designed and combine analysis of recollection and familiarity of object/face associations. However, substantial questions remain as to the validity of the <bold>incomplete</bold> statistical analyses applied to the imaging data, as well as the parsing of and interpretation of the behavioral data.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109530.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This manuscript presents an ambitious attempt to examine whether episodic memory traces (&quot;engrams&quot;) of forgotten associations persist in the human brain and whether these traces continue to influence behavior implicitly. Using 7T fMRI, the authors track 96 one-shot face-object associations across learning, 30-minute retrieval, and 24-hour retrieval, complemented by a recognition test. Participants classify each memory as sure, unsure, or guess, enabling an operational dissociation between consciously accessible and inaccessible memories.</p>
<p>Strengths:</p>
<p>The study addresses a timely and theoretically important question arising from rodent engram research, i.e., whether forgotten human memories leave detectable neural signatures. The use of high-resolution 7T fMRI, representational similarity analysis (RSA), and gPPI connectivity analyses aims at a detailed systems-level perspective. The results suggest that correct guess responses (i.e., when participants believe they are guessing) are accompanied by hippocampal activity and connectivity patterns that correlate with behavioral performance, potentially pointing to residual memory traces. The study also presents evidence for divergent consolidation trajectories: consciously accessible memories become more neocortically distributed after sleep, whereas inaccessible memories exhibit strengthened hippocampal signatures.</p>
<p>Weaknesses:</p>
<p>Despite the methodological rigor, some interpretational issues merit caution. First, the reliance on participants' subjective &quot;guess&quot; reports to categorize trials as forgotten is problematic. Guess responses at the 30-minute retrieval were at chance level, whereas guess responses during recognition were above chance; interpreting both as &quot;implicit episodic memory&quot; may conflate different mechanisms (episodic retrieval, familiarity, associative priming).</p>
<p>Second, several analyses raise concerns about circularity or insufficient independence, for example, when contrasting correct vs. incorrect guess trials to locate &quot;engram&quot; activity and then correlating that activity with guessing accuracy. Similarly, the behavioral analyses are fragmented (multiple t-tests across conditions) rather than using a factorial model that accounts for dependencies among confidence levels and timepoints.</p>
<p>Third, the choice to include only &quot;sure&quot; and &quot;guess&quot; responses discards a substantial portion of trials (&quot;unsure&quot;), reducing power and complicating interpretation, especially given that unsure responses show above-chance performance.</p>
<p>Finally, the study's two-scanner-sequence design (small-FOV vs. whole-brain) is challenging as it complicates comparisons across analyses, especially when some critical results (e.g., hippocampal reinstatement patterns) do not consistently replicate across sequences.</p>
<p>Conclusion:</p>
<p>Overall, the manuscript provides preliminary evidence that neural traces of forgotten episodic memories might persist in humans and could guide behavior in the absence of conscious awareness. While interpretational caution is warranted, especially regarding the nature of &quot;guess&quot;-based retrieval and the independence of neural contrasts, the study makes a valuable contribution to debates on engram persistence, systems consolidation, and the role of consciousness in episodic memory.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109530.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The goal of the experiment was to identify the fMRI neural correlates of persistence and recovery of forgotten memories. A forgotten memory was defined behaviorally as successful learning, followed by failure in a recall format task, followed by next-day success in a recognition format task. The comparison is to memories that were not forgotten at any stage of the task. Various univariate, connectivity, and multivariate analyses were used to identify neural correlates of forgotten memories that were recovered, that remained forgotten, and successful memory. Some claims are made about how activity of the &quot;episodic memory network&quot; predicts the persistence of forgotten memories.</p>
<p>Strengths:</p>
<p>Studies on the persistence of forgotten memories in rodent models have been used to make some novel claims about the potential properties of engrams. Attempting similar research in humans is a laudable goal.</p>
<p>Patterns of behavioral responses are consistent across subjects.</p>
<p>Weaknesses:</p>
<p>I do not find that the fMRI results fit the narrative provided.</p>
<p>A major issue is that primary results do not replicate across the two fMRI datasets that were collected using the same task. For example, hippocampal activity associated with correct responses (confident and guess) was identified in the group receiving the fMRI scan that used a small FOV, but not in the group that received an fMRI scan of the whole brain, for both 30-min and 24-hr delays (lines 202-217). This suggests that the main findings are not even replicable internally within the same experiment. There is no reasonable justification for this.</p>
<p>Next, most of the reported fMRI findings do not meet reasonable thresholds for statistical significance. In many places, the authors acknowledge this in the text by saying that a difference in the fMRI metric &quot;tended towards significant correlation&quot; or that comparisons &quot;revealed non-significant mean value comparisons&quot;. It is not clear why these non-significant findings are interpreted as though they are positive findings. Beyond that, many of the reported findings are not meeting the threshold (i.e., p=0.058), without any acknowledgement that they are marginal. Beyond that, the majority of comparisons that are interpreted in the main text are not significant based on the companion information provided in the supplementary tables. That is, they are totally non-significant when using FWE or FDR correction at either the cluster or peak levels.</p>
<p>Beyond this, the supplementary tables indicate that &quot;clusters identified solely within white matter regions have been excluded.&quot; The fact that there are any findings in white matter to ignore indicates that the statistical thresholds are inappropriate. It's tantamount to seeing activation in the brain of a dead fish.</p>
<p>The overall picture based on these factors is that the statistical tests did not use sufficiently stringent safeguards against false positives given the multiple comparison problem that plagues fMRI. So, there are tons of false positives, which are being selectively interpreted to tell a particular story. That is, each comparison yields lots of findings in many brain area, and those that do not fit the particular narrative are being ignored (including those in white matter). What's more, when the small FOV fMRI scan is done, the imaging volume is centered on the hippocampus and its close network, so all false positives appear to be exactly in those brain regions about which the authors want to make conclusions. When throwing darts, you will always hit a bullseye if that is all that exists. The fact that the same comparisons done in the companion whole-brain dataset do not yield the same results is telling: the analysis plan is not sufficiently rigorous to yield findings that are replicable.</p>
<p>Further, I think that it is highly debatable whether the task measures the recovery of forgotten memories at all. Forgotten memories are defined as those that fail when tested using a recollection format but succeed when tested using a recognition format. The well-characterized distinction between recollection and recognition is thus being construed as telling us something about the fate of engrams. I think the much more likely alternative is that &quot;forgotten&quot; memories are just relatively weak memories that don't meet whatever criteria subjects typically use when making recollection judgments, and not some special category of memory. In terms of brain activation, they seem for the most part to follow the pattern of stronger memory, but weaker.</p>
<p>Finally, many hypotheses are used as though they are proven. For instance, fMRI activity patterns are called &quot;engrams&quot; even though there are no tests to determine whether they meet reasonable criteria that have been adopted in the engram literature (e.g., necessity, sufficiency). Whatever happens over the 24-hour delay is called &quot;consolidation&quot; even if there is no test that consolidation has occurred. Etc. It becomes hard to differentiate what is an assumption, versus a hypothesis, versus an inference/conclusion.</p>
</body>
</sub-article>
</article>