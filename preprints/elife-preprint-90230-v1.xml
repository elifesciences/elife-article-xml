<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">90230</article-id>
<article-id pub-id-type="doi">10.7554/eLife.90230</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.90230.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title><italic>ChatGPT</italic> identifies gender disparities in scientific peer review</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7582-802X</contrib-id>
<name>
<surname>Verharen</surname>
<given-names>Jeroen P. H.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Molecular and Cell Biology and Helen Wills Neuroscience Institute, University of California</institution>, Berkeley, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Rodgers</surname>
<given-names>Peter</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>eLife</institution>
</institution-wrap>
<city>Cambridge</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Rodgers</surname>
<given-names>Peter</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>eLife</institution>
</institution-wrap>
<city>Cambridge</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence to: <email>jeroenverharen@berkeley.edu</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-08-08">
<day>08</day>
<month>08</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP90230</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-06-22">
<day>22</day>
<month>06</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-07-19">
<day>19</day>
<month>07</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.18.549552"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Verharen</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Verharen</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-90230-v1.pdf"/>
<abstract>
<p>The peer review process is a critical step in ensuring the quality of scientific research. However, its subjectivity has raised concerns. To investigate this issue, I examined over 500 publicly available peer review reports from 200 published neuroscience papers in 2022-2023. OpenAI’s generative artificial intelligence <italic>ChatGPT</italic> was used to analyze language use in these reports. This analysis found high levels of variability in how each reviewer scored the same paper, indicating the presence of subjectivity in the peer review process. The results also revealed that female first authors received less polite reviews than their male peers, indicating a gender bias in reviewing. Furthermore, published papers with a female senior author received more favorable reviews than papers with a male senior author, suggesting a gender disparity in academic publishing. This study highlights the potential of generative artificial intelligence in identifying areas of concern in scientific peer review and underscores the need to enhance transparency and objectivity in the scientific publishing process.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The peer review process is a crucial step in the publication of scientific research, where manuscripts are evaluated by independent experts in the field before being accepted for publication. This process helps ensure the quality and validity of scientific research and is a cornerstone of scientific integrity. Despite its importance, concerns have been raised regarding subjectivity in this process that may affect the fairness and accuracy of evaluations<sup><xref ref-type="bibr" rid="c1">1</xref>-<xref ref-type="bibr" rid="c5">5</xref></sup>. Indeed, most journals engage in single-blind peer review, in which the reviewers have information about the authors of the paper, but not vice versa. While some studies have found evidence of disparities in peer review as a result of gender bias, the scope and methodology of these studies are often limited<sup><xref ref-type="bibr" rid="c6">6</xref>-<xref ref-type="bibr" rid="c8">8</xref></sup>. For example, in one case study, a biology journal observed an increase in papers from female first authors after introduction of double-blind peer review<sup><xref ref-type="bibr" rid="c6">6</xref></sup>. Additionally, other factors, such as the seniority and institutional affiliation of authors, may influence the evaluation process and lead to biased assessments of research quality<sup><xref ref-type="bibr" rid="c7">7</xref></sup>. As such, papers from more prestigious research institutions may receive better peer reviews<sup><xref ref-type="bibr" rid="c9">9</xref></sup>. It is crucial to identify potential sources of disparity in the reviewing process to maintain scientific integrity and find areas for improvement within the scientific pipeline.</p>
<p>Natural language processing tools have shown promise in analyzing large amounts of textual data and extracting meaningful insights from evaluations<sup><xref ref-type="bibr" rid="c10">10</xref>-<xref ref-type="bibr" rid="c12">12</xref></sup>. However, applying these tools to scientific peer review has been challenging due to the specialized construction and language use in such reports. Past attempts to use natural language processing to analyze peer review reports have often been limited by small dataset sizes or the complexity of the text<sup><xref ref-type="bibr" rid="c13">13</xref>-<xref ref-type="bibr" rid="c15">15</xref></sup>. Recent advances in generative artificial intelligence, such as OpenAI’s <italic>ChatGPT</italic>, offer new possibilities for studying scientific peer review. These models can process vast amounts of text and provide accurate sentiment scores and language use metrics for individual sentences and documents. As such, using generative artificial intelligence to study scientific peer review may ultimately help improve the overall quality and fairness of scientific publications and identify areas of concern in the way towards equitable academic research.</p>
<p>This study had three main objectives. The first was to test whether the latest advances in generative artificial intelligence, such as OpenAI’s <italic>ChatGPT</italic>, can be used to analyze language use in scientific peer reviews. The second aim was to explore subjectivity in peer review by looking at consistency in favorability across reviews for the same paper. The last aim was to test whether the identity of the authors, such as institutional affiliation and gender, affect the favorability and language use of the reviews they receive.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>An analysis of scientific peer review</title>
<p><italic>Nature Communications</italic> has engaged in transparent peer review since January 2016, giving authors the option to publish the peer review history of their paper<sup><xref ref-type="bibr" rid="c16">16</xref></sup>. To explore language use in these reports, I downloaded the primary (i.e., first-round) reviews from the last 200 papers in the neuroscience field published in this journal. This yielded a total of 572 reviews from 200 papers, with publications dates ranging from August 2022 to February 2023. Additional metrics of these papers were manually collected (<bold><xref rid="fig1" ref-type="fig">Fig. 1a</xref> and <xref ref-type="fig" rid="fig1">1b</xref></bold>), including the total review time of the paper, the subfield of neuroscience, the geographical location and QS World Ranking score of the senior author’s institutional affiliation, the gender of the senior author, and whether the first author had a male or female name (see <bold>Methods</bold> for more information on classifications and a rationale for the chosen metrics). These metrics were collected to test whether they influenced the favorability and language use of the reviews that a paper received.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Characteristics of the 200 papers included in this analysis</title>
<p>(<bold>a</bold>) Paper metrics. (<bold>b</bold>) Author metrics. More information on how these metrics were collected and defined can be found in the <bold>Methods</bold> section.</p></caption>
<graphic xlink:href="549552v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2b">
<title>Sentiment analysis</title>
<p>To assess the sentiment and language use of each of the peer review reports, I asked OpenAI’s generative artificial intelligence <italic>ChatGPT</italic> to extract two scores from each of the reviews (<bold><xref rid="fig2" ref-type="fig">Fig. 2a</xref></bold>). The first score was the <italic>sentiment score</italic>, and measures how favorable the review is. This metric ranges from -100 (negative) to 0 (neutral) to +100 (positive). Sentiment reflects the reviewer’s opinion about the paper and is what presumably drives the decision for a paper to be accepted or rejected. The second score was the <italic>politeness score</italic>, which evaluates how polite a review’s language is, measured on a scale from -100 (rude) to 0 (neutral) to +100 (polite). <italic>ChatGPT</italic> was able to extract sentiment and politeness scores for all of the 572 reviews, and usually included a reasoning of how it established the score (<bold><xref rid="figS1" ref-type="fig">Supplementary Fig. 1</xref></bold>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Sentiment analysis on peer review reports using generative artificial intelligence</title>
<p>(<bold>a</bold>) OpenAI’s generative artificial intelligence model <italic>ChatGPT</italic> was used to extract a sentiment and politeness sores for each of the 572 first-round reviews. Shown is an example query and <italic>ChatGPT</italic>’s answer.</p>
<p>(<bold>b</bold>) Histograms showing the distribution in sentiment (top) and politeness (bottom) scores for all reviews.</p>
<p>(<bold>c</bold>) Scatter plot showing the relation between sentiment and politeness scores for the reviews (60% variance explained in third-degree polynomial). Insets show excerpts from selected peer reviews. Inset in the bottom right corner is a visual depiction of the expected selection bias in this dataset, as only papers accepted for publication were included in this analysis (gray area represents full pool of published and unpublished papers; not to scale).</p></caption>
<graphic xlink:href="549552v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The accuracy and consistency of the generated scores was validated in four different ways. First, for a representative sample of the reviews, I read both the review and <italic>ChatGPT</italic>’s reasoning of how it came to the scores (for examples see <bold><xref rid="figS1" ref-type="fig">Supplementary Fig. 1</xref></bold>). I established that the algorithm was able to extract the most important sentences from each of the reviews and to provide a plausible score. Second, since generative artificial intelligence can provide different answers every time it is prompted, the algorithm was asked to provide scores for each review twice. This yielded a significant correlation between the first and second iteration of scoring (<italic>P</italic> &lt; 0.0001 for both sentiment and politeness scores; <bold><xref rid="figS2" ref-type="fig">Supplementary Fig. 2</xref></bold>); the average of the two scores was used for all subsequent analyses in this paper. Third, manipulated reviews (in which I manually re-wrote a ‘neutral’ review in a more rude, polite, negative or positive manner) were input into <italic>ChatGPT</italic>, which confirmed that this changed the review’s politeness and sentiment scores, respectively (<bold><xref rid="figS3" ref-type="fig">Supplementary Fig. 3</xref></bold>). Finally, for a subset of reviews, <italic>ChatGPT’</italic>s scores were compared to that of seven human scorers that were blinded to the algorithm’s scores (<bold><xref rid="figS4" ref-type="fig">Supplementary Fig. 4</xref></bold>). Interestingly, there was high variability across human scorers, but their average score had a high correlation to that of <italic>ChatGPT</italic> (linear regression for sentiment score: R<sup>2</sup> = 0.91, <italic>P</italic> = 0.0010; for politeness score: R<sup>2</sup> = 0.70, <italic>P</italic> = 0.018). Together, these validations indicate that <italic>ChatGPT</italic> can accurately score the sentiment and politeness of scientific peer reviews.</p>
<p>The majority of the 558 peer reviews (90.1%) were of positive sentiment; 7.9% were negative; 2% were neutral (i.e., a sentiment score of 0) (<bold><xref rid="fig2" ref-type="fig">Fig. 2b</xref></bold>). 99.8% of reviews were deemed polite by the algorithm (i.e., a positive politeness score), only 1 review was scored as rude (i.e., a negative politeness score; <bold><xref rid="fig2" ref-type="fig">Fig. 2c</xref></bold>, bottom left inset). A regression analysis indicated a strong relation between the reviews’ sentiment and politeness scores (60% of variance explained in a third-degree polynomial regression) (<bold><xref rid="fig2" ref-type="fig">Fig. 2c</xref></bold>). Thus, the more positive a review, the more polite the reviewer’s language generally is. It is important to note here that the papers included in this analysis were ultimately accepted for publication in <italic>Nature Communications</italic>, which has a low acceptance rate of 7.7%. As a result of this selection, there will be an over-representation of positive scores in this analysis (<bold><xref rid="fig2" ref-type="fig">Fig. 2c</xref></bold>, bottom right inset).</p>
</sec>
<sec id="s2c">
<title>Consistency across reviewers</title>
<p>If a research paper meets certain objective standards of quality, one can reasonably expect that reviewers evaluating that paper would share a common view on its overall sentiment. To investigate if this is the case, I analyzed the consistency across review scores for the same paper (<bold><xref rid="fig3" ref-type="fig">Fig. 3</xref></bold>). As expected, the overall distribution of sentiment and politeness scores did not differ between the first three reviewers (<bold><xref rid="fig3" ref-type="fig">Fig. 3a</xref></bold>). Interestingly, a cross-correlational analysis of sentiment scores across reviewers indicated very low, if any, correlation between the sentiment scores of reviews for the same paper (<bold><xref rid="fig3" ref-type="fig">Fig. 3b</xref></bold>). The maximum variance explained in sentiment scores between reviewers was 5.5% (between reviewer 1 and 3; the only comparison that reached statistical significance). This surprising result indicates high levels of disagreement between the reviewers’ favorability of a paper, suggesting that the peer review process is subjective.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Consistency across reviews</title>
<p>(<bold>a</bold>) Sentiment (left) and politeness (right) scores for each of the 3 reviewers. The lower sample size for reviewer 3 is because 42 papers received only 2 reviews. No significant effects were observed of reviewer number on sentiment (mixed effects model, <italic>F</italic>(1.929, 343.3) = 1.564, <italic>P</italic> = 0.2116) and politeness scores (mixed effects model, <italic>F</italic>(1.862, 331.4) = 1.638, <italic>P</italic> = 0.1977).</p>
<p>(<bold>b</bold>) Cross-correlations showing low consistency of sentiment scores across reviews for the same paper. The sentiment scores between reviewers 1 and 3 (middle panel) is the only comparison the reached statistical significance (<italic>P</italic> = 0.0032), albeit with a low amount of variance explained (5.5%).</p>
<p>(<bold>c</bold>) Linear regression indicating a relation between a paper’s sentiment scores and the time a paper was under review. For this analysis, reviews were first split into a paper’s lowest, median (only for papers with an odd number of reviews) and highest sentiment score. The lowest and median sentiment score of a paper significantly predicted a paper’s review time, but its highest sentiment score did not. Note that the relation between politeness scores and review time were not individually tested given the high correlation between sentiment and politeness, thus having a high chance of finding spurious correlations. The metric ‘% variance in review time explained’ denotes the R<sup>2</sup> value of the linear regression.</p></caption>
<graphic xlink:href="549552v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>I then looked at the relation between a paper’s review scores and its review time (i.e., the time from paper submission to acceptance). For this analysis, review scores were first classified as the lowest, median (only for papers with an odd number of reviewers), or highest for a paper (<bold><xref rid="fig3" ref-type="fig">Fig. 3c</xref></bold>). A linear regression analysis indicated that the median sentiment score was the best predictor of a paper’s review time (R<sup>2</sup> = 0.0670, <italic>P</italic> = 0.0002), followed by the lowest sentiment score (R<sup>2</sup> = 0.1404, <italic>P</italic> &lt; 0.0001) (<bold><xref rid="fig3" ref-type="fig">Fig. 3c</xref></bold>, bottom left panels). Interestingly, a paper’s highest sentiment score did not significantly predict review time (R<sup>2</sup> = 0.0088, <italic>P</italic> = 0.1874).</p>
</sec>
<sec id="s2d">
<title>Exploring disparities in peer review</title>
<p>To explore potential sources of disparities in scientific publishing, I correlated the review scores, pooled across all papers, with the different paper and author metrics that were collected earlier (<bold><xref rid="fig1" ref-type="fig">Fig. 1b</xref></bold>). No significant effects were observed between sentiment and politeness scores across the different subfields of neuroscience (<bold><xref rid="fig4" ref-type="fig">Fig. 4a</xref></bold>). With respect to the institutional affiliation of the senior author, no effects were observed between the scores and the continent in which the senior author was based (<bold><xref rid="fig4" ref-type="fig">Fig. 4b</xref></bold>). Additionally, no correlation was observed between the institute’s score on the QS World ranking — an imperfect metric of the institute’s perceived prestige — and the paper’s sentiment and politeness scores (<bold><xref rid="fig4" ref-type="fig">Fig. 4c</xref></bold>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Exploring disparities in peer review</title>
<p>(<bold>a</bold>) Effects of the subfield of neuroscience on sentiment (left) and politeness (right) scores. No effects were observed on sentiment (Kruskal-Wallis ANOVA, <italic>H</italic> = 2.380, <italic>P</italic> = 0.6663) or politeness (Kruskal-Wallis ANOVA, <italic>H</italic> = 8.211, <italic>P</italic> = 0.0842). <italic>n</italic> = 178, 149, 100, 20, 125 reviews per subfield.</p>
<p>(<bold>b</bold>) Effects of geographical location of the senior author on sentiment (left) and politeness (right) scores. No effects were observed on sentiment (Kruskal-Wallis ANOVA, <italic>H</italic> = 1.856, <italic>P</italic> = 0.3953) or politeness (Kruskal-Wallis ANOVA, <italic>H</italic> = 0.5890, <italic>P</italic> = 0.7449). <italic>n</italic> = 239, 208, 103 reviews per continent.</p>
<p>(<bold>c</bold>) Effects of QS World Ranking score of the senior author’ institutional affiliation on sentiment (left) and politeness (right) scores. No effects were observed on sentiment (Linear regression, R<sup>2</sup> = 0.0006, <italic>P</italic> = 0.6351) or politeness (Linear regression, R<sup>2</sup> &lt; 0.0001, <italic>P</italic> = 0.9804). <italic>n</italic> = 430 reviews.</p>
<p>(<bold>d</bold>) Effects of the first author’s name on sentiment (left) and politeness (right) scores. No effects were observed on sentiment (Mann-Whitney test, <italic>U</italic> = 19521, <italic>P</italic> = 0.2131) but first authors with a female name received significantly less polite reviews (Mann-Whitney test, <italic>U</italic> = 17862, <italic>P</italic> = 0.0080). Post-hoc tests on the data split per lowest/median/highest politeness score indicated significantly lower politeness scores for females for the lowest (Mann-Whitney test, <italic>U</italic> = 1987, <italic>P</italic> = 0.0103) and median (Mann-Whitney test, <italic>U</italic> = 965.5, <italic>P</italic> = 0.0026) scores, but not of the highest score (Mann-Whitney test, <italic>U</italic> = 2279, <italic>P</italic> = 0.1607). <italic>n</italic> = 206 (F), 204 (M) reviews for top panels; <italic>n</italic> = 71 (F), 74 (M) papers for lower panel (but <italic>n</italic> = 54 (F), 53 (M) papers for median scores, because not all papers received 3 reviews).</p>
<p>(<bold>e</bold>) Effects of the senior author’s gender on sentiment (left) and politeness (right) scores. Women received more favorable reviews than man (Mann-Whitney test, <italic>U</italic> = 28007, <italic>P</italic> = 0.0481) but no effects were observed on politeness (Mann-Whitney test, <italic>U</italic> = 29722, <italic>P</italic> = 0.3265). Post-hoc tests on the data split per lowest/median/highest sentiment score indicated no effect of gender on the lowest (Mann-Whitney test, <italic>U</italic> = 3698, <italic>P</italic> = 0.7963) and median (Mann-Whitney test, <italic>U</italic> = 1865, <italic>P</italic> = 0.5685) sentiment scores, but the highest sentiment score was higher for women (Mann-Whitney test, <italic>U</italic> = 2852, <italic>P</italic> = 0.0072). <italic>n</italic> = 155 (F), 405 (M) reviews for top panels; <italic>n</italic> = 53 (F), 143 (M) papers for lower panel (but <italic>n</italic> = 39 (F), 102 (M) papers for median scores, because not all papers received 3 reviews). Asterisks indicate statistical significance in Mann-Whitney tests; * <italic>P</italic> &lt; 0.05, ** <italic>P</italic> &lt; 0.01.</p></caption>
<graphic xlink:href="549552v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Finally, I looked at how the gender of the first and senior authors may affect a paper’s review scores. First authors with a female name received significantly more impolite reviews, but no effect was observed on sentiment (<bold><xref rid="fig4" ref-type="fig">Fig. 4d</xref></bold>). When analyzing these same reviews split by low/median/high politeness score, I observed that the lower politeness scores for first authors with a female name was driven by significantly lower low and median scores (<bold><xref rid="fig4" ref-type="fig">Fig. 4d</xref></bold>, bottom panel). Conversely, female senior authors received significantly higher sentiment scores, indicating more favorable reviews, but these reviews did not differ in terms of politeness (<bold><xref rid="fig4" ref-type="fig">Fig. 4e</xref></bold>). An analysis of reviews split by low/median/high sentiment score indicated that the reviewer that gave the most favorable review to female senior authors did so with a significantly higher score (<bold><xref rid="fig4" ref-type="fig">Fig. 4e</xref></bold>, bottom panel). No interactions on scores were observed between the genders of the first and senior authors (<bold><xref rid="figS5" ref-type="fig">Supplementary Fig. 5</xref></bold>).</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Peer review is a crucial component of scientific publishing. It helps ensure that research papers are of high quality and have been scrutinized by experts in the field. However, the potential for subjectivity in the peer review process has been an ongoing concern. For example, implicit or explicit bias of reviewers may lead to disparities in peer review scores on the basis of gender or institutional affiliation. In this study, I used natural language processing tools embedded in OpenAI’s <italic>ChatGPT</italic> to analyze over 500 peer review reports from 200 papers that were accepted for publication in <italic>Nature Communications</italic> within the past year. I found that this approach was able to provide consistent and accurate scores, indicating that generative artificial intelligence can be an easy and useful tool in studying scientific peer review. The findings reveal several key insights into the peer review process and highlight potential areas of concern within academic publishing.</p>
<p>First, this study found that evaluations of the same manuscript varied considerably among different reviewers. This finding suggests that the peer review process may be subjective, with different reviewers having different opinions on the quality and validity of the research. This subjectivity may be due to the different backgrounds, experiences, and biases of the reviewers. The inconsistency in the evaluations emphasizes the need for greater standardization in the peer review process, with clear guidelines and protocols that can minimize such discrepancies<sup><xref ref-type="bibr" rid="c17">17</xref></sup>.</p>
<p>I also investigated disparities in peer review based on the institutional affiliation of the senior author of a paper. Specifically, I looked at the geographic location (continent) as well as the score of the institute in the 2023 QS World University Rankings. This analysis revealed no relation of these two metrics with the sentiment and politeness of the reviews, suggesting that evaluations were not influenced by the geographical location and perceived prestige of the senior author’s research institution. This finding is encouraging and suggests that peer review may be based on the quality and merit of the research rather than the authors’ research institute. That said, the identity of the peer reviewers is not known, so it cannot be tested whether reviewers have a bias with respect to authors from a more closely related country, culture or institution (i.e., in-group favoritism).</p>
<p>This study further found that first authors with a female name received less polite reviews than first authors with a male name, although this did not affect the favorability of their reviews. Regardless, this disparity is worrisome as it may indicate an unconscious gender bias in review writing that may ultimately impact the confidence and motivation of (especially early-stage) female researchers. One may argue that the effect size of gender on politeness scores is small, but given the selection bias in this dataset (<bold><xref rid="fig2" ref-type="fig">Fig 2c</xref></bold>, bottom right inset), this effect may be larger in the entire pool of reviewed manuscripts (i.e., rejected + accepted). To address this issue, double-blind peer review, where the authors’ names are anonymized, could be implemented. Double-blind peer review has been debated before, but has come under scrutiny for various reasons<sup><xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c19">19</xref></sup>. Another — arguably more simple — solution could be for reviewers to be more mindful of their language use. Indeed, even negative reviews can be written in a polite manner (<bold><xref rid="fig2" ref-type="fig">Fig. 2c</xref></bold>), and reviewers may want to use <italic>ChatGPT</italic> to extract a politeness score for their review before submitting.</p>
<p>Additionally, female senior authors received more favorable reviews than male senior authors in this pool of accepted papers. This disparity in sentiment score in favor of women may be surprising given the wealth of data showing unconscious bias against women, including in scientific research<sup><xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c21">21</xref></sup>. It is therefore likely that the observed effect is due to selection bias elsewhere in the publishing process. There may be two potential sources of this bias. The first one is that female senior authors may submit better papers to this journal than their male peers, such that the observed gender effect on sentiment is representative for the entire pool of submitted manuscript (i.e., rejected + accepted). This could be the result of institutional barriers that lead to a small, but highly talented pool of female principal investigators<sup><xref ref-type="bibr" rid="c22">22</xref></sup> that submits better papers than their male peers<sup><xref ref-type="bibr" rid="c23">23</xref></sup>. Alternatively, women may have a higher level of self-imposed quality control<sup><xref ref-type="bibr" rid="c24">24</xref></sup>, such that men submit more variable quality papers to high-impact journals like <italic>Nature Communications</italic>. In the imperfect process that is editorial decision making, this may lead to the publication of certain lower-quality papers from male senior authors. The second explanation may be related to an (unconscious) selection bias in the editorial process<sup><xref ref-type="bibr" rid="c25">25</xref></sup>, requiring female senior authors to have better papers before being sent out for peer review, or better scores before being invited for a revise-and-resubmit. As such, paper acceptance may serve as a collider variable<sup><xref ref-type="bibr" rid="c26">26</xref>,<xref ref-type="bibr" rid="c27">27</xref></sup>, inducing a spurious association between gender of the senior author and sentiment score. Further research is required to investigate the reasons behind this effect and to identify in what level of the academic system these differences emerge.</p>
<p>Notably, there are several limitations to this study. The peer review reports I analyzed are all ultimately accepted for publication in <italic>Nature Communications</italic>, meaning that there is a selection bias in the reviews that were included. As such, papers that have received less favorable reviews, or papers that have not been sent out for peer review at all, were not included in this analysis. It is unclear what the gender and institutional affiliation distribution is for the papers that were ultimately unpublished. Additionally, this study only focused on the neuroscience field, and the findings may not generalize to other fields. Similarly, it is not clear if the results from this study apply to journals beyond <italic>Nature Communications</italic>.</p>
<p>Together, this study serves as a proof of concept for the use of natural language processing to analyze scientific peer review. As such, areas of concern were discovered within the academic publishing system that require immediate attention. One such area is the inconsistency between the reviews of the same paper, highlighting the need for greater standardization in the peer review process. Additionally, I uncovered possible gender disparity in academic publishing and reviewing. This research underscores the potential of generative artificial intelligence to evaluate and enhance scientific peer review, which may ultimately lead to a more equitable and just academic system.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Downloading reviews</title>
<p>Reviewer reports were downloaded from the website of <italic>Nature Communications</italic> in February 2023. Only papers that were categorized under <italic>Biological sciences</italic> &gt; <italic>Neuroscience</italic> were included in this analysis. Not all papers had their primary reviewer reports published; to reach the total of 200 papers with primary review reports, the most recently published 283 papers were considered (published between August 16, 2022 and Feb 17, 2023).</p>
<p>Additional paper metrics were subsequently collected. Paper submission and acceptance date were downloaded from the ‘<italic>About this article</italic>’ section on the paper website. Review time was calculated by counting the number of days between these two dates. Research field was manually categorized on the basis of title and abstract of the paper into five different subfields. The affiliation of the senior author was downloaded from the paper website and manually categorized based on continent; if the senior author had affiliations across multiple continents, it was categorized as ‘multiple’ and not used for further analyses (this was the case for 5 papers). The affiliated institutions’ score in the 2023 QS World Ranking was downloaded from the QS World Ranking website (<ext-link ext-link-type="uri" xlink:href="http://TopUniversities.com">TopUniversities.com</ext-link>) in March 2023; the maximum score an institution could receive was 100 (in 2023 this was Massachusetts Institute of Technology). Not all institutions were listed in the QS World Ranking, usually because they were not considered an organization of higher education. If a senior author had multiple affiliations, then the affiliation with the highest score was used. The gender categorization of the first author was based on name only, to reflect that reviewers generally do not know the first author of a paper they review personally (and thus themselves may infer their gender on the name only). This name-based categorization was performed using <italic>ChatGPT</italic> (query: “<italic>Of the following list of international full (first+last) names, can you guess, based on name only, if these people are male, female, or unknown (i</italic>.<italic>e</italic>., <italic>name is not gender specific)?</italic>”). As a confirmation, all names that were assigned a gender by <italic>ChatGPT</italic> were verified using the Genderize database (<italic><ext-link ext-link-type="uri" xlink:href="http://genderize.io">http://genderize.io</ext-link></italic>; probability &gt; 0.5). The gender of the senior author was categorized in a similar manner, except that the categorization for gender-unspecific names was manually completed, usually by looking up the senior author on the research institution’s website or the author’s Google Scholar or Twitter profile. In this manual look up, I tried to find the senior author’s preferred pronouns. If not available, I inferred the senior author’s gender on the basis of a photograph. I did not find evidence that any of the senior authors included in this analysis identified as non-binary; for 4 senior authors I was not able to find or infer their gender. Note that this gender look-up was performed for the senior author, but not for the first author, because reviewers are generally familiar with the senior author of papers they review and thus are likely aware of their gender identity.</p>
</sec>
<sec id="s4b">
<title>Sentiment analysis</title>
<p>Scores of sentiment and politeness of language use of each peer review report was performed using OpenAI’s <italic>ChatGPT</italic> (Version Feb 13, 2023). The prompt consisted of the following question (see <bold><xref rid="fig3" ref-type="fig">Fig. 3a</xref></bold>):</p>
<p><italic>Below you will find a scientific peer review. Such reviews generally contain the reviewer’s sentiment in the first paragraph(s) of the review, followed by a list of specific recommendations to the authors. Can you score this peer review on [1] the sentiment, on a scale from -100 (negative) to 0 (neutral) to 100 (positive), and [2] politeness of language use, on a scale of -100 (rude) to 0 (neutral) to 100 (polite)?</italic> followed by the full text of the peer review. This question was entered into <italic>ChatGPT</italic> twice, and the average of these scores was used for further analyses; for a correlation between the two iterations see <bold><xref rid="figS2" ref-type="fig">Supplementary Fig. 2</xref></bold>.</p>
</sec>
<sec id="s4c">
<title>Statistics</title>
<p>Linear regression and cross-correlational analyses in <bold><xref rid="fig3" ref-type="fig">Fig. 3b</xref> and <xref ref-type="fig" rid="fig3">3c</xref></bold> was performed using JASP 0.16 (University of Amsterdam). For the polynomial linear regression in <bold><xref rid="fig3" ref-type="fig">Fig. 3c</xref></bold>, data were centered by <italic>z</italic>-scoring the individual sentiment and politeness scores. Statistical tests in <bold><xref rid="fig3" ref-type="fig">Fig. 3a</xref> and <xref ref-type="fig" rid="fig4">4</xref></bold> were performed in Prism 9 (GraphPad Inc.). For <bold><xref rid="fig3" ref-type="fig">Fig. 3a</xref></bold>, a mixed effects model was used to compute statistical significance between the reviewers, because repeated measures data was not always available (i.e., not all papers received a third review). To compute statistical significance in <bold><xref rid="fig4" ref-type="fig">Fig. 4a</xref> and <xref ref-type="fig" rid="fig4">4b</xref></bold>, a Kruskal-Wallis ANOVA was used. For <bold><xref rid="fig4" ref-type="fig">Fig. 4c</xref></bold>, significance was calculated using linear regression. For <bold><xref rid="fig4" ref-type="fig">Fig. 4d</xref> and <xref ref-type="fig" rid="fig4">4e</xref></bold>, Mann-Whitney tests were used to compute significance between male and female authors. Significant effects were further studied by splitting the reviews per score (i.e., splitting in lowest, median and highest scores per paper). To calculate statistical significance between male and female authors for lowest/median/highest score in <bold><xref rid="fig4" ref-type="fig">Fig. 4d</xref> and <xref ref-type="fig" rid="fig4">4e</xref></bold>, Mann-Whitney tests were used. Statistical tests were always two-tailed. Note that review scores were not always normally distributed, so non-parametric tests were mostly used. Significance was defined as <italic>P</italic> &lt; 0.05 and denoted with asterisks; * <italic>P</italic> &lt; 0.05, ** <italic>P</italic> &lt; 0.01, *** <italic>P</italic> &lt; 0.001.</p>
</sec>
</sec>
</body>
<back>
<sec id="s5">
<title>Data availability</title>
<p>All data are available as a Supplementary file to this paper.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>J.P.H.V. was supported by a Rubicon postdoctoral fellowship from the Netherlands Organization of Scientific Research. I thank Amanda Tose, Han de Jong and Stephan Lammel for helpful comments on this manuscript.</p>
</ack>
<sec id="s6">
<title>Conflict of interest statement</title>
<p>The author declares no competing interests.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Park</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Peacey</surname>, <given-names>M.W.</given-names></string-name>, <string-name><surname>Munafò</surname>, <given-names>M.R.</given-names></string-name> <article-title>Modelling the effects of subjective and objective decision making in scientfic peer review</article-title>. <source>Nature</source> <volume>506</volume>, <fpage>93</fpage>–<lpage>06</lpage> (<year>2014</year>)</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Lipworth</surname> <given-names>W.L.</given-names></string-name>, <string-name><surname>Kerridge</surname> <given-names>I.H.</given-names></string-name>, <string-name><surname>Carter</surname>, <given-names>S.M.</given-names></string-name>, <string-name><surname>Little</surname>, <given-names>M.</given-names></string-name> <article-title>Journal peer review in context: A qualitative study of the social and subjective dimensions of manuscript review in biomedical publishing</article-title>. <source>Social Science &amp; Medicine</source>, <volume>72</volume>, <fpage>1056</fpage>–<lpage>1063</lpage> (<year>2011</year>)</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>King</surname>, <given-names>E.B.</given-names></string-name>, <string-name><surname>Avery</surname>, <given-names>D.R.</given-names></string-name>, <string-name><surname>Hebl</surname>, <given-names>M.R.</given-names></string-name>, <string-name><surname>Cortina</surname>, <given-names>J.M.</given-names></string-name>, <article-title>Systematic Subjectivity: How Subtle Biases Infect the Scholarship Review Process</article-title>. <source>Journal of Management</source> <volume>44</volume>, <fpage>843</fpage>–<lpage>853</lpage> (<year>2018</year>)</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Lee</surname>, <given-names>C.J.</given-names></string-name>, <string-name><surname>Sugimoto</surname>, <given-names>C.R.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Cronin</surname>, <given-names>B.</given-names></string-name> <article-title>Bias in peer review</article-title>. <source>Journal of the American Society for Information Science and Technology</source> <volume>64</volume>, <fpage>2</fpage>–<lpage>17</lpage> (<year>2013</year>)</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Abramowitz</surname>, <given-names>S.I.</given-names></string-name>, <string-name><surname>Gomes</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Abramowitz</surname>, <given-names>C.V.</given-names></string-name> <article-title>Publish or Politic: Referee Bias in Manuscript Review</article-title>. <source>Journal of Applied Social Psychology</source> <volume>5</volume>, <fpage>187</fpage>–<lpage>200</lpage> (<year>1975</year>)</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Budden</surname>, <given-names>A.E.</given-names></string-name>, <string-name><surname>Tregenza</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Aarssen</surname>, <given-names>L.W.</given-names></string-name>, <string-name><surname>Koricheva</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Leimu</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Lortie</surname>, <given-names>C.J.</given-names></string-name> <article-title>Double-blind review favours increased representation of female authors</article-title>. <source>Trends in Ecology and Evolution</source> <volume>23</volume>, <fpage>4</fpage>–<lpage>6</lpage> (<year>2008</year>)</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Blank</surname>, <given-names>R.M.</given-names></string-name> <article-title>The effects of double-blind versus single-blind reviewing — experimental evidence from the American-Economic review</article-title>. <source>The American economic review</source> <volume>81</volume>, <fpage>1041</fpage>–<lpage>1067</lpage> (<year>1991</year>)</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Lundine</surname>, <given-names>J.</given-names></string-name> <string-name><surname>Bourgeault</surname>, <given-names>I.L.</given-names></string-name>, <string-name><surname>Glonti</surname>, <given-names>K.</given-names></string-name> <string-name><surname>Hutchinson</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Balabanova</surname>, <given-names>D.</given-names></string-name> <article-title>“I don’t see gender”: Conceptualizing a gendered system of academic publishing</article-title>. <source>Social Science and Medicine</source> <volume>235</volume>, <fpage>112388</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Tomkins</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Heavlin</surname>, <given-names>W.D.</given-names></string-name>, <article-title>Reviewer bias in single-versus double-blind peer review</article-title>, <source>PNAS</source> <volume>114</volume>, <fpage>12708</fpage>–<lpage>12713</lpage> (<year>2017</year>)</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="book"><string-name><surname>Chowdhary</surname>, <given-names>K.R.</given-names></string-name>, <chapter-title>Natural Language Processing</chapter-title>. <source>In: Fundamentals of Artficial Intelligence</source>. <publisher-name>Springer</publisher-name>, <publisher-loc>New Delhi</publisher-loc> (<year>2020</year>)</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Hirschberg</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Manning</surname>, <given-names>C.D.</given-names></string-name> <article-title>Advances in natural language processing</article-title>. <source>SCience</source> <volume>349</volume>, <fpage>261</fpage>–<lpage>266</lpage> (<year>2015</year>)</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Yadav</surname>, <given-names>A.</given-names></string-name> <string-name><surname>Vishwakarma</surname>, <given-names>D.K.</given-names></string-name>, <article-title>Sentiment analysis using deep learning architectures: a review</article-title>. <source>Artificial Intelligence Review</source> <volume>53</volume>, <fpage>4335</fpage>–<lpage>4385</lpage> (<year>2020</year>)</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="other"><string-name><surname>Wang</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Wan</surname>, <given-names>X.</given-names></string-name>, <article-title>Sentiment Analysis of Peer Review Texts for Scholarly Papers. SIGIR ‘18: The 41st International ACM SIGIR Conference on Research &amp;</article-title> <source>Development in Information Retrieval</source>, <fpage>175</fpage>–<lpage>184</lpage> (<year>2018</year>)</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="other"><string-name><surname>Chakraborty</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Goyal</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Mukherjee</surname>, <given-names>A.</given-names></string-name>, <source>Aspect-based Sentiment Analysis of Scientific Reviews, JCDL ‘20: Proceedings of the ACM/ IEEE Joint Conference on Digital Libraries in 2020</source>, <fpage>207</fpage>–<lpage>216</lpage> (<year>2020</year>)</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="other"><string-name><surname>Ribeiro</surname>, <given-names>A.C.</given-names></string-name>, <string-name><surname>Sizo</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Lopes Caroso</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Reis</surname>, <given-names>L.P.</given-names></string-name>, <article-title>Acceptance Decision Prediction in Peer-Review Through Sentiment Analysis</article-title>. <source>Progress in Artificial Intelligence</source> (<year>2021</year>)</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><collab>Transparent peer reviewat Nature Communications</collab>. <source>Nature Communications</source> <volume>6</volume>, <fpage>10277</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Tennant</surname>, <given-names>J.P.</given-names></string-name>, <string-name><surname>Ross-Hellauer</surname>, <given-names>T.</given-names></string-name> <article-title>The limitations to our understanding of peer review</article-title>. <source>Research Integrity and Peer Review</source> <volume>5</volume>, <fpage>6</fpage> (<year>2020</year>)</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Alam</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <string-name><given-names>Blinded</given-names> <surname>vs</surname></string-name>. <article-title>unblinded peer review of manuscripts submitted to a dermatology journal: a randomized multi-rater study</article-title>. <source>Clinical and Laboratory Investigations</source> <volume>165</volume>, <fpage>563</fpage>–<lpage>567</lpage> (<year>2011</year>)</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Snodgrass</surname>, <given-names>R.</given-names></string-name> <article-title>Single-versus double-blind reviewing: an analysis of literature</article-title>. <source>ACM SIGMOD Record</source> <volume>35</volume>, <fpage>8</fpage>–<lpage>21</lpage> (<year>2006</year>)</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Blickenstaff</surname>, <given-names>J.C.</given-names></string-name>, <article-title>Women and science careers: leaky pipeline or gender filter?</article-title> <source>Gender and Education</source> <volume>17</volume>, <fpage>369</fpage>–<lpage>386</lpage> (<year>2006</year>)</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Pell</surname>, <given-names>A.N.</given-names></string-name>, <article-title>Fixing the leaky pipeline: women scientists in academia</article-title>. <source>Journal of Animal Science</source> <volume>74</volume>, <fpage>2843</fpage>–<lpage>2848</lpage> (<year>1996</year>)</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Sheltzer</surname>, <given-names>J.M.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>J.C.</given-names></string-name>, <article-title>Elite male faculty in the life sciences employ fewer women</article-title>. <source>PNAS</source> <volume>111</volume>, <fpage>10107</fpage>–<lpage>10112</lpage> (<year>2014</year>)</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Hengel</surname>, <given-names>E.</given-names></string-name>, <article-title>Publishing while female: Are women held to higher standards?</article-title> <source>Evidence from peer review. The Economic Journal</source> <volume>132</volume>, <fpage>2951</fpage>–<lpage>2991</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>White</surname>, <given-names>K.</given-names></string-name>, <article-title>Women and leadership in higher education in Australia</article-title>. <source>Tertiary Education and Management</source> <volume>9</volume>, <fpage>45</fpage>–<lpage>60</lpage> (<year>2010</year>)</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Matías-Guiu</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>García-Ramos</surname>, <given-names>R.</given-names></string-name>, <article-title>Editorial bias in scientific publications</article-title>. <source>Neurología</source> <volume>26</volume>, <fpage>1</fpage>–<lpage>5</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Holmberg</surname>, <given-names>M.J.</given-names></string-name>, <string-name><surname>Andersen</surname>, <given-names>L.W.</given-names></string-name>, <article-title>Collider Bias</article-title>. <source>JAMA</source> <volume>327</volume>, <fpage>1282</fpage>–<lpage>1283</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Griffith</surname>, <given-names>G.J.</given-names></string-name> <etal>et al.</etal>, <article-title>Collider bias undermines our understanding of COVID-19 disease risk and severity</article-title>. <source>Nature Communications</source> <volume>11</volume>, <fpage>5749</fpage> (<year>2020</year>).</mixed-citation></ref>
</ref-list>
<sec id="s7">
<title>Supplementary Figures</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplementary Figure 1:</label>
<caption><title>Validation #1 — Examples of <italic>ChatGPT</italic> inputs and outputs</title></caption>
<graphic xlink:href="549552v1_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Supplementary Figure 2:</label>
<caption><title>Validation #2 — Consistency in sentiment and politeness scores for two different times <italic>ChatGPT</italic> was asked to analyze review reports.</title>
<p>A significant correlation was found between both times <italic>ChatGPT</italic> was asked to score the sentiment and politeness of the peer reviews. The average score of both iterations was used for all subsequent analyses in this paper.</p></caption>
<graphic xlink:href="549552v1_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Supplementary Figure 3:</label>
<caption><title>Validation #3 — Example of a manually manipulated review, showing that <italic>ChatGPT</italic> can pick up artificial changes in sentiment and language use.</title>
<p>It should be noted here that changes in sentiment usually also affected the politeness score (and vice versa), indicating that these scores are not fully independent. This may intuitively make sense; less polite language is often interpreted as more negative, also by human readers (see <bold><xref rid="figS4" ref-type="fig">Supplementary Fig. 4</xref></bold>).</p></caption>
<graphic xlink:href="549552v1_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Supplementary Figure 4:</label>
<caption><title>Validation #4 — Comparison of <italic>ChatGPT</italic>’s scores of sentiment and politeness as compared to seven (blinded) human scorers for a diverse sample of reviews.</title>
<p>Figure showing high levels of variability across human scorers, but their average score had a high correlation with <italic>ChatGPT</italic>’s score. For this experiment, human scorers were asked to score the sentiment of seven reviews on a scale from very negative - negative - neutral - positive - very positive. Politeness was scored on a scale from very rude - rude - neutral – polite - very polite. For the cross-correlograms in the bottom panels, human scores were first converted to numbers on a scale from 1-5, so that these could be correlated to <italic>ChatGPT</italic>’s numerical scores. Scorers 1, 2 and 5 were scientists with a PhD; scorer 3, 4 and 6 were neuroscience graduate students; scorer 7 was a non-scientist. Asterisks indicate significance in a linear regression; * <italic>P</italic> &lt; 0.05, ** <italic>P</italic> &lt; 0.01, *** <italic>P</italic> &lt; 0.001.</p></caption>
<graphic xlink:href="549552v1_figS4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Supplementary Figure 5:</label>
<caption><title>Sentiment and politeness scores for papers in different gender groups.</title>
<p>As an example, ‘F/M’ indicates that the first author had a female name and that the senior author was male. Two-way ANOVAs on these data indicated no significant first × last author gender interaction effects for both sentiment (<italic>F</italic>(1,397) = 0.05291, <italic>P</italic> = 0.8182) and politeness (<italic>F</italic>(1,397) = 0.02808, <italic>P</italic> = 0.8670). <italic>n</italic> = 73 reviews for F/F, 126 for F/M, 44 for M/F, 158 for M/M.</p></caption>
<graphic xlink:href="549552v1_figS5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.90230.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Rodgers</surname>
<given-names>Peter</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>eLife</institution>
</institution-wrap>
<city>Cambridge</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study used ChatGPT to assess certain linguistic characteristics (sentiment and politeness) of 500 peer reviews for 200 neuroscience papers published in Nature Communications. The vast majority of reviews were polite, but papers with female first authors received less polite reviews than papers with male first authors, whereas papers with a female senior author received more favourable reviews than papers with a male senior author. Overall, the study is an <bold>important</bold> contribution to work on gender bias, but the evidence that generative AI programs like ChatGPT have the potential to be applied in meta-research is <bold>incomplete</bold>, especially given the lack of a comparison to the many existing and already-validated tools for sentiment analysis based on natural language processing.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.90230.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Strengths:</p>
<p>The innovative method is the biggest strength of this article. Moreover, the method can be implemented across fields and disciplines. I myself would like to see this method implemented in a grander scale. The author invested a lot of effort in data collection and I especially commend that ChatGPT assessed the reviews twice, to ensure greater objectivity.</p>
<p>Weaknesses:</p>
<p>I have several concerns regarding the methodology of the article. The first relates to the fact that the sample is not random. The selection of journal and inclusion and exclusion criteria do not contribute well to the strength of the evidence.</p>
<p>An important methodological fact is that the correlation between the two assessments of peer reviews was actually lower than we would expect (around 0.72 and 0.3 for the different linguistic characteristics). If the ChatGPT gave such different scores based on two assessments, should it not be sound to do even more assessments and then take the average?</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.90230.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Strengths include:</p>
<p>1. Given the variability in responses from ChatGPT, the author pooled two scores for each review and demonstrated significant correlation between these two iterations. He confirmed also reasonable scoring by manipulating reviews. Finally, he compared a small subset (7 papers) to human scorers and again demonstrated correlation with sentiment and politeness.</p>
<p>2. The figures are consistently well presented and informative. Figure 2C nicely plots the scores with example reviews. The supplementary data are also thoughtful and include combination of first/last author genders. It is interesting that first author female last author male has the lowest score.</p>
<p>3. A series of detailed analysis including breaking down reviews by subfield (interesting to see the wide range of reviewer sentiment/politeness scores in computational papers), institution, and author's name and inferred gender using Genderize. The author suggests that peer review to blind the reviewers to authors' gender may be helpful to mitigating the impoliteness seen.</p>
<p>Weaknesses include:</p>
<p>1. This study does not utilize any of the wide range of Natural Language Processing (NLP) sentiment analysis tools. While the author did have a small subset reviewed by human scorers, the paper would be strengthened by examining all the reviews systematically using some of the freely available tools (for example, many resources are available through Hugging Face [<ext-link ext-link-type="uri" xlink:href="https://huggingface.co/blog/sentiment-analysis-python">https://huggingface.co/blog/sentiment-analysis-python</ext-link> ]). These methods have been used in previous examinations of review text analysis (Luo et al. 2022. Quantitative Science Studies 2:1271-1295). Why use ChatGPT rather than these older validated methods? How does ChatGPT compare to these established methods? See also: <ext-link ext-link-type="uri" xlink:href="http://colab.research.google.com/drive/1ZzEe1lqsZIwhiSv1IkMZdOtjPTSTlKwB?usp=sharing">colab.research.google.com/drive/1ZzEe1lqsZIwhiSv1IkMZdOtjPTSTlKwB?usp=sharing</ext-link></p>
<p>2. The author's claim in the last paragraph that his study is proof of concept for NLP to analyze peer review fails to take into account the array of literature already done in this domain. The statement in the introduction that past reports (only three citations) have been limited to small dataset sizes is untrue (Ghosal et al. 2022. PLoS One 17:e0259238 contains over 1000 peer review documents, including sentiment analysis) and reflects a lack of review on the topic before examining this question.</p>
<p>3. The author acknowledges the limitation that only papers under neuroscience were evaluated. Why not scale this method up to other fields within Nature Communications? Cross-field analysis of the features of interest would examine if these biases are present in other domains.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.90230.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Strengths:</p>
<p>On the positive side, I thought the use of ChatGPT to score the sentiment of text was novel and interesting, and I was largely convinced by the parts of the methods which illustrate that the AI provides broadly similar sentiment and politeness scores to humans who were asked to rank a sub-set of the reviews. The paper is mostly clear and well-written, and tackles a question of importance and broad interest (i.e. the potential for bias in the peer review process, and the objectivity of peer review).</p>
<p>Weaknesses:</p>
<p>The sample size and scope of the paper are a bit limited, and I have concerns covering diverse aspects including statistical/inferential issues, missing references, and suggestions for other material that could be included that would greatly increase the usefulness of the paper. A major limitation is that the paper focuses on published papers, and thus is a biased sample of all the reviews that were written, which prevents the paper properly answering the questions that it sets out to answer (e.g. is peer review repeatable, fair and objective).</p>
</body>
</sub-article>
</article>