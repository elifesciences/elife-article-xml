<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">91522</article-id>
<article-id pub-id-type="doi">10.7554/eLife.91522</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.91522.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>When Abstract Becomes Concrete: Naturalistic Encoding of Concepts in the Brain</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Kewenig</surname>
<given-names>Viktor</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Vigliocco</surname>
<given-names>Gabriella</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5503-764X</contrib-id>
<name>
<surname>Skipper</surname>
<given-names>Jeremy I</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Experimental Psychology, University College London</institution>, 26 Bedford Way, WC1H 0DS London</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Martin</surname>
<given-names>Andrea E</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Max Planck Institute for Psycholinguistics</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Shinn-Cunningham</surname>
<given-names>Barbara G</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Carnegie Mellon University</institution>
</institution-wrap>
<city>Pittsburgh</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>2</label>Corresponding Author: <email>viktor.kewenig18@ucl.ac.uk</email>; (+44)7821130004</corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-01-10">
<day>10</day>
<month>01</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP91522</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-09-13">
<day>13</day>
<month>09</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-08-01">
<day>01</day>
<month>08</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.09.08.506944"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Kewenig et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Kewenig et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-91522-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Language is acquired and processed in complex and dynamic naturalistic contexts, involving simultaneous processing of connected speech, faces, bodies, objects, etc.. How words and their associated concepts are encoded in the brain during real-world processing is still unknown. Here, the representational structure of concrete and abstract concepts was investigated during movie watching to address the extent to which brain responses dynamically change depending on contextual information. First, across contexts, concrete and abstract concepts are shown to encode different experience-based information in separable sets of brain regions. However, these differences are reduced when multimodal context is considered. Specifically, the response profile of abstract words becomes more concrete-like when these are processed in visual scenes highly related to their meaning. Conversely, when the visual context is unrelated to a given concrete word, the activation pattern resembles more that of abstract conceptual processing. These results suggest that while concepts generally encode habitual experiences, the underlying neurobiological organisation is not fixed but depends dynamically on available contextual information.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>concept representation</kwd>
<kwd>context</kwd>
<kwd>embodied cognition</kwd>
<kwd>naturalistic neuroimaging</kwd>
<kwd>semantic memory</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>We submitted this paper to a journal and got some very helpful reviewer comments that are now included to improve this manuscript.</p></fn>
</fn-group>
</notes>
</front>
<body>
<p>Humans acquire, and process language in situated multimodal contexts, through dynamic interactions with their environment. For example, children may learn what the word ‘tiger’ means primarily via sensory-motor experience: they see one on TV, or they are told that a tiger looks like a big cat. Conversely, the experience required for understanding the more abstract concept ‘good’ will likely include an evaluation of the rational and emotional motives underscoring intentional actions. Consequently, while more concrete concepts have external physical references (they refer to objects or actions that are easily perceived in the world) (Wiemer-Hastings, 2010), more abstract concepts do not necessarily have such reference (they generally refer more to cultural and societal constructs or peoples’ inner states of mind) (Villani, 2019). Is this difference reflected in concrete and abstract representations in the brain during naturalistic processing? And are these static or can they change as a function of the multimodal contexts in which processing occurs?</p>
<p>Most studies of concrete and abstract processing are not naturalistic in that they present words or sentences isolated from the rich contexts in which we usually process them. Collectively, these studies suggest that concrete and abstract concepts engage separate brain regions involved in processing different types of information. (<xref ref-type="bibr" rid="c8">Bedny &amp; Thompson-Schill, 2006</xref>; <xref ref-type="bibr" rid="c10">Binder et al., 2009</xref>; <xref ref-type="bibr" rid="c78">Sabsevitz et al., 2005</xref>; <xref ref-type="bibr" rid="c95">Wang et al., 2010</xref>; <xref ref-type="bibr" rid="c91">Vigliocco et al, 2014</xref>). Concrete words engage regions involved in experiential processing (<xref ref-type="bibr" rid="c6">Barsalou et al., 2003</xref>; <xref ref-type="bibr" rid="c75">Pulvermuller &amp; Fadiga, 2010</xref>). For example, motor related cortices activate during the processing of action verbs like ‘throw’ (<xref ref-type="bibr" rid="c42">Hauk &amp; Pulvermüller, 2004</xref>), or action related nouns like ‘hammer’ (Vigliocco et al, 2006; <xref ref-type="bibr" rid="c52">Kiefer &amp; Pulvermüller, 2012</xref>), auditory cortices for sound-related words like ‘telephone’ (<xref ref-type="bibr" rid="c35">Goldberg et al., 2006</xref>; <xref ref-type="bibr" rid="c53">Kiefer et al., 2008</xref>), and visual cortices for colour-related words like ‘yellow’ (<xref ref-type="bibr" rid="c47">Hsu et al., 2011</xref>; <xref ref-type="bibr" rid="c79">Simmons et al., 2007</xref>). These results are consistent with the view that we learn and neurobiologically encode concrete concepts in terms of the sensory and motor experiences associated with their referents.</p>
<p>In contrast, some studies of abstract concepts have found greater activation in brain regions associated with general linguistic processing (J. R. Binder, 2005; Mellet, 1998; <xref ref-type="bibr" rid="c66">Noppeney et al., 2004</xref>; <xref ref-type="bibr" rid="c78">Sabsevitz et al., 2005</xref>). These findings suggest that abstract concepts are learnt by understanding their role in linguistic context, including semantic relationships with other words (e.g. ‘democracy’ is understood through its relationships to words like ‘people’, ‘parliament’, ‘politics’, etc., e.g. Recchia &amp; Jones, 2012). However, neurobiological data also support the view that subcategories of abstract concepts retain sensorimotor information (<xref ref-type="bibr" rid="c39">Harpaintner et al, 2022</xref>, <xref ref-type="bibr" rid="c38">2020</xref> &amp; 2018; Fernandino et al., 2022) as well as social information (<xref ref-type="bibr" rid="c92">Villani et al., 2019</xref>; <xref ref-type="bibr" rid="c20">Conca et al, 2021</xref>) and internal/interoceptive/affective experiences (<xref ref-type="bibr" rid="c67">Oosterwijk et al., 2015</xref>; <xref ref-type="bibr" rid="c91">Vigliocco et al., 2014</xref>), which are also important for learning abstract concepts (Ponari et al., 2018). Thus, abstract concepts constitute a more heterogeneous category (<xref ref-type="bibr" rid="c77">Roversi et al., 2013</xref>; <xref ref-type="bibr" rid="c102">Zdrazilova et al., 2018</xref>; <xref ref-type="bibr" rid="c92">Villani et al., 2019</xref>; <xref ref-type="bibr" rid="c64">Muraki et al., 2020</xref>; <xref ref-type="bibr" rid="c64">Muraki et al., 2020</xref>; <xref ref-type="bibr" rid="c54">Kiefer et al., 2022</xref>) A limitation of these studies is that they have only investigated processing of decontextualized concepts (see e.g., Table 1 in a recent review by <xref ref-type="bibr" rid="c26">Del Maschio et al., 2022</xref>). That is, they (often implicitly) assume that conceptual representation in the brain is the product of a stable set of regions processing different types of information depending on whether a concept is concrete or abstract. However, this dichotomy may not account for the way in which we typically process concepts (<xref ref-type="bibr" rid="c58">Lebois et al., 2015</xref>), given that the information encoded during conceptual processing depends on the contextual information available. For example, the situated processing of concrete concepts like ‘chair’ could be linked to many abstract internal elements like goals (’I want to rest’), motivations (’I have been standing for two hours’), emotions (’I would like to feel comfortable’), and theory of mind (’is that older person more in the need of this chair than me?’). Conversely, an abstract concept like ‘truth’ is no longer particularly abstract when used in reference to a perceived physical situation (such as ‘snowing’) that matches the utterance’s meaning (’it is true that it is snowing’). Here, ‘truth’ refers to a concrete state of the world (<xref ref-type="bibr" rid="c5">Barsalou et al., 2018</xref>).</p>
<p>Indeed, previous work has postulated flexible conceptual processing in experiential brain circuits (<xref ref-type="bibr" rid="c2">Barclay et al., 1974</xref>; <xref ref-type="bibr" rid="c3">Barsalou, 1982</xref> &amp; 1987). Behavioural data support the view that contextual information can affect conceptual processing (<xref ref-type="bibr" rid="c17">Chambers et al., 2004</xref>; <xref ref-type="bibr" rid="c23">Cooper, 1974</xref>; <xref ref-type="bibr" rid="c84">Tanenhaus et al., 1995</xref>). For example, when an object is depicted in a context consistent with its use, the action associated with using the object is more readily available than when the context is more consistent with picking the object up (<xref ref-type="bibr" rid="c51">Kalenine et al., 2014</xref>). There is also neurobiological evidence that objects visually present in a situation can influence conceptual processing (<xref ref-type="bibr" rid="c45">Hoffman et al., 2013</xref>; <xref ref-type="bibr" rid="c100">Yee &amp; Thompson-Schill, 2016</xref>). For example, the task-related colour-congruency of objects correlates with less activation of brain regions involved in colour perception during processing – likely because less retrieval of detailed colour knowledge was necessary (<xref ref-type="bibr" rid="c47">Hsu et al., 2011</xref>). Dynamic, context-dependent recruitment of visual and motor-related areas during semantic processing has also been established (<xref ref-type="bibr" rid="c46">Hoenig et al, 2008</xref>; <xref ref-type="bibr" rid="c87">van Dam et al, 2012</xref>; <xref ref-type="bibr" rid="c71">Popp et al, 2019</xref>). An understanding of conceptual knowledge as static and context-independent is insufficient to account for these dynamics (<xref ref-type="bibr" rid="c73">Pulvermüller, 2018</xref>).</p>
<p>However, no previous study has addressed whether the concrete/abstract dichotomy is affected by dynamic recruitment of brain areas during semantic processing. The present study aims to fill this gap and test the following two predictions. First, we submit that results from previous investigations of conceptual processing, which generally depict a stable dichotomy between concrete and abstract words, reflect the average experiential information of the type of situational context in which concepts are habitually experienced. Therefore, we predict that the neurobiological representation of concrete concepts, because they retain experiences related to their physical referents that are predominantly characterised by sensory and motor information, will be related to associated brain regions (<xref ref-type="bibr" rid="c74">Pulvermuller, 2018</xref>; <xref ref-type="bibr" rid="c99">Willems et al., 2010</xref>). In contrast, because their representations mostly reflect information related to internal/interoceptive/affective experience as well as the relationship with other words, we expect abstract concepts to activate brain regions associated with emotional, interoceptive, and general linguistic processing (<xref ref-type="bibr" rid="c76">Reinboth &amp; Farkaš, 2022</xref>).</p>
<p>Second, the reviewed work also suggests that these habitual representations are not necessarily stable and might change during naturalistic processing depending on the specific contextual information available. We specify two context conditions: a concept is displaced if its context offers little or no visual information related to the concept’s external sensory-motor features. In contrast, a concept is situated, if its context contains visual objects related to its meaning. We predict that when a concrete concept is processed in displaced situations (e.g., ‘cat’ processed when discussing the general character traits of cats vs dogs), response profiles will shift towards more internalised processing and include regions related to processing of general linguistic information shared with abstract concepts. In contrast, when an abstract concept is processed in a situated context (for example the word ‘love’ processed in a scene with people kissing), its representation will more heavily draw on regions involved in processing external, visual information that otherwise characterise more concrete concepts.</p>
<p>We propose that this erosion of the concrete/abstract dichotomy for contextualised processing shows that both concrete and abstract concepts draw on information related to experience (external and internal) as well as linguistic association. Which associated neurobiological structures are engaged during processing depends dynamically on the contextual information available. This way of thinking about the representational nature of conceptual knowledge may help reconcile contradictory evidence concerning the involvement of different brain areas during conceptual processing.</p>
<sec id="s1">
<title>Materials and Methods</title>
<p>The present study analysed the ‘Naturalistic Neuroimaging Database’ (NNDb) (<xref ref-type="bibr" rid="c1">Aliko et al., 2020</xref>). All code will be made available upon publication on a designated repository under <ext-link ext-link-type="uri" xlink:href="https://github.com/ViktorKewenig">https://github.com/ViktorKewenig</ext-link>.</p>
<sec id="s1a">
<title>Participants and Task</title>
<p>The Naturalistic Neuroimaging Database (<xref ref-type="bibr" rid="c1">Aliko et al., 2020</xref>, <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds002837/versions/2.0.0">https://openneuro.org/datasets/ds002837/versions/2.0.0</ext-link>) includes 86 right-handed participants (42 females, range of age 18–58 years, M = 26.81, SD = 10.09 years) undergoing fMRI while watching one of 10 full-length movies selected across a range of genres. All had unimpaired hearing and (corrected) vision. None had any contraindication for magnetic resonance imaging (MRI), history of psychiatric or neurological disorder, or language-related learning disabilities. All participants gave informed consent, and the study was approved by the University College London Ethics Committee.</p>
</sec>
<sec id="s1b">
<title>Data Acquisition and Preprocessing</title>
<p>Functional and anatomical images were obtained using a 1.5T Siemens MAGNETOM Avanto, equipped with a 32-channel head coil. Whole-brain images were captured, each consisting of 40 slices per volume at an isotropic resolution of 3.2mm. These were obtained using a multiband echo-planar imaging (EPI) sequence with no in-plane acceleration, a multiband factor of 4x, a repetition time of 1 second, an echo time of 54.8 milliseconds, and a flip angle of 75 degrees. Each study participant yielded a number of brain volumes equivalent to movie runtime in seconds. Due to software constraints limiting the EPI sequence to 1 hour of continuous scanning, there were mandatory breaks during the movie for all participants.</p>
<p>The data were preprocessed with AFNI (Cox 1996) and included despiking, slice-time correction, coregistration, blurring and nonlinear alignment to the MNI152 template brain. The time series underwent smoothing using an isotropic full-width half-maximum of 6mm, with detrending accomplished through regressors for motion, white matter, cerebrospinal fluid, and run length. Adjustments were made to account for breaks in movie viewing, and artefacts identified by spatial independent component analysis were regressed out. Detailed information on data acquisition and preprocessing is available in <xref ref-type="bibr" rid="c1">Aliko et al. 2020</xref> and on openneuro.org.</p>
</sec>
<sec id="s1c">
<title>Materials</title>
<p>All words in the movies were annotated using automated approaches with a machine learning based speech-to-text transcription tool from Amazon Web Services (AWS; <ext-link ext-link-type="uri" xlink:href="https://aws.amazon.com/transcribe/">https://aws.amazon.com/transcribe/</ext-link>). The resulting transcripts contained on and offset timings for individual words. However, as not all words were transcribed or accurately transcribed, timings were subsequently corrected manually.</p>
<p>Concrete and abstract words were selected for the present study from existing Brysbaert et al (2013) norms. In this database, 37,058 words were rated for concreteness on a scale from 0 (not experience based) to 5 (experience based) by over 4,000 participants. We median split only content words on this scale to yield our set of concrete and abstract words. These were matched for word frequency within 1 SD of mean log frequency (3.61), using the SUTBLEX (US) corpus (Brybaert &amp; New, 2009), which contains frequency counts for 72,286 words. Concrete and abstract words were also matched to be within 1SD from mean length measured as number of letters (4.81).</p>
<p>After this matching process, we were left with more concrete words than abstract words in all movies (783 on average for concrete words; 440 for abstract words). To maintain equal numbers in the subsequent analysis, we randomly selected a subset of 440 concrete words in each movie to match the amount of abstract words, leaving us with 880 words (half concrete, half abstract) per movie on average. Mean concreteness rating for the resulting set of concrete words was 3.22, compared to 1.83 for abstract words. The final mean log frequency and mean length for the final set of concrete words was 3.69 and 4.91 compared to 3.46 and 5.27 for the final set of abstract words and were not significantly different as determined by t-tests (all ps &gt; .45).</p>
<p>We used luminance and loudness to control for visual and acoustic properties of the movies that might vary more or less for concrete or abstract words. These ‘low-level’ features might be correlated with other potentially confounding auditory and visual variables. For example, luminance correlates significantly with stimulus intensity and contrast (Johnson &amp; Casson, 1995) and loudness correlates with pitch (Wengenroth et al, 2014), prosody (E Couper-Kuhlen et al, 2004), and speaking rate (Kuhlmann et al, 2021). Thus, luminance and loudness for each frame in the movie was measured using the ‘Librosa’ package for music and audio analysis in Python (McFee et al, 2015). We then averaged these measures across the full duration of each word. Mean luminance for concrete words was 0.72, compared to 0.65 for abstract words. These were significantly different (t(4798) = 9.13 p &lt; 0.001). The mean loudness for concrete words was 0.69, compared to 0.77 for abstract words. These were also significantly different (t(4798) = 9.86, p &lt; 0.001).</p>
</sec>
<sec id="s1d">
<title>Conceptual Processing Across Contexts</title>
<p>In this analysis we tested the prediction that when contextual information is collapsed over, the neurobiological organisation of conceptual processing will reflect brain systems involved in experiential information processing, broadly in line with previous studies. Specifically, sensory and motor system engagement for concrete concepts and internal/interoceptive/affective and more general linguistic processing system engagement for abstract concepts. All statistical analyses on the preprocessed NiFTI files were carried out in AFNI (<xref ref-type="bibr" rid="c24">Cox, 1995</xref>, 1997). Individual AFNI programs used are indicated parenthetically or in italics in subsequent descriptions.</p>
</sec>
<sec id="s1e">
<title>Deconvolution Analysis</title>
<p>We used an amplitude (also known as parametric) modulated deconvolution regression to estimate activity associated with concrete and abstract words from the preprocessed fMRI data. In contrast to a standard convolution based regression analysis, deconvolution does not assume a canonical hemodynamic response function. Instead, an impulse response function (IRF) is estimated over a 20s time-window from stimulus onset at one second steps using multiple basis functions. This produces a better understanding of shape differences between individual hemodynamic response functions and achieves higher statistical power at both individual and group level (<xref ref-type="bibr" rid="c19">Chen et al, 2015</xref>). Furthermore, there might be differences in timing for the processing of concrete and abstract words (Kroll &amp; Nerves, 1986). In particular, the ‘concreteness effect’ indicates that concrete words are processed faster and more accurately than abstract words (Paivio et al., 1994; Jessen et al., 2000; Fliessbach et al., 2006). These timing differences can be captured by our approach. We chose a 20s time window because this should be sufficient to capture the hemodynamic response function for each word. We selected ‘Csplin’ over the Tent function to deconvolve the BOLD signal because this function offers more interpolation between time points, which might result in a more precise estimate of the individual response function (but is computationally more costly).</p>
<p>Furthermore, traditional ‘main effect’ analysis confounds various non-specific processes, such as acoustic processing, which co-vary with each presented word (especially during dynamic, naturalistic stimuli). In contrast, amplitude modulation allows us to isolate regions that exhibit activational fluctuations specifically in relation to the concreteness modulator beyond the ‘main effect’ and fluctuations in the amplitude response caused by other modulators included in our model. Including nuisance modulators can help serve as controls, mitigating potentially confounding effects - in our case the significant differences between luminance and loudness. By adjusting for these sensory attributes, we ensure that the final betas from this analysis represent the estimated BOLD response specifically associated with concreteness.</p>
<p>Specifically, we estimated four sets of amplitude modulated IRFs for 1) abstract words; 2) concrete words; 3) remaining words; and 4) other time points. Both concrete and abstract words included word onset and five modulators, two of interest and three nuisance modulators. These were the independent ratings of concreteness and abstractness and luminance, loudness, and duration for each word. We also estimated the IRFs in the same manner and with the same amplitude modulators for all the remaining words in the movie that were not of interest to our hypothesis. Finally, we generated IRFs (without amplitude modulators) for all time points which did not include any speech.</p>
<p>The deconvolution model also included general linear tests for 1) abstract words under the curve; 2) concrete words under the curve; 3) contrasts between concrete and abstract words at each timepoint.</p>
</sec>
<sec id="s1f">
<title>Group Level Analysis</title>
<p>We then used the 20 amplitude modulated beta-coefficients from the concrete-abstract contrasts in a linear mixed effects model for group level analysis using ‘<italic>3dLME’</italic> (<xref ref-type="bibr" rid="c18">Chen et al., 2013</xref>). The model included the factors ‘contrast’ with levels ‘abstract’ and ‘concrete’ and ‘time’ with 20 levels. The model also included a centred covariate for age of participant, and covariates for gender (2 levels) and movie ID (10 levels). Besides a random intercept for participant we included a control implemented in ‘<italic>3dLME’</italic> for the potentially auto-correlative structure of residuals to make sure that we model the true effect estimates of the multiple basis function (Hefley et al., 2017). The final model formula was: <italic>contrast + age + gender + movie</italic>. We included 20 general linear tests, one for each contrast between concrete and abstract activation at each of the 20 timepoints, because we wanted to see how the amplitude of the activation associated with concreteness and abstractness changes over time. We thought that the timing and/or amplitude of the response for concrete and abstract words might vary and that this might be particularly true of the subsequent context analysis. However, we do not further analyse timing differences herein.</p>
</sec>
<sec id="s1g">
<title>Correction for Multiple Comparisons</title>
<p>To correct for multiple comparisons in the LME, we used a multi-threshold approach rather than choosing an arbitrary <italic>P</italic> value at the individual voxel level threshold. In particular, we used a cluster simulation method to estimate the probability of noise-only clusters using the spatial autocorrelation function from the LME residuals (’<italic>3dFWHMx</italic>’ and ‘<italic>3dClustSim</italic>’). This resulted in the cluster sizes to achieve a corrected alpha value of 0.01 at 9 different <italic>P</italic> values (i.e., 0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002, and 0.0001). We thresholded each map at the corresponding z-value for each of these nine p-values and associated cluster sizes. We then combined the resulting maps, leaving each voxel with its original z-value. For additional protection and presentation purposes, we use a minimum cluster size 20 voxels for all results (using ‘3dMerge’). For tables, we determined the centre of mass for each of these clusters using ‘<italic>3dCM’</italic>. See Cox, 2017 for a validation of a related method and <xref ref-type="bibr" rid="c81">Skipper et al., 2022</xref> for an earlier application.</p>
</sec>
<sec id="s1h">
<title>Analyses of experiential features</title>
<p>In order to more closely characterise the functional specificity of the spatial activation maps from the preceding LME analysis, we carried out the following two additional analyses. In both, the goal is to determine whether brain activity associated with concrete and abstract word modulation relates to separable experiential domains that roughly map onto the aforementioned sensory-motor vs internal/interoceptive/affective/linguistic distinction, respectively.</p>
<sec id="s1h1">
<label>1.</label><title>Meta-Analytic Descriptions</title>
<p>The resulting coordinates of the centre of mass of each cluster associated with modulation of concreteness and abstractness were input into Neurosynth (<ext-link ext-link-type="uri" xlink:href="https://neurosynth.org/">https://neurosynth.org/</ext-link>, Yarkoni et al., 2011), an online tool that includes activation maps of 14,371 neuroscientific studies (accessed April, 2023). Neurosynth automatically mines all words in titles and abstracts of these articles and performs a two-way ANOVA, testing for the presence of a non-zero association between terms reporting activation that overlaps with the input location. We scraped all terms with z scores above 3.12 (p &lt; 0.001) (excluding those related to specific brain regions and nondescript terms related to methods, tasks or results) and repeated this procedure for each concrete and abstract cluster to determine functionally associated terms. We then tested whether any of these terms were more important for concrete or abstract words across clusters using a Kruskal Wallis test. We did not correct for multiple comparisons, as this analysis was exploratory in nature and we did not have a prediction about how many terms we would end up with.</p>
</sec>
<sec id="s1h2">
<label>2.</label><title>Peak and Valley Analysis</title>
<p>The meta-analytic approach can only provide relatively general functional descriptions of concrete and abstract words as it is based only on high frequency terms in published titles and abstracts. To provide more precise functional specificity, we used a variant of the ‘reverse correlation’ method (<xref ref-type="bibr" rid="c40">Hasson et al., 2004</xref>), called the ‘Peaks and Valleys Analysis’ (<xref ref-type="bibr" rid="c41">Hasson et al., 2008</xref>; <xref ref-type="bibr" rid="c82">Skipper et al., 2009</xref>). For each participant, this analysis averaged the timeseries of voxels within clusters of modulated activity associated with concreteness and abstractness and relates this directly to features of the perceived stimulus. The approach assumes that, if a brain region encodes certain features, e.g. sensorimotor features, valence, or arousal, then activity will rise (creating peaks) in that region when the feature is present in the stimulus and fall (resulting in valleys) when it is absent.</p>
<p>Specifically, for concrete clusters, we expected significantly more sensory-motor features (i.e., ‘Foot_Leg’, ‘Hand_Arm’, ‘Haptic’, ‘Visual’ and ‘Torso’ in the corpora) to be associated with peaks rather than valleys in the timeseries compared to abstract clusters. Conversely, we expected significantly more experiential features related to internal/interoceptive/affective processing (i.e., ‘Interoception’, ‘Valence’, and ‘Arousal’ in the corpora) to be associated with peaks compared to valleys for abstract relative to concrete clusters. It was not clear to us whether the dimensions (’Auditory’, ‘Head’, ‘Mouth’ and ‘Gustatory’) were more related to internal/interoceptive/affective or sensory-motor processing. Therefore, we made no predictions for those.</p>
<p>To accomplish this, we first extracted the averaged timeseries for each activation cluster for the concrete and abstract modulations across voxels using <italic>3dMerge</italic>. Next, we determined peaks and valleys by calculating the discrete difference ‘Δ’ along the timeseries ‘x’ for each value ‘i’ using the ‘<italic>Numpy</italic>’ Python package (Harris et al, 2020) (<xref rid="fig1" ref-type="fig">Figure 1</xref>, (1)), where Δx[i] = x[i + 1] - x[i]. Given that the canonical model of the hemodynamic response function is said to peak at around 6s after stimulus onset for stimuli of our length, we extracted the words that were mentioned at each peak and valley in a given cluster’s timeseries with a 5- and 6-seconds lag (<xref rid="fig1" ref-type="fig">Figure 1</xref>, (2)). We then used the Lancaster sensorimotor norms (Lynott et al, 2019) and norms for valence and arousal (Warriner, 2013) to determine a 13-dimensional experience-based representation for each word (<xref rid="fig1" ref-type="fig">Figure 1</xref>, (3)), which included the dimensions: ‘Auditory’, ‘Gustatory’, ‘Haptic’, ‘Interoception’, ‘Visual’, ‘Hand_Arm’, ‘Foot_Leg’, ‘Torso’, ‘Mouth’, ‘Head’, ‘Olfactory’, ‘Valence’, and ‘Arousal’.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Overview of the peak and valley analysis method. First, we average the fMRI timeseries for each participant, for each abstract, concrete, and overlap cluster of activity from <xref rid="fig1" ref-type="fig">Figure 1</xref>. Then we label peaks and valleys in these (1) and map them onto word on- and off-set times (2). Finally, we estimate sensorimotor as well as valence and arousal representations for each abstract (blue frame) and concrete word (red frame) (3) and determine which dimensions are associated with significantly more peaks than valleys across participants in each cluster using a Kruskal Wallis test (4).</p></caption>
<graphic xlink:href="506944v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>For each of these dimensions, we created two categorical arrays, one for peaks and one for valleys, noting down 0 if the word mentioned at a peak or valley was not highly rated on the dimension and 1 if it was rated highly. This was defined as a deviation of at least one standard deviation from the mean. Given the distributional nature of this data, we then conducted a Kruskal Wallis test between these arrays to determine whether a given experiential dimension occurred significantly more with peaks than valleys in the averaged timeseries of a cluster (<xref rid="fig1" ref-type="fig">Figure 1</xref>, (4)). We repeated this procedure for both a 5s and a 6s timeseries lag and conducted a cosine-similarity test between each result (using the ‘<italic>Sklearn</italic>’ package in Python (Pedregosa et al, 2011) in order to determine if they were significantly different.</p>
</sec>
</sec>
<sec id="s1i">
<title>Conceptual Processing in Context</title>
<p>The previous analyses tested whether, when activation is considered across contexts, concrete and abstract words are processed in separable brain regions encoding different types of experiential information. Here, we test if these response profiles dynamically change depending on the visual object context. We predict that when abstract concepts are situated in highly related contexts, they engage neurobiological regions that are usually involved in processing concrete concepts and are related to processing of external information (e.g. visual). Conversely, when concrete concepts are displaced from surrounding context, we predict them to engage more abstract-like regions in the brain that are related to processing of internal/interoceptive/affective information. Note that we chose to do the analysis in two stages because only a subset of the 440 words used in our analysis across context for concrete and abstract words are related to the objects present in the scene in a way that situates them in visual context (see below). We wanted to have as much power as possible for the first deconvolution/LME to look beyond the effects of context.</p>
</sec>
<sec id="s1j">
<title>Estimating Contextual Situatedness</title>
<p>To test our predictions, we estimated a measure of contextual situatedness for each concrete and abstract word included in the first analysis. To that end, we utilised two pre-trained visual recognition models, Faster R-CNN (Ren et al., 2015) and OmniSource (<xref ref-type="bibr" rid="c29">Duan et al., 2020</xref>), to extract object features using computer vision toolboxes (Chen et al., 2019; MMCV Contributors, 2018; MMAction2 Contributors, 2020), respectively. For each prediction frame (about every four frames, i.e., 4*0.04 = 0.16 s), the object recognition model generated a list of detected object labels and kept those that had a prediction confidence of 90% or greater (<xref rid="fig2" ref-type="fig">Figure 2</xref>, (1)). Then, we excluded all objects that were recognized at least 3 standard deviations more often by the model compared to the mean recognition rate of objects (which was 682 appearances), because they would bias our measure of situatedness. These labels were ‘person’ (17,856 appearances per movie on average), ‘chair’ (9,718 appearances per movie on average) and ‘tie’ (8,123 appearances per movie on average). After exclusion of these labels, the final object features were represented as the average of the vectorized object labels using GloVe (<xref ref-type="bibr" rid="c68">Pennington et al, 2014</xref> (<xref rid="fig2" ref-type="fig">Figure 2</xref>, (2)), which represents the meaning of each label via global co-occurrence statistics.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Method for estimating contextual situatedness for each concrete and abstract word to model context-dependent modulation of conceptual encoding. We use visual recognition models for automatically extracting labels that were visually present in the scene (60 frames, ∼2 seconds) before a given word was mentioned in the movie (1). We then correlate an average GloVe Vector embedding of all these labels with a GloVe Vector embedding of that word to estimate how closely related the labels of objects in the scene are to the word (2). Displayed are four randomly extracted measures of situated abstract (blue frame) and concrete (red frame) words (3) together with the objects that were visually present in the scene.</p></caption>
<graphic xlink:href="506944v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We then estimated a representation of a 2s (or 60 frames) context window, which should capture the immediate visual context leading up to each concrete and abstract word. We extracted all the labels of objects visually present in each frame within that window. Finally, we calculated the cosine similarity between the vector representation of each word and its context average, using the ‘<italic>Sklearn</italic>’ package in Python (Pedregosa et al, 2011), to estimate contextual situatedness for each concrete and abstract word (a value <italic>c</italic> between 0 and 1), <xref rid="fig2" ref-type="fig">Figure 2</xref>, (3)). After separating into situated (<italic>c</italic> &gt; 0.6) and displaced words (<italic>c</italic> &lt; 0.4), we were left with (on average for each movie) 164 abstract situated words, 201 abstract displaced words, 215 concrete situated words and 172 concrete displaced words. Given that, as concerns observations, the abstract situated condition was the limiting condition, we randomly selected words from the abstract displaced, concrete situated and concrete displaced conditions to have an equal number of 164 words in each condition (on average per movie).</p>
<p>Though we use visual nuisance regressors, we note that there may be additional confounding visual information when estimating contextual situatedness: high situatedness may correlate positively with the number of objects present and therefore ‘naturally’ engage visual processing more for abstract situated concepts. To alleviate this concern, we determined that there were only 872 more objects present in the abstract situated (8315 objects across movies) as compared to the abstract displaced condition (7443 across movies). A Kruskal Wallis test showed that this difference was not statistically significant (H(2)=4.1, p &lt; .09)</p>
</sec>
<sec id="s1k">
<title>Deconvolution Analysis</title>
<p>The deconvolution was as described previously except that the subset of concrete and abstract words used (see above) were broken into four equal sets of regressors, i.e., situated concrete, displaced concrete, situated abstract, and displaced abstract words and modulators. The four contrasts included were accordingly (1) between abstract situated and abstract displaced, (2) between concrete situated and concrete displaced, (3) between abstract situated and concrete situated and (4) between abstract displaced and concrete displaced. After this process, we were left with 164 words in each of these four conditions per movie on average. Mean concreteness rating for the resulting sets of concrete words were 3.39 for displaced words and 3.35 for situated words, compared to 1.84 for abstract situated words and 1.71 for abstract displaced words. The mean log frequency and mean length for concrete words was 4.91 and 4.88 for situated words and 5.33 and 4.91 for displaced words, compared to 5.11 and 5.08 for abstract situated words and 5.20 and 5.27 for abstract displaced words. T-tests between the ratings of all groups revealed no significant differences.</p>
</sec>
<sec id="s1l">
<title>Group Level Analysis</title>
<p>A linear mixed effects model for group level analysis was conducted on the 20 amplitude modulated betas from each condition (concrete situated, abstract situated, concrete displaced, situated displaced) using ‘<italic>3dLME’</italic> (<xref ref-type="bibr" rid="c18">Chen et al., 2013</xref>). The model included factors ‘word_type’ (concrete and abstract), ‘context’ (displaced and situated), and ‘time’ (20 levels) and all possible interactions between these factors. We again included covariates for age, gender, and movie, a random intercept for participant, and a control of the auto-correlative structure of residuals. The final model formula was: <italic>word_type * context * time + age + gender + movie</italic>. We had no prediction on whether the timing and/or amplitude of the response for concrete and abstract words would vary in the present analysis. Therefore we included 4 general linear tests, 1 for each contrast across time: 1 for the abstract situated vs. abstract displaced contrast, 1 for the concrete situated vs. concrete displaced contrast, 1 for the abstract situated vs abstract displaced contrast, and 1 for the concrete situated vs concrete displaced contrast.</p>
</sec>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Conceptual Processing Across Contexts</title>
<p>Consistent with previous studies, we predicted that across naturalistic contexts, concrete and abstract concepts are processed in a separable set of brain regions. To test this, we contrasted concrete and abstract modulators at each time point of the IRF (<xref rid="fig3" ref-type="fig">Figure 3</xref>). This showed that concrete produced more modulation than abstract modulation in the frontal lobes, including the right posterior inferior frontal gyrus (IFG) and the precentral sulcus (<xref rid="fig3" ref-type="fig">Figure 3</xref>, red). In the temporal lobes, greater modulation occurred in the bilateral transverse temporal gyrus and sulcus, planum polare and temporale, and superior temporal gyrus (STG) and sulcus (STS). In the parietal and occipital lobes, more concrete modulated activity was found in large bilateral swaths of the precuneus, occipital cortices (running into the inferior temporal lobe), and the ventral visual stream. Finally, subcortically, the dorsal and posterior medial cerebellum were more active bilaterally for concrete modulation.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Neurobiology of conceptual processing across contexts. Coloured regions show group level results from a linear mixed effect model and subsequent general linear tests contrasting activity for concrete (red) versus abstract (blue) modulation at each of 20 timepoints after word onset. Overlapping regions (yellow) indicate a concrete and abstract difference at one of these timepoints. Results are thresholded and corrected for multiple comparisons at α = 0.01 and displayed with a cluster-size ≧ 20 voxels.</p></caption>
<graphic xlink:href="506944v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Conversely, activation for abstract was greater than concrete modulation of words in the following regions (<xref rid="fig3" ref-type="fig">Figure 3</xref>, blue): In the frontal lobes, this included right anterior cingulate gyrus, lateral and medial aspects of the superior frontal gyrus. More left frontal activity was found in both lateral and medial prefrontal cortices, and orbital gyrus, posterior IFG, precentral sulcus. In the parietal lobes, bilateral activity was greater in the angular gyri (AG) and inferior parietal lobules, including the postcentral gyrus. In the temporal lobes, activity was restricted to the STS bilaterally. Subcortically, activity was bilaterally greater in the anterior thalamus, nucleus accumbens, and left amygdala for abstract modulation.</p>
<p>Finally, there was overlap in activity between modulation of both concreteness and abstractness (<xref rid="fig3" ref-type="fig">Figure 3</xref>, yellow). The overlap activity is due to the fact that we performed general linear tests for the abstract/concrete contrast at each of the 20 timepoints in our group analysis. Consequently, overlap means that activation in these regions is modulated by both concrete and abstract word processing but at different time-scales. In particular, we find that activity modulation associated with abstractness is generally processed over a longer time-frame. In the frontal, parietal, and temporal lobes, this was primarily in the left IFG, AG, and STG, respectively. In the occipital lobe, processing overlapped bilaterally around the calcarine sulcus.</p>
</sec>
<sec id="s2b">
<title>Meta-Analytic Results</title>
<p>Overall, these results suggest that concrete modulation engages sensory and motor regions more, whereas abstract words engage regions more associated with semantic as well as internal/interoceptive/affective processing. Both categories overlap (though necessarily at different time points) in regions typically associated with word processing. However, these interpretations are based on informal reverse inference. To more formally and quantitatively evaluate this distinction between concrete and abstract words, we employed meta-analytic description and reverse correlation analyses. Both test whether brain regions involved in concrete and abstract conceptual processing reflect different types of habitual experience (i.e., sensory-motor vs internal/interoceptive/affective).</p>
<p>Term-based labelling demonstrates that significantly more concrete clusters are related to the term ‘Movement’ compared to abstract clusters (H(2) = 12.4, p &lt; 0.001; <xref rid="fig4" ref-type="fig">Figure 4</xref>, red). In contrast, abstract clusters are more related to terms that are arguably associated with internal/interoceptive/affective processing compared to concrete activation clusters, i.e., ‘Autobiographical Memory’, ‘Nausea’, ‘Pain’, ‘Reward/Motivation’, and ‘Valence’ (all ps &lt; 0.05; <xref rid="fig4" ref-type="fig">Figure 4</xref>). Finally, ‘Language’ was the only term more associated with overlapping clusters than either concrete (H(2) = 7, p &lt; 0.001) or abstract clusters (H(2) = 4, p = 0.045; <xref rid="fig4" ref-type="fig">Figure 4</xref>). For meta-analytic associations of each individual cluster, see (<xref rid="tbls1" ref-type="table">Table S1</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Meta-analytic description of conceptual processing across contexts. We used the Neurosynth meta-analysis package to find the terms associated with the centres of mass for each concrete (red), abstract (blue), and overlap (yellow) cluster from <xref rid="fig1" ref-type="fig">Figure 1</xref>. Numbers refer to the number of activation clusters associated with each meta-analytic term. There were significantly more concrete than abstract clusters for the term ‘Movement’(p &lt; .001), whereas there were more abstract compared to concrete clusters for ‘Autobiographical Memory’, ‘Nausea’, ‘Pain’, ‘Theory of Mind’, and ‘Valence’ (all ps &lt; 0.05). The term ‘language’ was significantly more associated with overlap clusters compared to concrete (p&lt;0.001) and abstract clusters (p=0.045).</p></caption>
<graphic xlink:href="506944v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2c">
<title>Peaks and Valleys Results</title>
<p>Comparing dimensions for abstract vs concrete modulated clusters, we found significantly more concrete compared to abstract clusters associated with the dimension ‘Torso’ (H(2)=7, p&lt;0.001). Three concrete clusters were associated with ‘Haptic’ and ‘Mouth’, which was also significantly more than for abstract clusters (all tests H(2)=5.2, all ps=0.02). Two concrete clusters with ‘Foot_Leg’ compared to 0 abstract clusters was not significant, but the mean was in the expected direction (H(2)=3.4, p=0.06) All concrete clusters are displayed in <xref rid="fig5" ref-type="fig">Figure 5</xref> (red). Conversely, eight abstract clusters were significantly more associated with the dimension ‘Valence’, which was significantly more than for concrete clusters (H(2)=8.3, p &lt; .001). Three abstract clusters were associated with the dimension ‘Auditory’, which was not significantly more clusters than for concrete (H(2)=1.9, p=0.17). All abstract clusters are displayed in <xref rid="fig5" ref-type="fig">Figure 5</xref> (blue). Finally, five clusters in which modulation through concreteness and abstractness overlapped (though at different time points) were significantly more associated with the dimension ‘Mouth’ compared to 2 concrete clusters (H(2)= 5.1, p=0.03) and 0 abstract clusters (H(2)=7.8, p &lt; .001). All overlap clusters are displayed in <xref rid="fig5" ref-type="fig">Figure 5</xref> (yellow). For all results of the peak and valley tests for each individual cluster, see <xref rid="tbls2" ref-type="table">Table S2</xref>.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><p>Peak and valley analysis results for understanding conceptual processing across contexts. We extract the type of information processed in each activation cluster by looking at experience-based features of movie words that are aligned with significantly more peaks than valleys (see <xref rid="fig3" ref-type="fig">Figure 3</xref>). Words highly rated on the sensorimotor dimensions ‘Haptic’, ‘Hand_Arm’, and ‘Torso’ were significantly more associated with concrete clusters (red, all ps &lt; .05), ‘Valence’ with abstract clusters (blue, p &lt; .001) and ‘Mouth’ with overlap clusters (yellow, ps &lt; .05).</p></caption>
<graphic xlink:href="506944v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2d">
<title>Conceptual Processing in Context</title>
<p>Previous studies suggest that neurobiological activity underlying semantic processing may change as a function of different visual contexts. In this analysis, we wanted to understand what this meant for the distinction between concrete and abstract concepts. We hypothesised that displacing concreteness would cause a shift towards more internalised and potentially general linguistic processing, whereas situating abstractness would cause a shift towards processing external visual information.</p>
<p>Activation for the main effect of context was found bilaterally in posterior temporal lobe at the intersection with occipital lobe, as well as in nodes of the default mode network (DMN), including precuneus, medial prefrontal regions and angular gyrus (<xref rid="figs3" ref-type="fig">figure S3</xref>). Activation associated with the main effect of word_type overlapped with processing of concrete and abstract words across context in superior temporal sulcus, superior temporal gyrus and middle temporal gyrus (bilateral), in angular gyrus (bilateral), in the central sulcus and precentral and postcentral gyrus (right hemisphere), in lateral and medial frontal cortices as well as in the occipital lobe (see <xref rid="figs4" ref-type="fig">figure S4</xref>). The interaction between word_type and context modulated activity in the main nodes of the DMN (amongst other regions), including precuneus, medial prefrontal regions, and angular gyrus (all bilaterally, see <xref rid="figs5" ref-type="fig">figure S5</xref>). Indeed, the thresholded interaction map with 1501 voxels was ‘decoded’ using the Neurosynth package, where the Pearson correlation is computed between the vectorized map and all the maps in the Neurosynth database. The top four associated terms (excluding brain regions or methodological terms) were the ‘DMN’ (r(1500) = 0.194, p &lt; 0.001), ‘Default Mode’ (r(1500) = 0.219, p &lt; 0.001), and ‘Default’ (r(1500) = 0.226, p &lt; 0.001) as well as ‘Semantic Control’ (r(1500) = 0.206, p &lt; 0.001).</p>
<p>To better understand the nature of this interaction and how it relates to response profiles associated with concreteness and abstractness across contexts, we contrasted concrete vs abstract modulation in situated and displaced conditions (across timepoints, as we had no prediction about timing differences) and spatially compared the resulting activation maps with the brain map obtained from contrasting concreteness and abstractness across contexts (<xref rid="fig6" ref-type="fig">Figure 6</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Spatial overlap between thresholded statistical brain images of concrete and abstract conceptual processing obtained from the original analysis across contexts and from the situatedness/displacement contrasts. Results show overlap of concreteness across contexts (red) with situated abstractness (purple) and displaced concreteness (magenta) (panel A). Overlap between abstractness across context (blue) with displaced concreteness (purple) and situated abstractness (light magenta) are displayed in panel B. All maps were thresholded at α = 0.01 with a cluster-size ≧ 20 voxels.</p></caption>
<graphic xlink:href="506944v3_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To quantify this comparison, we used cosine similarity to calculate spatial correlation measures between the unthresholded results from contrasting concrete and abstract modulations in displaced and situated context with the unthresholded contrasts between concrete and abstract modulations across contexts (<xref rid="fig1" ref-type="fig">Figure 1</xref>, red is the thresholded version of this map). This shows that in situated context, the contrasted modulation by abstractness (<xref rid="fig6" ref-type="fig">Figure 6</xref>, A, purple) overlaps more with concreteness across context (r(72964) = 0.64, p &lt; 0.001) (<xref rid="fig6" ref-type="fig">Figure 6</xref>, A, red) compared to displaced concreteness (r(72964) = 0165, p = 0.476) (<xref rid="fig6" ref-type="fig">Figure 6</xref>, A, magenta). Concreteness across contexts overlaps with situated abstractness bilaterally in the fusiform, occipital lobe, inferior and superior parietal lobules and with displaced concreteness bilaterally in the occipital lobe, as well as large swaths of the superior temporal gyrus (<xref rid="fig6" ref-type="fig">Figure 6</xref>, A).</p>
<p>Conversely, in displaced context, the contrasted modulation by concreteness (<xref rid="fig6" ref-type="fig">Figure 6</xref>, B, purple) overlaps more with the pattern of activity modulated by abstractness across context (r(72,964) = 0.49, p &lt; 0.001) (<xref rid="fig6" ref-type="fig">Figure 6</xref>, B, blue) compared to situated abstractness (r(72,964) = 0.21, p &lt; 0.001) (<xref rid="fig6" ref-type="fig">Figure 6</xref>, B, light magenta). Abstractness across contexts overlaps with displaced concreteness bilaterally in large portions of the inferior parietal lobule, including supramarginal gyrus and post superior temporal sulcus, up to the intersection of the occipital and temporal lobes, lingual gyrus in particular. Overlap activation could also be found bilaterally in anterior thalamus and medial prefrontal regions. Overlap between abstractness across context and situated abstractness is found in fusiform (bilaterally) and the superior occipital lobe as well as the superior parietal lobe (<xref rid="fig6" ref-type="fig">Figure 6</xref>, B).</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Conceptual processing is typically investigated in experiments where words are stripped away from their naturally occurring context: most studies use isolated words, and sometimes sentences (see Table 1 in Maschio et al, 2022). However, conceptual processing in its ecology occurs in rich multimodal contexts. Our study investigated naturalistic conceptual processing during movie-watching to begin to understand the effect of multimodal context on the neurobiological organisation of real-world conceptual representation.</p>
<sec id="s3a">
<title>Conceptual Processing Across Contexts</title>
<p>First, we asked where in the brain concrete and abstract concepts are processed across different contexts as well as the type of information they encode. Given the hypothesis that conceptual representations reflect contextual information, we expected a set of regions that correspond to the most typical set of experiences (e.g., as encountered during word learning in development) to activate across different contexts. Specifically, we expected concrete conceptual encoding to activate regions more involved in sensory and motor processing and abstract conceptual encoding to activate regions associated with more internal/interoceptive/affective as well as general linguistic processing (Fernandino et al., 2019; <xref ref-type="bibr" rid="c62">Meteyard et al., 2012</xref>; J. R. Binder, 2005).</p>
<p>Indeed, we found a general tendency for concrete and abstract words to activate regions associated with different experiences (<xref rid="fig1" ref-type="fig">Figure 1</xref>). Consistent with prior work, concrete words were associated with multiple regions involved in sensory and motor processing (<xref ref-type="bibr" rid="c63">Mkrtychian et al., 2019</xref>), including most of the visual system (<xref ref-type="bibr" rid="c33">Gao et al., 2019</xref>) and the right frontal motor system (<xref ref-type="bibr" rid="c72">Pulvermuller, 2005</xref>). In contrast, abstract words engaged regions typically associated with internal/interoceptive/affective processing (anterior thalamus, somatosensory cortex)(<xref ref-type="bibr" rid="c37">Harpaintner et al., 2018</xref>; <xref ref-type="bibr" rid="c93">Villani et al., 2021</xref>), autobiographical memory (anterior medial prefrontal regions) (Conca, Borsa, et al., 2021), and emotional processing and regulation (anterior medial prefrontal regions, orbital prefrontal cortex, dorsolateral prefrontal cortex, nucleus accumbens and amygdala) (Vigliocco, 2014; Conca, Catricala, et al., 2021).</p>
<p>Consistent with this, both meta-analytic and peak and valley analyses showed that concrete regions were more associated with sensory-motor properties (e.g., ‘Movement’ and ‘Hand_Arm’) whereas abstract regions were more associated with internal/interoceptive/affective properties (e.g., ‘Valence’; <xref rid="fig2" ref-type="fig">Figures 2</xref>-<xref rid="fig4" ref-type="fig">4</xref>). Together, these results provide evidence from naturalistic processing that concrete and abstract concepts encode different types of experiences (<xref ref-type="bibr" rid="c90">Vigliocco et al., 2009</xref>; <xref ref-type="bibr" rid="c98">Wiemer-Hastings &amp; Xu, 2005</xref>; <xref ref-type="bibr" rid="c55">Kiehl et al., 1999</xref>).</p>
<p>However, the regions involved in processing concrete and abstract concepts across contexts did not imply a fully dichotomous encoding of experiences. First, we found that regions involved in sensory (mostly in visual cortices) and motor processing are involved in processing both types of words (<xref rid="fig1" ref-type="fig">Figure 1</xref>). Moreover, we found overlap activation in regions associated with language processing in general (Tang et al, 2021, <xref rid="fig1" ref-type="fig">Figure 1</xref>). Such results are in line with proposals in which both concrete and abstract representations rely on experiential information as well as their linguistic relationships with other words (e.g., Andrews, Vigliocco &amp; Vinson, 2009; <xref ref-type="bibr" rid="c90">Vigliocco et al., 2009</xref>, Piantadosi &amp; Hill, 2022). This latter hypothesis may also be supported by our Peaks and Valleys analysis, more specifically that information related to ‘Mouth’ (i.e. the language organ) drives activation in overlap clusters. This is furthermore evidence against hypotheses in which the mouth is specifically associated with abstract concepts (Borghi, 2016) .</p>
</sec>
<sec id="s3b">
<title>Conceptual Processing in Context</title>
<p>Though results across contexts presumably represent a form of experiential central tendency, the behavioural, neuroimaging, and electrophysiological literature suggests that conceptual representations might not be stable and may vary as a function of context (Elman, 1995; Spivey &amp; Dale, 2006 in <xref ref-type="bibr" rid="c14">Cai &amp; Vigliocco, 2018</xref>; <xref ref-type="bibr" rid="c57">Kutas &amp; Federmeier, 2011</xref>; <xref ref-type="bibr" rid="c100">Yee &amp; Thompson-Schill, 2016</xref>, Deniz et al., 2023). For this reason, we conducted a second set of analyses with the goal of understanding the extent to which representations associated with concrete or abstract conceptual processing in the brain change as a function of context (<xref ref-type="bibr" rid="c7">Barsalou &amp; Wiemer-Hastings, 2005</xref>).</p>
<p>We find that brain activation underlying concrete and abstract conceptual processing fundamentally changes as a function of visual context. We compared the activation profiles of concrete and abstract concepts in displaced and situated contexts with the activations obtained when collapsing across contexts. Our results show that concrete concepts become more abstract-like in displaced contexts with less relevant visual information (<xref rid="fig6" ref-type="fig">Figure 6a</xref>). Overlap between activation for concrete concepts in displaced conditions and abstract concepts across context can be found in ACC, thalamus, and large swaths of the anterior, middle and posterior temporal lobe. We propose that this is because, when a concrete concept is processed in displaced context, its representation will relate more to internal/interoceptive variables and linguistic associations, which are usually encoded by abstract concepts. Conversely, abstract concepts become more concrete-like when they are highly situated (<xref rid="fig6" ref-type="fig">Figure 6b</xref>). Overlap between activation for abstract concepts in situated conditions and concrete concepts across context can be found in fusiform and the occipital lobe (bilateral). We propose that this is because an abstract concept processed in a situated context relates more to external visual information, which is usually encoded by concrete concepts. A consequence of this finding is that the concrete/abstract distinction is neurobiologically less stable than might be assumed. Brain regions ‘switch alliance’ during concrete or abstract word processing depending on context.</p>
<p>What is the neurobiological mechanism behind contextual modulation of conceptual encoding in the brain? Our results indicate that variance in visual context interacted with word-type (both concrete and abstract) in regions commonly defined as the DMN, as well as a set of prefrontal regions associated with semantic control (Ralph et al, 2017; Hoffman et al, 2018) (<xref rid="figs3" ref-type="fig">Figure S3</xref>, <xref rid="figs5" ref-type="fig">S5</xref>). Recent literature on the role of the DMN suggests that these regions reactivate memories (Crittenden et al., 2015, Konishi et al., 2015, Murphy et al., 2019, Murphy et al., 2018, Sormaz et al., 2018, Spreng et al., 2014, Vatansever et al., 2017) and contexts-specific information (Hahamy et al., 2023), possibly to form contextually relevant situation models (Chen et al., 2017, Keidel et al., 2018, Ranganath and Ritchey, 2012, Smith et al., 2021, Smith et al., 2018), in order to guide semantic cognition (Binder et al, 1999; Binder &amp; Fernandino, 2015; <xref ref-type="bibr" rid="c101">Yeshurun et al., 2021</xref>; Tong et al, 2022).</p>
<p>Breaking up the interaction between word_type and context, we find that the DMN is especially involved in displaced conditions for both concrete and abstract conceptual processing (see <xref rid="figs6" ref-type="fig">figure S6</xref>). These results fit well with evidence suggesting that the DMN supports conceptual processing especially when displaced from sensorimotor input (Murphy et al., 2018; Lanzoni et al., 2020; Wang et al., 2020). Accordingly, the DMN is most strongly activated in the displaced conditions involving abstract concepts. Given their inherent lack of sensorimotor information, abstract concepts offer a greater degree of displacement than their concrete counterparts, thereby demanding a higher engagement of the DMN in these conditions.</p>
</sec>
<sec id="s3c">
<title>Conceptual Processing and Language</title>
<p>The exact relationship between concepts and language remains an open question, but it is undisputed that, as determinants of meaning, concepts are necessary for language (<xref ref-type="bibr" rid="c48">Jackendoff, 2002</xref>; Bloom, 2002; Fauconnier &amp; Mark, 2002). The present study examined language-driven conceptual processing, as we looked at brain activation during word processing. Our results imply that the underlying neurobiological processes are dynamically distributed and contextually determined. This view fits well with models of ‘natural’ organisation of language in the brain where it is argued that language processing more generally is a whole brain process whose patterns of activation are determined by available context (Skipper, 2014; 2015). These more distributed regions are typically averaged away when indiscriminately analysed together and following thresholding because (i) they are more variable given they are associated with different experiences (as we have seen here), linguistic categories (e.g., ‘formulaic speech’; see <xref ref-type="bibr" rid="c81">Skipper et al., 2022</xref>), and processes (e.g., different types of syntax) (ii) there are individual differences in all of these (e.g., Wang et al, 2022; <xref ref-type="bibr" rid="c81">Skipper et al, 2022</xref>; Skipper, 2015). These suppositions are supported by the fact that concrete and abstract modulation only overlaps in typical perisylvian ‘language regions’ (<xref rid="figs7" ref-type="fig">Figure S7</xref>).</p>
</sec>
<sec id="s3d">
<title>Conclusions</title>
<p>Our work emphasises the merits of investigating conceptual processing in naturalistic multimodal contexts. This paves the way for future analyses systematically quantifying different types of contexts (e.g. in terms of related objects, actions, emotions, or social interactions) and examining how these can affect conceptual processing in the brain. Such work might not only further our understanding of the neurobiology of conceptual processing in naturalistic settings, but also aid in the development of better artificial models by clarifying what type of contexts affect processing and how. This becomes especially important with the recent development of multimodal large language models, where processing depends on context beyond purely text based information (Driess, 2023). Apart from commercial applications, gaining a better understanding of the mechanisms underlying naturalistic conceptual processing in the brain might bear important implications for clinical domains, e.g., by informing progress towards helping patients who lost the ability to speak by real-time semantic reconstruction of non-invasive brain recordings with the help of large language models (Tang et al, 2023).</p>
</sec>
</sec>
<sec id="s4">
<title>Funding</title>
<p>This work was supported in part by the European Research Council Advanced Grant (ECOLANG, 743035); Royal Society Wolfson Research Merit Award (WRM\R3\170016) to GV; and Leverhulme award DS-2017-026 to VK and GV.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>VK would like to thank Bangjie Wang for help in using image recognition software, and Dr Sarah Aliko for help with neuroimaging analysis.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Aliko</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gheorghiu</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Meliss</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Skipper</surname>, <given-names>J. I</given-names></string-name>. (<year>2020</year>). <article-title>A naturalistic neuroimaging database for understanding the brain using ecological stimuli</article-title>. <source>Sci Data</source>, <volume>7</volume>(<issue>1</issue>), <fpage>347</fpage>. <pub-id pub-id-type="doi">10.1038/s41597-020-00680-2</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><given-names>J.R.</given-names> <surname>Barclay</surname></string-name>, <string-name><given-names>John D.</given-names> <surname>Bransford</surname></string-name>, <string-name><given-names>Jeffery J.</given-names> <surname>Franks</surname></string-name>, <string-name><given-names>Nancy S.</given-names> <surname>McCarrell</surname></string-name>, <string-name><surname>Kathy Nitsch</surname>, <given-names>Comprehension</given-names></string-name> and semantic flexibility, <article-title>Journal of Verbal Learning and Verbal Behaviour</article-title>, <source>Volume</source> <volume>13</volume>, Issue <issue>4</issue>, <year>1974</year>, Pages 471-481, ISSN 0022-5371, <pub-id pub-id-type="doi">10.1016/S0022-5371(74)80024-1</pub-id>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Barsalou</surname>, <given-names>L. W</given-names></string-name>. (<year>1982</year>). <article-title>Context-independent and context-dependent information in concepts</article-title>. <source>Memory &amp; Cognition</source>, <volume>10</volume>(<issue>1</issue>), <fpage>82</fpage>–<lpage>93</lpage>. <pub-id pub-id-type="doi">10.3758/BF03197629</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="book"><string-name><surname>Barsalou</surname>, <given-names>L. W</given-names></string-name>. (<year>1987</year>). <chapter-title>The instability of graded structure: Implications for the nature of concepts</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>U.</given-names> <surname>Neisser</surname></string-name></person-group> (Ed.), <source>Concepts and conceptual development: Ecological and intellectual factors in categorization</source> (pp. <fpage>101</fpage>–<lpage>140</lpage>). <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Barsalou</surname>, <given-names>L. W.</given-names></string-name>, <string-name><surname>Dutriaux</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Scheepers</surname>, <given-names>C</given-names></string-name>. (<year>2018</year>). <article-title>Moving beyond the distinction between concrete and abstract concepts</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source>, <volume>373</volume>(<fpage>1752</fpage>). <pub-id pub-id-type="doi">10.1098/rstb.2017.0144</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Barsalou</surname>, <given-names>L. W.</given-names></string-name>, <string-name><surname>Simmons</surname>, <given-names>W. K.</given-names></string-name>, <string-name><surname>Barbey</surname>, <given-names>A. K.</given-names></string-name>, &amp; <string-name><surname>Wilson</surname>, <given-names>C. D</given-names></string-name>. (<year>2003</year>). <article-title>Grounding Conceptual Knowledge in Modality Specific Systems</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>7</volume>(<issue>7</issue>), <fpage>7</fpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Barsalou</surname>, <given-names>L. W.</given-names></string-name>, &amp; <string-name><surname>Wiemer-Hastings</surname>, <given-names>K.</given-names></string-name> (<year>2005</year>). S<article-title>ituating Abstract Concepts</article-title>. In <source>Grounding Cognition</source> (pp. <fpage>129</fpage>–<lpage>163</lpage>). <pub-id pub-id-type="doi">10.1017/cbo9780511499968.007</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Bedny</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Thompson-Schill</surname>, <given-names>S. L</given-names></string-name>. (<year>2006</year>). <article-title>Neuroanatomically separable effects of imageability and grammatical class during single-word comprehension</article-title>. <source>Brain Lang</source>, <volume>98</volume>(<issue>2</issue>), <fpage>127</fpage>–<lpage>139</lpage>. <pub-id pub-id-type="doi">10.1016/j.bandl.2006.04.008</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Binder</surname>, <given-names>J.R.</given-names></string-name>, C. F. W., K. <string-name><given-names>A.</given-names> <surname>McKiernan</surname></string-name>, <string-name><given-names>E. T.</given-names> <surname>Possing</surname></string-name> and <string-name><given-names>D.A.</given-names> <surname>Medler</surname></string-name> (<year>2005</year>). <article-title>Distinct Brain Systems for Processing Concrete and Abstract Concepts</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>17</volume>(<issue>6</issue>), <fpage>12</fpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Binder</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Desai</surname>, <given-names>R. H.</given-names></string-name>, <string-name><surname>Graves</surname>, <given-names>W. W.</given-names></string-name>, &amp; <string-name><surname>Conant</surname>, <given-names>L. L</given-names></string-name>. (<year>2009</year>). <article-title>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies</article-title>. <source>Cereb Cortex</source>, <volume>19</volume>(<issue>12</issue>), 2767-2796. <pub-id pub-id-type="doi">10.1093/cercor/bhp055</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="book"><string-name><surname>Bloom</surname>, <given-names>P</given-names></string-name>. (<year>2000</year>). <source>How children learn the meanings of words</source>. <publisher-name>The MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Borghi</surname>, <given-names>A. M.</given-names></string-name>, &amp; <string-name><surname>Zarcone</surname>, <given-names>E.</given-names></string-name> (<year>2016</year>). <article-title>Grounding abstractness: Abstract concepts and the activation of the mouth</article-title>. <source>Frontiers in Psychology</source>, <volume>7</volume>, Article 1498.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Brysbaert</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Warriner</surname>, <given-names>A. B.</given-names></string-name>, &amp; <string-name><surname>Kuperman</surname>, <given-names>V</given-names></string-name>. (<year>2014</year>). <article-title>Concreteness ratings for 40 thousand generally known English word lemmas</article-title>. <source>Behav Res Methods</source>, <volume>46</volume>(<issue>3</issue>), <fpage>904</fpage>–<lpage>911</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-013-0403-5</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Cai</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>Vigliocco</surname>, <given-names>G</given-names></string-name>. (<year>2018</year>). <article-title>Word Processing</article-title>. <source>Language and Thought</source>, <volume>3</volume>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Caucheteux</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>King</surname>, <given-names>J. R</given-names></string-name>. (<year>2022</year>). <article-title>Brains and algorithms partially converge in natural language processing</article-title>. <source>Commun Biol</source>, <volume>5</volume>(<issue>1</issue>), <fpage>134</fpage>. <pub-id pub-id-type="doi">10.1038/s42003-022-03036-1</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Chambers</surname>, <given-names>C. G.</given-names></string-name>, <string-name><surname>Tanenhaus</surname>, <given-names>M. K.</given-names></string-name>, &amp; <string-name><surname>Magnuson</surname>, <given-names>J. S</given-names></string-name>. (<year>2004</year>). <article-title>Actions and affordances in syntactic ambiguity resolution</article-title>. <source>J Exp Psychol Learn Mem Cogn</source>, <volume>30</volume>(<issue>3</issue>), <fpage>687</fpage>–<lpage>696</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.30.3.687</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Chen</surname>, <given-names>G.</given-names></string-name>, <string-name><given-names>Z. S.</given-names> <surname>Saad</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Britton</surname></string-name>, <string-name><given-names>D. S.</given-names> <surname>Pine</surname></string-name>, and <string-name><given-names>R. W.</given-names> <surname>Cox</surname></string-name>. <article-title>Linear mixed-effects modeling approach to fmri group analysis</article-title>. <source>Neuroimage</source>, <volume>73</volume>:<fpage>176</fpage>–<lpage>90</lpage>, <year>2013</year>. ISSN 1095-9572. 1053-8119. 1053-8119. URL <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/23376789">https://www.ncbi.nlm.nih.gov/pubmed/23376789</ext-link>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Chen</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Saad</surname>, <given-names>Z. S.</given-names></string-name>, <string-name><surname>Adleman</surname>, <given-names>N. E.</given-names></string-name>, <string-name><surname>Leibenluft</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Cox</surname>, <given-names>R. W</given-names></string-name>. (<year>2015</year>). <article-title>Detecting the subtle shape differences in hemodynamic responses at the group level</article-title>. <source>Front Neurosci</source>, <volume>9</volume>, <fpage>375</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2015.00375</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Conca</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Borsa</surname>, <given-names>V. M.</given-names></string-name>, <string-name><surname>Cappa</surname>, <given-names>S. F.</given-names></string-name>, &amp; <string-name><surname>Catricala</surname>, <given-names>E</given-names></string-name>. (<year>2021</year>). <article-title>The multidimensionality of abstract concepts: A systematic review</article-title>. <source>Neurosci Biobehav Rev</source>, <volume>127</volume>, <fpage>474</fpage>–<lpage>491</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2021.05.004</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Conca</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Catricala</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Canini</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Petrini</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Vigliocco</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Cappa</surname>, <given-names>S. F.</given-names></string-name>, &amp; <string-name><surname>Della Rosa</surname>, <given-names>P. A.</given-names></string-name> (<year>2021</year>). <article-title>In search of different categories of abstract concepts: a fMRI adaptation study</article-title>. <source>Sci Rep</source>, <volume>11</volume>(<issue>1</issue>), <fpage>22587</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-021-02013-8</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Cooper</surname>, <given-names>R. M</given-names></string-name>. (<year>1974</year>). <article-title>The Control of Eye Fixation by the Meaning of Spoken Language</article-title>. <source>Cognitive Psychology</source>, <volume>6</volume>, <fpage>23</fpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Cox</surname>, <given-names>R. W</given-names></string-name>. (<year>1995</year>). <article-title>AFNI: Software for Analysis and Visualization of Functional Magnetic Resonance Neuroimages</article-title>. <source>Computers and Biomedical Research</source>, <volume>29</volume>(<issue>14</issue>), <fpage>11</fpage>.</mixed-citation></ref>
<ref id="c24a"><mixed-citation publication-type="journal"><string-name><surname>Cox</surname>, <given-names>R. W.</given-names></string-name> (<year>1997</year>). <article-title>Software tools for analysis and visualization of fMRI data</article-title>. <source>Nmr in Biomedicine</source>, <volume>10</volume>, 7.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="other"><string-name><surname>Deniz</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Tseng</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Wehbe</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Dupré La Tour</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Gallant</surname>, <given-names>J. L.</given-names></string-name> <article-title>Semantic Representations During Language Comprehension are Affected by Context</article-title>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Del Maschio</surname> <given-names>N</given-names></string-name>, <string-name><surname>Fedeli</surname> <given-names>D</given-names></string-name>, <string-name><surname>Garofalo</surname> <given-names>G</given-names></string-name>, <string-name><surname>Buccino</surname> <given-names>G</given-names></string-name>. <article-title>Evidence for the Concreteness of Abstract Language: A Meta-Analysis of Neuroimaging Studies</article-title>. <source>Brain Sciences</source>. <year>2022</year>; <volume>12</volume>(<issue>1</issue>):<fpage>32</fpage>. <pub-id pub-id-type="doi">10.3390/brainsci12010032</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Devlin</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Toutanova</surname>, <given-names>K</given-names></string-name>. (<year>2018</year>). <article-title>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</article-title>. <source>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</source>, <fpage>1</fpage>. <pub-id pub-id-type="doi">10.18653/v1/N19-1423</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="other"><string-name><surname>Driess</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Xia</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Sajjadi</surname>, <given-names>M.S.</given-names></string-name>, <string-name><surname>Lynch</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chowdhery</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ichter</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Wahid</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Tompson</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Vuong</surname>, <given-names>Q.H.</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Chebotar</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Sermanet</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Duckworth</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Levine</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Vanhoucke</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Hausman</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Toussaint</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Greff</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Zeng</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Mordatch</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name><surname>Florence</surname>, <given-names>P.R</given-names></string-name>. (<year>2023</year>). <article-title>PaLM-E: An Embodied Multimodal Language Model</article-title>. ArXiv, abs/2303.03378.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="other"><string-name><surname>Duan</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Xiong</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Lin</surname>, <given-names>D.</given-names></string-name> (<year>2020</year>). <article-title>Omni-source Webly-supervised Learning for Video Recognition</article-title>. <italic>Bioarchive (Tech Report)</italic>. <pub-id pub-id-type="doi">arXiv:2003.13042</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="other"><string-name><surname>Eberhard</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Spivey-Knowlton</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Sedivy</surname>, <given-names>J. C.</given-names></string-name>, &amp; <string-name><surname>Tanenhaus</surname>, <given-names>M</given-names></string-name>. <article-title>K</article-title>. <source>Eye Movements as a Window into Real-Time Spoken Language Comprehension in Natural Contexts</source>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="book"><string-name><surname>Fauconnier</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Turner</surname>, <given-names>M</given-names></string-name>. (<year>2002</year>). <source>The way we think: Conceptual blending and the mind’s hidden complexities</source>. <publisher-name>Basic Books</publisher-name>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Fedorenko</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Behr</surname>, <given-names>M. K.</given-names></string-name>, &amp; <string-name><surname>Kanwisher</surname>, <given-names>N</given-names></string-name>. (<year>2011</year>). <article-title>Functional specificity for high-level linguistic processing in the human brain</article-title>. <source>Proc Natl Acad Sci U S A</source>, <volume>108</volume>(<issue>39</issue>), <fpage>16428</fpage>–<lpage>16433</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1112937108</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Gao</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Baucom</surname>, <given-names>L. B.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wedell</surname>, <given-names>D. H.</given-names></string-name>, &amp; <string-name><surname>Shinkareva</surname>, <given-names>S. V</given-names></string-name>. (<year>2019</year>). <article-title>Distinguishing abstract from concrete concepts in supramodal brain regions</article-title>. <source>Neuropsychologia</source>, 102-110. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2019.05.032</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Geschwind</surname>, <given-names>N</given-names></string-name>. (<year>1970</year>). <article-title>The Organization of Language in the Brain</article-title>. <source>Science</source>, <volume>170</volume>, <fpage>5</fpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Goldberg</surname>, <given-names>R. F.</given-names></string-name>, <string-name><surname>Perfetti</surname>, <given-names>C. A.</given-names></string-name>, &amp; <string-name><surname>Schneider</surname>, <given-names>W</given-names></string-name>. (<year>2006</year>). <article-title>Perceptual knowledge retrieval activates sensory brain regions</article-title>. <source>J Neurosci</source>, <volume>26</volume>(<issue>18</issue>), <fpage>4917</fpage>–<lpage>4921</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.5389-05.2006</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Goldstein</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Zada</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Buchnik</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Schain</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Price</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Aubrey</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Nastase</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Feder</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Emanuel</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Jansen</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gazula</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Choe</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Rao</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Casto</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Fanda</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Doyle</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Friedman</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Dugan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Melloni</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Reichart</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Devore</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Flinker</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hasenfratz</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Levy</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Hassidim</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brenner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Matias</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Norman</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Devinsky</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Hasson</surname>, <given-names>U</given-names></string-name>. (<year>2022</year>). <article-title>Shared computational principles for language processing in humans and deep language models</article-title>. <source>Nat Neurosci</source>, <volume>25</volume>(<issue>3</issue>), <fpage>369</fpage>–<lpage>380</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-022-01026-4</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Harpaintner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Trumpp</surname>, <given-names>N. M.</given-names></string-name>, &amp; <string-name><surname>Kiefer</surname>, <given-names>M</given-names></string-name>. (<year>2018</year>). <article-title>The Semantic Content of Abstract Concepts: A Property Listing Study of 296 Abstract Words</article-title>. <source>Front Psychol</source>, <volume>9</volume>, <fpage>1748</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2018.01748</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Harpaintner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sim</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Trumpp</surname>, <given-names>N. M.</given-names></string-name>, <string-name><surname>Ulrich</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Kiefer</surname>, <given-names>M</given-names></string-name>. (<year>2020</year>). <article-title>The grounding of abstract concepts in the motor and visual system: An fMRI study</article-title>. <source>Cortex</source>, <volume>124</volume>, <fpage>1</fpage>–<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1016/j.cortex.2019.10.014</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Harpaintner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Trumpp</surname>, <given-names>N. M.</given-names></string-name>, &amp; <string-name><surname>Kiefer</surname>, <given-names>M</given-names></string-name>. (<year>2022</year>). <article-title>Time course of brain activity during the processing of motor- and vision-related abstract concepts: flexibility and task dependency</article-title>. <source>Psychological Research</source>, <volume>86</volume>(<issue>8</issue>), <fpage>2560</fpage>–<lpage>2582</lpage>. <pub-id pub-id-type="doi">10.1007/s00426-020-01374-5</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Hasson</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Nir</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Levy</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Fuhrmann</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Malach</surname>, <given-names>R</given-names></string-name>. (<year>2004</year>). <article-title>Intersubject Synchronization of Cortical Activity During Natural Vision</article-title>. <source>Science</source>, <volume>303</volume>(<issue>5664</issue>), <fpage>6</fpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Hasson</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Skipper</surname>, <given-names>J. I.</given-names></string-name>, <string-name><surname>Wilde</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Nusbaum</surname>, <given-names>H. C.</given-names></string-name>, &amp; <string-name><surname>Small</surname>, <given-names>S. L</given-names></string-name>. (<year>2008</year>). <article-title>Improving the analysis, storage and sharing of neuroimaging data using relational databases and distributed computing</article-title>. <source>NeuroImage</source>, <volume>39</volume>(<issue>2</issue>), <fpage>693</fpage>–<lpage>706</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="other"><string-name><surname>Hauk</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Pulvermüller</surname>, <given-names>F</given-names></string-name>. (<year>2004</year>). <article-title>Somatotopic Representation of Action Words in Human Motor and Premotor Cortex</article-title>. <pub-id pub-id-type="doi">10.1016/s0896-6273(03)00838-9</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="report"><string-name><surname>He</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Ren</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Sun</surname>, <given-names>J.</given-names></string-name> (<year>2015</year>). Deep Residual Learning for Image Recognition. <italic>Bioarchive (Tech Report)</italic>. <pub-id pub-id-type="doi">10.48550/arXiv.1512.03385</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Hickok</surname>, <given-names>G</given-names></string-name>. (<year>2022</year>). <article-title>The dual stream model of speech and language processing</article-title>. <source>Handb Clin Neurol</source>, <volume>185</volume>, <fpage>57</fpage>–<lpage>69</lpage>. <pub-id pub-id-type="doi">10.1016/B978-0-12-823384-9.00003-7</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Hoffman</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Lambon Ralph</surname>, <given-names>M. A.</given-names></string-name>, &amp; <string-name><surname>Rogers</surname>, <given-names>T. T</given-names></string-name>. (<year>2013</year>). <article-title>Semantic diversity: a measure of semantic ambiguity based on variability in the contextual usage of words</article-title>. <source>Behav Res Methods</source>, <volume>45</volume>(<issue>3</issue>), <fpage>718</fpage>–<lpage>730</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-012-0278-x</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Hoenig</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Sim</surname>, <given-names>E.-J.</given-names></string-name>, <string-name><surname>Bochev</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Herrnberger</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Kiefer</surname>, <given-names>M</given-names></string-name>. (<year>2008</year>). <article-title>Conceptual flexibility in the human brain: Dynamic recruitment of semantic maps from visual, motion and motor-related areas</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>20</volume>(<fpage>10</fpage>).</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Hsu</surname>, <given-names>N. S.</given-names></string-name>, J.M., D., <string-name><given-names>M.</given-names> <surname>Kraemer</surname></string-name>, <string-name><surname>Robyn</surname>, <given-names>Oliver</given-names></string-name>, <string-name><given-names>T.</given-names>, <surname>&amp; Schlichting</surname></string-name>, M. L. T.-S., S. (<year>2011</year>). <article-title>Color, Context, and Cognitive Style: Variations in Color Knowledge Retrieval as a Function of Task and Subject Variables</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>23</volume>(<issue>9</issue>), <fpage>13</fpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Jackendoff</surname>, <given-names>Ray</given-names></string-name>, <article-title>Foundations of Language: Brain, Meaning, Grammar</article-title>, <source>Evolution (Oxford</source>, <year>2002</year>; online edn, Oxford Academic, 1 Sept. 2007), <pub-id pub-id-type="doi">10.1093/acprof:oso/9780198270126.001.0001</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><collab>Jackson., R. L</collab>., <article-title>The neural correlates of semantic control revisited</article-title>. <source>Neuroimage</source>, <volume>224</volume>:<issue>117444</issue>, <year>2021</year>. ISSN 1095-9572. URL <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/33059049">https://www.ncbi.nlm.nih.gov/pubmed/33059049</ext-link>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><collab>Jones, M. N. B. T. Johns, and G. Recchia</collab>. <article-title>The role of semantic diversity in lexical organization</article-title>. 891 <source>Can J Exp Psychol</source>, <volume>66</volume>(<issue>2</issue>):<fpage>115</fpage>–<lpage>24</lpage>, <year>2012</year>. ISSN 1878-7290. URL <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/22686160.893">https://www.ncbi.nlm.nih.gov/pubmed/22686160.893</ext-link></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Kalenine</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Shapiro</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Flumini</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Borghi</surname>, <given-names>A. M.</given-names></string-name>, &amp; <string-name><surname>Buxbaum</surname>, <given-names>L. J</given-names></string-name>. (<year>2014</year>). <article-title>Visual context modulates potentiation of grasp types during semantic object categorization</article-title>. <source>Psychon Bull Rev</source>, <volume>21</volume>(<issue>3</issue>), <fpage>645</fpage>–<lpage>651</lpage>. <pub-id pub-id-type="doi">10.3758/s13423-013-0536-7</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Kiefer</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Pulvermüller</surname>, <given-names>F</given-names></string-name>. (<year>2012</year>). <article-title>Conceptual representations in mind and brain: theoretical developments, current evidence and future directions</article-title>. <source>Cortex</source>, <volume>48</volume>(<issue>7</issue>), <fpage>805</fpage>–<lpage>825</lpage>. <pub-id pub-id-type="doi">10.1016/j.cortex.2011.04.006</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Kiefer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sim</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Herrnberger</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Grothe</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Hoenig</surname>, <given-names>K</given-names></string-name>. (<year>2008</year>). <article-title>The sound of concepts: four markers for a link between auditory and conceptual brain systems</article-title>. <source>J Neurosci</source>, <volume>28</volume>(<issue>47</issue>), <fpage>12224</fpage>–<lpage>12230</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3579-08.2008</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Kiefer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Pielke</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Trumpp</surname>, <given-names>N. M</given-names></string-name>. (<year>2022</year>). <article-title>Differential temporo-spatial pattern of electrical brain activity during the processing of abstract concepts related to mental states and verbal associations</article-title>. <source>NeuroImage</source>, <volume>252</volume>, <fpage>119036</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2022.119036</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Kiehl</surname>, <given-names>K.A.</given-names></string-name>, <string-name><surname>Liddle</surname>, <given-names>P.F.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>A.M.</given-names></string-name>, <string-name><surname>Mendrek</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Forster and</surname>, <given-names>B.B.</given-names></string-name> and <string-name><surname>Hare</surname>, <given-names>R.D</given-names></string-name>. (<year>1999</year>), <article-title>Neural pathways involved in the processing of concrete and abstract words</article-title>. <source>Hum. Brain Mapp</source>., <volume>7</volume>: <fpage>225</fpage>–<lpage>233</lpage>. https://doi.org/10.1002/(SICI)1097-0193(1999)7:4&lt;225::AID-HBM1&gt;3.0.CO;2-P</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Kroll</surname>, <given-names>J. F.</given-names></string-name>, &amp; <string-name><surname>Merves</surname>, <given-names>J. S</given-names></string-name>. (<year>1986</year>). <article-title>Lexical access for concrete and abstract words. <italic>Journal of Experimental Psychology: Learning</italic></article-title>, <source>Memory, and Cognition</source>, <volume>12</volume>(<issue>1</issue>), <fpage>92</fpage>–<lpage>107</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.12.1.92</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Kutas</surname> <given-names>M</given-names></string-name>, <string-name><surname>Federmeier</surname> <given-names>KD</given-names></string-name>. <article-title>Thirty years and counting: finding meaning in the N400 component of the event-related brain potential (ERP)</article-title>. <source>Annu Rev Psychol</source>. <year>2011</year>;<volume>62</volume>:<fpage>621</fpage>–<lpage>47</lpage>. doi: <pub-id pub-id-type="doi">10.1146/annurev.psych.093008.131123</pub-id>. PMID: <pub-id pub-id-type="pmid">20809790</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC4052444</pub-id>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Lebois</surname>, <given-names>L. A.</given-names></string-name>, <string-name><surname>Wilson-Mendenhall</surname>, <given-names>C. D.</given-names></string-name>, &amp; <string-name><surname>Barsalou</surname>, <given-names>L. W</given-names></string-name>. (<year>2015</year>). <article-title>Are Automatic Conceptual Cores the Gold Standard of Semantic Processing? The Context-Dependence of Spatial Meaning in Grounded Congruency Effects</article-title>. <source>Cogn Sci</source>, <volume>39</volume>(<issue>8</issue>), <fpage>1764</fpage>–<lpage>1801</lpage>. <pub-id pub-id-type="doi">10.1111/cogs.12174</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Lu</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Fei</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Lu</surname>, <given-names>Z.</given-names></string-name>, M., D., <string-name><surname>Wen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Du</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Sun</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>He</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Wen</surname>, <given-names>J. R</given-names></string-name>. (<year>2022</year>). <article-title>Multimodal foundation models are better simulators of the human brain</article-title>. <source>arXivLabs (preprint</source><italic>)</italic>. <pub-id pub-id-type="doi">10.48550/arXiv.2208.08263</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Lynott</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Connell</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Brysbaert</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Brand</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Carney</surname>, <given-names>J</given-names></string-name>. (<year>2020</year>). <article-title>The Lancaster Sensorimotor Norms: multidimensional measures of perceptual and action strength for 40,000 English words</article-title>. <source>Behav Res Methods</source>, <volume>52</volume>(<issue>3</issue>), <fpage>1271</fpage>–<lpage>1291</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-019-01316-z</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Mellet</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Tzourio</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Mazoyer</surname>, <given-names>B</given-names></string-name>. (<year>1998</year>). <article-title>Cortical anatomy of mental imagery of concrete nouns based on their dictionary definition</article-title>. <source>NeuroReport</source>, <volume>9</volume>(<issue>5</issue>), <fpage>5</fpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>Meteyard</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Cuadrado</surname>, <given-names>S.R.</given-names></string-name>, <string-name><surname>Bahrami</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Vigliocco</surname>, <given-names>G</given-names></string-name>. (<year>2012</year>). <article-title>Coming of age: A review of embodiment and the neuroscience of semantics</article-title>. <source>Cortex</source>, <volume>48</volume>, <fpage>788</fpage>–<lpage>804</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Mkrtychian</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Blagovechtchenski</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Kurmakaeva</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Gnedykh</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kostromina</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Shtyrov</surname>, <given-names>Y</given-names></string-name>. (<year>2019</year>). <article-title>Concrete vs. Abstract Semantics: From Mental Representations to Functional Brain Mapping</article-title>. <source>Front Hum Neurosci</source>, <volume>13</volume>, <fpage>267</fpage>. <pub-id pub-id-type="doi">10.3389/fnhum.2019.00267</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Muraki</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Cortese</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Protzner</surname>, <given-names>A. B.</given-names></string-name>, &amp; <string-name><surname>Pexman</surname>, <given-names>P. M</given-names></string-name>. (<year>2020</year>). <article-title>Heterogeneity in abstract verbs: An ERP study</article-title>. <source>Brain and Language</source>, <volume>211</volume>, <fpage>104863</fpage>. <pub-id pub-id-type="doi">10.1016/j.bandl.2020.104863</pub-id></mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Muraki</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Sidhu</surname>, <given-names>D. M.</given-names></string-name>, &amp; <string-name><surname>Pexman</surname>, <given-names>P. M</given-names></string-name>. (<year>2020</year>). <article-title>Heterogenous abstract concepts: Is ‘ponder’ different from ‘dissolve’?</article-title> <source>Psychological Research</source>, <volume>86</volume>(<issue>8</issue>), <fpage>2478</fpage>–<lpage>2494</lpage>. <pub-id pub-id-type="doi">10.1007/s00426-020-01398-x</pub-id></mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><string-name><surname>Noppeney</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Phillips</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Price</surname>, <given-names>C</given-names></string-name>. (<year>2004</year>). <article-title>The neural areas that control the retrieval and selection of semantics</article-title>. <source>Neuropsychologia</source>, <volume>42</volume>(<issue>9</issue>), <fpage>1269</fpage>–<lpage>1280</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2003.12.014</pub-id></mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><string-name><surname>Oosterwijk</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Mackey</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Wilson-Mendenhall</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Winkielman</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Paulus</surname>, <given-names>M. P</given-names></string-name>. (<year>2015</year>). <article-title>Concepts in context: Processing mental state concepts with internal or external focus involves different neural systems</article-title>. <source>Soc Neurosci</source>, <volume>10</volume>(<issue>3</issue>), <fpage>294</fpage>–<lpage>307</lpage>. <pub-id pub-id-type="doi">10.1080/17470919.2014.998840</pub-id></mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><string-name><surname>Pennington</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Socher</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Manning</surname>, <given-names>C. D</given-names></string-name>. (<year>2014</year>). <article-title>GloVe: Global Vectors for Word Representation</article-title>. <source>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</source>, <volume>11</volume>. <pub-id pub-id-type="doi">10.3115/v1/D14-1162</pub-id></mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><string-name><surname>Pexman</surname>, <given-names>P. M.</given-names></string-name>, <string-name><surname>Heard</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Lloyd</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Yap</surname>, <given-names>M. J</given-names></string-name>. (<year>2017</year>). <article-title>The Calgary semantic decision project: concrete/abstract decision data for 10,000 English words</article-title>. <source>Behav Res Methods</source>, <volume>49</volume>(<issue>2</issue>), <fpage>407</fpage>–<lpage>417</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-016-0720-6</pub-id></mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><string-name><surname>Piantadosi</surname>, <given-names>S.</given-names></string-name>, <string-name><given-names>T.</given-names>, <surname>&amp; Hill</surname></string-name>, F. (<year>2022</year>). <article-title>Meaning Without Reference in Large Language Models</article-title>. <source>Archive (preprint</source><italic>)</italic>. <pub-id pub-id-type="doi">10.48550/arXiv.2208.02957</pub-id></mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><string-name><surname>Popp</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Trumpp</surname>, <given-names>N. M.</given-names></string-name>, &amp; <string-name><surname>Kiefer</surname>, <given-names>M</given-names></string-name>. (<year>2019</year>). <article-title>Processing of action and sound verbs in context: An fMRI study</article-title>. <source>Translational Neuroscience</source>, <volume>10</volume>, <fpage>200</fpage>–<lpage>222</lpage>. <pub-id pub-id-type="doi">10.1515/tnsci-2019-0035</pub-id></mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><string-name><surname>Pulvermuller</surname>, <given-names>F</given-names></string-name>. (<year>2005</year>). <article-title>Brain mechanisms linking language and action</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>6</volume>, <fpage>6</fpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><string-name><surname>Pulvermüller</surname>, <given-names>F</given-names></string-name>. (<year>2018</year>). <article-title>Neurobiological mechanisms for semantic feature extraction and conceptual flexibility</article-title>. <source>Topics in Cognitive Science</source>, <volume>10</volume>(<issue>3</issue>), <fpage>590</fpage>–<lpage>620</lpage>. <pub-id pub-id-type="doi">10.1111/tops.12367</pub-id></mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><string-name><surname>Pulvermuller</surname>, <given-names>F</given-names></string-name>. (<year>2018</year>). <article-title>Neural reuse of action perception circuits for language, concepts and communication</article-title>. <source>Prog Neurobiol</source>, <volume>160</volume>, <fpage>1</fpage>–<lpage>44</lpage>. <pub-id pub-id-type="doi">10.1016/j.pneurobio.2017.07.001</pub-id></mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><string-name><surname>Pulvermuller</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Fadiga</surname>, <given-names>L</given-names></string-name>. (<year>2010</year>). <article-title>Active perception: sensorimotor circuits as a cortical basis for language</article-title>. <source>Nat Rev Neurosci</source>, <volume>11</volume>(<issue>5</issue>), <fpage>351</fpage>–<lpage>360</lpage>. <pub-id pub-id-type="doi">10.1038/nrn2811</pub-id></mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><string-name><surname>Reinboth</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Farkaš</surname>, <given-names>I</given-names></string-name>. (<year>2022</year>). <article-title>Ultimate Grounding of Abstract Concepts: A Graded Account</article-title>. <source>Journal of Cognition</source>, <volume>5</volume>(<fpage>1</fpage>). <pub-id pub-id-type="doi">10.5334/joc.214</pub-id></mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><string-name><surname>Roversi</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Borghi</surname>, <given-names>A. M.</given-names></string-name>, &amp; <string-name><surname>Tummolini</surname>, <given-names>L</given-names></string-name>. (<year>2013</year>). <article-title>A marriage is an artefact and not a walk that we take together: An experimental study on the categorization of artefacts</article-title>. <source>Review of Philosophy and Psychology</source>, <volume>4</volume>(<issue>3</issue>), <fpage>527</fpage>–<lpage>542</lpage>. <pub-id pub-id-type="doi">10.1007/s13164-013-0150-7</pub-id></mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><string-name><surname>Sabsevitz</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Medler</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Seidenberg</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Binder</surname>, <given-names>J. R</given-names></string-name>. (<year>2005</year>). <article-title>Modulation of the semantic system by word imageability</article-title>. <source>Neuroimage</source>, <volume>27</volume>(<issue>1</issue>), <fpage>188</fpage>–<lpage>200</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.04.012</pub-id></mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><string-name><surname>Simmons</surname>, <given-names>W. K.</given-names></string-name>, <string-name><surname>Ramjee</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Beauchamp</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>McRae</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Barsalou</surname>, <given-names>L. W</given-names></string-name>. (<year>2007</year>). <article-title>A common neural substrate for perceiving and knowing about color</article-title>. <source>Neuropsychologia</source>, <volume>45</volume>(<issue>12</issue>), <fpage>2802</fpage>–<lpage>2810</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2007.05.002</pub-id></mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><string-name><surname>Skipper</surname>, <given-names>J. I.</given-names></string-name>, <string-name><surname>Aliko</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Jo</surname>, <given-names>Y. J.</given-names></string-name>, <string-name><surname>Lo</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Molimpakis</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Lametti</surname>, <given-names>D. R</given-names></string-name>. (<year>2022</year>). <article-title>Reorganization of the Neurobiology of Language After Sentence Overlearning</article-title>. <source>Cereb Cortex</source>, <volume>32</volume>(<issue>11</issue>), <fpage>2447</fpage>–<lpage>2468</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhab354</pub-id></mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><string-name><surname>Skipper</surname>, <given-names>J. I.</given-names></string-name>, <string-name><surname>Goldin-Meadow</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Nusbaum</surname>, <given-names>H. C.</given-names></string-name>, &amp; <string-name><surname>Small</surname>, <given-names>S. L</given-names></string-name>. (<year>2009</year>). <article-title>Gestures orchestrate brain networks for language understanding</article-title>. <source>Curr Biol</source>, <volume>19</volume>(<issue>8</issue>), <fpage>661</fpage>–<lpage>667</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2009.02.051</pub-id></mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="other"><string-name><surname>Skipper</surname>, <given-names>J. I.</given-names></string-name>, &amp; <string-name><surname>Willems</surname>, <given-names>R. M.</given-names></string-name> (<year>2015</year>). <article-title>The NOLB model: a model of the natural organization of language and the brain</article-title>. <source>In Cognitive Neuroscience of Natural Language Use</source> (pp. 101-134). <pub-id pub-id-type="doi">10.1017/cbo9781107323667.006</pub-id></mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><string-name><surname>Tanenhaus</surname>, <given-names>M. K.</given-names></string-name>, <string-name><given-names>M. J.</given-names> <surname>Spivey-Knowlton</surname></string-name>, <string-name><given-names>K. M.</given-names> <surname>Eberhard</surname></string-name>, and <string-name><given-names>J. C.</given-names> <surname>edivy</surname></string-name>. <article-title>Integration of visual and linguistic information in spoken language comprehension</article-title>. <source>Science</source>, <volume>268</volume>, <year>1995</year>.</mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="other"><string-name><surname>Tang</surname>, <given-names>J. Amanda</given-names></string-name> <string-name><surname>LeBel</surname>, <given-names>Shailee</given-names></string-name> <string-name><surname>Jain</surname>, and <given-names>Alexander G.</given-names></string-name> <article-title>Huth. Semantic reconstruction 1103 of continuous language from non-1 invasive brain recordings</article-title>. <source>Bioarchive</source>, <volume>2022</volume>.</mixed-citation></ref>
<ref id="c86"><mixed-citation publication-type="journal"><string-name><surname>Thompson-Schill</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>D’Esposito</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Kan</surname>, <given-names>I. P</given-names></string-name>. (<year>1999</year>). <article-title>Effects of repetition and competition on activity in left prefrontal cortex during word generation</article-title>. <source>Neuron</source>, <volume>23</volume>, <fpage>513</fpage>–<lpage>522</lpage></mixed-citation></ref>
<ref id="c87"><mixed-citation publication-type="journal"><string-name><surname>Van Dam</surname>, <given-names>W. O.</given-names></string-name>, <string-name><surname>van Dijk</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bekkering</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Rueschemeyer</surname>, <given-names>S. A.</given-names></string-name> (<year>2012</year>). <article-title>Flexibility in embodied lexical-semantic representations</article-title>. <source>Human Brain Mapping</source>, <volume>33</volume>(<issue>10</issue>), <fpage>2322</fpage>–<lpage>2333</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.21365</pub-id>)</mixed-citation></ref>
<ref id="c88"><mixed-citation publication-type="journal"><string-name><surname>Vaswani</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Shazeer</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Parmar</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Uszkoreit</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Jones</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Gomez</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kaiser</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Polosukhin</surname>, <given-names>I</given-names></string-name>. (<year>2017</year>). <article-title>Attention is All You Need</article-title>. <source>arXivLabs (preprint</source><italic>)</italic>. <pub-id pub-id-type="doi">10.48550/arXiv.1706.03762</pub-id></mixed-citation></ref>
<ref id="c89"><mixed-citation publication-type="journal"><collab>Vigliocco, G. J. Warren, S. Siri, J. Arciuli, S. Scott, and R. Wise</collab>. <article-title>The role of semantics and 866 grammatical class in the neural representation of words</article-title>. <source>Cereb Cortex</source>, <volume>16</volume>(<issue>12</issue>):<fpage>1790</fpage>–<lpage>6</lpage>, <year>2006</year>.867 ISSN 1047-3211 (Print) 1047-3211</mixed-citation></ref>
<ref id="c90"><mixed-citation publication-type="journal"><string-name><surname>Vigliocco</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Meteyard</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Andrews</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Kousta</surname>, <given-names>S</given-names></string-name>. (<year>2009</year>). <article-title>Toward a theory of semantic representation</article-title>. <source>Language and Cognition</source>, <volume>1</volume>(<issue>2</issue>), <fpage>219</fpage>–<lpage>247</lpage>. doi:<pub-id pub-id-type="doi">10.1515/LANGCOG.2009.011</pub-id></mixed-citation></ref>
<ref id="c91"><mixed-citation publication-type="journal"><string-name><surname>Vigliocco</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Kousta</surname>, <given-names>S. T.</given-names></string-name>, <string-name><surname>Della Rosa</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Vinson</surname>, <given-names>D. P.</given-names></string-name>, <string-name><surname>Tettamanti</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Devlin</surname>, <given-names>J. T.</given-names></string-name>, &amp; <string-name><surname>Cappa</surname>, <given-names>S. F.</given-names></string-name> (<year>2014</year>). <article-title>The neural representation of abstract words: the role of emotion</article-title>. <source>Cereb Cortex</source>, <volume>24</volume>(<issue>7</issue>), <fpage>1767</fpage>–<lpage>1777</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bht025</pub-id></mixed-citation></ref>
<ref id="c92"><mixed-citation publication-type="journal"><string-name><surname>Villani</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Lugli</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Liuzza</surname>, <given-names>M. T.</given-names></string-name>, &amp; <string-name><surname>Borghi</surname>, <given-names>A. M</given-names></string-name>. (<year>2019</year>). <article-title>Varieties of abstract concepts and their multiple dimensions</article-title>. <source>Language and Cognition</source>, <volume>11</volume>(<issue>3</issue>), <fpage>403</fpage>–<lpage>430</lpage>. <pub-id pub-id-type="doi">10.1017/langcog.2019.23</pub-id></mixed-citation></ref>
<ref id="c93"><mixed-citation publication-type="journal"><string-name><surname>Villani</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Lugli</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Liuzza</surname>, <given-names>M. T.</given-names></string-name>, <string-name><surname>Nicoletti</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Borghi</surname>, <given-names>A. M</given-names></string-name>. (<year>2021</year>). <article-title>Sensorimotor and interoceptive dimensions in concrete and abstract concepts</article-title>. <source>J Mem Lang</source>, <volume>116</volume>, <fpage>104173</fpage>. <pub-id pub-id-type="doi">10.1016/j.jml.2020.104173</pub-id></mixed-citation></ref>
<ref id="c94"><mixed-citation publication-type="journal"><string-name><surname>Wagner</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Paré-Blagoev</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Poldrack</surname>, <given-names>R. A</given-names></string-name>. (<year>2001</year>). <article-title>Recovering meaning: Left prefrontal cortex guides controlled semantic retrieval</article-title>. <source>Neuron</source>, <volume>31</volume>, <fpage>329</fpage>–<lpage>338</lpage></mixed-citation></ref>
<ref id="c95"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Conder</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Blitzer</surname>, <given-names>D. N.</given-names></string-name>, &amp; <string-name><surname>Shinkareva</surname>, <given-names>S. V</given-names></string-name>. (<year>2010</year>). <article-title>Neural representation of abstract and concrete concepts: a meta-analysis of neuroimaging studies</article-title>. <source>Hum Brain Mapp</source>, <volume>31</volume>(<issue>10</issue>), <fpage>1459</fpage>–<lpage>1468</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.20950</pub-id></mixed-citation></ref>
<ref id="c96"><mixed-citation publication-type="journal"><string-name><surname>Warriner</surname>, <given-names>A. B.</given-names></string-name>, <string-name><surname>Kuperman</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Brysbaert</surname>, <given-names>M</given-names></string-name>. (<year>2013</year>). <article-title>Norms of valence, arousal, and dominance for 13,915 English lemmas</article-title>. <source>Behav Res Methods</source>, <volume>45</volume>(<issue>4</issue>), <fpage>1191</fpage>–<lpage>1207</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-012-0314-x</pub-id></mixed-citation></ref>
<ref id="c97"><mixed-citation publication-type="journal"><string-name><surname>Whitney</surname>, <given-names>C.</given-names></string-name>, <string-name><given-names>M.</given-names> <surname>Kirk</surname></string-name>, <string-name><given-names>J.</given-names> <surname>O’Sullivan</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>Lambon Ralph</surname></string-name>, and <string-name><given-names>E.</given-names> <surname>Jefferies</surname></string-name>. <article-title>The neural organization of semantic control: Tms evidence for a distributed network in left inferior frontal and posterior middle temporal gyrus</article-title>. <source>Cereb Cortex</source>, <volume>21</volume>(<issue>5</issue>):<fpage>1066</fpage>–<lpage>75</lpage>, <year>2011</year>. URL <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/20851853">https://www.ncbi.nlm.nih.gov/pubmed/20851853</ext-link>.</mixed-citation></ref>
<ref id="c98"><mixed-citation publication-type="journal"><string-name><surname>Wiemer-Hastings</surname>, <given-names>K.</given-names></string-name> and <string-name><surname>Xu</surname>, <given-names>X</given-names></string-name>. (<year>2005</year>), <article-title>Content Differences for Abstract and Concrete Concepts</article-title>. <source>Cognitive Science</source>, <volume>29</volume>: <fpage>719</fpage>–<lpage>736</lpage>. <pub-id pub-id-type="doi">10.1207/s15516709cog0000_33</pub-id></mixed-citation></ref>
<ref id="c99"><mixed-citation publication-type="journal"><string-name><surname>Willems</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Hagoort</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Casasanto</surname>, <given-names>D</given-names></string-name>. (<year>2010</year>). <article-title>Body-specific representations of action verbs: neural evidence from right- and left-handers</article-title>. <source>Psychol Sci</source>, <volume>21</volume>(<issue>1</issue>), <fpage>67</fpage>–<lpage>74</lpage>. <pub-id pub-id-type="doi">10.1177/0956797609354072</pub-id></mixed-citation></ref>
<ref id="c100"><mixed-citation publication-type="journal"><string-name><surname>Yee</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Thompson-Schill</surname>, <given-names>S. L</given-names></string-name>. (<year>2016</year>). <article-title>Putting concepts into context</article-title>. <source>Psychon Bull Rev</source>, <volume>23</volume>(<issue>4</issue>), <fpage>1015</fpage>–<lpage>1027</lpage>. <pub-id pub-id-type="doi">10.3758/s13423-015-0948-7</pub-id></mixed-citation></ref>
<ref id="c101"><mixed-citation publication-type="journal"><string-name><surname>Yeshurun</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Nguyen</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Hasson</surname>, <given-names>U</given-names></string-name>. (<year>2021</year>). <article-title>The default mode network: where the idiosyncratic self meets the shared social world</article-title>. <source>Nat Rev Neurosci</source>, <volume>22</volume>(<issue>3</issue>), <fpage>181</fpage>–<lpage>192</lpage>. <pub-id pub-id-type="doi">10.1038/s41583-020-00420-w</pub-id></mixed-citation></ref>
<ref id="c102"><mixed-citation publication-type="journal"><string-name><surname>Zdrazilova</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Sidhu</surname>, <given-names>D. M.</given-names></string-name>, &amp; <string-name><surname>Pexman</surname>, <given-names>P. M</given-names></string-name>. (<year>2018</year>). <article-title>Communicating abstract meaning: Concepts revealed in words and gestures</article-title>. <source>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</source>, <volume>373</volume>(<fpage>1752</fpage>). <pub-id pub-id-type="doi">10.1098/rstb.2017.0138</pub-id></mixed-citation></ref>
</ref-list>
<sec id="s5">
<title>Supplementary Material</title>
<p>Complete Results for Meta-Analysis &amp; Peak and Valley Analysis</p>
<table-wrap id="tbls1" orientation="portrait" position="float">
<label>Table S1.</label><caption><title>Meta analytic description of concrete and abstract activation clusters.</title></caption>
<graphic xlink:href="506944v3_tbls1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbls2" orientation="portrait" position="float">
<label>Table S2.</label><caption><title>Peak and Valley between concrete and abstract activation clusters.</title></caption>
<graphic xlink:href="506944v3_tbls2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Figure S1.</label>
<caption><p>Peak and Valley Analysis for a 4s lag. A Kruskal-Wallis test shows that the distribution between sensorimotor and interoceptive/emotional dimensions for concrete and abstract words is significantly different to a 5s (H(2)=4,8, p=0.03 and 6s (H(2)=5.3, p=0.02) lag.</p></caption>
<graphic xlink:href="506944v3_figs1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Figure S2.</label>
<caption><p>Peak and Valley Analysis for a 5s lag. Internal dimensions Valence and Arousal are significantly more associated with peaks in abstract compared to concrete clusters (Valence: H(2) = 5.8, p=.02; Arousal: H(2) = 6.7, p = .01). Conversely, concrete clusters are more associated with sensorimotor dimensions (Hand_Arm, Foot_Leg and Visual) – though not significantly so. Overlap is significantly more associated with “Mouth” (H(2) = 6.2, p=0.2).</p></caption>
<graphic xlink:href="506944v3_figs2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Figure S3.</label>
<caption><p>Main effect of context. Most significantly modulated areas include the intersection between posterior temporal and occipital lobe, the Precuneus, Middle Prefrontal Cortex, as well as Angular Gyrus, and right inferior frontal gyrus. Results are thresholded and corrected for multiple comparisons at α = 0.01 and displayed with a cluster-size ≧ 20 voxels.</p></caption>
<graphic xlink:href="506944v3_figs3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Figure S4.</label>
<caption><p>Main effect of word_type. Most significantly modulated areas include superior temporal sulcus, superior temporal gyrus and middle temporal gyrus (bilateral), angular gyrus (bilateral), the central sulcus and precentral and postcentral gyrus (right hemisphere), as well as lateral and medial frontal cortices and the occipital lobe. Results are thresholded and corrected for multiple comparisons at α = 0.01 and displayed with a cluster-size ≧ 20 voxels.</p></caption>
<graphic xlink:href="506944v3_figs4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>Figure S5.</label>
<caption><p>Interaction between context (high/low) and word type (abstract/concrete). Most significantly modulated areas include the Precuneus, Middle Prefrontal Cortex as well as Middle Frontal Gyrus, Angular Gyrus and Posterior Cingulate Cortex. These correspond to the nodes of the default mode network, which was confirmed by using the neurosynth decoder on the untrhesholded brain image. The top 3 keywords were: “default”; “default mode” and “dmn”. Displayed results are thresholded and corrected for multiple comparisons at α = 0.01 and displayed with a cluster-size ≧ 20 voxels.</p></caption>
<graphic xlink:href="506944v3_figs5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs6" position="float" orientation="portrait" fig-type="figure">
<label>Figure S6.</label>
<caption><p>Interaction between context and word type broken up. Nodes of the DMN are especially active in the displaced condition for both abstract and concrete words. Visual and sensorimotor areas are especially active in situated conditions for both abstract and concrete words. Results are thresholded and corrected for multiple comparisons at α = 0.01 and displayed with a cluster-size ≧ 20 voxels</p></caption>
<graphic xlink:href="506944v3_figs6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs7" position="float" orientation="portrait" fig-type="figure">
<label>Figure S7.</label>
<caption><p>Comparison between the language network (outline) and overlap activity for both concrete and abstract words across context. Results are thresholded and corrected for multiple comparisons at α = 0.01 and displayed with a cluster-size ≧ 20 voxels</p></caption>
<graphic xlink:href="506944v3_figs7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Code</p>
<p>We implemented our data analysis in Bash, Python and R. Our code will be provided as online supplemental material upon publication and hosted openly on a dedicated Github repository.</p>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91522.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Martin</surname>
<given-names>Andrea E</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Max Planck Institute for Psycholinguistics</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>The work described in this manuscript is timely and <bold>useful</bold> in that it builds on prior research investigating the neural basis of abstract and concrete concepts by examining how these concepts are processed for a naturalistic stimulus - movie watching. The authors provide <bold>incomplete</bold> evidence that the varying strength of the relationship between a word and a particular visual scene is associated with a change in the similarity between the brain regions active for concrete and abstract words. This work makes a contribution that will be of general interest within the field despite some limitations in how the authors chose to define context, highlighting both the inherent challenge of quantifying context in a multimodal stimulus and the need to move towards brain imaging paradigms that capture context better than isolated word or sentence paradigms do.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91522.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
In this study, the authors investigate a very interesting but often overlooked aspect of abstract vs. concrete processing in language. Specifically, they study if the differences in processing of abstract vs. concrete concepts in the brain are static or dependent on the (visual) context in which the words occur. This study takes a two-step approach to investigate how context might affect the perception of concepts. First, the authors analyze if concrete concepts, expectedly, activate more sensory systems while abstract concepts activate higher-order processing regions. Second, they measure the contextual situatedness vs. displacement of each word with respect to the visual scenes it is spoken in and then evaluate if this contextual measure correlates with more activation in the sensory vs. higher-order regions respectively.</p>
<p>Strengths:</p>
<p>
This study raises a pertinent and understudied question in language neuroscience. It also combines both computational and meta-analytic approaches.</p>
<p>Weaknesses:</p>
<p>
Overall, the study had many intermediary steps that required manual subsection / random sampling and variable choices (like the time lag of analysis) with almost no visualization and interpretation of how these choices affect the observed results. The approach was also roundabout.</p>
<p>Peaks and Valleys Analysis:</p>
<p>
1. Doesn't this method assume that the features used to describe each word, like valence or arousal, will be linearly different for the peaks and valleys? What about non-linear interactions between the features and how they might modulate the response?</p>
<p>
2. Doesn't it also assume that the response to a word is infinitesimal and not spread across time? How does the chosen time window of analysis interact with the HRF? From the main figures and Figures S2-S3 there seem to be differences based on the timelag.</p>
<p>
3. Were the group-averaged responses used for this analysis?</p>
<p>
4. Why don't the other terms identified in Figure 5 show any correspondence to the expected categories? What does this mean? Can the authors also situate their results with respect to prior findings as well as visualize how stable these results are at the individual voxel or participant level? It would also be useful to visualize example time courses that demonstrate the peaks and valleys.</p>
<p>Estimating contextual situatedness:</p>
<p>
1. Doesn't this limit the analyses to &quot;visual&quot; contexts only? And more so, frequently recognized visual objects?</p>
<p>
2. The measure of situatedness is the cosine similarity of GloVE vectors that depend on word co-occurrence while the vectors themselves represent objects isolated by the visual recognition models. Expectedly, &quot;science&quot; and the label &quot;book&quot; or &quot;animal&quot; and the label &quot;dog&quot; will be close. But can the authors provide examples of context displacement? I wonder if this just picks up on instances where the identified object in the scene is unrelated to the word. How do the authors ensure that it is a displacement of context as opposed to the two words just being unrelated? This also has a consequence on deciding the temporal cutoff for consideration (2 seconds).</p>
<p>
3. While the introduction motivated the problem of context situatedness purely linguistically, the actual methods look at the relationship between recognized objects in the visual scene and the words. Can word surprisal or another language-based metric be used in place of the visual labeling? Also, it is not clear how the process identified in (2) above would come up with a high situatedness score for abstract concepts like &quot;truth&quot;.</p>
<p>
4. It is a bit hard to see the overlapping regions in Figures 6A-C. Would it be possible to show pairs instead of triples? Like &quot;abstract across context&quot; vs. &quot;abstract displaced&quot;? Without that, and given (2) above, the results are not yet clear. Moreover, what happens in the &quot;overlapping&quot; regions of Figure 3?</p>
<p>Miscellaneous comments:</p>
<p>
1. In Figure 3, it is surprising that the &quot;concrete-only&quot; regions dominate the angular gyrus and we see an overrepresentation of this category over &quot;abstract-only&quot;. Can the authors place their findings in the context of other studies?</p>
<p>
2. The following line (Pg 21) regarding the necessary differences in time for the two categories was not clear. How does this fall out from the analysis method?</p>
<p>
3. Both categories overlap **(though necessarily at different time points)** in regions typically associated with word processing.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91522.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
This study tests a plausible and intriguing hypothesis that one cause of the differences in the neural underpinnings of concrete and abstract words is differences in their grounding in the current sensory context. The authors reasoned that, in this case, an abstract word presented with a relevant visual scene would be processed in a more similar way to a concrete word. Typically, abstract and concrete words are tested in isolation. In contrast, this study takes advantage of naturalistic movie stimuli to assess the neural effects of concreteness in both abstract and concrete words (the speech within the film), when the visual context is more or less tied to the word meaning (measured as the similarity between the word co-occurrence-based vector for the spoken word and the average of this vector across all present objects). This novel approach allows a test of the dynamic nature of abstract and concrete word processing, and as such could extend the literature and add a useful perspective accounting for differences in processing these word types.</p>
<p>The critical contrasts needed to test the key hypothesis are not presented or not presented in full within the core text. To test whether abstract processing changes when in a situated context, the situated abstract condition would first need to be compared with the displaced abstract condition as in Supplementary Figure 6. Then to test whether this change makes the result closer to the processing of concrete words, this result should be compared to the concrete result. The correlations shown in Figure 6 in the main text are not focused on the differences in activity between the situated and displaced words or comparing the correlation of these two conditions with the other (concrete/abstract) condition. As such they cannot provide conclusive evidence as to whether the context is changing the processing of concrete/abstract words to be closer to the other condition. Additionally, it should be considered whether any effects reflect the current visual processing only or more general sensory processing.</p>
<p>Overall, the study would benefit from being situated in the literature more, including a) a more general understanding of the areas involved in semantic processing (including areas proposed to be involved across different sensory modalities and for verbal and nonverbal stimuli), and b) other differences between abstract and concrete words and whether they can explain the current findings, including other psycholinguistic variables which could be included in the model and the concept of semantic diversity (Hoffman et al.,). It would also be useful to consider whether difficulty effects (or processing effort) could explain some of the regional differences between abstract and concrete words (e.g., the language areas may simply require more of the same processing not more linguistic processing due to their greater reliance on word co-occurrence). Similarly, the findings are not considered in relation to prior comparisons of abstract and concrete words at the level of specific brain regions.</p>
<p>The authors use multiple methods to provide a post hoc interpretation of the areas identified as more involved in concrete, abstract, or both (at different times) words. These are designed to reduce the interpretation bias and improve interpretation, yet they may not successfully do so. These methods do give some evidence that sensory areas are more involved in concrete word processing. However, they are still open to interpretation bias as it is not clear whether all the evidence is consistent with the hypotheses or if this is the best interpretation of individual regions' involvement. This is because the hypotheses are provided at the level of 'sensory' and 'language' areas without further clarification and areas and terms found are simply interpreted as fitting these definitions. For instance, the right IFG is interpreted as a motor area, and therefore sensory as predicted, and the term 'autobiographical memory' is argued to be interoceptive. Language is associated with the 'both' cluster, not the abstract cluster, when abstract &gt;concrete is expected to engage language more. The areas identified for both vs. abstract&gt;concrete are distinguished in the Discussion through the description as semantic vs. language areas, but it is not clear how these are different or defined. Auditory areas appear to be included in the sensory prediction at times and not at others. When they are excluded, the rationale for this is not given. Overall, it is not clear whether all these areas and terms are expected and support the hypotheses. It should be possible to specify specific sensory areas where concrete and abstract words are predicted to be different based on a) prior comparisons and/or b) the known locations of sensory areas. Similarly, language or semantic areas could be identified using masks from NeuroSynth or traditional meta-analyses. A language network is presented in Supplementary Figure 7 but not interpreted, and its source is not given. Alternatively, there could be a greater interpretation of different possible explanations of the regions found with a more comprehensive assessment of the literature. The function of individual regions and the explanation of why many of these areas are interpreted as sensory or language areas are only considered in the Discussion when it could inform whether the hypotheses have been evidenced in the results section.</p>
<p>Additionally, these methods attempt to interpret all the clusters found for each contrast in the same way when they may have different roles (e.g., relate to different senses). This is a particular issue for the peaks and valleys method which assesses whether a significantly larger number of clusters is associated with each sensory term for the abstract, concrete, or both conditions than the other conditions. The number of clusters does not seem to be the right measure to compare. Clusters differ in size so the number of clusters does not represent the area within the brain well. Nor is it clear that many brain regions should respond to each sensory term, and not just one per term (whether that is V1 or the entire occipital lobe, for instance). The number of clusters is therefore somewhat arbitrary. This is further complicated by the assessment across 20 time points and the inclusion of the 'both' category. It would seem more appropriate to see whether each abstract and concrete cluster could be associated with each different sensory term and then summarise these findings rather than assess the number of abstract or concrete clusters found for each independent sensory term. In general, the rationale for the methods used should be provided (including the peak and valley method instead of other possible options e.g., linear regression).</p>
<p>The measure of contextual situatedness (how related a spoken word is to the average of the visually presented objects in a scene) is an interesting approach that allows parametric variation within naturalistic stimuli, which is a potential strength of the study. This measure appears to vary little between objects that are present (e.g., animal or room), and those that are strongly (e.g., monitor) or weakly related (e.g., science). Additional information validating this measure may be useful, as would consideration of the range of values and whether the split between situated (c &gt; 0.6) and displaced words (c &lt; 0.4) is sufficient.</p>
<p>Finally, the study assessed the relation of spoken concrete or abstract words to brain activity at different time points. The visual scene was always assessed using the 2 seconds before the word, while the neural effects of the word were assessed every second after the presentation for 20 seconds. This could be a strength of the study, however almost no temporal information was provided. The clusters shown have different timings, but this information is not presented in any way. Giving more temporal information in the results could help to both validate this approach and show when these areas are involved in abstract or concrete word processing. Additionally, no rationale was given for this long timeframe which is far greater than the time needed to process the word, and long after the presence of the visual context assessed (and therefore ignores the present visual context).</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91522.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
The primary aim of this manuscript was to investigate how context, defined from visual object information in multimodal movies, impacts the neural representation of concrete and abstract conceptual knowledge. The authors first conduct a series of analyses to identify context-independent regional responses to concrete and abstract concepts in order to compare these results with the networks observed in prior research using non-naturalistic paradigms. The authors then conduct analyses to investigate whether the regional response to abstract and concrete concepts changes when the concepts are either contextually situated or displaced. A concept is considered displaced if the visual information immediately preceding the word is weakly associated with the word whereas a concept is situated if the association is high. The results suggest that, when ignoring context, abstract and concrete concepts engage different brain regions with overlap in core language areas. When context is accounted for, however, similar brain regions are activated for processing concrete and situated abstract concepts and for processing abstract and displaced concrete concepts. The authors suggest that contextual information dynamically changes the brain regions that support the representation of abstract and concrete conceptual knowledge.</p>
<p>Strengths:</p>
<p>
There is significant interest in understanding both the acquisition and neural representation of abstract and concrete concepts, and most of the work in this area has used highly constrained, decontextualized experimental stimuli and paradigms to do so. This manuscript addresses this limitation by using multimodal narratives which allows for an investigation of how context-sensitive the regional response to abstract and concrete concepts is. The authors characterize the regional response in a comprehensive way.</p>
<p>Weaknesses:</p>
<p>
The context measure is interesting, but I'm not convinced that it's capturing what the authors intended. In analysing the neural response to a single word, the authors are presuming that they have isolated the window in which that concept is processed and the observed activation corresponds to the neural representation of that word given the prior context. I question to what extent this assumption holds true in a narrative when co-articulation blurs the boundaries between words and when rapid context integration is occurring. Further, the authors define context based on the preceding visual information. I'm not sure that this is a strong manipulation of the narrative context, although I agree that it captures some of the local context. It is maybe not surprising that if a word, abstract or concrete, has a strong association with the preceding visual information then activation in the occipital cortex is observed. I also wonder if the effects being captured have less to do with concrete and abstract concepts and more to do with the specific context the displaced condition captures during a multimodal viewing paradigm. If the visual information is less related to the verbal content, the viewer might process those narrative moments differently regardless of whether the subsequent word is concrete or abstract. I think the claims could be tailored to focus less generally on context and more specifically on how visually presented objects, which contribute to the ongoing context of a multimodal narrative, influence the subsequent processing of abstract and concrete concepts.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91522.1.sa4</article-id>
<title-group>
<article-title>Author Response</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Kewenig</surname>
<given-names>Viktor</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Vigliocco</surname>
<given-names>Gabriella</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Skipper</surname>
<given-names>Jeremy I</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5503-764X</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We thank the reviewers for their detailed and constructive criticisms of our work. They raise many important questions (such as the issue of defining context) that we have also been thinking about extensively and they provide new and insightful avenues that have the potential to meaningfully improve the manuscript. We also appreciate that they commented on the novelty and importance of this work. Going forward, we will address the methodological concerns raised as best as we can and thereby hope to make the evidence for our conclusion more compelling</p>
</body>
</sub-article>
</article>