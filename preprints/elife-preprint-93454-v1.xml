<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">93454</article-id>
<article-id pub-id-type="doi">10.7554/eLife.93454</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.93454.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Visual routines for detecting causal interactions are tuned to motion direction</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0292-2151</contrib-id>
<name>
<surname>Ohl</surname>
<given-names>Sven</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8214-8556</contrib-id>
<name>
<surname>Rolfs</surname>
<given-names>Martin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Psychology, Humboldt-Universität zu Berlin</institution>, Rudower Chaussee 18, 12489 Berlin, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>Berlin School of Mind and Brain, Humboldt-Universität zu Berlin</institution>, Rudower Chaussee 18, 12489 Berlin, <country>Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Kok</surname>
<given-names>Peter</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Moore</surname>
<given-names>Tirin</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Stanford University, Howard Hughes Medical Institute</institution>
</institution-wrap>
<city>Stanford</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label><bold>Corresponding author:</bold> Sven Ohl, Phone: ++49 (0)30 2093 6789, Email: <email>sven.ohl@hu-berlin.de</email></corresp>
<fn id="n1" fn-type="others"><p>Email: <email>martin.rolfs@hu-berlin.de</email></p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-01-10">
<day>10</day>
<month>01</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP93454</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-11-02">
<day>02</day>
<month>11</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-10-10">
<day>10</day>
<month>10</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.08.22.554237"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Ohl &amp; Rolfs</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Ohl &amp; Rolfs</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-93454-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Detecting causal relations structures our perception of events in the world. Here, we determined whether generalized or specialized visual routines underly the perception of causality by assessing the adaptability of specific features in launching events of simple geometric shapes. After prolonged exposure to causal launch events (the adaptor) defined by a particular set of features (i.e., a particular motion direction, motion speed, or feature conjunction), observers were less likely to see causal interactions in subsequent ambiguous test events. We assessed whether this negative aftereffect transfers to test events with a new set of feature values that were not presented during adaptation. Processing in specialized (as opposed to generalized) visual routines predicts that the transfer of adaptation depends on the feature-similarity of the adaptor and the test event. We show that negative aftereffects do not transfer to unadapted launch directions. Crucially, adaptation was contingent on the causal impression in launches as demonstrated by a lack of adaptation in non-causal control events. In contrast, adaptation to launches with a particular motion speed transferred also to a different speed. Moreover, adaptation based on feature conjunctions (color and launch direction) revealed that launch direction trumps the feature identity of the object for causal perception; the adaptation transferred across colors if the test event had the same motion direction as the adaptor. In summary, visual adaptation allowed us to carve out a visual feature space underlying the perception of causality and revealed specialized visual routines that are tuned to a launch’s motion direction.</p>
</abstract>
<abstract abstract-type="teaser">
<title>Significance statement</title>
<p>We used visual adaptation to carve out a visual feature space that is critical for detecting collisions in launching events. Observers were less likely to report perceiving a collision after the repeated viewing of launches. Importantly, observers’ perception of collisions in the opposite direction as the adaptor were not affected by the adaptation. However, provided the test stimulus had the adapted direction of motion, the speed or the color of the objects involved in the launching event did not need to be the same as during adaptation to show the negative aftereffect. Thus, visual routines underlying the detection of causal interactions are selective for motion direction, therefore providing evidence that the perception of causality relies on low-level perceptual processes.</p></abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Causality</kwd>
<kwd>perception</kwd>
<kwd>visual cognition</kwd>
<kwd>adaptation</kwd>
<kwd>direction selectivity</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Revision of the format.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>When two objects collide, the objects’ future path can be inferred based on physical laws, allowing us, for instance, to purposely change the motion path of an asteroid by steering an uncrewed spacecraft into a collision with the asteroid (see NASA’s Double Asteroid Redirection Test; <bold><xref rid="fig1" ref-type="fig">Figure 1a</xref></bold>). In contrast, how humans detect such causal interactions in their visual environment is less clear. The proposed theories regarding our understanding of causal sensory interactions vary considerably, proposing purely perceptual (<xref ref-type="bibr" rid="c14">Michotte, 1963</xref>; <xref ref-type="bibr" rid="c23">Scholl &amp; Tremoulet, 2000</xref>), abstract probabilistic (<xref ref-type="bibr" rid="c22">Sanborn et al., 2013</xref>), or cognitive mechanisms (<xref ref-type="bibr" rid="c18">Rips, 2011</xref>; <xref ref-type="bibr" rid="c25">Weir, 1978</xref>; <xref ref-type="bibr" rid="c26">White, 2006</xref>). These are neither mutually exclusive nor do they make distinct predictions and they are therefore hard to distinguish (<xref ref-type="bibr" rid="c18">Rips, 2011</xref>). Here, we will study the mechanisms underlying the computations of causal interactions by capitalizing on visual adaptation of causality (<xref ref-type="bibr" rid="c12">Kominsky &amp; Scholl, 2020</xref>; <xref ref-type="bibr" rid="c20">Rolfs et al., 2013</xref>). Adaptation is a powerful behavioral tool for discovering and dissecting a visual mechanism (<xref ref-type="bibr" rid="c11">Kohn, 2007</xref>; <xref ref-type="bibr" rid="c24">Webster, 2015</xref>) that provides an intriguing testing ground for the perceptual roots of causality. Perceptual accounts of causal understanding posit the existence of visual routines (e.g., cause detectors) located in the visual system, however, their precise nature remain rather hazy. In its purest form such a visual routine could constitute a generalized mechanism that responds to all kinds of causal interactions. Alternatively, there could be many different specialized visual routines for the detection of causality that are tuned to the features of a particular causal interaction (e.g., the direction, kinematics, or object identity; <bold><xref rid="fig1" ref-type="fig">Figure 1b</xref></bold>; see <xref ref-type="bibr" rid="c18">Rips, 2011</xref> for a discussion). Here, we will use visual adaptation to determine whether the computation of causality occurs in generalized (i.e., feature-invariant) or in specialized (i.e., feature-selective) visual routines. Specifically, we will determine whether or not an adaptor is most effective for test events that match the features of the adaptor.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><p>The perception of causality. <bold>a</bold> A person perceiving an upcoming causal interaction between an uncrewed spacecraft and an asteroid. <bold>b</bold> Features of such launching events are the direction and speed of the colliding objects as well as their object identities (i.e., a specific set of features). Assessing the adaptation’s transfer between features allows us to determine whether the perception of causality arises in specialized visual routines that are tuned to a particular visual feature. <bold>c</bold> Trial sequence of a test event. A peripheral disc moved towards a stationary disc and stopped with some degree of overlap (ranging from 0–100% overlap in seven equidistant steps) between the two discs. The second disc then immediately started to move in the same direction, with the same speed as the first disc. In adaptation blocks, 320 launches were presented before the first test event of a block, and 16 top-up adaptation events before each subsequent test event.</p></caption>
<graphic xlink:href="554237v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To this end, we took advantage of the phenomenon that observers perceive causality even in simple kinematic displays—a moving disc that stops next to another disc appears to launch the second disc into motion (i.e., launching effect, <bold><xref rid="fig1" ref-type="fig">Figure 1c</xref></bold>; <xref ref-type="bibr" rid="c14">Michotte, 1963</xref>; see <xref ref-type="bibr" rid="c18">Rips, 2011</xref>; <xref ref-type="bibr" rid="c23">Scholl &amp; Tremoulet, 2000</xref>; <xref ref-type="bibr" rid="c26">White, 2006</xref>, <xref ref-type="bibr" rid="c27">2017</xref> for reviews). The prolonged viewing of such launching events in an adaptation protocol strongly alters the perception of causality by reducing the proportion of reported launches in subsequent test events (<xref ref-type="bibr" rid="c20">Rolfs et al., 2013</xref>). The adaptation of causality is spatially specific to the retinotopic coordinates of the adapting stimulus (<xref ref-type="bibr" rid="c20">Rolfs et al., 2013</xref>), suggesting that the detection of causal interactions is implemented locally in visual space. Here, we selected adaptors from a feature space—while keeping their spatial locations constant—and determined whether adaptation transfers to test events with a different set of features in that feature space (<bold><xref rid="fig1" ref-type="fig">Figure 1b</xref></bold>). If the strength of the adaptation’s perceptual consequences depends on the similarity of the adapter and the test event, it would reveal the existence of specialized visual routines for the detection of causal interactions that are tuned to that feature (i.e., there would be multiple visual routines within a feature dimension, each tuned to a different preferred feature value). Alternatively, if we observe adaptation transfer from one feature to another, this will support the notion of a generalized, feature-invariant, visual routine.</p>
<p>In three experiments, we assessed whether adaptation to launches of a particular motion direction, motion speed, or feature identity (i.e., a conjunction of two features) transfers to other values of that feature space or, alternatively, whether the consequences of adaptation are restricted to the feature values of the adaptor. Our results provide compelling evidence for visual routines that are specialized for processing launches of a particular motion direction.</p>
</sec>
<sec id="s2">
<title>Method</title>
<sec id="s2a">
<title>Participants</title>
<p>In each of the three experiments, we tested eight human observers (<bold>Experiment 1</bold>: ages 21–32 years; 5 female; 3 male; 8 right-handed; 5 right-eye dominant: <bold>Experiment 2</bold>: ages 21–30 years; 5 female; 3 male; 7 right-handed; 6 right-eye dominant; <bold>Experiment 3</bold>: ages 23–30 years; 6 female; 1 non-binary; 7 right-handed; 6 right-eye dominant) in five sessions (1 training session without adaptation, 4 test sessions with adaptation). We determined the final sample size by computing 90 % power contours as a function of sample size and trial number (<xref ref-type="bibr" rid="c1">Baker et al., 2021</xref>) and defining the additional criterion of a minimum of 8 observers per experiment. Based on the data obtained in the session without adaptation (i.e., the first session), we determined whether participants do distinguish between passes and launches in the basic experiment by determining whether the proportion of reported passes increases with increasing disc overlap. We excluded observers that did not distinguish between passes and launches after the first session and replaced them by new observers (resulting in the replacement of one observer in each experiment). Data obtained in the first session (i.e., without adaptation) did not enter the final analyses. In <bold>Experiment 1</bold> and <bold>2</bold>, we paid observers 8€ per session as compensation for participation and a bonus of 4€ after successful completion of all sessions. In <bold>Experiment 3</bold>, we paid observers 10€ per session. In all experiments, we obtained observers’ written informed consent before the first session. All observers had normal or corrected-to-normal vision and color vision. The study was approved by the ethics committee of the Psychology Department of the Humboldt-Universität zu Berlin and it followed the guidelines of the Declaration of Helsinki (2008).</p>
</sec>
<sec id="s2b">
<title>Material</title>
<p>Observers sat in a sound-shielded, dimly lit room putting their head on a chin and forehead rest. We controlled for observers’ eye position by tracking their dominant eye using an Eyelink 1000 Desktop Mount eye tracker (SR Research, Ottawa, ON, Canada) with a sampling rate of 1000 Hz. We displayed visual stimuli on a video-projection screen (Celexon HomeCinema, Tharston, Norwich, UK) using a PROPixx DLP projector (VPixx Technologies Inc., Saint Bruno, QC, Canada) at a spatial resolution of 1920 x 1080 pixels and a refresh rate of 120 Hz. The screen was mounted on a wall at 180 cm away from the observer. The experiment was running on a DELL Precision T7810 (Debian GNU Linux 8) and implemented in Matlab (Mathworks, Natick, MA, USA) using the Psychophysics toolbox 3 (<xref ref-type="bibr" rid="c4">Brainard, 1997</xref>; <xref ref-type="bibr" rid="c10">Kleiner et al., 2007</xref>; <xref ref-type="bibr" rid="c16">Pelli, 1997</xref>) for stimulus presentation and the Eyelink toolbox (<xref ref-type="bibr" rid="c6">Cornelissen et al., 2002</xref>) for control of the eye tracker. Behavioral responses were collected by pressing one of the two possible keys on a standard keyboard.</p>
</sec>
<sec id="s2c">
<title>General procedure</title>
<p>In our experiments, we asked observers to report whether they perceived a launch or a pass in test events composed of two discs. In the test events, a peripheral disc approached a stationary second disc and stopped at varying disc overlaps across trials (<bold><xref rid="fig1" ref-type="fig">Figure 1c</xref></bold>). Immediately after that the second disc started moving in the same direction and with the same speed as the first disc. Before the first trial, observers read the instruction for the experiment that was displayed on the screen. As part of the instructions, we presented short demo trials of test events with 0 % overlap that are typically perceived as launches, and test events with full disc overlap, that are typically perceived as a pass. Observers had the opportunity to inspect these two events as often as they wanted. Following the instructions, observers ran a short training session of 14 trials with varying disc overlaps ranging from 0– 100 % overlap.</p>
<p>At the beginning of a trial, we asked observers to fixate a gray fixation point (diameter of 1.5 dva) in the center of the screen on a black background and the trial only started after observers successfully fixated the fixation symbol for at least 200 ms. We presented the test events at 3 dva below the fixation symbol. In these test events, the first moving disc (gray; diameter of 1.5 dva) located either left or right from the vertical meridian started moving towards a stationary disc (gray; diameter of 1.5 dva) located 3 dva below the fixation point. The first disc stopped moving at one of seven possible distances away from the stationary disc, resulting in seven different disc overlaps ranging from 0 to 100 %. The entire duration of the test event was 175 ms. At the end of the trial, observers reported whether they perceived a launch or a pass in the test event by pressing either the arrow up key for launches or arrow down key for passes.</p>
<p>The first session served the purpose to determine whether observers perceive launches and passes as a function of disc overlap in our behavioral task. To this end, observers completed 10 blocks with the direction of the test event (2 conditions: left vs. right) as well as the amount of disc overlap (7 conditions: ranging from 0–100 % overlap) presented in a randomized order in a block. Each combination of these manipulations was repeated two times in a block, resulting in 28 trials in each block and a total of 280 trials in the first session. In sessions 2–5 we presented additional adaptors that varied between the experiments.</p>
<p>In all experiments, we tracked observers’ dominant eye to ensure proper fixation behavior during presentation of the test events and presentation of the adaptors. More specifically, we tracked the dominant eye’s current position at a sampling rate of 1000 Hz and determined online the eyes’ distance to the screen center. We aborted a trial, whenever the distance between eye position and screen center exceeded 2 dva. Observers repeated these trials at the end of a block in randomized order. During presentation of the adaptors, we presented a short message (at the fixation point) asking observers to please fixate in the center of the screen once observers gaze exceeded 2 dva away from the screen center.</p>
</sec>
<sec id="s2d">
<title>Adaptation in Experiment 1</title>
<p>In <bold>Experiment 1</bold>, each observer ran in 15 blocks in each of sessions 2–5. The first 5 blocks in a session were again without adaptation to measure an observer’s perception of causality before adaptation. As in the first session, we presented test events in two possible horizontal directions and varied the disc overlap resulting in 28 trials in each block. In blocks 6–15, we presented an adaptor before the first trial of a block. The adaptor was chosen from one of four possible adaptors. In two of the sessions, we used launches in a particular direction as the adaptor (the adaptor’s direction was fixed in a session). Before the first trial of a block, we presented 320 launching events at the same location as the test events described above. The exact direction of these launching events was randomly chosen from a narrow uniform distribution around the direction on the horizontal meridian (±30 degrees). The long adaptation phase was complemented by a top-up adaptation of 16 launching events in the same direction as the adaptor (again drawn from the same narrow uniform distribution around that main direction) before each trial to maintain an effective adaptation across the entire block.</p>
<p>In two additional sessions, we presented slip events as adaptors to control that the adaptation was specific for the impression of causality in the launching events. Slip events are designed to match the launching events in as many physical properties as possible while producing a very different, non-causal phenomenology. In slip events, the first peripheral disc also moves towards a stationary disc. In contrast to launching events, however, the first disc passes the stationary disc and stops only when it is adjacent to the opposite edge of the stationary disc. While slip events do not elicit a causal impression, they have the same number of objects and motion onsets, the same motion direction and speed, as well as the same spatial area of the event as launches. As for the launch-adaptor, we displayed slip adaptors in a narrow uniform range of directions around one of the two possible horizontal directions (from left-to-right or from right-to-left being fixed in a session). This experimental design resulted in four sessions and the order of the type of adaptor (launches vs. slip adaptors; movement direction of the adaptor) was randomly determined for each participant. Overall, each observer ran in a total of 1,680 trials in <bold>Experiment 1</bold>.</p>
</sec>
<sec id="s2e">
<title>Adaptation variations in Experiment 2</title>
<p>In <bold>Experiment 2</bold>, we used a very similar design as in <bold>Experiment 1</bold> with one notable difference. Adaptors and test events varied in motion speed either being the same as in <bold>Experiment 1</bold> or half that speed. Correspondingly, in slow events the test event duration was twice as long (i.e., event duration of 350 ms) as for test events displayed at fast motion speed (i.e., event duration of 175 ms). We presented all test events (and adaptors) always in the same direction (from left to right). Similarly, we also displayed slip events as adaptors in slow and fast motion speeds. In sessions with adaptation, the first five blocks were without adaptation while blocks 6–15 were with adaptors, each block consisting of 28 trials. Each observer ran in a total of 1,680 trials in <bold>Experiment 2</bold>.</p>
</sec>
<sec id="s2f">
<title>Adaptation variations in Experiment 3</title>
<p>In <bold>Experiment 3</bold>, we determined the transfer of adaptation for feature conjunctions (motion direction x color). The two discs in the test events and during adaptation had different colors (i.e., red and green) and could move in both horizontal directions. In contrast to <bold>Experiment 1 and 2</bold>, slip events were not used as adaptors. This design resulted in four different adaptors that were presented in separate sessions. Again, the first five blocks of a session were without adaptation while blocks 6–15 were with adaptors, each block consisting of 28 trials. Each observer ran in a total of 1,680 trials in <bold>Experiment 3</bold>.</p>
</sec>
<sec id="s2g">
<title>Data analysis</title>
<p>For the statistical analyses and estimation of the psychometric functions we used the <italic>quickpsy</italic> package (<xref ref-type="bibr" rid="c13">Linares &amp; López-Moliner, 2016</xref>) and the R environment (<xref ref-type="bibr" rid="c17">R Core Team, 2022</xref>). We related disc overlap to the proportion of reported launches using logistic functions with four parameters for the intercept, slope, as well as upper and lower asymptotes. We fitted these functions separately for each observer and condition and obtained the points of subjective equality (PSE; the amount of overlap between the two discs in the test events that result in the same proportion of reported launches and passes). For inferential statistics, we analyzed PSEs using repeated-measures analyses of variance (rmANOVA). Error bars indicate ±1 within-subject standard error of the mean (SEM; Baguley, 2011; Morey, 2008). A significant interaction in the rmANOVA was complemented by running post-hoc paired t-tests. Please note, one observer in <bold>Experiment 3</bold> showed such a strong negative aftereffect when test event and adaptor were identical, such that the upper asymptote was below a proportion of 0.5 (i.e., the point when launches and passes are equally often reported). Instead of a non-identifiable PSE for that observer in that particular condition, we computed inflection points of the psychometric functions in all conditions for that observer which then entered the statistical analyses. Neither of the studies reported in this article was preregistered. The data and analysis code has been deposited at the Open Science Framework and is publicly available as of the date of publication [OSF-link].</p>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>Adaptation of causality is selective for motion direction</title>
<p>In <bold>Experiment 1</bold>, we tested whether causality is computed separately within visual routines specialized for different motion directions. To this end, we presented observers with brief test events in one of two possible horizontal directions (from left to right, or right to left) in which a peripheral disc moved swiftly towards a stationary one. The first disc stopped moving as soon as the two discs partially overlapped (the amount of overlap was manipulated in seven steps from zero to full overlap, <bold><xref rid="fig1" ref-type="fig">Figure 1c</xref></bold>). Simultaneously, the second disc started to move along the same trajectory, and we asked observers to report whether they perceived that the first disc passed the second one (i.e., a pass event; commonly reported at full overlap), or rather launched it into motion (i.e., a launch event; common at zero overlap). We quantified the point of subjective equality (PSE) between perceived launches and passes by modelling psychometric functions for the perception of causality both <italic>before</italic> and <italic>after</italic> adaptation to causal launches (note that we presented the adaptor in a range of ±30° around one of the two possible directions).</p>
<p>This visual adaptation successfully affected the perception of causality in this task. We observed a strong negative aftereffect when test events matched the direction of the launch-adaptor. That is, observers were less likely to report a launch after adapting to launches in the same direction as the test events (<bold><xref rid="fig2" ref-type="fig">Figure 2a–b</xref></bold>). This observation was corroborated by a two-way (2 event types: launch vs. slip; 2 directions: congruent vs. incongruent) repeated measures analysis of variance (rmANOVA) in which we assessed the magnitude of adaptation by subtracting the PSE before adaptation (PSE<sub>before</sub> = 0.60, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.59 0.62]) from the PSEs obtained in each of the four different adaptation conditions (PSE<sub>cong_launch</sub> = 0.40, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.36 0.43]; PSE<sub>incong_launch</sub> = 0.55, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.54 0.56]; PSE<sub>cong_slip</sub> = 0.55, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.54 0.57]; PSE<sub>incong_slip</sub> = 0.61, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.59 0.64]). The analysis revealed a significant main effect of event type (<italic>F</italic> (1, 7) = 62.73, <italic>p</italic> &lt; 0.001; <bold><xref rid="fig2" ref-type="fig">Figure 2a–b</xref></bold>) demonstrating stronger adaptation for launching than slip events (ΔPSE<sub>event</sub> = –0.11, <italic>CI</italic><sub><italic>95%</italic></sub> = [–0.14 –0.08]). Moreover, adaptors in a congruent direction as the test event resulted in stronger adaptation than in incongruent directions (<italic>F</italic> (1, 7) = 41.62, <italic>p</italic> &lt; 0.001; ΔPSE<sub>direction</sub> = –0.11, <italic>CI</italic><sub><italic>95%</italic></sub> = [–0.15 –0.07]). Critically, we observed a significant interaction (<italic>F</italic> (1, 7) = 12.23, <italic>p</italic> = 0.01), revealing that the influence of direction-congruency on the magnitude of adaptation was significantly stronger for launches than for slip events (Post-hoc t-test: <italic>t(</italic>7) = 3.50, <italic>p</italic> = 0.01; ΔPSE<sub>eventXdirection</sub> = –0.09, <italic>CI</italic><sub><italic>95%</italic></sub> = [–0.16 –0.03]) supporting the hypothesis that specialized visual routines are tuned to the motion direction of launching events.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Results of Experiment 1, 2, and 3. <bold>a</bold> Mean proportion of causal reports as a function of disc overlap in Experiment 1. Visualization of psychometric curves is based on the mean parameters averaged across observers before adaptation (pink), and after adaptation with direction-congruent launches (blue), direction-incongruent launches (in purple), direction-congruent slip events (red) and direction-incongruent slip events (in orange). <bold>b</bold> PSEs for each individual observers (circles) and the mean across observers (square). <bold>c</bold> Mean proportion of causal reports as a function of disc overlap in Experiment 2. Visualization of psychometric curves is based on the mean parameters averaged across observers before adaptation (pink), and after adaptation with speed-congruent launches (blue), speed-incongruent launches (in purple), speed-congruent slip events (red) and speed-incongruent slip events (in orange). <bold>d</bold> PSEs for each individual observers (circles) and the mean across observers (square). <bold>e</bold> Mean proportion of causal reports as a function of disc overlap in Experiment 3. Visualization of psychometric curves is based on the mean parameters averaged across observers before adaptation (pink), and after adaptation with adaptors that are identical with the test event (blue), share the same direction but different colors (in purple), same colors but different direction (red) and completely different test events (in orange). <bold>f</bold> PSEs for each individual observers (circles) and the mean across observers (square). All error bars are ± 1 SEM.</p></caption>
<graphic xlink:href="554237v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3b">
<title>Adaptation of causality transfers across motion speed</title>
<p>In <bold>Experiment 2</bold>, we determined whether the perception of causality is also selective for other feature dimensions that are relevant for causal interactions. Causal events in our visual environment encompass interactions of various motion speeds. Here, we examined whether adapting the perception of causality transfers between events that either had different speeds (same as in <bold>Experiment 1</bold> or half that). Both speed-congruent (i.e., test events had the same speed as the adaptor) and speed-incongruent launches (i.e., test events and adaptor differed by a factor of 2) resulted in adaptation, demonstrating a transfer of adaptation across motion speeds (<bold><xref rid="fig2" ref-type="fig">Figure 2c–d</xref></bold>). As in <bold>Experiment 1</bold>, we corroborated this observation by a two-way rmANOVA in which we assessed differences in the magnitude of adaptation (i.e., the difference in PSEs before and after adaptation; PSE<sub>before</sub> = 0.59, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.57 0.61]; PSE<sub>cong_launch</sub> = 0.43, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.40 0.46]; PSE<sub>incong_launch</sub> = 0.43, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.39 0.47]; PSE<sub>cong_slip</sub> = 0.60, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.57 0.63]; PSE<sub>incong_slip</sub> = 0.54, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.50 0.59]) as a function of speed congruency (congruent vs. incongruent speed), event type (launch vs. slip event) and their interaction. The analysis revealed a significant main effect of event type (<italic>F</italic> (1, 7) = 23.39, <italic>p</italic> = 0.002; <bold><xref rid="fig2" ref-type="fig">Figure 2c–d</xref></bold>) demonstrating stronger adaptation for launching than slip events (ΔPSE<sub>event</sub> = –0.14, <italic>CI</italic><sub><italic>95%</italic></sub> = [–0.21 –0.07]). Importantly, the magnitude of adaptation was not significantly different for congruent and incongruent speed between adaptor and test event (<italic>F</italic> (1, 7) = 3.43, <italic>p</italic> = 0.107; ΔPSE<sub>speed</sub> = 0.03 <italic>CI</italic><sub><italic>95%</italic></sub> = [–0.01 0.07]). Moreover, there was no significant interaction between event type and speed (<italic>F</italic> (1, 7) = 3.48, <italic>p</italic> = 0.105; ΔPSE<sub>eventXspeed</sub> = –0.06, <italic>CI</italic><sub><italic>95%</italic></sub> = [–0.14 0.02]). These findings demonstrate that the perception of causality is not tuned to motion speed—or, at least, that the tuning is very broad.</p>
</sec>
<sec id="s3c">
<title>Adaptation of causality using feature-conjunctions</title>
<p>In <bold>Experiment 3</bold>, we determined whether the identities of the two objects involved in the causal interaction can break the observed dominance of the direction-specific computation underlying the perception of causality. For instance, if two visually distinct objects are involved in a causal interaction with one type of object always launching a second, visually distinct object, it is unclear whether the influence of the adaptor is confined to events with the same feature conjunction or, alternatively, whether motion direction is the only relevant feature dimension for determining the presence of causal interactions. To distinguish between these alternatives, the two discs in the presented test events had two different colors (i.e., they were either red or green). Moreover, the adaptor in a session displayed only one particular feature conjunction (e.g., the adaptor in one session was always a red disc on the left launching a green disc on the right into rightward motion; adaptors varied across sessions and each subject saw each combination of feature conjunction across the multiple sessions). In contrast to the adaptor’s fixed feature conjunction in a session, both motion direction and color identities in the test events varied randomly from trial to trial. Again, we observed strong adaptation when test events and adaptors were identical. However, when one of the features in the feature conjunction differed, we observed adaptation only for test events in the same direction as the adaptor, irrespective of the object’s color. Thus, color does not constitute a critical feature of the visual routine for detecting causal interactions (<bold><xref rid="fig2" ref-type="fig">Figure 2e–f</xref></bold>). Again, we corroborated this observation by a two-way rmANOVA in which we assessed differences in the magnitude of adaptation (i.e., the difference in PSEs before and after adaptation; PSE<sub>before</sub> = 0.68, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.63 0.73]; PSE<sub>same_stimulus</sub> = 0.50, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.47 0.53]; PSE<sub>same_direction</sub> = 0.55, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.50 0.59]; PSE<sub>same_color</sub> = 0.68, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.65 0.72]; PSE<sub>different_stimulus</sub> = 0.65, <italic>CI</italic><sub><italic>95%</italic></sub> = [0.61 0.69]) as a function of motion direction (same vs. different), color assignment (same vs. different) and their interaction. The analysis revealed a significant main effect of motion direction (<italic>F</italic> (1, 7) = 21.07, <italic>p</italic> = 0.003) demonstrating stronger adaptation for launches in the same as compared to the opposite direction as the adaptor (ΔPSE<sub>direction</sub> = –0.14, <italic>CI</italic><sub><italic>95%</italic></sub> = [–0.22 –0.07]). Adaptation following adaptors with the same color vs. different color assignment were not significantly different (<italic>F</italic> (1, 7) = 0.071, <italic>p</italic> = 0.798; ΔPSE<sub>color</sub> = –0.004, <italic>CI</italic><sub><italic>95%</italic></sub> = [–0.03 0.03]). However, we observed a marginally significant interaction between color and motion direction (<italic>F</italic> (1, 7) = 4.59, <italic>p</italic> = 0.07; ΔPSE<sub>directionXcolor</sub> = –0.07, <italic>CI</italic><sub><italic>95%</italic></sub> = [–0.16 0.01]). Post-hoc paired t-tests showed that color had a marginally significant influence on the magnitude of adaptation when adaptor and test events were in same direction (<italic>t</italic> (7) = 1.97, <italic>p</italic> = 0.090; ΔPSE<sub>color_samedir</sub> = –0.04, <italic>CI</italic><sub><italic>95%</italic></sub> = [–0.09 0.01]). However, color had no significant influence on the adaptation of causality when adaptor and test events were in opposite direction (<italic>t</italic> (7) = 1.97, <italic>p</italic> = 0.090; ΔPSE<sub>color_opp_dir</sub> = 0.03, <italic>CI</italic><sub><italic>95%</italic></sub> = [–0.02 0.09]).</p>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>We provide new evidence for the fundamental role of perceptual processes in detecting cause and effect. Using visual adaptation, we revealed that visual routines underly the perception of causality that are specialized for a launch’s motion direction but invariant across a broad range of motion speeds. The tuning of causal perception to motion direction reveals a mechanism that is operating locally in feature space and complements previous reports of a spatially specific mechanism residing in retinotopic space (<xref ref-type="bibr" rid="c12">Kominsky &amp; Scholl, 2020</xref>; <xref ref-type="bibr" rid="c20">Rolfs et al., 2013</xref>).</p>
<p>The observed adaptation is specific to launching events that evoked a phenomenological impression of causality. This implies that adapting simply to the direction of a moving stimulus will only change the input to the visual routine but not the functioning of the routine itself. We controlled for such potential non-causal adapation of low-level featues (e.g., number of stimuli, time of contact, speed, overlap, or simply motion) using carefully designed control events (i.e., slip events) that did not result in comparable aftereffects. Indeed, motion direction constitutes a basic computational unit in vision and can be computed as early as in retinal circuits (e.g., in retinal ganglion cells about 2–3 synapses downstream of photoreceptors in rabbits, <xref ref-type="bibr" rid="c2">Barlow &amp; Hill, 1963</xref>). While a retinal origin of launch detection is unlikely, the specialization of visual routines for the perception of causality at the level of individual motion directions raises the possibility that this function is located surprisingly early in the visual system as opposed to a higher-level visual computation. A similar adaptation-based rationale can be applied to study whether different causal interactions can be distinguished from each other by assessing the transfer of adaptation between different causal interactions (<xref ref-type="bibr" rid="c12">Kominsky &amp; Scholl, 2020</xref>). While Michotte speculated about three separate causal impressions (i.e., launching, entraining, triggering; see <xref ref-type="bibr" rid="c27">White, 2017</xref> for an extended catalogue of causal interactions) adaptation helped to refine these categories as an adaptation to triggering events transferred to launching events, but adaptation to entraining had no such influence (<xref ref-type="bibr" rid="c12">Kominsky &amp; Scholl, 2020</xref>). Thus, adaptation at the category-level of the causal interaction allows to distinguish spezialized detectors for a particual causal interaction. Our findings break down this specialization to a more fundamental level, showing that a specialized visual routine for launching events exists even within separate motion direction channels.</p>
<p>The adaptation transferred across different colors as long as the test events shared the same motion direction as the adaptor. For instance, perceiving a red disc that launched a green disc into motion is also affected by the adaptation of a green disc launching a red disc (i.e., the opposite color assignment) into motion as long as the two events shared the same motion direction. This findings rules out an alternative cognitive mechanism, in which the causing-disc is first identified (e.g., the red disc is identified to launch other discs into motion) and the criterion for detecting a causal interaction would be selectively adjusted only for this particular causing-disc in a top-down manner. Indeed, our results show that the appearance of the objects in the launching event plays only a minor role for adapting the perception of causality (if any), suggesting that the visual system can calibrate the detection of causal interactions independent of the involved object identities. However, due to the limited age range of our sample, we lack information about whether the visual routines underlying the perception of causality in older individuals are also selective for the same visual features as demonstrated in our study or how the feature selectivity develops from childhood through adolescence. Furthermore, we have yet to explore the role of specialized visual routines for detecting causal interactions within different patient groups.</p>
<p>The existence of specialized visual routines computing causality, however, does not rule out the possibility of a more complex hierarchical architecture that is composed of both specialized and generalized routines. The output of local, specialized detectors within that architecture could feed into a global, generalized detector. Thus, a weaker response from adapted specialized cause detectors would elicit a weaker response in unadapted global detectors (or super-detectors; <xref ref-type="bibr" rid="c18">Rips, 2011</xref>). Indeed, visual adapation to other low-level visual features (e.g., contrast sensitivity) can yield weaker responses during early visual processing which are then passed on to other downstream areas (<xref ref-type="bibr" rid="c11">Kohn, 2007</xref>).</p>
<p>Neurophysiological studies support the view of distributed neural processing underlying sensory causal interactions with the visual system playing a major role therein. Imaging studies in particular revealed a network for the perception of causality that is also involved in action observation (<xref ref-type="bibr" rid="c3">Blakemore et al., 2003</xref>; <xref ref-type="bibr" rid="c7">Fonlupt, 2003</xref>; <xref ref-type="bibr" rid="c8">Fugelsang et al., 2005</xref>; <xref ref-type="bibr" rid="c21">Roser et al., 2005</xref>). The fact that visual adaptation of causality occurs in a retinotopic reference frame emphazises the role of retinotopically organized areas within that network (e.g., V5 and the superior temporal sulcus). Interestingly, single cell recordings in area F5 of the primate brain even portraited how motor areas are contributing to the perception of causality (<xref ref-type="bibr" rid="c5">Caggiano et al., 2016</xref>; <xref ref-type="bibr" rid="c19">Rolfs, 2016</xref>), emphasizing the distributed nature of the computations underlying causal interactions, and also stressing that the detection, and the prediction, of causality is essential for processes outside sensory systems (e.g., for understanding other’s actions, for navigating, and for avoiding collisions).</p>
<p>Visual adaptation of causality constitutes a powerful tool that allowed us to reveal how specialized visual routines are tuned to the motion direction of a launching event. Visual adaptation in general is thought to be one of the signatures of a perceptual process (<xref ref-type="bibr" rid="c9">Hafri &amp; Firestone, 2021</xref>) and therefore is informative for identifiying the visual origin of a mechanism as opposed to, for instance, cognitive accounts (e.g., cognitive schema; see <xref ref-type="bibr" rid="c18">Rips, 2011</xref> for a review). The detection of causal interactions features many hallmarks of perception: An impression of causality emerges fast and automatic for briefly presented stimuli (<xref ref-type="bibr" rid="c14">Michotte, 1963</xref>) and causal events reach awareness faster than non causal-events (<xref ref-type="bibr" rid="c15">Moors et al., 2017</xref>). The implementation of visual routines for the perception of causality in separate channels of a basic visual feature such as motion direction fortifies the view that our understanding of causal interactions indeed starts as a low-level perceptual routine.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>This research was supported by a DFG research grant to S.O (OH 274/2-2) as well as funding from the Heisenberg Programme of the DFG to M.R. (grants RO3579/8-1 and RO3579/12-1). The authors declare no competing financial interests.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Baker</surname>, <given-names>D. H.</given-names></string-name>, <string-name><surname>Vilidaite</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Lygo</surname>, <given-names>F. A.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Flack</surname>, <given-names>T. R.</given-names></string-name>, <string-name><surname>Gouws</surname>, <given-names>A. D.</given-names></string-name>, &amp; <string-name><surname>Andrews</surname>, <given-names>T. J.</given-names></string-name> (<year>2021</year>). <article-title>Power contours: Optimising sample size and precision in experimental psychology and human neuroscience</article-title>. <source>Psychological methods</source>, <volume>26</volume>(<issue>3</issue>), <fpage>295</fpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Barlow</surname>, <given-names>H. B.</given-names></string-name>, &amp; <string-name><surname>Hill</surname>, <given-names>R. M.</given-names></string-name> (<year>1963</year>). <article-title>Selective sensitivity to direction of movement in ganglion cells of the rabbit retina</article-title>. <source>Science</source>, <volume>139</volume>(<issue>3553</issue>), <fpage>412</fpage>–<lpage>414</lpage>. <pub-id pub-id-type="doi">10.1126/science.139.3553.412</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Blakemore</surname>, <given-names>S.-J.</given-names></string-name>, <string-name><surname>Boyer</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Pachot-Clouard</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Meltzoff</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Segebarth</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Decety</surname>, <given-names>J.</given-names></string-name> (<year>2003</year>). <article-title>The detection of contingency and animacy from simple animations in the human brain</article-title>. <source>Cerebral Cortex</source>, <volume>13</volume>(<issue>8</issue>), <fpage>837</fpage>–<lpage>844</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/13.8.837</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Brainard</surname>, <given-names>D.</given-names></string-name> (<year>1997</year>). <article-title>The psychophysics toolbox</article-title>. <source>Spatial Vision</source>, <volume>10</volume>, <fpage>433</fpage>–<lpage>436</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Caggiano</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Fleischer</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Pomper</surname>, <given-names>J. K.</given-names></string-name>, <string-name><surname>Giese</surname>, <given-names>M. A.</given-names></string-name>, &amp; <string-name><surname>Thier</surname>, <given-names>P.</given-names></string-name> (<year>2016</year>). <article-title>Mirror neurons in monkey premotor area F5 show tuning for critical features of visual causality perception</article-title>. <source>Current Biology</source>, <volume>26</volume>(<issue>22</issue>), <fpage>3077</fpage>–<lpage>3082</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2016.10.007</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Cornelissen</surname>, <given-names>F. W.</given-names></string-name>, <string-name><surname>Peters</surname>, <given-names>E. M.</given-names></string-name>, &amp; <string-name><surname>Palmer</surname>, <given-names>J.</given-names></string-name> (<year>2002</year>). <article-title>The Eyelink Toolbox: Eye tracking with MATLAB and the Psychophysics Toolbox</article-title>. <source>Behavior Research Methods, Instruments, &amp; Computers</source>, <volume>34</volume>(<issue>4</issue>), <fpage>613</fpage>–<lpage>617</lpage>. <pub-id pub-id-type="doi">10.3758/BF03195489</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Fonlupt</surname>, <given-names>P.</given-names></string-name> (<year>2003</year>). <article-title>Perception and judgement of physical causality involve different brain structures</article-title>. <source>Cognitive Brain Research</source>, <volume>17</volume>(<issue>2</issue>), <fpage>248</fpage>–<lpage>254</lpage>. <pub-id pub-id-type="doi">10.1016/S0926-6410(03)00112-5</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Fugelsang</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Roser</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>Corballis</surname>, <given-names>P. M.</given-names></string-name>, <string-name><surname>Gazzaniga</surname>, <given-names>M. S.</given-names></string-name>, &amp; <string-name><surname>Dunbar</surname>, <given-names>K. N.</given-names></string-name> (<year>2005</year>). <article-title>Brain mechanisms underlying perceptual causality</article-title>. <source>Cognitive Brain Research</source>, <volume>24</volume>(<issue>1</issue>), <fpage>41</fpage>–<lpage>47</lpage>. <pub-id pub-id-type="doi">10.1016/j.cogbrainres.2004.12.001</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Hafri</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Firestone</surname>, <given-names>C.</given-names></string-name> (<year>2021</year>). <article-title>The perception of relations</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>25</volume>(<issue>6</issue>), <fpage>475</fpage>–<lpage>492</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2021.01.006</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Kleiner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Brainard</surname>, <given-names>D. H.</given-names></string-name>, <string-name><surname>Pelli</surname>, <given-names>D. G.</given-names></string-name>, <string-name><surname>Ingling</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Murray</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Broussard</surname>, <given-names>C.</given-names></string-name> (<year>2007</year>). <article-title>What’s new in Psychtoolbox-3</article-title>. <source>Perception</source>, <volume>36</volume>(<issue>14</issue>), <fpage>1</fpage>–<lpage>16</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Kohn</surname>, <given-names>A.</given-names></string-name> (<year>2007</year>). <article-title>Visual adaptation: Physiology, mechanisms, and functional benefits</article-title>. <source>Journal of Neurophysiology</source>, <volume>97</volume>(<issue>5</issue>), <fpage>3155</fpage>–<lpage>3164</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00086.2007</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Kominsky</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Scholl</surname>, <given-names>B. J.</given-names></string-name> (<year>2020</year>). <article-title>Retinotopic adaptation reveals distinct categories of causal perception</article-title>. <source>Cognition</source>, <volume>203</volume>, <fpage>104339</fpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2020.104339</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Linares</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>López-Moliner</surname>, <given-names>J.</given-names></string-name> (<year>2016</year>) <article-title>quickpsy: An R Package to Fit Psychometric Functions for Multiple Groups</article-title>. <source>The R Journal</source>, <volume>8</volume>(<issue>1</issue>), <fpage>122</fpage>–<lpage>131</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="book"><string-name><surname>Michotte</surname>, <given-names>A.</given-names></string-name> (<year>1963</year>). <chapter-title>The perception of causality</chapter-title>. <source>Basic Books</source>. (<publisher-name>Original published 1946</publisher-name>).</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Moors</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Wagemans</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>de-Wit</surname>, <given-names>L.</given-names></string-name> (<year>2017</year>). <article-title>Causal events enter awareness faster than non-causal events</article-title>. <source>PeerJ</source>, <volume>5</volume>, <fpage>e2932</fpage>. <pub-id pub-id-type="doi">10.7717/peerj.2932</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Pelli</surname>, <given-names>D. G.</given-names></string-name> (<year>1997</year>). <article-title>The VideoToolbox software for visual psychophysics: Transforming numbers into movies</article-title>. <source>Spatial Vision</source>, <volume>10</volume>(<issue>4</issue>), <fpage>437</fpage>–<lpage>442</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="book"><collab>R Core Team</collab> (<year>2022</year>). <chapter-title>R: A language and environment for statistical computing</chapter-title>. <source>R Foundation for Statistical Computing</source>, <publisher-loc>Vienna, Austria</publisher-loc>. URL <ext-link ext-link-type="uri" xlink:href="https://www.R-project.org/">https://www.R-project.org/</ext-link>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Rips</surname>, <given-names>L. J.</given-names></string-name> (<year>2011</year>). <article-title>Causation from perception</article-title>. <source>Perspectives on Psychological Science</source>, <volume>6</volume>(<issue>1</issue>), <fpage>77</fpage>–<lpage>97</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Rolfs</surname>, <given-names>M.</given-names></string-name> (<year>2016</year>). <article-title>Visual neuroscience: Seeing causality with the motor system?</article-title> <source>Current Biology</source>, <volume>26</volume>(<issue>22</issue>), <fpage>R1183</fpage>–<lpage>R1185</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2016.09.046</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Rolfs</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dambacher</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Cavanagh</surname>, <given-names>P.</given-names></string-name> (<year>2013</year>). <article-title>Visual adaptation of the perception of causality</article-title>. <source>Current Biology</source>, <volume>23</volume>(<issue>3</issue>), <fpage>250</fpage>–<lpage>254</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2012.12.017</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Roser</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>Fugelsang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Dunbar</surname>, <given-names>K. N.</given-names></string-name>, <string-name><surname>Corballis</surname>, <given-names>P. M.</given-names></string-name>, &amp; <string-name><surname>Gazzaniga</surname>, <given-names>M.</given-names></string-name> (<year>2005</year>). <article-title>Dissociating processes supporting causal perception and causal inference in the brain</article-title>. <source>Neuropsychology</source>, <volume>19</volume>(<issue>5</issue>), <fpage>591</fpage>–<lpage>602</lpage>. <pub-id pub-id-type="doi">10.1037/0894-4105.19.5.591</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Sanborn</surname>, <given-names>A. N.</given-names></string-name>, <string-name><surname>Mansinghka</surname>, <given-names>V. K.</given-names></string-name>, &amp; <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name> (<year>2013</year>). <article-title>Reconciling intuitive physics and Newtonian mechanics for colliding objects</article-title>. <source>Psychological Review</source>, <volume>120</volume>(<issue>2</issue>), <fpage>411</fpage>–<lpage>437</lpage>. <pub-id pub-id-type="doi">10.1037/a0031912</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Scholl</surname>, <given-names>B. J.</given-names></string-name>, &amp; <string-name><surname>Tremoulet</surname>, <given-names>P. D.</given-names></string-name> (<year>2000</year>). <article-title>Perceptual causality and animacy</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>4</volume>(<issue>8</issue>), <fpage>299</fpage>–<lpage>309</lpage>. <pub-id pub-id-type="doi">10.1016/S1364-6613(00)01506-0</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Webster</surname>, <given-names>M. A.</given-names></string-name> (<year>2015</year>). <article-title>Visual adaptation</article-title>. <source>Annual Review of Vision Science</source>, <volume>1</volume>(<issue>1</issue>), <fpage>547</fpage>–<lpage>567</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-vision-082114-035509</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Weir</surname>, <given-names>S.</given-names></string-name> (<year>1978</year>). <article-title>The perception of motion: Michotte revisited</article-title>. <source>Perception</source>, <volume>7</volume>(<issue>3</issue>), <fpage>247</fpage>–<lpage>260</lpage>. <pub-id pub-id-type="doi">10.1068/p070247</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>White</surname>, <given-names>P. A.</given-names></string-name> (<year>2006</year>). <article-title>The causal asymmetry</article-title>. <source>Psychological Review</source>, <volume>113</volume>(<issue>1</issue>), <fpage>132</fpage>–<lpage>147</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295X.113.1.132</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="book"><string-name><surname>White</surname>, <given-names>P. A.</given-names></string-name> (<year>2017</year>). <chapter-title>Visual impressions of causality. In M. R. Waldmann (Hrsg</chapter-title>.), <source>The Oxford Handbook of Causal Reasoning (Bd. 1)</source>. <publisher-name>Oxford University Press</publisher-name>. <pub-id pub-id-type="doi">10.1093/oxfordhb/9780199399550.013.17</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93454.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Kok</surname>
<given-names>Peter</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study provides a <bold>valuable</bold> contribution to our understanding of causal inference in visual perception. The evidence provided through multiple well-designed psychophysical experiments is <bold>solid</bold>. However, the conclusions drawn on the implementation of causal inference in general are too broad to be properly supported by the current results given their narrow focus on visual launch events.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93454.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
The authors investigated causal inference in the visual domain through a set of carefully designed experiments, and sound statistical analysis. They suggest the early visual system has a crucial contribution to computations supporting causal inference.</p>
<p>Strengths:</p>
<p>
I believe the authors target an important problem (causal inference) with carefully chosen tools and methods. Their analysis rightly implies the specialization of visual routines for causal inference and the crucial contribution of early visual systems to perform this computation. I believe this is a novel contribution and their data and analysis are in the right direction.</p>
<p>Weaknesses:</p>
<p>
In my humble opinion, a few aspects deserve more attention:</p>
<p>1. Causal inference (or causal detection) in the brain should be quite fundamental and quite important for human cognition/perception. Thus, the underlying computation and neural substrate might not be limited to the visual system (I don't mean the authors did claim that). In fact, to the best of my knowledge, multisensory integration is one of the best-studied perceptual phenomena that has been conceptualized as a causal inference problem. Assuming the causal inference in those studies (Shams 2012; Shams and Beierholm 2022; Kording et al. 2007; Aller and Noppeney 2018; Cao et al. 2019) (and many more e.g., by Shams and colleagues), and the current study might share some attributes, one expects some findings in those domains are transferable (at least to some degree) here as well. Most importantly, underlying neural correlates that have been suggested based on animal studies and invasive recording that has been already studied, might be relevant here as well. Perhaps the most relevant one is the recent work from the Harris group on mice (Coen et al. 2021). I should emphasize, that I don't claim they are necessarily relevant, but they can be relevant given their common roots in the problem of causal inference in the brain. This is a critical topic that the authors may want to discuss in their manuscript.</p>
<p>2. If I understood correctly, the authors are arguing pro a mere bottom-up contribution of early sensory areas for causal inference (for instance, when they wrote &quot;the specialization of visual routines</p>
<p>
for the perception of causality at the level of individual motion directions raises the possibility that this function is located surprisingly early in the visual system *as opposed to a higher-level visual computation*.&quot;). Certainly, as the authors suggested, early sensory areas have a crucial contribution, however, it may not be limited to that. Recent studies progressively suggest perception as an active process that also weighs in strongly, the top-down cognitive contributions. For instance, the most simple cases of perception have been conceptualized along this line (Martin, Solms, and Sterzer 2021)</p>
<p>
and even some visual illusion (Safavi and Dayan 2022), and other extensions (Kay et al. 2023). Thus, I believe it would be helpful to extend the discussion on the top-down and cognitive contributions of causal inference (of course that can also be hinted at, based on recent developments). Even adaptation, which is central in this study can be influenced by top-down factors (Keller et al. 2017). I believe, based on other work of Rolfs and colleagues, this is also aligned with their overall perspective on vision.</p>
<p>3. The authors rightly implicate the neural substrate of causal inference in the early sensory system. Given their study is pure psychophysics, a more elaborate discussion based on other studies that used brain measurements is needed (in my opinion) to put into perspective this conclusion. In particular, as I mentioned in the first point, the authors mainly discuss the potential neural substrate of early vision, however much has been done about the role of higher-tier cortical areas in causal inference e.g., see (Cao et al. 2019; Coen et al. 2021).</p>
<p>There were many areas in this manuscript that I liked: clever questions, experimental design, and statistical analysis.</p>
<p>Bibliography</p>
<p>
============</p>
<p>Aller, Mate, and Uta Noppeney. 2018. &quot;To Integrate or Not to Integrate: Temporal Dynamics of Bayesian Causal Inference.&quot; Biorxiv, December, 504118. .</p>
<p>Cao, Yinan, Christopher Summerfield, Hame Park, Bruno Lucio Giordano, and Christoph Kayser. 2019. &quot;Causal Inference in the Multisensory Brain.&quot; Neuron 102 (5): 1076-87.e8. .</p>
<p>Coen, Philip, Timothy P. H. Sit, Miles J. Wells, Matteo Carandini, and Kenneth D. Harris. 2021. &quot;The Role of Frontal Cortex in Multisensory Decisions.&quot; Biorxiv, April. Cold Spring Harbor Laboratory, 2021.04.26.441250. .</p>
<p>Kay, Kendrick, Kathryn Bonnen, Rachel N. Denison, Mike J. Arcaro, and David L. Barack. 2023. &quot;Tasks and Their Role in Visual Neuroscience.&quot; Neuron 111 (11). Elsevier: 1697-1713. .</p>
<p>Keller, Andreas J, Rachael Houlton, Björn M Kampa, Nicholas A Lesica, Thomas D Mrsic-Flogel, Georg B Keller, and Fritjof Helmchen. 2017. &quot;Stimulus Relevance Modulates Contrast Adaptation in Visual Cortex.&quot; Elife 6. eLife Sciences Publications, Ltd: e21589.</p>
<p>Kording, K. P., U. Beierholm, W. J. Ma, S. Quartz, J. B. Tenenbaum, and L. Shams. 2007. &quot;Causal Inference in Multisensory Perception.&quot; PloS One 2: e943. .</p>
<p>Martin, Joshua M., Mark Solms, and Philipp Sterzer. 2021. &quot;Useful Misrepresentation: Perception as Embodied Proactive Inference.&quot; Trends Neurosci. 44 (8): 619-28. .</p>
<p>Safavi, Shervin, and Peter Dayan. 2022. &quot;Multistability, Perceptual Value, and Internal Foraging.&quot; Neuron, August. .</p>
<p>Shams, L. 2012. &quot;Early Integration and Bayesian Causal Inference in Multisensory Perception.&quot; In The Neural Bases of Multisensory Processes, edited by M. M. Murray and M. T. Wallace. Frontiers in</p>
<p>
Neuroscience. Boca Raton (FL).</p>
<p>Shams, Ladan, and Ulrik Beierholm. 2022. &quot;Bayesian Causal Inference: A Unifying Neuroscience Theory.&quot; Neuroscience &amp; Biobehavioral Reviews 137 (June): 104619. .</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93454.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This paper seeks to determine whether the human visual system's sensitivity to causal interactions is tuned to specific parameters of a causal launching event, using visual adaptation methods. The three parameters the authors investigate in this paper are the direction of motion in the event, the speed of the objects in the event, and the surface features or identity of the objects in the event (in particular, having two objects of different colors).</p>
<p>The key method, visual adaptation to causal launching, has now been demonstrated by at least three separate groups and seems to be a robust phenomenon. Adaptation is a strong indicator of a visual process that is tuned to a specific feature of the environment, in this case launching interactions. Whereas other studies have focused on retinotopically-specific adaptation (i.e., whether the adaptation effect is restricted to the same test location on the retina as the adaptation stream was presented to), this one focuses on feature-specificity.</p>
<p>The first experiment replicates the adaptation effect for launching events as well as the lack of adaptation event for a minimally different non-causal 'slip' event. However, it also finds that the adaptation effect does not work for launching events that do not have a direction of motion more than 30 degrees from the direction of the test event. The interpretation is that the system that is being adapted is sensitive to the direction of this event, which is an interesting and somewhat puzzling result given the methods used in previous studies, which have used random directions of motion for both adaptation and test events.</p>
<p>The obvious interpretation would be that past studies have simply adapted to launching in every direction, but that in itself says something about the nature of this direction-specificity: it is not working through opposed detectors. For example, in something like the waterfall illusion adaptation effect, where extended exposure to downward motion leads to illusory upward motion on neutral-motion stimuli, the effect simply doesn't work if motion in two opposed directions is shown (i.e., you don't see illusory motion in both directions, you just see nothing). The fact that adaptation to launching in multiple directions doesn't seem to cancel out the adaptation effect in past work raises interesting questions about how directionality is being coded in the underlying process. In addition, one limitation of the current method is that it's not clear whether the motion-direction-specificity is also itself retinotopically-specific, that is, if one retinotopic location were adapted to launching in one direction and a different retinotopic location adapted to launching in the opposite direction, would each test location show the adaptation effect only for events in the direction presented at that location?</p>
<p>The second experiment tests whether the adaptation effect is similarly sensitive to differences in speed. The short answer is no; adaptation events at one speed affect test events at another. Furthermore, this is not surprising given that Kominsky &amp; Scholl (2020) showed adaptation transfer between events with differences in speeds of the individual objects in the event (whereas all events in this experiment used symmetrical speeds). This experiment is still novel and it establishes that the speed-insensitivity of these adaptation effects is fairly general, but I would certainly have been surprised if it had turned out any other way.</p>
<p>The third experiment tests color (as a marker of object identity), and pits it against motion direction. The results demonstrate that adaptation to red-launching-green generates an adaptation effect for green-launching-red, provided they are moving in roughly the same direction, which provides a nice internal replication of Experiment 1 in addition to showing that the adaptation effect is not sensitive to object identity. This result forms an interesting contrast with the infant causal perception literature. Multiple papers (starting with Leslie &amp; Keeble, 1987) have found that 6-8-month-old infants are sensitive to reversals in causal roles exactly like the ones used in this experiment. The success of adaptation transfer suggests, very clearly, that this sensitivity is not based only on perceptual processing, or at least not on the same processing that we access with this adaptation procedure. It implies that infants may be going beyond the underlying perceptual processes and inferring genuine causal content. This is also not the first time the adaptation paradigm has diverged from infant findings: Kominsky &amp; Scholl (2020) found a divergence with the object speed differences as well, as infants categorize these events based on whether the speed ratio (agent:patient) is physically plausible (Kominsky et al., 2017), while the adaptation effect transfers from physically implausible events to physically plausible ones. This only goes to show that these adaptation effects don't exhaustively capture the mechanisms of early-emerging causal event representation.</p>
<p>One overarching point about the analyses to take into consideration: The authors use a Bayesian psychometric curve-fitting approach to estimate a point of subjective equality (PSE) in different blocks for each individual participant based on a model with strong priors about the shape of the function and its asymptotic endpoints, and this PSE is the primary DV across all of the studies. As discussed in Kominsky &amp; Scholl (2020), this approach has certain limitations, notably that it can generate nonsensical PSEs when confronted with relatively extreme response patterns. The authors mentioned that this happened once in Experiment 3 and that a participant had to be replaced. An alternate approach is simply to measure the proportion of 'pass' reports overall to determine if there is an adaptation effect. I don't think this alternate analysis strategy would greatly change the results of this particular experiment, but it is robust against this kind of self-selection for effects that fit in the bounds specified by the model, and may therefore be worth including in a supplemental section or as part of the repository to better capture the individual variability in this effect.</p>
<p>In general, this paper adds further evidence for something like a 'launching' detector in the visual system, but beyond that, it specifies some interesting questions for future work about how exactly such a detector might function.</p>
<p>Kominsky, J. F., &amp; Scholl, B. J. (2020). Retinotopic adaptation reveals distinct categories of causal perception. Cognition, 203, 104339. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cognition.2020.104339">https://doi.org/10.1016/j.cognition.2020.104339</ext-link></p>
<p>Kominsky, J. F., Strickland, B., Wertz, A. E., Elsner, C., Wynn, K., &amp; Keil, F. C. (2017). Categories and Constraints in Causal Perception. Psychological Science, 28(11), 1649-1662. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797617719930">https://doi.org/10.1177/0956797617719930</ext-link></p>
<p>Leslie, A. M., &amp; Keeble, S. (1987). Do six-month-old infants perceive causality? Cognition, 25(3), 265-288. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0010-0277(87)80006-9">https://doi.org/10.1016/S0010-0277(87)80006-9</ext-link></p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93454.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
This paper presents evidence from three behavioral experiments that causal impressions of &quot;launching events&quot;, in which one object is perceived to cause another object to move, depending on motion direction-selective processing. Specifically, the work uses an adaptation paradigm (Rolfs et al., 2013), presenting repetitive patterns of events matching certain features to a single retinal location, then measuring subsequent perceptual reports of a test display in which the degree of overlap between two discs was varied, and participants could respond &quot;launch&quot; or &quot;pass&quot;. The three experiments report results of adapting to motion direction, motion speed, and &quot;object identity&quot;, and examine how the psychometric curves for causal reports shift in these conditions depending on the similarity of the adapter and test. While causality reports in the test display were selective for motion direction (Experiment 1), they were not selective for adapter-test speed differences (Experiment 2) nor for changes in object identity induced via color swap (Experiment 3). These results support the notion that causal perception is computed (in part) at relatively early stages of sensory processing, possibly even independently of or prior to computations of object identity.</p>
<p>Strengths:</p>
<p>
The setup of the research question and hypotheses is exceptional. The experiments are carefully performed (appropriate equipment, and careful control of eye movements). The slip adaptor is a really nice control condition and effectively mitigates the need to control motion direction with a drifting grating or similar. Participants were measured with sufficient precision, and a power curve analysis was conducted to determine the sample size. Data analysis and statistical quantification are appropriate. Data and analysis code are shared on publication, in keeping with open science principles. The paper is concise and well-written.</p>
<p>Weaknesses:</p>
<p>
The biggest uncertainty I have in interpreting the results is the relationship between the task and the assumption that the results tell us about causality impressions. The experimental logic assumes that &quot;pass&quot; reports are always non-causal impressions and &quot;launch&quot; reports are always causal impressions. This logic is inherited from Rolfs et al (2013) and Kominsky &amp; Scholl (2020), who assert rather than measure this. However, other evidence suggests that this assumption might not be solid (Bechlivanidis et al., 2019). Specifically, &quot;[our experiments] reveal strong causal impressions upon first encounter with collision-like sequences that the literature typically labels &quot;non-causal&quot;&quot; (Bechlivanidis et al., 2019) -- including a condition that is similar to the current &quot;pass&quot;. It is therefore possible that participants' &quot;pass&quot; reports could also involve causal experiences.</p>
<p>Furthermore, since the only report options are &quot;launch&quot; or &quot;pass&quot;, it is also possible that &quot;launch&quot; reports are not indications of &quot;I experienced a causal event&quot; but rather &quot;I did not experience a pass event&quot;. It seems possible to me that different adaptation transfer effects (e.g. selectivity to motion direction, speed, or color-swapping) change the way that participants interpret the task, or the uncertainty of their impression. For example, it could be that adaptation increases the likelihood of experiencing a &quot;pass&quot; event in a direction-selective manner, without changing causal impressions. Increases of &quot;pass&quot; impressions (or at least, uncertainty around what was experienced) would produce a leftward shift in the PSE as reported in Experiment 1, but this does not necessarily mean that experiences of causal events changed. Thus, changes in the PSEs between the conditions in the different experiments may not directly reflect changes in causal impressions. I would like the authors to clarify the extent to which these concerns call their conclusions into question.</p>
<p>Leaving these concerns aside, I am also left wondering about the functional significance of these specialised mechanisms. Why would direction matter but speed and object identity not? Surely object identity, in particular, should be relevant to real-world interpretations and inputs of these visual routines? Is color simply too weak an identity?</p>
<p>References:</p>
<p>Bechlivanidis, C., Schlottmann, A., &amp; Lagnado, D. A. (2019). Causation without realism. Journal of Experimental Psychology: General, 148(5), 785-804. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/xge0000602">https://doi.org/10.1037/xge0000602</ext-link></p>
<p>Kominsky, J. F., &amp; Scholl, B. J. (2020). Retinotopic adaptation reveals distinct categories of causal perception. Cognition, 203, 104339.</p>
<p>Rolfs, M., Dambacher, M., &amp; Cavanagh, P. (2013). Visual Adaptation of the Perception of Causality. Current Biology, 23(3), 250-254. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2012.12.017">https://doi.org/10.1016/j.cub.2012.12.017</ext-link></p>
</body>
</sub-article>
</article>