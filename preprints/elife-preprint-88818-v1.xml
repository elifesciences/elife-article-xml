<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">88818</article-id>
<article-id pub-id-type="doi">10.7554/eLife.88818</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.88818.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>BOUNTI: Brain vOlumetry and aUtomated parcellatioN for 3D feTal MRI</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Uus</surname>
<given-names>Alena U.</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="author-notes" rid="n1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kyriakopoulou</surname>
<given-names>Vanessa</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
<xref ref-type="author-notes" rid="n1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Makropoulos</surname>
<given-names>Antonios</given-names>
</name>
<xref ref-type="aff" rid="a4">d</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Fukami-Gartner</surname>
<given-names>Abi</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cromb</surname>
<given-names>Daniel</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Davidson</surname>
<given-names>Alice</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cordero-Grande</surname>
<given-names>Lucilio</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
<xref ref-type="aff" rid="a2">b</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Price</surname>
<given-names>Anthony N.</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Grigorescu</surname>
<given-names>Irina</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Williams</surname>
<given-names>Logan Z. J.</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Robinson</surname>
<given-names>Emma C.</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lloyd</surname>
<given-names>David</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a3">c</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Pushparajah</surname>
<given-names>Kuberan</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a3">c</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Story</surname>
<given-names>Lisa</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hutter</surname>
<given-names>Jana</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Counsell</surname>
<given-names>Serena J.</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Edwards</surname>
<given-names>A. David</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Rutherford</surname>
<given-names>Mary A.</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hajnal</surname>
<given-names>Joseph V.</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Deprez</surname>
<given-names>Maria</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<aff id="a1"><label>a</label><institution>School of Imaging Sciences and Biomedical Engineering, King’s College London</institution>, London, <country>UK</country></aff>
<aff id="a2"><label>b</label><institution>Biomedical Image Technologies, ETSI Telecomunicacion, Universidad Politécnica de Madrid and CIBER-BBN, ISCII</institution>, Madrid, <country>Spain</country></aff>
<aff id="a3"><label>c</label><institution>Department of Congenital Heart Disease, Evelina London Children’s Hospital</institution>, London, <country>UK</country></aff>
<aff id="a4"><label>d</label><institution>Department of Computing, Imperial College London</institution>, London, <country>UK</country></aff>
<aff id="a5"><label>e</label><institution>Centre for the Developing Brain, King’s College London</institution>, London, <country>UK</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Dubois</surname>
<given-names>Jessica</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Inserm Unité NeuroDiderot, Université Paris Cité</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Roiser</surname>
<given-names>Jonathan</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label><italic>Email address:</italic> <email>alena.uus@kcl.ac.uk</email> (Alena U. Uus)</corresp>
<fn id="n1" fn-type="equal"><label>1</label><p>Equal contribution.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-08-07">
<day>07</day>
<month>08</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP88818</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-05-11">
<day>11</day>
<month>05</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-04-27">
<day>27</day>
<month>04</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.04.18.537347"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Uus et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Uus et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-88818-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Fetal MRI is widely used for quantitative brain volumetry studies. However, currently, there is a lack of universally accepted protocols for fetal brain parcellation and segmentation. Published clinical studies tend to use different segmentation approaches that also reportedly require significant amounts of time-consuming manual refinement. In this work, we propose to address this challenge by developing a new robust deep learning-based fetal brain segmentation pipeline for 3D T2w motion corrected brain images. At first, we defined a new refined brain tissue parcellation protocol with 19 regions-of-interest using the new fetal brain MRI atlas from the Developing Human Connectome Project. This protocol design was based on evidence from histological brain atlases, clear visibility of the structures in individual subject 3D T2w images and the clinical relevance to quantitative studies. It was then used as a basis for developing an automated deep learning brain tissue parcellation pipeline trained on 360 fetal MRI datasets with different acquisition parameters using semi-supervised approach with manually refined labels propagated from the atlas. The pipeline demonstrated robust performance for different acquisition protocols and GA ranges. Analysis of tissue volumetry for 390 normal participants (21-38 weeks gestational age range), scanned with three different acquisition protocols, did not reveal significant differences for major structures in the growth charts. Only minor errors were present in &lt; 15% of cases thus significantly reducing the need for manual refinement. In addition, quantitative comparison between 65 fetuses with ventriculomegaly and 60 normal control cases were in agreement with the findings reported in our earlier work based on manual segmentations. These preliminary results support the feasibility of the proposed atlas-based deep learning approach for large-scale volumetric analysis. The created fetal brain volumetry centiles and a docker with the proposed pipeline are publicly available online at <ext-link ext-link-type="uri" xlink:href="https://hub.docker.com/r/fetalsvrtk/segmentation">https://hub.docker.com/r/fetalsvrtk/segmentation</ext-link> (tag brain bounti tissue).</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Fetal MRI</kwd>
<kwd>Brain development</kwd>
<kwd>Tissue parcellation</kwd>
<kwd>Automated segmentation</kwd>
<kwd>Growth charts</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Added link to the docker with segmentation pipeline.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<label>1.</label>
<title>Introduction</title>
<p>Fetal MRI provides complementary diagnostic information to antenatal ultrasound (<xref ref-type="bibr" rid="c35">Rutherford et al. (2008)</xref>) and allows detailed characterisation of normal and abnormal patterns of fetal brain development based on both visual analysis and quantitative metrics. Dedicated acquisition protocols for structural fetal MRI such as single shot turbo spin echo (SSTSE) and recent developments in retrospective motion correction methods such as 3D slice-tovolume registration (SVR) have lead to the generation of high-resolution 3D isotropic images <xref ref-type="bibr" rid="c29">Prayer et al. (2017)</xref>; <xref ref-type="bibr" rid="c1">Aertsen et al. (2020</xref>)<xref ref-type="bibr" rid="c11">Gholipour et al. (2010)</xref>; KuklisovaMurgasova et al. (2012); <xref ref-type="bibr" rid="c8">Ebner et al. (2020)</xref><xref ref-type="bibr" rid="c38">Uus et al. (2022)</xref>. The continuity of these images in 3D space allows for accurate 3D segmentation and volumetry of individual brain Regions-of-Interests (ROIs) or tissue compartments. The protocols for measurements and segmentation of brain structures (relevant to a specific study) have been commonly defined in a reference space represented by either individual subject datasets at different gestational ages (GA) or population-averaged atlases <xref ref-type="bibr" rid="c12">Gholipour et al. (2017)</xref>.</p>
<p>In fetal MRI studies, manual brain segmentations are conventionally performed in 2D planes on 3D T2w SVR-reconstructed images. This is a time consuming process and manual labels are generally prone to errors including inconsistencies in through plane views, missing finer parts of large region of interest (ROIs) (e.g., cortex) and over- or underestimation at tissue interfaces.</p>
<p>The classical automated brain parcellation methods widely used for fetal MRI rely on simple single or multiatlas registration-guided label propagation with probabilistic label fusion. However, these methods are notably prone to significant under- / over-estimations at tissue interfaces due to limits of registration (especially for the cortex). As a result, the most recent volumetric fetal brain studies <xref ref-type="bibr" rid="c36">Story et al. (2021)</xref>; <xref ref-type="bibr" rid="c31">Rollins et al. (2021)</xref>; <xref ref-type="bibr" rid="c22">Machado-Rivas et al. (2021)</xref>; <xref ref-type="bibr" rid="c39">Vasung et al. (2022)</xref> reported the need for substantial manual refinement of segmentations produced by automated atlas-based methods.</p>
<p>In contrast, the results of the recent FETA fetal MRI challenge <xref ref-type="bibr" rid="c25">Payette et al. (2021)</xref> suggest that deep learning provides robust performance for multi-label segmentation in T2w 3D SVR images. Here, commonly used baseline models included conventional 2D and 3D UNet convolutional neural networks (CNN) <xref ref-type="bibr" rid="c32">Ronneberger et al. (2015)</xref>; Özg ü n Çiçek et al. (2016), as well as use of the more recent advanced nnUNet <xref ref-type="bibr" rid="c14">Isensee et al. (2021)</xref>. <xref ref-type="bibr" rid="c16">Khalili et al. (2019)</xref> proposed one of the first works that used 2D UNet for brain tissue parcellation in 2D fetal MRI slices. Since then, a number of works focused on different challenges specific to fetal MRI. For example, <xref ref-type="bibr" rid="c9">Fidon et al. (2021a)</xref> introduced label-set loss functions for cases with partial input annotations, and <xref ref-type="bibr" rid="c10">Fidon et al. (2021b)</xref> proposed distributionally robust optimisation to improve generalisation for unseen abnormal cases with anatomical variabilities. Other works by <xref ref-type="bibr" rid="c21">Li et al. (2021)</xref>; <xref ref-type="bibr" rid="c28">Pei et al. (2021)</xref> used anatomical priors to train conditional atlases and increase performance. Deep attentive modules <xref ref-type="bibr" rid="c6">Dou et al. (2021)</xref> and incorporation of additional topological information <xref ref-type="bibr" rid="c7">de Dumast et al. (2021)</xref>; <xref ref-type="bibr" rid="c20">Li et al. (2022)</xref> were used to improve cortical segmentation. Recently, <xref ref-type="bibr" rid="c15">Karimi et al. (2023)</xref> also reported a significant improvement of segmentation results based on training on smoothed noisy segmentations of globally refined propagated atlas labels <xref ref-type="bibr" rid="c12">Gholipour et al. (2017)</xref>.</p>
<p>One of the remaining major challenges is caused by the lack of established high quality ground truth segmentations. Even with advanced deep learning methods, use of low quality training labels is generally expected to propagate systematic errors to the predicted segmentation and volumetry outputs. This is made more challenging, since there is still no universally accepted reference parcellation protocol for fetal brain anatomy. Recent quantitative studies relied either on publicly available atlas parcellation maps <xref ref-type="bibr" rid="c12">Gholipour et al. (2017)</xref> or internal fetal MRI exper-115 tise. Reliability if further affected by different acquisition parameters, image quality and anatomical variations.</p>
</sec>
<sec id="s2">
<label>2.</label>
<title>Contributions</title>
<p>In this work, we propose a new refined protocol for parcellation of fetal brain tissue in 3D T2w SVR-reconstructed fetal brain images. It is defined a set of labels for the T2w channel of the new publicly available 21-36 GA fetal brain MRI atlas <xref ref-type="bibr" rid="c37">Uus et al. (2023)</xref> from the developing Human Connectome Project (dHCP). This protocol is then used as a basis for semi-supervised training of a dedicated deep learning segmentation pipeline (BOUNTI) for 3D T2w SVR-reconstructed images. The training of networks is based a large set of high-quality brain segmentations created by thorough manual refinement of labels propagated from the GA-matched atlases. In addition, the feasibility of the pipeline is assessed by comparison of brain tissue volumetry growth charts created from segmentations of 390 3D T2w brain images from three normal cohorts, acquired with different acquisition protocols, and quantitative volumetric comparison between 60 normal control and 65 ventriculomegaly cases.</p>
</sec>
<sec id="s3">
<label>3.</label>
<title>Methods</title>
<p>This work proposes a practical deep learning segmentation solution for 3D T2w fetal brain images for automated volumetric analysis of large cohorts that would minimise the need for excessive manual editing. <xref rid="fig1" ref-type="fig">Fig. 1</xref> summarises the main components of implementation of the proposed pipeline. At first, we define a new refined brain tissue parcellation protocol in the dHCP fetal atlas space. The atlas label propagation in combination with thorough manual refinement is then used to generate a large consistent set of high quality segmentations of 3D SVR fetal brain images from cohorts with different acquisition protocols. The brain segmentation networks are trained in several iterations based on semi-supervised approach.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><p>The main steps of the proposed solution for implementation of a deep learning pipeline for 3D brain tissue parcellation for motioncorrected 3D fetal MRI.</p></caption>
<graphic xlink:href="537347v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s3a">
<label>3.1.</label>
<title>Cohorts, datasets and preprocessing</title>
<p>The fetal brain T2w SSTSE MRI datasets used in this work were acquired as part of different studies at Kings College London with different acquisition protocols. These included:</p>
<list list-type="bullet">
<list-item><p>302 fetal participants from the developing Human Connectom Project - dHCP (REC 14/Lo/1169) project acquired on 3T Philips Achieva MRI system with a 32-channel cardiac coil using a dedicated dHCP fetal acquisition protocol <xref ref-type="bibr" rid="c30">Price et al. (2019)</xref> with TE=250ms, acquisition resolution 1.1 × 1.1mm, slice thickness 2.2mm, -1.1mm gap and 6 stacks;</p></list-item>
<list-item><p>55 fetal participants from the Intelligent Fetal Imaging and Diagnosis - iFIND (REC 14/LO/1806) project acquired on 1.5T Philips Ingenia MRI system using 28-channel torso coil with TE=80ms and TE=180ms, acquisition resolution 1.25×1.25mm, slice thickness 2.5, -1.25mm gap and 9-11 stacks;</p></list-item>
<list-item><p>85 fetal participants with cardiac anomalies from the fetal CMR service at Evelina London Children’s Hospital (REC 07/H0707/105) acquired on 1.5T Philips Ingenia MRI system using 28-channel torso coil with165 TE=80ms, acquisition resolution 1.25 × 1.25mm, slice thickness 2.5, -1.25mm gap and 9-11 stacks;</p></list-item>
<list-item><p>91 fetal participants from the Placental Imaging Project-PiP (REC 16/LO/1573) and Individualised Risk prediction of adverse neonatal outcome in pregnancies that deliver preterm using advanced MRI techniques and machine learning study (REC 21/SS/0082), on 3T Philips Achieva MRI system using a 32-channel cardiac coil with TE=180ms, acquisition resolution 1.25 × 1.25mm, slice thickness 2.5, -1.5mm gap and 5-6 stacks;</p></list-item>
<list-item><p>55 fetal participants from the CARP (REC 19/LO/0852) and Placental Imaging Project -PiP (REC 16/LO/1573) projects acquired on 1.5T Philips Ingenia MRI system using 28-channel torso coil with TE=180ms, ac-SVR method to 0.75-0.8mm isotropic resolution using the quisition resolution 1.25 × 1.25mm, slice thickness 2.5, -1.25mm gap, and 4-5 stacks;</p></list-item>
<list-item><p>125 fetal participants from the Quantification of fetal growth and development using magnetic resonance imaging study (REC 07/H0707/105) acquired on 1.5T Philips Achieva MRI system using 32-channel cardiac coil with TE= 160ms, acquisition resolution 1.25 × 1.25mm, slice thickness 2.5, -1.5mm gap and 8 stacks.</p></list-item>
</list>
<p>The cohort includes both normal control and a subset of cases with abnormal findings but without extreme deviations in their anatomy (presence and preserved global shape of all brain regions and absence of lesions). The GA of participants varies within 20-38 weeks range.</p>
<p>All 3D brain images were reconstructed using fully automated SVR motion-corrected pipelines. The dHCP datasets were reconstructed using the dedicated dHCP SVR method Cordero-Grande1 et al. (2019) to 0.5mm resolution and reoriented <xref ref-type="bibr" rid="c40">Wright et al. (2018)</xref> to the standard radiological space. The rest of the datasets were reconstructed based on the <xref ref-type="bibr" rid="c17">Kuklisova-Murgasova et al. (2012)</xref> automated version<sup><xref ref-type="fn" rid="fn2">2</xref></sup> that also includes automatic reorientation to the standard space. We used only acceptable quality datasets with sufficient visibility of all brain structures and anatomical features. SVR reconstructions with intensity artifacts or failed motion correction (that on average tend to be present in approximately 10-15% of all cases) were not included in this study.</p>
</sec>
<sec id="s3b">
<label>3.2.</label>
<title>Proposed brain tissue parcellation protocol</title>
<p>Currently, there is no established consensus in the existing fetal brain manual annotation protocols (e.g., <xref ref-type="bibr" rid="c12">Gholipour et al. (2017)</xref>; <xref ref-type="bibr" rid="c18">Kyriakopoulou et al. (2017)</xref>; <xref ref-type="bibr" rid="c16">Khalili et al. (2019)</xref>; <xref ref-type="bibr" rid="c25">Payette et al. (2021)</xref>). This is further complicated by the difference between the fetal and neonatal anatomy and lower image resolution of fetal MRI (e.g., DRAW-EM <xref ref-type="bibr" rid="c23">Makropoulos et al. (2018)</xref>) relative to the size of the fetal brain. Therefore, we formalised a new brain tissue segmentation protocol that is defined as a set of labels in the new fetal brain MRI dHCP atlas (<xref ref-type="bibr" rid="c37">Uus et al. (2023)</xref>) space using the T2w channel and 16 timepoints from 21 to 36 weeks.</p>
<p>The inclusion and definition criteria for individual tissue structures were based on the clinical relevance to quantitative studies, evidence from the anatomy histology atlases <xref ref-type="bibr" rid="c2">Bayer and Altman (2003</xref>, <xref ref-type="bibr" rid="c3">2005</xref>) and the clear visibility of the structures in individual subject 3D T2w SVR MRI images. At first, we used the optimised neonatal dHCP DRAW-EM pipeline <xref ref-type="bibr" rid="c23">Makropoulos et al. (2018)</xref> to create an initial set of segmentations of the major tissue structures. Next, a clinical researcher (VK), with more than 10 years experience in fetal MRI, manually refined and subdivided (when relevant) the labels to 19 ROIs using ITK-SNAP<sup><xref ref-type="fn" rid="fn3">3</xref></sup> including cortical grey matter (GM), white matter (WM), cerebrospinal fluid (CSF), deep GM (DGM), ventricles, cavum, brainstem and cerebellum ROIs. The refinement was based on the fetal brain anatomy guidebooks <xref ref-type="bibr" rid="c2">Bayer and Altman (2003</xref>, <xref ref-type="bibr" rid="c3">2005</xref>) and performed for 3 atlas timepoints: 25, 30 and 36 weeks GA. This was followed by left/right separation of all paired structures. These preliminary parcellation maps were propagated to the rest of the atlas timepoints using nonlinear registration from MIRTK<sup><xref ref-type="fn" rid="fn4">4</xref></sup> and manually refined, when required. These parcellations were then used to generate the ground truth labels for training of the proposed BOUNTI segmentation network described in the next section. The final set of atlas parcellation maps was created by using the final version of the trained BOUNTI segmentation pipeline (described in Sec. 3.3). This was done to reduce any partial volume effects at the cortex interface or inconsistencies in manual segmentations.</p>
<p>The atlas along with the proposed tissue parcellation maps is publicly available at the online Centre for the Developing Brain (CDB) data repository <sup><xref ref-type="fn" rid="fn5">5</xref></sup>.</p>
</sec>
<sec id="s3c">
<label>3.3.</label>
<title>Automated parcellation of the fetal brain BOUNTI segmentation pipeline</title>
<p>The proposed pipeline for “Brain vOlumetry and aU-tomated parcellatioN for 3D feTal MRI” (BOUNTI) is summarised in <xref rid="fig2" ref-type="fig">Fig. 2.A</xref>. It consists of two main steps.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><p>Proposed BOUNTI pipeline for automated brain tissue parcellation for 3D T2w fetal MRI (A) and preparation of labels for semi-supervised training (B).</p></caption>
<graphic xlink:href="537347v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Initially, a 3D CNN module is used for global localisation of the brain in order to remove any present external background ROI. This also increases robustness to variations in formats of outputs of different SVR methods (e.g., with or without masking and padding). Next, the cropped, masked and bias corrected 3D brain ROI is segmented using a multi-label 3D CNN module trained on datasets with manually refined labels propagated from the atlas using registration. Taking into account the large number of datasets required for training, as well as the time-consuming nature of the manual refinement process, we employed a semi-supervised approach with several iterations. At each iteration, a preliminary version of a pretrained network is used for generation of a larger dataset followed by manual fine-editing of labels for the final training stage.</p>
<sec id="s3c1">
<title>Selected deep learning models</title>
<p>For the segmentation pipeline, we chose to use a combination of a classical 3D UNet Özgün Çiçek et al. (2016) and an attention UNet <xref ref-type="bibr" rid="c24">Oktay et al. (2018)</xref> architectures for both CNN modules for brain extraction and tissue parcellation. While 3D UNet is a robust and well established tool widely used in 3D fetal MRI <xref ref-type="bibr" rid="c25">Payette et al. (2021)</xref>, attention UNet reportedly improves prediction performance by focusing on important structures of varying shapes.</p>
<p>We used the standard MONAI <xref ref-type="bibr" rid="c4">Cardoso et al. (2022)</xref> 3D UNet and Attention-UNet implementations with five and four encoder-decoder blocks (output channels 32, 64, 128, 256 and 512), correspondingly, convolution and upsampling kernel size of 3, ReLU activation, dropout ratio of 0.5. We employed AdamW optimiser with a linearly decaying learning rate, initialised at 1×10<sup><italic>−</italic>3</sup>, default <italic>β</italic> parameters and weight decay=1×10<sup><italic>−</italic>5</sup>. The input image dimensions are 128×128×128 and 256×256×256 and the outputs have 2 and 20 channels (with background) for global localisation and tissue parcellation networks, correspondingly. At inference, the predictions (per tissue ROI) of 3D UNet and Attention-UNet networks are averaged at the output before softmax. In addition, in order to improve robustness of the pipeline and limit any possible bias in segmentation of the left and right structures, the images are passed through the network twice, in the original orientation and flipped along Y-axis. The second prediction is then flipped to the original orientation, and order of the output channels is updated. The two segmentations are then averaged to produce the final output.</p>
</sec>
<sec id="s3c2">
<title>Selected datasets for training and testing</title>
<p>The training for both brain extraction and tissue parcellation was performed on datasets with different acquisition protocols and SVR reconstruction methods. The summary is provided in Tab. 1. The GA range of the participants varies within the 21-38 weeks GA range. The testing dataset includes 40 randomly selected (not used in training) 3D T2w SVR reconstructed images from 4 different acquisition protocols.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p>Summary information about training and testing datasets.</p></caption>
<graphic xlink:href="537347v2_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s3c3">
<title>Image preprocessing</title>
<p>Taking into account the varying size, resolution and intensity ranges of input SVR reconstructions, the general preprocessing steps for all images in both steps of the pipeline included: transformation to the standard radiological space coordinate system, cropping of the background, resampling with padding to the required input grid size and rescaling to 0-1 range. For the brain tissue segmentation step, the brain images were also masked and cropped with the dilated (2 iterations) global brain masks obtained from the first step of the BOUNTI pipeline. All preprocessing steps were implemented based on MIRTK toolbox.</p>
</sec>
<sec id="s3c4">
<title>Preparation of training datasets</title>
<p>For both CNN steps of the pipeline, training was performed in three stages. In this case, a version of the network pretrained on a small number of cases (from the previous iteration) was used for segmentation of the main training dataset. This strategy was selected for both practical reasons and required accuracy and consistency of the ground truth labels.</p>
<p>For the brain extraction CNN step, we used an already existing network (3D UNet in MONAI pretrained on datasets from other research projects at our institution) to segment all SVR brain reconstructions with different background coverage and masking. The output segmentations were inspected and manually refined (at every stage), when required, resulting in 380 images for final training. We augmented the training dataset by allowing image masking to be performed with a varying degree of dilation (2 to 18 iterations) of the brain mask and background padding. For the first stage of training of the brain tissue parcellation CNN, we generated labels via registration-guided atlas propagation n (19 ROIs) for a preliminary set of 200 fetal brain from dHCP and iFIND/fCMR cohorts covering 20-38 weeks GA range. Image registration was run with multi-channel (T2w and cortex generated by an existing in-house 3D UNet trained on Draw-EM cortical segmentations for dHCP cohort) nonlinear MIRTK registration <xref ref-type="bibr" rid="c34">Rueckert et al. (1999)</xref> with LNCC metric and 6mm window size. After visual inspection, 100 images (distributed across the whole GA range) with the minimal/average amount of errors (based on visual assessment of cortical interface) were selected and semi-manually refined by researchers (AU, DC, AD) trained in fetal MRI (<xref rid="fig2" ref-type="fig">Fig. 2.B</xref>). The refinement included editing of the cortex, WM, CSF, deep GM and cerebellum ROIs using the user-guided active contour segmentation tool <xref ref-type="bibr" rid="c41">Yushkevich et al. (2006)</xref> in ITK-SNAP, followed by local manual editing of individual tissue labels. In general, label propagation worked well for 21-31 weeks GA range with only minimal editing required (mainly for low image quality or cases with abnormal findings). For late GA (<italic>&gt;</italic>34 weeks) cases, refinement required approximately 1-2 hours per case, primarily focusing on the cortex ROI. Notably, even after refinement the cortex labels were not smooth and had minor discontinuities / overlap between WM/GM/CSF ROIs. In addition, the training dataset was extended by flipping of the brain in a left/right direction (with corresponding changes of the label numbers) and histogram matching to different TE references (e.g., from TE=250ms to TE=80ms) as augmentation for the flipped versions.</p>
<p>This first version of the refined datasets was used for preliminary training of a 3D UNet. The network was then used to segment all 380 fetal brain images from a mixture of the available cohorts (including the originally refined) with more early (<italic>&lt;</italic>22 weeks) and late (<italic>&gt;</italic>34) participants to balance the extreme anatomy differences. All labels were reviewed in terms of errors and 200 images were selected for further training. The output CNN labels for the selected images were again edited in ITK-SNAP (using active contours and manual refinement), when required. The new training dataset was then used to train the network with the same data augmentation strategy followed by segmenting, review and editing of the next part of 3D brain images. This procedure was repeated for a second time. The final training dataset consisted of 380 images (doubled by flipping augmentation).</p>
</sec>
<sec id="s3c5">
<title>Training of the networks</title>
<p>Training of all networks was performed in MONAI framework using soft Dice and cross entropy loss and AdamW optimiser. The final training stage of the brain extraction 3D UNet and Attention-UNet was performed on 360 training and 20 validation datasets for 20000 and 50000 iterations, correspondingly. The networks were trained separately. The final training of the brain tissue parcellation 3D UNet and Attention-UNet was performed on 360 training and 20 validation datasets for 150000 and 300000 iterations, correspondingly. We used standard MONAI augmentation including: bias field, affine rotations, Gaussian noise and blurring.</p>
</sec>
<sec id="s3c6">
<title>Docker for the brain segmentation pipeline</title>
<p>The proposed fetal brain segmentation pipeline with trained networks is publicly available as a standalone docker application<sup><xref ref-type="fn" rid="fn6">6</xref></sup> at SVRTK fetal segmentation repository. In order to ensure high segmentation quality, the main input requirements to 3D fetal MRI SVR reconstructed images include: T2w contrast (1.5/3T, TE=80-250ms), orientation in the standard radiological space, 21-38 weeks GA range, no extreme structural anomalies, sufficient image quality (in terms of clear visibility and definition of the brain structures) and no extreme SNR loss or shading artifacts.</p>
</sec>
</sec>
<sec id="s3d">
<label>3.4.</label>
<title>Growth charts of the fetal brain development</title>
<p>In order to assess the practical application of the proposed dHCP brain parcellation protocol and segmentation pipeline, we used the BOUNTI pipeline for segmentation of 244 normal control fetuses from the dHCP project (185 of these datasets were used during the training stage) and 146 normal participants from two other cohorts (1.5T, TE=180ms and 3T, TE=180) with different MRI acquisition parameters from 21 to 38 weeks GA range and singleton pregnancies (these datasets were not used in training). All images were resampled to 0.5mm isotropic resolution. All segmentations were reviewed and manually fine-edited, if required, in order to ensure reliability of nomograms and assess the impact on global trends.</p>
<p>The label volumetry was used to create growth charts (mean, 5<sup>th</sup> and 95<sup>th</sup> centiles) for brain development of 9 structures (combined right/left and associated ROIs) based on the guidelines from <xref ref-type="bibr" rid="c33">Royston and Wright (1998)</xref>. The output table-format centile calculator for all individual structures is available at the atlas repository. The statistical difference between the cohorts was assessed for the main solid tissue structures (WM, cortical GM, deep GM) using ANCOVA analysis (volume measurements were converted to log format, when relevant).</p>
<sec id="s3d1">
<title>Comparison of normal control and VM cohorts</title>
<p>In addition, to test the performance of the BOUNTI pipeline we utilised imaging data from our previously published study <xref ref-type="bibr" rid="c18">Kyriakopoulou et al. (2017)</xref> and compared the volumetric results. We run BOUNTI on a cohort of fetuses with ventriculomegaly (65) and a normal control (60) cohort. All 125 fetal MRI datasets were reconstructed using the classical SVR method <xref ref-type="bibr" rid="c17">Kuklisova-Murgasova et al. (2012)</xref>, reoriented to the standard space and resampled to 0.5 mm resolution. The 3D brain images were segmented using the BOUNTI pipeline and visually inspected and manually refined, when required. The volume of the total lateral ventricles and suprantentorial brain tissue was compared between the cohorts using ANOVA with and without manual refinement.</p>
</sec>
</sec>
</sec>
<sec id="s4">
<label>4.</label>
<title>Results and experiments</title>
<sec id="s4a">
<label>4.1.</label>
<title>Proposed tissue parcellation protocol</title>
<p>The proposed multi-tissue parcellation protocol defined for the dHCP fetal brain MRI atlas<sup><xref ref-type="fn" rid="fn7">7</xref></sup> is shown in <xref rid="fig3" ref-type="fig">Fig. 3</xref>. It includes 19 major brain tissue ROI labels: cortical GM, fetal WM, external CS, lateral ventricles, cavum, thalamus, basal ganglia, brainstem, cerebellum, vermis, 3rd and 4th ventricles, with left/right separation of paired structures. <xref rid="fig4" ref-type="fig">Fig. 4</xref> demonstrates parcellation maps at 21, 26, 31 and 36 weeks that reflect the expected changes during normal brain development such as cortical folding and shape of the ventricles. Rendered cortical GM and WM have smooth boundaries without gaps and with well defined cortical folds. The cortical ribbon parcellation is thin without partial volume effect in WM.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><p>Proposed tissue parcellation protocol defined in the dHCP fetal brain MRI atlas.</p></caption>
<graphic xlink:href="537347v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><p>Proposed multi-tissue brain parcellation maps at 21, 26, 31 and 36 weeks GA timepoints of the dHCP fetal brain MRI atlas.</p></caption>
<graphic xlink:href="537347v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s4b">
<label>4.2.</label>
<title>Automated parcellation of the fetal brain Comparison with semi-manual GT segmentations</title>
<p>The results of testing of the BOUNTI pipeline on 40 T2w SVR brain images from 4 different acquisition protocols and 21-38 weeks GA range (Tab. 2) showed robust performance for all tissue ROIs. In all 40 test cases, all structures were correctly globally detected in all BOUNTI segmentations (100 % detection rate). The relatively high Dice values are expected due to the high quality and consistency of training datasets generated by label propagation and thorough manual refinement. There were no systematic differences in the method performance for different test groups apart from slightly higher Dice values for the dHCP cohort (3T, TE=250ms). This potentially is due to higher tissue contrast and spatial resolution of the images, as well as similarity to the atlas. The relative volume differences are within the generally acceptable range. Even after manual and active contour refinement, the classical registration-based LP is prone to minor inconsistencies for the cortex ROI especially at late GA due to complex folding patterns. <xref rid="fig5" ref-type="fig">Fig. 5</xref> demonstrates that BOUNTI corrected overestimation of CSF and cortical GM that were present in the semi-manual ground LP labels. The CNN outputs have significantly smoother cortex boundaries and less errors at different tissue interfaces than the ground truth LP. This is in agreement with the previously reported successful CNN performance in the recent FETA brain MRI challenge <xref ref-type="bibr" rid="c25">Payette et al. (2021)</xref>.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><p>An example of comparison of BOUNTI segmentation results vs. the original and manually refined (ground truth) label propagation: late GA test case from dHCP cohort (3T, TE=250ms).</p></caption>
<graphic xlink:href="537347v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s4b1">
<title>Impact of GA at scan</title>
<p><xref rid="fig6" ref-type="fig">Fig. 6</xref> shows BOUNTI segmentation results for test cases at different GA ranges. In general, the network performed better for the early and medium GA ranges. Several minor errors were present at the back of the cortex ROI in 6 late GA cases <italic>≥</italic>35 weeks. This suggests the further need for incorporation of topological information <xref ref-type="bibr" rid="c20">Li et al. (2022)</xref> to ensure spatial continuity of individual structures, which will be especially relevant for surfacebased analysis as well as late GA cases.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><p>Examples of the outputs of segmentation pipeline for the test cases with different acquisition protocols and gestational ages.</p></caption>
<graphic xlink:href="537347v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s4b2">
<title>Impact of acquisition and SVR reconstruction parameters</title>
<p>The examples of the segmentation results for all four acquisition protocols with 1.5T and 3T field strength and 80, 180 and 250ms echo time in <xref rid="fig6" ref-type="fig">Fig. 6</xref> show clearly different tissue contrasts and different image quality in terms of definition of the finer features (due to SNR levels and blurring). In addition to the quantitative analysis (Tab. 2), visual assessment of all test cases did not reveal distinct differences in terms of the network performance. This is also in agreement with the experiments in <xref ref-type="bibr" rid="c26">Payette et al. (2020)</xref> that the choice of SVR methods does not significantly affect segmentation performance (excluding cases with failed reconstruction).</p>
</sec>
<sec id="s4b3">
<title>Impact of image quality and artifacts</title>
<p>Similarly to acquisition parameters, intensity artifacts or low SNR alter tissue contrast and visibility of structures, which in turn tend to affect accuracy and certainty of segmentations. The examples in <xref rid="fig7" ref-type="fig">Fig. 7.A</xref> show the results of BOUNTI segmentation pipeline for previously unseen suboptimal image quality cases. While the network seemed to produce relatively stable results for low SNR regions, it failed in the cortex ROI with severe B1 shading (that could not be resolved by N4). This suggests that the degree of MONAI bias field augmentation used during the training was not sufficient, and more severe simulated shading artifacts (or more advanced bias field correction approach) would be required to address this issue. However, volumetry derived from low image quality datasets cannot be considered reliable by definition. Therefore, clinical translation of the pipeline would require a detailed specification of the image quality requirements and an additional step for automated assessment of expected segmentation certainty.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7:</label>
<caption><p>Examples of BOUNTI segmentation results for suboptimal image quality (A) and abnormal <xref ref-type="bibr" rid="c25">Payette et al. (2021)</xref> (B) cases.</p></caption>
<graphic xlink:href="537347v2_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s4b4">
<title>Impact of anomalies</title>
<p>Two examples of BOUNTI segmentations for the previously unseen abnormal cases from the FETA challenge <xref ref-type="bibr" rid="c25">Payette et al. (2021)</xref> are shown in <xref rid="fig7" ref-type="fig">Fig. 7.B</xref>. Since the training dataset included abnormal cases with ventriculomegaly, visual analysis confirms that the network performance was relatively acceptable for cases with slightly enlarged ventricles. However, as expected, the network produces various errors for anomalies with significant alternations in the brain anatomy such as extreme ventriculomegaly. The optimal solution would require further training on large abnormal cohorts (e.g., similarly to <xref ref-type="bibr" rid="c10">Fidon et al. (2021b)</xref>) along with possible introduction of classification step and optimisation of the network architecture and parcellation protocol. Notably, the best reported performances in terms of average Dice from the FETA segmentation challenge <xref ref-type="bibr" rid="c27">Payette et al. (2022)</xref> vary within 0.78-0.79 range (vs. 0.87-0.90 for BOUNTI performance540 Tab. 2), which highlights the advantages of using high quality consistent ground truth labels for training.</p>
</sec>
<sec id="s4b5">
<label>4.2.1.</label>
<title>Alternative fetal brain segmentation methods</title>
<p>Taking into account the intrinsic differences in parcel-545 lation protocols (e.g., different exclusion / inclusion strategies for cortical and deep grey matter ROIs), the outputs of BOUNTI cannot be directly quantitatively compared to alternative segmentation methods. The example of visual comparison with a classical 3D UNet trained on the original FETA <xref ref-type="bibr" rid="c25">Payette et al. (2021)</xref> datasets (7 ROIs) and label propagation from a GA-matched alternative atlas <xref ref-type="bibr" rid="c12">Gholipour et al. (2017)</xref> (27 ROIs) is shown in <xref rid="fig8" ref-type="fig">Fig. 8</xref>. These two datasets at 24 and 35 weeks GA are from 3T, TE=180ms cohort. In general, BOUNTI provides more robust performance for the cortex ROI with thinner and smoother cortical ribbon and smaller amount of errors in comparison the other methods. This is caused by failed registration or inconsistencies in training datasets.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8:</label>
<caption><p>Examples of visual comparison of BOUNTI results with classical 3D UNet trained on the original FETA <xref ref-type="bibr" rid="c25">Payette et al. (2021)</xref> datasets with manual labels (7 ROIs) and label propagation from an alternative atlas<xref ref-type="bibr" rid="c12">Gholipour et al. (2017)</xref> (27 ROIs): two datasets at 24 and 35 weeks GA are from 3T, TE=180ms cohort. Note: the label colours were adapted for optimal comparison.</p></caption>
<graphic xlink:href="537347v2_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s4c">
<label>4.3.</label>
<title>Growth charts of normal fetal brain development</title>
<p>In order to assess the general applicability of the proposed brain atlas parcellation protocol and BOUNTI pipeline, we used it to create volumetry growth charts (<xref rid="fig9" ref-type="fig">Fig. 9</xref>) of the typical fetal brain development during 21 to 38 weeks GA range based on healthy control datasets from four studies with different acquisition protocols. It includes: 55 cases with 1.5T, TE=180ms (PiP, CARP); 91 cases 3T, TE=180ms (PiP, PRESTO) and 244 cases with 3T, TE=250ms (dHCP). Only cases without reported anomalies and with good quality images were selected. In order to ensure the validity of nomograms all segmentations generated by the BOUNTI pipeline were visually inspected.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><p>Quantitative comparison of BOUNTI segmentation results with semi-manual (label propagation with manual refinement) ground truth labels: average Dice, recall and precision. The datasets include 40 cases from 21-38 weeks GA range from 4 different acquisition protocols. Note: the labels for pair/related structures were combined.</p></caption>
<graphic xlink:href="537347v2_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9:</label>
<caption><p>Growth charts: volumetry of the major brain structures for normal fetal cohorts from fetal MRI research studies with different acquisition parameters: 1.5T, TE=180ms (blue, 55 participants); 3T, TE=180ms (red, 91 participants); 3T, TE=250ms (lilac, 244 participants). Note: the left and right labels for pair structures were combined.</p></caption>
<graphic xlink:href="537347v2_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Only minor refinements at the cortex interface were required for 6 early (<italic>&lt;</italic>23 weeks) and 38 late (<italic>&gt;</italic>35 weeks) GA cases due to either suboptimal regional image quality or complex cortical patterns. Notably, the refinements did not produce significant changes in volumetry results (not exceeding 5% for individual labels volumes) and, on average, required less than 1-5 minutes per case of manual editing. This is a significant improvement in comparison to the previously reported required time-consuming extensive manual refinement (e.g., 1-3 hours per case in <xref ref-type="bibr" rid="c36">Story et al. (2021)</xref>). This further emphasises that results of any automated segmentation methods should always be inspected and confirmed before any quantitative analysis. Further development of the BOUNTI pipeline would also require integration of automated image and segmentation quality control steps as well definition of what constitutes a correct segmentation and the acceptable levels of accuracy.</p>
<p>The trends for all structures demonstrate the expected increase in volume with GA <xref ref-type="bibr" rid="c18">Kyriakopoulou et al. (2017)</xref>; <xref ref-type="bibr" rid="c22">Machado-Rivas et al. (2021)</xref> with higher variability for external CSF and lateral ventricle volumes. There are no visible systematic deviations in the trends for different field strength and echo time. This was further confirmed by ANCOVA analysis that showed no significant differences in volumetry for the major solid tissue structures. These preliminary results show general feasibility of automated CNN solution for the accurate brain volumetry, even in the presence of acquisition differences. However, any quantitative volumetry analysis of datasets from different studies would still require careful analysis of systematic differences and implementation of a dedicated harmonisation solution.</p>
</sec>
</sec>
<sec id="s5">
<label>4.4.</label>
<title>Comparison on normal control and VM cohorts</title>
<p>Following visual inspection of the 125 datasets for any miss-labelled voxels, 6 out of the 125 cases required manual refinement in the lateral ventricle and cortical ROIs. The graphs in <xref rid="fig10" ref-type="fig">Fig. 10</xref> demonstrate the volumetric comparison between the ventriculomegaly (65) and normal control (60) fetal MRI datasets (without manual editing). For this study, manual editing in the ventricle and cortex ROIs was required for 6 cases. Prior to manual editing, there is a significant difference between the cohorts, with higher supratentorial brain (<italic>p &lt;</italic> 0.0001) and lateral ventricle (<italic>p &lt;</italic> 0.0001) volumes in the VM cohort. The statistical significant difference in both the lateral ventricular volume (<italic>p &lt;</italic> 0.0001) and supratentorial brain (<italic>p &lt;</italic> 0.0001) remained following manual editing of the 6 cases. This is also in agreement with the originally reported results that were based on exclusively manually performed segmentations <xref ref-type="bibr" rid="c18">Kyriakopoulou et al. (2017)</xref>.</p>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure 10:</label>
<caption><p>Comparison of the VM (65) and normal control (60) fetal MRI cases from <xref ref-type="bibr" rid="c19">Kyriakopoulou et al. (2014)</xref> study based on the new set of unedited parcellations from BOUNTI: lateral ventricle and supratentorial brain volumes. Note: the left and right labels for pair structures were combined.</p></caption>
<graphic xlink:href="537347v2_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s6">
<label>5.</label>
<title>Discussion</title>
<p>The main aim of the new dHCP tissue T2w parcellation protocol and training of the “BOUNTI” pipeline was implementation of a foundation automated multi-label segmentation tool suitable for robust and practical volumetric analysis at wide GA ranges and different acquisition protocols that would minimise required manual refinement.</p>
<p>First, we defined a new protocol for brain tissue parcellation in the fetal MRI dHCP atlas space for 21-36 weeks GA timepoints. The proposed parcellation map includes 19 tissue ROIs defined in the atlas space.</p>
<p>The CNN pipeline (based on combination of 3D Attention and classical UNet) was trained on 360 T2w 3D SVR-reconstructed brain images from 6 studies with different acquisition protocols and SVR reconstruction methods. In order to generate a high quality training dataset, we used a semi-supervised approach based on several iterations of manual refinement of atlas label propagations and outputs of the pretrained network. The results of testing on 40 images from different cohorts showed consistent performance for the whole GA range and varying image contrast. The predicted segmentations have a well defined cortex interface with only minor errors present in a small proportion of late GA cases. This significantly minimises required manual editing in comparison to the alternative solutions. Furthermore, BOUNTI segmentation is significantly faster (1-5 minutes per case depending on system configuration and image parameters) than the alternative classical methods such as Draw-EM or label propagation.</p>
<p>The BOUNTI pipeline was then used to segment 390 3D T2w fetal brain images of the normal participants from the dCHP and two other cohorts acquired at different field strength and with different echo time. Notably, only minor manual editing was required in <italic>&lt;</italic> 15% of all cases without significant changes in volumetric measurements. The corresponding generated growth charts showed no significant differences in trends of the main solid brain tissue ROIs for different acquisition parameters. Furthermore, comparison of BOUNTI label volumes between the normal and cases with VM from our earlier study <xref ref-type="bibr" rid="c19">Kyriakopoulou et al. (2014)</xref> showed similar significant differences. These preliminary results potentially suggest the suitability of using one universal network for segmentation of datasets with different acquisition protocols. The good quality of BOUNTI cortical segmentations also suggests that they can be used for automated surface-based analysis <xref ref-type="bibr" rid="c23">Makropoulos et al. (2018)</xref>. However, any quantitative volumetry analysis of datasets from different studies will still require implementation of a dedicated harmonisation solution. The BOUNTI segmentation pipeline docker is publicly available online.</p>
</sec>
<sec id="s7">
<title>Limitations and future work</title>
<p>In terms of the limitations, unlike the previously presented fetal brain atlas parcellation map in <xref ref-type="bibr" rid="c12">Gholipour et al. (2017)</xref>, the current version of the BOUNTI pipeline includes only global tissue segmentation protocol with 19 ROIs without further subdivision into standard anatomical regions (e.g., frontal lobe). We are planning to further extend the parcellation map by separating the tissue compartments into anatomical ROIs and transient fetal compartments at the next stage of optimisation of the BOUNTI pipeline.</p>
<p>Any large scale application of the pipeline will also require retraining on a wider range of anomalies <xref rid="c10" ref-type="bibr">Fidon et al. (2021b</xref>) with potential optimisation of the parcellation protocol (e.g., for agenesis of the corpus callosum).</p>
<p>Moreover, while this work provides a baseline pipeline for further development, we did not perform any quantitative investigations of the impact of changes in intensity or image quality (i.e., definition of features) on segmentation results. Application of deep learning segmentation for multi-centre/scanner quantitative volumetry studies would require careful analysis of harmonisation requirements and potential optimisation of the networks.</p>
<p>Integration of data harmonisation <xref ref-type="bibr" rid="c13">Grigorescu et al. (2021)</xref> for different acquisition parameters and suboptimal image quality is one of the planned future steps along with incorporation of additional topological cortical constrains.</p>
<p>Further development of the BOUNTI pipeline would also require integration of automated image and segmentation quality control steps as well definition of what constitutes a correct segmentation and the acceptable levels of accuracy. This will also include a comprehensive quantitative evaluation of feasibility of using BOUNTI pipeline for analysis of different cohorts.</p>
</sec>
<sec id="s8">
<label>6.</label>
<title>Conclusions</title>
<p>In this work, we formalised the new refined brain tissue protocol for 3D motion-corrected T2w fetal MRI in the spatiotemporal fetal atlas from the dHCP project. This protocol was used as a basis for training a deep learning BOUNTI pipeline for automated fetal brain segmentation on 360 fetal MRI datasets with different acquisition parameters. We used a semi-supervised approach for generation of the training datasets with manually refined labels propagated from the atlas. The pipeline showed robust performance across 21 - 36 weeks GA range and with different acquisition protocols.</p>
<p>The BOUNTI pipeline was then used to segment 390 normal control cases from 3 different cohorts with different acquisition parameters. Only minor errors in <italic>&lt;</italic> 15% of cases thus significantly reducing the need for manual refinement. A preliminary analysis of the growth charts (21-38 weeks GA range) revealed no significant differences in the major solid tissue structures between the cohorts. In addition, comparison between 65 cases with ventriculomegaly and 60 normal control cases was in agreement with the findings reported in our earlier work using manual segmentation<xref ref-type="bibr" rid="c19">Kyriakopoulou et al. (2014)</xref>. These initial results suggest the general feasibility of using this pipeline as a basis for further development of fetal brain MRI parcellation tools and large-scale volumetric analysis.</p>
<p>The BOUNTI pipeline docker is publicly available online at SVRTK fetal segmentation repository<sup><xref ref-type="fn" rid="fn8">8</xref></sup>.</p>
<p>Our future work will focus on further extension of the anatomical parcellation map and optimisation of the BOUNTI pipeline for a wider range of brain anomalies as well as harmonisation, advanced cortex segmentation and segmentation quality control.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We thank everyone who was involved in acquisition and analysis of the datasets at the Department of Perinatal Imaging and Health at Kings College London and St Thomas’ Hospital. We thank all participants and their families.</p>
<p>This work was supported by MRC Confidence in concept [MC PC 19041], the European Research Council under the European Union’s Seventh Framework Programme [FP7/ 20072013]/ERC grant agreement no. 319456 Dhcp project, the Wellcome Trust and EPSRC IEH award [102431] for the iFIND project, the NIH Human Placenta Project grant [1U01HD087202-01], MRC UK grant [MR/V002465/1], the Wellcome/ EPSRC Centre for Medical Engineering at King’s College London [WT 203148/Z/16/Z], Comunidad de Madrid-Spain under the line support for R&amp;D projects for Beatriz Galindo researchers, MICIN / AEI / 10.13039/501100011033 / FEDER, EU, under Project PID2021-129022OA-I00, NIHR Advanced Fellowship awarded to Lisa Story [NIHR30166], the NIHR Clinical Research Facility (CRF) at Guy’s and St Thomas’ and by the National Institute for Health Research Biomedical Research Centre based at Guy’s and St Thomas’ NHS Foundation Trust and King’s College London.</p>
<p>The views expressed are those of the authors and not necessarily those of the NHS, the NIHR or the Department of Health.</p></ack>
<sec id="s9">
<title>Author contributions</title>
<p>AUU prepared the datasets, developed the pipeline and prepared the manuscript; VK created the original parcellation protocol and contributed to development and testing of the pipeline; AM provided the initial dHCP segmentation pipeline; AG contributed to development the parcellation protocol and testing of the pipeline; DC contributed to training of the networks and testing of the pipeline; AD contributed to training of the networks; LCG contributed to preparation of the datasets; ANP contributed to acquisition of the datasets; IG contributed to development of the pipeline; LG contributed to analysis of the results; ER contributed to analysis of the results; DL provided fetal MRI datasets; KP provided fetal MRI datasets; SJC provided fetal MRI datasets; JH: provided fetal MRI datasets; LS contributed to testing of the pipeline and provided fetal MRI datasets; ADE provided fetal MRI datasets; MR contributed to conceptualisation of the project, development of the parcellation protocol and provided fetal MRI datasets; JVH provided fetal MRI datasets and contributed to analysis of the results; MD contributed to conceptualisation of the project and analysis of the results. All authors reviewed the manuscript.</p></sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Aertsen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Diogo</surname>, <given-names>M.C.</given-names></string-name>, <string-name><surname>Dymarkowski</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Deprest</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Prayer</surname>, <given-names>D.</given-names></string-name>, <year>2020</year>. <article-title>Fetal mri for dummies: what the fetal medicine specialist should know about acquisitions and sequences</article-title>. <source>Prenatal Diagnosis</source> <volume>40</volume>, <fpage>6</fpage>–<lpage>17</lpage>. doi:<pub-id pub-id-type="doi">10.1002/pd.5579</pub-id>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="other"><string-name><surname>Bayer</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Altman</surname>, <given-names>J.</given-names></string-name>, <year>2003</year>. <source>The Human Brain During the Third Trimester</source>. doi:<pub-id pub-id-type="doi">10.1201/9780203494943</pub-id>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="other"><string-name><surname>Bayer</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Altman</surname>, <given-names>J.</given-names></string-name>, <year>2005</year>. <source>The Human Brain During the Second Trimester</source>. doi:<pub-id pub-id-type="doi">10.1201/9780203507483</pub-id>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="other"><string-name><surname>Cardoso</surname>, <given-names>M.J.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Kerfoot</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Murrey</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Myronenko</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>D.</given-names></string-name>, <etal>et al.</etal>, <year>2022</year>. <article-title>Monai: An open-source framework for deep learning in health-care</article-title>. <source>arXiv</source> preprint arXiv:<pub-id pub-id-type="arxiv">2211.02701</pub-id> doi:<pub-id pub-id-type="doi">10.48550/arXiv.2211.02701</pub-id>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="other"><string-name><surname>Cordero-Grande</surname>, <given-names>L.</given-names></string-name>, <etal>et al.</etal>, <year>2019</year>. <source>Automating Motion Compensation in 3T Fetal Brain Imaging: Localize, Align and Reconstruct, in: ISMRM 2019</source>, p. <fpage>1000</fpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Dou</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Karimi</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Rollins</surname>, <given-names>C.K.</given-names></string-name>, <string-name><surname>Ortinau</surname>, <given-names>C.M.</given-names></string-name>, <string-name><surname>Vasung</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Velasco-Annis</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Ouaalam</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Ni</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Gholipour</surname>, <given-names>A.</given-names></string-name>, <year>2021</year>. <article-title>A deep attentive convolutional neural network for automatic cortical plate segmentation in fetal mri</article-title>. <source>IEEE Transactions on Medical Imaging</source> <volume>40</volume>, <fpage>1123</fpage>–<lpage>1133</lpage>. doi:<pub-id pub-id-type="doi">10.1109/TMI.2020.3046579</pub-id>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="book"><string-name><surname>de Dumast</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Kebiri</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Atat</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Dunet</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Koob</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Cuadra</surname>, <given-names>M.B.</given-names></string-name>, <year>2021</year>. <chapter-title>Segmentation of the cortical plate in fetal brain mri with a topological loss</chapter-title>, <source>in: UNSURE and PIPPI MICCAI workshop 2021</source>, <publisher-name>Springer International Publishing</publisher-name>. pp. <fpage>200</fpage>–<lpage>209</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-030-87735-4_19</pub-id>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Ebner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Aertsen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Patel</surname>, <given-names>P.A.</given-names></string-name>, <string-name><surname>Aughwane</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Melbourne</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Doel</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Dymarkowski</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>De Coppi</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>David</surname>, <given-names>A.L.</given-names></string-name>, <string-name><surname>Deprest</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Ourselin</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Vercauteren</surname>, <given-names>T.</given-names></string-name>, <year>2020</year>. <article-title>An automated framework for localization, segmentation and super-resolution reconstruction of fetal brain MRI</article-title>. <source>NeuroImage</source> <volume>206</volume>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116324</pub-id>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="book"><string-name><surname>Fidon</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Aertsen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Emam</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Mufti</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Guffens</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Deprest</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Demaerel</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>David</surname>, <given-names>A.L.</given-names></string-name>, <string-name><surname>Melbourne</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ourselin</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>De-prest</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Vercauteren</surname>, <given-names>T.</given-names></string-name>, <year>2021a</year>. <chapter-title>Label-set loss functions for partial supervision: Application to fetal brain 3d mri parcellation</chapter-title>, <source>in: MICCAI 2021</source>, <publisher-name>Springer International Publishing</publisher-name>. pp. <fpage>647</fpage>–<lpage>657</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-030-87196-3_60</pub-id>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="other"><string-name><surname>Fidon</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Aertsen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Mufti</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Deprest</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Emam</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Guffens</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Schwartz</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ebner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Prayer</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kasprian</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>David</surname>, <given-names>A.L.</given-names></string-name>, <string-name><surname>Melbourne</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ourselin</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Deprest</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Langs</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Vercauteren</surname>, <given-names>T.</given-names></string-name>, <year>2021b</year>. <article-title>Distributionally robust segmentation of abnormal fetal brain 3d mri</article-title>, <source>in: MICCAIN UNSURE, PIPPI work-shops 2021</source>, pp. <fpage>263</fpage>–<lpage>273</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-030-87735-4_25</pub-id>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Gholipour</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Estroff</surname>, <given-names>J.A.</given-names></string-name>, <string-name><surname>Warfield</surname>, <given-names>S.K.</given-names></string-name>, <year>2010</year>. <article-title>Robust super-resolution volume reconstruction from slice acquisitions: Application to fetal brain mri</article-title>. <source>IEEE Transactions on Medical Imaging</source> <volume>29</volume>, <fpage>1739</fpage>–<lpage>1758</lpage>. doi:<pub-id pub-id-type="doi">10.1109/TMI.2010.2051680</pub-id>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Gholipour</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Rollins</surname>, <given-names>C.K.</given-names></string-name>, <string-name><surname>Velasco-Annis</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Ouaalam</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Akhondi-Asl</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Afacan</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Ortinau</surname>, <given-names>C.M.</given-names></string-name>, <string-name><surname>Clancy</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Limperopoulos</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Estroff</surname>, <given-names>J.A.</given-names></string-name>, <string-name><surname>Warfield</surname>, <given-names>S.K.</given-names></string-name>, <year>2017</year>. <article-title>A normative spatiotemporal mri atlas of the fetal brain for automatic segmentation and analysis of early brain growth</article-title>. <source>Nature: Scientific Reports</source> <volume>7</volume>, <fpage>1</fpage>–<lpage>13</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41598-017-00525-w</pub-id>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Grigorescu</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Vanes</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Uus</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Batalle</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Cordero-Grande</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Nosarti</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Edwards</surname>, <given-names>A.D.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.V.</given-names></string-name>, <string-name><surname>Modat</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Deprez</surname>, <given-names>M.</given-names></string-name>, <year>2021</year>. <article-title>Harmonized segmentation of neonatal brain mri</article-title>. <source>Frontiers in Neuroscience</source> <volume>15</volume>, <fpage>565</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnins.2021.662005</pub-id>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Isensee</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Jaeger</surname>, <given-names>P.F.</given-names></string-name>, <string-name><surname>Kohl</surname>, <given-names>S.A.A.</given-names></string-name>, <string-name><surname>Petersen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Maier-Hein</surname>, <given-names>K.H.</given-names></string-name>, <year>2021</year>. <article-title>nnu-net: a self-configuring method for deep learning-based biomedical image segmentation</article-title>. <source>Nature Methods</source> <volume>18</volume>, <fpage>203</fpage>–<lpage>211</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41592-020-01008-z</pub-id>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="other"><string-name><surname>Karimi</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Rollins</surname>, <given-names>C.K.</given-names></string-name>, <string-name><surname>Velasco-Annis</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Ouaalam</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gholipour</surname>, <given-names>A.</given-names></string-name>, <year>2023</year>. <article-title>Learning to segment fetal brain tissue from noisy annotations</article-title>. <source>Medical Image Analysis</source>, <fpage>102731</fpage> doi:<pub-id pub-id-type="doi">10.1016/j.media.2022.102731</pub-id>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Khalili</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Lessmann</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Turk</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Claessens</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>de Heus</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kolk</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Viergever</surname>, <given-names>M.A.</given-names></string-name>, <string-name><surname>Benders</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Iasgum</surname>, <given-names>I.</given-names></string-name>, <year>2019</year>. <article-title>Automatic brain tissue segmentation in fetal mri using convolutional neural networks</article-title>. <source>Magnetic Resonance Imaging</source> <volume>64</volume>, <fpage>77</fpage>–<lpage>89</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.mri.2019.05.020</pub-id>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Kuklisova-Murgasova</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Quaghebeur</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Rutherford</surname>, <given-names>M.A.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.V.</given-names></string-name>, <string-name><surname>Schnabel</surname>, <given-names>J.A.</given-names></string-name>, <year>2012</year>. <article-title>Reconstruction of fetal brain mri with intensity matching and complete outlier removal</article-title>. <source>Med Image Analysis</source> <volume>16</volume>, <fpage>1550</fpage>–<lpage>1564</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.media.2012.07.004</pub-id>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Kyriakopoulou</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Vatansever</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Davidson</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Patkee</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Elkommos</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Chew</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Martinez-Biarge</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Hagberg</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Damodaram</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Allsop</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Fox</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.V.</given-names></string-name>, <string-name><surname>Rutherford</surname>, <given-names>M.A.</given-names></string-name>, <year>2017</year>. <article-title>Normative biometry of the fetal brain using magnetic resonance imaging</article-title>. <source>Brain Structure and Function</source> <volume>222</volume>, <fpage>2295</fpage>–<lpage>2307</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s00429-016-1342-6</pub-id>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Kyriakopoulou</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Vatansever</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Elkommos</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Dawson</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>McGuinness</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Allsop</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Molnér</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Rutherford</surname>, <given-names>M.</given-names></string-name>, <year>2014</year>. <article-title>Cortical overgrowth in fetuses with isolated ventriculomegaly</article-title>. <source>Cerebral Cortex</source> <volume>24</volume>, <fpage>2141</fpage>–<lpage>2150</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bht062</pub-id>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="other"><string-name><surname>Li</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Ouyang</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Price</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kyriakopoulou</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Grande</surname>, <given-names>L.C.</given-names></string-name>, <string-name><surname>Makropoulos</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Rueckert</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kainz</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Alansary</surname>, <given-names>A.</given-names></string-name>, <year>2022</year>. <article-title>Fetal cortex segmentation with topology and thickness loss constraints</article-title>, <source>in: MICCAI EPIMI, ML-CDS, TDA4BioMedicalImaging workshop 2022</source>, pp. <fpage>123</fpage>–<lpage>133</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-031-23223-7_11</pub-id>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="book"><string-name><surname>Li</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Sinclair</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Makropoulos</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.V.</given-names></string-name>, <string-name><surname>David Edwards</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kainz</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Rueckert</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Alansary Amir”</surname>, <given-names>e.C.H.</given-names></string-name>, <string-name><surname>Licandro</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Baumgartner</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Melbourne</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Dalca</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hutter</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Tanno</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Abaci Turk</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Van Leemput</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Torrents Barrena</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wells</surname>, <given-names>W.M.</given-names></string-name>, <string-name><surname>Macgowan</surname>, <given-names>C.</given-names></string-name>, <year>2021</year>. <chapter-title>Cas-net: Conditional atlas generation and brain segmentation for fetal mri</chapter-title>, <source>in: UNSURE and PIPPI MICCAI workshops</source>, <publisher-name>Springer Nature Switzerland</publisher-name>. pp. <fpage>221</fpage>–<lpage>230</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-030-87735-4_21</pub-id>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="other"><string-name><surname>Machado-Rivas</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Gandhi</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Choi</surname>, <given-names>J.J.</given-names></string-name>, <string-name><surname>Velasco-Annis</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Afacan</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Warfield</surname>, <given-names>S.K.</given-names></string-name>, <string-name><surname>Gholipour</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Jaimes</surname>, <given-names>C.</given-names></string-name>, <year>2021</year>. <article-title>Normal growth, sexual dimorphism, and lateral asymmetries at fetal brain mri</article-title>. <source>Radiology</source>, <fpage>211222</fpage> doi:<pub-id pub-id-type="doi">10.1148/radiol.211222</pub-id>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Makropoulos</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Robinson</surname>, <given-names>E.C.</given-names></string-name>, <string-name><surname>Schuh</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Wright</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Fitzgibbon</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Bozek</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Counsell</surname>, <given-names>S.J.</given-names></string-name>, <string-name><surname>Steinweg</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Vecchiato</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Passerat-Palmbach</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Lenz</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Mortari</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Tenev</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Duff</surname>, <given-names>E.P.</given-names></string-name>, <string-name><surname>Bastiani</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Cordero-Grande</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Hughes</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Tusor</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Tournier</surname>, <given-names>J.D.</given-names></string-name>, <string-name><surname>Hutter</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Price</surname>, <given-names>A.N.</given-names></string-name>, <string-name><surname>Teixeira</surname>, <given-names>R.A.P.G.</given-names></string-name>, <string-name><surname>Mur-gasova</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Victor</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Kelly</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Rutherford</surname>, <given-names>M.A.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S.M.</given-names></string-name>, <string-name><surname>Edwards</surname>, <given-names>A.D.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.V.</given-names></string-name>, <string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Rueckert</surname>, <given-names>D.</given-names></string-name>, <year>2018</year>. <article-title>The developing human connectome project: a minimal processing pipeline for neonatal cortical surface reconstruction</article-title>. <source>Neuroimage</source> <volume>173</volume>, <fpage>88</fpage>–<lpage>112</lpage>. doi:<pub-id pub-id-type="doi">10.1101/125526</pub-id>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="other"><string-name><surname>Oktay</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Schlemper</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Folgoc</surname>, <given-names>L.L.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Heinrich</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Mi-sawa</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Mori</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Mcdonagh</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hammerla</surname>, <given-names>N.Y.</given-names></string-name>, <string-name><surname>Kainz</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Glocker</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Rueckert</surname>, <given-names>D.</given-names></string-name>, <year>2018</year>. <source>Attention u-net: Learning where to look for the pancreas, in: MIDDL 2016</source>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Payette</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>de Dumast</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Kebiri</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Ezhov</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Paetzold</surname>, <given-names>J.C.</given-names></string-name>, <string-name><surname>Shit</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Iqbal</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Khan</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kottke</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Grehten</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Ji</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Lanczi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Nagy</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Beresova</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Nguyen</surname>, <given-names>T.D.</given-names></string-name>, <string-name><surname>Natalucci</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Karayannis</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Menze</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Cuadra</surname>, <given-names>M.B.</given-names></string-name>, <string-name><surname>Jakab</surname>, <given-names>A.</given-names></string-name>, <year>2021</year>. <article-title>An automatic multi-tissue human fetal brain segmentation benchmark using the fetal tissue annotation dataset</article-title>. <source>Scientific Data</source> <volume>8</volume>, <fpage>1</fpage>–<lpage>14</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41597-021-00946-3</pub-id>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="other"><string-name><surname>Payette</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Kottke</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Jakab</surname>, <given-names>A.</given-names></string-name>, <year>2020</year>. <article-title>Efficient multi-class fetal brain segmentation in high resolution mri reconstructions with noisy labels</article-title>, <source>in: MICCAI PIPPI workshop 2020</source>, pp. <fpage>295</fpage>–<lpage>304</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-030-60334-2_29</pub-id>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="other"><string-name><surname>Payette</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>de Dumast</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Licandro</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Ji</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Siddiquee</surname>, <given-names>M.M.R.</given-names></string-name>, <string-name><surname>Xu</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Myronenko</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Pei</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Peng</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Xie</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Dong</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Fu</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Rieu</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>H.G.</given-names></string-name>, <string-name><surname>Karimi</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Gholipour</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Torres</surname>, <given-names>H.R.</given-names></string-name>, <string-name><surname>Oliveira</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Vilaça</surname>, <given-names>J.L.</given-names></string-name>, <string-name><surname>Lin</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Avisdris</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Ben-Zvi</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Bashat</surname>, <given-names>D.B.</given-names></string-name>, <string-name><surname>Fidon</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Aertsen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Vercauteren</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Sobotka</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Langs</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Alenyà</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Villanueva</surname>, <given-names>M.I.</given-names></string-name>, <string-name><surname>Camara</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Fadida</surname>, <given-names>B.S.</given-names></string-name>, <string-name><surname>Joskowicz</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Weibin</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Yi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Xuesong</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Mazher</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Qayyum</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Puig</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kebiri</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Xu</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Liao</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Xu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Vasung</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Menze</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Cuadra</surname>, <given-names>M.B.</given-names></string-name>, <string-name><surname>Jakab</surname>, <given-names>A.</given-names></string-name>, <year>2022</year>. <source>Fetal brain tissue annotation and segmentation challenge results</source>. doi:<pub-id pub-id-type="doi">10.48550/arXiv.2204.09573</pub-id>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="other"><string-name><surname>Pei</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Zhong</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>G.</given-names></string-name>, <year>2021</year>. <article-title>Learning spatiotemporal probabilistic atlas of fetal brains with anatomically constrained registration network</article-title>, <source>in: MICCAI 2021</source>, pp. <fpage>239</fpage>–<lpage>248</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-030-87234-2_23</pub-id>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Prayer</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Malinger</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Brugger</surname>, <given-names>P.C.</given-names></string-name>, <string-name><surname>Cassady</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Catte</surname>, <given-names>L.D.</given-names></string-name>, <string-name><surname>Keersmaecker</surname>, <given-names>B.D.</given-names></string-name>, <string-name><surname>Fernandes</surname>, <given-names>G.L.</given-names></string-name>, <string-name><surname>Glanc</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Gonçalves</surname>, <given-names>L.F.</given-names></string-name>, <string-name><surname>Gruber</surname>, <given-names>G.M.</given-names></string-name>, <string-name><surname>Laifer-Narin</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Millischer</surname>, <given-names>A.E.</given-names></string-name>, <string-name><surname>Molho</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Neelavalli</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Platt</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Pugash</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Ramaekers</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Salomon</surname>, <given-names>L.J.</given-names></string-name>, <string-name><surname>Sanz</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Timor-Tritsch</surname>, <given-names>I.E.</given-names></string-name>, <string-name><surname>Tutschek</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Twickler</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Weber</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ximenes</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Raine-Fenning</surname>, <given-names>N.</given-names></string-name>, <year>2017</year>. <article-title>Isuog practice guidelines: performance of fetal magnetic resonance imaging</article-title>. <source>Ultrasound in Obstetrics and Gynecology</source> <volume>49</volume>, <fpage>671</fpage>–<lpage>680</lpage>. doi:<pub-id pub-id-type="doi">10.1002/uog.17412</pub-id>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="other"><string-name><surname>Price</surname>, <given-names>A.N.</given-names></string-name>, <string-name><surname>Cordero-grande</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Hughes</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Hiscocks</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Green</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Mccabe</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Ferrazzi</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Deprez</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Roberts</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Christiaens</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Duff</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Karolis</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Malik</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Rutherford</surname>, <given-names>M.A.</given-names></string-name>, <string-name><surname>Edwards</surname>, <given-names>D.A.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.V.</given-names></string-name>, <year>2019</year>. <source>The developing human connectome project (dhcp): fetal acquisition protocol, in: ISMRM 2019</source>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Rollins</surname>, <given-names>C.K.</given-names></string-name>, <string-name><surname>Ortinau</surname>, <given-names>C.M.</given-names></string-name>, <string-name><surname>Stopp</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Friedman</surname>, <given-names>K.G.</given-names></string-name>, <string-name><surname>Tworetzky</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Gagoski</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Velasco-Annis</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Afacan</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Vasung</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Beaute</surname>, <given-names>J.I.</given-names></string-name>, <string-name><surname>Rofeberg</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Estroff</surname>, <given-names>J.A.</given-names></string-name>, <string-name><surname>Grant</surname>, <given-names>P.E.</given-names></string-name>, <string-name><surname>Soul</surname>, <given-names>J.S.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Wypij</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Gholipour</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Warfield</surname>, <given-names>S.K.</given-names></string-name>, <string-name><surname>Newburger</surname>, <given-names>J.W.</given-names></string-name>, <year>2021</year>. <article-title>Regional brain growth trajectories in fetuses with congenital heart disease</article-title>. <source>Annals of Neurology</source> <volume>89</volume>, <fpage>143</fpage>–<lpage>157</lpage>. doi:<pub-id pub-id-type="doi">10.1002/ana.25940</pub-id>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="other"><string-name><surname>Ronneberger</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Fischer</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brox</surname>, <given-names>T.</given-names></string-name>, <year>2015</year>. <source>U-net: Convolutional networks for biomedical image segmentation, in: MICCAI 2015</source>, pp. <fpage>234</fpage>–<lpage>241</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Royston</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Wright</surname>, <given-names>E.</given-names></string-name>, <year>1998</year>. <article-title>How to construct ‘normal ranges’ for fetal variables</article-title>. <source>Ultrasound in Obstetrics Gynecology</source> <volume>11</volume>, <fpage>30</fpage>–<lpage>38</lpage>. doi:<pub-id pub-id-type="doi">10.1046/j.1469-0705.1998.11010030.x</pub-id>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Rueckert</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Sonoda</surname>, <given-names>L.I.</given-names></string-name>, <string-name><surname>Hayes</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Hill</surname>, <given-names>D.L.G.</given-names></string-name>, <string-name><surname>Leach</surname>, <given-names>M.O.</given-names></string-name>, <string-name><surname>Hawkes</surname>, <given-names>D.J.</given-names></string-name>, <year>1999</year>. <article-title>Nonrigid registration using free-form deformations: Application to breast mr images</article-title>. <source>IEEE TRANSACTIONS ON MEDICAL IMAGING</source> <volume>18</volume>, <fpage>712</fpage>–<lpage>721</lpage>. doi:<pub-id pub-id-type="doi">10.1109/42.796284</pub-id>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Rutherford</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Jiang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Allsop</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Perkins</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Srinivasan</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Hayat</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kumar</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.</given-names></string-name>, <year>2008</year>. <article-title>Mr imaging methods for assessing fetal brain development</article-title>. <source>Developmental Neurobiology</source> <volume>68</volume>, <fpage>700</fpage>–<lpage>711</lpage>. doi:<pub-id pub-id-type="doi">10.1002/dneu.20614</pub-id>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Story</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Davidson</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Patkee</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Fleiss</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Kyriakopoulou</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Colford</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Sankaran</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Seed</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Jones</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hutter</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Shennan</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Rutherford</surname>, <given-names>M.</given-names></string-name>, <year>2021</year>. <article-title>Brain volumetry in fetuses that deliver very preterm: An mri pilot study</article-title>. <source>NeuroImage: Clinical</source> <volume>30</volume>, <fpage>102650</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.nicl.2021.102650</pub-id>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="other"><string-name><surname>Uus</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kyriakopoulou</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Cordero Grande</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Christiaens</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Pietsch</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Price</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Patkee</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Karolis</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Schuh</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gartner</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Williams</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Hughes</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Arichi</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>O’Muircheartaigh</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Hutter</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Robinson</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Tournier</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Rueckert</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Counsell</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Rutherford</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Deprez</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Edwards</surname>, <given-names>A.</given-names></string-name>, <year>2023</year>. <article-title>Multi-channel spatio-temporal mri atlas of the normal fetal brain development from the developing human connectome project</article-title>. <source>G-Node</source> doi:<pub-id pub-id-type="doi">10.12751/g-node.ysgsy1</pub-id>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="other"><string-name><surname>Uus</surname>, <given-names>A.U.</given-names></string-name>, <string-name><surname>Collado</surname>, <given-names>A.E.</given-names></string-name>, <string-name><surname>Roberts</surname>, <given-names>T.A.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.V.</given-names></string-name>, <string-name><surname>Rutherford</surname>, <given-names>M.A.</given-names></string-name>, <string-name><surname>Deprez</surname>, <given-names>M.</given-names></string-name>, <year>2022</year>. <article-title>Retrospective motion correction in foetal mri for clinical applications: existing methods, applications and integration into clinical practice</article-title>. <source>The British Journal of Radiology</source> doi:<pub-id pub-id-type="doi">10.1259/bjr.20220071</pub-id>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="other"><string-name><surname>Vasung</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Rollins</surname>, <given-names>C.K.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Velasco-Annis</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Lin</surname>, <given-names>P.Y.</given-names></string-name>, <string-name><surname>Sutin</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Warfield</surname>, <given-names>S.K.</given-names></string-name>, <string-name><surname>Soul</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Estroff</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Connolly</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Barnewolt</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Gholipour</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Feldman</surname>, <given-names>H.A.</given-names></string-name>, <string-name><surname>Grant</surname>, <given-names>P.E.</given-names></string-name>, <year>2022</year>. <article-title>Abnormal development of transient fetal zones in mild isolated fetal ventriculomegaly</article-title>. <source>Cerebral Cortex, bhac125</source> doi:<pub-id pub-id-type="doi">10.1093/cercor/bhac125</pub-id>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="other"><string-name><surname>Wright</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Khanal</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Gomez</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Skelton</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Matthew</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Hajnal</surname>, <given-names>J.V.</given-names></string-name>, <string-name><surname>Rueckert</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Schnabel</surname>, <given-names>J.A.</given-names></string-name>, <year>2018</year>. <article-title>Lstm spatial cotransformer networks for registration of 3d fetal us and mr brain images</article-title>, <source>in: MICCAI 2018, Springer International Publishing</source>. pp. <fpage>107</fpage>–<lpage>116</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-030-00807-9</pub-id>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Yushkevich</surname>, <given-names>P.A.</given-names></string-name>, <string-name><surname>Piven</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Hazlett</surname>, <given-names>H.C.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>R.G.</given-names></string-name>, <string-name><surname>Ho</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Gee</surname>, <given-names>J.C.</given-names></string-name>, <string-name><surname>Gerig</surname>, <given-names>G.</given-names></string-name>, <year>2006</year>. <article-title>User-guided 3d active contour segmentation of anatomical structures: Significantly improved efficiency and reliability</article-title>. <source>NeuroImage</source> <volume>31</volume>, <fpage>1116</fpage>–<lpage>1128</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.015</pub-id>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="other"><string-name><surname>Özgün Ç</surname> <given-names>içek</given-names></string-name>, <string-name><surname>Abdulkadir</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Lienkamp</surname>, <given-names>S.S.</given-names></string-name>, <string-name><surname>Brox</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Ronneberger</surname>, <given-names>O.</given-names></string-name>, <year>2016</year>. <article-title>3d u-net: Learning dense volumetric segmentation from sparse annotation</article-title>, <source>in: MICCAI 2016</source>, pp. <fpage>424</fpage>–<lpage>432</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-319-46723-8_49</pub-id>.</mixed-citation></ref>
</ref-list>
<fn-group>
<fn id="fn2">
<label><sup>2</sup></label>
<p>SVRTK docker (auto-2.00): <ext-link ext-link-type="uri" xlink:href="https://hub.docker.com/r/fetalsvrtk/svrtk">https://hub.docker.com/r/fetalsvrtk/svrtk</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/SVRTK/SVRTK">https://github.com/SVRTK/SVRTK</ext-link></p></fn>
<fn id="fn3">
<label><sup>3</sup></label>
<p>ITK-SNAP tool: <ext-link ext-link-type="uri" xlink:href="http://www.itksnap.org/">http://www.itksnap.org/</ext-link></p></fn>
<fn id="fn4">
<label><sup>4</sup></label>
<p>MIRTK toolbox: <ext-link ext-link-type="uri" xlink:href="https://github.com/BioMedIA/MIRTK">https://github.com/BioMedIA/MIRTK</ext-link></p></fn>
<fn id="fn5">
<label><sup>5</sup></label><p>dHCP fetal brain MRI atlas repository: <ext-link ext-link-type="uri" xlink:href="https://gin.g-node.org/kcl_cdb/fetal_brain_mri_atlas">https://gin.g-node.org/kcl_cdb/fetal_brain_mri_atlas</ext-link></p></fn>
<fn id="fn6">
<label><sup>6</sup></label><p>BOUNTI automated segmentation docker: <ext-link ext-link-type="uri" xlink:href="https://hub.docker.com/r/fetalsvrtk/segmentation">https://hub.docker.com/r/fetalsvrtk/segmentation</ext-link> tag brain_bounti_tissue</p></fn>
<fn id="fn7">
<label><sup>7</sup></label><p>dCHP fetal brain MRI atlas repository: <ext-link ext-link-type="uri" xlink:href="https://gin.g-node.org/kcl_cdb/fetal_brain_mri_atlas">https://gin.g-node.org/kcl_cdb/fetal_brain_mri_atlas</ext-link></p></fn>
<fn id="fn8">
<label><sup>8</sup></label><p>BOUNTI automated segmentation docker: <ext-link ext-link-type="uri" xlink:href="https://hub.docker.com/r/fetalsvrtk/segmentation">https://hub.docker.com/r/fetalsvrtk/segmentation</ext-link> tag brain_bounti_tissue</p></fn>
</fn-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88818.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Dubois</surname>
<given-names>Jessica</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Inserm Unité NeuroDiderot, Université Paris Cité</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study proposes a deep learning-based segmentation pipeline of fetal brain MRI, with parcellation based on a newly implemented atlas. This represents an <bold>important</bold> contribution to the field of developmental neuroscience and pediatric neuroimaging, especially as the pipeline and atlas are publicly available. The evidence for the pipeline robustness and atlas relevance is <bold>convincing</bold> given the extensive validations provided and the very high-quality ground truth dataset. Although beyond the state of the art, the study would benefit from further comparisons with existing methods and additional evaluations of the framework generalizability according to image quality, subject age or brain abnormalities.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88818.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Main contributions / strengths</p>
<p>The authors propose a process to improve the ground truth segmentation of fetal brain MRI via a semi-supervised approach based on several iterations of manual refinement of atlas label propagations. This procedure represents an impressive amount of work, likely resulting in a very high-quality ground truth dataset. The corrected labels (obtained from multiple different datasets) are then used to train the final model which performs the brain extraction and tissue segmentation tasks. We also acknowledge the caution paid by the authors regarding the future application of their pipeline to unseen datasets.</p>
<p>The conclusions of this paper are mostly well supported by data, but some aspects of the analysis and validation procedure need to be clarified and extended. In addition, the article would greatly benefit from providing further descriptions of crucial aspects of the study.</p>
<p>Main limitations and potential improvements</p>
<p>1. New nomenclature/atlas not sufficiently described/justified.</p>
<p>The proposed nomenclature and atlas are one of the main contributions of this work. We clearly acknowledge the importance for the community of such a contribution. The definition of any nomenclature implies that decisions were taken regarding the acceptable level of ambiguity in the identification of the boundary between neighboring anatomical structures with respect to the gradient in the intensities in the MRI. It is acceptable (and probably inevitable) to set relatively arbitrary criteria in ambiguous regions, providing that these criteria are explicitly stated. The explicit statement of the decisions taken is essential in particular for better interpretation of residual segmentation inaccuracies in application studies.</p>
<p>As a matter of comparison, the postnatal atlas and nomenclature were based on the Albert protocol, which is described in extensive detail. While such a complete description might fall beyond the scope of this work, we believe that an additional description of the nomenclature and protocol, allowing reproduction the manual segmentation on external datasets is required, at least for most ambiguous junctions between structures. For instance, the boundaries across substructures within the DGM are difficult to visualize on the exemplar subjects shown in Fig. 5 and Fig. 6.</p>
<p>Please provide additional precision on how the following were defined: boundaries between lateral ventricles and cavum; between cavum and CSF; the delineation of 3rd and 4th ventricles; the definition of the vermis, especially its junctions with the cerebellum and the brainstem.</p>
<p>
How are these boundaries impacted by the changes in the image intensities related to tissue maturation?</p>
<p>We would also greatly appreciate an extension of the qualitative comparison with the two most commonly used protocols (Albert and FETA), for instance, why didn't the authors isolate the hippocampus/amygdala structure? And then how is the boundary between gray and white matter defined in this region?</p>
<p>1. More detailed comparison with FETA for some structures would be informative despite obvious limitations.</p>
<p>More specifically, the GM should have a very similar definition. In the &quot;Impact of anomalies' section (page 7) the authors compare their results with the dice score from the FETA challenge and conclude that the difference &quot;highlights the advantages of using high-quality consistent ground truth labels for training&quot;. The better performances (from ~0.78 to ~0.88) might be mostly due to the improvement of the ground truth (of the test set). This could be confirmed by observing the ground truth from FETA of the GM for a few cases for which the dice shows a strong increase in performance with respect to FETA. Note that the gain in performance is appreciable even if it is due to a better ground truth.</p>
<p>1. Improvement of the ground truth labels is an important contribution of this work, thus we would appreciate a more quantitative description of the impact of the manual correction, such as reporting the change in the dice score induced by the correction.</p>
<p>Quantification of the refinement process would help to better evaluate the relevance of the proposed approach in future studies e.g. introducing a different nomenclature. More specifically, a marked change would be expected after the first training when there is a switch (and refinement) from the registration-propagated labels to the ones predicted by the DL model (as shown in Fig. 5, the changes are quite strong). Again a dice score indicating quantitatively how much improvement results from each iteration would be informative. In the same line, is the last iteration of this process needed or did the authors observe a 'stabilization' (i.e. less manual editing needing to be performed)?</p>
<p>1. The testing / training data-splitting strategy is not sufficiently detailed and difficult to follow. The following points deserve clarification:</p>
<p>a) Why did the authors select only four sites for the test set (out of six studies presented in the 3.1 section)?</p>
<p>b) Data used for training: in the first step the authors selected 200 for label propagation and selected only the best 100. In the second stage, the predictions are computed for all training/validation sets (380) and only 200 are selected. When the process was iterated, why did the authors select only 200 out of the 380? Are the same subjects selected across iterations?</p>
<p>
Were the acquisition parameters / gestational age controlled for each selection? If yes please specify the distributions precisely.</p>
<p>Did the authors control the potential imbalanced proportion that is present in the dataset (more subjects from dHCP for instance)? (line 316, 100 subjects were selected from only three centers. Why only three? Did the authors keep the same sub-site for other stages?)</p>
<p>c) &quot;The testing dataset includes 40 randomly selected images from four different acquisition protocols&quot; which shows that attention was paid to variations in the scanning parameters, which is of crucial importance. However, no precision is provided regarding the gestational age of this dataset, which impedes the interpretation since a potential influence of age on the accuracy of the segmentation would be problematic. Indeed, the authors mention that the manual correction deserved special attention for late GA (&gt;34 weeks). Please specify precisely the age distribution across the 10 subjects of each of the four acquisition protocols. In addition, the qualitative results shown in Fig.6 and subsection &quot;Impact of GA at scan&quot; are not sufficient and an additional result table reporting the same population and metrics as in Table 2, but dissociating younger versus older fetuses, would be much more informative to rule out potential bias related to gestational age.</p>
<p>d) The definition of the ground truth labels for the test set is not described.</p>
<p>We understand (from the result) that the ground truth for the test set is defined by manual refinement of the atlas label propagated. This should be explicitly described on page 5 after the &quot;Preparation of training datasets&quot; section.</p>
<p>1. The validation of segmentation accuracy based on the volumetry growth chart is invalid.</p>
<p>In Section &quot;4.3. Growth charts of normal fetal brain development&quot;, since manual corrections were involved, the reported results cannot be considered as a validation of the segmentation pipeline. Regarding the validation of the segmentation pipeline, the quantitative and qualitative results provided in Table 2 and the corresponding text and figures seem sufficient to us (providing our concerns above are addressed, especially regarding the impact of the gestational age).</p>
<p>The growth charts are still valuable to support the validity of the nomenclature and segmentation protocol, but then why are the growth charts computed only for some structures? Reporting the growth chart and statistical evaluation of the impact of acquisition settings using ANCOVA for all the substructures from the proposed protocol would be expected here, in particular for the structures for which the delineation might be ambiguous such as the cavum, the vermis, and DGM substructures such as the thalamus.</p>
<p>Finally, please provide further details on the type and amount of manual correction needed for computing the growth charts.</p>
<p>1. MRI data was acquired only on Phillips scanners.</p>
<p>We acknowledge the efforts to maximize heterogeneity in the MRIs,e.g. with both 1.5T and 3T scanners, variations in TE and image resolution, but still, all MRIs included in this study were acquired using the SSTSE sequence on Phillips scanners. The study does not include any MRI acquired on Siemens nor GE scanners, and no image was acquired using the balance-FFE/TRUFISP/FIESTA type sequence. This might limit generalizability.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88818.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This work presents a new, automated, deep learning-based segmentation pipeline for fetal cerebral MRI based on the anatomical definitions of the new fetal atlas of the Developing Human Connectome Project. The authors' new software pipeline demonstrated robust performance across different acquisition protocols and gestational age ranges, reducing the need for manual refinement. To provide ground truth data for training their deep learning network, the authors employed a semi-supervised approach, in which atlas labels were propagated to the datasets, and they were corrected manually.</p>
<p>This work stands out for its extensive training on a large number of datasets, it achieves precise anatomical definition through a refined brain tissue parcellation protocol, and it evaluates the segmentation results against growth curves, allowing for a comprehensive assessment of fetal brain development. Due to the fact that abnormal anatomy was largely unobserved by the segmentation network, it is highly likely, however, that the BOUNTI pipeline would lead to some incorrect segmentations in subjects with moderate to large ventriculomegaly, as well as in cases of malformations of the corpus callosum, brainstem or neural tube defects. Further work is required for BOUNTI to generalize its application to pathological brains, as the vast majority of fetal cerebral MRI cases in clinical practice involve such abnormalities rather than normal brain development. This step is crucial for facilitating the clinical translation of BOUNTI. The algorithm is publicly available and works without limitations on datasets acquired in other centers.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88818.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This work provides a novel framework for semi-automatic segmentation and parcellation of brain tissues from fetal magnetic resonance imaging (MRI) by fusing an advanced deep learning technique and manual correction by experts. Over the broad age spectrum spanning newborns to adults, several fully-automatic segmentation/parcellation techniques have been proposed, showing robust, reliable performance across MR images with varying imaging quality. Unlike other age groups, however, scanning of the fetal brain is conducted in the womb; thus, there are additional and unique challenges, such as ambiguous positioning of the fetal brain, the surrounding maternal tissue in the fetal MRI, and fetal and maternal motion. These challenges in fetal MRI have collectively served as important bottlenecks in developing robust, reliable automatic segmentation/parcellation frameworks to date. This paper proposes a methodological framework for the segmentation and parcellation of fetal MRI scans using a two-step deep learning model, each for segmentation and parcellation. It is also noteworthy that the validity of the proposed framework has been extensively tested over different datasets with different image quality and different recording parameters, so the robust generalizability of the framework over other fetal MRI datasets is clearly suggested.</p>
<p>Strengths:</p>
<p>In general, a novel design framework, with separation of segmentation and parcellation schemes under each deep learning model, provides ample room for improving the model performance, as suggested by the results of this study. In addition, thanks to the flexibility in the model design (e.g., the choice of deep learning model) and parameters (e.g., manual correction step during training), an identical or similar framework can be easily extended to other datasets for different age groups or diagnostic groups/brain disorders. Another strength is the minimal requirement of human interaction after the training stage as significant time and effort of manual correction is often required following the automatic segmentation of fetal MR images. Lastly, thorough investigation of the inter-dataset generalizability of the proposed segmentation/parcellation framework will be well-received by the fetal neuroscience community.</p>
<p>Weakness:</p>
<p>The main weakness of this paper is the vague definition of the scientific novelty. By design, this paper is a technical study. The technical advancement claimed by the authors is a novel design of deep learning and a two-step deep-learning framework; each for segmentation and parcellation. There have been, however, other deep learning studies, and some share nearly identical model architecture to the one published by Asis-Cruz et al. (Frontiers in Neuroscience, 2022). As such the conceptual improvement in terms of deep learning model architecture is overstated. Regarding the separate framework for segmentation and parcellation, the conventional preprocessing protocol (e.g., Draw-EM; Makropoulos et al. IEEE Transactions on Medical Imaging, 2014) already presented a similar concept. Overall, it is unclear what unique technical advances have been made in the current paper.</p>
<p>A second weakness of the work is the insufficient comparison to other conventional published methods. While the authors' claim that there is no &quot;universally accepted&quot; protocol for fetal brain segmentation/parcellation is at least partially true, Draw-EM, which was originally designed for neonatal brain segmentation, has been widely and successfully utilized in many fetal MRI studies, as discussed by the authors. Instead of a direct comparison to Draw-EM, the authors only performed a descriptive comparison using two exemplar MRI scans. It is unclear whether the superior performance of the proposed framework in these selected scans would be generalizable to others. Similarly, the authors claim that the proposed deep-learning-based segmentation/parcellation framework required minimal time for manual post-preprocessing refinement (1-3 mins), compared to 1-3 hours in another study using Draw-EM (Story et al. Neuroimage: Clinical, 2021). Again, this may not represent a fair comparison considering that the intensity/precision of manual refinement may differ depending on the different goals/objectives of other studies.</p>
</body>
</sub-article>
</article>