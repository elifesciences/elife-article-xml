<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">93251</article-id>
<article-id pub-id-type="doi">10.7554/eLife.93251</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.93251.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>An Information-Theoretic Approach to Reward Rate Optimization in the Tradeoff Between Controlled and Automatic Processing in Neural Network Architectures</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1847-5031</contrib-id>
<name>
<surname>Petri</surname>
<given-names>Giovanni</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8896-639X</contrib-id>
<name>
<surname>Musslick</surname>
<given-names>Sebastian</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cohen</surname>
<given-names>Jonathan D.</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<aff id="a1"><label>1</label><institution>NPLab, Network Science Institute, Northeastern University London</institution>, London, <country>UK</country></aff>
<aff id="a2"><label>2</label><institution>CENTAI Institute</institution>, Turin, <country>Italy</country></aff>
<aff id="a3"><label>3</label><institution>Department of Cognitive, Linguistic, and Psychological Sciences, Brown University</institution>, Providence, <country>US</country></aff>
<aff id="a4"><label>4</label><institution>Institute of Cognitive Science, Osnabrück University</institution>, Osnabrück, <country>Germany</country></aff>
<aff id="a5"><label>5</label><institution>Princeton Neuroscience Institute, Princeton University</institution>, Princeton, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence to: <email>giovanni.petri@nulondon.ac.uk</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-02-26">
<day>26</day>
<month>02</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP93251</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-12-12">
<day>12</day>
<month>12</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-09-18">
<day>18</day>
<month>09</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.09.18.558214"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Petri et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Petri et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-93251-v1.pdf"/>
<abstract>
<p>This article introduces a quantitative approach to modeling the cost of control in a neural network architecture when it is required to execute one or more simultaneous tasks, and its relationship to automaticity. We begin by formalizing two forms of cost associated with a given level of performance: an <italic>intensity cost</italic> that quantifies how much information must be added to the input to achieve the desired response for a given task, that we treat as the contribution of <italic>control</italic> ; and an <italic>interaction cost</italic> that quantifies the degree to which performance is degraded as a result of interference between processes responsible for performing two or more tasks, that we treat as inversely related to <italic>automaticity</italic>. We develop a formal expression of the relationship between these two costs, and use this to derive the optimal control policy for a desired level of performance. We use that, in turn, to quantify the tradeoff between control and automaticity, and suggest how this can be used as a normative framework for understanding how people adjudicate between the benefits of control and automaticity.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<label>I.</label>
<title>Introduction</title>
<sec id="s1a">
<title>Control-dependent processing versus automaticity</title>
<p>One of the most striking features of human cognition is the ability to adapt behavior over both short and long terms. The former confers remarkable flexibility in responding to novel environments, while the latter can lead to considerable improvements in the efficacy of processing in stable environments. Rapid adjustments of behavior to novel circumstances rely on the capacity for cognitive control, and are a fundamental component of characteristically human capabilities, such as problem-solving, planning, and language [<xref ref-type="bibr" rid="c1">1</xref>]. While this ability allows remarkable flexibility, it is generally associated with limitations in processing. The most salient of these are: a strict constraint on the number of control-dependent tasks that can be performed simultaneously (e.g., the ability to talk with a passenger when first learning to drive a car, or to sing while learning to play a musical instrument [2– 4]); and processing costs associated with switching from one task to another (e.g., when switching from parsing an equation to talking to a friend [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>]). In many cases these limitations can be overcome with sufficient learning, and tasks can come to be performed more effectively and, in some cases, even simultaneously with others [<xref ref-type="bibr" rid="c7">7</xref>–<xref ref-type="bibr" rid="c9">9</xref>]. However, this requires an investment of practice, and the resulting improvements in processing efficacy are largely tailored to that particular task (e.g., learning to play one instrument does not transfer fully to others [<xref ref-type="bibr" rid="c10">10</xref>]). This long-term adaptation is often referred to as the acquisition of automaticity for a task [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c11">11</xref>].</p>
<p>The distinction between control-dependent and automatic processing is one of the cornerstones of cognitive psychology, and ample progress has been made in understanding the mechanisms that underlie this distinction [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c12">12</xref>]. Considerable effort has been made to characterize computational mechanisms that can explain behavioral observations, and in some cases how these may be implemented in the brain. Recently, formal analyses have been proposed of some of the factors relevant to the allocation of control [<xref ref-type="bibr" rid="c13">13</xref>–<xref ref-type="bibr" rid="c19">19</xref>], and to the acquisition of automaticity [<xref ref-type="bibr" rid="c20">20</xref>]. Most recently, these analyses have begun to address the tradeoff between control and automaticity in neural network architectures—a tradeoff that is fundamental to understanding the adaptive nature of human behavior, and may be instructive in designing artificial systems with capabilities similar to those of humans [<xref ref-type="bibr" rid="c21">21</xref>]. Here, we build on this work, to develop a formally rigorous, normative framework for quantifying the costs associated with control-dependent processing versus automaticity, and the tradeoff between these.</p>
</sec>
<sec id="s1b">
<title>An information-theoretic approach</title>
<p>Following previous efforts [<xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>], we cast automaticity and control in information-theoretic terms: as the probability, given one or more stimuli (information), of encoding these and generating a task-appropriate response to each (i.e., executing the relevant actions, whether internal, such as encoding in longer term memory, or external, such as overtly motor responses). We use this approach, in relation to neural network processing architectures, to evaluate the processing efficacy of a network in executing a set of tasks, by encoding a set of stimuli as a pattern of activity over sets of input units corresponding to the stimulus dimensions relevant to those tasks, and propagating those inputs over one or more layers of intermediate (“hidden”) processing units, to generate a pattern of activity over a set of output units that determine the probability of response for each task. Implemented in neural networks, this approach has been used widely to account for human performance and underlying neural mechanisms in a wide range of cognitive paradigms [<xref ref-type="bibr" rid="c21">21</xref>–<xref ref-type="bibr" rid="c24">24</xref>] and, in machine learning, to build systems that approximate or exceed human performance in many of those tasks and others [<xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c26">26</xref>].</p>
</sec>
<sec id="s1c">
<title>A fundamental tradeoff between control-dependent and automatic processing</title>
<p>Neural network formalisms have also been used within cognitive psychology and neuroscience to address the mechanisms responsible for control-dependent processing and automaticity, and the fundamental computational tradeoff between these [<xref ref-type="bibr" rid="c12">12</xref>]. However, these efforts have largely focused on relatively simple networks that are tractable to exhaustive numerical analysis (an example of which we provide in the following sections). In this article, we build on these efforts, and bring them into contact with information-theoretic approaches, to address the tradeoffs between control and automaticity both from a normative perspective and in more complex, multitask networks. In this section, we outline the key assumptions of the approach, drawn from the neural network literature.</p>
<p>First, we assume that the allocation of control is implemented as a set of biases that are used to regulate the activity of units required for executing a given task, both to insure that there is sufficient activity to overcome a response threshold for that task (increasing its probability of execution), and to compete effectively with other tasks that share processing units with the task by preventing them from activating conflicting representations in those units (thereby increasing the probability of <italic>accurate</italic> execution [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>]). Adjustments of these biases in the service of control are assumed to operate over short-time scales, thus enabling the flexible switching from one task to another [12, 29–3 Furthermore, to the extent that control confers the ability to use shared, general-purpose representations for different tasks, it affords the flexibility to perform novel tasks—a hallmark of the capacity for cognitive control [<xref ref-type="bibr" rid="c21">21</xref>]. However, this comes at a cost: the need to serialize processing in order to avoid the potential for conflict posed by the use of shared representations for different purposes at the <italic>same time</italic> [<xref ref-type="bibr" rid="c28">28</xref>]. This seriality constraint, that comes with the flexibility of processing, is also a hallmark of cognitive control. Together, they reflect a fundamental tradeoff in network architectures posed by the use of shared representations and the attendant requirement for control: they facilitate learning and generalization, but compromise the efficiency of processing afforded parallel execution [<xref ref-type="bibr" rid="c12">12</xref>]. Recent work has begun to formalize this tradeoff [<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c32">32</xref>], the broader implications of which we will consider in the Discussion. Here, we build on this idea, by formalizing the costs associated with the use of control, and addressing the implications it has for the choice between reliance on control-dependent processing versus the development of automaticity.</p>
<p>In contrast to control-dependent processing, we assume that automaticity is associated with the ajustment of connection weights that occurs over a longer time scale through training [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c33">33</xref>]. This can strengthen an existing processing pathway responsible for executing a task, allowing it to more readily overcome a response threshold, compete more effectively with other tasks with which it shares representations, or induce a new pathway using separate processing units that are dedicated to that task and that isolate it from others, thus diminishing the like-lihood of conflict with or interference from them and the attendant dependence on control [<xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c21">21</xref>]. This can also be exploited to augment processing efficiency, through parallel task execution. However, the development of automaticity requires training, involving gradual, incremental adjustment of weights to insure a stable statistical encoding of the relevant associations [<xref ref-type="bibr" rid="c34">34</xref>, <xref ref-type="bibr" rid="c35">35</xref>]. Thus, in addition to conferring the potential for greater efficiency of processing, automaticity also confers a form of flexibility, but over a longer time frame and with a different set of attendant costs than does control.</p>
</sec>
<sec id="s1d">
<title>Benefits and costs</title>
<p>As outlined above, both control-dependent processing and automaticity have their benefits and costs. In previous work, this tradeoff has been explored in the context of specific tasks, with respect to both the speed and accuracy of processing [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c37">37</xref>]. However, while these efforts have been useful in specifying computationally explicit mechanisms underlying automaticity and control, they have focused on networks configured to perform a small number of tasks (usually just 2 or 3), and for the most part, have not addressed the question of whether or how the system optimizes the balance between automaticity and dependence on control— that is, they have not provided a normative account of this tradeoff. In this article, we develop an information theoretic approach to addressing these challenges. We do so by casting benefits in terms of the amount of reward accrued—proportional to the accuracy of processing— per unit time; that is, <italic>expected reward rate</italic>. Accordingly, costs can arise in either of two ways: degradation in processing accuracy, or prolongation of execution. Theoretical work in cognitive science [<xref ref-type="bibr" rid="c38">38</xref>] and neural network modeling [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c40">40</xref>] suggests that these may be different expressions of a single underlying factor—strength of processing—interacting with strategic choices regarding control (e.g., by regulating speed-accuracy tradeoffs and/or the allocation of attention). These align with the formulations of control and automaticity described above: with strength of processing determined by the connection weights in the processing pathway required to execute a specified task, and control determined by the biases allocated to the processing units responsible for task execution. Previous work within this framework, both theoretical and empirical, has shown how control parameters can be optimized to maximize reward rate. For example, for a given set of connection weights in a simple one-layered network, the speed-accuracy tradeoff is determined by the threshold of activity on the output layer (that is used to determine an overt response); there is a unique such threshold that optimizes reward rate; and, in many instances, this has been shown to accurately describe human performance in correspondingly simple decision making tasks [37, 41–4 Here, we assume that control can be used to achieve such threshold optimization by applying the appropriate bias to the units responsible for implementing the decision process (e.g., [<xref ref-type="bibr" rid="c45">45</xref>]), thus ensuring the optimal balance of speed and accuracy for a given strength of processing. Similarly, in settings requiring switching between tasks, the amount of control allocated to each can be optimized to balance the tradeoff between performance of each and the costs associated with switching between them, in order to maximize overall reward rate [<xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c46">46</xref>, <xref ref-type="bibr" rid="c47">47</xref>]. Thus, the benefits and costs of processing can be optimized with respect to reward rate.</p>
<p>The optimization of reward rate can be considered with respect to benefits and costs that accrue over a range of timescales of task performance, from the level of individual instances of performance (e.g., a “trial” of an experimental task) and/or the transition between these, to extended sequences of trials, and even longer timescales associated with training and practice. Neural network (and closely related dynamical systems) analyses of the optimization of the speed-accuracy tradeoff and/or task switching at the single trial (and trial-to-trial) timescale have provided valuable insights into the basic mechanisms underlying cognitive control, and how it may be implemented in neural architectures [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c30">30</xref>, <xref ref-type="bibr" rid="c46">46</xref>, <xref ref-type="bibr" rid="c48">48</xref>]. While the timescale of the effects for an individual trial (and transitions between them) is generally small (on the order of hundreds of milliseconds), optimization can have a substantial impact on reward rate; for example, when the stakes for performance are very high, or over repeated performance of the same task(s). Nevertheless, the timescale of these effects contrasts with two other forms of temporal costs that can be an order of magnitude larger, and that are the focus of this article. These concern the serialization of the performance of multiple tasks forced by the reliance on shared representations (and enforced by control), and the training time required to acquire separated, task-dedicated representations that support parallel processing (i.e., to acquire automaticity). We briefly consider each of these below.</p>
</sec>
<sec id="s1e">
<title>Serialization costs</title>
<p>The use of shared representations confers a benefit on performance by allowing new tasks to be acquired quickly. However, as suggested above, if more than one of the tasks that share those representations is to be performed, this carries a temporal cost imposed by the additional time required to serialize execution (through the allocation of control), as compared to their simultaneous parallel execution when they rely on separate, task-dedicated representations. We refer to this as the <italic>serialization cost</italic>, and assume this is proportional to the total number of tasks to be executed [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c50">50</xref>]. We should note that the serialization cost of control-dependent processing is closely associated with a corollary temporal cost of switching from one task to another, commonly referred to as the <italic>switch cost</italic> [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c51">51</xref>], that is, in addition to the time spent on performing each task individually. However, as noted above, switch costs are generally an order of magnitude smaller than the serialization cost itself, and thus, for simplicity, they are not included in the analyses presented in this article. In the Discussion (Section V), we consider how the framework might be extended to include these in the future.</p>
</sec>
<sec id="s1f">
<title>Learning costs</title>
<p>As opposed to control-dependent processing, the benefits of automaticity are not only more rapid performance of each individual task but, critically, the potential for parallel execution of multiple tasks [<xref ref-type="bibr" rid="c7">7</xref>]. The efficiency that comes from multitasking obviates the serialization cost attached to control-dependent processing. This stems from reliance on more specialized, or fully task-dedicated representations, which makes them less likely to conflict with others, and therefore more amenable to execution in parallel [8, 21, 52–54]. However, these benefits also carry a temporal cost, in this case, the (often considerable) amount of time required to achieve automaticity through practice [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c55">55</xref>]. We refer to this as the <italic>learning cost</italic>. Thus, while control-dependent processing is associated with seriality (and switch costs), automaticity is associated with a learning cost.</p>
</sec>
<sec id="s1g">
<title>An intertemporal choice</title>
<p>The different types of cost associated with control-dependent processing and automaticity pose a fundamental intertemporal choice–and corresponding optimization problem–with regard to reward rate maximization: Under what circumstances should the more immediate benefits of control-dependent processing (as a consequence of rapid task acquisition) be favored, at the expense of less efficient serial processing, as compared to the benefits of automaticity (more efficient, parallel processing) that come at the expense of greater time required for acquisition [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c50">50</xref>]. This tradeoff is familiar to anyone who has considered the relative advantages of hunt-and-peck typing versus learning to touch type, and similarly for using the keyboard of a musical instrument. It is also likely to be relevant to the ability of autonomous artificial agents to adapt and optimize their behavior in changing environments (to which we return in the Discussion).</p>
<p>To formalize and analyze this problem, in this article we quantify the costs of control-dependent versus automatic processing at two levels of description, the <italic>neural network</italic> level and the <italic>task graph</italic> level, that are closely related to one another. We include the former, as neural networks have been useful in providing well-specified process models of control and automaticity [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c29">29</xref>]. Such models implement tasks at the scale of processing units used to represent individual stimuli, responses, and often internal (“hidden”) units used to associate stimuli to responses.[<xref ref-type="bibr" rid="c122">122</xref>] Stimulus and response units are often divided into subsets of units (e.g., corresponding to different stimulus and response dimensions, such as colors versus shapes and verbal versus manual responses), with tasks implemented as pathways that map a set of stimulus representations to a set of response representations, possibly by way of one or more layers of hidden representations (<xref rid="fig1" ref-type="fig">Figure 1</xref>, left panel). Such models have been used to explain detailed patterns of performance in a wide range of tasks that address both the effects of different stimulus conditions and the dynamics of processing. However, such models are often intractable to closed-form analysis, and become even more of a challenge when used to address how interactions among multiple tasks affect performance. Accordingly, we address interactions among tasks at the level of a task graph. This builds on a simplification of the neural network implementation of an individual task, which summarizes its relevant properties (under assumptions we describe below), and allows us to formally analyze the interaction among multiple tasks. In a task graph, each node corresponds to one of the sets of processing units in a neural network model that represent a particular type of information (e.g., a stimulus dimension such as colors or shapes, or a particular type of response such as verbal or manual (<xref rid="fig1" ref-type="fig">Figure 1</xref>, right panel), and each edge corresponds to the weights of the connections from the set of processing units represented by one node to the processing units represented by another. Thus, the edge connecting an input node (representing a particular stimulus dimension) to an output node (representing a type of response) corresponds to the pathway in a neural network model that maps the set of stimulus units to the set of response units used to perform a given task. Following prior information-theoretic formalisms [<xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c18">18</xref>], we use the task graph to define the costs of automaticity and control with respect to the formation and use of such mappings.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Correspondence of neural network and task graph representations of two tasks.</title>
<p><italic>Neural network level:</italic> shows the processing units in a neural network that implement two tasks, each of which maps the two stimulus units in each of two separate stimulus sets to the two response units of a shared response set. <italic>Graph:</italic> shows the corresponding task graph, in which each node corresponds to the processing units in a given set (outlined in blue) in the neural network, and each edge (red and green arrows) represents the set of connections (shown in gray) between the sets of processing units represented by the corresponding nodes. Note that in this task graph, we illustrate only the mapping from internal (“hidden”) representations corresponding to two sources of stimulus information to the set of response representations that are shared by them. For a more complete treatment that includes the relationship of external stimuli to their internal representations, see [<xref ref-type="bibr" rid="c57">57</xref>].</p></caption>
<graphic xlink:href="558214v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Beginning with single tasks (along the lines of [<xref ref-type="bibr" rid="c13">13</xref>]), we extend the formalism to address an arbitrary number of tasks and consider how performance can be optimized when confronted with the requirement to perform two or more of them. We investigate whether the benefits are greatest from the use of shared representations and control (at the expense of serialization) versus separated representations and automatic parallel processing (at the expense of additional training). We do so by defining a metric that specifies the expected level of interference between processes for a given network configuration, and use that to derive a corresponding metric for the amount of control (in terms of biasing parameters) required to mitigate this interference for a desired level of expected processing efficacy. We then discuss how this metric can be integrated with a corresponding metric for the learning cost of automaticity, that specifies the extent to which a network architecture must be adjusted through weight modifications (i.e., the formation of separated, task-dedicated representations) to mitigate multitasking interference and support parallelization of performance. In each case, we quantify the benefits and costs in terms of the common currency of time, thus permitting a normative analysis of the tradeoff between reliance on control-dependent processing versus the acquisition of automaticity.</p>
</sec>
</sec>
<sec id="s2">
<label>II.</label>
<title>An information-theoretic formulation of automaticity and control</title>
<sec id="s2a">
<label>A.</label>
<title>Single Task Processing: Reflexes, Automaticity, and Control</title>
<p>To consider control-dependent processing within an information theoretic framework, Koechlin and Summer-field [<xref ref-type="bibr" rid="c13">13</xref>] proposed an expression for probability of performing a single task given a relevant stimulus. More precisely, to select a given action <italic>a</italic> with relative frequency <italic>p</italic>(<italic>a</italic>), they used standard Shannon entropy as a measure of the information required to select the action <italic>a</italic> irrespective of the stimulus, i.e.
<disp-formula id="eqn1">
<graphic xlink:href="558214v1_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We refer to this as the <italic>information cost</italic> of action a. However, this formulation does not explicitly take into account the distribution of stimuli in an environment (i.e. the relative frequency of encountering a given stimulus or set of stimuli), which can be done by considering the mutual information ℐ (<italic>s, a</italic>) between a stimulus s and the associated action a, written as:
<disp-formula id="eqn2">
<graphic xlink:href="558214v1_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This, in turn, leads to the natural expression for the amount of information needed to select action <italic>a</italic> given the stimulus <italic>s</italic>:
<disp-formula id="eqn3">
<graphic xlink:href="558214v1_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Here 𝒬 measures the extra information contained in observing the action a given that stimulus s was present (ℐ; (<italic>s, a</italic>)), compared with the case in which no information about the stimulus is available (ℋ (<italic>a</italic>)). Note that the functional forms of 𝒬 (<italic>a</italic> |<italic>s</italic>) and ℋ (<italic>a</italic>) are the same, but they are given different probability distributions (<italic>p</italic>(<italic>a</italic> | <italic>s</italic>) and <italic>p</italic>(<italic>a</italic>), respectively; see [<xref ref-type="bibr" rid="c18">18</xref>] for a related formulation).</p>
<sec id="s2a1">
<title>Reflexes</title>
<p>Given the formulation above, 𝒬 (<italic>a</italic> | <italic>s</italic>) effectively captures the degree to which an action is selected irrespective of current task goal (i.e., context): if action a is <italic>always</italic> executed when a stimulus s is present (i.e. <italic>p</italic>(a | <italic>s</italic>) = 1), then 𝒬 (<italic>a</italic> | <italic>s</italic>) = 0. We define such actions as <italic>reflexes</italic>, insofar as they occur independently of task context or the allocation of control, and treat them as an extreme form of automaticity. It is important to note, here, that whereas the term “actions” connotes overt motor responses, the formulation applies equally well to covert, internal actions, such as the encoding of a stimulus into memory or the elicitation of emotional response, that do not have immediate observable consequences.</p>
</sec>
<sec id="s2a2">
<title>Automaticity</title>
<p>While reflexes that elicit overt actions can be thought of as a limiting case of automaticity, the latter more commonly refers to processes that, although they do not elicit an overt action, and have not been allocated control, nevertheless, elicit internal responses that are strong enough to interfere with competing processes to which control <italic>has</italic> been allocated. Word reading is widely regarded as a canonical example of this [<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c58">58</xref>]. This is evidenced by the classic Stroop effect [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c60">60</xref>], in which the response for naming the color in which a word is printed is slowed for incongruent stimuli (e.g., the stimulus GREEN)— that is, when the word itself is different than the color, and thus conveys competing information. This is taken as evidence of the automaticity of word reading, insofar as the effect occurs despite the instructions and intent to ignore the orthographic features of the stimulus. That is, processing of the word appears to occur (at least to some extent) independently of control, and thereby interfere with the processes required for color naming, to which control <italic>has</italic> been allocated, even when no overt response is made to the word. According to the formulation above, the internal processes of encoding the orthographic features of the stimulus, and associating these with phonological representations used to generate verbal responses, might be thought of as reflexive. Nevertheless, these processes are not <italic>so strong</italic> as to command an obligate overt response to the word or fully corrupt a response to the color: When confronted with a written word, people do not reflexively blurt these out loud without instructions (or intent) to do so; and, in the Stroop paradigm, people are able to name the color of incongruent stimuli with near perfect accuracy (i.e., degradation in performance manifests primarily in slower response time, not erroneous responses). Furthermore, there is considerable empirical evidence that word reading is sensitive in some degree to attentional demands (e.g., [<xref ref-type="bibr" rid="c61">61</xref>, <xref ref-type="bibr" rid="c62">62</xref>]). Thus, word reading is an example of a task that is considered to be automatic, insofar as it engages internal processes that are strong enough to interfere with others that rely on similar representations (e.g., the phonological codes required for naming colors), but not so strong as to obligatorily elicit an overt action or to be fully independent of the effects of control. That is, overt responding <italic>always</italic> requires some additional support from control.</p>
</sec>
<sec id="s2a3">
<title>Control</title>
<p>While the foregoing suggests that tasks that are not overtly reflexive require <italic>some</italic> degree of support from control (e.g., word reading), that support must be augmented if the overt response to a stimulus must compete with a different one favored by a stronger, competing task (e.g., color naming). This suggests that a task’s dependence on control (or, conversely, its degree of automaticity) should be viewed both as a <italic>continuous</italic> attribute that is determined by the strength of the processing pathway required to execute the task, and as a <italic>relative</italic> attribute that is determined by any other tasks with which it may be in competition (see [<xref ref-type="bibr" rid="c27">27</xref>] for a more elaborate treatment of this point). These two attributes align with the two biasing effects of control introduced above—allowing a process to exceed a response threshold and/or diminish interference from competing processes— that are central to the formal treatment of its relationship to automaticity we present below. Critically, they suggest that, other than for reflexes, performance relies on the <italic>context</italic> in which a task is executed, which includes both the stimuli present in the environment (that may elicit other competing tasks) as well as internal signals (e.g., task goals) used for control.</p>
<p>For cases in which a response to a particular stimulus depends on the context in which it occurs, Koechling and Summerfield proposed to add terms to the expression for 𝒬 (<italic>a</italic> | <italic>s</italic>) that are sensitive to the context, <italic>c</italic>, in which a stimulus appears [<xref ref-type="bibr" rid="c13">13</xref>]. In the same way as <xref ref-type="disp-formula" rid="eqn3">Eq. 3</xref>, this splits the expression as follows:
<disp-formula id="eqn4">
<graphic xlink:href="558214v1_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Here the first term refers to the additional information encoded by the context in presence of the stimulus <italic>s</italic>, and the second to past experiences. Importantly, context can be thought of as determining the task that should be performed (i.e., the stimulus-response mapping that is appropriate for that setting). To emphasize this point, and to align with the formulation of control as a signal that provides an internal representation of context used to specify which <italic>task</italic> should be performed, we replace the term c with t. Accordingly, the same pair (a, s) can have different probabilities, and hence informational demands, under different task requirements (and corresponding control specifications). This means that, to the extent that a task depends on control, it is not sufficient to consider the stimulus-response pair (<italic>s, a</italic>) alone. Rather, the task context <italic>t</italic> must be considered. We represent this as the triplet (a, <italic>s, t</italic>) and focus on the properties of <italic>Q</italic>(a | <italic>s, t</italic>) where, once again, <italic>t</italic> corresponds to the current task to be performed.</p>
</sec>
</sec>
<sec id="s2b">
<label>B.</label>
<title>Multitask Environments: Cross-Task Interactions</title>
<p>The formulation outlined above defines the informational demands of performing a single task. However, this becomes more complicated when the possibility of performing more than one task is introduced. In this section, we focus on the performance of multiple tasks simultaneously (i.e., “multitasking”)[<xref ref-type="bibr" rid="c123">123</xref>]. As an example, consider two tasks <italic>t, t</italic><sup><italic>′</italic></sup> respectively characterized by stimulus-response pairs (<italic>s</italic><sub>1</sub>, a<sub>1</sub>, <italic>t</italic><sub>1</sub>) and (<italic>s</italic><sub>2</sub>, <italic>a</italic><sub>2</sub>, <italic>t</italic><sub>2</sub>). To address performance of these simultaneously, it would be natural to simply elaborate the formulation for performing each of them individually, given by <xref ref-type="disp-formula" rid="eqn3">Eq. 3</xref>, to include the joint stimulus and joint action pairs, along the lines of (<italic>a</italic><sub>1</sub>, <italic>a</italic><sub>2</sub> | <italic>s</italic><sub>1</sub>, <italic>s</italic><sub>2</sub>) = log<sub>2</sub> <italic>p</italic>(<italic>a</italic><sub>1</sub>, <italic>a</italic><sub>2</sub> | <italic>s</italic><sub>1</sub>, <italic>s</italic><sub>2</sub>, <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>). While this is a reasonable elaboration, it assumes the two tasks are independent of one another, without considering potential dependencies between stimuli, responses, and/or any internal representations that are shared by the two tasks. For example, in the case of the Stroop task, it does not take into account that color naming and word reading make use of the same phonological representations, precluding simultaneous execution of both tasks in response to an incongruent stimulus (i.e., it is not possible to accurately represent nor utter “red” and “green” at the same time).</p>
<p>As noted in the I, analyzing the interactions among more than just a few tasks in a neural network can become unmanageably complex. Thus, to address such interactions, we turn to the use of a simplified expression of the relationship among tasks in the form of a task graph (see <xref rid="fig1" ref-type="fig">Figure 1</xref>). The first simplification is to assume that all of the processing units in the neural network can be segmented into <italic>sets</italic>, each of which is represented as a node in the graph. For the moment we will focus on stimulus and response sets, designated S and R respectively, but the formalism generalizes to intermediate associative layers that we consider further on. In principle, a set can be an arbitrary collection of items (i.e., a stimulus set can be comprised of an arbitrary collection of stimuli, and similarly for responses). In practice, however, sets are assumed to correspond to naturally occurring dimensions along which stimulus features and response modalities are organized (e.g., colors, shapes, or locations; manual, verbal, or oculomotor responses). Following the definitions introduced in [<xref ref-type="bibr" rid="c57">57</xref>], we consider a task to be determined by a mapping <italic>S</italic> → <italic>R</italic>. This specification of a task generalizes the one used by Koechlin and Summerfield [<xref ref-type="bibr" rid="c13">13</xref>], by specifying dependencies among tasks in terms of the stimulus and/or response sets that they share. This, in turn, allows us to consider potential interactions among tasks at the level of the task graph.</p>
<p>As an example of how a task graph can be used to summarize and examine the interaction among a set of tasks fully defined at the neural network level, we consider the Stroop paradigm [<xref ref-type="bibr" rid="c64">64</xref>] referred to above, and shown as a task graph in <xref rid="fig2" ref-type="fig">Fig. 2a</xref> (corresponding to the format in <xref rid="fig1" ref-type="fig">Fig. 1b</xref>). In this simplified version, there are two sets of stimulus representations, one for colors, <inline-formula><inline-graphic xlink:href="558214v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (e.g, <inline-formula><inline-graphic xlink:href="558214v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, etc.) and one for words, <inline-formula><inline-graphic xlink:href="558214v1_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. There is also a set of representations for verbal responses, <inline-formula><inline-graphic xlink:href="558214v1_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> . In the color naming task, designated by the edge <italic>f</italic><sub>11</sub>, participants are instructed to verbally report the color in which the stimulus is displayed. This is specified by the mapping: <inline-formula><inline-graphic xlink:href="558214v1_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="558214v1_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Similarly, the word reading task, in which participants are instructed to report the word while ignoring the color, and designated as <italic>f</italic><sub>11</sub>, is specified by the mapping: <inline-formula><inline-graphic xlink:href="558214v1_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. As noted above, participants are asked and, critically, are only <italic>able</italic> to successfully perform one of these tasks at a time; that is, either <italic>f</italic><sub>11</sub> or <italic>f</italic><sub>21</sub>, due to their shared use of the response set. However, the task environment can be extended to permit multitasking by adding a third task, such as <italic>word pointing</italic>, in which participants are instructed to point in a specified direction in response to each word, as shown in <xref rid="fig2" ref-type="fig">Fig. 2b</xref>. Following [<xref ref-type="bibr" rid="c21">21</xref>], we refer to this as the <italic>extended Stroop paradigm</italic>. The word pointing task involves an additional response set for pointing in a given direction, <inline-formula><inline-graphic xlink:href="558214v1_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and the task is designated by the edge <italic>f</italic><sub>22</sub>, that is specified by the mapping: <inline-formula><inline-graphic xlink:href="558214v1_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. In the extended Stroop paradigm, participants can be instructed to perform any of the single tasks on their own (<italic>f</italic><sub>11</sub>, <italic>f</italic><sub>21</sub>, or <italic>f</italic><sub>22</sub>), or to multitask color naming and word pointing (i.e., perform (<italic>f</italic><sub>11</sub>) and f<sub>22</sub>) simultaneously). The latter is possible, at least in principle, because these two tasks do not share any nodes (i.e., they involve fully independent sets of stimuli and responses), unlike color naming and word reading (<italic>f</italic><sub>11</sub>) and color naming (<italic>f</italic><sub>21</sub>) which share a response set (<italic>R</italic><sub>1</sub>). However, whether it can be done successfully <italic>in practice</italic> depends on the nature of <italic>f</italic><sub>21</sub>. We will return to this point in Section III A.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Tasks Graphs for the Stroop Paradigm.</title>
<p>Examples of task graphs showing the relationship between representations of stimulus and response sets in: (a) simple version of the standard Stroop paradigm, involving color naming and word reading; and (b) an extended version that includes an additional word pointing task. Note that shaded boxes correspond to nodes of the task graph (light gray for input nodes and pale green for output nodes), with each node comprised of a set of processing units (dark gray circles) that represent individual stimuli or responses in the set, corresponding to the processing units of the neural network implementation, and edges representing the aggregate set of associations (connection weights) between processing units that comprise a task processing pathway (see text and <xref rid="fig1" ref-type="fig">Figure 1</xref> for further explanation).</p></caption>
<graphic xlink:href="558214v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>This example illustrates how the framework outlined above (and fully introduced in [<xref ref-type="bibr" rid="c57">57</xref>]) can be used to describe an architecture <italic>U</italic> = (𝒮, ℛ, 𝒯) capable of performing multiple tasks over a set of stimulus sets 𝒮 = {<italic>S</italic><sub><italic>i</italic></sub>}<sub><italic>i</italic>∈{1,…<italic>N</italic> }</sub> and response sets ℛ = {<italic>R</italic><sub><italic>j</italic></sub> }<sub><italic>j</italic>∈{1,…<italic>M</italic> }</sub>. Here, N and M are the number of distinct stimulus and response sets, respectively, and the tasks that can be performed are defined as a collection of mappings 𝒯 = { <italic>f</italic><sub><italic>ij</italic></sub> : <italic>S</italic><sub><italic>i</italic></sub> → <italic>R</italic><sub><italic>j</italic></sub> } between them (and in which any particular mapping f<sub><italic>ij</italic></sub> might not exist for the pair (<italic>i, j</italic>)). This framework provides a formally rigorous characterization of tasks involving single, fixed mappings between stimuli and responses. While tasks of this form are a staple of cognitive research, as well as many applications in machine learning (such as classification tasks), they are obviously just a subset of the full range of tasks of which humans and machines are capable, that often involve complex <italic>sequences</italic> of processing. Below, and in the Discussion (Section V), we consider ways in which this framework can be extended to address more complex tasks, as well as initial efforts to do so. Nevertheless, even focusing on tasks involving single, fixed mappings, the framework can be used to formally analyze a number of factors that determine how interactions among tasks determine dependence on control, and that are likely to generalize to more complex tasks. Here, we explore three of these factors: (i) differences in the level of automaticity among tasks (determined by the relative strength of their processing pathways); (ii) the number of processing layers implementing the input-output mappings for the tasks (i.e., the depth of the network); and (iii) the potential for simultaneous parallel execution of multiple tasks (i.e., <italic>concurrent multitasking</italic>). In the section that follows, we consider how each of these factors determines the demands for control and the processing constraints with which this is associated.</p>
</sec>
<sec id="s2c">
<label>C.</label>
<title>Functional relationship between neural network and task graph descriptions</title>
<p>As discussed above, and illustrated in <xref rid="fig2" ref-type="fig">Figure 2</xref>, the task structure identified by set 𝒯 can be represented as a task graph, with nodes defined by the sets <italic>H</italic><sub><italic>i</italic></sub> in one layer that encode representations of stimuli, and the sets {<italic>R</italic><sub><italic>i</italic></sub>} in another layer that represents responses, linked by edges representing the mapping between them as defined by the task(s). This can be used to describe a neural network structure that can perform different tasks, by defining the strength of their pathways (represented as edges) required to perform individual tasks, and their relationship to one another. For tractability, previous work using this approach (e.g., [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c19">19</xref>]) has treated edges (i.e., representing the sets of connections that associate stimulus representation sets and response sets) as binary, encoded in an adjacency matrix A in which the entry <italic>a</italic><sub><italic>ij</italic></sub> = 1 ⇔ ∃ <italic>f</italic><sub><italic>ij</italic></sub>. This assumes that all tasks (and all stimulus-response associations within a task) are of equal strength (i.e., identical degree of automaticity). Here, we extend this approach to include weighted edges, used to represent the strength of associations between <italic>H</italic><sub><italic>i</italic></sub> and <italic>R</italic><sub><italic>j</italic></sub>, and corresponding to the automaticity of each task, by assigning a weight ω<sub><italic>ij</italic></sub> to a given stimulus-response set pair if an association exists between them (∈ ℝ <sup>+</sup> ⇔ ∃<italic>f</italic><sub><italic>ij</italic></sub>), and 0 otherwise.[<xref ref-type="bibr" rid="c124">124</xref>]</p>
<sec id="s2c1">
<title>Automatic efficacy and cost for single tasks</title>
<p>Using these definitions, we can formally express the effectiveness with which a task can be performed in the absence of control. We refer to this as <italic>automatic efficacy</italic> that, for a given task <italic>f</italic><sub><italic>ij</italic></sub> is defined as:
<disp-formula id="eqn5">
<graphic xlink:href="558214v1_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where ω<sub><italic>ij</italic></sub> designates its strength (i.e., of the associations implementing the mappings that define the task), and β<sub><italic>j</italic></sub> designates its baseline inhibition (i.e., determines the likelihood that a response unit <italic>R</italic><sub><italic>j</italic></sub> will exceed its threshold, and the corresponding action is taken). Note that, insofar as we are not interested in reflexes, we assume that by default the value of inhibition for all nodes is <inline-formula><inline-graphic xlink:href="558214v1_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and typically much larger than the ω<sub><italic>ij</italic></sub>. That is, as discussed above, even strongly automatic processes (other than reflexes) require <italic>some</italic> amount of control to overcome baseline inhibition and elicit an overt response. Nevertheless, such processes can still have an automatic influence on processing in the absence of control. For example, this captures the influence of words on color naming that produces the Stroop effect as described above: word processing (labelled as f<sub>11</sub> in <xref rid="fig2" ref-type="fig">Fig. 2a</xref>) is associated with an automatic efficacy (weight <italic>w</italic><sub>21</sub> &gt;&gt; <italic>w</italic><sub>11</sub>) that is sufficient to allow orthographic stimuli to influence verbal responding even when no control is allocated to the word reading process, thus interfering with color naming (<italic>f</italic><sub>21</sub> in <xref rid="fig2" ref-type="fig">Fig. 2a</xref>).</p>
<p>It is important to note that performance efficacy as defined above should be considered from an information-theoretical perspective as the fraction of information available in support of performing a task relative to the amount that would ensure perfect performance. This should not be confused with the probability of actually responding correctly (i.e., accuracy), inasmuch as it does not take account of dynamical factors, such as the <italic>integration</italic> of information over time that are known to underlie performance in natural systems (e.g., see Note V D and <xref ref-type="app" rid="app1">Appendix A</xref>). Rather, it can be thought of as more closely related to signal strength (such as the drift rate in dynamical models [<xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c38">38</xref>]), which contributes to but does not uniquely determine either accuracy or response time.</p>
<p>We also note that processing efficacy can be related directly to <xref ref-type="disp-formula" rid="eqn1">Equation 1</xref> (following [<xref ref-type="bibr" rid="c13">13</xref>]) as:
<disp-formula id="eqn6">
<graphic xlink:href="558214v1_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
which formulates it as the cost associated with automatic performance. We use this formulation further below, together with a similar one for the cost associated with control-dependent processing, to consider both the overall cost of processing in various network configurations (Section II D) and how this can be optimized to maximize reward rate (Sections III and IV). <italic>Task pathways in multilayer networks</italic>. Finally, before considering the influence of control, we generalize the notion of automatic efficacy, and the corresponding cost, to cases in which tasks rely on pathways that span multiple layers of processing units in the network, as well as task environments in which multiple tasks are possible. Multilayer networks encompass both “deep” feed-forward networks that are widely used to address the complex mappings involved in naturalistic tasks such as computer vision ([<xref ref-type="bibr" rid="c25">25</xref>]), as well as recurrent networks used to address tasks that involve temporally extended and/or sequential processes [<xref ref-type="bibr" rid="c66">66</xref>–<xref ref-type="bibr" rid="c69">69</xref>]. For the purpose of illustration, we focus here on feed-forward networks, but the formalism can readily be extended to recurrent networks.</p>
<p>Consider a network architecture described by a multi-partite graph with L layers constituted by sets 𝒱<sub><italic>l</italic></sub>, with <italic>l</italic> = 0, …, <italic>L</italic> − 1. This can be transformed into a feed-forward network by allowing edges only between sets 𝒱<sup><italic>l</italic></sup> and 𝒱<sup><italic>l</italic>+1</sup>, in which each of these edge sets is called ε <sup><italic>l</italic></sup>. It is natural to think each edge <inline-formula><inline-graphic xlink:href="558214v1_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula> as a <italic>sub-mapping</italic> <inline-formula><inline-graphic xlink:href="558214v1_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula> propagating inputs from internal set <inline-formula><inline-graphic xlink:href="558214v1_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula> to internal set <inline-formula><inline-graphic xlink:href="558214v1_inline14.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. This can be thought as of a stack of bipartite networks (akin to those considered above) layered on top of one another, with the only condition that the first layer is <italic>V</italic> <sup>0</sup> = 𝒮, corresponding to stimuli, and the last is <italic>V</italic> <sup><italic>L</italic>−1</sup> = ℛ, corresponding to the responses.</p>
<p>Accordingly, and following similar treatments in previous work (e.g., [<xref ref-type="bibr" rid="c32">32</xref>]), the definition of a task introduced above (in Section II B) can be generalized to a composition of sub-mappings from an input set to an output set along a specific path <inline-formula><inline-graphic xlink:href="558214v1_inline15.gif" mimetype="image" mime-subtype="gif"/></inline-formula> through the network. For example, the task of reading a word can be considered as a series of sub-mappings, from the visual input to orthographic representations of letters, from those to lexical representations of words [<xref ref-type="bibr" rid="c70">70</xref>, <xref ref-type="bibr" rid="c71">71</xref>] and/or directly to corresponding phonological representations used to generate a verbal response (as in <xref rid="fig2" ref-type="fig">Figure 2</xref>). Such task pathways can be expressed formally as:
<disp-formula id="eqn7">
<graphic xlink:href="558214v1_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
If we denote the set of all such tasks that can be performed by a given network as 𝒫, then the set of the processing pathways in the multitask network for performing those tasks can be written as: 𝒰 = ({𝒱<sup><italic>l</italic></sup>}, { ε <sup><italic>l</italic></sup>}, 𝒫).</p>
<p>Using this framework, we can define the processing of task P to be successful if, at every step l along its pathway, the corresponding edge <inline-formula><inline-graphic xlink:href="558214v1_inline16.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is successful in producing the associated response on unit <inline-formula><inline-graphic xlink:href="558214v1_inline17.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. (Note that the the bipartite case discussed above is a simplified case of this more general definition, in which there are only stimulus representation and response sets and no internal layers). More specifically, the automatic efficacy for the task pathway <italic>P</italic> is given by:
<disp-formula id="eqn8">
<graphic xlink:href="558214v1_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
It is easy to see that, on the assumption that there is some finite amount of inhibition [<xref ref-type="bibr" rid="c125">125</xref>] associated with processing at each layer (represented by the β parameters) then, all other factors held constant, efficacy decreases with network depth due to the accumulated effects of β across layers as pathway length increases. This is illustrated in <xref rid="fig3" ref-type="fig">Figure 3a</xref>), which shows the efficacy p[P] for a single task path P processed through a network of growing depth for various possible β values (for simplicity, in this case, we set the β to the same value throughout a given network). As the depth increases, the probability decreases rapidly, implying that automatic processing of even a single task incurs greater reductions in processing efficacy in deeper networks. Consequently, the automatic processing cost Ψ(<italic>P</italic>) increases with depth (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>, dashed lines) and inhibition (higher values of β). As we demonstrate in Section III B, increases in network depth are also associated with a greater likelihood of two tasks interfering with one another, yielding greater performance costs.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Performance cost and control for single tasks.</title>
<p>(a) Efficacy <italic>p</italic>[<italic>P</italic>] for single task execution as a function of network depth for various values of <italic>β</italic>. (b) Automatic processing cost Ψ (solid lines) and ΔΨ (dots) for single task execution as a function of network depth for various values of <italic>β</italic>. Note that, for single tasks and sufficiently small values of <italic>β</italic>, the processing cost approaches and even reaches 0 (ΔΨ = Ψ). (c) Relationship between the processing cost reduction ΔΨ and the total amount of applied inhibition <bold>Δ<italic>β</italic></bold>, which represent the control applied to modulate the basal inibitions <bold><italic>β</italic></bold>.</p></caption>
<graphic xlink:href="558214v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><italic>Example: The Stroop Task Paradigm</italic></p>
<p>As an example of how the information-theoretic framework introduced above can be used to summarize task performance in a given network architecture, we compare this to the results of a neural network model that has been used to simulate the patterns of human performance in the Stroop paradigm [<xref ref-type="bibr" rid="c27">27</xref>]. <xref rid="fig4" ref-type="fig">Figure 4a</xref>) shows the two processing pathways in that model used to simulate the color naming and word reading tasks. Each pathway is comprised of a set of input units used to represent each of the two stimuli in each of the two stimulus dimensions (<inline-formula><inline-graphic xlink:href="558214v1_inline18.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="558214v1_inline19.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for the colors red and green; and <inline-formula><inline-graphic xlink:href="558214v1_inline20.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="558214v1_inline21.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for the words RED and GREEN). The input representation units in each dimension project to a corresponding set of internal (hidden) units <inline-formula><inline-graphic xlink:href="558214v1_inline22.gif" mimetype="image" mime-subtype="gif"/></inline-formula> that, in turn, project, to units in the output layer of the network used to represent each of two verbal responses (<inline-formula><inline-graphic xlink:href="558214v1_inline23.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="558214v1_inline24.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, corresponding to “red” and “green” respectively). Thus, the network is comprised of two processing pathways, one for color stimuli and one for word stimuli, that converge on a common set of output units. The connections between processing units in <xref rid="fig4" ref-type="fig">Figure 4a</xref> represent the associations between each stimulus and each response that constitute the mappings defined by the task, with the sign (shown in black for positive and orange for negative) and weight (thickness) of the connection designating the strength of the association between individual stimulus and response pairs (i.e., their automaticity). Note that each stimulus is positively associated with a single response, and negatively with all others. This is consistent with a one-to-one mapping of stimuli to responses. The weight of the connections in the word reading pathway is greater than in the color naming pathway, capturing the greater automaticity of word reading relative to color naming. This network corresponds to the task graph shown in <xref rid="fig2" ref-type="fig">Figure 2a</xref> [<xref ref-type="bibr" rid="c126">126</xref>]</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Information theoretic analysis of automatic performance in the Stroop paradigm.</title>
<p>Panel a): Neural network model of automatic processing in the Stroop task (adapted from [<xref ref-type="bibr" rid="c27">27</xref>], showing the processing pathways for each task, but not the mechanism responsible for control). Excitatory connections are shown as black lines, inhibitory connections as orange lines, and line thickness represents connection weight (corresponding to |<italic>ω</italic>| at the network level; see <xref rid="fig1" ref-type="fig">Figure 1</xref>). The pathway on the left <inline-formula><inline-graphic xlink:href="558214v1_inline58.gif" mimetype="image" mime-subtype="gif"/></inline-formula> implements the stimulus-response mappings for the color naming task, and the pathway on the right <inline-formula><inline-graphic xlink:href="558214v1_inline59.gif" mimetype="image" mime-subtype="gif"/></inline-formula> the mappings for word reading (see text for fuller description). All units have an inhibitory bias (corresponding to <italic>β</italic>) = 500. Panels b) and c): Efficacy values and processing costs, respectively, calculated for automatic performance under each of the three task conditions (see text) using the information theoretic formulation of the task corresponding to the network shown in Panel a) (see text and <xref ref-type="disp-formula" rid="eqn9">Equations 9</xref>-<xref ref-type="disp-formula" rid="eqn13">13</xref>). Network parameters are reported in Tables I in <xref ref-type="app" rid="app3">Appendix C</xref>.</p></caption>
<graphic xlink:href="558214v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>This network can be used to simulate performance of the two tasks, color naming and word reading, each under the three possible stimulus conditions: <italic>neutral</italic>, in which relevant information is presented in only one dimension (e.g., for color naming, X’s shown in red [XXX] and, for word reading, the word red shown in black [<bold>RED</bold>]); <italic>incongruent</italic>, in which the color and word information disagree (e.g., GREEN); and <italic>congruent</italic>, in which they agree (e.g., RED). Simulations using this network produce results that qualitatively match those of human performance [<xref ref-type="bibr" rid="c27">27</xref>]. That is, they are characterized by four distinctive and robust effects: i) performance is better overall for word reading in all conditions; ii) word reading performance varies minimally across conditions, showing little effect if any of the color on the ability to respond to the word; iii) color naming is heavily affected by the word, with substantial interference in the incongruent condition and facilitation in the congruent condition, relative to control; iv) the interference effect is substantially greater in magnitude than the facilitation effect. The first three of these are consistent with the contention that word reading is more automatic (i.e., has a stronger processing pathway) than color naming, while the asymmetry of interference and facilitation effects has been attributed to nonlinearities in processing [<xref ref-type="bibr" rid="c27">27</xref>].</p>
<p>The original neural network model was designed to simulate both the <italic>dynamics</italic> (e.g. responses times) and <italic>outcome</italic> (i.e., response accuracy) of processing. The formalisms introduced above can be used to compute an information theoretic characterization of performance that, while not taking account of the dynamics (see Note V D), nevertheless accurately captures the effects of relative differences in the strength of the two processing pathways, and their interaction, on the outcome of performance. This can be done by first using (<xref ref-type="disp-formula" rid="eqn5">Equations 5</xref>-<xref ref-type="disp-formula" rid="eqn8">8</xref>) to compute the probability, for a given input, that only the correct response unit (and not the incorrect one) is activated. For example, in the neutral condition for color naming, if the stimulus is the color red, then <inline-formula><inline-graphic xlink:href="558214v1_inline25.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the only input unit activated, and the desired propagation of activation (designated by →) is <inline-formula><inline-graphic xlink:href="558214v1_inline26.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="558214v1_inline27.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and <italic>R</italic><sup><italic>g</italic></sup> should <italic>not</italic> be activated (i.e., <inline-formula><inline-graphic xlink:href="558214v1_inline28.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). The probabilities for the corresponding activations under this condition are given by:
<disp-formula id="eqn9">
<graphic xlink:href="558214v1_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn10">
<graphic xlink:href="558214v1_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn11">
<graphic xlink:href="558214v1_eqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This can be used, in turn, to compute the automatic efficacy of performance for that input:
<disp-formula id="eqn12">
<graphic xlink:href="558214v1_eqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
A similar computation can be performed for all of the other stimuli (i.e., in each of the three conditions for each of the two tasks). Note that, in the neutral condition used in the example above, only one source of input to the response units had to be computed. However, in the incongruent and congruent conditions, there are two sources of input. This can be quantified by computing the probability of the responses given all incoming connections. For example, in the incongruent condition, if the stimulus is comprised of <inline-formula><inline-graphic xlink:href="558214v1_inline29.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="558214v1_inline30.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, then the probability of responding to the color rather than the word (i.e., activating <italic>R</italic><sup><italic>r</italic></sup> rather than <italic>R</italic><sup><italic>g</italic></sup>) is computed as:
<disp-formula id="eqn13">
<graphic xlink:href="558214v1_eqn13.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
More generally, by calculating the activation probabilities for each unit given a particular input, and summing over all possible input patterns for a given task under each condition, we can determine the <italic>automatic</italic> processing efficacy and the processing costs for a given task under each condition. [<xref ref-type="bibr" rid="c127">127</xref>]. The results of these calculations are shown in <xref rid="fig4" ref-type="fig">Figure 4</xref>(b and c), assuming that the “correct” response to each stimulus is the one associated with the input in the task-relevant stimulus dimensions. Like the neural network model, the information-theoretic analysis closely aligns with the four canonical empirical results: i) word reading shows greater overall efficacy than color naming (compare the neutral condition for the two tasks); ii) word reading is only minimally impacted by information about the color of the stimulus (cf. word reading incongruent condition); iii) by contrast, color naming <italic>is</italic> profoundly impacted by information about the word (cf. color naming incongruent condition); and iv) interference is substantially greater than facilitation (compare the congruent and incongruent conditions against the neutral condition for each task).</p>
<p>Note, however, that this analysis deviates from the canonical effects associated with the Stroop paradigm in two ways. First, in the congruent condition, automatic efficacy is identical for color naming and word reading. On the surface, this is in contrast with the idea that word reading has greater efficacy than color naming; however, thus far, the information-theoretic analysis has only been applied to <italic>automatic</italic> efficacy, and has not taken into account any effects of control. Thus, for <italic>both</italic> tasks, performance is governed equally by all available information (i.e., <italic>both</italic> the color <italic>and</italic> word dimensions), and thus determined by the strongest pathway; in this case, that is word reading, and thus performance in the congruent condition is at “ceiling” irrespective of task. For similar reasons, the analysis indicates that the efficacy for color naming in the incongruent condition is at floor; that is, the network is unable to respond correctly, instead producing the word as the response. This result is consistent with the intuition (and easily verified prediction) that if an individual who has no familiarity with the Stroop paradigm is presented with an incongruent stimulus and asked to respond out loud <italic>without any additional instructions</italic> (i.e., no incentive to allocate control to process one dimension over the other), they are almost certain to respond to the word rather the color. In the Stroop model [<xref ref-type="bibr" rid="c27">27</xref>], both the ability to name the color, performance differences between color naming and word reading in the congruent condition, are explained by the allocation of control, to which we turn in the next section.</p>
<p>In summary, we have shown that our formalism, applied to task processing described at the neural network level, is able to reproduce characteristic features of performance in the Stroop paradigm. However, as noted at the outset, analysis at the neural network level – that takes account of both the full details of stimulus-response associations across all tasks as well as the dynamics of processing – can quickly become intractable when considering potential interactions among multiple tasks, each of which may involve a multiplicity of stimuli and responses. Accordingly, to examine interactions among tasks, and how this impacts the requirements for control and multi-tasking capabilities, we turn to an analysis at the level of the task graph. We use this to consider task interactions in terms of the interference produced by patterns of task “dependencies” (that we define in Section III A 1 below). First, however, we develop the construct of control at this level of analysis.</p>
</sec>
</sec>
<sec id="s2d">
<label>D.</label>
<title>Modulation and Control Efficacy</title>
<p>To address the influence of control at the task graph level, we add we add a parameter <bold>∆<italic>β</italic></bold> to the expression for efficacy in <xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref>, that is a vector with a value for each node of the task graph that modifies its corresponding baseline <bold><italic>β</italic></bold>. Thus, for a given node j receiving an input from a set of nodes I, the activation probability can be written as:
<disp-formula id="eqn14">
<graphic xlink:href="558214v1_eqn14.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The role of the ∆β<sub><italic>j</italic></sub> is to diminish the inhibition of j, hence facilitating j’s activation. Although <bold>∆<italic>β</italic></bold> is implemented as an additive parameter, its interaction with the non-linearity of the activation function has a multiplicative, gating-like effect on processing: since baseline β is assumed to be high, processing units associated with the units (e.g., see <xref rid="fig2" ref-type="fig">Figure 2</xref>) are not only inhibited, but also in an insensitive range of their activation function (i.e., changes to other inputs have little effect on the unit); by diminishing β, <bold>∆<italic>β</italic></bold> places units in a more sensitive range of their activation function, and thus renders them more responsive to other inputs (see [<xref ref-type="bibr" rid="c27">27</xref>] for a more detailed discussion). By modulating the sensitivity of processing units in a task pathway, the <bold>∆<italic>β</italic></bold> can be used to control the efficacy of that task, in a manner similar to the multiplicative (“gating”) effects used to implement control in models with linear processing units (e.g., [<xref ref-type="bibr" rid="c75">75</xref>, <xref ref-type="bibr" rid="c76">76</xref>]). For example, where the activation function is a sigmoid (e.g., logistic or tanh) and the net input and β appear in the exponent, <bold>∆<italic>β</italic></bold> has the effect of adding to the exponent, which is comparable to multiplying the net input when the activation function is linear.</p>
<p>To the extent that each ∆β<sub><italic>j</italic></sub> applies to a unit in the network, then its value applies to all processing units represented by that node (see <xref rid="fig2" ref-type="fig">Figures 2</xref> and <xref rid="fig1" ref-type="fig">1</xref>). This aligns with the simplifying assumption that processing units are arranged into sets that represent similar information, and that control operates uniformly over such sets of units (i.e., over a node), and independently of others. This approach has been used productively to model the effects of control in tasks that align with well-defined and dissociable categories of information, such as colors and words in the Stroop task [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c77">77</xref>, <xref ref-type="bibr" rid="c78">78</xref>]. More generally, however, the representations required to perform different tasks may not be so discretely separable. Nevertheless, the ability to perform different tasks based on similar information requires that there be <italic>some</italic> basis on which distinctions can be made, usually at a higher level of abstraction, that can be exploited by the control system to perform the different tasks (see [<xref ref-type="bibr" rid="c79">79</xref>] for recent work that has begun to address how the simplifying representational assumptions made here can be generalized to address control over more graded distinctions among distributed representation reflecting more complex forms of semantic structure. <xref rid="fig4" ref-type="fig">Figure 4b</xref> and <xref rid="fig4" ref-type="fig">c</xref> (solid lines) show the automatic efficacy of performance for the color naming task (see Appendix for the specific <bold>∆<italic>β</italic></bold> parameters), which aligns qualitatively with the effects in a neural network model of the Stroop task [<xref ref-type="bibr" rid="c27">27</xref>], including the observation that the magnitude of interference is influenced by the relative strength of one task with respect to the other (e.g., word reading interferes more with color naming than the converse and, accordingly, color naming cannot be performed for incongruent stimuli without control).</p>
<p>For the case of multiple tasks, the efficacy for a given task pathway <italic>P</italic> (again with node <italic>j</italic> = <italic>i</italic>+1) can be written as:
<disp-formula id="eqn15">
<graphic xlink:href="558214v1_eqn15.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The <bold>∆<italic>β</italic></bold> parameters in this expression implement the function of control discussed above. That is, ∆β<sub><italic>i</italic></sub> for node i mediates its effects by counteracting the intrinsic inhibition imposed by the corresponding β<sub><italic>i</italic></sub>, thus disinhibiting unit i. This not only makes it more likely for weaker pathways, which are more influenced by intrinsic inhibition, to reach their threshold for responding, but also allows them to compete more effectively with stronger pathways (i.e., ones with greater automatic efficacy) to which control has not been allocated (but that are less impacted by their own intrinsic inhibition). Since the <bold>∆<italic>β</italic></bold> parameters account for changes in efficacy due to the allocation of control, we refer to their contribution to the overall efficacy p as the <italic>controlled efficacy</italic> component.</p>
<p>Note that, in addition to <bold>∆<italic>β</italic></bold>, the expression for pathway efficacy (<xref ref-type="disp-formula" rid="eqn15">Eq. 15</xref>) is dependent on another parameter, <italic>v</italic>. This represents another form of control that has its primary effect on the interaction between tasks in multitask networks, and that we consider in Section III B. In single task networks, however, <italic>v</italic> has effects qualitatively similar to those of <bold>∆<italic>β</italic></bold>, and thus we ignore it for the remainder of this section.</p>
<p>In general, <bold>∆<italic>β</italic></bold> can be thought of as reflecting the influence of task representations used for control—that themselves are activity-based—and thus subject to rapid updating. Here, we do not directly consider the mechanisms responsible for the activating and updating (nor the learning) of such representations. However, we assume that, as suggested by other work, they are subject to the same principles of learning, representation, and processing as the ones discussed here, simply applied at a higher (e.g., more abstract) level of representation [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c79">79</xref>, <xref ref-type="bibr" rid="c80">80</xref>]. We return to this point further on, where we discuss the <italic>acquisition</italic> of automaticity. First, however, we focus on the effects that the elements of <bold>∆<italic>β</italic></bold> have on overall efficacy p, by treating a given <bold>∆<italic>β</italic></bold> as a <italic>control policy</italic> and considering how it can be adjusted to optimize processing.</p>
<p>The simplest, but the most important effect is the interaction of <bold>∆<italic>β</italic></bold> with the β and ω parameters that determine pathway strength (i.e., automatic efficacy), allowing weaker pathways to compete more effectively with stronger ones: the greater the disparity of automatic parameters between two pathways in competition, the more the weaker one relies on its ∆β<sub><italic>i</italic></sub>’s for execution.</p>
<p>Using <xref ref-type="disp-formula" rid="eqn15">Eq. 15</xref>, we can formulate the information cost Ψ for P associated with a control policy <bold>∆<italic>β</italic></bold> as:
<disp-formula id="eqn16">
<graphic xlink:href="558214v1_eqn16.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
and the cost reduction ∆Ψ induced by that control policy as:
<disp-formula id="eqn17">
<graphic xlink:href="558214v1_eqn17.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The control policy <bold>∆<italic>β</italic></bold> can then be optimized, by finding elements that minimize the processing cost Ψ (and thereby maximize processing efficacy p) for a given task pathway P. <xref rid="fig3" ref-type="fig">Figure 3b</xref> shows that for single tasks, it is always possible to find the set of control values <bold>∆<italic>β</italic></bold><sup>∗</sup> for the corresponding pathway that bring the controlled processing cost to zero, Ψ<sup>∗</sup> = 0 (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>, black stars), which in turn implies ∆Ψ = Ψ −Ψ<sup>∗</sup> = Ψ (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>, coloured dots). This is trivially done by setting ∆β<sub><italic>j</italic></sub> = β<sub><italic>j</italic></sub>, which in turn makes all efficiencies 1 and thus all costs 0. However, this requires progressively more control to be applied as the network becomes deeper, which implies that the requirement for control <bold>∆<italic>β</italic></bold><sup><bold>∗</bold></sup> grows with network depth, proportionally to the growth in processing costs (<xref rid="fig3" ref-type="fig">Fig. 3c</xref>). Furthermore, in the next section we will see that, even with an unlimited budget for control, it is not always possible to bring performance costs to zero when <italic>multiple</italic> tasks must be performed. Moreover, as control engages more task pathways, there is a greater potential for those task pathways to interfere.</p>
</sec>
</sec>
<sec id="s3">
<label>III.</label>
<title>Optimization of control at the task graph level in multitask environments</title>
<p>In the previous section we affirmed that the treatment of automatic and controlled efficacy in information-theoretic terms aligns closely with previous work using neural networks to model the effects of pathway strength (automaticity) and activation-based modulation (control) under conditions in which a <italic>single</italic> task must be performed, but its pathway shares a set of representations with another task pathway that may have greater or less automatic efficacy (e.g., the output representations shared by color naming and word reading in the Stroop paradigm). Here, we broaden the scope of the approach to address the optimization of control in situations where more than one task must be performed. To do so, we introduce some additional simplifications.</p>
<p>Following similar efforts [14, 16, 19, 21, 32, 57], the first simplification is to assume that for tasks that share representations, the inputs relevant to each task are always associated with different specific representations in the shared set (as in the incongruent condition of the Stroop task; see <xref rid="fig4" ref-type="fig">Figure 4b</xref>). This is motivated by two considerations. First, as noted above, the costs associated with incongruence (interference) are generally much greater than the benefits associated with congruence (facilitation; e.g., see <xref rid="fig4" ref-type="fig">Figure 4</xref>, Panels b and c), and therefore likely have a greater impact on processing. Furthermore, in realistic environments, incongruence among independent stimulus dimensions is much more likely than congruence [<xref ref-type="bibr" rid="c128">128</xref>]. For both of these reasons, optimization of control in multitask settings is likely to be driven more strongly by the interfering effects of incongruent stimuli than the facilitative effects of congruent ones.</p>
<p>The second simplification follows the approach taken to the formulations of efficacy above (e.g., <xref ref-type="disp-formula" rid="eqn12">Equations 12</xref> and <xref ref-type="disp-formula" rid="eqn15">15</xref>), by focusing on effects at the graph level through the construction of a <italic>task graph</italic> (along the lines used to depict the Stroop paradigm in <xref rid="fig2" ref-type="fig">Figure 2</xref>). In this graph, each node corresponds to a <italic>set of processing units</italic> used to represent similar information (as discussed in Section II C), and edges correspond to the <italic>mappings among them</italic> that define each task. For example, the two hidden units per stimulus dimension (colors and words) in the model of the Stroop paradigm shown in <xref rid="fig4" ref-type="fig">Figure 4a</xref> (and corresponding to the model shown in the left of <xref rid="fig1" ref-type="fig">Figure 1</xref>) are each summarized by a node, <italic>H</italic><sub>1</sub> and <italic>H</italic><sub>2</sub> respectively (shown on the right in <xref rid="fig1" ref-type="fig">Figure 1</xref>). The shared set of verbal responses units are represented by <italic>R</italic><sub>1</sub>, and the strengths of the mappings in each pathway by the edges (<italic>f</italic><sub>11</sub> and <italic>f</italic><sub>12</sub>, respectively [<xref ref-type="bibr" rid="c129">129</xref>]. Note that the state of each node in the task graph—rather than representing the activation of stimulus- or response-specific information—represents the likelihood that information corresponding to a particular type of information is processed.</p>
<sec id="s3a">
<label>A.</label>
<title>Automatic Multitask Processing</title>
<p>Thus far, we have considered processing efficacy when the network is asked to perform only a single task at a time. However, the formalism outlined above can be used to describe a network architecture 𝒰 capable of performing multiple tasks, and to analyze how the architecture impacts efficacy of task performance. As discussed in the Introduction, reward can sometimes be optimized if more than one task is performed at a time, by performing them in parallel; that is, through <italic>concurrent multitasking</italic>. For a given network architecture, parallel execution can substantially increase the reward rate for some combinations of tasks (that do not share representations). However, for other combinations (that <italic>do</italic> share representations), parallel execution may be disadvantageous by introducing the potential for interference, which can compromise performance and thus diminish reward rate. Such combinations demand serial execution and concomitant dependence on control. Here, we consider how the analysis of efficacy can be applied to the question of when (and for which tasks) performance should be parallelized, by formalizing the automatic efficacy of parallel execution (multitasking) for a given set of tasks, as a benchmark against which the value of serial processing and the demands for control can be compared (that we address in the next section). We start by considering single-layered networks, in which representational sharing is restricted to stimulus and/or response sets, and use this to define different forms of dependence that can arise among tasks as a consequence of different configurations of sharing. We then build on this formalization to examine more complex, multilayered networks.</p>
<sec id="s3a1">
<label>1.</label>
<title>Single Layer Task Graphs</title>
<p>In <xref rid="fig5" ref-type="fig">Figure 5</xref>, we show the combinations of tasks that can be formed from a pair of stimulus and response sets, arranged from left to right according to the extent of sharing of sets between tasks. In the leftmost configuration (<italic>a</italic>), the two tasks do not share any stimulus or response sets, and thus are independent of one another and do not pose a risk of interference, allowing them to be performed in parallel. All of the other configurations exhibit various forms of dependence among tasks, that pose the risk of interference, though for different reasons and with different consequences. We first consider these qualitatively—in terms of a distinction between <italic>structural</italic> versus <italic>functional</italic> dependence—and then quantify them using the formalisms introduced above.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Possible configurations of interference among tasks.</title>
<p>Blue nodes show stimulus and response sets, and colored edges show tasks formed by various mappings between them. (Note that here, as in <xref rid="fig1" ref-type="fig">Figure 1</xref>, we label the input nodes of the task graph as <italic>H</italic><sub><italic>i</italic></sub>, on the assumption that each receives a mapping from a different stimulus set (as in the model of the Stroop paradigm shown in <xref rid="fig4" ref-type="fig">Figure 4</xref>), and thus is sufficient to capture the neural network-level effects of shared representations at the hidden and/or response levels.) Green and yellow edges designate tasks that do not share representations with (i.e., are independent of) one another and thus can be performed in parallel. Red edges designate mappings that share a set of representations with another task, and thus either introduce dependencies among those tasks (panels b, d and e), or do not constitute a legal (independent) task (panel c; see Section II B or [<xref ref-type="bibr" rid="c57">57</xref>]). Different panels show examples of mappings associated with different types of dependencies (see text), arranged from left to right according to extent of representational sharing.</p></caption>
<graphic xlink:href="558214v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s3a1a">
<title>Structural dependence</title>
<p>The problem of interference arises in the simplest form when a pair of tasks share the same response set (configuration <italic>b</italic> in <xref rid="fig5" ref-type="fig">Figure 5</xref>), as in the case of color naming and word reading tasks in the Stroop paradigm (see <xref rid="fig2" ref-type="fig">Fig. 2a</xref> and <xref rid="fig4" ref-type="fig">Figure 4a</xref>). This is because the inputs for the two tasks may make disparate demands of their shared response set (e.g., for the stimulus GREEN, say “red” in response to the color versus “green” in response to the word). This reflects two fundamental assumptions about the definition of tasks and the nature of the architecture (formalized in [<xref ref-type="bibr" rid="c57">57</xref>]): i) tasks are defined by the ability to sample a stimulus for processing <italic>independently</italic> of any other task; ii) the units in a given set (stimulus, internal or response) cannot simultaneously represent different information at the same time. Furthermore, as noted above (Section II B) and in [<xref ref-type="bibr" rid="c57">57</xref>]), independent sampling along stimulus dimensions means that the likelihood of an incongruent stimulus is much greater than of a congruent stimulus, and thus the risk of conflict is high for tasks that share a set of representations. We refer to such sharing of representations by two or more tasks, exemplified by the configuration shown in Panel b), as <italic>structural dependence</italic> [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c83">83</xref>, <xref ref-type="bibr" rid="c84">84</xref>], as it directly reflects a structural feature of the graph architecture.</p>
<p>As just suggested, structural dependence can also arise from a shared stimulus set if it maps to different response sets, as shown in <xref rid="fig5" ref-type="fig">Figure 5c</xref>. While this configuration would not seem to pose the risk of conflict (since it maps to independent response sets), it poses another, <italic>conceptual</italic>, problem. Distinct tasks are defined by the ability to sample task-relevant stimuli independently of one another, a requirement that cannot be met if two tasks share the same stimulus set. For example, imagine that one task is to name the color of the stimulus, and another is to point at a matching color patch in another part of the display. It is not possible to isolate these as separate tasks and perform them simultaneously, since it is not possible for the target stimulus to be two different colors at the same time (that is, to sample the stimuli for each task independently of the other). Conversely, if the <italic>same</italic> stimulus is always used for the two colors (i.e., the stimuli are not sampled independently for the two tasks), then what is labeled as two tasks could just as naturally be thought of as a <italic>single</italic> task that simply has a more complex response. For this reason, we treat two pathways that share a stimulus set as a form of structural dependence that, in this case, precludes considering their simultaneous execution as a form of genuine multitasking performance [<xref ref-type="bibr" rid="c130">130</xref>].</p>
</sec>
<sec id="s3a1b">
<title>Functional dependence</title>
<p>A subtler case of dependence arises when two tasks do not share any stimulus or response sets (such the tasks shown in green and yellow in <xref rid="fig5" ref-type="fig">Figure 5d</xref> and <xref rid="fig5" ref-type="fig">e</xref>) or, more generally, even any internal representations—that is, they are not structurally dependent—but one shares a stimulus set and the other shares a response set with a third task (shown in red and orange). In this case, any attempt to simultaneously perform the fist two tasks inadvertently invokes the third task. That is, even though the first two tasks are not themselves structurally dependent, they are still at risk of the functional consequences of interference as a result of their mutual structural dependence on a third task. Accordingly, we refer to the first two tasks as being <italic>functionally</italic> dependent. The same applies for the sharing of internal representations (in place of or in addition to stimulus and/or response sets), so long as the same criteria apply: they are not shared directly by the first two tasks but, by disjoint sharing with each, they comprise a third task.</p>
<p>The consequences of functional dependence are illustrated by color naming and word pointing in the extended Stroop paradigm discussed above (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>). To simultaneously perform the color naming and word pointing tasks (<italic>f</italic><sub>11</sub>, <italic>f</italic><sub>22</sub> in <xref rid="fig2" ref-type="fig">Fig. 2b</xref>, respectively), control must be allocated to the color and word stimulus sets (e.g. by increasing <inline-formula><inline-graphic xlink:href="558214v1_inline31.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="558214v1_inline32.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, respectively), as well as to the verbal and manual response sets (by increasing <inline-formula><inline-graphic xlink:href="558214v1_inline33.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="558214v1_inline34.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). Note, however, that doing so allows information to flow from the stimulus set for words to the response set for verbal responses via <italic>w</italic><sub>21</sub>, inadvertently engaging the word reading task. For incongruent stimuli, this will not just prolong responding, but will prevent an accurate response altogether. For example, in the standard Stroop task, when color naming is the only task being performed, information from a conflicting word may partially activate representation in the word stimulus set, which will compete with and thereby slow down processing of the verbal response to the color; however, since no control has been allocated to the word stimulus set, that information will not be active enough to determine the actual response. In contrast, when the word pointing task is performed simultaneously, and therefore control <italic>is</italic> allocated to the word stimulus set, it will now determine the response since its connection to the verbal response set is stronger than the one for colors (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). Thus, even though color naming and word pointing are not <italic>structurally</italic> dependent (they involve independent stimulus and response sets), they are <italic>functionally</italic> dependent by way of word reading. As a consequence, without a change in graph configuration (that we consider further on, in Section IV B), the graph cannot simultaneously and accurately perform (i.e., <italic>multitask</italic>) both color naming and word pointing. This is consistent with empirical findings that, without extensive practice, people are incapable of performing these two tasks simultaneously [<xref ref-type="bibr" rid="c21">21</xref>] (see [<xref ref-type="bibr" rid="c53">53</xref>] for another example). <italic>Formal analysis of multitasking efficacy</italic>. The risks of interference associated with multitasking performance, exemplified by the various types of dependence shown in <xref rid="fig5" ref-type="fig">Fig. 5</xref>, can be generalized to more complex bipartite graphs by defining a multitask combination as a set of tasks <inline-formula><inline-graphic xlink:href="558214v1_inline35.gif" mimetype="image" mime-subtype="gif"/></inline-formula> from an arbitrarily complex 𝒰 [<xref ref-type="bibr" rid="c57">57</xref>]. Simultaneous performance of the tasks in ℳ entails the activation of internal representations <italic>H</italic> <sub>ℳ</sub> associated with the stimulus sets for all of those tasks, and the corresponding responses <italic>R</italic> <sub>ℳ</sub> from the response sets for those tasks. Based on this, we can then identify the full set of tasks engaged by ℳ —that is, including any additional tasks inadvertently engaged due to functional dependence among those in <italic>R</italic> <sub>ℳ</sub> —as the extended multitask <inline-formula><inline-graphic xlink:href="558214v1_inline36.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where by construction <inline-formula><inline-graphic xlink:href="558214v1_inline37.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. This is because, as discussed above, when the stimulus and response sets of ℳ are activated, all tasks that map representations <italic>H</italic> <sub>ℳ</sub> to <italic>R</italic> <sub>ℳ</sub> (i.e., those responsible for any functional dependence among them) are also engaged. For example, if multitasking is attempted for the green and yellow tasks in <xref rid="fig5" ref-type="fig">Figure 5d</xref> (i.e., ℳ = {<italic>f</italic><sub>11</sub>, f<sub>22</sub> }), then the red task will join them in comprising the extended multitask <inline-formula><inline-graphic xlink:href="558214v1_inline38.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. From the definition of <inline-formula><inline-graphic xlink:href="558214v1_inline39.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, it follows that the probability of correctly performing any task <italic>f</italic><sub><italic>ij</italic></sub> ∈ ℳ depends on the extent to which the probability of its output response <italic>R</italic><sub><italic>j</italic></sub> depends on H<sub><italic>i</italic></sub> relative to any other input to the graph H<sub><italic>k</italic></sub> via the other tasks associated with <inline-formula><inline-graphic xlink:href="558214v1_inline40.gif" mimetype="image" mime-subtype="gif"/></inline-formula> Accordingly, the automatic efficacy <italic>p</italic>[<italic>f</italic><sub><italic>ij</italic></sub>| ℳ] of task <italic>f</italic><sub><italic>ij</italic></sub> in multitask <italic>ℳ</italic> can be expressed as:
<disp-formula id="eqn18">
<graphic xlink:href="558214v1_eqn18.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="558214v1_inline41.gif" mimetype="image" mime-subtype="gif"/></inline-formula> encodes the probability that the node <italic>R</italic><sub><italic>j</italic></sub> will not respond to any of the activated input set ℋ <sub>ℳ</sub>, and the term
<disp-formula id="eqn19">
<graphic xlink:href="558214v1_eqn19.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
summarizes all edges originating from input nodes incident to node <italic>j</italic> in the context of the extended multitask set <inline-formula><inline-graphic xlink:href="558214v1_inline42.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The function <inline-formula><inline-graphic xlink:href="558214v1_inline43.gif" mimetype="image" mime-subtype="gif"/></inline-formula> then corresponds to the probability that node <italic>j</italic> responds (i.e. is activated) in the context of multitask <inline-formula><inline-graphic xlink:href="558214v1_inline44.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="558214v1_inline45.gif" mimetype="image" mime-subtype="gif"/></inline-formula> the probability that the input coming from the preceding node i is influenced by <italic>j</italic>.</p>
<p>Note that the difference between <xref ref-type="disp-formula" rid="eqn5">Eqs. 5</xref> and <xref ref-type="disp-formula" rid="eqn18">18</xref> is the dependence of <italic>Z</italic><sub><italic>j</italic></sub> on <inline-formula><inline-graphic xlink:href="558214v1_inline46.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, which in turn quantifies the effect of interference between shared representations among tasks.</p>
<p>Using <xref ref-type="disp-formula" rid="eqn18">Eq. 18</xref>, the performance cost of task <italic>f</italic><sub><italic>ij</italic></sub> in multitask ℳ is:
<disp-formula id="eqn20">
<graphic xlink:href="558214v1_eqn20.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
and thus the total performance cost of ℳ is:
<disp-formula id="eqn21">
<graphic xlink:href="558214v1_eqn21.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s3a1c">
<title>Examples</title>
<p>As an illustration of how <xref ref-type="disp-formula" rid="eqn21">Eq. 21</xref> can be used to quantify the multitasking performance of different task configurations, we apply it to the ones shown in <xref rid="fig5" ref-type="fig">Figure 5</xref> (we consider more complex examples in <xref ref-type="app" rid="app2">Appendix B</xref>). For the configuration shown in 5<italic>a</italic>, the two tasks are independent, and thus the multitask efficacy Ψ(ℳ) is simply the product of their individual efficacies, which can be computed using the expression for a single task (<xref ref-type="disp-formula" rid="eqn14">Eq. 14</xref>). However, for all of the other configurations, structural and/or functional dependence plays a role.</p>
<p>Configuration 5<italic>b</italic> shows a case in which two tasks (<italic>f</italic><sub>11</sub> and <italic>f</italic><sub>21</sub>) are structurally dependent due their shared response set (<italic>R</italic><sub>1</sub>). As a consequence, the individual efficacies of the two tasks,
<disp-formula id="eqn22">
<graphic xlink:href="558214v1_eqn22.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
are in tension. If one is stronger (i.e., has a higher <italic>ω</italic>) than the other, then that one will prevail to an extent determined by the asymmetry, and only one of the two tasks can be performed reliably, as in the case of color naming and word reading in the standard Stroop paradigm.</p>
<p>In configuration 5<italic>c</italic>, the two tasks are structurally dependent due to a shared <italic>stimulus</italic> set. As discussed above, this makes it impossible to independently choose stimuli for the two tasks, and thus only one of the two tasks can be performed at a given time.</p>
<p>Configuration 5<italic>d</italic> and <italic>e</italic> illustrate cases in which two tasks (<italic>f</italic><sub>11</sub> and <italic>f</italic><sub>22</sub>, shown in green and yellow, respectively) are <italic>structurally in</italic>dependent, but <italic>functionally</italic> dependent by way of either one (<italic>f</italic><sub>21</sub>) or two (also <italic>f</italic><sub>21</sub>) other tasks in the graph (shown in red). In these cases, even if a multitask is restricted to just tasks <italic>f</italic><sub>12</sub> and <italic>f</italic><sub>22</sub>, their efficacies suffer by an amount dependent on the strength of the task(s) responsible for their <italic>functional</italic> dependence. This is illustrated in <xref rid="fig6" ref-type="fig">Figure 6</xref>. The top panel plots the efficacies for tasks <italic>f</italic><sub>12</sub> and <italic>f</italic><sub>22</sub> in the configuration shown in 5<italic>d</italic>, as a function of the strength (<italic>ω</italic>) of task <italic>f</italic><sub>12</sub> responsible for the functional dependence between them. Since <italic>R</italic><sub>2</sub> is not shared, the efficacy of <italic>f</italic><sub>22</sub> is simply:</p>
<p>
<disp-formula id="eqn23">
<graphic xlink:href="558214v1_eqn23.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
which is unaffected by <italic>ω</italic><sub>21</sub>(flat yellow line in top panel of <xref rid="fig6" ref-type="fig">Figure 6</xref>). However, since <italic>R</italic><sub>1</sub> is shared between <italic>f</italic><sub>11</sub> and <italic>f</italic><sub>21</sub>, they are structurally dependent, and their efficacies are the same as those for the corresponding tasks shown task in <xref rid="fig5" ref-type="fig">Figure 5</xref><italic>b</italic>, given by <xref ref-type="disp-formula" rid="eqn22">Eq. 22</xref> (and plotted, respectively, as the green and red lines in the top panel of <xref rid="fig6" ref-type="fig">Figure 6</xref>): As <italic>ω</italic><sub>21</sub> increases, the efficacy of <italic>f</italic><sub>21</sub> increases, and thus the efficacy of <italic>f</italic><sub>12</sub> decreases. A similar pattern is seen for the configuration shown in <xref rid="fig5" ref-type="fig">Figure 5</xref><italic>e</italic>. However, in this case, since <italic>R</italic><sub>2</sub> is now shared between <italic>f</italic><sub>12</sub> and <italic>f</italic><sub>22</sub>, they too are now structurally dependent, and thus the efficacy for <italic>f</italic><sub>22</sub> is now also compromised (as is the additional task <italic>f</italic><sub>12</sub> in this configuration). Note that, since neither is dependent on ω<sub>21</sub>, they are not affected by it (i.e., their plot is flat, with the height determined by <italic>ω</italic><sub>12</sub> = <italic>ω</italic><sub>22</sub> = 1 used in this example. These results provide a formal account of previous simulation results with non-linear neural networks, demonstrating that increases in the strength of interfering tasks (e.g., via training), can negatively impact multitasking performance for functionally dependent tasks [<xref ref-type="bibr" rid="c20">20</xref>]. <xref ref-type="app" rid="app2">Appendix B</xref> provides a more detailed characterization of the efficacies in these different configurations.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Task efficacies in multitask settings.</title>
<p>Efficacies for individual tasks (calculated using <xref ref-type="disp-formula" rid="eqn18">Eq. 18</xref>) in the multitask settings shown in Figure 5<italic>d</italic> (reproduced in panel a) and 5<italic>e</italic> (reproduced in panel d), as a function of the strength (<italic>ω</italic>) of the tasks (shown in red) responsible for structural and/or functional interference in each configuration. Panels b) and c) refer to the configuration in panel a). Panels e) and f) refer to the configuration in panel d). The efficacy curves for each task are shown in the corresponding colors in the plots. For completeness and comparison with the bottom row, in the top row right panel we show also the curve for <italic>f</italic><sub>12</sub> although it is zero for all <italic>ω</italic><sub>21</sub> values. Note that in this case the presence of <italic>f</italic><sub>12</sub> changes the efficacy for <italic>f</italic><sub>22</sub>. For these examples, <italic>β</italic> = 1.2, <italic>ω</italic><sub>11</sub> = <italic>ω</italic><sub>22</sub> = 1, <italic>ω</italic><sub>12</sub> = .5.</p></caption>
<graphic xlink:href="558214v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3a2">
<label>2.</label>
<title>Multilayer Task Graphs</title>
<p>The three kinds of relationships between tasks— independence, structural dependence, and functional dependence—introduced above with respect to two-layered task graphs, can be extended to multilayered graphs (i.e., from bipartite to multipartite graphs), as shown in <xref rid="fig7" ref-type="fig">Figure 7</xref>. A pair of tasks is considered independent if their pathways do not share any nodes, nor are they linked by nodes of any other pathways in the graph (as shown by the green and orange paths in 7<italic>a</italic>); tasks are structurally dependent if they share any nodes (<xref rid="fig7" ref-type="fig">Fig. 7</xref><italic>b</italic>); and they are functionally dependent if they do not share any nodes directly (<xref rid="fig7" ref-type="fig">Fig. 7</xref><italic>c</italic>), but are linked by links of any other pathway in the graph.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Dependencies among task pathways in multilayered task graphs.</title>
<p>Examples of two task pathways (green and orange) in a task graph that also implements other task pathways (blue). Panels show configurations illustrating different dependency relationships between the green and orange pathways: a) independence; b) structural dependence, due to a shared node (outlined in red); c) functional dependence, due to other pathways that connect them (red dashed edges); and d) both types of dependence.</p></caption>
<graphic xlink:href="558214v1_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Note that, in the multipartite case, the dependence between a pair of tasks may not be limited to just structural or functional (e.g., 7<italic>b</italic> and 7<italic>c</italic>), but may involve both forms of dependence as shown in 7<italic>d</italic>. In general, the opportunities for dependence between tasks—and the attendant risks of interference—are considerably greater in a multilayered graph, that has been analyzed in previous work ([<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c32">32</xref>]). That work has similarly exploited the representation of neural networks in the form of task graphs, analyzed the consequences of structural and functional interference in terms of the matching and induced matching problems, and identified the maximum independent set as a way of determining the maximum number of independent tasks supported by the neural network. In particular, such work has shown that this number grows dramatically sublinearly with network size [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c16">16</xref>], including depth [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c32">32</xref>]. Our analysis reaffirms this observation, further suggesting that the effect of network depth is due largely to the increase in structural dependence (see <xref rid="fig8" ref-type="fig">Figure 8</xref>. Nevertheless, not surprisingly, functional dependence also remains a problem with deeper networks. Critically, and consistent with previous results, the combined effects of structural and functional dependence quickly become overwhelmingly prevalent, even for relatively shallow graphs (3-4 layers). This implies that, with an increase in the size of the graphs, the capacity for multitasking diminishes as the likelihood for cross-task interference grows, underscoring the importance of control to which we turn next.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Frequency of dependency types for multitasks as a function of graph depth.</title>
<p>Each point corresponds to the mean proportion (and its standard deviation) of multitasks composed by two tasks that are independent (white), structurally dependent (black), and functionally dependent (gray). Results are for 1000 simple graphs with 10 nodes per layer and edges between units across adjacent layers assigned uniformly at random, with a fixed density per layer pair. Note that the proportion of independent pairs rapidly decreases, and thus increases for dependent pairs with graph depth.</p></caption>
<graphic xlink:href="558214v1_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3b">
<label>B.</label>
<title>Control in Multitask Graphs</title>
<p>The characterization of different forms of dependencies above helps clarify the different roles that control can play in performance in multitask settings. First, we consider these qualitatively, and then use the framework introduced above to provide a formal analysis of the demands for control in such settings.</p>
<p>As discussed earlier, insofar as we are not concerned with reflexes, <italic>some</italic> allocation of control is required even for independent tasks, to “license” their execution by ensuring that activity in the corresponding output nodes is sufficient to overcome baseline inhibition (i.e., their thesholds for responding); that is, ∆<italic>β</italic> &gt; <italic>ω</italic> + <italic>β</italic>. Control may be required at internal layers for similar reasons, and to augment processing where a pathway is weak (small <italic>ω</italic>). Thus, while tasks that are independent can be safely multitasked, they nevertheless require <italic>some</italic> allocation of control. Insofar as the analysis of control in such cases does not need to take into account any interaction among tasks, it can be viewed as an extension of the analysis in [<xref ref-type="bibr" rid="c13">13</xref>] to multiple independent tasks.</p>
<p>In contrast, for tasks that are either structurally or functionally dependent, control is needed not only to augment task processing, but also to mitigate the risk of conflict and ensure that the desired task(s) can compete with any stronger ones—that is, ones with larger <italic>ω</italic> values—with which they are dependent for which stimuli are present in the environment. This aligns with the role of control in neural network models, such as the model of the Stroop effect discussed above ([<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c77">77</xref>, <xref ref-type="bibr" rid="c86">86</xref>]. However, such neural network models, while mechanistically explicit, have been largely descriptive. Here, we use the information theoretic approach outlined above to provide a more rigorous formal analysis of the need for control, that provides the foundation for a normative analysis of the tradeoff between automaticity and control that we consider further on.</p>
<p>Using the expressions, and the multitask graph = 𝒰 (𝒱 ε<sup><italic>l</italic></sup>, 𝒫<sup><italic>l</italic></sup>,) introduced above, we can extend <xref ref-type="disp-formula" rid="eqn18">Eq. 18</xref> to include the controlled efficacy of each task in a multitask ℳ as follows:
<disp-formula id="eqn24">
<graphic xlink:href="558214v1_eqn24.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Here, ℳ specifies the intended set of tasks, whereas <inline-formula><inline-graphic xlink:href="558214v1_inline47.gif" mimetype="image" mime-subtype="gif"/></inline-formula> specifies the full set of tasks that may be engaged by the presence of functional dependence among the tasks in ℳ, and that can degrade their performance.</p>
<p>Note that <xref ref-type="disp-formula" rid="eqn24">Eq. 24</xref> re-introduces the <italic>v</italic> control parameter, that appeared in the initial formulation of pathway efficacy (<xref ref-type="disp-formula" rid="eqn15">Eq. 15</xref>). We ignored it in the context of the single task graphs discussed above, as there it has effects that are qualitatively similar to (and trade off against) the effects of the <bold>∆<italic>β</italic></bold> parameter. In the context of multitask graphs, however, there is a subtle but important distinction between the effects of <bold>∆<italic>β</italic></bold> and <italic>v</italic>.</p>
<p>As discussed in Section II D, <bold>∆<italic>β</italic></bold> regulates the overall responsivity of a node (by offsetting its inhibitory bias β), which is required in some amount to perform any task (except reflexes; see Section II A), and can be used to support the performance of ones that rely on weak pathways (or, as we discuss below, competition with tasks that rely on stronger pathways). In these respects, <bold>∆<italic>β</italic></bold> can be thought of as reflecting a <italic>selective</italic> form of control, inasmuch as it licenses the execution of a specified task. This aligns with the assumption that the <bold>∆<italic>β</italic></bold> parameters reflect the effect of learned control signals projecting to each processing node, mimicking the processing bias of task units in neural network models of control-dependent processing (e.g., [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c79">79</xref>]).</p>
<p>In contrast <italic>v</italic> implements a strictly <italic>modulatory</italic> form of control, by modifying the sensitivity of the node to differences among its inputs. Critically, as <italic>v</italic> → 0, not only does the node become less discriminative, but it also becomes <italic>more</italic> likely to be active by chance (viz. with probability 0.5) irrespective of its <bold>∆<italic>β</italic></bold> or ω parameters. [<xref ref-type="bibr" rid="c131">131</xref>] This would, of course, be deleterious when the <bold>∆<italic>β</italic></bold> and/or ω parameters can be used effectively to implement a desired task. Under such conditions, increasing <italic>v</italic> can actually serve to <italic>exploit</italic> (i.e., further reinforce) their effects. However, for cases in which appropriate values of <bold>∆<italic>β</italic></bold> and/or ω are <italic>not</italic> available to perform a given task (e.g., they have not yet been learned), <italic>reducing v</italic> can actually serve to increase the likelihood of performing that task (i.e., by chance). This can be thought of as supporting exploration, which can be valuable for discovery and learning [<xref ref-type="bibr" rid="c88">88</xref>–<xref ref-type="bibr" rid="c91">91</xref>]. Gain modulation of this sort has been proposed as a model of the effects of neuromodulatory neurotransmitters [<xref ref-type="bibr" rid="c92">92</xref>], and of norepinephrine in particular, in regulating the balance between exploitation and exploration [<xref ref-type="bibr" rid="c91">91</xref>, <xref ref-type="bibr" rid="c93">93</xref>]. Since the timing of such neuromodulatory effects can be relatively precise [<xref ref-type="bibr" rid="c94">94</xref>, <xref ref-type="bibr" rid="c95">95</xref>], although somewhat topographically diffuse [<xref ref-type="bibr" rid="c91">91</xref>], we assume that, while the <italic>v</italic> parameter can vary freely over time and can be modulated across nodes. It also important to note that the modulatory effects of <bold><italic>v</italic></bold> described above are relevant only in the context of multiple tasks because they describe a competition between tasks of different strenghts, at a given level of inhibition (<bold>∆<italic>β</italic></bold>), whereas when only one task is present the effect of <bold><italic>v</italic></bold> can be reabsorbed in the <bold>∆<italic>β</italic></bold>.</p>
<p>To consider how the control parameters <bold>∆<italic>β</italic></bold> and <italic>v</italic> interact and can be optimized to perform multiple tasks, <xref rid="fig9" ref-type="fig">Figure 9</xref> shows an example of a task graph for a network with a multitask combination ℳ composed of two pathways (shown in orange and green). In this case, the corresponding <inline-formula><inline-graphic xlink:href="558214v1_inline48.gif" mimetype="image" mime-subtype="gif"/></inline-formula> contains two additional mappings (shown as red edges) that introduce functional dependence and thus the potential for interference between the tasks constituting the desired multitask. In the case of strictly automatic processing considered above (see <xref ref-type="disp-formula" rid="eqn18">Eq. 18</xref>), the interference effects are determined fully by the ω<sub><italic>ij</italic></sub>’s for the pathways in <inline-formula><inline-graphic xlink:href="558214v1_inline49.gif" mimetype="image" mime-subtype="gif"/></inline-formula> responsible for functional dependence among the tasks ℳ in to be performed. However, the ∆β and <italic>v</italic> terms introduced in <xref ref-type="disp-formula" rid="eqn24">Eq. 24</xref>, representing the effects of control, can be used to mitigate interference by modulating processing in the relevant pathways: These can be used to attenuate and/or eliminate processing along some pathways, restricting performance to only a subset of tasks or, in the limit, a single task within ℳ at a time. Based on <xref ref-type="disp-formula" rid="eqn24">Eq. 24</xref>, the control policy (i.e., set of <bold>∆<italic>β</italic></bold> and <italic>v</italic> terms) that optimizes performance relative to strictly automatic processing can be determined, for a single-layered graph, as follows:</p>
<p>
<disp-formula id="eqn25">
<graphic xlink:href="558214v1_eqn25.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This can be further generalized to address a full multilayer graph, 𝒰, by calculating the product of the efficacies of each task pathway, <italic>P</italic> in ℳ and, once again, taking into account the extended multitask <inline-formula><inline-graphic xlink:href="558214v1_inline50.gif" mimetype="image" mime-subtype="gif"/></inline-formula> induced by any functional independence among those <italic>P</italic>’s:
<disp-formula id="eqn26">
<graphic xlink:href="558214v1_eqn26.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>i, j</italic> label tasks in <italic>P</italic> (mapping stimulus set <italic>i</italic> to response set <italic>j</italic>). The overall efficacy of ℳ is thus:
<disp-formula id="eqn27">
<graphic xlink:href="558214v1_eqn27.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The corresponding multitask performance cost is then:
<disp-formula id="eqn28">
<graphic xlink:href="558214v1_eqn28.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
and the amount by which control and adaptive weights can modulate the interference in a multitask ℳ as:
<disp-formula id="eqn29">
<graphic xlink:href="558214v1_eqn29.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
To illustrate how the expressions introduced above can be used to determine an optimal control policy for different graph configurations, we consider simple cases in which each task has only two possible values for the weights of the edges along its pathway, a strong one (ω=S) and a weaker one (ω=W). Specifically, we focus on multitasks involving functionally dependent tasks with two different patterns of pathway strengths: one in which the task pathways are composed of a mixture of strong and weak edges (SW; <xref rid="fig10" ref-type="fig">Figure 10a</xref>), and another in which all of the edges are similarly weak (WW; <xref rid="fig10" ref-type="fig">Figure 10b</xref>).</p>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9.</label>
<caption><title>Pathway selection in a multitask graph.</title>
<p>a) The full task graph for a multitask graph, 𝒰, showing the pathways (in orange and green) for two tasks in a specified multitask, ℳ, and the mappings for other tasks that introduce functional dependence between them (shown in red) and others that do not pose a risk of conflict (shown in blue). b) The pathways in the graph relevant for the multitask ℳ constituted by the two highlighted paths (orange and green, respectively) plus the edges in red, which are included in <inline-formula><inline-graphic xlink:href="558214v1_inline60.gif" mimetype="image" mime-subtype="gif"/></inline-formula> due to the presence of functional dependence and irrelevant pathways (faded).</p></caption>
<graphic xlink:href="558214v1_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure 10.</label>
<caption><title>Examples of multitasks involving dependent tasks with different patterns of pathway strengths.</title>
<p>Two multitask configurations, ℳ, each involving two tasks (orange and green pathways): a) the two pathways are composed of a mixture of stronger and weaker edges (SW in text), or b) the two pathways are composed of edges all of which have weak weights (WW in text). In both cases, the two tasks in ℳ are functionally dependent as result of the another pathway (red dashed edges) constituting <inline-formula><inline-graphic xlink:href="558214v1_inline61.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p></caption>
<graphic xlink:href="558214v1_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref rid="fig11" ref-type="fig">Figure 11</xref> shows the automatic processing costs Ψ (dark points) and controlled processing costs Ψ<sup>∗</sup> (lighter points) for a large sample of pair-wise multitasks for the WW and SW cases in graphs of varying depth (from 3 to 8). Controlled processing costs were computed by optimizing the parameters (β, <italic>v</italic>) to minimize cost. As expected, allocation of control, improves the efficacy of processing by reducing performance costs: these are consistently lower in the controlled than the automatic condition in graphs of all sizes for both the WW (<xref rid="fig11" ref-type="fig">Figure 11a</xref>) and SW (<xref rid="fig11" ref-type="fig">Figure 11b</xref>) types of task pairs. Interestingly, the Ψ’s for multitasking pathways with similarly weak weights (WW, 11a) are much greater (performance is worse) than for ones with a mixture of strong and weak weights (SW, 11b). Nevertheless, even in the conditions showing the best performance (SW in graph with 3 layers), in no case can Ψ<sup>∗</sup> be brought to zero. This is the result of functional dependence among the pathways; that is, the interference associated with functional dependence can be mitigated, but not entirely eliminated by control [<xref ref-type="bibr" rid="c132">132</xref>].</p>
<fig id="fig11" position="float" fig-type="figure">
<label>Figure 11.</label>
<caption><title>Performance costs for multitasks involving tasks with different relative strengths.</title>
<p>Performance costs (automatic: Ψ; control-optimized: Ψ<sup>∗</sup>) for multitasking pairs of tasks chosen to have: a) both strong and weak pathways (SW; see example in <xref rid="fig10" ref-type="fig">Fig. 10a</xref>); and b) only weak pathways (WW; see example in <xref rid="fig10" ref-type="fig">Fig. 10b</xref>). In each case, performance costs are shown for strictly automatic execution (darker points) and control-optimized execution (lighter points). Note that, for graphs of all sizes, costs are less (performance efficacy is greater) for SW pairs relative to WW pairs, both for automatic and control-optimized execution. However, c) the <italic>fractional</italic> reduction in performance cost (i.e., improvement in efficacy) as a function of control, given by <xref ref-type="disp-formula" rid="eqn30">Eq. 30</xref>), is considerably greater for WW (violet and light blue) as compared to SW pairs (SW; red and orange), although SW pairs exhibit greater variance in this effect.</p></caption>
<graphic xlink:href="558214v1_fig11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>It is also interesting to note that, even though multitasking performance is overall better for SW pairs (including in the controlled conditions), the <italic>fractional reduction in performance cost (i</italic>.<italic>e</italic>., <italic>improvement in efficacy</italic> achieved by the allocation of control, calculated as:
<disp-formula id="eqn30">
<graphic xlink:href="558214v1_eqn30.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
is substantially greater for WW pairs, as shown in <xref rid="fig11" ref-type="fig">Figure 11c</xref> (red points consistently higher than violet ones). This suggests that, although similarly weighted pathways tend to interfere more, their dependency can be modulated effectively by control, and that this holds irrespective of graph depth (Kruscal <italic>s</italic> = 35.1, <italic>p</italic> &lt; 10<sup>−3</sup> for WW, Kruscal <italic>s</italic> = 10.1, <italic>p</italic> &lt; 10<sup>−3</sup> for SW), although the variance in δΨ is greater for SW pairs (Levene test on paired distributions (F &gt; 19 df 1 = 2, df 2 = 60, <italic>p</italic> &lt; 10<sup>−4</sup> for all comparisons) and seems to decrease with graph depth. These effects can also be seen in the distributions of control parameters for the various configurations, shown in <xref rid="fig12" ref-type="fig">Figure 12</xref>: for WW pairs, the optimized ∆β<sup>∗</sup> values are distributed toward the upper limit of the range allowed, presumably because they have a substantial impact on cost; whereas for SW pairs they are smaller and more heterogeneous. Conversely, the <italic>v</italic><sup>∗</sup> values for the WW cases tend to take extreme values (0 and 2), while for SW we find a finer modulation of values between 1 and 2. This suggests that optimizing control for SW cases requires identifying more complex configurations of control signals (with greater information), in that SW cases require finer-grained adjustments to optimize performance, compared to WW cases, in which control is allocated more in a more binary (all-or-none) fashion, splitting between high <italic>v</italic><sup>∗</sup> values that amplify the effects of control, and low values that relegate the outcome of performance to pathway strengths in the absence of control (i.e., the effects of automaticity).</p>
<fig id="fig12" position="float" fig-type="figure">
<label>Figure 12.</label>
<caption><title>Differences in optimal control policies.</title>
<p>Distributions of optimal control parameter sets <italic>{</italic>Δ<italic>β</italic><sup>∗</sup><italic>}</italic> (panel a) and <italic>{ν</italic><sup>∗</sup><italic>}</italic> (panel b) for the WW and SW cases.</p></caption>
<graphic xlink:href="558214v1_fig12.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s4">
<label>IV.</label>
<title>The tradeoff between automatization and control</title>
<p>The framework introduced above permits quantification of the efficacies of automatic and controlled-based performance for sets of tasks given a neural network architecture used to perform them. The formulations we described all held the {<bold><italic>β</italic>}</bold> (intrinsic inhibition) and {<bold><italic>ω</italic>}</bold> (connection weight) parameters constant under the assumption that, to the extent that these are modifiable, they change at a much slower rate than the control parameters, {<bold>∆<italic>β</italic>}</bold> and {<bold><italic>v</italic>}</bold> . This is consonant with the widely held assumption that mechanisms of control are responsible for the short-term flexibility of human behavior. However, humans are of course also capable of remarkable flexibility over longer terms as well, including the ability to dramatically improve performance on tasks through practice, transitioning from what was initially a laborious and inefficient form of control-dependent processing to more fluid and automatic forms of processing. For example, a person who has never used a keyboard can quickly begin to type using one finger at time. However, while this exhibits remarkable flexibility (e.g., any finger can be used, and anything can be typed), it is also inefficient, something that can be overcome with sufficient time spent learning to touch type.</p>
<p>As discussed in the Introduction, the reliance on control for newly acquired skills, and the transition from control-dependent to automatic processing with practice, are some of the most widely recognized and studied phenomena in cognitive science [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c40">40</xref>]. Various models have been proposed that provide a mechanistic account of this transition [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c97">97</xref>, <xref ref-type="bibr" rid="c98">98</xref>], including recent work that has begun to address this from a strategic perspective [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c50">50</xref>]; that is, how and when people decide to invest the time and effort to transition from control-dependent to automatic processing? The framework outlined above lays the foundation for a mathematically rigorous, normative answer to this question. In addition to addressing how control may be optimized for performing a set of tasks that are dependent on control (as formulated in the preceding section), it also allows us to determine whether and when the system should exploit the immediate benefits of control-dependent processing (through rapid adjustment of {<bold>∆<italic>β</italic>}</bold> and {<bold><italic>v</italic>}</bold>), at the cost of efficiency due to functional dependence, or seek to improve efficiency by restructuring the graph to strengthen and/or develop task-dedicated pathways that afford parallel processing (through the slower adjustment of {<bold><italic>ω</italic>}</bold>), but at the cost of the time and effort required by the training to do so.</p>
<p>Below, we formalize this optimization with respect to a given graph architecture, a set of tasks to be performed, a finite horizon over which reward is to be optimized, and the relative speed with which the {<bold>∆<italic>β</italic></bold>} and {<bold><italic>v</italic></bold>} versus {<bold><italic>ω</italic></bold>} parameters can be adjusted.</p>
<sec id="s4a">
<label>A.</label>
<title>Tradeoff Between Current Serial and Future Parallel Execution</title>
<p>The optimization problem outlined above can be framed as one of finding the control policies and/or investments in automatization for a given set of tasks, over a specified period of time, that maximize total cumulative reward (or, alternatively, average reward rate). For a given graph, the set of tasks to be performed can be considered as a multitask, ℳ, that must be performed in the context of an extended multitask <inline-formula><inline-graphic xlink:href="558214v1_inline51.gif" mimetype="image" mime-subtype="gif"/></inline-formula> that includes any other tasks defined by the graph’s architecture that induce functional dependence among the tasks in ℳ. Of course, at any point in time, the environment and/or internal needs of the agent may render some subsets of tasks in ℳ more viable and/or desirable than others (e.g., depending on whether the relevant stimuli are present, actions are possible, and/or results are presently valued); those subsets, in turn, will be associated with different extended multitasks. These are critical factors for addressing the complexity of any real-world scenarios and agents, an issue to which we return in the Discussion.</p>
<p>Here, as a tractable starting point, we assume a stationary environment in which all tasks are uniformly viable and desirable. Accordingly, executing as many as possible, as reliably, and as frequently as possible will yield the greatest rewards. However, as the preceding analyses make clear, the extent to which this can be achieved depends on the graph architecture—that is, its {<bold><italic>β</italic>}</bold> and {<bold><italic>ω</italic>}</bold> automaticity parameters. In the extreme, if all tasks are independent, they can all be performed in parallel, and the only constraints on reward rate are the environment and the speed with which the tasks can be performed—that is, the absolute values of the automaticity parameters for each task [<xref ref-type="bibr" rid="c133">133</xref>]. Conversely, if all pairwise combinations of tasks are either structurally or functionally dependent, then only <italic>one</italic> can be performed reliably at a time; that is, performance is constrained to be serial, and the reward rate is directly proportional to the number of tasks in ℳ. What is less clear is the optimal policy for graph architectures that fall somewhere between these two extremes; that is, in which some combinations of tasks can be safely parallelized, but others cannot. For such a graph structure, and a set of tasks to be performed, the question is: How can those tasks best be combined into multitask subsets, such that the tasks within each subset are as independent as possible (i.e., have high multitasking efficacy) and can thus be executed effectively in parallel, while the subsets are executed in series to avoid conflict among tasks that are dependent on one another. Below, we formalize this partitioning, and the overall efficacy of performance it yields, and use this to quantify the best performance that can be achieved for a specified set of tasks in a given graph architecture. In the section that follows, we then show how this can be used to address the tradeoff between automaticity and control, by comparing the current performance efficacy of a graph against the benefits of improving its efficacy by modifying its structure to diminish dependence among the specified tasks, weighed against the costs (in time, and thus average reward rate) of doing so.</p>
<sec id="s4a1">
<title>Optimization of multitasking covers</title>
<p>The optimal execution of multiple tasks may be achieved by varying the degree of serialization in a continuous manner, from time step to time step [<xref ref-type="bibr" rid="c54">54</xref>]. To ease formal analysis, we consider cases in which an agent either fully serializes or parallelizes tasks for execution. We begin by defining a multitask ℳ containing tasks 𝒯 to performed, and seek a cover, Θ, of the tasks 𝒯 in ℳ, that divides them into subsets Θ<sub><italic>i</italic></sub> such that Θ<sub><italic>i</italic></sub> ∩ Θ<sub><italic>j</italic></sub> = ∅ for all i, j and the union ∪<sub><italic>i</italic></sub> Θ<sub><italic>i</italic></sub> = <italic>T</italic> . Denoting Θ<sub><italic>i</italic></sub> = |Θ<sub><italic>i</italic></sub>|, we have that Σ<sub><italic>i</italic></sub> Θ<sub><italic>i</italic></sub> = Θ. Thus, the cover Θ corresponds to a collection of subsets of tasks (Θ<sub><italic>i</italic></sub>’s) formed by dividing all of the tasks in ℳ into <italic>s</italic> disjoint subsets (with the index s starting at 1, as there is always at least one set in Θ), such that every task in ℳ belongs to one and only one Θ<sub><italic>i</italic></sub>. The tasks in each Θ<sub><italic>i</italic></sub> are considered a multitask (i.e., they are executed at the same time), while the Θ<sub><italic>i</italic></sub>’s will be executed serially. Accordingly, the goal is to construct Θ such that overall processing efficacy is maximized, by maximizing the multitasking efficacy for each subset Θ<sub><italic>i</italic></sub> (given by the automaticity parameters of tasks in the subset, and the optimal control policy for that multitask, as described in Section III) and minimizing the total number of Θ<sub><italic>i</italic></sub>’s to reduce serialization costs and thereby maximize reward rate.</p>
<p>The overall efficacy of a cover Θ can be expressed as:
<disp-formula id="eqn31">
<graphic xlink:href="558214v1_eqn31.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where the <sup>∗</sup> represents optimized parameters. Furthermore, we can express the reward rate associated with Θ as:
<disp-formula id="eqn32">
<graphic xlink:href="558214v1_eqn32.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in which the denominator describes the overall time it takes to execute the full set of Θ<sub><italic>i</italic></sub>’s in Θ. The first term in the denominator, S, includes the number s of sets in Θ that contribute directly to the serialization cost. S also includes two additional terms: <inline-formula><inline-graphic xlink:href="558214v1_inline52.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, which denotes the execution time of the slowest task in each of the Θ<sub><italic>i</italic></sub>’s; and R(Θ, t), that denotes the total time required for switching between performing different task subsets (Θ<sub><italic>i</italic></sub>’s), which may involve both the regulation of control parameters [<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c46">46</xref>] as well as passive processes associated with the updating of task sets [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c31">31</xref>]. Thus, these terms reflect the aggregated effects of dynamics of performance of individual tasks (Θ<sub><italic>t</italic></sub> in <italic>S</italic>) and switching between subsets of tasks (<italic>R</italic>(Θ, <italic>s</italic>), respectively. Although our preceding analysis of performance for individual tasks and multitasks ignored these effects (see Note V D), here we include them as we are now interested in the reward <italic>rate</italic> associated with the performance of <italic>sequences</italic> of tasks and/or multitasks. Thus, while the effects for individual tasks or multitasks may be relatively small, they may accumulate over sequential executions.</p>
<p>Note that the efficacy <italic>P</italic>[Θ, <italic>s</italic>] can be re-written explicitly in terms of accuracy, by replacing <italic>p</italic>[Θ<sub><italic>i</italic></sub> | ∆<italic>β</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>i</italic></sub>] in <xref ref-type="disp-formula" rid="eqn31">Eq. 31</xref> with 1 − ER(Θ<sub><italic>i</italic></sub>), where ER is error rate. Accordingly, <xref ref-type="disp-formula" rid="eqn32">Eq. 32</xref> can be expressed in the more familiar form of a reward rate [<xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c100">100</xref>]:
<disp-formula id="eqn33">
<graphic xlink:href="558214v1_eqn33.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Thus, maximizing Φ(Θ, s) is equivalent to maximizing reward rate. Φ(Θ, s) in <xref ref-type="disp-formula" rid="eqn33">Eq. 33</xref> can also be re-expressed in terms of costs, similar to Ψ, as:
<disp-formula id="eqn34">
<graphic xlink:href="558214v1_eqn34.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This is useful for considering Φ in graph theoretic terms, that in turn, provides a useful approach to the optimization problem. For example, an ideal cover, Θ, would be composed exclusively of Θ<sub><italic>i</italic></sub> each of which is a subset of tasks that are independent of one another, constituting multitasks that can be performed entirely in parallel without any allocation of control. In that case, <xref ref-type="disp-formula" rid="eqn34">Eq. 34</xref> can be reduced so that Φ[Θ, s] depends only on the serialization and switch costs:
<disp-formula id="eqn35">
<graphic xlink:href="558214v1_eqn35.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
A cover comprised exclusively of subsets of tasks that are independent of one another in the interference graph for the task graph represents a <italic>coloring</italic> [<xref ref-type="bibr" rid="c101">101</xref>], and thus the optimal Θ corresponds to a minimal graph coloring of the interference graph for ℳ. Previous work [<xref ref-type="bibr" rid="c19">19</xref>] reports an approach to solving this problem. This formal treatment of partial task serialization relates closely to the optimal scheduling of task processes in symbolic processing architectures [<xref ref-type="bibr" rid="c83">83</xref>, <xref ref-type="bibr" rid="c84">84</xref>].</p>
<p><italic>Example</italic></p>
<p>As an illustration of how the formalisms introduced above can be used to find the optimal cover for a given graph configuration, <xref rid="fig13" ref-type="fig">Figure 13</xref> shows the results of numerically optimizing Φ over multitasks comprised of three tasks with different types of pathways and in graphs of different depths, taking into account both the costs of control and serialization. Graphs and task sets of each type were constructed and, for each, <xref ref-type="disp-formula" rid="eqn33">Eq. 33</xref> was used to compute Φ for each of the three possible types of cover Θ for the three tasks in multitask ℳ: a single set, such that all three tasks are performed simultaneously (3 <italic>tasks</italic>); two Θ<sub><italic>i</italic></sub> subsets, in which two of the tasks are performed simultaneously and one on its own (2 + 1 <italic>tasks</italic>); and three Θ<sub><italic>i</italic></sub> subsets, each containing a single task, so that the tasks in ℳ are all performed serially (1 + 1 + 1 <italic>tasks</italic>). The plots in <xref rid="fig13" ref-type="fig">Figure 13</xref> show the frequency of each type of cover for different graph depths and types of task combinations. Note that as graphs become deeper, and thus the likelihood of dependencies increases (<xref rid="fig8" ref-type="fig">Fig. 8</xref>), the optimal serialization strategies shift from full multitasking (3 <italic>tasks</italic>) to intermediate (2+1 <italic>tasks</italic>) or full serialization (1 + 1 + 1 <italic>tasks</italic>). Similarly, sets composed of weaker tasks (13b) are associated with a shift toward greater serialization as compared to those with strong tasks (13b), reflecting both increased processing costs and the greater likelihood of interference with multitasking.</p>
<fig id="fig13" position="float" fig-type="figure">
<label>Figure 13.</label>
<caption><title>Optimal serialization for three tasks.</title>
<p>Frequency of types of partitioning of three tasks into subsets (Θ<sub><italic>i</italic></sub> covers) to minimize overall performance cost Ψ (i.e., optimize efficacy) in graphs of various depths (3-7 layers), in which the balance of strength among the three tasks is varied in a manner similar to <xref rid="fig12" ref-type="fig">Figure 12</xref>: a) two strong and one weak; or b) one strong and two weak. Each plot shows the frequency with which each type of partitioning of the three tasks (cover Θ<sub><italic>i</italic></sub>) yields the best Ψ: all tasks in a single set and thus executed in parallel (3 <italic>tasks</italic>); two tasks in one subset executed in parallel, and in series with the remaining task executed on its own (2 + 1 <italic>tasks</italic>); or all three tasks executed in series (1 + 1 + 1 <italic>tasks</italic>). Results were obtained from 1000 graph instances for each depth, with randomly assigned weights and sets of tasks of each type chosen from them.</p></caption>
<graphic xlink:href="558214v1_fig13.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s4b">
<label>B.</label>
<title>Joint Optimization of Control and Automatization</title>
<p>The optimization described in the previous section sought to partition a set of tasks in a multitask ℳ into a cover Θ comprised of one or more subsets of tasks that are as mutually independent as possible. The extent to which this is possible is constrained by the graph structure, including the relative strengths of the pathways for the tasks in ℳ, as illustrated in <xref rid="fig13" ref-type="fig">Figure 13</xref>. Alternatively, Φ (and thus reward rate) could be maximized for a given by ℳ modifying the graph structure itself; that is, by modifying the <bold><italic>ω</italic></bold> for the tasks in so as to make them more independent of one another, and thus more effectively executed in parallel. As discussed earlier, we assume that the <bold><italic>ω</italic></bold> can be modified over the course of learning, which occurs at a much slower time scale than adaptation of the control parameters, <bold>Δ<italic>β</italic></bold> and <bold><italic>ν</italic></bold> parameters used to implement the Θ for a given ℳ. This formalizes the tradeoff between reliance on control-dependent processing and the acquisition of automaticity as an intertemporal choice: For a given time horizon and multitask ℳ, is it preferable to pay the cost of control-dependent processing (i.e., constrained Φ) for the current graph structure, or to pay the cost of increasing Φ by modifying the relevant <italic>ω</italic>s to afford better multitasking and thereby permit a better Θ (and therefore Φ). Which is preferable will, of course, depend on the probability distribution of the tasks in ℳ, and their corresponding reward values.</p>
<p>To formalize this tradeoff, we can refine the definition of Φ to include the structure of the graph at a given time <italic>t</italic> as <italic>ω</italic>(<italic>t</italic>), and Φ = Φ[Θ, <italic>s, ω</italic>(<italic>t</italic>)], which can change with time as a function of learning. Then, over a horizon of total time <italic>T</italic>, the cumulative reward is given as the integral:
<disp-formula id="eqn36">
<graphic xlink:href="558214v1_eqn36.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>ρ</italic>(ℳ)(<italic>t</italic>) is the probability at time <italic>t</italic> of encountering the task set ℳ, which the agent can perform optimally using the task cover Θ, and the average reward rate is <inline-formula><inline-graphic xlink:href="558214v1_inline53.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p>Importantly, the total time <italic>T</italic> can be split into two contributions, <italic>T</italic> = <italic>T</italic><sub><italic>exec</italic></sub> + <italic>T</italic><sub><italic>learning</italic></sub>. The first component, <italic>T</italic><sub><italic>exec</italic></sub>, accounts for all the task execution times, and is, therefore, a function of: i) the distribution of tasks in the environment (<italic>ρ</italic>); ii) the pattern of (in)dependence among those tasks as determined by the temporally evolving <bold><italic>ω</italic>(<italic>t</italic>)</bold> that determines both the optimal cover Θ; and iii) the corresponding serialization and reconfiguration times (<italic>S</italic> and <italic>R</italic>). The second component, <italic>T</italic><sub><italic>learning</italic></sub>, accounts for the time required to adapt <bold><italic>ω</italic></bold>, that results in a temporal trajectory of <italic>ω</italic> configurations <inline-formula><inline-graphic xlink:href="558214v1_inline54.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p>Given this formulation, the strategy that maximizes <italic>R</italic> depends on two critical factors: the rate at which {<bold><italic>ω}</italic></bold> s can adapt, and the time horizon <italic>T</italic> over which optimization is sought. The former is determined by the learning rate, that we assume is intrinsic to the system and/or task, while the latter is determined by the environment. In general, it is easy to see that both faster learning rates and longer time horizons will favor the acquisition of automaticity, as it provides more time to benefit from the investment in learning {<bold><italic>ω}</italic></bold> s that maximize independence among tasks and thus permit parallel execution of task combinations in ℳ. However, whether this is the optimal policy (i.e., maximizes <italic>R</italic>) will depend on the actual learning rate[<xref ref-type="bibr" rid="c134">134</xref>] and time horizon. Furthermore, it will also depend on the value of continuing to rely on control-dependent processing, which provides more immediate reward, albeit less than what could be achieved in the same circumstances once automaticity has been achieved. For example, if the time horizon is sufficiently short relative to the learning rate, such that <italic>T</italic><sub><italic>learning</italic></sub> <italic>&lt; T</italic><sub><italic>exec</italic></sub>, then the investment in acquiring automaticity will not be worth more than the value of continued reliance on control (e.g., it may not be worth learning to touch type just to write a single essay). However, for longer time horizons, the relative values may reverse (e.g., if the goal is to make a living as a stenographer). That is, choosing between control-dependent processing versus the acquisition of automaticity is an intertemporal choice that is determined by the relative values of <italic>T</italic><sub><italic>exec</italic></sub> and <italic>T</italic><sub><italic>learning</italic></sub>.</p>
<p>Previous work has described how the tradeoff between control and automaticity may be optimized in the context of specific learning algorithms and neural network architectures [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c50">50</xref>]. The formulation outlined above provides a more general framing of the problem. While a full solution may be demanding, and potentially intractable for realistically complex conditions, below we illustrate how, with some simplifying assumptions the formulation can be used to analyze the trade-offs between control and automaticity in order to maximize <italic>R</italic>. This may serve as an example of how natural agents, using heuristics, may make similar computations, and how artificial systems might be designed to do the same.</p>
<sec id="s4b1">
<title>Automatization in the extended Stroop task</title>
<p>As an illustration, we consider the case of the extended Stroop task (see <xref rid="fig2" ref-type="fig">Figure 2b</xref>), in which word pointing and color naming are initially functionally dependent but, with practice, automaticity can be acquired for word pointing, allowing it to be performed in parallel (i.e., multi-tasked) with color naming. This can be accomplished by learning a new set of associations for word pointing that can be used to map word stimuli (<italic>S</italic><sub>2</sub>) to manual responses (<italic>R</italic><sub>2</sub>), but that are mediated by internal representations (shown as <italic>H</italic><sub>3</sub> in <xref rid="fig14" ref-type="fig">Figure 14a</xref>) that are distinct from those used for word reading (<italic>H</italic><sub>2</sub>). That is, with learning, <italic>H</italic><sub>3</sub> can be used to strengthen a latent (weak) pathway [<xref ref-type="bibr" rid="c135">135</xref>] and/or form a new one (<italic>T</italic><sub>3</sub>(<italic>S</italic><sub>2</sub> <italic>H</italic><sub>3</sub> <italic>R</italic><sub>2</sub>) that is fully independent of the color naming pathway (<italic>T</italic><sub>1</sub> = {<italic>S</italic><sub>1</sub> <italic>→ H</italic><sub>1</sub> <italic>→ R</italic><sub>1</sub>}, and thus allow word pointing to be performed in parallel. We assume that <italic>T</italic><sub>3</sub> starts with small initial weights (i.e., small <bold><italic>ω</italic></bold> s for <italic>S</italic><sub>2</sub> <italic>→ H</italic><sub>3</sub> and <italic>H</italic><sub>3</sub> <italic>→ R</italic><sub>2</sub>), but that these can be made stronger with practice on the word pointing task as they are updated with learning rate λ.</p>
<fig id="fig14" position="float" fig-type="figure">
<label>Figure 14.</label>
<caption><title>Total cumulative reward accrued under different automatization policies in the extended Stroop task and fixed learning rate of <italic>λ</italic> = .001.</title>
<p>a) Task graph for the extended Stroop task (based on the graph shown in <xref rid="fig2" ref-type="fig">Figure 2b</xref>) in which color naming relies on <italic>S</italic><sub>1</sub> <italic>→ H</italic><sub>1</sub> <italic>→ R</italic><sub>1</sub> (<italic>T</italic><sub>1</sub>) and word pointing on <italic>S</italic><sub>2</sub> <italic>→ H</italic><sub>2</sub> <italic>→ R</italic><sub>2</sub> (<italic>T</italic><sub>2</sub>, with functional dependence induced by word reading due to edge <italic>H</italic><sub>2</sub> <italic>→ R</italic><sub>1</sub>); but here with the addition of internal representation node (<italic>H</italic><sub>3</sub>) that provides an alternative, initially weak pathway for word pointing, <italic>S</italic><sub>2</sub> <italic>→ H</italic><sub>3</sub> <italic>→ R</italic><sub>2</sub> (<italic>T</italic><sub>3</sub>), that is independent of the color naming pathway <italic>T</italic><sub>1</sub>. b) Plots of the total accumulated reward (<italic>R</italic>) over executions (proportional to <italic>T</italic>) for different practice policies (see text for description). Note that <italic>R</italic> is expressed in log units, and thus linear accumulation of reward (e.g., in the <italic>no practice</italic> condition) follows a standard logarithmic form.</p></caption>
<graphic xlink:href="558214v1_fig14.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To quantify this, we consider the case in which the agent is confronted with repeatedly performing the color naming and word pointing tasks, and thus performing either {<italic>T</italic><sub>1</sub>, <italic>T</italic><sub>2</sub>}(constrained by serial performance) or {<italic>T</italic><sub>1</sub>, <italic>T</italic><sub>3</sub>}(which permits parallel performance, but must be acquired through practice). <xref rid="fig14" ref-type="fig">Figure 14b</xref> shows the total accrued reward ℛas a function of time (i.e., number of executions of the two tasks) under four policies that vary with respect to whether and how {<italic>T</italic><sub>1</sub>, <italic>T</italic><sub>3</sub>}is “practiced:”</p>
<list list-type="bullet">
<list-item><p><italic>no multitasking practice</italic>: this serves as a baseline, in which learning rate λ = 0, performance of the word pointing task relies exclusively on the existing set of word representations (i.e., pathway <italic>T</italic><sub>2</sub>), and word pointing and color naming continue to rely on control for serial execution of {<italic>T</italic><sub>1</sub>, <italic>T</italic><sub>2</sub>}(blue solid line).</p></list-item>
<list-item><p><italic>simple probabilistic multitasking practice</italic>: {<italic>T</italic><sub>1</sub>, <italic>T</italic><sub>3</sub>}is performed with a probability <italic>p</italic> (i.e., executing word pointing using <italic>T</italic><sub>3</sub> in parallel with color naming is practiced with this probability, in this case we adopted <italic>p</italic> = 0.2). Although performance is poor early on, <italic>T</italic><sub>3</sub> is strengthened with each execution, so that performance gradually improves, and eventually, cumulative reward exceeds that of strict reliance on control (orange solid line).</p></list-item>
<list-item><p><italic>adaptive multitasking practice</italic>: {<italic>T</italic><sub>1</sub>, <italic>T</italic><sub>3</sub>}is also performed probabilistically, but adaptively as an inverse function of its cost (Ψ) relative to that of {<italic>T</italic><sub>1</sub>, <italic>T</italic><sub>3</sub>}:
<disp-formula id="ueqn1">
<graphic xlink:href="558214v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This policy is superior to the simple probabilistic practice, and converges to the same total reward as full practice (see below), but with a different tradeoff, yielding a higher initial reward but deferring the benefits of automaticity (green dashed line).</p></list-item>
<list-item><p><italic>full multitasking practice</italic>: {<italic>T</italic><sub>1</sub>, <italic>T</italic><sub>3</sub>}is executed on every trial. This yields the lowest immediate rewards but the earliest benefits of automaticity (red broken line).</p></list-item>
</list>
<p>In general, <xref rid="fig14" ref-type="fig">Figure 14</xref> shows the qualitative pattern of intertemporal choice: over short temporal horizons it is better to forgo automatization and exploit the more immediate benefits of control-dependent processing by relying on {<italic>T</italic><sub>1</sub>, <italic>T</italic><sub>2</sub>}, even though this involves slower serial execution; whereas for sufficiently long temporal horizons, the deferred benefits of investing in automatization pay off, yielding overall greater cumulative reward. Importantly, the figure also shows that formalizing the processes involved can reveal subtler, quantitative effects associated with different policies that may be relevant to strategic decision-making as a function of differences in horizons and temporal discounting, that we consider in the next section.</p>
</sec>
<sec id="s4b2">
<title>Effects of online estimation and discounting</title>
<p>Thus far, we have considered the total cumulative rewards obtained under different automatization policies from the point of view of an “ideal observer” (i.e., with full knowledge of all relevant factors such as learning rate and task likelihood), using a fixed policy and, critically, assuming an infinite time horizon with no temporal discounting of future reward. However, in realistic scenarios, it is likely that the agent can extract estimates of its efficacy and reward rate based on its preceding experience with the task, and how these affect improvement, which it can use to generate expectations for the effects of practice on further improvement (e.g., priors on performance based on effects experienced in the past), and to take account of the temporal horizon <italic>T</italic><sub><italic>h</italic></sub> it has available for such practice, subject to discounting the value of future rewards. To capture these effects, we assumed that the agent could estimate future reward based on the learning curve (a logistic function relating the past amount of practice to the rate of improvement in performance).</p>
<p>To consider an agent that chooses a policy at a given point in time <italic>t</italic> based on these factors, we can formulate a simple estimate of what, at that moment, it can expect to accrue by sticking to a policy <italic>P</italic> until a horizon time <italic>T</italic><sub><italic>h</italic></sub> as:
<disp-formula id="ueqn2">
<graphic xlink:href="558214v1_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>r</italic><sub><italic>P</italic></sub> (<italic>t</italic>) is the estimated reward rate for policy <italic>P</italic>, and <italic>d</italic> is an exponential discount function <italic>d</italic>(<italic>x</italic>) = <italic>e</italic><sup><italic>−αx</italic></sup> for some discount factor <italic>α</italic>. Given multiple policies 𝒫= {<italic>P</italic><sub>0</sub>, <italic>P</italic><sub>1</sub>, … <italic>P</italic><sub><italic>k</italic></sub> }, the probability that the agent chooses a certain policy <italic>P</italic><sub><italic>i</italic></sub> at time <italic>t</italic> can be defined as:
<disp-formula id="ueqn3">
<graphic xlink:href="558214v1_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<xref rid="fig15" ref-type="fig">Figure 15</xref> shows the relative choice frequency between two of the policies outlined above — i) serial execution of <italic>T</italic><sub>1</sub> and <italic>T</italic><sub>2</sub> (no multitasking practice, as a baseline), and parallel execution of <italic>T</italic><sub>1</sub> and <italic>T</italic><sub>3</sub>, with updating of the weights of <italic>T</italic><sub>3</sub> over the course of learning, as described ii) above (adaptive multitasking practice) — for four horizon times (<italic>T</italic><sub><italic>h</italic></sub> = 0, 20, 100, 500, where 0 corresponds to the situation without any learning) and three discount rates (<italic>α</italic> = 0, 0.2, .5, where 0 corresponds to no discounting of future value). In each case, the agent repeatedly executed the two tasks, each time selecting between the two policies based on the average of instantaneous reward rates obtained in previous execution of the same policy and estimated future value of the policy based the effects of practice experienced to that point, for the specified <italic>T</italic><sub><italic>h</italic></sub> and <italic>α</italic>. The effects are consistent with those observed in <xref rid="fig14" ref-type="fig">Figure 14b</xref>, with the value of automatization increasing for both longer horizons (larger <italic>T</italic><sub><italic>h</italic></sub>) and lower discounting of future value (smaller <italic>α</italic>) for a given learning rate.</p>
<fig id="fig15" position="float" fig-type="figure">
<label>Figure 15.</label>
<caption><title>Choice of execution policy for different time horizons and discount rates, and fixed learning rate of <italic>λ</italic> = .001 (same as used in <xref rid="fig14" ref-type="fig">Figure 14</xref>).</title>
<p>Frequency of execution of serial policy (<italic>T</italic><sub>1</sub> and <italic>T</italic><sub>2</sub> in series) versus frequency of execution of new parallel pathway (<italic>T</italic><sub>1</sub> and <italic>T</italic><sub>3</sub>) (see text for description) for an agent for three possible horizon times (<italic>T</italic><sub><italic>h</italic></sub> = 0, 20, 100, 500) and three discount rates (<italic>α</italic> = 0, 0.2, 0.5, respectively panels a-b-c). For longer horizons the preferred policies shift toward automatization (i.e., parallel execution of <italic>T</italic><sub>1</sub>, <italic>T</italic><sub>3</sub>), but this interacts with discount rate, such that automatization is favored to a greater extent when future value is discounted less.</p></caption>
<graphic xlink:href="558214v1_fig15.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The observations suggest that an agent that favors future value (low discount rate) can, under appropriate circumstances (availability of long time horizons for practice) favor the development of separated, task-dedicated representations in order to parallelize performance (i.e. develop automaticity). At the same time, they also suggest that a large range of parameters favor the use of reliance on shared representation (at the expense of less efficient serial processing), which may be consistent with a general bias toward control-dependent processing when confronting the need to acquire a novel task. While this is of course contingent on learning rate, there may also be a strong bias toward lower learning rates to avert the well-known problem of catastrophic interference in neural networks associated with higher learning rates [<xref ref-type="bibr" rid="c34">34</xref>, <xref ref-type="bibr" rid="c104">104</xref>]. More generally, it illustrates the usefulness of the formulation, and invites its application both in analyzing empirical findings concerning human performance, and building artificial agents that can autonomously optimize the tradeoff between the flexibility of “general purpose” computing and the efficiency of tailoring processing to specific tasks. We return to a broader consideration of this issue in the Discussion below.</p>
</sec>
</sec>
</sec>
<sec id="s5">
<label>V.</label>
<title>Discussion</title>
<sec id="s5a">
<label>A.</label>
<title>Summary</title>
<p>In this article, we introduce an information-theoretic approach to quantifying the cost of control in neural network architectures. Our approach builds on an understanding of what has come to be considered, from a cognitive and neuroscientific perspective, a fundamental role of control: managing the risk of conflict associated with shared representations [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>]. Critically, this can be overcome through additional training, by learning to separate the representations responsible for conflicting tasks, thus permitting parallel processing (i.e., multitasking) [<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c21">21</xref>]. These observations point to a fundamental tradeoff between:</p>
<list list-type="order">
<list-item><p>the efficacy of learning and flexibility of processing (via generalization) afforded by shared representations, but at the cost of the dependence on control to serialize processing;</p></list-item>
<list-item><p>the efficiency of automatic, parallel processing (e.g., multitasking) afforded by separated, task-dedicated representations, but at the cost of the additional time and effort required for training to develop these [<xref ref-type="bibr" rid="c12">12</xref>].</p></list-item>
</list>
<p>This formulation of the relationship between control-dependent and automatic processing has been used to account for a wide range of behavioral phenomena associated with human performance [<xref ref-type="bibr" rid="c21">21</xref>], and motivated formal analyses of the capability of neural network architectures that may be relevant both to understanding human performance as well as the design of artificial systems [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c32">32</xref>, <xref ref-type="bibr" rid="c50">50</xref>].</p>
<p>Here, we extended, and lent additional rigor to these ideas, by casting them in formal terms that allowed them to be integrated into an information-theoretic framework developed in prior work to analyze the effects of cognitive control [<xref ref-type="bibr" rid="c13">13</xref>]. That work focused on the performance of <italic>individual</italic> tasks, and the role of cognitive control in augmenting processing to ensure their reliable execution. Here, we extended the framework, by relating it to more fine-grained analyses of the neural network architecture required to perform an individual task (e.g., the patterns of performance, including the dynamics [see A] in response to individual stimuli and responses), as well as to include <italic>interactions</italic> among tasks in multitask graphs, and used it to address: the role of control in augmenting weaker tasks when in competition with stronger ones; how performance can be optimized (operationalized as maximizing reward rate) by selecting which tasks to execute at any one time; and how total cumulative reward can be optimized through decisions about when to rely on control for serial execution versus investing the time and effort in automatization to achieve the efficiency of parallel processing.</p>
<p>Central to the approach is the notion of <italic>processing cost</italic> or, inversely, <italic>processing efficacy</italic>. We first demonstrated that dependencies between tasks (in the form of shared representations) impose constraints on the processing efficacy of a neural network by limiting the number of tasks that can be performed at once, and showed that such limitations scale with the number of processing layers in the network, and are remarkably resistant to increases in the size of the network. We then provided a formal analysis of optimal efficacy for a given task graph structure and set of tasks to be performed. Finally, taking account of the fact that optimal efficacy can be improved by reconfiguring the graph over a longer time frame through learning, we formalized the tradeoff between the allocation of control in an existing graph and the investment in learning to reconfigure it, in terms of the joint of maximization of cumulative reward over a specified horizon, through the optimization in the allocation of control and the acquisition of automaticity through learning. This framework provides a foundation for analyzing how neural network architectures—whether biological or artificial—may manage the tradeoff between control-dependent and automatic processing, given the relative benefits and costs of each and how these relate to the task environment.</p>
</sec>
<sec id="s5b">
<label>B.</label>
<title>Relationship to Previous Work</title>
<sec id="s5b1">
<title>Information theoretic work</title>
<p>As noted above, the work presented here is grounded in prior work introducing an information-theoretic framework for analyzing the effects of cognitive control [<xref ref-type="bibr" rid="c13">13</xref>]. According to this approach, cognitive control serves to integrate information about a stimulus and task context into a task-dependent response [<xref ref-type="bibr" rid="c13">13</xref>]. While this approach offers a formal distinction between controlled and automatic processing for single tasks in information-theoretic terms (with the former but not the latter integrating information about the task context), it does not consider dependencies between multiple tasks. Zénon et al. [<xref ref-type="bibr" rid="c18">18</xref>] have proposed a more fine-grained analysis, according to which the information integrated in the service of one task—forming a posterior distribution of responses given the stimulus and task context—can influence the prior distribution of responses for the same stimulus in the context of another task, and thus the amount of information to be integrated for the other task. However, their approach does not take into account the representational structure of those tasks; that is, the extent to which the tasks interact with one another as a consequence of shared representations. By considering the implementation of tasks in a neural network architecture, our treatment takes account of dependencies between tasks induced by shared representations. This allows us to formulate, in information-theoretic terms, the effect of these dependencies at different levels of processing (from the processing of individual stimuli and responses within a single pathway at the neural network level to the interactions among tasks at the graph level), as well as the influence of factors intrinsic to the processing mechanisms in neural architectures, such as inhibition, the modulatory effects of control, and the depth of the network.</p>
</sec>
<sec id="s5b2">
<title>Graph theoretic work</title>
<p>The work presented in this article also extends previous graph theoretic analyses of the multitasking capabilities of neural networks, that were restricted to unweighted graphs in which interference and control are treated as all-or-nothing effects [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c32">32</xref>, <xref ref-type="bibr" rid="c105">105</xref>]. Here, we exploited the information-theoretic formulation to consider these as graded effects, and cast the tradeoffs among parameters as optimization problems. However, the formulation presented here continued to treat the task-specific mapping of individual stimuli to responses as having uniform strengths. This may be a reasonable assumption on average (e.g., the strength of the mapping from the word RED to the utterance “red” is roughly comparable to that from GREEN to “green”), but is certainly violated in some contexts (e.g., in a task that mapped red to stop, green to go and blue to wait). This might be usefully addressed by integrating the frame-work presented here with recent work on the relationship of control to statistical learning and semantics [<xref ref-type="bibr" rid="c79">79</xref>].</p>
</sec>
<sec id="s5b3">
<title>The tradeoff between the allocation of control and the acquisition of automaticity</title>
<p>As noted in Section III, previous work has begun to address this question both analytically [<xref ref-type="bibr" rid="c49">49</xref>] and in deep learning architectures [<xref ref-type="bibr" rid="c50">50</xref>]. However, these have involved highly abstracted forms of the problem (e.g., using simplified assumptions about learning curves, categorical costs, and Bayesian optimal estimation) or implementations in deep learning networks using more complex, realistic environments (e.g., video images as inputs) but restricted numbers of tasks. For example, Sagiv et al. [<xref ref-type="bibr" rid="c49">49</xref>] contrasted two pre-specified, extreme task configurations involving either quickly learned shared representations and strictly serial processing (with a fixed, pre-determined serialization cost), or more slowly acquired separated representations and fully parallel processing. The analysis of this system demonstrated that over a wide range of parameters (e.g., relative learning rates and time horizons), control-dependent, serial processing was favored over the acquisition of automaticity, but that this can reversed under reasonable conditions (e.g., more severe serialization rates or longer time horizons). Similar results have been obtained using a deep learning network trained in a more complex but realistic environment (with video images as inputs, and object recognition, object localization, and navigation tasks) [<xref ref-type="bibr" rid="c50">50</xref>]. The work presented here helps bridge these lines of work, by providing a framing of the problem that can take account of the complexities associated with neural network implementations, including standard learning algorithms and dependence among tasks as continuous and heterogeneous factors, while in a form that is more tractable to formal analysis than the full implementation of a neural network model.</p>
</sec>
<sec id="s5b4">
<title>Task scheduling in symbolic models and serial versus parallel processing</title>
<p>Dependencies between individual tasks and concomitant requirements for serial processing have been considered extensively in the context of scheduling the execution of tasks in symbolic (e.g. production system) architectures, such as EPIC [<xref ref-type="bibr" rid="c106">106</xref>] and threaded cognition [<xref ref-type="bibr" rid="c84">84</xref>]. However, to our knowledge, these have not provided a formally rigorous, normative analysis of the problem. Furthermore, they do not take into account the graded effects of representational sharing that are a critical source of constraints on multi-tasking and the requirements for control in neural network architectures, and that are accommodated in the information-theoretic framework we have described here. Rather, in symbolic models, constraints on multitasking are generally assumed to arise from the limited capacity of a central executive responsible for scheduling and the allocation of control, and/or a set of scheduling rules inherent to the processing architecture [<xref ref-type="bibr" rid="c84">84</xref>] that decide which resources get allocated to which tasks. It is worth noting, however, that this approach <italic>has</italic> been used to address empirical observations, and interpret these as evidence that humans shift between different processing modes (serial versus parallel task execution) depending on characteristics of the task environment [<xref ref-type="bibr" rid="c107">107</xref>]. At the same time, others have suggested that serial versus parallel processing may be better viewed as lying along a continuum, depending on the degree of interference between processing pathways [<xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c108">108</xref>], a view that is more closely aligned with neural network models [<xref ref-type="bibr" rid="c21">21</xref>], and the framework presented here. While we have not explicitly considered intermediate solutions, they may be derived from this framework by considering micro-dynamics of processing within the processing nodes. While we have simplified our formulation by abstracting over such dynamics, in <xref ref-type="app" rid="app1">Appendix A</xref> we should how our framework can be related to previous work that addresses how these dynamics are critical for reward rate optimization in neural systems [47, 48, 109–112]. Such micro-dynamics also remain crucial for addressing the temporal dynamics of interference within a task [<xref ref-type="bibr" rid="c77">77</xref>, <xref ref-type="bibr" rid="c78">78</xref>, <xref ref-type="bibr" rid="c113">113</xref>], as well as between-trial dynamics of control allocation to a single tasks [<xref ref-type="bibr" rid="c28">28</xref>] and across multiple tasks [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c46">46</xref>–<xref ref-type="bibr" rid="c48">48</xref>].</p>
</sec>
</sec>
<sec id="s5c">
<label>C.</label>
<title>Simplifications and Future Work</title>
<p>The formalisms introduced in this article rely on several important simplifications that should be addressed in future work.</p>
<sec id="s5c1">
<title>Interference versus facilitation</title>
<p>First, analyses assumed that information in different stimulus dimensions is always incongruent, thus any dependencies between tasks are always detrimental to processing efficacy. As discussed in Section III B, the justification for this was that, assuming independent sampling of values along different stimulus dimensions, incongruent stimuli are substantially more likely and, therefore, frequent than congruent stimuli; and that the adverse effects of interference from incongruence are usually substantially more costly than the benefits of facilitation from congruence (i.e., when the sources of information favor the same set of responses). However, there are certainly some circumstances that do not align with either or both of these assumptions. For example, some previous work has focused on circumstances in which the sources of information for two tasks are congruent [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c83">83</xref>, <xref ref-type="bibr" rid="c108">108</xref>], and formal modeling of such situations, both mathematical [<xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c114">114</xref>], and neural network [<xref ref-type="bibr" rid="c27">27</xref>], have shown how this can lead to facilitation, sometimes referred to as “super capacity”). It seems to expect that an elaboration of the framework presented here, that takes into account both the relative benefits of congruence versus costs of incongruence, and the likelihood of each, should be able to explain the effects of both. However, this remains an important direction for future research.</p>
</sec>
</sec>
<sec id="s5d">
<title>Task availability</title>
<p>A second simplifying assumption was that stimulus information is always available along all dimensions (i.e., relevant to all tasks), irrespective of the task to be performed. In one respect, this makes the control problem more challenging, as the only way to avoid interference from irrelevant information is through the allocation of control. However, in many realistic scenarios, information for irrelevant tasks may simply not be present in the environment, making the control problem easier by affording simpler solutions. At the same time, in other respects, assuming the information is always available for all tasks also makes the control problem easier, as the system can assume that any tasks <italic>can</italic> be performed at any time, and the only determination that must be made is in what combinations and/or order. Again, however, in realistic environments, information may be available for some tasks but not others, posing the challenge of determining which tasks <italic>can</italic> be performed, before determining how to execute them. One approach to this is to consider the probability distribution of task “availability,” along the lines suggested in [<xref ref-type="bibr" rid="c19">19</xref>], where it is shown how reasonable assumptions about task availability may be useful as priors that shape expectations about the likelihood of opportunities for multitasking, and that favor reliance control over the investment in automaticity [<xref ref-type="bibr" rid="c19">19</xref>]. Further work along these lines, that explores the impact of task distribution on strategic decisions about how and when control is allocated is an important future direction, both for understanding how people manage this tradeoff and for the design of adaptive autonomous agents responsible for managing their profile of performance capabilities in complex and changing environments.</p>
<sec id="s5d1">
<title>Complexity of tasks</title>
<p>Finally, as noted at the outset, the analyses presented here focused on simple “mapping” tasks, in which i) stimulus dimensions are clearly defined, ii) stimulus features along a specified input dimension are paired one-to-one with responses to be executed along a particular output dimension, and iii) processing is formulated in terms of trials in which stimulus information is presented and the expected response(s) must be generated. Needless to say, people (and machines) are capable of performing more complex tasks, i) involving environments in which stimuli do not consist of independent stimulus dimensions, ii) involving both more complex mappings from stimuli to responses and iii) more complex dynamics of execution. For example, in many cases, a task may involve the execution of actions in a particular order; and, similarly, achieving a goal may require the execution of a set of tasks in a particular order. This introduces complexity of timing and coordination that would need to be taken into account in the partitioning of tasks considered in Section IV A. Conversely, some behaviors may require coordination of the parallel execution of otherwise dissociable tasks (for example, singing and playing an instrument, or juggling). Given the large space of interactions this involves, addressing these factors in an analytically tractable form remains a challenge for future research on control and automaticity.</p>
</sec>
</sec>
<sec id="s5e">
<label>D.</label>
<title>Conclusion</title>
<p>Considerable progress has been made in building computational models of human cognitive performance in increasingly complex domains, both using traditional symbolic, and, more recently, neural network architectures. These have the virtue of being mechanistically explicit, and addressing empirical phenomena— concerning human performance and/or that of artificial agents—in a quantitatively precise manner. However, they remain largely descriptive, providing an account of how the human cognitive system functions, and how its processes may be implemented in the brain, or how to build machines that approximate these abilities, but without specifically addressing <italic>why</italic> the brain functions in those ways and/or why this would be the best way to build a machine. While a complete answer to these normative questions may never be achieved, recent work within the resource rational framework suggests that progress {emphcan be made in addressing such questions. Here, we have tried to contribute to this effort with respect to an understanding of the human capacity for cognitive control. Building on prior work using an information-theoretic approach to the allocation of control to single tasks, we have extended this to address how the system manages interactions among tasks that can arise in neural network architectures, balancing the advantages this can have through the exploitation of representational sharing for faster learning and better generalization (i.e., flexibility), against the costs it imposes by way of the need for serialization of processing (i.e. less efficient processing). The framework we have described not only undergirds a normative account of this tradeoff, and the association between capacity constraints and dependence on cognitive control, but also a normative approach to how this may be optimally balanced with the longer-term flexibility associated with the acquisition of automaticity, by modifying the task graph structure to accommodate more efficient, parallel processing through the development of separated task pathways. We hope that this approach will provide both deeper insights into the architecture of human cognition and its implementation in the brain, as well as a useful guide for how to develop artificial systems that more closely approximate the remarkable, and still uniquely human balance of flexibility and efficiency of processing.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>We would like to offer a special expression of gratitude to Biswadip Dey and Kayhan Ö zcimder who helped lay some of the foundations for the work presented in this article, as well as Jonathan Pillow who helped us formulate the approach. In addition, we thank Zahra Aminzare, Adam Charles, Malory Marin, and Vaibhav Srivastava for helpful discussions. This work was supported in part by a Vannevar Bush Fellowship supported by the Office of Naval Research to JDC, and by a Schmidt Science Fellowship, in partnership with the Rhodes Trust, to SM.</p>
</ack>
<ref-list>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="other"><string-name><given-names>Jonathan D.</given-names> <surname>Cohen</surname></string-name>. <source>Cognitive control. In The [9] Wiley Handbook of Cognitive Control, chapter 1, pages 1–28. John Wiley &amp; Sons, Ltd</source>, <year>2017</year>. <ext-link ext-link-type="uri" xlink:href="https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118920497.cNha1t">https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118920497.cNha1t</ext-link>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>Charles Witt</given-names> <surname>Telford</surname></string-name>. <article-title>The refractory phase of voluntary and associative responses</article-title>. <source>Journal of Experimental Psychology</source>, <volume>14</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>36</lpage>, <year>1931</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>A. T.</given-names> <surname>Welford</surname></string-name>. <article-title>The psychological refractory period and the timing of high-speed performance—a review and a theory</article-title>. <source>British Journal of Psychology</source>, <volume>43</volume>(<issue>1</issue>):<fpage>2</fpage>–<lpage>19</lpage>, <year>1952</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>Harold</given-names> <surname>Pashler</surname></string-name>. <article-title>Dual-task interference in simple tasks: data and theory</article-title>. <source>Psychological bulletin</source>, <volume>116</volume>(<issue>2</issue>):<fpage>220</fpage>–<lpage>244</lpage>, <year>1994</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="other"><string-name><given-names>Alan</given-names> <surname>Allport</surname></string-name>, <string-name><given-names>Elizabeth A</given-names> <surname>Styles</surname></string-name>, and <string-name><given-names>Shulan</given-names> <surname>Hsieh</surname></string-name>. <source>17 shifting intentional set: Exploring the dynamic control of tasks</source>. <year>1994</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>Robert D</given-names> <surname>Rogers</surname></string-name> and <string-name><given-names>Stephen</given-names> <surname>Monsell</surname></string-name>. <article-title>Costs of a predictible switch between simple cognitive tasks</article-title>. <source>Journal of experimental psychology: General</source>, <volume>124</volume>(<issue>2</issue>):<fpage>207</fpage>–<lpage>231</lpage>, <year>1995</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>Richard M</given-names> <surname>Shiffrin</surname></string-name> and <string-name><given-names>Walter</given-names> <surname>Schneider</surname></string-name>. <article-title>Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory</article-title>. <source>Psychological Review</source>, <volume>84</volume>(<issue>2</issue>):<fpage>127</fpage>–<lpage>190</lpage>, <year>1977</year>. <pub-id pub-id-type="doi">10.1037/0033-295X.84.2.127</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>Eric H</given-names> <surname>Schumacher</surname></string-name>, <string-name><given-names>Travis L</given-names> <surname>Seymour</surname></string-name>, <string-name><given-names>Jennifer M</given-names> <surname>Glass</surname></string-name>, <string-name><given-names>David E</given-names> <surname>Fencsik</surname></string-name>, <string-name><given-names>Erick J</given-names> <surname>Lauber</surname></string-name>, <string-name><given-names>David E</given-names> <surname>Kieras</surname></string-name>, and <string-name><given-names>David E</given-names> <surname>Meyer</surname></string-name>. <article-title>Virtually perfect time sharing in dual-task performance: Uncorking the central cognitive bottleneck</article-title>. <source>Psychological science</source>, <volume>12</volume>(<issue>2</issue>):<fpage>101</fpage>–<lpage>108</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>KG</given-names> <surname>Garner</surname></string-name> and <string-name><given-names>Paul E</given-names> <surname>Dux</surname></string-name>. <article-title>Training conquers multitasking costs by dividing task representations in the frontoparietal-subcortical system</article-title>. <source>Proceedings of the ional Academy of Sciences</source>, <volume>112</volume>(<issue>46</issue>):<fpage>14372</fpage>–<lpage>14377</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>Tilo</given-names> <surname>Strobach</surname></string-name> and <string-name><given-names>Schubert</given-names> <surname>Torsten</surname></string-name>. <article-title>Mechanisms of practice-related reductions of dual-task interference with simple tasks: data and theory</article-title>. <source>Advances in cognitive psychology</source>, <volume>13</volume>(<issue>1</issue>):<fpage>28</fpage>–<lpage>41</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="other"><string-name><given-names>M. I.</given-names> <surname>Posner</surname></string-name> and <string-name><given-names>CRR</given-names> <surname>Snyder</surname></string-name>. <source>Attention and cognitive control. information processing and cognition: The loyola symposium. pages 55–85</source>, <year>1975</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>Sebastian</given-names> <surname>Musslick</surname></string-name> and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>Rationalizing constraints on the capacity for cognitive control</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>25</volume>(<issue>9</issue>):<fpage>757</fpage>–<lpage>775</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>Etienne</given-names> <surname>Koechlin</surname></string-name> and <string-name><given-names>Christopher</given-names> <surname>Summerfield</surname></string-name>. <article-title>An information theoretical approach to prefrontal executive function</article-title>. <source>Trends in cognitive sciences</source>, <volume>11</volume>(<issue>6</issue>):<fpage>229</fpage>–<lpage>235</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>Samuel F</given-names> <surname>Feng</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Schwemmer</surname></string-name>, <string-name><given-names>Samuel J</given-names> <surname>Gershman</surname></string-name>, and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>Multitasking versus multiplexing: Toward a normative account of limitations in the simultaneous execution of control-demanding behaviors</article-title>. <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source>, <volume>14</volume>(<issue>1</issue>):<fpage>129</fpage>–<lpage>146</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>Timo</given-names> <surname>Flesch</surname></string-name>, <string-name><given-names>David G</given-names> <surname>Nagy</surname></string-name>, <string-name><given-names>Andrew M</given-names> <surname>Saxe</surname></string-name>, and <string-name><given-names>Christopher</given-names> <surname>Summerfield</surname></string-name>. <article-title>Modelling continual learning in humans with hebbian context gating and exponentially decaying task signals</article-title>. <source>PLOS Computational Biology</source>, <volume>19</volume>(<issue>1</issue>):<fpage>e1010808</fpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="other"><string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Dey</surname></string-name>, K. Ö zcimder, <string-name><given-names>M.</given-names> <surname>Patwary</surname></string-name>, <string-name><given-names>T. L.</given-names> <surname>Willke</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>. <article-title>Controlled vs. automatic processing: A graph-theoretic approach to the analysis of serial vs. parallel processing in neural network architectures</article-title>. In <source>Proceedings of the 38th Annual Meeting of the Cognitive Science Society</source>, pages <fpage>1547</fpage>—1552. Philadelphia, PA, <year>2016</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="other"><string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Saxe</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Özcimder</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Dey</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Henselman</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>. <article-title>Multitasking capability versus learning efficiency in neural network architectures</article-title>. In <source>Proceedings of the 39th Annual Meeting of the Cognitive Science Society, pages 829—834. London, UK</source>, <year>2017</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="other"><string-name><given-names>Alexandre</given-names> <surname>Zenon</surname></string-name>, <string-name><given-names>Oleg</given-names> <surname>Solopchuk</surname></string-name>, and <string-name><given-names>Giovanni</given-names> <surname>Pezzulo</surname></string-name>. <article-title>An information-theoretic perspective on the costs of cognition</article-title>. <source>Neuropsychologia, 123:5–18</source>, <year>2019</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>Giovanni</given-names> <surname>Petri</surname></string-name>, <string-name><given-names>Sebastian</given-names> <surname>Musslick</surname></string-name>, <string-name><given-names>Biswadip</given-names> <surname>Dey</surname></string-name>, <string-name><surname>Kayhan</surname> <given-names>Özcimder</given-names></string-name>, <string-name><given-names>David</given-names> <surname>Turner</surname></string-name>, <string-name><given-names>Nesreen K</given-names> <surname>Ahmed</surname></string-name>, <string-name><given-names>Theodeore L</given-names> <surname>Willke</surname></string-name>, and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>Topological limits to the parallel processing capability of network architectures</article-title>. <source>Nature Physics</source>, <volume>17</volume>(<issue>5</issue>):<fpage>646</fpage>–<lpage>651</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="other"><string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name> and <string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name> <article-title>A mechanistic account of constraints on control-dependent processing: Shared representation, conflict and persistence</article-title>. In <source>Proceedings of the 41st Annual Meeting of the Cognitive Science Society, pages 849—855. Montreal, CA</source>, <year>2019</year>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="other"><string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Saxe</surname></string-name>, <string-name><given-names>A. N.</given-names> <surname>Hoskin</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Reichman</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>. <source>On the rational boundedness of cognitive control: Shared versus separated representations. page PsyArXiv</source>: <pub-id pub-id-type="doi">10.31234/osf.io/jkhdf</pub-id>, <year>2020</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><given-names>David E</given-names> <surname>Rumelhart</surname></string-name>, <string-name><given-names>Geoffrey E</given-names> <surname>Hinton</surname></string-name>, and <string-name><given-names>Ronald J</given-names> <surname>Williams</surname></string-name>. <article-title>Learning representations by backpropagating errors</article-title>. <source>nature</source>, <volume>323</volume>(<issue>6088</issue>):<fpage>533</fpage>–<lpage>536</lpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="other"><string-name><given-names>Timothy T</given-names> <surname>Rogers</surname></string-name> and <string-name><given-names>James L</given-names> <surname>McClelland</surname></string-name>. <source>Semantic cognition: A parallel distributed processing approach. MIT press</source>, <year>2004</year>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>Randall C</given-names> <surname>O’Reilly</surname></string-name>. <article-title>Six principles for biologically based computational models of cortical cognition</article-title>. <source>Trends in cognitive sciences</source>, <volume>2</volume>(<issue>11</issue>):<fpage>455</fpage>–<lpage>462</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><given-names>Yann</given-names> <surname>LeCun</surname></string-name>, <string-name><given-names>Yoshua</given-names> <surname>Bengio</surname></string-name>, and <string-name><given-names>Geoffrey</given-names> <surname>Hinton</surname></string-name>. <article-title>Deep learning</article-title>. <source>nature</source>, <volume>521</volume>(<issue>7553</issue>):<fpage>436</fpage>–<lpage>444</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><given-names>Jürgen</given-names> <surname>Schmidhuber</surname></string-name>. <article-title>Deep learning in neural networks: An overview</article-title>. <source>Neural networks</source>, <volume>61</volume>:<fpage>85</fpage>–<lpage>117</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>, <string-name><given-names>Kevin</given-names> <surname>Dunbar</surname></string-name>, and <string-name><given-names>James L</given-names> <surname>McClelland</surname></string-name>. <article-title>On the control of automatic processes: a parallel distributed processing account of the stroop effect</article-title>. <source>Psychological Review</source>, <volume>97</volume>(<issue>3</issue>):<fpage>332</fpage>–<lpage>361</lpage>, <year>1990</year>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><given-names>Matthew M</given-names> <surname>Botvinick</surname></string-name>, <string-name><given-names>Todd S</given-names> <surname>Braver</surname></string-name>, <string-name><given-names>Deanna M</given-names> <surname>Barch</surname></string-name>, <string-name><given-names>Cameron S</given-names> <surname>Carter</surname></string-name>, and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>Conflict monitoring and cognitive control</article-title>. <source>Psychological Review</source>, <volume>108</volume>(<issue>3</issue>):<fpage>624</fpage>–<lpage>652</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><string-name><given-names>Sam J</given-names> <surname>Gilbert</surname></string-name> and <string-name><given-names>Tim</given-names> <surname>Shallice</surname></string-name>. <article-title>Task switching: A pdp model</article-title>. <source>Cognitive psychology</source>, <volume>44</volume>(<issue>3</issue>):<fpage>297</fpage>–<lpage>337</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>Seth A</given-names> <surname>Herd</surname></string-name>, <string-name><given-names>Tom E</given-names> <surname>Hazy</surname></string-name>, <string-name><given-names>Christopher H</given-names> <surname>Chatham</surname></string-name>, <string-name><given-names>Angela M</given-names> <surname>Brant</surname></string-name>, <string-name><given-names>Naomi P</given-names> <surname>Friedman</surname></string-name>, <etal>et al.</etal> <article-title>A neural network model of individual differences in task switching abilities</article-title>. <source>Neuropsychologia</source>, <volume>62</volume>:<fpage>375</fpage>–<lpage>389</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="other"><string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Bizyaeva</surname></string-name>, <string-name><given-names>Shamay</given-names> <surname>Agaron</surname></string-name>, <string-name><given-names>E. L.</given-names> <surname>Naomi</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>. <article-title>Stability-flexibility dilemma in cognitive control: A dynamical system perspective</article-title>. In <source>Proceedings of the 41st Annual Meeting of the Cognitive Science Society, pages 2420—2426. Montreal, CA</source>, <year>2019</year>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="other"><string-name><given-names>N.</given-names> <surname>Alon</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Reichman</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Shinkar</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Wagner</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name>, <string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name>, <string-name><given-names>T.</given-names> <surname>Griffiths</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Dey</surname></string-name>, and K. Ö zcimder. <article-title>A graph-theoretic approach to multitasking. advances in neural information processing systems</article-title>. In <source>Advances in Neural Information Processing Systems, pages 2097—2106. Long Beach, CA</source>, <year>2017</year>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><string-name><given-names>James L</given-names> <surname>McClelland</surname></string-name>, <string-name><given-names>David E</given-names> <surname>Rumelhart</surname></string-name>, <string-name><given-names>PDP Research</given-names> <surname>Group</surname></string-name>, <etal>et al.</etal> <article-title>Parallel distributed processing</article-title>. <source>Explorations in the Microstructure of Cognition</source>, <volume>2</volume>:<fpage>216</fpage>– <lpage>271</lpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><string-name><given-names>James L</given-names> <surname>McClelland</surname></string-name>, <string-name><given-names>Bruce L</given-names> <surname>McNaughton</surname></string-name>, and Randall C O’Reilly. <article-title>Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title>. <source>Psychological Review</source>, <volume>102</volume>(<issue>3</issue>):<fpage>419</fpage>–<lpage>457</lpage>, <year>1995</year>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><string-name><given-names>Andrew M</given-names> <surname>Saxe</surname></string-name>, <string-name><given-names>James L</given-names> <surname>McClelland</surname></string-name>, and <string-name><given-names>Surya</given-names> <surname>Ganguli</surname></string-name>. <article-title>A mathematical theory of semantic development in deep neural networks</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>116</volume>(<issue>23</issue>):<fpage>11537</fpage>–<lpage>11546</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><string-name><given-names>Nick</given-names> <surname>Yeung</surname></string-name> and <string-name><given-names>Stephen</given-names> <surname>Monsell</surname></string-name>. <article-title>Switching between tasks of unequal familiarity: The role of stimulusattribute and response-set selection</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>29</volume>(<issue>2</issue>):<fpage>455</fpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><string-name><given-names>Rafal</given-names> <surname>Bogacz</surname></string-name>, <string-name><given-names>Eric</given-names> <surname>Brown</surname></string-name>, <string-name><given-names>Jeff</given-names> <surname>Moehlis</surname></string-name>, <string-name><given-names>Philip</given-names> <surname>Holmes</surname></string-name>, and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks</article-title>. <source>Psychological Review</source>, <volume>113</volume>(<issue>4</issue>):<fpage>700</fpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><given-names>Roger</given-names> <surname>Ratcliff</surname></string-name>. <article-title>A theory of memory retrieval</article-title>. <source>Psychological review</source>, <volume>85</volume>(<issue>2</issue>):<fpage>59</fpage>–<lpage>108</lpage>, <year>1978</year>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><given-names>Marius</given-names> <surname>Usher</surname></string-name> and <string-name><given-names>James L</given-names> <surname>McClelland</surname></string-name>. <article-title>The time course of perceptual choice: the leaky, competing accumulator model</article-title>. <source>Psychological Review</source>, <volume>108</volume>(<issue>3</issue>):<fpage>550</fpage>–<lpage>592</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><string-name><given-names>Sebastian</given-names> <surname>Musslick</surname></string-name> and <string-name><given-names>Javier Alejandro</given-names> <surname>Masis</surname></string-name>. <article-title>Pushing the bounds of bounded optimality and rationality</article-title>. <source>Cognitive Science</source>, <volume>47</volume>(<issue>4</issue>):<fpage>e13259</fpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><given-names>Frederick</given-names> <surname>Callaway</surname></string-name>, <string-name><given-names>Antonio</given-names> <surname>Rangel</surname></string-name>, and <string-name><given-names>Thomas L</given-names> <surname>Griffiths</surname></string-name>. <article-title>Fixation patterns in simple choice reflect optimal information sampling</article-title>. <source>PLoS computational biology</source>, <volume>17</volume>(<issue>3</issue>):<fpage>e1008863</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><string-name><given-names>Jan</given-names> <surname>Drugowitsch</surname></string-name>, Rubén Moreno-Bote, <string-name><given-names>Anne K</given-names> <surname>Churchland</surname></string-name>, <string-name><given-names>Michael N</given-names> <surname>Shadlen</surname></string-name>, and <string-name><given-names>Alexandre</given-names> <surname>Pouget</surname></string-name>. <article-title>The cost of accumulating evidence in perceptual decision making</article-title>. <source>Journal of Neuroscience</source>, <volume>32</volume>(<issue>11</issue>):<fpage>3612</fpage>–<lpage>3628</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><string-name><given-names>Patrick</given-names> <surname>Simen</surname></string-name>, <string-name><given-names>David</given-names> <surname>Contreras</surname></string-name>, <string-name><given-names>Cara</given-names> <surname>Buck</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>Hu</surname></string-name>, <string-name><given-names>Philip</given-names> <surname>Holmes</surname></string-name>, and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>Reward rate optimization in two-alternative decision making: empirical tests of theoretical predictions</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>35</volume>(<issue>6</issue>):<fpage>1865</fpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="other"><string-name><given-names>Javier Alejandro</given-names> <surname>Masis</surname></string-name>, <string-name><given-names>Travis</given-names> <surname>Chapman</surname></string-name>, <string-name><given-names>Juliana Y</given-names> <surname>Rhee</surname></string-name>, <string-name><given-names>David D</given-names> <surname>Cox</surname></string-name>, and <string-name><given-names>Andrew M</given-names> <surname>Saxe</surname></string-name>. <source>Rats strategically manage learning during perceptual decision making. page bioRxiv</source>: <pub-id pub-id-type="doi">10.1101/2020.09.01.259911</pub-id>, <year>2020</year>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><string-name><given-names>Patrick</given-names> <surname>Simen</surname></string-name> and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>Explicit melioration by a neural diffusion model</article-title>. <source>Brain research</source>, <volume>1299</volume>:<fpage>95</fpage>–<lpage>117</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="other"><string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name>, <string-name><given-names>J. S.</given-names> <surname>Jang</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Shvartsman</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Shenhav</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>. <article-title>Constraints associated with cognitive control and the stability-flexibility dilemma</article-title>. In <source>Proceedings of the 40th Annual Meeting of the Cognitive Science Society</source>, pages 806—811. Madison, WI, <year>2018</year>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="other"><string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Bizyaeva</surname></string-name>, <string-name><given-names>Shamay</given-names> <surname>Agaron</surname></string-name>, <string-name><given-names>E. L.</given-names> <surname>Naomi</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>. <article-title>Stability-flexibility dilemma in cognitive control: A dynamical system perspective</article-title>. In <source>Proceedings of the 41st Annual Meeting of the Cognitive Science Society, pages 2420—2426. Montreal, CA</source>, <year>2019</year>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal">Kai Ueltzhöffer, <string-name><surname>Diana</surname> <given-names>JN</given-names></string-name> Armbruster-Genç, and <string-name><given-names>Christian J</given-names> <surname>Fiebach</surname></string-name>. <article-title>Stochastic dynamics underlying cognitive stability and flexibility</article-title>. <source>PLoS computational biology</source>, <volume>11</volume>(<issue>6</issue>):<fpage>e1004331</fpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="other"><string-name><given-names>Y.</given-names> <surname>Sagiv</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Niv</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>. <article-title>Efficiency of learning vs. processing: Towards a normative theory of multitasking</article-title>. In <source>Proceedings of the 40th Annual Meeting of the Cognitive Science Society</source>, pages <fpage>1004</fpage>—1009, arXiv:<pub-id pub-id-type="arxiv">2007.03124</pub-id>. Madison, WI, <year>2018</year>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="other"><string-name><given-names>S.</given-names> <surname>Ravi</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Hamin</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Willke</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>. <source>Navigating the tradeoff between multi-task learning and learning to multitask in deep neural networks. page</source> arXiv: <pub-id pub-id-type="arxiv">2007.10527</pub-id>, <year>2020</year>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="other"><string-name><given-names>Arthur T</given-names> <surname>Jersild</surname></string-name>. <article-title>Mental set and shift</article-title>. <source>Archives of psychology</source>, <year>1927</year>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="journal"><string-name><given-names>R.M.</given-names> <surname>Shiffrin</surname></string-name> and <string-name><given-names>W.</given-names> <surname>Schneider</surname></string-name>. <article-title>Controlled and automatic human information processing: Ii. perceptual learning, automatic attending and a general theory</article-title>. <source>Psychological Review</source>, <volume>84</volume>(<issue>2</issue>):<fpage>127</fpage>–<lpage>190</lpage>, <year>1977</year>. <pub-id pub-id-type="doi">10.1037/0033-295X.84.2.127</pub-id>.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="other"><string-name><given-names>LH</given-names> <surname>Shaffer</surname></string-name>. <article-title>Multiple attention in continuous verbal tasks</article-title>. <source>Attention and performance V</source>, pages <fpage>157</fpage>–<lpage>167</lpage>, <year>1975</year>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><string-name><given-names>J. T.</given-names> <surname>Townsend</surname></string-name> and <string-name><given-names>M. J.</given-names> <surname>Wenger</surname></string-name>. <article-title>A theory of interactive parallel processing: new capacity measures and predictions for a response time inequality series</article-title>. <source>Psychological Review</source>, <volume>111</volume>(<issue>4</issue>):<fpage>1003</fpage>–<lpage>1035</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="journal"><string-name><given-names>Colin M</given-names> <surname>MacLeod</surname></string-name> and <string-name><given-names>Kevin</given-names> <surname>Dunbar</surname></string-name>. <article-title>Training and stroop-like interference: Evidence for a continuum of automaticity</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>14</volume>(<issue>1</issue>):<fpage>126</fpage>, <year>1988</year>.</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="other"><collab>Note that processing units can be assigned either to individual stimuli (“localist” representations), or sets of them can be used to represent different stimuli as different patterns of activity over the set (“distributed” representations). For expository purposes, in this article we present models using localist representations; however, all of the analyses and results can readily be extended to models using distributed representations</collab>.</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="other"><string-name><given-names>M.</given-names> <surname>Lesnick</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Dey</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>. <source>A formal framework for cognitive models of multitasking</source>. <year>2020</year>.</mixed-citation></ref>
<ref id="c58"><label>[58]</label><mixed-citation publication-type="journal"><string-name><given-names>Robert E</given-names> <surname>Warren</surname></string-name>. <article-title>Stimulus encoding and memory</article-title>. <source>Journal of Experimental Psychology</source>, <volume>94</volume>(<issue>1</issue>):<fpage>90</fpage>, <year>1972</year>.</mixed-citation></ref>
<ref id="c59"><label>[59]</label><mixed-citation publication-type="journal">J <string-name><given-names>Ridley</given-names> <surname>Stroop</surname></string-name>. <article-title>Studies of interference in serial verbal reactions</article-title>. <source>Journal of experimental psychology</source>, <volume>18</volume>(<issue>6</issue>):<fpage>643</fpage>, <year>1935</year>. <pub-id pub-id-type="doi">10.1037/h0054651</pub-id>.</mixed-citation></ref>
<ref id="c60"><label>[60]</label><mixed-citation publication-type="journal"><string-name><given-names>Colin M</given-names> <surname>MacLeod</surname></string-name>. <article-title>Half a century of research on the stroop effect: an integrative review</article-title>. <source>Psychological bulletin</source>, <volume>109</volume>(<issue>2</issue>):<fpage>163</fpage>, <year>1991</year>.</mixed-citation></ref>
<ref id="c61"><label>[61]</label><mixed-citation publication-type="journal"><string-name><given-names>Daniel</given-names> <surname>Kahneman</surname></string-name> and <string-name><given-names>Diane</given-names> <surname>Chajczyk</surname></string-name>. <article-title>Tests of the automaticity of reading: dilution of stroop effects by color-irrelevant stimuli</article-title>. <source>Journal of Experimental Psychology: Human perception and performance</source>, <volume>9</volume>(<issue>4</issue>):<fpage>497</fpage>, <year>1983</year>.</mixed-citation></ref>
<ref id="c62"><label>[62]</label><mixed-citation publication-type="other"><string-name><given-names>Daniel</given-names> <surname>Kahneman</surname></string-name> and <string-name><given-names>Avishai</given-names> <surname>Henik</surname></string-name>. <article-title>Effects of visual grouping on immediate recall and selective attention</article-title>. In <source>Attention and performance VI</source>, pages <fpage>307</fpage>–<lpage>332</lpage>. Routledge, <year>1977</year>.</mixed-citation></ref>
<ref id="c63"><label>[63]</label><mixed-citation publication-type="other"><collab>Here, we assume that each has already been learned</collab>. <source>Further on, in Section IV, we consider how multiple tasks may be learned (i.e., “multi-task learning”), and how this may interact with the ability to perform them simultaneously</source>.</mixed-citation></ref>
<ref id="c64"><label>[64]</label><mixed-citation publication-type="journal"><string-name><given-names>J.R.</given-names> <surname>Stroop</surname></string-name>. <article-title>Studies of interference in serial verbal reactions</article-title>. <source>Journal of Experimental Psychology</source>, <volume>18</volume>(<issue>6</issue>):<fpage>643</fpage>–<lpage>662</lpage>, <year>1935</year>. <pub-id pub-id-type="doi">10.1037/h0054651</pub-id>.</mixed-citation></ref>
<ref id="c65"><label>[65]</label><mixed-citation publication-type="other"><collab>Note that, whereas the weights can differ across tasks, we continue to assume that the strengths of all of the associations constituting the stimulus-response mappings</collab> <source>within a task are of equal strengths — an assumption that is commonly made in models of simple directmapping tasks [27, 115]; also see Note V D</source>.</mixed-citation></ref>
<ref id="c66"><label>[66]</label><mixed-citation publication-type="journal"><string-name><given-names>Jeffrey L</given-names> <surname>Elman</surname></string-name>. <article-title>Distributed representations, simple recurrent networks, and grammatical structure</article-title>. <source>Machine learning</source>, <volume>7</volume>(<issue>2</issue>):<fpage>195</fpage>–<lpage>225</lpage>, <year>1991</year>.</mixed-citation></ref>
<ref id="c67"><label>[67]</label><mixed-citation publication-type="journal"><string-name><given-names>Sepp</given-names> <surname>Hochreiter</surname></string-name> and <string-name><given-names>Jürgen</given-names> <surname>Schmidhuber</surname></string-name>. <article-title>Long shortterm memory</article-title>. <source>Neural computation</source>, <volume>9</volume>(<issue>8</issue>):<fpage>1735</fpage>–<lpage>1780</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c68"><label>[68]</label><mixed-citation publication-type="journal"><string-name><given-names>Trenton</given-names> <surname>Kriete</surname></string-name>, <string-name><given-names>David C</given-names> <surname>Noelle</surname></string-name>, <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>, and Randall C O’Reilly. <article-title>Indirection and symbollike processing in the prefrontal cortex and basal ganglia</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>110</volume>(<issue>41</issue>):<fpage>16390</fpage>–<lpage>16395</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c69"><label>[69]</label><mixed-citation publication-type="journal"><string-name><given-names>Nicolas P</given-names> <surname>Rougier</surname></string-name>, <string-name><given-names>David C</given-names> <surname>Noelle</surname></string-name>, <string-name><given-names>Todd S</given-names> <surname>Braver</surname></string-name>, <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>, and Randall C O’Reilly. <article-title>Prefrontal cortex and flexible cognitive control: Rules without symbols</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>102</volume>(<issue>20</issue>):<fpage>7338</fpage>–<lpage>7343</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c70"><label>[70]</label><mixed-citation publication-type="other"><string-name><given-names>David C</given-names> <surname>Plaut</surname></string-name>, <string-name><given-names>James L</given-names> <surname>McClelland</surname></string-name>, <string-name><given-names>Mark S</given-names> <surname>Seidenberg</surname></string-name>, and <string-name><given-names>Karalyn</given-names> <surname>Patterson</surname></string-name>. <article-title>Understanding normal and impaired word reading: Computational principles in quasi-regular domains</article-title>. In <source>Connectionist psychology: A text with readings</source>, pages <fpage>367</fpage>–<lpage>454</lpage>. Psychology Press, <year>2020</year>.</mixed-citation></ref>
<ref id="c71"><label>[71]</label><mixed-citation publication-type="journal"><string-name><given-names>Mark S</given-names> <surname>Seidenberg</surname></string-name> and <string-name><given-names>James L</given-names> <surname>McClelland</surname></string-name>. <article-title>A distributed, developmental model of word recognition and naming</article-title>. <source>Psychological review</source>, <volume>96</volume>(<issue>4</issue>):<fpage>523</fpage>, <year>1989</year>.</mixed-citation></ref>
<ref id="c72"><label>[72]</label><mixed-citation publication-type="other">Alternatively, <string-name><given-names>this can be formulated as a leak term in models involving</given-names> <surname>integrator</surname></string-name> and/<string-name><given-names>or recurrent</given-names> <surname>units</surname></string-name>, e.g. [37, 39].</mixed-citation></ref>
<ref id="c73"><label>[73]</label><mixed-citation publication-type="other"><collab>Note that the input units shown in Figure 4a (<inline-formula><inline-graphic xlink:href="558214v1_inline62.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="558214v1_inline63.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) are not shown in Figure 2a) because they correspond to environmental inputs, as opposed to the <inline-formula><inline-graphic xlink:href="558214v1_inline64.gif" mimetype="image" mime-subtype="gif"/></inline-formula> units which refer to an agent’s representations of the environmental inputs</collab>.</mixed-citation></ref>
<ref id="c74"><label>[74]</label><mixed-citation publication-type="other"><collab>Note that these calculations focus on the probability of different outcomes of processing (i.e., accuracy of performance), relating this directly to costs without taking account of the dynamics of processing (i.e., response times) which, in principle, should also impact reward rate and thus costs. This is licensed by three assumptions. First, while longer response times associated with a weaker pathway and/or interference from a competing one clearly impact reward rate (i.e., by lengthening the time to reward), these are small with regard to the cost of inaccurate performance (which can eliminate reward altogether). Second, the costs in response time are also small with respect to the serialization costs associated with shared representations (again, owing to their effect on accuracy). Finally, while it is certainly possible that changes in the allocation of control may occur while a stimulus is being processed, and thus on a similar timescale (e.g. [78, 116–118]), we assume that for the most part strategic adjustments of control used to optimize performance more often occur on a longer timescale (e.g., from one stimulus to the next). Thus, for present purposes, we ignore the detailed dynamics of processing individual stimulus, and focus our analyses on the accuracy of such processing. Toward this end, our formulation assumes a particular probabilistic form for the outcome of processing as a function of inputs and connection strengths (e.g., in Equations 5, 8, 14 and 15). In Appendix A, we provide an analysis that grounds this form directly in widely used models of the dynamics of processing in simple mapping tasks, including the neural network model of the Stroop task on which we focus here</collab>.</mixed-citation></ref>
<ref id="c75"><label>[75]</label><mixed-citation publication-type="other"><string-name><given-names>Andrew</given-names> <surname>Saxe</surname></string-name>, <string-name><given-names>Shagun</given-names> <surname>Sodhani</surname></string-name>, and <string-name><given-names>Sam Jay</given-names> <surname>Lewallen</surname></string-name>. <article-title>The neural race reduction: dynamics of abstraction in gated networks</article-title>. In <source>International Conference on Machine Learning</source>, pages <fpage>19287</fpage>–<lpage>19309</lpage>. PMLR, <year>2022</year>.</mixed-citation></ref>
<ref id="c76"><label>[76]</label><mixed-citation publication-type="journal"><string-name><given-names>Pieter</given-names> <surname>Verbeke</surname></string-name> and <string-name><given-names>Tom</given-names> <surname>Verguts</surname></string-name>. <article-title>Using top-down modulation to optimally balance shared versus separated task representations</article-title>. <source>Neural networks</source>, <volume>146</volume>:<fpage>256</fpage>–<lpage>271</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c77"><label>[77]</label><mixed-citation publication-type="journal"><string-name><given-names>Eyal</given-names> <surname>Kalanthroff</surname></string-name>, <string-name><given-names>Eddy J</given-names> <surname>Davelaar</surname></string-name>, <string-name><given-names>Avishai</given-names> <surname>Henik</surname></string-name>, <string-name><given-names>Liat</given-names> <surname>Goldfarb</surname></string-name>, and <string-name><given-names>Marius</given-names> <surname>Usher</surname></string-name>. <article-title>Task conflict and proactive control: A computational theory of the stroop task</article-title>. <source>Psychological Review</source>, <volume>125</volume>(<issue>1</issue>):<fpage>59</fpage>–<lpage>82</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c78"><label>[78]</label><mixed-citation publication-type="journal"><string-name><given-names>Yuan Sophie</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Philip</given-names> <surname>Holmes</surname></string-name>, and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>A neural network model of the eriksen task: Reduction, analysis, and data fitting</article-title>. <source>Neural computation</source>, <volume>20</volume>(<issue>2</issue>):<fpage>345</fpage>–<lpage>373</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c79"><label>[79]</label><mixed-citation publication-type="other"><string-name><given-names>D.</given-names> <surname>Giallanza</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Campbell</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Rogers</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>. <source>An integrated model of semantics and control. 2023</source>. <ext-link ext-link-type="uri" xlink:href="https://psyarxiv.com/jq7ta">https://psyarxiv.com/jq7ta</ext-link>.</mixed-citation></ref>
<ref id="c80"><label>[80]</label><mixed-citation publication-type="journal"><string-name><given-names>Matthew M</given-names> <surname>Botvinick</surname></string-name> and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>The computational and neural basis of cognitive control: Charted territory and new frontiers</article-title>. <source>Cognitive science</source>, <volume>38</volume>(<issue>6</issue>):<fpage>1249</fpage>–<lpage>1285</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c81"><label>[81]</label><mixed-citation publication-type="other"><collab>This is because, for independent sampling among stimulus dimensions (required by the definition of independent tasks; see Section II B above), the likelihood of incongruence grows exponentially with the number of features in each dimension, as compared to the likelihood of congruence which grows linearly</collab>).</mixed-citation></ref>
<ref id="c82"><label>[82]</label><mixed-citation publication-type="other"><collab>This simplification rests on the assumption that the strength of processing for a task at each layer of the network can be adequately summarized by a single value (the weight of the corresponding edge in the task graph). This value can be expected to be reasonably representative of the processing for individual task stimuli if the strengths of the connections implementing the mappings between each layer of processing for that task are roughly comparable across stimuli. That, in turn, is a reasonable assumption if task-relevant stimuli are sampled with approximately equal frequency during training on that task</collab>..</mixed-citation></ref>
<ref id="c83"><label>[83]</label><mixed-citation publication-type="journal"><string-name><given-names>David E</given-names> <surname>Meyer</surname></string-name> and <string-name><given-names>David E</given-names> <surname>Kieras</surname></string-name>. <article-title>A computational theory of executive cognitive processes and multipletask performance: Part I. Basic mechanisms</article-title>. <source>Psychological Review</source>, <volume>104</volume>(<issue>1</issue>):<fpage>3</fpage>–<lpage>65</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c84"><label>[84]</label><mixed-citation publication-type="journal"><string-name><given-names>Dario D</given-names> <surname>Salvucci</surname></string-name> and <string-name><given-names>Niels A</given-names> <surname>Taatgen</surname></string-name>. <article-title>Threaded cognition: An integrated theory of concurrent multitasking</article-title>. <source>Psychological Review</source>, <volume>115</volume>(<issue>1</issue>):<fpage>101</fpage>–<lpage>130</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c85"><label>[85]</label><mixed-citation publication-type="other"><collab>This treatment is consistent with the focus of this article on the demands for control, and the definition of a task formalized for that purpose [57]: If two tasks that share a stimulus set require independent sampling, then they cannot be performed at the same time, and are therefore subject to control; and the only violation of this constraint is if they violate the definition of a task, that requires independence of sampling from any other</collab>.</mixed-citation></ref>
<ref id="c86"><label>[86]</label><mixed-citation publication-type="journal"><string-name><given-names>Tom</given-names> <surname>Verguts</surname></string-name> and <string-name><given-names>Wim</given-names> <surname>Notebaert</surname></string-name>. <article-title>Adaptation by binding: A learning account of cognitive control</article-title>. <source>Trends in cognitive sciences</source>, <volume>13</volume>(<issue>6</issue>):<fpage>252</fpage>–<lpage>257</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c87"><label>[87]</label><mixed-citation publication-type="other"><collab>Note that Δβ, by offsetting the effects of β, also modulates the sensitivity of a node to its inputs, by placing it in the sensitive range of its response function. However, unlike ν, when Δβ is low (relative to β), it reduces the overall responsivity of the node, and not just its sensitivity to its inputs</collab>.</mixed-citation></ref>
<ref id="c88"><label>[88]</label><mixed-citation publication-type="journal"><string-name><given-names>Timothy EJ</given-names> <surname>Behrens</surname></string-name>, <string-name><given-names>Mark W</given-names> <surname>Woolrich</surname></string-name>, <string-name><given-names>Mark E</given-names> <surname>Walton</surname></string-name>, and <string-name><given-names>Matthew FS</given-names> <surname>Rushworth</surname></string-name>. <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nature neuroscience</source>, <volume>10</volume>(<issue>9</issue>):<fpage>1214</fpage>–<lpage>1221</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c89"><label>[89]</label><mixed-citation publication-type="journal"><string-name><given-names>Matthew R</given-names> <surname>Nassar</surname></string-name>, <string-name><given-names>Katherine M</given-names> <surname>Rumsey</surname></string-name>, <string-name><given-names>Robert C</given-names> <surname>Wilson</surname></string-name>, <string-name><given-names>Kinjan</given-names> <surname>Parikh</surname></string-name>, <string-name><given-names>Benjamin</given-names> <surname>Heasly</surname></string-name>, and <string-name><given-names>Joshua I</given-names> <surname>Gold</surname></string-name>. <article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title>. <source>Nature neuroscience</source>, <volume>15</volume>(<issue>7</issue>):<fpage>1040</fpage>–<lpage>1046</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c90"><label>[90]</label><mixed-citation publication-type="journal"><string-name><given-names>Marius</given-names> <surname>Usher</surname></string-name>, <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>, <string-name><given-names>David</given-names> <surname>ServanSchreiber</surname></string-name>, <string-name><given-names>Janusz</given-names> <surname>Rajkowski</surname></string-name>, and <string-name><given-names>Gary</given-names> <surname>Aston-Jones</surname></string-name>. <article-title>The role of locus coeruleus in the regulation of cognitive performance</article-title>. <source>Science</source>, <volume>283</volume>(<issue>5401</issue>):<fpage>549</fpage>–<lpage>554</lpage>, <year>1999</year>.</mixed-citation></ref>
<ref id="c91"><label>[91]</label><mixed-citation publication-type="journal"><string-name><given-names>Gary</given-names> <surname>Aston-Jones</surname></string-name> and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance</article-title>. <source>Annu. Rev. Neurosci</source>., <volume>28</volume>:<fpage>403</fpage>–<lpage>450</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c92"><label>[92]</label><mixed-citation publication-type="journal"><string-name><given-names>David</given-names> <surname>Servan-Schreiber</surname></string-name>, <string-name><given-names>Harry</given-names> <surname>Printz</surname></string-name>, and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>A network model of catecholamine effects: gain, signal-to-noise ratio, and behavior</article-title>. <source>Science</source>, <volume>249</volume>(<issue>4971</issue>):<fpage>892</fpage>–<lpage>895</lpage>, <year>1990</year>.</mixed-citation></ref>
<ref id="c93"><label>[93]</label><mixed-citation publication-type="journal"><string-name><given-names>Mark S</given-names> <surname>Gilzenrat</surname></string-name>, <string-name><given-names>Sander</given-names> <surname>Nieuwenhuis</surname></string-name>, <string-name><given-names>Marieke</given-names> <surname>Jepma</surname></string-name>, and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>Pupil diameter tracks changes in control state predicted by the adaptive gain theory of locus coeruleus function</article-title>. <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source>, <volume>10</volume>(<issue>2</issue>):<fpage>252</fpage>–<lpage>269</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c94"><label>[94]</label><mixed-citation publication-type="journal"><string-name><given-names>Sander</given-names> <surname>Nieuwenhuis</surname></string-name>, <string-name><given-names>Mark S</given-names> <surname>Gilzenrat</surname></string-name>, <string-name><given-names>Benjamin D</given-names> <surname>Holmes</surname></string-name>, and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>The role of the locus coeruleus in mediating the attentional blink: a neurocomputational theory</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>134</volume>(<issue>3</issue>):<fpage>291</fpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c95"><label>[95]</label><mixed-citation publication-type="journal"><string-name><given-names>Eric</given-names> <surname>Shea-Brown</surname></string-name>, <string-name><given-names>Mark S</given-names> <surname>Gilzenrat</surname></string-name>, and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>Optimization of decision making in multilayer networks: the role of locus coeruleus</article-title>. <source>Neural computation</source>, <volume>20</volume>(<issue>12</issue>):<fpage>2863</fpage>–<lpage>2894</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c96"><label>[96]</label><mixed-citation publication-type="other"><collab>Note that this is in contrast to single task processing, in which the performance cost Φ<sup>∗</sup> can always be brought to zero with sufficient allocation of control (see Figure 3</collab>).</mixed-citation></ref>
<ref id="c97"><label>[97]</label><mixed-citation publication-type="journal"><string-name><given-names>John R</given-names> <surname>Anderson</surname></string-name>. <article-title>Acquisition of cognitive skill</article-title>. <source>Psychological review</source>, <volume>89</volume>(<issue>4</issue>):<fpage>369</fpage>, <year>1982</year>.</mixed-citation></ref>
<ref id="c98"><label>[98]</label><mixed-citation publication-type="journal"><string-name><given-names>Niels A</given-names> <surname>Taatgen</surname></string-name> and <string-name><given-names>Frank J</given-names> <surname>Lee</surname></string-name>. <article-title>Production compilation: A simple mechanism to model complex skill acquisition</article-title>. <source>Human Factors</source>, <volume>45</volume>(<issue>1</issue>):<fpage>61</fpage>–<lpage>76</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c99"><label>[99]</label><mixed-citation publication-type="other"><collab>In models that address the dynamics of processing, speed is determined by the strength of connections (or corresponding parameters, such as the drift rate in the DDM), and thus subject to modification by adjustments in β and ω. However, along the lines discussed earlier (see Note V D), we ignore this factor because: changes in the speed of processing as a function of strength are relatively small (on the scale of 100s of milliseconds) relative to the time scales at which modifications in control parameters (seconds) and automaticity parameters (minutes to years) occur; b) for a constant speed, the same changes in the strength of processing are also expressed as changes in accuracy, which are the focus of the analyses presented in this article</collab>.</mixed-citation></ref>
<ref id="c100"><label>[100]</label><mixed-citation publication-type="journal"><string-name><given-names>Joshua I</given-names> <surname>Gold</surname></string-name> and <string-name><given-names>Michael N</given-names> <surname>Shadlen</surname></string-name>. <article-title>Banburismus and the brain: decoding the relationship between sensory stimuli, decisions, and reward</article-title>. <source>Neuron</source>, <volume>36</volume>(<issue>2</issue>):<fpage>299</fpage>–<lpage>308</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c101"><label>[101]</label><mixed-citation publication-type="journal"><string-name><given-names>Dániel</given-names> <surname>Marx</surname></string-name>. <article-title>Graph colouring problems and their applications in scheduling</article-title>. <source>Periodica Polytechnica Electrical Engineering (Archives)</source>, <volume>48</volume>(<issue>1-2</issue>):<fpage>11</fpage>–<lpage>16</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c102"><label>[102]</label><mixed-citation publication-type="other"><collab>Previous work has shown that the speed of learning also depends on the environmental statistics, and the opportunity to share representations [17, 35, 119]</collab>.</mixed-citation></ref>
<ref id="c103"><label>[103]</label><mixed-citation publication-type="other"><collab>The availability of the particular latent (weak) pathway required to perform a given task aligns with empirical findings of mixed selectivity neurons, especially in prefrontal cortex, which have been interpreted as providing a rich range of pre-existing conjunctive codes that are sufficient to support the associative requirements to perform any given task[120]</collab>.</mixed-citation></ref>
<ref id="c104"><label>[104]</label><mixed-citation publication-type="other"><string-name><given-names>Michael</given-names> <surname>McCloskey</surname></string-name> and <string-name><given-names>Neal J</given-names> <surname>Cohen</surname></string-name>. <article-title>Catastrophic interference in connectionist networks: The sequential learning problem</article-title>. In <source>Psychology of learning and motivation, volume 24</source>, pages <fpage>109</fpage>–<lpage>165</lpage>. Elsevier, <year>1989</year>.</mixed-citation></ref>
<ref id="c105"><label>[105]</label><mixed-citation publication-type="other">K. Ö zcimder, <string-name><given-names>B.</given-names> <surname>Dey</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Musslick</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Petri</surname></string-name>, <string-name><given-names>N. K.</given-names> <surname>Ahmed</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Willke</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>. <article-title>A formal approach to modeling the cost of cognitive control</article-title>. In <source>Proceedings of the 39th Annual Meeting of the Cognitive Science Society</source>, pages <fpage>895</fpage>—900. London, UK, <year>2017</year>.</mixed-citation></ref>
<ref id="c106"><label>[106]</label><mixed-citation publication-type="journal"><string-name><given-names>Davis E</given-names> <surname>Kieras</surname></string-name> and <string-name><given-names>Davis E</given-names> <surname>Meyer</surname></string-name>. <article-title>An overview of the epic architecture for cognition and performance with application to human-computer interaction</article-title>. <source>Human– Computer Interaction</source>, <volume>12</volume>(<issue>4</issue>):<fpage>391</fpage>–<lpage>438</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c107"><label>[107]</label><mixed-citation publication-type="journal"><string-name><given-names>Rico</given-names> <surname>Fischer</surname></string-name> and <string-name><given-names>Franziska</given-names> <surname>Plessow</surname></string-name>. <article-title>Efficient multitasking: parallel versus serial processing of multiple tasks</article-title>. <source>Frontiers in psychology</source>, <volume>6</volume>:Article 1366, <year>2015</year>.</mixed-citation></ref>
<ref id="c108"><label>[108]</label><mixed-citation publication-type="journal"><string-name><given-names>J. T.</given-names> <surname>Townsend</surname></string-name> and Mario Fifić. <article-title>Parallel versus serial processing and individual differences in high-speed search in human memory</article-title>. <source>Perception &amp; Psychophysics</source>, <volume>66</volume>(<issue>6</issue>):<fpage>953</fpage>–<lpage>962</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c109"><label>[109]</label><mixed-citation publication-type="journal"><string-name><given-names>Vinod</given-names> <surname>Menon</surname></string-name> and Mark D’Esposito. <article-title>The role of pfc networks in cognitive control and executive function</article-title>. <source>Neuropsychopharmacology</source>, <volume>47</volume>(<issue>1</issue>):<fpage>90</fpage>–<lpage>103</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c110"><label>[110]</label><mixed-citation publication-type="journal"><string-name><given-names>Ahmed A</given-names> <surname>Moustafa</surname></string-name>, <string-name><given-names>Michael X</given-names> <surname>Cohen</surname></string-name>, <string-name><given-names>Scott J</given-names> <surname>Sherman</surname></string-name>, and <string-name><given-names>Michael J</given-names> <surname>Frank</surname></string-name>. <article-title>A role for dopamine in temporal decision making and reward maximization in parkinsonism</article-title>. <source>Journal of Neuroscience</source>, <volume>28</volume>(<issue>47</issue>):<fpage>12294</fpage>– <lpage>12304</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c111"><label>[111]</label><mixed-citation publication-type="journal"><string-name><given-names>Pieter</given-names> <surname>Verbeke</surname></string-name> and <string-name><given-names>Tom</given-names> <surname>Verguts</surname></string-name>. <article-title>Learning to synchronize: How biological agents can couple neural task modules for dealing with the stability-plasticity dilemma</article-title>. <source>PLoS computational biology</source>, <volume>15</volume>(<issue>8</issue>):<fpage>e1006604</fpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c112"><label>[112]</label><mixed-citation publication-type="journal"><string-name><given-names>Tom</given-names> <surname>Verguts</surname></string-name>. <article-title>Binding by random bursts: A computational model of cognitive control</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>29</volume>(<issue>6</issue>):<fpage>1103</fpage>–<lpage>1118</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c113"><label>[113]</label><mixed-citation publication-type="journal"><string-name><given-names>Matthew F</given-names> <surname>Panichello</surname></string-name>, <string-name><given-names>Brian</given-names> <surname>DePasquale</surname></string-name>, <string-name><given-names>Jonathan W</given-names> <surname>Pillow</surname></string-name>, and <string-name><given-names>Timothy J</given-names> <surname>Buschman</surname></string-name>. <article-title>Error-correcting dynamics in visual working memory</article-title>. <source>Nature communications</source>, <volume>10</volume>(<issue>1</issue>):<fpage>3366</fpage>. doi: <pub-id pub-id-type="doi">10.1038/s41467-019-11298-3</pub-id>., <year>2019</year>.</mixed-citation></ref>
<ref id="c114"><label>[114]</label><mixed-citation publication-type="journal"><string-name><given-names>J. T.</given-names> <surname>Townsend</surname></string-name> and <string-name><given-names>Georgie</given-names> <surname>Nozawa</surname></string-name>. <article-title>Spatio-temporal properties of elementary perception: An investigation of parallel, serial, and coactive theories</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>39</volume>(<issue>4</issue>):<fpage>321</fpage>–<lpage>359</lpage>, <year>1995</year>.</mixed-citation></ref>
<ref id="c115"><label>[115]</label><mixed-citation publication-type="journal"><string-name><given-names>Thomas J</given-names> <surname>Faulkenberry</surname></string-name>. <article-title>Testing a direct mapping versus competition account of response dynamics in number comparison</article-title>. <source>Journal of Cognitive Psychology</source>, <volume>28</volume>(<issue>7</issue>):<fpage>825</fpage>–<lpage>842</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c116"><label>[116]</label><mixed-citation publication-type="journal"><string-name><given-names>Barbara A</given-names> <surname>Eriksen</surname></string-name> and <string-name><given-names>Charles W</given-names> <surname>Eriksen</surname></string-name>. <article-title>Effects of noise letters upon the identification of a target letter in a nonsearch task</article-title>. <source>Perception &amp; psychophysics</source>, <volume>16</volume>(<issue>1</issue>):<fpage>143</fpage>– <lpage>149</lpage>, <year>1974</year>. <pub-id pub-id-type="doi">10.3758/BF03203267</pub-id>.</mixed-citation></ref>
<ref id="c117"><label>[117]</label><mixed-citation publication-type="journal"><string-name><given-names>Jeff</given-names> <surname>Miller</surname></string-name>. <article-title>The flanker compatibility effect as a function of visual angle, attentional focus, visual transients, and perceptual load: A search for boundary conditions</article-title>. <source>Perception &amp; psychophysics</source>, <volume>49</volume>(<issue>3</issue>):<fpage>270</fpage>–<lpage>288</lpage>, <year>1991</year>.</mixed-citation></ref>
<ref id="c118"><label>[118]</label><mixed-citation publication-type="journal"><string-name><given-names>Angela J</given-names> <surname>Yu</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>Dayan</surname></string-name>, and <string-name><given-names>Jonathan D</given-names> <surname>Cohen</surname></string-name>. <article-title>Dynamics of attentional selection under conflict: toward a rational bayesian account</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>35</volume>(<issue>3</issue>):<fpage>700</fpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c119"><label>[119]</label><mixed-citation publication-type="other"><string-name><given-names>Andrew M</given-names> <surname>Saxe</surname></string-name>, <string-name><given-names>James L</given-names> <surname>McClelland</surname></string-name>, and <string-name><given-names>Surya</given-names> <surname>Ganguli</surname></string-name>. <article-title>Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</article-title>. <source>arXiv preprint</source> arXiv:<pub-id pub-id-type="arxiv">1312.6120</pub-id>, <year>2013</year>.</mixed-citation></ref>
<ref id="c120"><label>[120]</label><mixed-citation publication-type="journal"><string-name><given-names>Mattia</given-names> <surname>Rigotti</surname></string-name>, <string-name><given-names>Omri</given-names> <surname>Barak</surname></string-name>, <string-name><given-names>Melissa R</given-names> <surname>Warden</surname></string-name>, <string-name><given-names>XiaoJing</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Nathaniel D</given-names> <surname>Daw</surname></string-name>, <string-name><given-names>Earl K</given-names> <surname>Miller</surname></string-name>, and <string-name><given-names>Stefano</given-names> <surname>Fusi</surname></string-name>. <article-title>The importance of mixed selectivity in complex cognitive tasks</article-title>. <source>Nature</source>, <volume>497</volume>(<issue>7451</issue>):<fpage>585</fpage>–<lpage>590</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c121"><label>[121]</label><mixed-citation publication-type="journal"><string-name><given-names>Alex</given-names> <surname>Roxin</surname></string-name>. <article-title>Drift–diffusion models for multiplealternative forced-choice decision making</article-title>. <source>The Journal of Mathematical Neuroscience</source>, <volume>9</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>23</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c122"><label>[122]</label><mixed-citation publication-type="other"><collab>Note that processing units can be assigned either to individual stimuli (“localist” representations), or sets of them can be used to represent different stimuli as different patterns of activity over the set (“distributed” representations). For expository purposes, in this article we present models using localist representations; however, all of the analyses and results can readily be extended to models using distributed representations</collab>.</mixed-citation></ref>
<ref id="c123"><label>[123]</label><mixed-citation publication-type="other"><collab>Here, we assume that each has already been learned. Further on, in Section IV, we consider how multiple tasks may be learned (i.e., “multi-task learning”), and how this may interact with the ability to perform them simultaneously</collab>.</mixed-citation></ref>
<ref id="c124"><label>[124]</label><mixed-citation publication-type="other"><collab>Note that, whereas the weights can differ across tasks, we continue to assume that the strengths of all of the associations constituting the stimulus-response mappings within a task are of equal strengths — an assumption that is commonly made in models of simple directmapping tasks [27, 115]; also see Note V D</collab>.</mixed-citation></ref>
<ref id="c125"><label>[125]</label><mixed-citation publication-type="other"><collab>Alternatively, this can be formulated as a leak term in models involving integrator and/or recurrent units, e.g. [37, 39]</collab>.</mixed-citation></ref>
<ref id="c126"><label>[126]</label><mixed-citation publication-type="other"><collab>Note that the input units shown in Figure 4a (<inline-formula><inline-graphic xlink:href="558214v1_inline65.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="558214v1_inline66.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) are not shown in Figure 2a) because they correspond to environmental inputs, as opposed to the <inline-formula><inline-graphic xlink:href="558214v1_inline67.gif" mimetype="image" mime-subtype="gif"/></inline-formula> units which refer to an agent’s representations of the environmental inputs</collab>.</mixed-citation></ref>
<ref id="c127"><label>[127]</label><mixed-citation publication-type="other"><collab>Note that these calculations focus on the probability of different outcomes of processing (i.e., accuracy of performance), relating this directly to costs without taking account of the dynamics of processing (i.e., response times) which, in principle, should also impact reward rate and thus costs. This is licensed by three assumptions. First, while longer response times associated with a weaker pathway and/or interference from a competing one clearly impact reward rate (i.e., by lengthening the time to reward), these are small with regard to the cost of inaccurate performance (which can eliminate reward altogether). Second, the costs in response time are also small with respect to the serialization costs associated with shared representations (again, owing to their effect on accuracy). Finally, while it is certainly possible that changes in the allocation of control may occur while a stimulus is being processed, and thus on a similar timescale (e.g. [78, 116–118]), we assume that for the most part strategic adjustments of control used to optimize performance more often occur on a longer timescale (e.g., from one stimulus to the next). Thus, for present purposes, we ignore the detailed dynamics of processing individual stimulus, and focus our analyses on the accuracy of such processing. Toward this end, our formulation assumes a particular probabilistic form for the outcome of processing as a function of inputs and connection strengths (e.g., in Equations 5, 8, 14 and 15). In Appendix A, we provide an analysis that grounds this form directly in widely used models of the dynamics of processing in simple mapping tasks, including the neural network model of the Stroop task on which we focus here</collab>.</mixed-citation></ref>
<ref id="c128"><label>[128]</label><mixed-citation publication-type="other"><collab>This is because, for independent sampling among stimulus dimensions (required by the definition of independent tasks; see Section II B above), the likelihood of incongruence grows exponentially with the number of features in each dimension, as compared to the likelihood of congruence which grows linearly</collab>).</mixed-citation></ref>
<ref id="c129"><label>[129]</label><mixed-citation publication-type="other"><collab>This simplification rests on the assumption that the strength of processing for a task at each layer of the network can be adequately summarized by a single value (the weight of the corresponding edge in the task graph). This value can be expected to be reasonably representative of the processing for individual task stimuli if the strengths of the connections implementing the mappings between each layer of processing for that task are roughly comparable across stimuli. That, in turn, is a reasonable assumption if task-relevant stimuli are sampled with approximately equal frequency during training on that task</collab>..</mixed-citation></ref>
<ref id="c130"><label>[130]</label><mixed-citation publication-type="other"><collab>This treatment is consistent with the focus of this article on the demands for control, and the definition of a task formalized for that purpose [57]: If two tasks that share a stimulus set require independent sampling, then they cannot be performed at the same time, and are therefore subject to control; and the only violation of this constraint is if they violate the definition of a task, that requires independence of sampling from any other</collab>.</mixed-citation></ref>
<ref id="c131"><label>[131]</label><mixed-citation publication-type="other"><collab>Note that Δβ, by offsetting the effects of β, also modulates the sensitivity of a node to its inputs, by placing it in the sensitive range of its response function. However, unlike ν, when Δβ is low (relative to β), it reduces the overall responsivity of the node, and not just its sensitivity to its inputs</collab>.</mixed-citation></ref>
<ref id="c132"><label>[132]</label><mixed-citation publication-type="other"><collab>Note that this is in contrast to single task processing, in which the performance cost Φ<sup>∗</sup> can always be brought to zero with sufficient allocation of control (see Figure 3</collab>).</mixed-citation></ref>
<ref id="c133"><label>[133]</label><mixed-citation publication-type="other"><collab>In models that address the dynamics of processing, speed is determined by the strength of connections (or corresponding parameters, such as the drift rate in the DDM), and thus subject to modification by adjustments in β and ω. However, along the lines discussed earlier (see Note V D), we ignore this factor because: changes in the speed of processing as a function of strength are relatively small (on the scale of 100s of milliseconds) relative to the time scales at which modifications in control parameters (seconds) and automaticity parameters (minutes to years) occur; b) for a constant speed, the same changes in the strength of processing are also expressed as changes in accuracy, which are the focus of the analyses presented in this article</collab>.</mixed-citation></ref>
<ref id="c134"><label>[134]</label><mixed-citation publication-type="other"><collab>Previous work has shown that the speed of learning also depends on the environmental statistics, and the opportunity to share representations [17, 35, 119]</collab>.</mixed-citation></ref>
<ref id="c135"><label>[135]</label><mixed-citation publication-type="other"><collab>The availability of the particular latent (weak) pathway required to perform a given task aligns with empirical findings of mixed selectivity neurons, especially in prefrontal cortex, which have been interpreted as providing a rich range of pre-existing conjunctive codes that are sufficient to support the associative requirements to perform any given task[120]</collab>.</mixed-citation></ref>
</ref-list>
<app-group>
<app id="app1">
<label>Appendix A</label>
<title>Relationship of Probabilistic Outcome to Dynamics of Processing</title>
<p>In the main text we provide an information theoretic analysis of performance in the Stroop task based on the neural network described in [<xref ref-type="bibr" rid="c27">27</xref>]. That ignores the <italic>dynamics</italic> of processing, and assumes a probabilistic form for the <italic>outcome</italic> of processing (i.e., accuracy). This implements our assumption that the dynamics of decision processing evolve on a timescale that is much faster than the forms of control allocation and optimization that are the focus of this article (see Note V D). Here, we provide a more direct derivation of the probabilistic form we use for the outcome of processing, that relates it to dynamical systems models commonly used to address processing in simple decision making tasks (e.g., [37–39, 121]), and closely related neural network models (e.g., [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c39">39</xref>]. We begin by assuming that each node in a task graph is comprised of a set of hidden units that exhibit their own dynamics of processing capable of selecting between different stimuli (see main text, <xref rid="fig1" ref-type="fig">Figure 1</xref>) and seek to collapse their dynamics, by focusing on steady state solutions. Inspired by the formalisms presented in [<xref ref-type="bibr" rid="c37">37</xref>] for two alternative forced choice decisions, and generalized to multi-choice decisions in [<xref ref-type="bibr" rid="c121">121</xref>], we can consider each set of processing hidden units in a population as making a decision at that layer of the network, and hidden node (<italic>H</italic><sub><italic>x</italic></sub>) within that population as representing a choice alternative at that level of processing, which accumulates evidence for that choice <italic>y</italic><sub><italic>x</italic></sub> with rate <italic>ω</italic><sub><italic>x</italic>1</sub>. Following [<xref ref-type="bibr" rid="c37">37</xref>], we can estimate the likelihood of activating <italic>R</italic><sub>1</sub> in response to the hidden unit <italic>H</italic><sub><italic>x</italic></sub> that provides its input as:
<disp-formula id="eqnA1">
<graphic xlink:href="558214v1_eqnA1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
which amounts to
<disp-formula id="eqnA2">
<graphic xlink:href="558214v1_eqnA2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
If evidence accrues with rates <bold><italic>ω</italic></bold>, at time <italic>t</italic> the evidence accrued will be <italic>t</italic><bold><italic>ω</italic></bold>, which is a constant factor for all <bold><italic>ω</italic></bold>, and can thus be renormalized away, implicitly defining the system’s natural temporal scale. Accordingly, the probability that the response is driven by node <italic>x</italic> can be expressed as :
<disp-formula id="eqnA3">
<graphic xlink:href="558214v1_eqnA3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Finally, for each response node (representing the set of responses within a given response dimension), the possibility of a <italic>no-response choice</italic> outcome can be accommodated by adding a dummy node <italic>H</italic><sub>0</sub>. For consistency with the previous sections, we will call the contribution to this term log <inline-formula><inline-graphic xlink:href="558214v1_inline55.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, corresponding in effect to self-inhibition of units in the response node. Thus, in aggregate, we have the set of equations
<disp-formula id="eqnA4">
<graphic xlink:href="558214v1_eqnA4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
that satisfy the closure property <inline-formula><inline-graphic xlink:href="558214v1_inline56.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. These are the equations used in the main body of the text, for describing the behavior of nodes in a task graph. In the Discussion, we consider whether and how the assumptions on which this simplification is based impact finer grained reward rate computations that take account of the dynamics of processing, and the corresponding allocation of control.</p>
</app>
<app id="app2">
<label>Appendix B</label>
<title>Full explanation of efficiencies for task architectures of <xref rid="fig5" ref-type="fig">Figure 5</xref></title>
<p>List of extended multitasks <inline-formula><inline-graphic xlink:href="558214v1_inline57.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for the examples in <xref rid="fig5" ref-type="fig">Figure 5</xref>
<disp-formula id="ueqn4">
<graphic xlink:href="558214v1_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table I.</label>
<caption><p>Edgelist for the Stroop task network in <xref rid="fig4" ref-type="fig">Figure 4</xref>. Here <italic>ω</italic><sub><italic>w</italic></sub> = 1.5, <italic>ω</italic><sub><italic>m</italic></sub> = 2, <italic>ω</italic><sub><italic>s</italic></sub> = 3, and <italic>κ</italic> = 1.2. For each different realization, we add .5 ∗ <italic>ϵ</italic> with <italic>ϵ</italic> a uniformly sampled noise in (0, 1). The <italic>β</italic> values were all set to 3 in this case.</p></caption>
<graphic xlink:href="558214v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table II.</label>
<caption><p>Edge weights for the graph in <xref rid="fig14" ref-type="fig">Figure 14</xref>. Here <italic>ω</italic><sub><italic>w</italic></sub> = 1.5, <italic>ω</italic><sub><italic>s</italic></sub> = 6, and <italic>κ</italic> = 1.8. For each different realization, we add .5 ∗ <italic>ϵ</italic> with <italic>ϵ</italic> a uniformly sampled noise in (0, 1).</p></caption>
<graphic xlink:href="558214v1_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</app>
<app id="app3">
<label>Appendix C: Tables</label>
</app>
</app-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93251.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>useful</bold> study addresses the interesting and challenging problem of how neural networks (including possibly the brain) can optimize performance while multi-tasking. The authors address this problem by introducing an information-theoretic framework that balances the costs of control and of automaticity to achieve a desired level of overall performance. They present detailed analyses of this framework, but overall the manuscript is not easily accessible to a broad audience, and the supporting evidence is currently <bold>incomplete</bold> (but could be greatly improved with substantial revisions). They use information-theoretic terminology in non-standard ways that are not clearly explained, leading to difficulties in interpreting the framework and comparing it to other computational approaches, and the relationship between their findings and empirical data is not always clear.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93251.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
A long literature in cognitive neuroscience studies how humans and animals adjudicate between conflicting goals. However, despite decades of research on the topic, a clear computational account of control has been difficult to pin down. In this project, Petri, Musslick, &amp; Cohen attempt to formalize and quantify the problem of control in the context of toy neural networks performing conflicting tasks.</p>
<p>This manuscript builds on the formalism introduced in Petri et al (2021), &quot;Topological limits to the parallel processing capability of network architectures&quot;, which describes a set of tasks as a graph in which input nodes (stimuli) are connected to output nodes (responses). Each edge in this graph links an input node to an output node, representing a &quot;task&quot;; i.e. a word reading task connects the input node &quot;word&quot; to the output node &quot;read&quot;. Cleverly, patterns of interference and conflict between tasks can be quantified from this graph. In the current manuscript, the authors extend this framework by converting these graphs into neural networks and a) allowing edges to be continuous rather than binary; b) introducing &quot;hidden layers&quot; of units between input and output nodes; and c) introducing a &quot;control&quot; signal that modulates edge weights. The authors then examine how, in such a network, optimal behavior may involve serial versus parallel execution of different sets of tasks.</p>
<p>Strengths:</p>
<p>
There is a longstanding belief in cognitive neuroscience that &quot;control&quot; manages conflicts by scheduling tasks to be executed in parallel versus serially; I applaud the efforts of the authors to give these intuitions a more concrete computational grounding.</p>
<p>My main scientific concern is that the authors focus on what seems like an arbitrary set of network architectures. The networks considered here are derived by converting task graphs, which represent a multitasking problem, into networks for _performing_ that multitasking problem. Frankly, these networks do not look like any neural network a computer scientist would use to actually solve a problem, nor do they seem biologically realistic. Furthermore, adding hidden layers to these networks only ever seems to make performance worse (Figures 4, 11), introducing unnecessary noise and interference; it would seem more useful to study a network architecture in which hidden layers fulfilled some useful purpose (as they do in the brain and machine learning).</p>
<p>However, this scientific concern is secondary to the major problem with this paper, which is clarity.</p>
<p>Major problem: A lack of clarity</p>
<p>I found this paper extremely difficult to read. To illustrate my difficulty, I will describe a subset of my confusion.</p>
<p>The authors define the &quot;entropy&quot; of an action in equation 1, but the content of the equation gives what is sometimes referred to as the &quot;surprisal&quot; of the action. Conventionally (as per Wikipedia and any introductory textbook I am familiar with), entropy is the &quot;expected surprisal&quot; of a random variable, not the surprisal of a single action. This creates immediate confusion going into the results. Furthermore, defining &quot;entropy&quot; this way means that &quot;information&quot; is functionally equivalent to accuracy for the purposes of this paper, in which case I do not know what has been gained by this excursion into (non-standard) information-theoretic terminology.</p>
<p>They next assert that equation 1 is the information _cost_ of an action. No motivation is given for this statement and I do not know what it means. In what sense is a &quot;cost&quot; associated with the negative logarithm of a probability?</p>
<p>In the next section II.B, the authors introduce a new formalism in which responses are represented by task graph nodes _R_. What is the relationship between an action _a_ and the responses _R_? Later, in section II.C, edges _f_ in the task graph are used as seemingly drop-in replacements for actions _a_.</p>
<p>I simply have no idea what is going on in equations 31 through 33. Where are the functions _R_ (not to be confused with the response nodes _R_) and _S_ defined? Or how are they approximated? What does the variable _t_ mean and why does it appear and disappear from equations seemingly at random?</p>
<p>Response times seem to be important, but as far as I can tell, nowhere do the authors actually describe how response times are calculated for the simulated networks.</p>
<p>Similar issues persist through the rest of the paper: unconventional formalism is regularly introduced using under-explained notation and without a clear relationship to the scientific questions at hand. As a result, the content and significance of the findings are largely inscrutable to me, and I suspect also to the vast majority of readers.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93251.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
The authors develop a normative account of automaticity-control trade-offs using the mathematics of information theory, which they apply to abstract neural networks. They use this framework to derive optimal trade-off solutions under particular task conditions.</p>
<p>Strengths:</p>
<p>
On the positive side, I appreciate the effort to rigorously synthesize ideas about multi-tasking within an information-theoretic framework. There is potentially a lot of promise in this approach. The analyis is quite comprehensive and careful.</p>
<p>Weaknesses:</p>
<p>
Generally speaking, the paper is very long and dense. I don't in principle mind reading long and dense papers (though conciseness is a virtue); it becomes more of a slog when it's not clear what new insights are being gained from laboring through the math. For example, after reading the Stroop section, I wasn't sure what new insight was provided by the information-theoretic formalism which goes beyond earlier models. Is this just an elegant formalism for expressing previously conceived ideas, or is there something fundamentally new here that's not predicted by other frameworks? The authors cite multiple related frameworks addressing the same kinds of data, but there is no systematic comparison of predictions or theoretical interpretations. Even in the Discussion, where related work is directly addressed, I didn't see much in terms of explaining how different models made different predictions, or even what predictions any of them make.</p>
<p>After a discussion of the Stroop task early in the paper, the analysis quickly becomes disconnected from any empirical data. The analysis could be much more impactful if it was more tightly integrated with relevant empirical data.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93251.1.sa3</article-id>
<title-group>
<article-title>Author Response</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Petri</surname>
<given-names>Giovanni</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1847-5031</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Musslick</surname>
<given-names>Sebastian</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8896-639X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Cohen</surname>
<given-names>Jonathan D.</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>We thank both the editors and the Reviewers for their thoughtful comments and recommendations, that will certainly help us improve the manuscript. Below we address in a brief format some of the comments made, and then outline the changes to the manuscript that we plan to implement in the revision.</p>
<p>We see three interrelated issues in the comments of the Reviewers:</p>
<p>•   the length and complexity of the manuscript;</p>
<p>•   the link to previously proposed formalisms;</p>
<p>•   the impact of adopting the proposed information-theoretic framework.</p>
<p>With regard to all of these issues, we would first like to highlight that the overall goal of our effort was to integrate con tributions to understanding the mechanisms underlying cognitive control across multiple different disciplines, using the information theoretic framework as a common formalism, while respecting and building on prior efforts as much as possible. Accordingly, we sought to be as explicit as possible about how we bridge from prior work using information theory, as well as neural networks and dynamical systems theory, which contributed to length of the original manuscript. While we continue to consider this an important goal, we will do our best to shorten and clarify the main exposition by reorganizing the manuscript as suggested by Reviewer #1 (i.e., in a way that is similar to what we did in our previous Nature Physics paper on multitasking). Specifically, we will move a substantially greater amount of the bridging material to the Supple mentary Information (SI), including the detailed discussion of the Stroop task, and the description of the link to Koechlin &amp; Summerfield’s [L1] information theory formalism. We will also now include an outline of the full model at the beginning of the manuscript, that includes control and learning, and then more succinctly describe simplifications that focus on specific issues and applications in the remainder of the document.</p>
<p>Along similar lines, we will revise and harmonize our presentation of the formalism and notations, to make these more consistent, clearer and more concise throughout the document. Again, some of the inconsistencies in notation arose from our initial description of previous work, and in particular that of Koechlin &amp; Summerfield[L1] that was an important inspiration for our work but that used slightly different notations. An important motivation for our introduction of new notation was that their formulation focused on the performance of a single task at a time, whereas a primary goal of our work was to extend the information theoretic treatment to simultaneous performance of multiple tasks. That is, in focusing on single tasks, Koechlin &amp; Summerfield could refer to a task simply as a direct association between stimuli and responses, whereas we required a way of being able to refer to sets of tasks performed at once (”multitasks”), which in turn required specification of internal pathways. Moreover, they do not provide a mechanism to compute the conditional information Q(a|s) of a response/action s conditioned to a stimulus s does not provide a way to compute it explicitly. Our formalism instead provides a way to explicitly unpack this expression in terms of the efficacies –automatic (Eq. 5) or controlled (Eq. 15)– which can also account for the competition between different stimuli {s1, s2, . . . sn}. It also describes explicitly the competition between multiple tasks (Eq. 18, and Eq. 25 for multiple layers), because different ways of processing schemes for the same combinations of stimuli/responses can incur different levels of internal dependencies and thus require different control strategies.</p>
<p>To mitigate any confusion over terminology we will, as noted above, move a detailed discussion of Koechlin &amp; Summer- field’s formulation, and how it maps to the one we present, to the SI, while taking care to introduce ours clearly at the beginning of the main document, and use it consistently throughout the remainder of the document. We will also make an important distinction – between informational and cognitive costs – more clearly, that we did not do adequately in the original manuscript.</p>
<p>Finally, to more clearly and concretely convey what we consider to be the most important contributions, we will restrict the number of examples we present to ones that relate most directly to the central points (e.g., the effect and limits of control in the presence of interference, and the differences in control strategy under limited temporal horizons).
Accompanying our revision, we will also provide a full point-by-point response to the comments and questions raised by the Reviewers. We summarize some the key points we will address below.</p>
<p>PRELIMINARY REPLY TO THE REPORT OF REVIEWER #1</p>
<p>We want to thank the Reviewer for the time and effort put into reviewing our paper and constructive feedback that was provided. We also thank the Reviewer for recognizing the need for a clear computational account of how ”control” manages conflicts by scheduling tasks to be executed in parallel versus serially, and for the positive evaluation on our “efforts of the authors to give these intuitions a more concrete computational grounding.”. As noted in the general reply above, we regret the lack of clarity in several parts of the manuscript and in our introduction and use of the formalism.
We consider the following to be the main points to be addressed:</p>
<p>•   the role of task graphs and their mapping to standard neural architectures</p>
<p>•   the description of entropy and related information-theoretic concepts;</p>
<p>•   confusing choice of symbols in our notation between stimuli/responses and serialization/reconfiguration costs;</p>
<p>•   missing definition of response time;</p>
<p>Regarding the first part point, we acknowledge that the network architectures we focus on do not draw direct inspiration from conventional machine learning models. Instead, our approach is rooted in the longstanding tradition of using (often simpler, but also more readily interpretable) neural network models to address human cognitive function and how this may be implemented in the brain [L2]; and, in particular, the mechanisms underlying cognitive control (e.g., [L3, L4]). In this context, we emphasize that, for analytical clarity, we deliberately abstract away from many biological details, in an effort to identify those principles of function that are most relevant to cognitive function. Nevertheless, our network architecture is inspired by two concepts that are central to neurobiological mechanisms of control: inhibition and gain modulation. Specifi- cally, we incorporate mutual inhibition among neural processing units, a feature represented by the parameter β. This aspect of our model is consistent with biologically inspired frameworks of neural processing, such as those discussed by Munakata et al. (2011)[L5], reflecting the competitive dynamics observed in neural circuits. Moreover, we introduce the parameter ν to represent a strictly modulatory form of control, akin to the role of neuromodulators in the brain. This modulatory control adjusts the sensitivity of a node to differences among its inputs (e.g., Servan-Schreiber, Printz, &amp; Cohen, (1990)[L6]; Aston-Jones &amp; Cohen (2005)[L7]). Finally, as the Reviewer notes, additional hidden layers can improve expressivity in neural networks, enabling the efficient implementation of more complex tasks, and are a universal feature of biological and artificial neural systems. We thus examined multitasking capability under the assumption that multiple hidden layers are present in a network; irrespective of whether they are needed to implement the corresponding tasks.</p>
<p>Regarding the second point, as noted above, we believe that the confusion arose from our review of the work by Koechlin &amp; Summerfield. In their formalism, in which an action a is chosen (from a set of potential actions) with probability p(a), the cost of choosing that action is − log p(a). This is usually referred to as the information content or, alternatively, the localized entropy [L8]. As the Reviewer correctly observed, the canonical (Shannon) entropy is actually the expectation lEa[− log p(a)] over the localized entropies of a set of actions. In summarizing their formulation, we misleadingly stated that ”they used standard Shannon entropy formalism as a measure of the information required to select the action a.” We will now correct this to state: “[..] they used local entropy (− log p(a)) as a measure of the information required to select the action a, that can be treated as the cost of choosing that action.” We follow this formulation in our own, referring to informational cost as Ψ, and generalizing this to include cases in which more than one action may be chosen to perform at a time.</p>
<p>Regarding the third point, the confusion is due to our use of the letters S and R for both the stimulus and response units (in Sec. II.B) and then serialization and reconstruction costs (in eqs 31-33). We will fix this by renaming the serialization and reconstruction costs more explicitly as S er and Rec.</p>
<p>Finally, we realized we never explicitly stated the expression of the response time we used, but only pointed to it in the literature. In the manuscript we used the expression given in Eq. 53 of [L9], which provides response times as function of the error rates ER and the number of options <inline-formula id="sa3equ1"><inline-graphic xlink:href="elife-93251-sa3-equ1.jpg" mimetype="image" mime-subtype="jpeg"/></inline-formula>.</p>
<p>PRELIMINARY REPLY TO THE REPORT OF REVIEWER #2</p>
<p>We want to thank the Reviewer for recognizing our effort to ”rigorously synthesize ideas about multi-tasking within an information-theoretic framework” and its potential. We also thank the Reviewer for the careful comments.</p>
<p>To our best understanding, and similarly to Reviewer #1, the main comments of the Reviewer are on:</p>
<p>•   the length and density of the paper;</p>
<p>•   the presentation of the Koechlin &amp; Summerfield’s formalism, and the mismatch/lack of clarity of ours in certain points;</p>
<p>•   the added value of the information theoretic formalism.</p>
<p>Regarding the first two points, which are common to Reviewer #1, we plan to move a significant part of the manuscript to the Supplementary Information, both to improve readability and make the manuscript shorter, as well as to provide one consistent and cleaner formalism (in particular with regards to the typos and errors highlighted by the Reviewer). In par- ticular, with respect to the comment on Eq. 4-5-6, we will clarify that the probability p[ fi j] is the probability that a certain input dimension (i in this case) is selected by on node j to produce its response (averaged over the individual inputs in each input dimension). We will also take care to make sure that the definition and domain of the various probabilities and probability distributions we use are clearly delineated (e.g. where the costs computed for tasks and task pathways come from).</p>
<p>Regarding the third point, we hope that our work offers value in at least two ways: i) it helps bring unity to ideas and descriptions about the capacity constraints associated with cognitive control that have previously been articulated in different forms (viz., neural networks, dynamical systems, and statistical mechanical accounts); and ii) doing so within an information theoretic framework not only lends rigor and precision to the formulation, but also allows us to cast the allocation of control in normative form – that is, as an optimization problem in which the agent seeks to minimize costs while maximizing gains. While we do not address specific empirical phenomena or datasets in the present treatment, we have done our best to provide examples showing that: a) our information theoretic formulation aligns with treatments using other formalisms that have been used to address empirical phenomena (e.g., with neural network models of the Stroop task); and b) our formulation can be used as a framework for providing a normative approach to widely studied empirical phenomena (e.g., the transition from control-dependent to automatic processing during skill acquisition) that, to date, have been addressed largely from a descriptive perspective; and that it can provide a formally rigorous approach to addressing such phenomena.</p>
<p>[L1] E. Koechlin and C. Summerfield, Trends in cognitive sciences 11, 229 (2007).</p>
<p>[L2] J. L. McClelland, D. E. Rumelhart, P. R. Group, et al., Explorations in the Microstructure of Cognition 2, 216 (1986).</p>
<p>[L3] J. D. Cohen, K. Dunbar, and J. L. McClelland, Psychological Review 97, 332 (1990).</p>
<p>[L4] E. K. Miller and J. D. Cohen, Annual review of neuroscience 24, 167 (2001).</p>
<p>[L5] Y. Munakata, S. A. Herd, C. H. Chatham, B. E. Depue, M. T. Banich, and R. C. O’Reilly, Trends in cognitive sciences 15, 453 (2011).</p>
<p>[L6] D. Servan-Schreiber, H. Printz, and J. D. Cohen, Science 249, 892 (1990).</p>
<p>[L7] G. Aston-Jones and J. D. Cohen, Annu. Rev. Neurosci. 28, 403 (2005).</p>
<p>[L8] T. F. Varley, Plos one 19, e0297128 (2024).</p>
<p>[L9] T. McMillen and P. Holmes, Journal of Mathematical Psychology 50, 30 (2006).</p>
</body>
</sub-article>
</article>