<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">108223</article-id>
<article-id pub-id-type="doi">10.7554/eLife.108223</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.108223.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Two time scales of adaptation in human learning rates</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Simoens</surname>
<given-names>Jonas</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>Jonas.Simoens@hotmail.com</email>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2619-8225</contrib-id>
<name>
<surname>Braem</surname>
<given-names>Senne</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>Senne.Braem@UGent.be</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2919-1528</contrib-id>
<name>
<surname>Verbeke</surname>
<given-names>Pieter</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chen</surname>
<given-names>Haopeng</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8279-6118</contrib-id>
<name>
<surname>Mattioni</surname>
<given-names>Stefania</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0004-9756-7421</contrib-id>
<name>
<surname>Chai</surname>
<given-names>Mengqiao</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0150-8776</contrib-id>
<name>
<surname>Schuck</surname>
<given-names>Nicolas W</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7783-4754</contrib-id>
<name>
<surname>Verguts</surname>
<given-names>Tom</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>Tom.Verguts@UGent.be</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00cv9y106</institution-id><institution>Department of Experimental Psychology, Ghent University</institution></institution-wrap>, <city>Ghent</city>, <country country="BE">Belgium</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00g30e956</institution-id><institution>Institute of Psychology, Universität Hamburg</institution></institution-wrap>, <city>Hamburg</city>, <country country="DE">Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Diaconescu</surname>
<given-names>Andreea Oliviana</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country>Canada</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="supported-by"><p><bold>Financial Disclosure and acknowledgements</bold>: This work was funded by an FWO fellowship awarded to Jonas Simoens (#11K5121N), an FWO project grant awarded to Tom Verguts and Senne Braem (G010319N), and an ERC Starting grant awarded to Senne Braem (European Union’s Horizon 2020 research and innovation program, Grant agreement 852570). NWS was supported by the Excellence Strategy of the Federal Government and the Länder and a ERC Starting Grant (ERC StG REPLAY-852669). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. The authors thank Matthew Nassar for useful discussion.</p></fn>
<fn id="n2" fn-type="con"><p><bold>Author contributions</bold>: Jonas Simoens: data curation, formal analysis, funding acquisition, investigation, methodology, project administration, resources, software, validation, visualisation, writing - original draft preparation. Senne Braem and Tom Verguts: conceptualisation, funding acquisition, methodology, project administration, supervision, writing - review &amp; editing. Nicolas Schuck: supervision, writing - review &amp; editing. Pieter Verbeke, Haopeng Chen, Stefania Mattioni, and Mengqiao Chai: data curation, investigation.</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-10-02">
<day>02</day>
<month>10</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP108223</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-07-31">
<day>31</day>
<month>07</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-06-21">
<day>21</day>
<month>06</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.06.05.658048"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Simoens et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Simoens et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-108223-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Different situations may require radically different information updating speeds (i.e., learning rates). Some demand fast learning rates, while others benefit from using slower ones. To adjust learning rates, people could rely on either global, meta-learned differences between environments, or faster but transient adaptations to locally experienced prediction errors. Here, we introduce a new paradigm that allows researchers to measure and empirically disentangle both forms of adaptations. Participants performed short blocks of trials of a continuous estimation task – fishing for crabs – on six different islands that required different optimal (initial) learning rates. Across two experiments, participants showed fast adaptations in learning rate within a block. Critically, participants also learned global environment-specific learning rates over the time course of the experiment, as evidenced by computational modelling and by the learning rates calculated on the very first trial when revisiting an environment (i.e., unconfounded by transient adaptations). Using representational similarity analyses of fMRI data, we found that differences in voxel pattern responses in the central orbitofrontal cortex correlated with differences in these global environment-specific learning rates. Our findings show that humans adapt learning rates at both slow and fast time scales, and that the central orbitofrontal cortex may support meta-learning by representing environment-specific task-relevant features such as learning rates.</p>
</abstract>
<funding-group>
<award-group id="funding-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/03q83t159</institution-id>
<institution>Fund for Scientific Research</institution>
</institution-wrap>
</funding-source>
<award-id>11K5121N</award-id>
</award-group>
<award-group id="funding-1a">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/03q83t159</institution-id>
<institution>Fund for Scientific Research</institution>
</institution-wrap>
</funding-source>
<award-id>G010319N</award-id>
</award-group>
<award-group id="funding-2">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/0472cxd90</institution-id>
<institution>European Research Council</institution>
</institution-wrap>
</funding-source>
<award-id award-id-type="doi">10.3030/852570</award-id>
</award-group>
<award-group id="funding-2a">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/0472cxd90</institution-id>
<institution>European Research Council</institution>
</institution-wrap>
</funding-source>
<award-id award-id-type="doi">10.3030/852669</award-id>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>RDM matrices are added in Figure 6.
Coronal slices are added in Figure 7.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Decisions that humans make on a daily basis range from the ordinary, such as what to have for lunch, to the life-defining, such as what career to pursue. The computational framework of reinforcement learning (RL) stipulates that such decision making requires estimating and continuously updating relevant feature values of specific options (e.g., the nutritional value, the tastiness, and the price of the lunch), and subsequently using these estimates to make a good choice. The most common RL approach to learning such values is the delta rule (<xref ref-type="bibr" rid="c37">Rescorla &amp; Wagner, 1972</xref>):
<disp-formula>
<graphic xlink:href="658048v2_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the (<italic>Q</italic>) value of action <italic>a</italic> at time <italic>t</italic> + 1 is updated in proportion to the error made in predicting the outcome <italic>r</italic> of action <italic>a</italic> at time <italic>t</italic> (i.e., the prediction error). This learning algorithm requires choosing a learning rate <italic>α</italic>. Performance of the algorithm depends on the value of this parameter, and different values are optimal for different environments (<xref ref-type="bibr" rid="c45">Sutton &amp; Barto, 2018</xref>; <xref ref-type="bibr" rid="c48">Verbeke &amp; Verguts, 2024</xref>). Learning the parameters that shape learning is termed meta-learning (<xref ref-type="bibr" rid="c6">Binz et al., 2024</xref>; <xref ref-type="bibr" rid="c50">Wang et al., 2018</xref>), and theories of human meta-learning suggest that people can flexibly adapt their learning rates to the environment (<xref ref-type="bibr" rid="c28">Mathys, 2011</xref>; <xref ref-type="bibr" rid="c41">Schweighofer &amp; Doya, 2003</xref>; <xref ref-type="bibr" rid="c42">Silvetti et al., 2018</xref>). Similarly, in artificial agents, setting a learning rate is critical, and a breakthrough in AI was the development of an algorithm that set its learning rate in an adaptive manner (Adam optimizer (<xref ref-type="bibr" rid="c26">Kingma &amp; Ba, 2017</xref>)).</p>
<p>Consistent with these ideas, humans can adjust their learning rate to the reward volatility and variability of a given environment (<xref ref-type="bibr" rid="c5">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c9">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="c14">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="c22">Goris et al., 2021</xref>). An important limiting aspect of these studies, however, is that participants typically spend extended periods of time within one environment. Therefore, previous studies cannot dissociate between fast, transient adaptations (i.e., fast time scale learning within an environment; (<xref ref-type="bibr" rid="c4">Bai et al., 2014</xref>; <xref ref-type="bibr" rid="c27">Krugel et al., 2009</xref>; <xref ref-type="bibr" rid="c30">Nassar et al., 2012</xref>) versus learned environment-specific learning rates that can be reused when revisiting an environment (i.e., slow time scale learning about an environment (<xref ref-type="bibr" rid="c43">Simoens et al., 2024</xref>)). From an optimality perspective (Kalman filter; (<xref ref-type="bibr" rid="c16">Dayan et al., 2000</xref>)), the learning rate should gradually decrease as the task statistics within an environment become increasingly known. When the environmental statistics are reset (e.g., when visiting a new environment), learning rate should be reset as well. Nevertheless, if the higher-order statistics in an environment remain fixed (e.g., amount of noise in the environment), an optimal agent could (meta-)learn higher-order parameters (e.g., the starting point of the learning rate) so that learning in the environment becomes increasingly efficient. From this perspective, people could learn about the optimal learning rate at two levels: On a fast time scale in response to local prediction errors as an environment becomes known, and on a slower time scale as an environment’s higher-order statistics and optimal initial settings are learned.</p>
<p>To test this, we administered a novel task in two experiments in which participants went fishing for crabs on six different locations around an island that allowed us to measure both trial-by-trial (transient) adaptations in learning rate as a function of locally experienced prediction errors, as well as learned variations in learning rate adapted to the environmental statistics. This task required continuous responses (i.e., estimating the crab locations) and provided continuous feedback (on those crab locations), which allowed us to estimate learning rates on a trial-by-trial basis by calculating how much people updated their fishing location based on feedback (<xref ref-type="bibr" rid="c30">Nassar et al., 2012</xref>). Importantly, each of the six locations around the island had one of three different optimal initial learning rates. This was achieved by changing two quantities that governed the outcome (crab location) distributions of each island: the standard deviation of the distribution that determined the latent mean of crab locations upon an island visit (prior distribution), and the standard deviation of the noise with which crabs were sampled around their latent mean (sampling distribution). As a result, different locations around the island required different learning rates for optimal task performance.</p>
<p>Participants switched between locations on a block-by-block basis, where blocks only lasted two to ten trials (depending on the experiment, see below). Crucially, without prior experience, environments were indistinguishable up to the moment feedback was provided on the second trial of each block, so any differences in learning rates between locations after feedback on the first trial suggest meta-learning of environment-specific learning rates. Across two experiments, we found that participants dynamically updated their learning rate within environments, but also, critically, learned over time to use different initial learning rates when revisiting different environments, showing the meta-learning of learning rates tailored to the different environments.</p>
<p>In the second experiment, we also collected fMRI data to investigate which brain regions are involved in representing sustained environment-specific learning rates. Namely, we performed representational similarity analyses on neural voxel pattern activity when participants had just been transported to the next location around the island, while they were preparing to perform the task in a particular environment. We hypothesized that the orbitofrontal cortex (OFC) would be the main region involved in this preparation, consistent with its broader role in the representation of task states (<xref ref-type="bibr" rid="c29">Moneta et al., 2024</xref>; <xref ref-type="bibr" rid="c39">Schuck et al., 2016</xref>; <xref ref-type="bibr" rid="c44">Stalnaker et al., 2015</xref>; <xref ref-type="bibr" rid="c51">Wilson et al., 2014</xref>)– the integration of contextual information that is necessary to predict the outcomes of decisions, crucial for reward maximization. While shifts in task state representations and value computations are often linked to the OFC, the environment-specific responses to reward predictions are often linked to the basal ganglia. Therefore, we also studied ventral striatum activity as a candidate for processing prediction errors on the first trial of each block. That is, given the role of the ventral striatum in processing (reward) prediction errors (<xref ref-type="bibr" rid="c10">Calderon et al., 2021</xref>; <xref ref-type="bibr" rid="c32">O’Doherty et al., 2004</xref>; <xref ref-type="bibr" rid="c36">Pessiglione et al., 2006</xref>; <xref ref-type="bibr" rid="c40">Schultz et al., 1997</xref>), we assumed that this region would show the effect of these learned environment-specific learning rates through a differential response to on-task (reward) prediction errors.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Experiment 1</title>
<p>Forty-nine participants performed a novel crab-fishing task. At the start of each of 60 blocks, a boat took them to one of six locations around an island (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). In each location, participants could drop a cage on a chosen position ten times (trials), with the goal to catch as many crabs as possible (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). Each time a cage was dropped, five crabs appeared and spread out from one position in the sand sampled from the sampling distribution <italic>S ∼ N</italic>(<italic>µ<sub>s</sub>,</italic> <inline-formula><inline-graphic xlink:href="658048v2_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula>), a truncated normal distribution ranging between <italic>µ<sub>s</sub> ± 1.65 * σ<sub>s</sub></italic>. Each crab was either caught by the cage or ran away. At the beginning of each block, the latent mean of the sampling distribution, <italic>µ<sub>s</sub></italic>, was sampled from the prior distribution <italic>µ<sub>s</sub> ∼ N</italic>(<italic>µ<sub>p</sub>,</italic> <inline-formula><inline-graphic xlink:href="658048v2_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>), truncated between <italic>µ<sub>p</sub> ± 1.65 * σ<sub>p</sub></italic>, with <italic>µ<sub>p</sub></italic> set to be the centre of the screen, where the cage position was initialized on the 1st trial of each block. Crucially, the variance of the latent mean <inline-formula><inline-graphic xlink:href="658048v2_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and the noise variance around that mean <inline-formula><inline-graphic xlink:href="658048v2_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, were dependent on the location around the island. In two randomly selected adjacent locations, <inline-formula><inline-graphic xlink:href="658048v2_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula> was large, while <inline-formula><inline-graphic xlink:href="658048v2_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula> was small. Here, the true mean position of the crabs was widely dispersed and could be nearly everywhere on the screen, while the individual crabs appeared very close to that true mean. Hence, participants could infer the mean crab position from a single observation and performed best if they strongly adjusted the position of the cage after the first trial. We termed this the <italic>low noise environment</italic>, which required a high initial learning rate (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). On the two adjacent locations on the exact opposite side of the island, the situation was reversed (i.e., small <inline-formula><inline-graphic xlink:href="658048v2_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, large <inline-formula><inline-graphic xlink:href="658048v2_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, henceforth the <italic>high noise environment</italic>), requiring a low initial learning rate. Finally, on the two locations in between, <inline-formula><inline-graphic xlink:href="658048v2_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="658048v2_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, were intermediate and equal (i.e., the <italic>medium noise environment</italic>), requiring an intermediate initial learning rate.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Experimental design.</title><p><bold>A:</bold> Participants went fishing for crabs on six different locations around an island which differed in terms of optimal initial learning rate. At the beginning of each block, <italic>µ<sub>s</sub></italic> was sampled from the prior distribution <italic>µ<sub>s</sub> ∼ N(µ<sub>p</sub>,</italic> <inline-formula><inline-graphic xlink:href="658048v2_inline22.gif" mime-subtype="gif" mimetype="image"/></inline-formula>,<italic>)</italic>, truncated between <italic>µ<sub>p</sub> ± 1.65 * σ<sub>p</sub></italic>, with <italic>µ<sub>p</sub></italic> = the centre of the screen. Subsequently, on each trial, once a cage was dropped, five crabs appeared and spread out from one location in the sand sampled from the sampling distribution <italic>S ∼ N(µ<sub>s</sub>,</italic> <inline-formula><inline-graphic xlink:href="658048v2_inline23.gif" mime-subtype="gif" mimetype="image"/></inline-formula><italic>)</italic>, truncated between <italic>µ<sub>s</sub> ± 1.65 * σ<sub>s</sub></italic>, each of which was either caught by the cage or ran away. <bold>B:</bold> Overview of optimal learning rates for performing the task for 1 block of trials according to the Kalman filter assuming that measurement uncertainty = <inline-formula><inline-graphic xlink:href="658048v2_inline24.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and estimate uncertainty = <inline-formula><inline-graphic xlink:href="658048v2_inline25.gif" mime-subtype="gif" mimetype="image"/></inline-formula> on trial 1 (See <italic>Model estimation and selection</italic> for details). <bold>C:</bold> Overview of the trial procedure. At the beginning of each block, participants were taken to one of six locations around the island. On each trial, participants positioned the cage somewhere along the x-axis of the screen and dropped it. As the cage sank, five crabs appeared out of one point in the sand and spread out. When the cage reached the ocean floor, crabs caught by the cage remained there while the other crabs ran away. At the start of the next trial, the cage was again at the top of the screen, but at the same x-coordinate where it was dropped in the last trial, and a little heap of sand was left where the five crabs had appeared out of the sand on the last trial.</p></caption>
<graphic xlink:href="658048v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>On the first trial of each block, participants could only drop the cage in the centre of the screen. Crucially, the position of the first crabs was determined by the randomly drawn latent mean (with variance <inline-formula><inline-graphic xlink:href="658048v2_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula>), and the variance of the sampling distribution, <inline-formula><inline-graphic xlink:href="658048v2_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula>., i.e. corresponding to a normal distribution with mean equal to the centre of the screen and variance equal to <inline-formula><inline-graphic xlink:href="658048v2_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Although <inline-formula><inline-graphic xlink:href="658048v2_inline14.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="658048v2_inline15.gif" mime-subtype="gif" mimetype="image"/></inline-formula> differed across the different environments as described above, their sum was constant, and hence the normal distribution for the first trial in a block was identical across the three environments. Therefore, the first prediction errors participants experienced across the three environments were identical, which we also confirmed by analysing the feedback data. This implies that variations in the first learning rate are uniquely attributable to the meta-learned learning rates.</p>
<sec id="s2b">
<title>Behavioural results</title>
<p>We first evaluated whether our design was successful in inducing variations in learning rate within environments – where learning rate was defined as the percentage of the direction taken from the last cage drop to last appearance of crabs (see Methods). Specifically, consistent with the optimality analyses depicted in <xref rid="fig1" ref-type="fig">Figure 1B</xref>, we assumed that learning rate would decrease over the course of a block, as participants learned more and more about the crab locations within that block. Consistently, a linear mixed effects model analysis, with a random intercept for participant and random slopes for environment and trial number, indicated that learning rates significantly decreased over trials (within blocks) (<xref rid="fig2" ref-type="fig">Figure 2A</xref>; <italic>ß</italic> = -0.056, SE = 0.006, <italic>p</italic> &lt; .001).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Behavioural results Experiment 1.</title><p><bold>A:</bold> Group-level mean of each participant’s median learning rate for each trial in each environment (See <italic>Behavioural data analyses</italic> for details). Error bars represent standard errors of the means. <bold>B</bold>: Detailed overview of all participants’ median initial learning rates. <bold>C-D:</bold> Evolution of (group-level mean) learning rates over trials (within blocks) for the first half (C) and the second half (D) of the task separately.</p></caption>
<graphic xlink:href="658048v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Second, to probe whether people were also able to learn and adapt their learning rate to the environment-specific differences, we analysed the learning rates separately focusing on the second trial only (after their first feedback). Differences in learning rates between environments after first feedback could not be attributed to differences in experienced prediction errors, as prediction errors after the first trial were similar across the three environments. Instead, differences in this initial learning rate had to reflect a reaction to learned statistics of the environment from earlier environment visits (i.e., meta-learning). Indeed, we found that observed learning rates on the second trial of each block were significantly higher in the low noise compared to in the high noise environment, <italic>t</italic>(49) = 2.896, <italic>p</italic> = .003 (see <xref rid="fig2" ref-type="fig">Figure 2B</xref>). Moreover, these learning rates were also higher in the low noise compared to in the medium noise environment, <italic>t</italic>(49) = 2.407, <italic>p</italic> = .01, but not in the medium noise compared to in the high noise environment, <italic>t</italic>(49) = 1.304, <italic>p</italic> = .099.</p>
<p>Assuming these differences could only have developed over time, after sufficient experience with each of the environments, we also evaluated whether they were more pronounced in the second half of the experiment, compared to the first half. <xref rid="fig2" ref-type="fig">Figure 2C-D</xref> indeed suggests this difference in learning rates between the low and high noise environment after the second trial could not yet be observed in the first half of the experiment (<italic>t</italic>(49) = 0.415, <italic>p</italic> = .34), while it appeared in the second half (<italic>t</italic>(49) = 2.067, <italic>p</italic> = .022). However, this was not further corroborated by an interaction between time (first vs. second half of the task) and environment (low vs. medium vs. high noise environment) (<italic>F</italic>(2, 98) = 0.923, <italic>p</italic> = .401).</p>
</sec>
<sec id="s2c">
<title>Modelling results</title>
<p>Next, we turned to computational modelling to evaluate which model could best describe the variations in learning rate reported above. We fitted six models to the data using hierarchical Bayesian analysis (<xref ref-type="bibr" rid="c2">Ahn et al., 2017</xref>). We fitted three model types, one of which assumed no local adaptations to learning rates, and two of which allowed for learning rates to be adjusted on a trial-by-trial basis. For each of these model types, we tested both a variant with (initial) learning rates for each environment separately (i.e., environment-specific), and one with a single initial learning rate (non-environment-specific). The first two models were the environment-specific and non-environment specific versions of the Rescorla-Wagner model. The Rescorla-Wagner model assumes that participants updated their <italic>µ<sub>s</sub></italic> estimates (within blocks) using the delta rule with a fixed learning rate (across trials, within blocks). The next two models were the environment-specific and the non-environment-specific version of the Kalman filter. The Kalman filter assumes that participants updated their <italic>µ<sub>s</sub></italic> estimates (within blocks) using the delta rule, where the learning rate is a function of estimation noise and measurement noise. Because estimation noise gradually decreases in a block (as people are increasingly aware of the mean crab location), learning rate gradually decreases. Here, initial estimation noise is the free, estimated parameter. The final two models were the environment- specific and non-environment-specific versions of a model that allowed for local, prediction-error weighted changes to the learning rate, here referred to as the Bai model (<xref ref-type="bibr" rid="c4">Bai et al., 2014</xref>; <xref ref-type="bibr" rid="c43">Simoens et al., 2024</xref>). The Bai model also assumes that participants updated their <italic>µ<sub>s</sub></italic> estimates (within blocks) using the delta rule. The Bai model further assumes that participants start with an initial learning rate that they up- and down-regulate (within blocks) in proportion to experienced prediction errors. Here, both initial learning rate and decay rate are free, estimated parameters, and both were either environment-specific or non-environment-specific.</p>
<p>According to the leave-one-out information criterion (LOOIC) (<xref ref-type="bibr" rid="c47">Vehtari et al., 2017</xref>), the environment-specific Bai model fitted the data best (<xref rid="tbl1" ref-type="table">Table 1</xref>), indicating that participants indeed learned to use environment-specific initial learning rates and that they indeed decreased their learning rates over trials (in contrast to what the RW model predicts), but that they did so driven by experienced prediction errors rather than in a statistically optimal way (in contrast to what the Kalman filter predicts).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1</label>
<graphic xlink:href="658048v2_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>The posterior probabilities that the initial learning rates (<xref rid="fig3" ref-type="fig">Figure 3A</xref>; estimated by the environment-specific Bai model) were higher in the low noise compared to the high noise environment was 0.999; in the low noise compared to the medium noise environment was 0.962; and in the medium noise compared to the high noise environment was 0.999. Decay rates were not significantly different from each other (<xref rid="fig3" ref-type="fig">Figure 3B</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Bai model estimation results Experiment 1.</title><p>The density plots on the left side of each subfigure show the full posterior densities over the means of the group-level distributions of the relevant parameters. The scatter plots on the right side of each subfigure show the means of all individual-level posterior distributions of the relevant parameters.</p></caption>
<graphic xlink:href="658048v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Experiment 2</title>
<p>To establish whether our findings could be reproduced in an independent sample and to investigate where in the brain environment-specific learning rates are represented, we ran a near-exact replication of our first experiment, which 53 participants performed inside an MR-scanner. Experiment 2 consisted of 60 blocks that were identical to the blocks in Experiment 1, except that they consisted of only eight trials. Additionally, 60 blocks consisting of only two trials were randomly intermixed with the 60 longer blocks. These shorter blocks were included to increase power for analysis on the first few trials within blocks. Furthermore, we equipped the fishing boat with a laser pointer (i.e., a vertical red line from the middle of the cage to the sand) so participants could estimate more precisely where their cage would land when dropped. Similarly, to avoid miscalibrations in relation to their previous attempt, we reminded participants of their last cage location by placing a red cross wherever their cage last appeared.</p>
<sec id="s3a">
<title>Behavioural results</title>
<p>As in Experiment 1, we found that learning rates significantly decreased over trials within blocks (<xref rid="fig4" ref-type="fig">Figure 4A</xref>; <italic>ß</italic> = -0.059, SE = 0.008, <italic>p</italic> &lt; .001). Also, observed learning rates on the second trial of each block were significantly different across environments (<xref rid="fig4" ref-type="fig">Figure 4B</xref>; <italic>F</italic>(2, 104) = 12.839, <italic>p</italic> &lt; .001). That is, they were significantly higher in the low noise compared to in the high noise environment (<italic>t</italic>(52) = 3.843, <italic>p</italic> &lt; .001), in the low noise compared to in the medium noise environment (<italic>t</italic>(52) = 1.998, <italic>p</italic> = .025), and in the medium noise compared to in the high noise environment (<italic>t</italic>(52) = 3.555, <italic>p</italic> &lt; .001).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Behavioural results Experiment 2.</title><p><bold>A:</bold> Group-level mean of each participant’s median learning rate for each trial in each environment (See <italic>Behavioural data analyses</italic> for details). Error bars represent standard errors of the means. <bold>B</bold>: Detailed overview of all participants’ median initial learning rates. One participant’s median initial learning rate of -0.674 in the high noise environment is not visible on the plot. <bold>C-E:</bold> Evolution of (group-level mean) learning rates over trials (within blocks) for each quarter of the task separately.</p></caption>
<graphic xlink:href="658048v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Because we had twice as many first trials as in Experiment 1, we next compared quarters of the task rather than halves of the task as done in Experiment 1, as a more sensitive measure of what they learned over the course of the experiment. In line with our expectation that initial learning rates reflect learned statistics of the environment, a significant interaction between time (four quarters of the tasks) and environment (three measurement noises) indicated that learning rates on the second trial of each block became more environment-specific over time (<xref rid="fig4" ref-type="fig">Figure 4C-E</xref>; <italic>F</italic>(6, 312) = 2.819, <italic>p</italic> = .011). To unpack this interaction, in the first quarter, initial learning rates were significantly higher in the medium noise environment compared to the high noise environment (<italic>t</italic>(52) = 2.252, <italic>p</italic> = .014), but not in the low noise compared to the high noise environment (<italic>t</italic>(52) = 1.338, <italic>p</italic> = .093), nor in the low noise compared to in the medium noise environment (<italic>t</italic>(52) = -0.258, <italic>p</italic> = .601). In the second quarter, initial learning rates were significantly higher in the low noise compared to in the high noise environment (<italic>t</italic>(52) = 2.442, <italic>p</italic> = .009) and in medium noise compared to in the high noise environment (<italic>t</italic>(52) = 2.443, <italic>p</italic> = .009), but not in the low noise compared to in the medium noise environment (<italic>t</italic>(52) = -0.12, <italic>p</italic> = .548). In the third and fourth quarters, initial learning rates were significantly higher in the low noise compared to in the high noise environment (<italic>t</italic>(52) = 4.164, <italic>p</italic> &lt; .001; <italic>t</italic>(52) = 4.116, <italic>p</italic> &lt; .001), in the low noise compared to in the medium noise environment (<italic>t</italic>(52) = 2.207, <italic>p</italic> = .016; <italic>t</italic>(52) = 2.829, <italic>p</italic> = .003), and in the medium noise compared to in the high noise environment (<italic>t</italic>(52) = 3.073, <italic>p</italic> = .002; <italic>t</italic>(52) = 2.425, <italic>p</italic> = .009).</p>
</sec>
<sec id="s3b">
<title>Modelling results</title>
<p>Replicating our findings from Experiment 1, the environment-specific Bai model fitted the data best (<xref rid="tbl2" ref-type="table">Table 2</xref>), indicating that participants indeed learned to use environment-specific initial learning rates and that they indeed decreased their learning rates over trials (as opposed to what the RW model predicts), but that they did so driven by experienced prediction errors rather than in a statistically optimal way (as opposed to what the Kalman filter predicts).</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2</label>
<graphic xlink:href="658048v2_tbl2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>The posterior probabilities that initial learning rates estimated by the environment-specific Bai model (<xref rid="fig5" ref-type="fig">Figure 5A</xref>) were higher in the low noise compared to the high noise environment, in the low noise compared to the medium noise environment, and in the medium noise compared to the high noise environment, were 0.999, 0.992, and 0.992, respectively. Decay rates were not significantly different (<xref rid="fig5" ref-type="fig">Figure 5B</xref>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Bai model estimation results Experiment 2.</title><p>The density plots on the left side of each subfigure show the full posterior densities over the means of the group-level distributions of the relevant parameters. The scatter plots on the right side of each subfigure show the means of all individual-level posterior distributions of the relevant parameters.</p></caption>
<graphic xlink:href="658048v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s3c">
<title>fMRI results</title>
<sec id="s3c1">
<title>The neural representation of environment-specific learning rates during island presentation</title>
<p>To investigate the neural representation of environment-specific learning rates, we first performed a whole-brain searchlight representational similarity analysis (RSA) that tested for higher similarities between locations that required the same learning rate versus locations that required more different learning rates. This analysis was done on data at the time of island presentation at the start of each block, which allowed us to test whether the mere presentation of the boat informing participants of where they would be fishing for crabs next triggered a state representation that differed depending on the relevant (initial) learning rate. Our hypothesis of representations that were specific to the high, mid, and low noise environments, but not for exact location, was encoded in a corresponding learning rate model representational dissimilarity matrix (RDM; <xref rid="fig6" ref-type="fig">Figure 6B</xref>). We then correlated this learning rate RDM with the corresponding neural RDM throughout the whole brain for each participant and we tested which voxels showed a significant (FDR-corrected <italic>p</italic> &lt; .05) correlation on the group-level. This resulted in multiple clusters of significant voxels in left as well as right OFC (<xref rid="fig6" ref-type="fig">Figure 6C</xref>), in accordance with our hypotheses. We also found a large cluster of significant voxels in the occipital cortex. In the next paragraph, we further interpret the activation in the two clusters.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>RSA analsyis of the fMRI data.</title><p><bold>A:</bold> spatial location RDM. <bold>B:</bold> Learning rate RDM. <bold>C:</bold> Brain map of significant t-values resulting from the whole-brain searchlight RSA of fMRI data acquired while participants had just been transported to the next location around the island (correlation with learning rate RDM). The map is centred around coordinate X = -21.5 Y = 37.5 Z = -18.5 where the largest cluster of significant voxels in the OFC reached its peak t-value. <bold>D-F:</bold> Interaction effect between time (first vs. second half of task) and RDM (spatial location vs. learning rate RDM) in the occipital cortex, defined as the cluster of significant voxels found in the aforementioned whole-brain searchlight RSA (D); the central OFC as defined by (<xref ref-type="bibr" rid="c25">Kahnt et al., 2012</xref>), based on connections to other brain regions (E); and the ventral striatum, defined as the left and right nucleus accumbens according to the AAL atlas (F). Grey dots represent individual-level Kendall’s tau-values, while black dots and error bars represent group-level means and SEs of the means, respectively.</p></caption>
<graphic xlink:href="658048v2_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s3c2">
<title>Dissociating the representation of spatial location and learning rate during island presentation</title>
<p>Since differences in optimal initial learning rate and differences in spatial location between the six locations are correlated, the activity in the occipital cortex is likely driven by spatial location rather than by learned initial learning rate. Crucially, representations of initial learning rate will tend to increase over blocks because they must be learned. Indeed, the behavioural data showed that environment-specificity of initial learning rates increased over time and was most pronounced in the second half of the task. Instead, representations of spatial locations should not. This allowed us to disentangle representations of spatial location and representations of initial learning rate. We thus performed a region of interest (ROI)-based follow-up analysis within the occipital cortex (defined as the cluster of significant voxels from the whole-brain RSA). For this analysis we constructed a second model RDM that encoded the different spatial locations, rather than the environments (spatial location model RDM; <xref rid="fig6" ref-type="fig">Figure 6A</xref>). We then calculated how strongly each participant’s neural RDM correlated with both model RDMs in the first half and the second half of the task separately. Finally, we performed a two (model RDM: spatial location vs. learning rate) by two (time: first vs. second half of the task) repeated measures ANOVA on the resulting correlations. We found a significant main effect of model RDM (<italic>F</italic>(1, 48) = 4.732, <italic>p</italic> = .035; <xref rid="fig6" ref-type="fig">Figure 6D</xref>), indicating that activity in the occipital cortex was indeed mostly driven by spatial location rather than initial learning rate, as well as a significant main effect of time (<italic>F</italic>(1, 48) = 6.665, <italic>p</italic> = .013), indicating that the representation of spatial location as well as initial learning rate decreased over time. We found no interaction effect between RDM and time.</p>
<p>To confirm that activity in the OFC was driven by differences in initial learning rate between the six locations and to pin down where exactly in the OFC environment-specific initial learning rates were represented, we divided the OFC into six subregions as defined by (<xref ref-type="bibr" rid="c25">Kahnt et al., 2012</xref>), based on its connections to other brain regions. We opted for this independent ROI approach, because the significant whole-brain cluster we observed only partially overlapped with OFC, as well as with other neighbouring regions. For each of these ROIs, we then calculated how strongly each participant’s neural RDM correlated with their learning rate RDM and with their spatial location RDM in the first half and the second half of the task separately. Finally, we performed a two (RDM: spatial location vs. learning rate) by two (time: first vs. second half of the task) repeated measures ANOVA on the resulting correlations. We found no main effect of RDM nor time in any of the OFC subregions, but we did find a significant interaction between RDM and time in one of the OFC subregions, namely the central OFC (<italic>F</italic>(1, 48) = 13.076, <italic>p</italic> &lt; .001; Bonferroni corrected; <xref rid="fig6" ref-type="fig">Figure 6E</xref>), which is the OFC subregion that overlapped most with the largest cluster of significant voxels observed in the whole-brain RSA. Follow-up one-tailed paired t-tests confirmed that in the central OFC correlations between learning rate RDMs and neural RDMs were higher in the second half than in the first half of the task (<italic>t</italic>(48) = 3.051, <italic>p</italic> = .002), suggesting that representations of environment-specific initial learning rates increased over time. Instead, the correlation between spatial location RDMs and neural RDMs did not change across time (<italic>t</italic>(48) = -0.109, <italic>p</italic> = .543).</p>
<p>We also performed the same interaction analysis in the ventral striatum to study whether the ventral striatum also represented environment-specific initial learning rates during island presentation. We found no interaction effect between RDM and time, nor a main effect of RDM. However, we did find a main effect of time (<italic>F</italic>(1, 48) = 5.499, <italic>p</italic> = .023; <xref rid="fig6" ref-type="fig">Figure 6F</xref>), indicating that in the ventral striatum the representations of spatial location as well as initial learning rate increased over time.</p>
</sec>
<sec id="s3c3">
<title>Environment-sensitive neural processing of prediction errors during crab fishing</title>
<p>Finally, we also investigated how participants processed reward prediction errors. That is, we used the distance between the cage location (their prediction) and target location (the reward) as an approximation of reward prediction errors. To investigate neural activity during this phase we focused on the neural response to these prediction errors after the first and second trial, which was included as a parametric modulator in a series of first-level general linear models (GLMs). As a first analysis, we performed a whole brain (univariate) analysis on this parametric modulator, averaged over all environments, to evaluate whether we observed a typical response to prediction errors in the brain (<xref rid="fig7" ref-type="fig">Figure 7A-B</xref>). Indeed, in line with previous studies on reward prediction error processing (<xref ref-type="bibr" rid="c10">Calderon et al., 2021</xref>; <xref ref-type="bibr" rid="c32">O’Doherty et al., 2004</xref>; <xref ref-type="bibr" rid="c36">Pessiglione et al., 2006</xref>; <xref ref-type="bibr" rid="c40">Schultz et al., 1997</xref>), we observed significant clusters of voxels in the left and the right striatum, including in the ventral striatum.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Results of the analyses of the effect of prediction error on the fMRI data.</title><p><bold>A-B:</bold> Brain map of significant t-values resulting from the whole-brain (univariate) tests of voxel activity being (parametrically) modulated by prediction error on trial 1 (A) and trial 2 (B). Each map is centred around the coordinate where it reaches its peak (negative) t-value. <bold>C-D:</bold> Interaction effect between time (first vs. second half of task) and environment (low vs. medium vs. high measurement noise) on the modulating effect of prediction error on trial 1 (C) and trial 2 (D) on ventral striatum activity. This ROI was defined as the left and right nucleus accumbens accordingto the AAL atlas . Grey dots represent individual-level GLM beta-values, while black dots and error bars represent group-level means and SEs of the means, respectively.</p></caption>
<graphic xlink:href="658048v2_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Next, we investigated whether there were interactions between environment (low vs. medium vs. high noise environment) and time (first vs. second half of the task) on these neural prediction error signals. Importantly, as mentioned above, our measure is only an (inverse) approximation of reward prediction error, because it measures the mismatch in location but not how much uncertainty people had around their point estimation. For example, seeing crabs appear on the exact cage location could still come with varying degrees of positive surprise depending on the uncertainty around their prediction, making it also difficult to estimate where exactly the prediction error turned form negative to positive. However, a region that is sensitive to the reward information in this signal, should show a neural response that is further dependent by environment and time, reflecting people’s ability to learn over time the more reward-informative nature of this signal in low noise environments.</p>
<p>We investigated this in the six OFC subregions and the ventral striatum using repeated measures ANOVAs. There were no significant effects in any of the OFC subregions. The ventral striatum, however, showed a significant interaction effect between environment and time (<italic>F</italic>(1, 48) = 4.222, <italic>p</italic> = .017; <xref rid="fig7" ref-type="fig">Figure 7C</xref>) in an analysis focusing on feedback processing during the first trial.</p>
<p>Follow-up t-tests confirmed that the ventral striatum responded differently to prediction errors in the low noise environment in the second half compared to the first half of the task (<italic>t</italic>(48) = 2.284, <italic>p</italic> = .027), while it did not show such an evolution in the medium noise environment (<italic>t</italic>(48) = -1.468, <italic>p</italic> = .149), nor the high noise environment (<italic>t</italic>(48) = -0.842, <italic>p</italic> = .404). Specifically, it showed a more negative response to larger (location) prediction errors, which is consistent with its documented role in showing a more positive response to more positive reward prediction errors (<xref ref-type="bibr" rid="c10">Calderon et al., 2021</xref>) – keeping in mind that being closer to the centre of where the crabs appeared (i.e. smaller location prediction errors) is less negatively or more positively surprising (i.e. smaller negative or larger positive reward prediction errors). On the second trial, there were no significant effects in any of the OFC subregions, while the ventral striatum only showed a significant main effect of time (<italic>F</italic>(1, 48) = 4.884, <italic>p</italic> = .032; <xref rid="fig7" ref-type="fig">Figure 7D</xref>), suggesting it may have become less sensitive to reward prediction errors on the second trial over time.</p>
</sec>
</sec>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>Humans can adapt how they learn in response to environmental demands, but how these adaptations unfold over time, and how to dissociate different types of adjustments, remains poorly understood. Here, we developed a new paradigm that systematically disentangles two types of learning rate adaptations: a fast and transient response to local prediction errors, and a slower form of meta-learning an optimal learning rate as a function of higher-level environmental statistics.</p>
<p>Specifically, we designed a gamified task in which participants fish for crabs on six different fishing locations around an island. The environmental statistics about the crabs’ hiding spots implied different optimal learning rates for the different locations. We extracted participants’ learning rates on each trial, which allowed us to test both (1) whether participants dynamically adjusted their learning rates in response to locally experienced prediction errors and (2) whether we could observe, above and beyond these local adaptations, different initial learning rates tailored to the environmental statistics. Across two experiments, we observed that participants did both: They immediately adapted their learning rates on a trial-by-trial basis in response to just-experienced prediction errors, but also learned, over time, to use different initial learning rates on the different locations around the island.</p>
<p>Computational modelling confirmed our findings. We fitted six models to the data, and in both experiments the best fitting model was the environment-specific Bai model, which implemented both the learning of environment-specific initial learning rates (across blocks) and learning rate updating proportional to recently experienced prediction errors (within blocks). While the Kalman filter provides optimal learning rates for the present task on every trial based on underlying environment statistics, the Bai model assumes a (learned) initial learning rate which is up- or downregulated by experienced prediction errors. According to the Kalman filter, learning rates should quickly decrease towards 0 irrespective of the initial learning rate, and independently of (individual differences in sensitivity to) experienced prediction errors. While participants’ learning rates do decrease over trials, they stabilise around 0.3, indicating that people are more responsive to noise than is optimal.</p>
<p>Overall, our behavioural data and modelling suggest that, over the course of both experiments, participants learned to instantaneously retrieve relevant learning rates upon arrival on any given location around the island. As such, our findings go beyond previous studies that documented changes in learning rates over time (<xref ref-type="bibr" rid="c5">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c9">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="c22">Goris et al., 2021</xref>), by showing that people can also switch back and forth between learning rates across environments (see also (<xref ref-type="bibr" rid="c43">Simoens et al., 2024</xref>)). As such, the present study provides support for recent theories of meta-learning (<xref ref-type="bibr" rid="c7">Botvinick et al., 2009</xref>; <xref ref-type="bibr" rid="c24">Holroyd &amp; Verguts, 2021</xref>; <xref ref-type="bibr" rid="c42">Silvetti et al., 2018</xref>; <xref ref-type="bibr" rid="c50">Wang et al., 2018</xref>), as well as cognitive control (<xref ref-type="bibr" rid="c1">Abrahamse et al., 2016</xref>; <xref ref-type="bibr" rid="c8">Braem et al., 2019</xref>; <xref ref-type="bibr" rid="c12">Chiu &amp; Egner, 2017</xref>), which posit that cognitive control is implemented as the environment-specific regulation of task execution parameters, such as learning rate.</p>
<p>We also investigated which brain regions represent sustained, meta-learned associations between environments and learning rates, enabling one to instantaneously retrieve the relevant learning rate when revisiting an environment. We hypothesized that the OFC would do so because it presumably represents task states (<xref ref-type="bibr" rid="c29">Moneta et al., 2024</xref>; <xref ref-type="bibr" rid="c44">Stalnaker et al., 2015</xref>; <xref ref-type="bibr" rid="c51">Wilson et al., 2014</xref>). While earlier evidence shows that the OFC represents concrete aspects of task states, such as task-relevant stimulus features (<xref ref-type="bibr" rid="c39">Schuck et al., 2016</xref>), we hypothesized that the OFC also represents more abstract aspects, such as environment-specific learning rates. Indeed, we showed that the central OFC gradually came to represent these environment-specific learning rates (or the environment-specific statistics that drive them). We further observed that the ventral striatum learned to differentially respond more to positive reward prediction errors (or less to negative reward prediction errors) depending on the currently relevant environment-specific learning rate. Taken together, our fMRI data analyses suggest that the OFC, more specifically the central OFC, represents environment-specific learning rates, which may in turn affect how the ventral striatum responds to prediction errors.</p>
<p>Our findings are in line with recent conceptualizations of learning across two time scales, both in artificial (<xref ref-type="bibr" rid="c38">Russin et al., 2024</xref>; <xref ref-type="bibr" rid="c50">Wang et al., 2018</xref>) and biological (<xref ref-type="bibr" rid="c6">Binz et al., 2024</xref>) agents. Here, fast learning would presumably occur in (neural) activation space, whereas slower learning would occur in weight space. Although our study did not allow specifying the locus of (fast and slow) learning, a direct comparison between artificial and biological agents was reported in (<xref ref-type="bibr" rid="c23">Hattori et al., 2023</xref>). They used a two-armed bandit task to study how mice as well as deep reinforcement learning models adapt their behaviour over time. They found that, in mice, the OFC is crucial for slow, across-session learning, which gradually refines neural circuits that support fast, within-session learning.</p>
<p>The researchers also observed parallels between the mechanisms underlying learning at these two different time scales in mice and deep reinforcement learning models. That is, both systems employed synaptic plasticity mechanisms to shape neural connectivity for learning on the slow time scale, but instead on recurrent activity dynamics for learning on the fast time scale (<xref ref-type="bibr" rid="c19">Duan et al., 2017</xref>; <xref ref-type="bibr" rid="c50">Wang et al., 2018</xref>). Indeed, blocking synaptic plasticity in the OFC disrupted across-session learning, but left within-session learning intact in expert mice. Thus, slow, across-session meta-learning may involve plasticity-based mechanisms in the OFC, which serve to improve fast, within-session learning of new tasks through recurrent activity dynamics. Here, we provided first evidence that a similar dual process may operate in humans.</p>
<p>A recent theme in artificial intelligence and computational neuroscience is that (artificial and biological) agents (should) learn to cluster the environments they are confronted with; and associate different (low- or high-level) parameters to each such environment (<xref ref-type="bibr" rid="c13">Collins &amp; Frank, 2013</xref>; <xref ref-type="bibr" rid="c49">Verbelen et al., 2022</xref>). This approach leads to efficient learning, not least because it shields against catastrophic interference. Here, we used only three environments (albeit on six locations), so the clustering was relatively easy in our case. However, future studies could use a design similar to the one presented here to investigate the neural underpinnings of clustering environments (and associated learning rates) in a continuous range of environments around the island. Similarly, the present study focused on differentiating between environments in terms of learning rate. However, human as well as nonhuman agents are often confronted with novel situations, in which they may instantaneously deduce appropriate settings for task execution parameters such as learning rate, across contexts; in brief, adaptive agents can generalize task execution parameters across similar contexts. Future studies could leverage the task developed for the present study to investigate the neural underpinnings of this generalisation of (abstract) knowledge by, for example, introducing more locations later on in the task.</p>
<p>In conclusion, the present study demonstrates the importance of differentiating between two time scales of adaptation in human learning rates. Fast time scale learning within environments and slow time scale learning about environments likely involve different cognitive processes with different neural underpinnings. Nevertheless, this distinction has thus far been largely overlooked, in favour of the fast time scale. Future research could leverage the experimental design presented here to further investigate the slow time scale as well. Our gamified design (<xref ref-type="bibr" rid="c3">Allen et al., 2024</xref>) can also provide new ways to test theories about the relation between meta-learning and development (<xref ref-type="bibr" rid="c31">Nussenbaum &amp; Hartley, 2024</xref>) or psychological pathologies, such as theories of autism which posit that autism is related to deficits in the detection of environmental differences in learning opportunities (<xref ref-type="bibr" rid="c22">Goris et al., 2021</xref>; <xref ref-type="bibr" rid="c46">van de Cruys et al., 2014</xref>).</p>
</sec>
<sec id="s5">
<title>Methods</title>
<sec id="s5a">
<title>Participants</title>
<p>50 participants (42 female, 8 male) were recruited for Experiment 1 (<ext-link ext-link-type="uri" xlink:href="https://osf.io/qft2p">https://osf.io/qft2p</ext-link>), and 53 participants (41 female, 12 male) for Experiment 2, through Sona (<ext-link ext-link-type="uri" xlink:href="https://www.ugent.sona-systems.com/">https://www.ugent.sona-systems.com/</ext-link>). All participants were between 18 and 35 years old. Because all participants caught about the same number of crabs, no participants were excluded from the behavioural data analyses. Since no response time deadline was implemented, no trials were excluded from the analyses. However, two participants were excluded from the fMRI data analyses because they were left handed, and another two because of technical problems with the fMRI data acquisition.</p>
<p>Experiment 1 was approved by the Ghent University Psychology and Educational Sciences Ethical Committee, and Experiment 2 by the Ghent University Medical Ethical Committee. Participants signed informed consents prior to participation. Experiment 1 took participants about 45 minutes to complete, in return for which they received a participation fee of €10. Participants in Experiment 2 received a participation fee of €35, because we also administered fMRI recording. In both experiments, the participant who caught the most crabs, received a €50 gift certificate for <ext-link ext-link-type="uri" xlink:href="http://bol.com">bol.com</ext-link> (an online store that offers general merchandising products).</p>
</sec>
<sec id="s5b">
<title>Experimental design</title>
<p>In Experiment 1, participants performed a novel crab-fishing task, which was programmed in jsPsych (<xref ref-type="bibr" rid="c17">de Leeuw et al., 2023</xref>). At the start of each of 60 blocks, a boat took them to one of six locations around an island (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). There they dropped a cage ten times (trials) trying to catch crabs. Each time a cage was dropped, one location was sampled from the sampling distribution <italic>S ∼ N</italic>(<italic>µ<sub>s</sub>,</italic> <inline-formula><inline-graphic xlink:href="658048v2_inline16.gif" mime-subtype="gif" mimetype="image"/></inline-formula>), truncated between <italic>µ<sub>s</sub> ± 1.65 * σ<sub>s</sub></italic> in order to avoid confusing participants with the occasional extreme outlier as well as off-screen locations. Before the cage reached the ocean floor, five crabs appeared and spread out from this location, each of which was either caught by the cage or ran away. At the beginning of each block, <italic>µ<sub>s</sub></italic> was sampled from the prior distribution <italic>µ<sub>s</sub> ∼ N</italic>(<italic>µ<sub>p</sub>,</italic> <inline-formula><inline-graphic xlink:href="658048v2_inline17.gif" mime-subtype="gif" mimetype="image"/></inline-formula>), truncated between <italic>µ<sub>p</sub> ± 1.65 * σ<sub>p</sub></italic>, with <italic>µ<sub>p</sub></italic> = the centre of the screen.</p>
<p>Crucially, the standard deviations of both prior and sampling distributions were dependent on the location around the island. On two randomly selected adjacent locations, <italic>σ<sub>p</sub></italic> was large (18.75% of the screen width), while <italic>σ<sub>s</sub></italic> was small (6.25% of screen width), making this a low noise environment. Here, a high initial learning rate is optimal since the mean of the sampling distribution could be far away from the centre of the screen, but all crabs will cluster close together. Thus, in estimating the mean of the sampling distribution, it makes sense to give a lot of weight to the first crabs (i.e., use a high learning rate), and exponentially decrease the learning rate afterwards. On the two adjacent locations on the exact opposite side of the island, the situation was reversed, making this a high noise environment. Here, a low (initial) learning rate is optimal since the mean of the sampling distribution can only be near the centre of the screen, but crabs can appear far away from each other (and the centre of the screen). Thus, in estimating the mean of the sampling distribution, it makes sense not to give too much weight to any individual crabs (i.e., use a low learning rate). Finally, on the two locations in between, the standard deviations <italic>σ<sub>p</sub></italic> and <italic>σ<sub>s</sub></italic> were intermediate (12.5% of screen width) and equal to each other, making this a medium noise environment and requiring an intermediate (initial) learning rate.</p>
<p>Participants visited all six locations around the island once in randomised order before visiting all locations a second time in (re)randomised order, and so on. The sailing of the boat from the previous to the next location unfolded over three to five seconds, depending on how far apart the locations were (one second stationary at previous location, followed by 60 degrees per second of sailing around the island, followed by one second stationary at the next location). Next, participants could move the cage to the left using the f-key and to the right using the j-key. Tapping the key would move the cage 1% of the screen width in the corresponding direction, while holding the key would slide the cage in that direction more quickly. There was no response time deadline. Participants could drop the cage by pressing the space bar, after which feedback unfolded over the course of 1.5 seconds: for the first 500 ms the cage sank until halfway to the bottom of the ocean, for the next 500 ms the cage sank all the way to the bottom of the ocean while five crabs appeared out of one point on the ocean floor and spread out to cover the same proportion of the screen width as the cage (18.75%), for the last 500 ms crabs that were not caught by the cage ran away, while crabs that were caught by the cage remained in place. The usage of a wide cage as well as five crabs was to ensure that participants could still catch some crabs in the high noise environment. At the start of each trial after the first trial (within blocks), the cage was moved back to the top of the screen at the x-coordinate where it was dropped on the last trial. The heap of sand where five crabs had crawled out of the sand on the last trial, would still be visible in order to help participants determine where to drop the cage next. While participants were fishing for crabs, a radar at the top of the screen reminded them of where around the island they were at all times.</p>
<p>Participants were instructed that around this island, crabs live in groups that are denser near the centre than towards the edges and that the local group of crabs would not change location while they were fishing on its location. The local group of crabs would only change location while they were fishing somewhere else. Hence, they should try to drop their cage over the centre of the group to maximise reward. They were also instructed that these groups of crabs might have different sizes around the island, so that they should keep track of where around the island they are.</p>
<p>After receiving the instructions, participants first performed a short practice phase during which they performed one block in each of the three environments. During the practice phase, participants could not see where around the island they were, while the (normally distributed) group of crabs under the sand was made visible while they were fishing.</p>
<p>During the actual task, the group of crabs was, of course, not visible while participants were fishing for crabs. However, they did receive block feedback at the end of each block. That is, at the end of each block, the group of crabs was made visible, as well as all ten (heaps of sand at) locations where crabs had crawled out of the sand during the block. During the fishing, only the location where crabs had appeared after the previous cage was dropped, was made visible as a little heap of sand. Finally, the task was divided into four rounds, in between which participants could take a short break.</p>
<p>Experiment 2 was programmed in PsychoPy (<xref ref-type="bibr" rid="c35">Peirce, 2007</xref>) and consisted of 60 blocks that were identical to the blocks in Experiment 1, except that they consisted of only eight trials. Additionally, 60 blocks that consisted of only two trials were randomly intermixed with the 60 longer blocks. These blocks were included to increase power for analyses on the very first (i.e., the most informative) trials within blocks. At the end of these shorter blocks, participants received no block feedback.</p>
<p>To make the design suitable for the MR-scanner, some additional minor changes were made. At the start of a block, the boat did not sail to a new location around the island but was immediately presented at the new location for a duration of three to seven seconds. Next, participants could move the cage to the left and to the right using their right index finger and right middle finger, respectively, on a response box that was placed in their right hand. Participants could drop the cage using their left index finger on a response box placed in their left hand. A laser pointer was added to the cage that pointed straight down from the centre of the cage to the ocean floor. Feedback unfolded over the course of 750 ms. During the first 250 ms, the cage sank until halfway to the bottom of the ocean. During the next 250 ms, the cage sank further to the bottom of the ocean and five crabs appeared out of one point on the ocean floor and spread out to cover the same proportion of the screen width as the cage. Before the start of the last 250 ms, crabs that were not caught by the cage disappeared from the screen. After the first and second trial of each block, there was an intertrial interval of three to seven seconds during which only the heap of sand where crabs had just crawled out of the ocean floor as well as a red cross (also on the ocean floor) at the centre of where the cage had just been dropped remained visible on the screen. Finally, block feedback lasted for three to seven seconds.</p>
</sec>
<sec id="s5c">
<title>Behavioural data analysis</title>
<p>All data and analysis scripts can be found on the Open Science Framework. Participants’ continuous responses allowed us to solve the delta rule:
<disp-formula>
<graphic xlink:href="658048v2_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>E<sub>t</sub></italic> and <italic>E<sub>t</sub></italic><sub>-1</sub> are the participant’s estimates of <italic>µ<sub>s</sub></italic> on trials <italic>t</italic> and <italic>t</italic> - 1, respectively (i.e., the locations where the participant dropped the cages), <italic>α<sub>t</sub></italic> is the participant’s learning rate on trial <italic>t</italic>, and <italic>M<sub>t</sub></italic> is the location where the five crabs appeared on trial <italic>t</italic>, for the learning rate <italic>α</italic> for each trial <italic>t &gt;</italic> 1. That is, each trial <italic>t</italic> &gt; 1 we calculated:
<disp-formula>
<graphic xlink:href="658048v2_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This allowed us to test whether participants showed a decrease in learning rate over the course of a block, as they learned more and more about the location of crabs within that block. To this end, we performed a linear mixed effects model analysis, with a random intercept for participant and a random slope for environment as well as for trial number (as well as for the environment-trial interaction), on participants’ median learning rates (for each environment-trial combination). We opted for median rather than mean learning rates (on a participant-level) because we observed some extreme outlier learning rates on trials directly following a trial in which crabs appeared directly next to where participants dropped their last cage. Here, any movement of the cage has an effect on the resulting learning rate which is unlikely to be proportional to participants’ actual learning rates (by blowing up the numerator, either positively or negatively, in the above formula for <italic>𝛼<sub>t</sub></italic>.</p>
<p>To investigate whether participants’ median learning rates on the second trial of each block were significantly different in the three environments and whether participants gradually learned to use different initial learning rates in the different environments, we divided Experiment 1 into two halves and Experiment 2 into four quarters (i.e., the four functional runs in the MR-scanner) and performed a two (time: the two halves) or four (time: the four runs) by three (environment: the three environments) repeated measures ANOVA on participants’ median learning rates on the second trial of each block. We interpreted the significant main effect of environment and the significant interaction effect between time and environment using one-tailed paired t-tests. We opted for median rather than mean learning rates (on a participant-level) because we observed some extreme outlier learning rates on trials directly following a trial in which crabs appeared directly next to where participants dropped their last cage. Here, any movement of the cage has an effect on the resulting learning rate which is unlikely to be proportional to participants’ actual learning rates (because the denominator in the formula for <italic>𝛼<sub>t</sub></italic> is close to zero and the equation hence unstable).</p>
</sec>
<sec id="s5d">
<title>Model estimation and selection</title>
<p>We fitted six models to the data using hierarchical Bayesian analyses (HBA) (<xref ref-type="bibr" rid="c2">Ahn et al., 2017</xref>). The HBA was performed in Stan (<xref ref-type="bibr" rid="c11">Carpenter et al., 2017</xref>), which uses Hamiltonian Monte Carlo (HMC) sampling, a variant of Markov chain Monte Carlo (MCMC) sampling. The first two models were the environment-specific and non-environment specific versions of the Kalman filter. The Kalman filter assumes that people update their estimates using the delta rule, with a learning rate that depends on both estimate and measurement uncertainty:
<disp-formula>
<graphic xlink:href="658048v2_ueqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>𝛼<sub>t</sub></italic> is the participant’s current learning rate; <inline-formula><inline-graphic xlink:href="658048v2_inline18.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the participant’s current estimate uncertainty, which initially is the variance of the prior distribution; and <inline-formula><inline-graphic xlink:href="658048v2_inline19.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the measurement uncertainty, which here is the variance of the sampling distribution. Crucially, learning rate decreases over time because:
<disp-formula>
<graphic xlink:href="658048v2_ueqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Initial estimate uncertainty <inline-formula><inline-graphic xlink:href="658048v2_inline20.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and measurement uncertainty <inline-formula><inline-graphic xlink:href="658048v2_inline21.gif" mime-subtype="gif" mimetype="image"/></inline-formula> cannot both be free parameters, because they trade off against each other, which would result in bimodal and unreliable posteriors (<xref ref-type="bibr" rid="c15">Daw et al., 2006</xref>). Therefore, we fixed measurement uncertainty to 0.125<sup>2</sup> (the true value in the medium noise environment) and only estimated initial estimate uncertainty. As an alternative procedure, we also tried fixing measurement uncertainty to the true value in each environment separately. The two approaches resulted in different posterior densities (see below) for estimate uncertainties, but in similar posterior densities (see below) for learning rates. Moreover, both approaches resulted in almost identical values for the LOOIC (see below). We conclude that we can safely fix measurement uncertainty to 0.125<sup>2</sup> across environments. In the environment-specific version of the model, each participant was assumed to use separate initial estimate uncertainties for each environment, while in the non-environment-specific version of the model, participants were assumed to use the same initial estimate uncertainty in both environments.</p>
<p>The next two models were the environment-specific and non-environment specific versions of the Rescorla-Wagner model, which assumes that people update their estimates according to the delta rule (with a constant learning rate). In the environment-specific version of the model, each participant was assumed to use separate learning rates for each environment, while in the non-environment-specific version of the model, participants were assumed to use the same learning rate in both environments.</p>
<p>The final two models were the environment-specific and non-environment specific versions of the Bai model (<xref ref-type="bibr" rid="c4">Bai et al., 2014</xref>), which is in the general family of models that adapt learning rate as a function of prediction errors (<xref ref-type="bibr" rid="c27">Krugel et al., 2009</xref>; <xref ref-type="bibr" rid="c34">Pearce &amp; Hall, 1980</xref>). Hence, the Bai model also supposes that people update their estimates according to the delta rule, but use a learning rate dependent on recently experienced prediction errors:
<disp-formula>
<graphic xlink:href="658048v2_ueqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>η</italic> is a decay rate, which also takes a value between 0 and 1 and determines how much learning rates are affected by recently experienced prediction errors. That is, when prediction errors are large, learning rate increases, but when prediction errors are small, learning rate decreases exponentially. In the environment-specific version of the model, each participant was assumed to use separate initial learning rates and decay rates for each environment, while in the non-environment-specific version of the model, participants were assumed to use the same learning rate and decay rate in both environments.</p>
<p>For each environment (low vs. medium vs. high noise), individual-level free parameters were assumed to be drawn from a group-level normal distribution specific to that environment. For the means of these group-level distributions, we used uniform priors between the lower and upper bounds of the relevant parameters, while for the standard deviations we used half-Cauchy (0, 5) priors. For the individual-level parameters we also used bounded uniform priors. To minimize the dependence between the means and standard deviations of group-level distributions, we used non-centred parameterisations. To maximise the efficiency of HMC sampling, parameters were first estimated in an unbounded space and then probit-transformed to the relevant bounded space (<xref ref-type="bibr" rid="c2">Ahn et al., 2017</xref>).</p>
<p>For each model, 4000 samples were drawn from the posterior distributions, the first 1000 of which were discarded as burn-in, across four sampling chains, resulting in a total of 12,000 posterior samples. Convergence of posterior distributions was checked by visually inspecting the traces and by numerically checking the Gelman-Rubin statistics (<xref ref-type="bibr" rid="c21">Gelman &amp; Rubin, 1992</xref>), which were all well below 1.1, for each estimated parameter.</p>
<p>We used the LOOIC (<xref ref-type="bibr" rid="c47">Vehtari et al., 2017</xref>) for model comparisons. The LOOIC approximates the log pointwise posterior predictive density of observed data, which is the out-of-sample predictive accuracy of a model. Therefore, higher values indicate higher out-of-sample predictive fit of the model to the data.</p>
<p>To calculate the posterior probability that learning rates were higher in one environment than in another, we calculated the proportion of posterior samples in which the group-level mean learning rate was higher in the one environment than in the other. Thus, a posterior probability higher than 95% corresponds to a one-tailed p-value lower than 0.05.</p>
</sec>
<sec id="s5e">
<title>Parameter recovery</title>
<p>To make sure that the experimental design and model estimation procedure would allow for the reliable estimation of the model parameters, we performed parameter recovery simulations. Specifically, using the aforementioned design details, we simulated 16 datasets with each of the three models in each of the three environments separately. For the RW model we used each of the learning rates {0.2, 0.4, 0.6, 0.8} four times as the true mean of the group-level distribution of this parameter. For the Kalman filter we used each of the estimate uncertainties {0.25, 0.5, 0.75, 1} four times as the true mean of the group-level distribution of this parameter. For the Bai model we used each combination of learning rates {0.2, 0.4, 0.6, 0.8} and decay rates {0.2, 0.4, 0.6, 0.8} as the true mean of the group-level distribution of these parameters. For each parameter, we then randomly sampled 50 true parameter values from the group-level normal distribution with the relevant mean and an SD of 0.2 for learning rates and decay rates, and 0.25 for estimate uncertainties. We then simulated a dataset using these parameter values and the experimental design described above and fitted the model to this simulated dataset using our model estimation procedure. Finally, for each model and each environment separately, we calculated parameter recovery rates by correlating all (16 datasets x 50 participants = 800) true parameters to the corresponding estimated parameters, that is, the individual-level posterior means. These simulations indicated that the model could be reliably fitted to our behavioural data. For learning rates in the RW model, estimate uncertainties in the Kalman filter, and initial learning rates in the Bai model recovery rates were higher than 0.975 in each environment. For decay rates in the Bai model parameter recovery rates were 0.807, 0.868 and 0.918 for the low, medium and high noise environment, respectively.</p>
</sec>
<sec id="s5f">
<title>Model recovery</title>
<p>To ensure that the experimental design and model selection procedure would allow for the reliable selection of the model fitting the data best, we also performed model recovery simulations. Specifically, using the experimental design described above, we simulated 10 datasets with each of the six models described above. For each model parameter, we used the estimated posterior mean and SD of the group-level distribution (of the empirical data) as the mean and SD, respectively, of the group-level distribution (of the simulated data), and randomly sampled 50 values from this distribution. For each model, we then simulated a dataset using these parameter values and the experiment design described above and fitted all six models to this simulated dataset using the model estimation procedure described above. Finally, using the model selection procedure described above, we tested for each simulated dataset which model fitted it best and calculated model recovery rates as the proportion of datasets simulated with each of the three models that was best fit by the correct model. Model recovery rates were 100% for each of the six models.</p>
</sec>
<sec id="s5g">
<title>Model validation</title>
<p>For validating the winning model, we used the posterior predictive check method (Gelman et al., 1996). This method takes participants’ fitted model parameters and uses them to simulate responses given their individual trial sequence. Simulated and true response patterns can then be compared to determine how well the model captures participants’ behaviour (<xref ref-type="bibr" rid="c33">Palminteri et al., 2017</xref>). Specifically, for each participant, we used the means of the participant-level posterior densities over the relevant parameters to simulate a response sequence conditional on the trial sequence this participant had received. We then (Pearson) correlated each participant’s true response sequence with the simulated response sequence.</p>
<p>Posterior predictive checks indicated that the environment-specific Bai model indeed adequately captured participants’ behaviour. The average correlation between participants’ true choice sequences and the response sequences obtained by simulating data using their parameter estimates was 0.793 in Experiment 1 and 0.863 in Experiment 2. More specifically, the average correlations were 0.927, 0.81 and 0.642 for the low, medium and high noise environment, respectively, in Experiment 1 and 0.955, 0.879 and 0.754 for the low, medium and high noise environment, respectively, in Experiment 2.</p>
</sec>
<sec id="s5h">
<title>fMRI data acquisition and preprocessing</title>
<p>T1-weighted MPRAGE structural images (1 mm isotropic voxels, 256 x 256 matrix, 176 axial slices, 9° flip angle), GRE field map images (528 ms TR, 7.38 TE, 60° flip angle), and T2*-weighted EPI functional data (2.5 mm isotropic voxels, 64 x 64 matrix, 1780 ms TR, 27 ms TE, 66° flip angle) were acquired on a 3 T Prisma scanner system (Siemens) with a 64 channel head coil. Functional data were acquired in 4 runs, each of which lasted about 12 minutes.</p>
<p>MRI data were preprocessed using fMRIPrep 23.1.0 (<xref ref-type="bibr" rid="c20">Esteban et al., 2019</xref>) and involved motion correction, field map based geometric undistortion, slice timing correction, coregistration of anatomical and functional scans, normalization into MNI space, and spatial smoothing with a 5 mm FWHM Gaussian kernel.</p>
</sec>
<sec id="s5i">
<title>fMRI data analyses</title>
<p>First-level (subject-wise) general linear modelling was done in SPM (<ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/">https://www.fil.ion.ucl.ac.uk/spm/</ext-link>) and involved regressors of interest that captured stimulus onset events (using an event-related design (i.e., with all event durations = 0); see below) and nuisance regressors that reflected participant movement (six regressors) as well as the global signal (one regressor). All regressors were convolved with a canonical hemodynamic response function.</p>
<p>Standard GLMs were used to estimate voxel activations associated with stimulus display. First-level models included separate regressors for each of the seven events of interest in each experimental block crossed with each of the six locations around the island plus the above described seven nuisance regressors for each run separately. The seven events of interest (regressor onset times) were: (1) presentation of the island at the beginning of each block, (2) the onset of the first trial, (3) the end of the feedback of the first trial, (4) the onset of the second trial, (5) the end of the feedback of the second trial, (6) the onsets of each remaining trial in the experimental block (when it was a long block), and (7) the onset of the block feedback (when it was a long block). We also included (mean-centred absolute) prediction error (in the current trial) as a parametric modulator for events 3 and 5 separately (as well as for each location around the island separately). This resulted in 244 whole brain maps of parameter estimates (“betas”; ((seven events of interest + two parametric modulators) * six locations around the island + seven nuisance regressors) * four runs).</p>
<p>The RSA focused on the beta maps capturing voxel activation during the presentation of the island at the beginning of each block. Before proceeding to the RSA, we normalized each voxel to its own within-run mean, by subtracting the voxel’s overall mean activation from each location’s activation, so that the overall mean is zero (<xref ref-type="bibr" rid="c18">Diedrichsen &amp; Kriegeskorte, 2017</xref>). Next, we performed a whole-brain searchlight RSA in three steps. Firstly, for each participant, we constructed a 24x24 design-based RDM with as rows and columns the six locations in each run (out of 4) and in each cell the dissimilarity between the optimal initial learning rate in the row’s location and the optimal initial learning rate in the column’s location (which could be 0, 1, or 2). Secondly, for each participant, we went through the entire brain in spherical searchlights with a radius of three voxels to construct 24x24 neural RDMs and compare (the upper triangle of) these RDMs to (the upper triangle of) the design-based RDM (also excluding within run cells) by computing Kendall’s Tau. Within each searchlight, the neural dissimilarity between each pair of locations was computed as one minus the Pearson correlation between the voxel wise activations for those locations. This resulted in a brain map of dissimilarity values (tau-values) for each participant where each voxel’s tau-value is computed with that voxel in the centre of a searchlight. Finally, we used one-tailed t-tests to test which voxels had tau-values significantly higher than zero, which indicates that they responded differently to different locations around the island, using a significance threshold of 0.05 corrected for multiple comparisons using the false discovery rate (FDR).</p>
<p>Next, we performed a ROI-based follow-up analysis with the occipital cortex, defined as the cluster of significant voxels from the whole brain searchlight RSA, as ROI in order to tease apart representations of spatial location and initial learning rate in this ROI, which were strongly correlated with each other. For this analysis we constructed a second 24x24 design-based RDM with as rows and columns the six locations in each of the four runs, and in each cell the dissimilarity between the spatial location in the row’s location and the spatial location in the column’s location (which could be 0, 1, 2, or 3). We then correlated the parts of (the upper triangle of) both design-based RDMs that concerned the first two runs (excluding within run cells) to the corresponding part of the neural RDMs, and then did the same for the last two runs. Finally, we performed a two (design feature: spatial location vs. optimal initial learning rate) by two (time: first vs. second half of the task) repeated measures ANOVA on the resulting correlations.</p>
<p>Next, we performed more in depth RSAs within predefined anatomical ROIs within the OFC to test whether within these regions the representation of initial learning rate level gradually became stronger than the representation of spatial location. To this end, we performed four RSAs within each ROI. That is, we correlated the parts of (the upper triangle of) both design-based RDMs that concerned the first two runs (excluding within run cells) to the corresponding part of the neural RDMs, and then did the same for the last two runs. Finally, we performed a two (design feature: spatial location vs. optimal initial learning rate) by two (time: first vs. second half of the task) repeated measures ANOVA on the resulting correlations. Where a significant interaction effect was found, we used one-tailed paired t-tests to interpret this interaction effect. The ROIs were created using SPM’s wfupickatlas toolbox. The OFC subregions were defined as in, based on connections to other brain regions. Here, we defined multiple ROIs within the OFC based on what is known about its structure, rather than defining an ROI based on the cluster of significant voxels observed in the whole brain RSA described above, as we did for the occipital cortex, because we wanted to check whether there were no significant effects in ROIs in which clusters of voxels did not exceed the stringent significance threshold applied in the whole brain RSA described above. Since we tested six ROIs, we used Bonferroni correction for multiple comparisons, which lowered the significance threshold to .05/6 = .008.</p>
<p>Although we found no significant clusters of voxels in the ventral striatum in the whole-brain RSA described above, we also performed the same repeated measures ANOVA we performed in the occipital cortex and the OFC in the ventral striatum to check if there was no effect there that did not survive the stringent significance threshold applied in the whole-brain RSA (or was cancelled out by an interaction between time and RDM, considering the whole-brain RSA exclusively tests for a main effect of RDM). This ROI was created using SPM’s wfupickatlas toolbox and was defined as the left and right nucleus accumbens according to the AAL atlas.</p>
<p>We also performed all of the (whole-brain and ROI-based) RSAs described above on neural data acquired during the presentation of feedback after the first two trials in each block.</p>
<p>Finally, we also checked the effect of prediction errors on brain activity using univariate analyses. First, as a sanity check, we used a whole-brain approach in which we averaged together (over blocks and environments) all whole-brain maps of first level beta-values for the parametric modulator “prediction error” on the regressor “end of feedback presentation after the first trial” and checked which voxels had significant beta-values using FDR correction for multiple comparisons. Crucially, we also tested whether there was a significant interaction effect between time (first vs. second half of the task) and environment (low vs. medium vs. high noise environment) on the parametric modulator “prediction error” on the regressor “end of feedback presentation after the first trial” in one of the seven ROIs described above (six OFC subregions and the ventral striatum) using repeated measures ANOVAs and, if applicable, follow-up paired one-tailed t-test to interpret significant interaction effects. We used the same approach to investigate the effect of prediction errors on brain activity during feedback presentation on the second trial of each block.</p>
<p>For analysing the reward localiser, we used the same approach as for analysing the main task up to and including first-level analyses, where we used the first three events of interest from the main task. This resulted in 13 whole brain maps of parameter estimates (betas; three events of interest * two locations around the island + seven nuisance regressors). Next, we simply took the univariate contrast between the high and the low reward conditions at the first event of interest (i.e., island presentation). We did this because this should have shown us which brain regions were responsive to expected reward during the event of interest that our main analyses were focused on. In that way, we could control for this effect there. However, no brain regions were significantly responsive to reward expectancy during our reward localiser.</p>
</sec>
</sec>
</body>
<back>
    <sec id="nt1">
        <title>Note</title>
        <p>This reviewed preprint has been updated to correct level headings.</p>
    </sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abrahamse</surname>, <given-names>E. L.</given-names></string-name>, <string-name><surname>Braem</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Notebaert</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Verguts</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Grounding cognitive control in associative learning</article-title>. <source>Psychological Bulletin</source>, <volume>142</volume>(<issue>7</issue>), <fpage>693</fpage>–<lpage>728</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahn</surname>, <given-names>W.-Y.</given-names></string-name>, <string-name><surname>Haines</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Zhang</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Revealing Neurocomputational Mechanisms of Reinforcement Learning and Decision-Making With the hBayesDM Package</article-title>. <source>Computational Psychiatry (Cambridge, Mass.)</source>, <volume>1</volume>, <fpage>24</fpage>–<lpage>57</lpage>. <pub-id pub-id-type="doi">10.1162/CPSY_a_00002</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Allen</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Brändle</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Fan</surname>, <given-names>J. E.</given-names></string-name>, <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Gopnik</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Hartshorne</surname>, <given-names>J. K.</given-names></string-name>, <string-name><surname>Hauser</surname>, <given-names>T. U.</given-names></string-name>, <string-name><surname>Ho</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>de Leeuw</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Murayama</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Nelson</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>van Opheusden</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Pouncy</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Rafner</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Rahwan</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Rutledge</surname>, <given-names>R. B.</given-names></string-name>, <etal>…</etal> <string-name><surname>Schulz</surname>, <given-names>E.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Using games to understand the mind</article-title>. <source>Nature Human Behaviour</source>, <volume>8</volume>(<issue>6</issue>), <fpage>1035</fpage>–<lpage>1043</lpage>. <pub-id pub-id-type="doi">10.1038/s41562-024-01878-9</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bai</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Katahira</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Ohira</surname>, <given-names>H</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Dual learning processes underlying human decision-making in reversal learning tasks: Functional significance and evidence from the model fit to human behavior</article-title>. <source>Frontiers in Psychology</source>, <volume>5</volume>(August), <fpage>1</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2014.00871</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Walton</surname>, <given-names>M. E.</given-names></string-name>, &amp; <string-name><surname>Rushworth</surname>, <given-names>M. F. S</given-names></string-name></person-group>. (<year>2007</year>). <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nature Neuroscience</source>, <volume>10</volume>(<issue>9</issue>), <fpage>1214</fpage>–<lpage>1221</lpage>. <pub-id pub-id-type="doi">10.1038/nn1954</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Binz</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dasgupta</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Jagadish</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>J. X.</given-names></string-name>, &amp; <string-name><surname>Schulz</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Meta-learned models of cognition</article-title>. <source>Behavioral and Brain Sciences</source>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Barto</surname>, <given-names>A. G</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Hierarchically organized behavior and its neural foundations: A reinforcement learning perspective</article-title>. <source>Cognition</source>, <volume>113</volume>(<issue>3</issue>), <fpage>262</fpage>–<lpage>280</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2008.08.011</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Braem</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Bugg</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Schmidt</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Crump</surname>, <given-names>M. J. C.</given-names></string-name>, <string-name><surname>Weissman</surname>, <given-names>D. H.</given-names></string-name>, <string-name><surname>Notebaert</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Egner</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Measuring Adaptive Control in Conflict Tasks</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>23</volume>(<issue>9</issue>), <fpage>769</fpage>–<lpage>783</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2019.07.002</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Browning</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Jocham</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>O’Reilly</surname>, <given-names>J. X.</given-names></string-name>, &amp; <string-name><surname>Bishop</surname>, <given-names>S. J</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Anxious individuals have difficulty learning the causal statistics of aversive environments</article-title>. <source>Nat Neurosci</source>, <volume>18</volume>(<issue>4</issue>), <fpage>590</fpage>–<lpage>596</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3961</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Calderon</surname>, <given-names>C. B.</given-names></string-name>, <string-name><surname>De Loof</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ergo</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Snoeck</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Boehler</surname>, <given-names>C. N.</given-names></string-name>, &amp; <string-name><surname>Verguts</surname>, <given-names>T.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Signed Reward Prediction Errors in the Ventral Striatum Drive Episodic Memory</article-title>. <source>Journal of Neuroscience</source>, <volume>41</volume>(<issue>7</issue>), <fpage>1716</fpage>–<lpage>1726</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carpenter</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hoffman</surname>, <given-names>M. D.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Goodrich</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Betancourt</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Brubaker</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Guo</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Riddell</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Stan: A probabilistic programming language</article-title>. <source>Journal of Statistical Software</source>, <volume>76</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>32</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chiu</surname>, <given-names>Y.-C.</given-names></string-name>, &amp; <string-name><surname>Egner</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Cueing cognitive flexibility: Item-specific learning of switch readiness</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>43</volume>(<issue>12</issue>), <fpage>1950</fpage>–<lpage>1960</lpage>. <pub-id pub-id-type="doi">10.1037/xhp0000420</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname>, <given-names>A. G. E.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Cognitive control over learning: Creating, clustering, and generalizing task-set structure</article-title>. <source>Psychological Review</source>, <volume>120</volume>(<issue>1</issue>), <fpage>190</fpage>–<lpage>229</lpage>. <pub-id pub-id-type="doi">10.1037/a0030852</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cook</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Swart</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Frobo</surname>, <given-names>M. I.</given-names></string-name>, <string-name><surname>Geurts</surname>, <given-names>D. E. M.</given-names></string-name>, &amp; <string-name><surname>Den Ouden</surname>, <given-names>H. E. M.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Catecholaminergic modulation of meta-learning</article-title>. <source>eLife</source>, <fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name>, <string-name><surname>Doherty</surname>, <given-names>J. P. O.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Seymour</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Dolan</surname>, <given-names>R. J</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Cortical substrates for exploratory decisions in humans</article-title>. <source>Nature</source>, <volume>441</volume>(<issue>June</issue>), <fpage>876</fpage>–<lpage>879</lpage>. <pub-id pub-id-type="doi">10.1038/nature04766</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Kakade</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Montague</surname>, <given-names>P. R</given-names></string-name></person-group>. (<year>2000</year>). <article-title>Learning and selective attention</article-title>. <source>Nature Neuroscience</source>, <volume>3</volume> <italic>Suppl</italic>(<issue>november</issue>), <fpage>1218</fpage>–<lpage>1223</lpage>. <pub-id pub-id-type="doi">10.1038/81504</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Leeuw</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Gilbert</surname>, <given-names>R. A.</given-names></string-name>, &amp; <string-name><surname>Luchterhandt</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2023</year>). <article-title>jsPsych: Enabling an Open-Source Collaborative Ecosystem of Behavioral Experiments</article-title>. <source>Journal of Open Source Software</source>, <volume>8</volume>(<issue>85</issue>), <fpage>5351</fpage>. <pub-id pub-id-type="doi">10.21105/joss.05351</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diedrichsen</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Kriegeskorte</surname>, <given-names>N</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Representational models: A common framework for understanding encoding, pattern-component, and representational-similarity analysis</article-title>. <source>PLOS Computational Biology</source>, <volume>13</volume>(<issue>4</issue>), <fpage>e1005508</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005508</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Duan</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Schulman</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Bartlett</surname>, <given-names>P. L.</given-names></string-name>, <string-name><surname>Sutskever</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name><surname>Abbeel</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2017</year>). <article-title>RL2: Fast reinforcement learning via slow reinforcement learning</article-title>. <source>Arxiv</source>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esteban</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Markiewicz</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Blair</surname>, <given-names>R. W.</given-names></string-name>, <string-name><surname>Moodie</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Isik</surname>, <given-names>A. I.</given-names></string-name>, <string-name><surname>Erramuzpe</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kent</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Goncalves</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dupre</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Oya</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Ghosh</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Wright</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Durnez</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, &amp; <string-name><surname>Gorgolewski</surname>, <given-names>K. J</given-names></string-name></person-group>. (<year>2019</year>). <article-title>fmriPrep: A robust preprocessing pipeline for functional MRI</article-title>. <source>Nature Methods</source>, <volume>16</volume>(January). <pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Rubin</surname>, <given-names>D. B</given-names></string-name></person-group>. (<year>1992</year>). <article-title>Inference from Iterative Simulation Using Multiple Sequences</article-title>. <source>Statistical Science</source>, <volume>7</volume>(<issue>4</issue>), <fpage>457</fpage>–<lpage>472</lpage>. <pub-id pub-id-type="doi">10.1214/ss/1177011136</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goris</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Silvetti</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Verguts</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Wiersema</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Brass</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Braem</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Autistic traits are related to worse performance in a volatile reward learning task despite adaptive learning rates</article-title>. <source>Autism</source>, <volume>25</volume>(<issue>2</issue>), <fpage>440</fpage>–<lpage>451</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hattori</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Hedrick</surname>, <given-names>N. G.</given-names></string-name>, <string-name><surname>Jain</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>You</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Hattori</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Choi</surname>, <given-names>J.-H.</given-names></string-name>, <string-name><surname>Lim</surname>, <given-names>B. K.</given-names></string-name>, <string-name><surname>Yasuda</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Komiyama</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Meta-reinforcement learning via orbitofrontal cortex</article-title>. <source>Nature Neuroscience</source>, <volume>26</volume>(<issue>12</issue>), <fpage>2182</fpage>–<lpage>2191</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-023-01485-3</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holroyd</surname>, <given-names>C. B.</given-names></string-name>, &amp; <string-name><surname>Verguts</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2021</year>). <article-title>The best laid plans: Computational principles of ACC</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>25</volume>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kahnt</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>L. J.</given-names></string-name>, <string-name><surname>Park</surname>, <given-names>S. Q.</given-names></string-name>, <string-name><surname>Heinzle</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Haynes</surname>, <given-names>J.-D</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Connectivity-Based Parcellation of the Human Orbitofrontal Cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>32</volume>(<issue>18</issue>), <fpage>6240</fpage>–<lpage>6250</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0257-12.2012</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Kingma</surname>, <given-names>D. P.</given-names></string-name>, &amp; <string-name><surname>Ba</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2017</year>). <article-title><italic>Adam: A Method for Stochastic Optimization</italic> (arXiv:1412.6980)</article-title>. <source>arXiv</source>. <pub-id pub-id-type="doi">10.48550/arXiv.1412.6980</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krugel</surname>, <given-names>L. K.</given-names></string-name>, <string-name><surname>Biele</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Mohr</surname>, <given-names>P. N. C.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>S.-C.</given-names></string-name>, &amp; <string-name><surname>Heekeren</surname>, <given-names>H. R</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Genetic variation in dopaminergic neuromodulation influences the ability to rapidly and flexibly adapt decisions</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>106</volume>(<issue>42</issue>), <fpage>17951</fpage>–<lpage>17956</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0905191106</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mathys</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2011</year>). <article-title>A Bayesian Foundation for Individual Learning Under Uncertainty</article-title>. <source>Front Hum Neurosci</source>, <volume>5</volume>, <fpage>39</fpage>–<lpage>39</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moneta</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Grossman</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Schuck</surname>, <given-names>N. W</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Representational spaces in orbitofrontal and ventromedial prefrontal cortex: Task states, values, and beyond</article-title>. <source>Trends in Neurosciences</source>, <volume>47</volume>(<issue>12</issue>), <fpage>1055</fpage>–<lpage>1069</lpage>. <pub-id pub-id-type="doi">10.1016/j.tins.2024.10.005</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Rumsey</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Parikh</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Heasly</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title>. <source>Nature Neuroscience</source>, <volume>15</volume>(<issue>7</issue>), <fpage>1040</fpage>–<lpage>1045</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3130</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nussenbaum</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Hartley</surname>, <given-names>C. A</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Understanding the development of reward learning through the lens of meta-learning</article-title>. <source>Nature Reviews Psychology</source>, <volume>3</volume>(<issue>6</issue>), <fpage>424</fpage>–<lpage>438</lpage>. <pub-id pub-id-type="doi">10.1038/s44159-024-00304-1</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Doherty</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Schultz</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Deichmann</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name>, &amp; <string-name><surname>Dolan</surname>, <given-names>R. J</given-names></string-name></person-group>. (<year>2004</year>). <article-title>Dissociable roles of ventral and dorsal striatum in instrumental conditioning</article-title>, <source>Science</source>, <volume>304</volume>(<issue>5669</issue>), <fpage>452</fpage>–<lpage>454</lpage>. <pub-id pub-id-type="doi">10.1126/science.1094285</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Palminteri</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Wyart</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Koechlin</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2017</year>). <article-title>The Importance of Falsification in Computational Cognitive Modeling</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>21</volume>(<issue>6</issue>), <fpage>425</fpage>–<lpage>433</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2017.03.011</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pearce</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name><surname>Hall</surname>, <given-names>G</given-names></string-name></person-group>. (<year>1980</year>). <article-title>A model for Pavlovian learning: Variations in the effectiveness of conditioned but not of unconditioned stimuli</article-title>. <source>Psychological Review</source>, <volume>87</volume>(<issue>6</issue>), <fpage>532</fpage>–<lpage>552</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peirce</surname>, <given-names>J. W</given-names></string-name></person-group>. (<year>2007</year>). <article-title>PsychoPy—Psychophysics software in Python</article-title>. <source>J Neurosci Methods</source>, <volume>162</volume>(<issue>1</issue>), <fpage>8</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.11.017</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pessiglione</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Seymour</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Flandin</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Frith</surname>, <given-names>C. D</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans</article-title>. <source>Nature</source>, <volume>442</volume>(<issue>7106</issue>), <fpage>1042</fpage>–<lpage>1045</lpage>. <pub-id pub-id-type="doi">10.1038/nature05051</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Rescorla</surname>, <given-names>R. A.</given-names></string-name>, &amp; <string-name><surname>Wagner</surname>, <given-names>A</given-names></string-name></person-group>. (<year>1972</year>). <chapter-title>A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>A.</given-names> <surname>Black</surname></string-name> &amp; <string-name><given-names>W.</given-names> <surname>Prokasy</surname></string-name></person-group> (Eds.), <source>Classical Conditioning II: Current Research and Theory</source> (pp. <fpage>64</fpage>–<lpage>99</lpage>). <publisher-name>Appleton Century Crofts</publisher-name>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Russin</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Pavlick</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Human Curriculum Effects Emerge with In-Context Learning in Neural Networks</article-title>, <source>arXiv</source>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2402.08674">http://arxiv.org/abs/2402.08674</ext-link></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schuck</surname>, <given-names>N. W.</given-names></string-name>, <string-name><surname>Cai</surname>, <given-names>M. B.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, &amp; <string-name><surname>Niv</surname>, <given-names>Y</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Human Orbitofrontal Cortex Represents a Cognitive Map of State Space</article-title>. <source>Neuron</source>, <volume>91</volume>(<issue>6</issue>), <fpage>1402</fpage>–<lpage>1412</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2016.08.019</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schultz</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Montague</surname>, <given-names>P. R</given-names></string-name></person-group>. (<year>1997</year>). <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source>, <volume>275</volume>(<issue>5306</issue>), <fpage>1593</fpage>–<lpage>1599</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schweighofer</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Doya</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2003</year>). <article-title>Meta-learning in Reinforcement Learning</article-title>. <source>Neural Networks</source>, <volume>16</volume>(<issue>1</issue>), <fpage>5</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1016/S0893-6080(02)00228-9</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Silvetti</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Vassena</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Abrahamse</surname>, <given-names>E. L.</given-names></string-name>, &amp; <string-name><surname>Verguts</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Dorsal anterior cingulate-brainstem ensemble as a reinforcement meta-learner</article-title>. <source>PLOS Computational Biology</source>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006370</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simoens</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Verguts</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Braem</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Learning environment-specific learning rates</article-title>. <source>PLOS Computational Biology</source>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1011978</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stalnaker</surname>, <given-names>T. A.</given-names></string-name>, <string-name><surname>Cooch</surname>, <given-names>N. K.</given-names></string-name>, &amp; <string-name><surname>Schoenbaum</surname>, <given-names>G</given-names></string-name></person-group>. (<year>2015</year>). <article-title>What the orbitofrontal cortex does not do</article-title>. <source>Nature Neuroscience</source>, <volume>18</volume>(<issue>5</issue>), <fpage>620</fpage>–<lpage>627</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3982</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Sutton</surname>, <given-names>R. S.</given-names></string-name>, &amp; <string-name><surname>Barto</surname>, <given-names>A. G.</given-names></string-name></person-group> (<year>2018</year>). <source>Reinforcement Learning: An Introduction</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van de Cruys</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Evers</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Hallen</surname>, <given-names>R. V. D.</given-names></string-name>, <string-name><surname>Eylen</surname>, <given-names>L. V.</given-names></string-name>, <string-name><surname>Boets</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Wagemans</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Precise minds in uncertain worlds: Predictive coding in autism</article-title>. <source>Psychological Review</source>, <volume>121</volume>(<issue>4</issue>), <fpage>649</fpage>–<lpage>675</lpage>. <pub-id pub-id-type="doi">10.1037/a0037665</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vehtari</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Gabry</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC</article-title>. <source>Statistics and Computing</source>, <volume>27</volume>(<issue>5</issue>), <fpage>1413</fpage>–<lpage>1432</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Verbeke</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Verguts</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Humans adaptively select different computational strategies in different learning environments</article-title>. <source>Psychological Review</source>. <pub-id pub-id-type="doi">10.1101/2023.01.27.525944</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Verbelen</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Tinguy</surname>, <given-names>D. D.</given-names></string-name>, <string-name><surname>Mazzaglia</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Çatal</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Safron</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Chunking Space and Time with Information Geometry</article-title>. <conf-name>NeurIPS, NeurIPS</conf-name>, <fpage>1</fpage>–<lpage>6</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>J. X.</given-names></string-name>, <string-name><surname>Kurth-nelson</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Kumaran</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Tirumala</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Soyer</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Leibo</surname>, <given-names>J. Z.</given-names></string-name>, <string-name><surname>Hassabis</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Botvinick</surname>, <given-names>M. M</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Prefrontal cortex as a meta-reinforcement learning system</article-title>. <source>Nature Neuroscience</source>, <volume>21</volume>(<issue>6</issue>), <fpage>860</fpage>–<lpage>868</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-018-0147-8</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Takahashi</surname>, <given-names>Y. K.</given-names></string-name>, <string-name><surname>Schoenbaum</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Niv</surname>, <given-names>Y</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Orbitofrontal Cortex as a Cognitive Map of Task Space</article-title>. <source>Neuron</source>, <fpage>267</fpage>–<lpage>279</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108223.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Diaconescu</surname>
<given-names>Andreea Oliviana</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country>Canada</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study makes a <bold>valuable</bold> contribution by separating two timescales of adaptation: rapid, within block reductions in learning rate, and slower, location specific, meta-learned adjustments. Behavioural data and computational modeling converge to support both processes. The evidence is <bold>solid</bold> with neuroimaging results suggesting that meta-learned learning rates are encoded in the orbitofrontal cortex, while prediction errors are represented in a distributed network including the ventral striatum and are modulated by expected error magnitude, though the specificity of these effects requires further contextualization. The manuscript is timely and clearly written; its main limitation is the weak linkage between neural signals and behavior, leaving uncertainty over whether the reported signals play a mechanistic role in learning.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108223.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Simoens and colleagues use a continuous estimation task to disentangle learning rate adjustments on shorter and longer timescales. They show that participants rapidly decrease learning rates within a block of trials in a given &quot;location&quot;, but that they also adjust learning rates for the very first trial based on information accrued gradually about the statistics of each location, which can be viewed as a form of metalearning. The authors show that the metalearned learning rates are represented in patterns of neural activity in the orbitofrontal cortex, and that prediction errors are represented in a constellation of brain regions, including the ventral striatum, where they are modulated by expectations about error magnitude to some degree. Overall, the work is interesting, timely, and well communicated. My primary concern with the work was that the link between the brain signals and their role in the behavior of interest was not well explored, raising some questions about the degree to which signals are really involved in the learning process, versus playing some downstream role.</p>
<p>Strengths:</p>
<p>The authors build on an interesting task design, allowing them to distinguish moment-to-moment adjustments in learning rate from slower adjustments in learning rate corresponding to slowly-gained knowledge about the statistics of specific &quot;locations&quot;. Behavior and computational modeling clearly demonstrate that individuals adjust to environmental statistics in a sort of metalearning. fMRI data reveal representations of interest, including those related to adjusted learning rates and their impact on the degree of prediction error encoding in the striatum.</p>
<p>Weaknesses:</p>
<p>It was nice to see that the authors could distinguish differences between the OFC signals that they observed and those in the visual regions based on changes through the session. However, the linkage between these brain activations and a functional role in generating behavior was left unexplored. Without further exploration, it is hard to tell exactly what role the signals might be playing, if any, in the behavior of interest.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108223.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Across two experiments, this work presents a novel spatial predictive inference paradigm that facilitates the investigation of meta-learning across multiple environments with distinct statistics, as well as more local learning from sequences of observations within an environment. The authors present behavioral data indicating that people can indeed learn to distinguish between noise levels and calibrate their learning rates accordingly across environments, even on initial trials when revisiting an environment. They complement their behavioral results with computational modeling, further bolstering claims of both local and global adaptation. Additional fMRI results support the role of OFC in this meta-learning process, with central OFC activity reflecting similarity between environments. This similarity emerges over time with task experience. Holistically, this paradigm and these data add to our understanding of how humans dynamically adapt their behavior on different timescales.</p>
<p>Strengths:</p>
<p>The novel paradigm represents a clever and creative expansion of spatial predictive inference tasks. The cover story was well chosen to facilitate an intuitive understanding of both the differences between environments and the estimation of the mean within environments.</p>
<p>Additionally, the authors present complementary results from two experiments, which strengthen the behavioral findings. This is especially effective as the initial experiment's results were a bit noisy, and the modifications within the second experiment increased both power and the specificity/accuracy of participant predictions. Taken together, the behavioral results provide convincing evidence that participants did distinguish environments based on their underlying statistics and adapted their initial behavior accordingly.</p>
<p>Beyond this, the combination of behavioral results, computational modeling, and neuroimaging enhances the impact of the work. It paints a fuller picture of whether and how humans meta-learn the global statistics of environments, and this is an important direction for the field of adaptive learning.</p>
<p>Weaknesses:</p>
<p>(1) The authors make the distinction between meta-learned &quot;global&quot; learning rates and within-environment learning rate adaptation in response to &quot;local&quot; fluctuations/observations. Though the experimental paradigm is novel, there are certainly links to prior work - for instance, though change point structures don't entail revisiting unique environments, they do require meta-learning from environmental statistics that is distinct from transient local adaptation to prediction errors. This tendency to increase one's learning rate after large prediction errors is appropriate in change point environments, though, as is true in this study, the amount of increase should be dependent on. This represents a similar kind of slower-timescale learning or reuse of more &quot;global&quot; parameters, and can be seen to different extents in prior work. It might benefit readers if the authors were to link the current work to previous research more explicitly to draw clearer connections between the approaches and findings.</p>
<p>(2) Throughout much of the paper, the authors refer to the distinctions between environments primarily as differences in &quot;initial learning rates&quot; or &quot;environment-specific learning rates.&quot; This is particularly prominent when discussing fMRI results. Though the optimal initial learning rate did differ across environments, this was the result of differences in underlying task statistics. It will be important to clarify this throughout the text, because of the confounds between task statistics and initial learning rate (and to some extent, the position on the screen), it is not possible to separate the impact of these specific variables. This is also relevant to understanding the justification for using methods like RSA to test whether brain regions represent task states similarly. If the main hypothesis is that neural activity reflects the (initial) learning rate itself, then a univariate analysis approach would seem more natural.</p>
<p>(3) For the neuroimaging results in particular, the specificity of some of the results (e.g. ventral striatum showing an effect of prediction error only in the low noise condition in the second half of task experience, only on the first trial) is a bit surprising. Additional justification of or context for these results would be useful to help readers gauge how expected or surprising these findings are.</p>
<p>(4) There are some methodological details that are unclear (e.g., how were the positions of the crabs selected relative to the location they emerged from? Looking at Figure 1C, it looks like the crabs spread out unevenly, and that the single position they emerge from is not necessarily at the center of the crab locations.) Additional detail and clarity would help address some unanswered questions (more details below).</p>
</body>
</sub-article>
</article>