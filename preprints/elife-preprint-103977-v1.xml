<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">103977</article-id>
<article-id pub-id-type="doi">10.7554/eLife.103977</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.103977.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>NeuroSCAN: Exploring Neurodevelopment via Spatiotemporal Collation of Anatomical Networks</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1886-2891</contrib-id>
<name>
<surname>Koonce</surname>
<given-names>Noelle L</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9587-3784</contrib-id>
<name>
<surname>Emerson</surname>
<given-names>Sarah E</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8068-3101</contrib-id>
<name>
<surname>Bhaskar</surname>
<given-names>Dhananjay</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7512-9739</contrib-id>
<name>
<surname>Kuchroo</surname>
<given-names>Manik</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Moyle</surname>
<given-names>Mark W</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a10">10</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5369-6097</contrib-id>
<name>
<surname>Arroyo-Morales</surname>
<given-names>Pura</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Martínez</surname>
<given-names>Nabor Vázquez</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5823-1985</contrib-id>
<name>
<surname>Krishnaswamy</surname>
<given-names>Smita</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3586-547X</contrib-id>
<name>
<surname>Mohler</surname>
<given-names>William</given-names>
</name>
<xref ref-type="aff" rid="a6">6</xref>
<email>wmohler@neuron.uchc.edu</email>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0223-7717</contrib-id>
<name>
<surname>Colón-Ramos</surname>
<given-names>Daniel</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a7">7</xref>
<xref ref-type="aff" rid="a8">8</xref>
<xref ref-type="aff" rid="a9">9</xref>
<email>daniel.colon-ramos@yale.edu</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Neuroscience and Department of Cell Biology, Wu Tsai Institute, Yale University</institution></institution-wrap>, <city>New Haven</city>, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Genetics, Yale School of Medicine</institution></institution-wrap>, <city>New Haven</city>, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Computer Science, Yale University</institution></institution-wrap>, <city>New Haven</city>, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Program for Computational Biology and Bioinformatics, Yale University</institution></institution-wrap>, <city>New Haven</city>, <country>USA</country></aff>
<aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Program for Applied Mathematics, Yale University</institution></institution-wrap>, <city>New Haven</city>, <country>USA</country></aff>
<aff id="a6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02kzs4y22</institution-id><institution>Department of Genetics and Genome Sciences and Center for Cell Analysis and Modeling, University of Connecticut Health Center</institution></institution-wrap>, <city>Farmington</city>, <country>USA</country></aff>
<aff id="a7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046dg4z72</institution-id><institution>MBL Fellow, Marine Biological Laboratory</institution></institution-wrap>, <city>Woods Hole</city>, <country>USA</country></aff>
<aff id="a8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Wu Tsai Institute, Yale University</institution></institution-wrap>, <city>New Haven</city>, <country>USA</country></aff>
<aff id="a9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02yg0nm07</institution-id><institution>Instituto de Neurobiología, Recinto de Ciencias Médicas, Universidad de Puerto Rico</institution></institution-wrap>; <city>San Juan</city>, <country>Puerto Rico</country></aff>
<aff id="a10"><label>10</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05j7qk258</institution-id><institution>Department of Biology, Brigham Young University-Idaho</institution></institution-wrap>, <city>Rexburg</city>, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Kratsios</surname>
<given-names>Paschalis</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Chicago</institution>
</institution-wrap>
<city>Chicago</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Cardona</surname>
<given-names>Albert</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Cambridge</institution>
</institution-wrap>
<city>Cambridge</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-12-18">
<day>18</day>
<month>12</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP103977</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-10-23">
<day>23</day>
<month>10</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-10-24">
<day>24</day>
<month>10</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.08.27.609993"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Koonce et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Koonce et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-103977-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Volume electron microscopy (vEM) datasets such as those generated for connectome studies allow nanoscale quantifications and comparisons of the cell biological features underpinning circuit architectures. Quantifications of cell biological relationships in the connectome result in rich multidimensional datasets that benefit from data science approaches, including dimensionality reduction and integrated graphical representations of neuronal relationships. We developed NeuroSCAN, an online open-source platform that bridges sophisticated graph analytics from data science approaches with the underlying cell biological features in the connectome. We analyze a series of published <italic>C. elegans</italic> brain neuropils and demonstrate how these integrated representations of neuronal relationships facilitate comparisons across connectomes, catalyzing new insights on the structure-function relationships of the circuits and their changes during development. NeuroSCAN is designed for intuitive examination and comparisons across connectomes, enabling synthesis of knowledge from high-level abstractions of neuronal relationships derived from data science techniques to the detailed identification of the cell biological features underpinning these abstractions.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>This version integrates minor text edits and clarifications to figures.</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://neuroscan.net/">https://neuroscan.net/</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/colonramoslab/NeuroSCAN">https://github.com/colonramoslab/NeuroSCAN</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Neural circuit structure supports function. The underlying image data that yields anatomical connectomes (or wiring diagrams) are typically obtained using volume electron microscopy (vEM) techniques (<xref ref-type="bibr" rid="c10">Collinson et al., 2023</xref>). Since the first complete connectome was published for <italic>C. elegans</italic> (<xref ref-type="bibr" rid="c36">White et al., 1986</xref>), these last decades have seen an increase in the generation of vEM datasets, as reviewed in (<xref ref-type="bibr" rid="c18">Kaiser, 2023</xref>) and others. The expansion in available anatomical connectomes has resulted from recent advancements in: 1) data generation (via automation of EM data acquisition (<xref ref-type="bibr" rid="c38">Xu et al., 2017</xref>; <xref ref-type="bibr" rid="c14">Eberle and Zeidler, 2018</xref>; <xref ref-type="bibr" rid="c40">Zheng et al., 2018</xref>; <xref ref-type="bibr" rid="c25">Phelps et al., 2021</xref>); and 2) alignment, segmentation and reconstruction (including recent implementation of AI-driven methods) as reviewed in (<xref ref-type="bibr" rid="c16">Galili et al., 2022</xref>; <xref ref-type="bibr" rid="c8">Choi et al., 2024</xref>) and others. As these developing methodologies continue to improve, they will continue to facilitate the generation of additional connectomes of whole brains and organisms.</p>
<p>The increasing availability of vEM datasets, including the first series of developmental connectomes published for <italic>C. elegans</italic> (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>) has highlighted the need for new tools to enable intuitive examination and comparisons across connectomes to promote novel discoveries (<xref ref-type="bibr" rid="c19">Kasthuri et al., 2015</xref>; <xref ref-type="bibr" rid="c20">Lichtman et al., 2014</xref>; <xref ref-type="bibr" rid="c3">Barabási et al., 2023</xref>; <xref ref-type="bibr" rid="c39">Xu et al., 2021</xref>). It has also underscored the fact that vEM datasets contain a wealth of untapped information that has yet to be fully examined, represented and integrated for more comprehensive analyses (<xref ref-type="bibr" rid="c24">Perez et al., 2014</xref>; <xref ref-type="bibr" rid="c4">Brittin et al., 2021</xref>). For example, vEM datasets enable nanoscale explorations of the underlying cell biological features that govern the properties of neural circuit architectures (<xref ref-type="bibr" rid="c28">Rivlin et al., 2024</xref>; <xref ref-type="bibr" rid="c4">Brittin et al., 2021</xref>; <xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>; <xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="c17">Heinrich et al., 2021</xref>). Yet most of these cell biological features (cell morphologies, contact profiles, organelle positions and shapes, etc) are not currently represented in most anatomical connectomes. Quantification of cell biological data result in high-dimensional datasets that require new approaches for their analyses and representations. The advances in vEM data generation and the resulting need for new methodologies in data science and integrated representations of neuronal relationships (e.g. from neuronal positions to neuropil structures) is akin to how advances in genetic sequencing required new methodologies in bioinformatics and new, integrated representations of genomic data (e.g. from gene sequence to gene structure) (<xref ref-type="bibr" rid="c32">Swanson and Lichtman, 2016</xref>). Addressing this gap holds the promise of integrating new knowledge from the fields of cell biology, neurodevelopment, physiology and systems neuroscience towards explaining how nervous system structure underpins its function.</p>
<p>Most representations of anatomical connectomes have focused on defining neuronal relationships at the level of the chemical synapse (NemaNode; WormWiring; EleganSign; FlyWire) (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="c12">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="c15">Fenyves et al., 2020</xref>; <xref ref-type="bibr" rid="c13">Dorkenwald et al., 2023</xref>). While the existence of chemical synapses between neuron pairs is an important feature of neuronal communication, these representations do not capture other neuroanatomical features that also underlie neuron structure and function, including contact sites from adjacent (or nearby) neurons. Recent work in <italic>C. elegans</italic> examined neuronal relationships by quantifying neuron-neuron contact sites to build contact profiles, or contactomes (<xref ref-type="bibr" rid="c4">Brittin et al., 2021</xref>). Examination of the contactome with data science approaches uncovered structural principles that were not evident from interrogating the synaptic connectome alone (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>; <xref ref-type="bibr" rid="c4">Brittin et al., 2021</xref>). These included the existence of higher- order structural motifs and the stratification of neurons (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>), whose hierarchical assembly during development is guided by centrally located pioneer neurons (<xref ref-type="bibr" rid="c27">Rapti et al., 2017</xref>). Moreover, integrating neuronal adjacencies (contactome) with synaptic profiles (connectome) allowed for a deeper understanding of the functional segregation of neurons within the stratified neuropil structures (<xref ref-type="bibr" rid="c4">Brittin et al., 2021</xref>; <xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>). Key to achieving this were data science approaches such as Diffusion Condensation (DC) and C-PHATE (<xref ref-type="bibr" rid="c6">Brugnone et al., 2019</xref>; <xref ref-type="bibr" rid="c21">Moon et al., 2019</xref>), which resulted in reduced dimensionality of the neuronal relationships, revealing architectural motifs across various scales of granularity, from individual neurons within circuits, to individual circuits within the neuropil. These techniques produced graphs that enabled exploration of these computationally identified groups (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>). DC/C-PHATE graphs are powerful tools, but they have yet to be integrated to connectomics datasets as to enable explorations of the underlying cell biological features. This limits their effectiveness for hypothesis generation and comparative analyses across connectomes.</p>
<p>To address this, we generated NeuroSCAN, a tool for exploring neuroarchitectures across vEM datasets via novel representations of the connectome, contactome, and anatomical networks. Neu-roSCAN is an online, open-source platform that facilitates comparisons of neuronal features and relationships across vEM data to catalyze new insights of the relationships that underpin architectural and functional motifs of the nerve ring neuropil. NeuroSCAN builds on recent publications in whole-brain EM datasets, integrating the latest set of developmental connectomes (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>) and employing data science tools (<xref ref-type="bibr" rid="c6">Brugnone et al., 2019</xref>; <xref ref-type="bibr" rid="c21">Moon et al., 2019</xref>) to examine neuronal relationships based on contact profiles. We demonstrate how these integrated representations of neuronal relationships facilitate comparisons across these connectomes, catalyzing new insights on their structure-function and changes during development. NeuroSCAN achieves this by addressing three challenges in current neuronal representations: 1) accessibility of specific neuronal cell biological features (i. e. synapses and contacts), 2) integration of features for examining neuronal relationships across anatomical scales, and 3) spatiotemporal comparisons of these features across developmental datasets.</p>
<p>These challenges were addressed by 1) creating representations of contact sites and establishing the ability to visualize subsets of synaptic sites; 2) enabling synchronous visualization of neuron morphologies, contacts and synapses and integrating these cell biological features with algorithmically-generated graphical representations of neuronal relationships; and 3) enabling simultaneous exploration of these relational representations across developmental connectomes. NeuroSCAN was designed as a suite of tools that facilitates future incorporation of additional datasets and representations with the goal of enabling integrated data exploration beyond the available <italic>C. elegans</italic> connectomes. The NeuroSCAN-based approaches used here for <italic>C. elegans</italic> could be applicable to other systems as new EM-based datasets and reconstructions become available.</p>
</sec>
<sec id="s2">
<title>Results (Comparing contactome-based relationships using C-PHATE.)</title>
<p>The adult hermaphrodite <italic>C. elegans</italic> nerve ring is a neuropil of 181 neurons of known identities, morphologies, contact profiles, and synaptic partners (<xref ref-type="bibr" rid="c36">White et al., 1986</xref>). Even for this relatively small neuropil, representations of a single feature type, such as neuronal contact profiles, constitute over 100,000 data points of multidimensional information: cell identity, region of contact, presence of synapses, etc. Analysis of this multidimensional information requires approaches that can both capture higher order patterns of organization while enabling researchers to access the underlying cell biological features resulting in these relationships. We implemented Diffusion Condensation (DC), a clustering algorithm that iteratively group neurons based on the quantitative similarities of their ‘contact’ or ‘adjacency’ profiles (<xref ref-type="bibr" rid="c6">Brugnone et al., 2019</xref>; <xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>). Briefly, DC makes use of pair-wise quantifications of adjacent neuron contacts to move neurons with similar adjacency profiles closer together by applying a diffusion filter in a multidimensional manifold. This diffusion filter effectively removes variability between neurons at each iteration. As iterations proceed, individual neurons (and eventually groups of neurons) are clustered together based on how close their diffused contact profiles are to one another in the manifold (<xref ref-type="bibr" rid="c6">Brugnone et al., 2019</xref>). In this way, DC uncovers hierarchical neuronal relationships in the contactome (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>).</p>
<p>To ensure accurate comparisons of DC across available EM datasets (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="c36">White et al., 1986</xref>), we first empirically set minimum-distance adjacency thresholds (measured in pixels; Supplemental Table 1) to build adjacency profiles (see also Methods and Materials), schematized in <xref rid="fig1" ref-type="fig">Figure 1A-C</xref>). We then quantified the lengths of the physical adjacencies (or contacts) between neuron pairs (<xref ref-type="bibr" rid="c4">Brittin et al., 2021</xref>) and built an adjacency matrix for each of the seven selected <italic>C. elegans</italic> contactome datasets (L1, 0 hours post hatch (hph); L1, 5hph; L2, 16hph; L3, 27hph; L4, 36hph; Adult 48hph (<xref rid="fig1" ref-type="fig">Figure 1C</xref>; See also Methods and Materials). To visualize and compare the results from DC, we used C-PHATE (<xref ref-type="bibr" rid="c21">Moon et al., 2019</xref>; <xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>), a 3-D visualization tool that builds a hierarchical visual representation of the DC agglomeration procedure (<xref rid="fig1" ref-type="fig">Figure 1D-E</xref>). In C-PHATE visualizations, the DC output is mapped in 3-D space with spheres. Initially, all individual neurons in the neuropil dataset are at the periphery of the C-PHATE graph (left hand side in schematic in <xref rid="fig1" ref-type="fig">Figure 1D</xref>, edges of graph in <xref rid="fig1" ref-type="fig">Figure 1E</xref>). Neurons are iteratively condensed based on the similarity of their adjacency profiles (schematized in <xref rid="fig1" ref-type="fig">Figure 1D</xref>). In the last iteration of DC, there is a single point at the center of the C-PHATE graph which contains the entire neuropil (<xref rid="fig1" ref-type="fig">Figure 1E</xref>, red dot). C-PHATE representations enable visualization and comparisons of contactomes across datasets, and explorations of neuronal relationships, from individual neuron interactions to circuitcircuit bundling (<xref rid="fig1" ref-type="fig">Figure 1F</xref> and <xref rid="fig2" ref-type="fig">Figure 2</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>DC/C-PHATE representations of contactome-based relationships.</title>
<p>DC/C PHATE graphs enable representations of neuronal contact relationships. To build DC/C-PHATE graphs we <bold>(A)</bold> analyzed serial section EM datasets of the <italic>C. elegans</italic> nerve ring neuropil (located in the head of the animal). <bold>(B)</bold> Single cross section of the nerve ring (surrounding the pharynx), with segmented neurites pseudo-colored. Dark box corresponds to the zoomed-in image in (C). The cross section is from the JSH dataset digitally segmented (<xref ref-type="bibr" rid="c4">Brittin et al., 2021</xref>). <bold>(C)</bold> Zoom-in cross section with three arbitrary neurons (called A, B, C) highlighted by overlaying opaque cartoon (2-D, left image) and 3-D shapes (middle image) to represent the segmentation process in the z-axis (arrow) and the neuronal contact sites (highlighted Yellow, Yellow dashed, Red). Contacts are quantified for all neuron pairs across the contactome (See Methods), to generate a Contact Matrix (represented here as a table, schematized for the three arbitrary neurons selected and in which specific contact quantities are represented by a color scale and not numerical values). <bold>(D)</bold> Schematic of how the Diffusion Condensation algorithm (visualized with C-PHATE) works. DC/C-PHATE makes use of the contact matrix to group neurons based on similar adjacency profiles (<xref ref-type="bibr" rid="c6">Brugnone et al. 2019</xref>; <xref rid="c6" ref-type="bibr">2019</xref>; <xref ref-type="bibr" rid="c22">Moyle et al. 2021</xref>), schematized here for the three neurons in (C). <bold>(E)</bold> Screenshot of the 3-D C-PHATE graph from a Larva stage 1 (L1; 0 hours post hatching;) contactome, with individual neurons represented as spheres at the periphery. Neurons were iteratively clustered towards the center, with the final iteration containing the nerve ring represented as a sphere in the center of the graph (Highlighted in maroon). <bold>(F)</bold> Integration in NeuroSCAN of the DC/C-PHATE and EM-derived 3-D neuron morphology representations allow users to point to each sphere in the graph and determine cellular or cluster identities for each iteration. Shown here and circled in Red, an arbitrarily selected cluster (in E), with the identities of the neurons belonging to that cluster (four letter codes in the column to the left of F) and the corresponding neuronal morphologies (right) of this group of neurons in the EM-reconstructed nerve ring (with individual neurons pseudo-colored according to their names to the left). Compass: Anterior (A), Posterior (P), Dorsal (D), Ventral (V), Left (L), Right (R).</p></caption>
<graphic xlink:href="609993v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Implementation of DC/C-PHATE to developmental contactomes reveal a conserved layered organization maintained during post-embryonic growth.</title>
<p><bold>(A)</bold> Cartoon of the <italic>C. elegans</italic> head and nerve ring (outlined with black box). Below, nerve ring reconstruction from EM data of an L1 animal (5 hours post hatching), with all neurons in gray. Scale bar 2 <italic>µ</italic>m. <bold>(B-F)</bold> DC/C-PHATE plots generated for available contactomes across <italic>C. elegans</italic> larval development, colored by stratum identity as described (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>). Individual neurons are located at the edges of the graph and condense centrally. The four super-clusters identified and all iterations before are colored accordingly. The identity of the individual neurons belonging to each stratum, and at each larval stage, were largely preserved, and are provided in (Supplemental Table 1). Some datasets contain 5 or 6 super-clusters (colored dark purple, yellow and orange), which are classified as groups of neurons that are differentially categorized across the developmental connectomes. <bold>(G-K)</bold> Volumetric reconstruction of the <italic>C. elegans</italic> neuropil (from EM serial sections for the indicated larval stages (columns)) with the neurons colored based on their strata identity. Scale bar 2 m; Anterior (A) left, Dorsal (D) up.</p></caption>
<graphic xlink:href="609993v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>By Larval stage 1 (L1), neuronal differentiation has concluded and 90% of the neurons in the neuropil (161 neurons out of the 181 neurons) have entered the nerve ring and adopted characteristic morphologies and positions (<xref ref-type="bibr" rid="c31">Sun and Hobert, 2023</xref>). Although the organism grows approximately 5 fold from L1 to the adult, contacts in the nerve ring are also largely established by L1 and preserved during postembryonic growth (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>). In agreement with this, when we used DC and C-PHATE to examine contactomes from these datasets we consistently identified four main superclusters– Stratum 1, Stratum 2, Stratum 3, and Stratum 4 (<xref rid="fig2" ref-type="fig">Figure 2B-F</xref>). These findings are consistent with previous studies on the Larval Stage 4 (L4) and adult contactomes (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>), and further suggest that neurons establish core relationships during embryogenesis and maintain them into adulthood. Moreover, aligning the neuronal morphologies of strata members reveals a persistent layered organization to the nerve ring neuropil (<xref rid="fig2" ref-type="fig">Figure 2 G-K</xref>), and exploring the functional identities of the neurons in each stratum suggests that there is spatial segregation of sensory information and motor outputs (see (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>) see: Supplemental Tables 3, 4, 5, 6. Our findings are in agreement with previous reports that the organization of the nerve ring is largely established in embryogenesis, and then maintained during postembryonic growth (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>). Our findings also demonstrate the utility of DC and C-PHATE analyses in extracting, visualizing and comparing the structure of the neuropil architecture across contactomes.</p>
<p>Because DC and C-PHATE allow for the examination of relationships at varying levels of granularity, they also facilitate the interrogation of the architectural motifs that underlie distinct neural strata. A more detailed examination of clusters reveals that while the overall strata are preserved, the underlying neuronal configurations undergo changes during post embryonic growth (<xref rid="fig2" ref-type="fig">Figure 2 B-F</xref>, <xref rid="fig3" ref-type="fig">Figure 3</xref>, see: Supplemental Tables 3, 4, 5, 6). Three general features were extracted from these analyses: 1) individual neurons renegotiate their positions in the context of the identified C-PHATE clusters in different developmental contactomes, suggesting developmental changes; 2) the degree of these changes varied across the distinct strata; and 3) the degree of these changes mapped onto known features of each stratum, such as plasticity. For example, Stratum 1, which contains shallow reflex circuits, displayed the fewest changes among the developmental connectomes (<xref rid="fig3" ref-type="fig">Figure 3 B-F</xref>; Supplemental Table 3). On the other hand, Strata containing circuits associated with behavioral plasticity (Stratum 3 and Stratum 4), displayed the largest changes across postembryonic development (<xref rid="fig3" ref-type="fig">Figure 3H-L</xref>; Supplemental Tables 5, 6).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Examination of the architectural motifs underlying the distinct strata across development.</title>
<p>Visualization of <bold>(A-F)</bold> Stratum 1 (Red) and <bold>(G-L)</bold> Strata 3 and 4 (Blue and Green) reveal motifs that are preserved (Strata 1) and change (Strata 3 and 4) across developmental contactomes (L1 to Adult, left to right, as indicated by labels on top). <bold>(B-F)</bold> Cropped view of Stratum 1 at each developmental stage showing a similar shape of two ‘horn-like’ clusters in the C-PHATE graphs (as seen by orange and blue shaded areas). These two clusters have similar neuronal memberships, which are largely invariant across developmental contactomes (Supplemental Table 3). <bold>(H-L)</bold> Cropped view of Strata 3 and 4 at each developmental stage highlighting differences in the organization and number of neurons contained in each of the Blue and Green strata, which is particularly distinct when comparing (H) L1 and (K) L4 (Supplemental Tables 5, 6). There is an additional supercluster (Yellow in (I-J)) at stages L2 and L3 that contains neurons of S3 and S4 identity.</p></caption>
<graphic xlink:href="609993v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To examine the changes in DC/C-PHATE during postembryonic development, we made the C-PHATE plots fully interactive. This enables users to hover over and identify members of each intermediate cluster, to highlight specific cell trajectories via pseudo-coloring, and compare specific neuronal relationship dynamics across development within a multiview window of distinct C-PHATE plots (<xref rid="fig1" ref-type="fig">Figure 1 E-F</xref>, <xref rid="figS6" ref-type="fig">Supplemental Figure 6</xref>, Supplemental Video 1). Because C-PHATE graphs ultimately represent cells of known identities, we reasoned that interactive mapping of the C-PHATE cluster objects to their component cellular identities and anatomies could yield greater insights on neurodevelopmental changes, linking the algorithmic abstractions of the relationships with the cell biological features and their changes across development (<xref rid="fig4" ref-type="fig">Figure 4</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Case study: AIML and PVQL neurons change clustering patterns across the developmental contactomes.</title>
<p>(A-E) C-PHATE plots across development, with the trajectories of AIM neurons (in purple) and the rest of the spheres colored by stratum identity (see <xref rid="fig2" ref-type="fig">Figure 2</xref>). <bold>(F-G)</bold> Zoom in of the AIM, PVQ, and AVF trajectories corresponding to Larval Stage 1 (A, dotted box) and in (G), Larval Stage 3 (C, dashed box). Note how the relationship between AIM and PVQ neurons in the C-PHATE graph varies for each of the examined contactomes across development, as seen by the iterations before co-clustering (<xref rid="fig1" ref-type="fig">Supplemental Figure 1</xref>, Supplemental Table 7).</p></caption>
<graphic xlink:href="609993v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To examine our hypothesis and determine the utility of C-PHATE for discovery, we inspected specific regions where the distribution, or ‘shape’ of superclusters changed across the set of developmental contactomes. When comparing C-PHATE graphs representing distinct contactomes, we accounted for changes in the iterations at which “merge events” (or co-clustering of neurons) occurred. The logic in considering the ‘iterations of the merge events’ is because variations in contact profiles influence changes in iterations of merge events. Based on these criteria, we focused on a region displaying changes in Strata 3 and 4 and using the interactive C-PHATE graphs (<xref rid="fig4" ref-type="fig">Figure 4 A-E</xref>), we determined the identities of neurons that changed clustering patterns across the developmental contactomes (<xref rid="fig4" ref-type="fig">Figure 4F</xref> and <xref rid="fig4" ref-type="fig">G</xref>). Specifically, we focused on two interneurons, named AIML and PVQL, which we observed undergo a change in their cluster assignment from Stratum 4 (at L1) to Stratum 3 (at Larva stage 4, L4; <xref rid="fig4" ref-type="fig">Figure 4A</xref> and <xref rid="fig4" ref-type="fig">D</xref>). We pseudo-colored the trajectories of the AIML and PVQL neurons in C-PHATE to explore the changes in their merge events throughout the developmental stages (<xref rid="fig4" ref-type="fig">Figure 4F</xref> and <xref rid="fig4" ref-type="fig">G</xref>, <xref rid="figS1" ref-type="fig">Supplemental Figure 1</xref>, Supplementary Table 7). Comparing L1, L2 (Larval Stage 2) and L3 (Larval Stage 3) datasets, we observe the AIML and PVQL neurons merge at iterations 16, 14 and 22 (respectively). The increasing numbers of iterations across the L1, L2 and L3 datasets suggests the relative contact profiles of AIML and PVQL diverge across these contactomes (<xref rid="fig4" ref-type="fig">Figure 4F</xref> and <xref rid="fig4" ref-type="fig">G</xref>; <xref rid="figS1" ref-type="fig">Supplemental Figure 1</xref>; Supplementary Table 7). Yet, between the L4 and Adult datasets, we observe the PVQL and the AIML neurons merge at iterations 20 in the L4 and iteration 14 in the Adult (<xref rid="figS1" ref-type="fig">Supplemental Figure 1</xref>; Supplementary Table 7). The decrease in the number of iterations required for the merge event suggests that the relative contact relationships of AIML and PVQL eventually converge between L4 and adult animals. Comparison of the identities of the neurons that co-cluster with AIML and PVQL similarly suggests that the contact relationships varied across developmental stages (<xref rid="fig4" ref-type="fig">Figure 4F</xref> and <xref rid="fig4" ref-type="fig">G</xref>, <xref rid="figS1" ref-type="fig">Supplemental Figure 1</xref>, Supplementary Table 7).</p>
<sec id="s2a">
<title>Visualizing contact profiles in individual cells</title>
<p>DC/C-PHATE changes should result from changes in contact profiles. To link the observed changes in the C-PHATE graphs with the cell-biological changes in contact profiles, we generated a tool that would simultaneously enable: 1) 3D visualization of the cell-cell contact sites onto individual neuronal morphologies; 2) examination and comparisons of these contact profiles throughout development for the available contactomes; and 3) integration with DC/C-PHATE to link C-PHATE cluster objects to the 3-D morphologies of the algorithmically clustered cells. With these capabilities integrated, we could simultaneously view the contactome from two complementary perspectives – at an abstract systems level via DC/C-PHATE and at a cell biological level via 3D contact modeling – to perceive the architectural themes that underlie similar network patterns.</p>
<p>To create this tool, we generated 3D models of the area of physical contact between adjacent neuron pairs (Supplemental Tables 1, 2, Methods and Materials; <xref rid="fig5" ref-type="fig">Figure 5</xref>) Supplemental Figure 2). Visualizing contacts from all adjacent neurons builds a multi-colored skeleton of the neuron morphology mapped onto the boundaries of this neuron (<xref rid="fig5" ref-type="fig">Figure 5A</xref> and <xref rid="fig5" ref-type="fig">C</xref>). Because the identities of the neurons are known and linked to the 3D contact models, we built text pop ups that define the contact partners for each site (<xref rid="fig5" ref-type="fig">Figure 5C</xref>). Furthermore, since neuron names are consistent across EM datasets, we can link and compare contact sites across development (<xref rid="fig5" ref-type="fig">Figure 5D</xref>). Additionally, we can analyze the representations of contact sites in the context of DC/C-PHATE clustering profiles (<xref rid="fig5" ref-type="fig">Figure 5B</xref>), 3D models of neuronal morphologies (<xref rid="fig1" ref-type="fig">Figure 1F</xref>), and 3D models of synaptic sites for any neuron(s) across development (<xref rid="fig7" ref-type="fig">Figure 7</xref>).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Case Study: Visualization of contact profiles in individual neurons.</title>
<p><bold>(A</bold>) Cartoon schematic of the head of the animal with the AIM neurons (purple) and pharynx (gray), and (dotted box) a 3-D reconstruction of the AIM neuron morphology from the L1 (0 hours post-hatching) dataset. <bold>(B)</bold> Zoom-in of the simplified DC/C-PHATE clustering of the AIM (purple), PVQ (orange), and AVF (green) neurons for the contactome of an L3 animal. <bold>(C)</bold> 3-D representation of all contacts onto the AIM neuron morphology in an L1 animal, colored based on contacting partner identity, as labeled (right) in the detailed inset (black box) region. <bold>(D)</bold> AIM-PVQ contacts (in orange) and AIM-AVF contacts (in green), projected onto the AIM neurons (light purple) across developmental stages and augmented for clarity in the figure (see non-augmented contacts in (<xref rid="figS5" ref-type="fig">Supplemental Figure 5</xref>). Scale bar 2 <italic>µ</italic>m.</p></caption>
<graphic xlink:href="609993v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We used the integrated tools of DC/C-PHATE and 3D representations of the contact profiles to examine the potential cell biological changes leading to the DC/C-PHATE clustering changes observed for the AIML neuron during development. With these tools, we observed changes in the identities of the contacts made in the dorsal region of the AIML neurite (<xref rid="fig5" ref-type="fig">Figure 5D</xref>; Supplemental Figure 3). Specifically, in the L2 stage (as compared to L1), we observed a decrease in the contacts from PVQL and an increase in contacts from the AVF neurons. This change persists to the adult stage (<xref rid="fig5" ref-type="fig">Figure 5D</xref>; Supplemental Figure 3).</p>
<p>To then determine the possible source of these developmental changes in contacts, we visualized 3D models of the segmented morphologies for these neurons across L1 to adulthood (<xref rid="fig6" ref-type="fig">Figure 6</xref>). We find that AIM and PVQ neurons maintain similar morphologies throughout development (<xref rid="fig6" ref-type="fig">Figure 6C</xref>), while AVF neurons undergo substantial neurite outgrowth onto new regions of contact between AIM and PVQ (<xref rid="fig6" ref-type="fig">Figure 6 B-D</xref>). Specifically, the data revealed that although the AVF neurons terminally differentiate in the embryo, they do not grow into the nerve ring until the L2 stage, and continue to grow until the Adult stage (<xref rid="fig6" ref-type="fig">Figure 6 B-D</xref>). The AVF neurons grow in between the AIM and PVQ neurons (<xref rid="fig6" ref-type="fig">Figure 6D</xref>), altering their contact profiles, which likely contributes to the observed changes in the C-PHATE graphs (although we note that DC/C-PHATE representations systematically cluster neurons based on relative similarities across contact profiles, not solely by scoring changes in specific contacts within any given pair (<xref rid="fig4" ref-type="fig">Figure 4F</xref> and <xref rid="fig4" ref-type="fig">G</xref>; <xref rid="fig5" ref-type="fig">Figure 5B</xref> and <xref rid="fig5" ref-type="fig">D</xref>; Supplemental Video 2). We also observe that both AVFL and AVFR grow into the nerve ring alongside AIML, later continuing to grow around to reach AIMR, and that these relationships were also reflected in the C-PHATE graphs in terms of the clustering profiles throughout development; (<xref rid="fig4" ref-type="fig">Figure 4G</xref>; <xref rid="figS1" ref-type="fig">Supplemental Figure 1</xref>).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Case study: Segmented morphologies of AIM, PVQ and AVF across larval development.</title>
<p><bold>(A)</bold> Cartoon schematic of the <italic>C. elegans</italic> head, pharynx (gray) and examined neurons with dashed black box representing the nerve ring region. <bold>(B)</bold> Schematic representation of the outgrowth path of the AVF neurons as observed by EM (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>). AVFL and AVFR (green) grow along the AIML neuron (purple) onto the AIMR neurite. The distal end of the AVF neurite is highlighted with a black arrowhead in the schematic. <bold>(C)</bold> Neuronal morphologies of AIM (purple), PVQ (orange), AVF (green) across post embryonic development, as indicated, with black arrowhead pointing to AVF outgrowth. Scale bar = 2 <italic>µ</italic>m. Regions for insets (L1, dotted box; L2, dashed box) correspond to (D). <bold>(D)</bold> Morphologies of these neurons (rotated to the posterior view) display the AVF neurons’ positions between the AIM and PVQ neurons at the L1 and L2 stage. Indicated outgrowth between neurons continues to the Adult stage (Supplemental Video 2). Note how AVF outgrowth alters contact between PVQ and AIM (<xref rid="fig5" ref-type="fig">Figure 5D</xref>).</p></caption>
<graphic xlink:href="609993v2_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We then examined if the developmental changes in contact profiles result in changes in circuitry. We examined this by layering on synaptic information. Despite dwindling AIM-PVQ contacts, AIM and PVQ neurons maintained their synaptic relationship throughout development, with synaptic sites observed primarily at the base of AIM neurons, a region of persistent contact with PVQ (<xref rid="fig7" ref-type="fig">Figure 7A-B</xref>). We observed that increases in contacts between AIM and AVF neurons resulted in additional en passant synapses at the new points of contact, beginning at the L2 stage and continuing to adulthood (<xref rid="fig7" ref-type="fig">Figure 7A-B</xref>). We also observed that AVF forms synapses with the adjacent PVQ neurons (<xref rid="fig7" ref-type="fig">Figure 7</xref>; <xref rid="figS4" ref-type="fig">Supplemental Figure 4</xref>).</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Case study: AIM-PVQ and AIM-AVF synaptic positions across development.</title>
<p><bold>(A)</bold> AIM-PVQ synaptic sites (dark orange arrowheads) and AIM-AVF synaptic sites (dark green arrowheads) in the segmented AIM neurons and reconstructed across post embryonic development from original connectomics data. Scale bar = 2 <italic>µ</italic>m. <bold>(B)</bold> Schematic of the AIM, PVQ and AVF circuitry across development based on synaptic connectivity and focusing on the stage before AVF outgrowth (L1), during AVF outgrowth (L2) and Adult; arrow direction indicates pre to post synaptic connection, and arrow thickness indicates relative number of synaptic sites (finest, &lt;5 synapses; medium, 5-10 synapses; thickest, 11-30 synapses). <bold>(C)</bold> Zoom in of synaptic sites (green) in the Adult connectome and embedded into the AIM neuron morphology (light purple). In NeuroSCAN, presynaptic sites are displayed as blocks and postsynaptic sites as spheres, and a scaling factor is applied to the 3-D models (References Materials and Methods).</p></caption>
<graphic xlink:href="609993v2_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In summary, by integrating, representing and comparing datasets using the new C-PHATE tools and contact profiles in NeuroSCAN, we identified developmental changes in the relationships of AIM, AVF and PVQ. This case-study highlights the utility of combining cell biological representations (such as morphologies, contacts and synapses) with coarse-grained systems-level representations (like DC/C-PHATE) of vEM datasets to uncover developmental changes which could be further explored experimentally. Therefore, NeuroSCAN serves as a powerful platform for generating hypotheses for empirical testing, which can lead to insights into the dynamics of circuit development.</p>
</sec>
<sec id="s3">
<title>NeuroSCAN: Facilitating multi-layered interrogation of neuronal relationships in the <italic>C. elegans</italic> nerve ring throughout larval development</title>
<p>NeuroSCAN is built as a web-based client-server system designed to enable the sharing of anatomical connectomics data with an emphasis on facilitating the analyses of neuropil relationships across hierarchies and scales. To achieve this, we integrated tools of neuroanatomical investigation from the available <italic>C. elegans</italic> nerve ring connectomes and contactomes with a collection of 3-D modeled elements (morphologies, contacts and synapses and C-PHATE) representing different aspects of neuronal architecture and relationships (<xref rid="fig8" ref-type="fig">Figure 8</xref>). NeuroSCAN differs from other available web-based tools in this area with the integration of C-PHATE graphs that enable exploration of hierarchical organizations of stratified fascicles, the availability of new tools to examine the contactome, and the integration of these data with existing connectome and morphological datasets across developmental stages.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><title>NeuroSCAN is a tool that enables integrated comparisons of neuronal relationships across development.</title>
<p>With NeuroSCAN, users have integrated access to: C-PHATE plots, 3-D morphological renderings, neuronal contact sites and synaptic representations. Through stage-specific C-PHATE renderings, users can explore neuronal relationships from high dimensional contactome data. <bold>(Top)</bold> On C-PHATE plots, schematized here, each sphere represents an individual neuron, like AVF or AIM, or a group of neurons clustered together during algorithm iterations. <bold>(Right)</bold> 3D renderings of AIM neurons (Purple), PVQ neurons (Orange), AVF neurons (Green) can be visualized in the context of the entire nerve ring or other circuits (gray). <bold>(Left)</bold> AIM:AVF contact sites (green) onto the AIM neuron (purple) with the AIM-AVF synaptic sites (orange). Inset shows zoomed in of contacts and synapses-presynaptic sites (blocks) postsynaptic sites (spheres). Data depicted here are from the L3 stage (27 hours post hatching).</p></caption>
<graphic xlink:href="609993v2_fig8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>NeuroSCAN has eight key user-driven features: (1) C-PHATE, with the ability to highlight clusters containing neurons of interest (<xref rid="figS6" ref-type="fig">Supplemental Figure 6</xref>, Supplemental Video 1), (2) reconstructions of neuronal morphologies (Supplemental Figure 10, Supplemental Video 3) (3) reconstructions of neuronal morphologies of C-PHATE cluster members with a right-click on C-PHATE clusters (Sup-plemental Video 1), (4) 3-D renderings of neuronal contacts to visualize the spatial distribution of contact profiles (<xref rid="figS5" ref-type="fig">Supplemental Figure 5</xref>, Supplemental Video 4) (5) 3-D representations of synaptic sites with the option to visualize subsets of those sites (<xref rid="figS7" ref-type="fig">Supplemental Figure 7</xref>, Supplemental Video 4) (6) the ability to perform side-by-side comparisons across development (Supplemental Figure 11, Supplemental Video 3), (7) the option to pseudo color each object to highlight points of interest (<xref rid="figS11" ref-type="fig">Supplemental Figure 11</xref>, Supplemental Video 3) and (8) each item is an individual object with the ability to be further customized by the user (<xref rid="figS11" ref-type="fig">Supplemental Figures 11</xref>, <xref rid="figS12" ref-type="fig">12</xref>).</p>
<p>The NeuroSCAN website architecture and data structure were designed to integrate these key user-driven features via a modular platform and linked datasets. The architecture uses Geppetto, an open-source platform designed for neuroscience applications, modularity, and large datasets (<xref ref-type="bibr" rid="c7">Cantarelli et al., 2018</xref>). Briefly, the architecture is effectively separated into two applications, a frontend React/JavaScript bundle that is delivered to the client, rendering the neuron data and assets, and a NodeJS application that exposes a JSON API, serving the neuron data and assets based on user interactions (<xref rid="figS13" ref-type="fig">Supplemental Figure 13</xref>). The backend uses a Postgres Database to store underlying data (<xref rid="figS14" ref-type="fig">Supplemental Figure 14</xref>), a Persistent Storage Volume that houses and serves static assets, and a variable number of Virtual Machines to run the frontend and backend application code, scaling as needed to accommodate traffic. The User Interface is a React application that allows users to filter, sort, and search through the Neurons so that they can be added to an interactive canvas (<xref rid="figS13" ref-type="fig">Supplemental Figure 13</xref>). When users add Neurons to a viewer, a .gltf file is loaded in for a given model (Synapses, Neurons, Contacts) at the selected developmental stage (<xref rid="figS13" ref-type="fig">Supplemental Figure 13</xref>), which can then be manipulated in the 3D environment or layered with other meshes as needed. NeuroSCAN can be used on common web-browsers (e.g. Google Chrome, Safari) and mobile devices.</p>
<p>The underlying data model makes use of tables representing Synapses, Neurons, Contacts and Developmental Stages. Relationships between these models are represented by foreign keys (<xref rid="figS14" ref-type="fig">Supplemental Figure 14</xref>). Source data is defined in a file-tree structure containing various assets (such as .gltf files representing various entities), as well as CSV’s which store relationships across entities. The directory structure outlines a vertical hierarchy, starting at the developmental stages, then branching downwards onto neuron and synapse data. A Python script is invoked to traverse the directory tree and parse the files, writing to the database accordingly. This configuration enables: 1) verification of the ingested data and 2) quick search times through the datasets to identify related items. Code is version-controlled in GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/colonramoslab/NeuroSCAN">https://github.com/colonramoslab/NeuroSCAN</ext-link>) and deployed through a CI/CD pipeline when updates are committed to the main branch (Supplemental Figure 13).</p>
</sec>
<sec id="s3a">
<title>NeuroSCAN: practical considerations</title>
<p>We offer seven practical considerations for users. First, NeuroSCAN is available on mobile platforms as a quick and convenient way to look up neuron morphologies and relationships. Second, since contact sites offer the ability to explore the surrounding neurons and the position(s) of contact between adjacent neurons, NeuroSCAN is designed to enable studies of adjacent neurons (e.g. phenotypes that result in site-specific ectopic synapses; neuron morphology changes that may affect specific surrounding neurons; developmental events requiring communication between neurons, etc.). Third, C-PHATE can be used to identify neurons with similar contact profiles. Because contact profiles are associated with circuits identities (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>), exploration of neuronal relationships via C-PHATE can be used to identify new relationships between specific neurons and circuits. Fourth, visualization of subsets of synaptic and contact sites allows direct comparisons to light microscopy approaches such as cell-specific labeling of synapses or GFP-Reconstitution across synaptic partners (Feinberg et al. 2008). Fifth, because the color and transparency of each 3-D model can be customized, users can further integrate NeuroSCAN outputs of additional atlases (for gene expression, neurotransmitter and receptor expression, functional connectivity, etc. (<xref ref-type="bibr" rid="c23">Packer et al., 2019</xref>; <xref ref-type="bibr" rid="c33">Taylor et al., 2021</xref>; <xref ref-type="bibr" rid="c35">Wang et al., 2023</xref>; <xref ref-type="bibr" rid="c15">Fenyves et al., 2020</xref>; <xref ref-type="bibr" rid="c26">Randi et al., 2023</xref>) and directly use the NeuroSCAN outputs to create figures and comparisons (as done for this paper). Sixth, although synaptic sites with BWM (body wall muscles) are included in NeuroSCAN, the current data model limits the ability to search for these non-neuronal cells. Users can search for neurons with synapses to BWM to find this datatype. Seventh, to enable direct comparisons between our data representations and the primary EM data, the original annotations have been preserved and can be accessed by users via the sister app, CytoSHOW (<ext-link ext-link-type="uri" xlink:href="http://CytoSHOW.org">CytoSHOW.org</ext-link>). As the data continues to be curated, the modular design of NeuroSCAN and its companionship with CytoSHOW enables integration of future annotations.</p>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>NeuroSCAN is an integrative tool for analyzing detailed, web-based representations of neuronal connectomes and contactomes throughout post-embryonic development in <italic>C. elegans</italic>. Connectomes and contactomes are derived from volume electron microscopy (vEM) micrographs of neuropil regions (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="c36">White et al., 1986</xref>). These EM micrographs are information-rich and have the potential to reveal architectural motifs across scales, from the nanoarchitecture of the neuron to the neuroanatomy of each circuit in the brain. Cell biological features, such as contact profiles and synaptic positions, can be rigorously quantified and systematically represented as graphs capturing multidimensional relationships. These representations require methodologies from data science that enable dimensionality reduction and comparisons of the architecture across scales. Yet to derive new intuitions about the spatiotemporal events leading to the architecture that shapes its function, it is necessary to integrate and compare these various representations, bridging knowledge from the cell biological events to the systems-level network relationships. NeuroSCAN is designed to achieve this integration, enabling synthesis of knowledge ranging from the abstractions of neuronal relationships in C-PHATE to the cell biological features underpinning these abstractions. We provide a case study to illustrate how integration of analyses performed in NeuroSCAN can result in new insights. First, we demonstrated the discovery process with C-PHATE representations to identify neurons that undergo changes in their contactome during development. Second, we developed 3-D representations of contact sites to analyze the local neuronal regions that were identified via DC/C-PHATE analysis. Third, we visualized and compared these representations across development to identify cell biological changes in neuronal morphologies and synaptic positions across neuron classes. Our case study demonstrates the utility NeuroSCAN to facilitate exploration of neuronal relationships, leading to new insights on structural features of the connectome and hypotheses for empirical testing.</p>
<sec id="s4a">
<title>Comparisons of NeuroSCAN to other connectomics atlases</title>
<p>NeuroSCAN is one of several efforts centered around interpreting the <italic>C. elegans</italic> EM datasets. Other open-source tools for data exploration in <italic>C. elegans</italic> include efforts to capture neuron morphologies and synaptic information (including integration of new connectomes across larval development), to map neurotransmitter and receptor expression, and to record whole brain functional connectivity across genotypes (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="c1">Altun, Z.F. et al., 2002</xref>; <xref ref-type="bibr" rid="c12">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="c15">Fenyves et al., 2020</xref>; <xref ref-type="bibr" rid="c26">Randi et al., 2023</xref>). NeuroSCAN was inspired by tools like NemaNode and WormWiring (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="c12">Cook et al., 2019</xref>), which enable 3-D visualizations of neuronal morphologies and synaptic sites with synaptic subsets restricted to pre or postsynaptic sites. In NeuroSCAN we sought to generate and integrate information beyond the synaptic connectome to include local neuronal regions (contactome) and neuronal morphologies across available developmental vEM datasets. Contactomes represent features that have been largely overlooked in connectomic datasets, and which capture circuit structures not evident by inspecting solely synaptic relationships (<xref ref-type="bibr" rid="c5">Brittin et al., 2018</xref>). NeuroSCAN extends existing representations to also offer user-driven experience with choice over the visualization of specific synaptic sites, the option to search for synaptic partners, and the ability to customize the color of each synaptic representation (<xref rid="fig7" ref-type="fig">Figure 7</xref>). NeuroSCAN representations complement resource databases like WormAtlas, which hosts digitized electron micrographs and schematics of neuron morphologies with aggregated information on each neuron (<xref ref-type="bibr" rid="c1">Altun, Z.F. et al., 2002</xref>). As such, NeuroSCAN extends an existing suite of opensource resources to facilitate community wide exploration of vEM datasets.</p>
</sec>
<sec id="s4b">
<title>NeuroSCAN design and future directions</title>
<p>NeuroSCAN code and development was intentional in its design as an open-source resource that is modular and allows integration of additional features and data structures (<xref ref-type="bibr" rid="c7">Cantarelli et al., 2018</xref>). It is a hypothesis-generating tool that can be equally used by educators seeking to teach neuroanatomical principles, and researchers seeking to identify changes across connectome datasets. NeuroSCAN could be integrated into emerging datasets, including developmental time-courses of cell-specific transcriptomic data that would enable further insights on the molecular events underpinning neuronal development and function– from synaptogenic processes to the logic of neurotransmitter use (<xref ref-type="bibr" rid="c23">Packer et al., 2019</xref>; <xref ref-type="bibr" rid="c33">Taylor et al., 2021</xref>; <xref ref-type="bibr" rid="c15">Fenyves et al., 2020</xref>) and how it sustains functional connectivity (<xref ref-type="bibr" rid="c26">Randi et al., 2023</xref>). Future iterations of NeuroSCAN could also include positions and relationships of neurons to non-neuronal cell types, as well as the relative networks of segmented and quantified organelles within cells. NeuroSCAN could be used to compare new datasets from genetic variants, from animals trained under specific conditions or from additional developmental datasets across embryogenesis. As such, the pipeline and design of NeuroSCAN can serve as a sandbox to examine the value of the integration of datasets in exploring representations of neuronal relationships across connectomes.</p>
<p>NeuroSCAN forms part of a longer tradition that has leveraged the pioneering datasets generated for <italic>C. elegans</italic> connectomes towards exploring structure-function relationships in the nervous system. While the smaller scale of the <italic>C. elegans</italic> neuropil allowed us to rigorously vet the utility of these approaches, we suggest that these same methods would be beneficial in comparative studies in neuropils of other species, including those with less stereotypically formed connectomes. We suggest that contact profiles, along with neuron morphologies and synaptic partners, can act as ‘fingerprints’ for individual neurons and neuron classes. These ‘fingerprints’ can be aligned across animals of the same species to create identities for neurons. Frameworks for systematic connectomics analysis in tractable model systems such as <italic>C. elegans</italic> are critical in laying a foundation for future analyses in other organisms with up to a billion-fold increase in neurons (<xref ref-type="bibr" rid="c34">Toga et al., 2012</xref>). Therefore, we envision these collective efforts akin to the foundational work from <italic>C. elegans</italic> in pioneering genomic analysis and annotations ahead of the Human Genome Project (<xref ref-type="bibr" rid="c30">Stein et al., 2001</xref>; <xref ref-type="bibr" rid="c9">Collins and Fink, 1995</xref>). We believe that further integration of datasets in platforms like NeuroSCAN would be key in determining the representations and features necessary for the interpretation and analyses of other connectomes.</p>
</sec>
</sec>
<sec id="s5">
<title>Methods and materials</title>
<sec id="s5a">
<title>Lead Contact</title>
<p>Further information and requests can be directed to Daniel.colon-ramos@yale.edu.</p>
</sec>
<sec id="s5b">
<title>Data Code and Availability</title>
<p>Figures in this article have been generated with NeuroSCAN (<xref rid="fig5" ref-type="fig">Figures 5D</xref>, <xref rid="fig6" ref-type="fig">Figures 6</xref>-<xref rid="fig7" ref-type="fig">7</xref>, <xref rid="figS2" ref-type="fig">Figure S2G-I</xref>, <xref rid="figS3" ref-type="fig">Figure S3</xref>, <xref rid="figS4" ref-type="fig">Figure S4</xref>, <xref rid="figS5" ref-type="fig">Figure S5 A-B</xref>, <xref rid="fig8" ref-type="fig">Figure 8</xref>, <xref rid="figS6" ref-type="fig">Figures S6</xref>-<xref rid="figS12" ref-type="fig">S12</xref>, Videos S1-S4) and CytoSHOW (<xref rid="fig1" ref-type="fig">Figures 1</xref>-<xref rid="fig4" ref-type="fig">4</xref>, <xref rid="fig5" ref-type="fig">Figure 5A</xref> and <xref rid="fig5" ref-type="fig">C</xref>, <xref rid="figS1" ref-type="fig">Figure S1</xref>, Figure S 5C). Data can be visualized via the viewer at NeuroSCAN.net or by downloading glTF files from NeuroSCAN and using a glTF viewer to visualize them. Additionally, the data generated for NeuroSCAN is available in .OBJ file format (and can be visualized from a local hard drive with CytoSHOW (<ext-link ext-link-type="uri" xlink:href="http://neuroscan.cytoshow.org/">http://neuroscan.cytoshow.org/</ext-link>). All excel files for Diffusion Condensation iterations and adjacency quantifications can be found in Tables S3-S13. Tutorials for NeuroSCAN are available on NeuroSCAN.net upon opening the website, within the main menu of the website (<xref rid="figS8" ref-type="fig">Figure S8</xref>), and in the supplementary materials (<xref rid="figS5" ref-type="fig">Figure S5</xref>-<xref ref-type="fig" rid="figS12">S12</xref>; Videos S1 and S3-S4). These tutorials generally cover the process of engaging in analysis at and across specific developmental stages by filtering the data items and adding items to viewers (<xref rid="figS10" ref-type="fig">Figure S10</xref>). General understanding for how to use C-PHATE to analyze neuronal relationships can be found in <xref rid="fig1" ref-type="fig">Figure 1</xref>, <xref rid="fig4" ref-type="fig">Figure 4</xref>, <xref rid="figS6" ref-type="fig">Figure S6</xref>, Video S1, and in our previous publication (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>). For additional information on filters and in-viewer changes to the data (colors, developmental stages, downloading data) see <xref rid="figS5" ref-type="fig">Figure S5</xref>, <xref rid="figS7" ref-type="fig">Figure S7</xref>, <xref rid="figS11" ref-type="fig">Figure S11</xref>, <xref rid="figS12" ref-type="fig">Figure S12</xref>, and Videos S3-S4. All code for website development is available at Github (<ext-link ext-link-type="uri" xlink:href="https://github.com/colonramoslab/NeuroSCAN">https://github.com/colonramoslab/NeuroSCAN</ext-link>) and for information on website architecture and data model see <xref rid="figS13" ref-type="fig">Figures S13</xref>-<xref ref-type="fig" rid="figS14">S14</xref>.</p>
</sec>
<sec id="s5c">
<title>Experimental Model and Subject Details</title>
<p>Volume electron microscopy (vEM) data and segmentation of neurons and synapses were analysed from (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="c36">White et al., 1986</xref>; <xref ref-type="bibr" rid="c5">Brittin et al., 2018</xref>; <xref ref-type="bibr" rid="c12">Cook et al., 2019</xref>). We analyzed available EM datasets that were transversely sectioned and segmented (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="c4">Brittin et al., 2021</xref>; <xref ref-type="bibr" rid="c36">White et al., 1986</xref>). We deleted the CAN neurons in the L1-L3 datasets to keep these datasets consistent with the legacy datasets L4 and Adult (N2U), which do not contain CAN neurons (as in (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>)).</p>
</sec>
<sec id="s5d">
<title>Method Details</title>
<p>All 3-D object isosurfaces (Morphologies (Neurons), Contacts, Synapses, C-PHATE plots) were generated from segmented EM datasets using a modified version of the ImageJ 3D viewer plug-in (<xref ref-type="bibr" rid="c29">Schmid et al. 2010</xref>) implemented in CytoSHOW (<ext-link ext-link-type="uri" xlink:href="http://scytoshow.org">scytoshow.org</ext-link>). This tool employs the marching cubes algorithm for polygon-generation. All 3-D objects are first exported as wavefront (.OBJ) files then converted to GL Transmission Format (.glTF) file format which does not distort the resolution but compacts the file information to enable faster loading times in the web-based 3-D viewer.</p>
<sec id="s5d1">
<title>Pixel Threshold Distance for Adjacency Profiles and Contacts</title>
<p>We identified two challenges in compiling Electron Microscopy (EM) datasets for comparisons: 1) how to uniformly capture neuronal relationships based on areas of physical adjacency (contact) across datasets that have differences in volume depth and in x-y-z resolutions, and 2) how to standardize across datasets in which membrane boundaries had been called using a variety of methods, including contrast methods and segmentation methods (hand-drawn vs predicted via centroid node expansion by a shallow convolutional neural network) (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="c5">Brittin et al., 2018</xref>; <xref ref-type="bibr" rid="c36">White et al., 1986</xref>). To address this, we first standardized the region of the neuropil across all developmental stages as in (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>). Briefly, all cell bodies were deleted, and we used the entry of the nerve ring neurons into the ventral cord as the posterior boundary landmark for the entire volume, focusing on the AIY Zone 2 (<xref ref-type="bibr" rid="c11">Colón-Ramos et al., 2007</xref>); slice range Table S1). Previously reported adjacency profiles used 10 pixels (or 45 nm) as the pixel threshold distance for the L4 (JSH) and Adult (N2U) datasets (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>). To account for differences in resolution (x-y axis) and in calling membrane boundaries between the L4 and Adult datasets and L1-L3 datasets, we designed a protocol to define the pixel threshold for each dataset. In short, for two cells that are in direct contact (<xref rid="figS2" ref-type="fig">Figure S2 D</xref>) in the manually segmented datasets (L4 and Adult), we calculated the length of overlap needed to reach from the segmented edge of one cell, across the membrane, and into the adjacent cell, when the segmented area of one cell is expanded by 45 nm (10 pixels). This results in an average overlap of 30 nm for directly contacting cells in the L4 dataset. Then, in each computationally segmented dataset (L1-L3), we empirically tested the distance (e.g. 55 nm, 60 nm, 62 nm) required to achieve a similar overlap of 30 nm in direct contact cells. That empirical number (in nm) was used for adjacency calculations and rendering of contacts. The numbers were converted from nanometers into pixels to create a pixel threshold distance for each dataset, and these are shown in Table S1. Once these corrections had been applied, we calculated the cell-to-cell adjacency scores for all cell pairs in each dataset by using the measure_adjacency algorithm from <ext-link ext-link-type="uri" xlink:href="https://github.com/cabrittin/volumetric_analysis">https://github.com/cabrittin/volumetric_analysis</ext-link>; (<xref ref-type="bibr" rid="c5">Brittin et al., 2018</xref>) (Tables S8-S13). Adjacency matrices were used for Diffusion condensation (<xref ref-type="bibr" rid="c6">Brugnone et al., 2019</xref>).</p>
</sec>
<sec id="s5d2">
<title>Diffusion Condensation</title>
<p>Diffusion condensation (DC) is a dynamic, time-inhomogeneous process designed to create a sequence of multiscale data representations by condensing information over time (<xref ref-type="bibr" rid="c6">Brugnone et al., 2019</xref>). The primary objective of this technique is to capture and encode meaningful abstractions from high-dimensional data, facilitating tasks such as manifold learning, denoising, clustering, and visualization. The underlying principle of diffusion condensation is to iteratively apply diffusion operators that adapt to the evolving data representation, effectively summarizing the data at multiple scales. The diffusion condensation process begins with the initialization of an initial data representation, typically the raw high-dimensional data or a preprocessed version. This initial representation is used to construct a diffusion operator, a matrix derived from a similarity matrix that reflects the local geometry of the data. The similarity metric, such as Euclidean distance or cosine similarity, plays a crucial role in defining these local relationships. Once the initial diffusion operator is established, the algorithm proceeds to the diffusion step. In this step, the diffusion operator is applied to the data, smoothing it by spreading information along the edges of the similarity graph. This operation captures the intrinsic geometry of the data while reducing noise. The specific form of the diffusion operator, such as the heat kernel or graph Laplacian, significantly impacts how information is propagated during this step. Following the diffusion step, the condensation step updates the data representation by aggregating diffused data points if the distance between them falls below a ‘merge threshold’. This step creates a more compact and abstract representation of the data. These diffusion and condensation steps are iteratively repeated. At each iteration, the diffusion operator is recomputed based on the updated diffuse data representation, ensuring that the process adapts to the evolving structure of the data. The iterations continue until a stopping criterion is met, such as convergence of the data representation to a single point. The output of the diffusion condensation process is a sequence of multiscale data representations. Each representation in this sequence captures the data at a different level of abstraction, with earlier representations preserving more detailed information and later representations providing more condensed summaries. This sequence of representations can be utilized for various tasks, including manifold learning, denoising, clustering, and visualization. By iteratively smoothing and condensing the data, diffusion condensation reveals the underlying structure of high-dimensional datasets. A detailed algorithm description is provided in Box 1 and Algorithm 1.</p>
<boxed-text id="box1">
<p><bold>Diffusion Condensation</bold></p>
<p><bold>Initialization</bold></p>
<p>Let <bold>X</bold> = {<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, …, <italic>x</italic><sub><italic>n</italic></sub>} be the set of <italic>n</italic> data points in a high-dimensional space. Construct the affinity matrix <bold>A</bold>, where <italic>A</italic><sub><italic>ij</italic></sub> measures the similarity between <italic>x</italic><sub><italic>i</italic></sub> and <italic>x</italic><sub><italic>j</italic></sub>. Typically,
<disp-formula id="ueqn1">
<graphic xlink:href="609993v2_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
for a chosen scale parameter σ.</p>
<p><bold>Diffusion Operator</bold></p>
<p>Define the degree matrix <bold>D</bold> as a diagonal matrix where D diffusion operator D<sub><italic>ii</italic></sub> = ∑<sub><italic>j</italic></sub> <italic>A</italic> <sub><italic>ij</italic></sub>. Construct the
<disp-formula id="ueqn2">
<graphic xlink:href="609993v2_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
which normalizes the affinity matrix.</p>
<p><bold>Diffusion Step</bold></p>
<p>Apply the diffusion operator to the data:
<disp-formula id="ueqn3">
<graphic xlink:href="609993v2_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This step smooths the data, capturing the intrinsic geometry.</p>
<p><bold>Condensation Step</bold></p>
<p>After each diffusion step, merge data points that are within a small distance, ϵ, from each other to form a condensed representation. Specifically, data points <italic>x</italic><sub><italic>i</italic></sub> and <italic>x</italic><sub><italic>j</italic></sub> are merged if
<disp-formula id="ueqn4">
<graphic xlink:href="609993v2_ueqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>This merging process produces a set of condensed cluster centers <bold>C</bold> = {<italic>c</italic><sub>1</sub>, <italic>c</italic><sub>2</sub>, …, <italic>c</italic>}, where each center represents the mean of merged data points.</p>
<p><bold>Iteration</bold></p>
<p>Repeat the diffusion and condensation steps, adjusting the parameter σ adaptively, until convergence or for a predefined number of iterations.</p>
</boxed-text>
<statement id="alg1">
<label>Algorithm 1</label>
<p>Diffusion Condensation</p>
<p><fig id="alg1a" position="float" fig-type="figure">
<graphic xlink:href="609993v2_alg1.tif" mime-subtype="tiff" mimetype="image"/>
</fig></p>
</statement>
</sec>
<sec id="s5d3">
<title>C-PHATE</title>
<p>C-PHATE is an extension of the PHATE technique (<xref ref-type="bibr" rid="c21">Moon et al., 2019</xref>) which is specifically aimed at handling and visualizing high-dimensional biological data. C-PHATE is specifically designed to handle compositional data, which are datasets where the components represent parts of a whole and are inherently constrained. It learns the intrinsic manifold of the data, effectively capturing non-linear relationships and structures that are not apparent with traditional methods like PCA or t-SNE. The C-PHATE algorithm starts by loading affinity matrices associated with specific clusterings obtained from diffusion condensation. These matrices are normalized to generate kernel matrices that emphasize the strength of connections within each cluster. The algorithm then builds a connectivity matrix by integrating these kernel matrices based on cluster assignments over multiple time points. This is achieved by first initializing the matrix with kernel matrices along its diagonal and then filling in off-diagonal blocks with transition probabilities that reflect how clusters transition from one time point to the next. Next, we apply the PHATE dimensionality reduction technique to the connectivity matrix to generate 3D embeddings of the data. These embeddings are derived from multiple iterations of diffusion condensation, capturing the geometry of the data at various levels of granularity. The resulting coordinates are saved for subsequent analysis. The final step involves visualizing the PHATE results in a 3D graphics tool, CytoSHOW (Java-based; <ext-link ext-link-type="uri" xlink:href="http://CytoSHOW.org">CytoSHOW.org</ext-link>; <ext-link ext-link-type="uri" xlink:href="https://github.com/mohler/CytoSHOW">https://github.com/mohler/CytoSHOW</ext-link>; (<xref ref-type="bibr" rid="c22">Moyle et al., 2021</xref>)). The results are plotted in a 3D environment, with functionality enabling rollover labels to display information about clustered cells. This requires cross-referencing output tables from the original data collection. CytoSHOW is an interactive tool that allows for assigning colors and annotations to individual neurons and clusters of interest. A detailed algorithm description is provided in Box 2 and Algorithm 2. The python code for C-PHATE allows for user specification of four numerical parameters within the command line, and we used the same set of values for all C-PHATE plots shown in this report (100, 30, 50, 1). The first two integers define the weighting of connectivity between the current condensation step t and previous steps t-1 (weighting = 100) or t-2 (30), respectively, during construction of the connectivity matrix. Values 100 and 30 consistently resulted in a series of plotted clustering trajectories that form a dome-like convergence of paths, enhancing our visual perception of relative relationships and showcasing the super clusters that constitute anatomical strata in the nerve ring neuropil (Video S1). The reproducibility of the dome shape depends on assigning two specific PHATE parameters (<ext-link ext-link-type="uri" xlink:href="https://phate.readthedocs.io/en/stable/api.html">https://phate.readthedocs.io/en/stable/api.html</ext-link>) to non-default values when calling PHATE, the “t” value is set to 50; the “randomstate” value is set to 1.</p>
<boxed-text id="box2">
<p><bold>C-PHATE</bold></p>
<p>Given <italic>n</italic> data points, <bold>X</bold> = {<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, …, <italic>x</italic><sub><italic>n</italic></sub>}, and the diffusion condensation output, consisting of <bold>C</bold> = {<italic>c</italic><sub>1</sub>, <italic>c</italic><sub>2</sub>, …, <italic>c</italic>} denoting the merged data points and <bold>A</bold> denoting the affinity matrix at iteration.</p>
<p><bold>Kernel Matrix</bold></p>
<p>For each iteration,, compute the degree matrix <bold>D</bold>, where D<sub><italic>ii</italic></sub> = ∑<sub><italic>j</italic></sub> <italic>A</italic> <sub><italic>ij</italic></sub>. Then, normalize the affinity matrix to construct the kernel matrix:
<disp-formula id="ueqn5">
<graphic xlink:href="609993v2_ueqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<bold>Initial Connectivity Matrix</bold></p>
<p>Initialize the connectivity matrix <bold>C</bold><sub>PHATE</sub> with zeros. Next, populate it with the kernel matrices,, along its diagonal, reflecting self-connections within each cluster at each time point.</p>
<p><bold>Update Transition Probabilities</bold></p>
<p>For each pair of adjacent time points and + 1, compute a transition probability matrix to determine how points transition between clusters and <italic>C</italic><sub>+1</sub>. Each entry <italic>C</italic> <sub><italic>j</italic></sub> Each entry <italic>p</italic><sub><italic>i</italic>j</sub> in this matrix represents the probability of moving from cluster <italic>i</italic> at time to cluster <italic>j</italic> at time + 1.<italic>p</italic> <sub><italic>ij</italic></sub> is calculated by counting the number of points moving from cluster <italic>i</italic> to cluster <italic>j</italic> and normalizing by the total number of points in cluster <italic>i</italic> at time. This can be expressed as:
<disp-formula id="ueqn6">
<graphic xlink:href="609993v2_ueqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Use these transition probabilities to populate the off-diagonal blocks of <bold>C</bold><sub>PHATE</sub></p>
<p><bold>Dimensionality Reduction</bold></p>
<p>Apply the PHATE algorithm to the final connectivity matrix <sub>PHATE</sub> to obtain the low-dimensional embedding <bold>Y</bold>:
<disp-formula id="ueqn7">
<graphic xlink:href="609993v2_ueqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<bold>Visualization</bold></p>
<p>Visualize low-dimensional embedding <bold>Y</bold> in CytoSHOW.</p>
</boxed-text>
<p>Box 2: Mathematical description of C-PHATE</p>
<statement id="alg2">
<label>Algorithm 2</label>
<p>C-PHATE</p>
<p><fig id="alg2a" position="float" fig-type="figure">
<graphic xlink:href="609993v2_alg2.tif" mime-subtype="tiff" mimetype="image"/>
</fig></p>
</statement>
</sec>
<sec id="s5d4">
<title>Electron Microscopy based 3-D Models</title>
<p>To make 3-D models of neuron morphologies from vEM datasets, we created Image-J format regions of interest (ROIs) using published segmentation data (<xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="c36">White et al., 1986</xref>; <xref ref-type="bibr" rid="c4">Brittin et al., 2021</xref>). For a given cell, the stack of all sectioned ROIs was then used to draw binary image masks as input to a customized version of the marching cubes algorithm (<xref ref-type="bibr" rid="c29">Schmid et al., 2010</xref>) to build and save a 3-D isosurface. All steps of this pipeline were executed within the ImageJ-based Java program, CytoSHOW (<xref ref-type="bibr" rid="c2">AU Duncan et al., 2019</xref>). Slightly modified versions of this workflow were also followed for: 1) generating cell-to-cell contact ROIs and 2) for generating 3-D representations of synaptic objects. To align the 3-D models from the variously oriented vEM datasets, all surfaces from a given specimen were rotated and resized to fit a consensus orientation and scale. This was achieved by applying a rotation matrix multiplication and scaling factor to all vertex coordinates in isosurfaces comprising each modeled dataset (Table S2). Each 3-D object (morphology, contact or synapse) was then exported as a Wavefront file (.OBJ) and then web-optimized by conversion to a Draco-compressed .GLTF file. Each neuron was assigned a type-specific color that is consistent across all datasets to enable facile visual comparison. All the original EM annotations that were used to create the representative 3D models in NeuroSCAN have been preserved, and can be accessed via the sister app, CytoSHOW (<ext-link ext-link-type="uri" xlink:href="https://github.com/mohler/CytoSHOW">https://github.com/mohler/CytoSHOW</ext-link>; (<xref ref-type="bibr" rid="c2">AU Duncan et al., 2019</xref>)).</p>
</sec>
<sec id="s5d5">
<title>Morphologies</title>
<p>Neuron morphologies were linked across datasets for users to visualize changes over time. To enhance 3-D graphics performance without sacrificing gross morphologies we employed a defined amount of data reduction when building each cell-morphology object. NeuroSCAN can therefore display multiple (or even all) neurons of a specimen within a single viewer. The number of vertices for a given object was decreased by reducing 10-fold the pixel resolution of the stacked 2-D masks input into the marching cubes algorithm of CytoSHOW.</p>
</sec>
<sec id="s5d6">
<title>Nerve Ring</title>
<p>To make a simplified mesh of the overall nerve ring shape, individual neuron ROIs were fused together into a single nerve-ring-scale-stack of image masks. This was used for input to the marching cubes algorithm. The union of all overlapping enlarged neurite ROIs in a vEM section was data reduced (20-fold reduced pixel resolution). This rendered a performance-friendly outer shell of the nerve ring.</p>
</sec>
<sec id="s5d7">
<title>Contacts</title>
<p>To build 3-D representations of neuron-neuron contacts, we captured the degree of overlap when an adjacent cell outline was expanded by the specimen-specific, empirically-defined pixel threshold distance listed in Table S1 (see <xref rid="figS2" ref-type="fig">Figure S2</xref>). This was done for each cell outline. This expansion step employs a custom-written method in CytoSHOW that increases the scale of the adjacent outlined region by the pixel threshold distance (Table S1; <xref rid="figS2" ref-type="fig">Figure S2</xref> B and E), while maintaining its congruent shape. The entire collection of captured 2-D contact overlaps (<xref rid="figS2" ref-type="fig">Figure S2 C</xref> and <xref rid="figS2" ref-type="fig">F</xref>) for each adjacent neuron pairs was then reconstructed as a single 3-D object (<xref rid="figS2" ref-type="fig">Figure S2 H</xref>). Contact patches shown in NeuroSCAN are largely reciprocal (e.g. if there is a AIML contact from PVQL then there will be a PVQL contact from AIML), but rarely, 2-D overlap regions may be too small to be reliably converted to 3-D isosurfaces by the marching cubes algorithm, resulting in absence of an expected reciprocal contact model within the collection. Contacts, like cell morphology models, are named to be automatically linked across time-point datasets and to facilitate user-driven visualization of changes over time.</p>
</sec>
<sec id="s5d8">
<title>Synapses</title>
<p>Synaptic positions were derived from the original datasets and segmentations, which annotate synaptic sites in the EM cross-sections (<xref ref-type="bibr" rid="c36">White et al., 1986</xref>; <xref ref-type="bibr" rid="c12">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>). To represent these coordinates in the 3-D segmented neurons, we used Blocks (presynaptic sites), Spheres (postsynaptic sites) and Stars (electrical synapses). The synaptic 3-D objects were placed at the annotated coordinates (<xref ref-type="bibr" rid="c36">White et al., 1986</xref>; <xref ref-type="bibr" rid="c12">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>). Additionally, the objects were scaled with the scaling factor (Table S2). Synaptic objects were named by using standard nomenclature across all datasets, as explained in Supplementary Figure 7.</p>
<p>We note that the L4 and Adult datasets and the L1-L3 datasets were prepared and annotated by different groups (<xref ref-type="bibr" rid="c36">White et al., 1986</xref>; <xref ref-type="bibr" rid="c12">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="c37">Witvliet et al., 2021</xref>). Integration of these datasets reveals nanoscale disagreements in the alignment of the boundaries and synapses. Our representations reflect the original annotations by the authors. Because of these disagreements in annotations, the synapses are not linked across datasets. However, all the original EM annotations that were used to create the representative 3D models in NeuroSCAN, including the synaptic annotations, have been preserved, and can be accessed by the users via the sister app, CytoSHOW (<ext-link ext-link-type="uri" xlink:href="http://CytoSHOW.org">CytoSHOW.org</ext-link>).</p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We are grateful for current and former members of the Colón-Ramos lab for their guidance and suggestions, in particular, Agustín Almoril-Porras and Malcolm Díaz García for assisting with data formatting, Patricia Chanabá-López and Andrea Cuentas-Condori for feedback on the NeuroSCAN website, Mayra Blakey for administrative roles in managing contracts for funding distribution, and Ben Clark and Milind Singh for feedback on the paper. We also thank Stephen Larson, Dario Del Piano and Zoran Sinnema (MetaCell) and Jamie Emerson (Bilte Co.) for website software development, method reporting and hosting services. We thank Brandi Mattson for editing early paper drafts. We acknowledge Ryan Christensen and Hari Shroff (Janelia Research Campus) and Patrick La Riviere (University of Chicago) for helpful discussions and guidance for the NeuroSCAN website. We thank the Research Center for Minority Institutions program, the Marine Biological Laboratories (MBL), and the Instituto de Neurobiología de la Universidad de Puerto Rico for providing meeting and brainstorming platforms. D.A.C-R. acknowledges the Whitman Fellows program at MBL for providing funding and space for discussions valuable to this work. Research in D.A.C-R. and W.A.M. labs was supported by NIH grant R24-OD016474. This work was also funded by the NIH/NINDS grant R35 NS132156-01, DP1 NS111778 and R01 NS076558–2.</p>
</ack>
<sec id="s8">
<title>Additional information</title>
<sec id="s8a">
<title>Authorship Contributions</title>
<p>N.L.K. Conceptualization; Data curation; Investigation; Methodology; Project Administration; Validation; Visualization; Writing-Original Draft S.E.E. Conceptualization; Data curation; Formal Analysis; Investigation; Project Administration; Software; Visualization; Writing-Original Draft D.B. Formal Analysis; Software; Writing - Original Draft M.W.M. Conceptualization; Formal Analysis; Investigation; Project Administration; Software; Writing-Review, Editing P.A.-M. Data curation; Writing-Review, Editing N.V.M. Data curation; Investigation; Writing - Review, Editing S.K. Resources; Supervision W.A.M. Conceptualization; Data curation; Formal Analysis; Funding Acquisition; Methodology; Resources; Software; Supervision; Validation; Writing-Review, editing; Corresponding Author D.A.C.-R. Conceptualization; Funding Acquisition; Resources; Supervision; Visualization; Writing - Review, editing; Corresponding Author</p>
</sec>
<sec id="s9">
<title>Competing Interests</title>
<p>Authors do not declare any competing interests.</p>
<p>Declaration of generative AI and AI-assisted technologies in the writing process. During the preparation of this work the author(s) used ChatGPT in order to improve readability. After using this tool, the author(s) reviewed and edited the content as needed and take full responsibility for the content of the published article.</p>
</sec>
</sec>
<sec id="s10">
<title>Supplementary material</title>
<sec id="s10a">
<title>Supplementary Figures</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplementary Figure S1.</label>
<caption><title>DC/C-PHATE clustering of AIM, PVQ, and AVF across postembryonic development.</title>
<p>(A-E) A cropped view of the DC/C-PHATE plot colored to identify individual neurons and clustering events in (A) Larva stage 1 (5 hours post hatching); (B) Larva stage 2 (23 hours post hatching); (C) Larva Stage 3 (27 hours post hatching); (D) Larva stage 4 (36 hours post hatching); and (E) Adult (48 hours post hatching). See also Video S1 and Table S7.</p></caption>
<graphic xlink:href="609993v2_figS1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Supplementary Figure S2.</label>
<caption><title>Projecting contact profiles onto the segmented neuronal shapes.</title>
<p>(A-C) Graphical representations of the strategy utilized for creating the contact profiles for each of the adjacent neurons (purple, red, cyan) onto a cross section of the neuron of interest (Neuron A, yellow). (D-F) Electron micrograph from the L4 dataset with two adjacent neurons colored yellow and cyan. To build 3-D reconstructions of contact sites from adjacent neurons, we analyzed segmented neurons from the electron microscopy datasets in each slice (A, D). Each adjacent neuron is expanded in all directions to the pixel threshold distance (specified for each dataset; Table S1; Methods; <ext-link ext-link-type="uri" xlink:href="http://CytoSHOW.org">CytoSHOW.org</ext-link>) (B, E). A new ROI (region of interest; purple, red, cyan in C; green in F) is created from the overlapping areas between the neuron of interest (yellow) and the adjacent neurons (C,F). (G-I) 3-D reconstruction of neuron (yellow) (G) with adjacent neuron (cyan), (H) with contact sites captured (green) across all slices, and (I) with contact areas from the adjacent neuron augmented (green) as seen in <xref rid="fig5" ref-type="fig">Figure 5</xref> D.</p></caption>
<graphic xlink:href="609993v2_figS2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Supplementary Figure S3.</label>
<caption><title>AIM contact sites.</title>
<p>Contact sites from PVQ (Orange and highlighted with orange arrowheads) and from AVF (Green and highlighted with green arrowheads) across developmental stages (as indicated) and projected onto the segmented AIM neurons (transparent purple). This figure is the unmodified NeuroSCAN outputs of contact profiles that corresponds to <xref rid="fig5" ref-type="fig">Figure 5D</xref>. In <xref rid="fig5" ref-type="fig">Figure 5D</xref> these contact profiles were augmented. Scale bar = 2 um. See also <xref rid="fig5" ref-type="fig">Figure 5</xref> and Video S4.</p></caption>
<graphic xlink:href="609993v2_figS3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Supplementary Figure S4.</label>
<caption><title>AVF synaptic sites.</title>
<p>Synaptic sites displayed onto transparent (green) AVF neurons across developmental stages. Presynaptic sites (spheres) and postsynaptic sites (Blocks) arevisualized between the AVF neurons and the AIM (Purple) neurons, PVQ (Orange) neurons and other AVF (either AVFL or AVFR; opaque green) neuron; Scale bar = 2 um.</p></caption>
<graphic xlink:href="609993v2_figS4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Supplementary Figure S5.</label>
<caption><title>Visualization of contact sites in NeuroSCAN.</title>
<p>(A) Search for a specific neuron (here, AIM) to filter (B) the list of contacts corresponding to the developmental slider. Neuron A (AIML, here) is the neuron onto which the contacts will be mapped. The Contacts dropdown menu sorts neurons alphabetically (here, colored according to the contact patch color in C). (C) 3-D reconstruction of all AIM contacts at L3 stage. See also Video S3-S4. In the <xref rid="fig5" ref-type="fig">Figure 5D</xref>, contacts are augmented.</p></caption>
<graphic xlink:href="609993v2_figS5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS6" position="float" fig-type="figure">
<label>Supplementary Figure S6.</label>
<caption><title>C-PHATE tutorial in NeuroSCAN.</title>
<p>(A) Add the C-PHATE plot corresponding to the position of the purple circle on the developmental slider (yellow box) by clicking (B) the + sign. (C) Screenshot of C-PHATE plot at L4 (36 hours post hatching), spheres represent individual neurons at the outer edge of the plot and DC iterations increase towards the center where spheres represent clusters of neurons and eventually the entire nerve ring. (D) Screenshot of C-PHATE plot at L4 (36 hours post hatching) with the spheres/clusters containing the AIM neurons highlighted (Blue) by selecting the AIM neurons within the lightbulb menu (red box). See also Video S1. NeuroSCAN features in this figure are not shown to scale.</p></caption>
<graphic xlink:href="609993v2_figS6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS7" position="float" fig-type="figure">
<label>Supplementary Figure S7.</label>
<caption><title>Visualization of synaptic sites with NeuroSCAN.</title>
<p>(A) Search for synaptic sites for specific neuron(s) (e.g., AIM, PVQ) and choose a developmental time point with the slider. (B) Synapses dropdown menu contains a list of objects representing pre- and postsynaptic sites corresponding to all neuron names in the search bar and sorted alphabetically. Searched neurons can be used with the synaptic filter (C) to select for synapse type (electrical or chemical; Note: only use this feature for L4_36 hours post hatching and Adult_48 hours post hatching) and to filter objects by synaptic specialization (pre or post; gray dotted box), (D) which will follow the filter logic (example shown for AIM and PVQ). (E) To enable visualization of subsets of synapses and differentiate between pre- and postsynaptic sites, each synapse contains object(s) representing the postsynaptic site(s) as spheres (Blue and Purple) and the presynaptic site as a block (Orange). These are ordered “by synapse”, with all postsynaptic objects, then the presynaptic object. This specific example corresponds to a 3-D representation of the PVQL (Orange, Pre) AIAL (Blue, Post), AIML (Purple, Post) synapse. (F-G) All synaptic sites contain the name of the presynaptic neuron (Orange), neuron type (chemical, electrical, or undefined), list of postsynaptic neuron(s) (Blue), and Unique identifier (Black; Section, letter) for cases with multiple synapses between the same neurons. The ‘section’ is unique to each synapse between specified neurons and at that specific developmental stage. It is listed in order of its antero-posterior position in the neuron. Synapse names are not linked through developmental datasets. If the synapse is polyadic, there will be multiple postsynaptic neuron names and objects associated with a single presynaptic site. See also Video S4.</p></caption>
<graphic xlink:href="609993v2_figS7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS8" position="float" fig-type="figure">
<label>Supplementary Figure S8.</label>
<caption><title>Opening page view and menu.</title>
<p>(A) View of opening page. (B) Menu for access to the ‘About’ window for referencing source information, the Tutorial, and the developmental Promoter database. See also Video S3.</p></caption>
<graphic xlink:href="609993v2_figS8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS9" position="float" fig-type="figure">
<label>Supplementary Figure S9.</label>
<caption><title>The NeuroSCAN interface enables interrogation of neuronal relationships across development.</title>
<p>(A) The left facing arrow to minimize the left panel and optimize space for the viewer windows. The interface contains four main parts: (B-E) Filters, (F-J) Results, (K-M) Viewer Navigation, and (N-Q) viewer windows. Filter Results by (C) searching for neuron names, (D) selecting a dataset with the developmental slider (in hours posthatching), (E) and filtering synapses based on the pre- or post-synaptic partner on the neurons that are on the search bar. (F) Results drop down menus (filtered by B) for (G) Neuronal morphologies (shown in the viewer as purple in (O)), (H) Contacts (shown in green (O)); (I) Synapses (shown in Orange in (O)); and (J) C-PHATE (shown in (Q)), which gets filtered by the developmental slider in (D). (K) Viewer Navigation to rotate the 3-D projections in all viewers simultaneously (Play All) and which contains a drop-down menu for each viewer (L,M). The viewers are named as Viewer 1 (L, N) or CPHATE viewer (M, P) and followed by information of the developmental stage and the hours post hatching for the objects in the viewer. (O) Reconstruction of the AIM neurons with AVF contacts and synapses at L3 (27 hours post hatching; scale bar = 2 um. (Q) C-PHATE plot at L1 (0 hours post hatching). See also Video S3.</p></caption>
<graphic xlink:href="609993v2_figS9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS10" position="float" fig-type="figure">
<label>Supplementary Figure S10.</label>
<caption><title>Select and Add objects to viewers.</title>
<p>(A) Click “select (number) items” to select all items in the dropdown list (green box), or (A’) click the hexagon next to each item (green box). (B) Click “Add Selected” (purple box) to add all selected items or (B’) click “Add to” (purple box) to add each item individually. (C) To add the selected item(s) to an existing viewer of the same developmental stage or to a new viewer, choose a viewer as indicated. (D) Click “Deselect (number) items” (orange box) to deselect items. See also Video S3 and S4.</p></caption>
<graphic xlink:href="609993v2_figS10.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS11" position="float" fig-type="figure">
<label>Supplementary Figure S11.</label>
<caption><title>In-viewer toolbar features</title>
<p>(A) In-viewer toolbar for Neurons, Contacts and Synapses and C-PHATE (shown here, only Neurons). (B, K) Change the background color of viewer from dark (white box, moon) to white (white box, sun). (C, L) Change the color of any objects by selecting a desired color, transparency or color code and selecting the object (or instance) name (here, AIML and AIMR). (D, M) Change developmental stage for items in the viewer by using the in-viewer developmental slider. (N) Add 3-D representations of the Nerve Ring for that developmental stage. (E, O) Record and download movies for the viewer. (F,P) Download .gltf files and viewer screenshot (png). (G) Rotate objects around the y-axis. (H) Zoom in and (I) zoom out, and (J) reset objects to original positions in the viewer. See also Video S3.</p></caption>
<graphic xlink:href="609993v2_figS11.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS12" position="float" fig-type="figure">
<label>Supplementary Figure S12.</label>
<caption><title>Viewer navigation menu.</title>
<p>((A) Navigation bar contains a drop-down menu for each viewer (shown here, six viewers at varied developmental stages) and a “Play all” button for simultaneously rotating all objects in each viewer around the y-axis (Video S3). Each viewer dropdown menu contains a dropdown menu for Neurons (green box), Contacts and Synapses. (B) Viewer 6 with reconstructions of three neurons (AIML and AIMR, purple; PVQL, orange) at Larval Stage 4 (L4), 36 hours post hatching. (C) Browse and Select objects in the viewer by navigating the nested dropdown menus. (D) Manage objects in viewers with options to select, group, hide, and delete objects in each viewer. Objects can be deleted with “select” and keyboard “delete”. See also Video S3.</p></caption>
<graphic xlink:href="609993v2_figS12.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS13" position="float" fig-type="figure">
<label>Supplementary Figure S13.</label>
<caption><title>NeuroSCAN architecture.</title>
<p>(A) Source data is defined in a file tree structure that contains various assets such as .gltf files representing various entities, as well as CSVs storing relationships across entities (Data model in <xref rid="figS14" ref-type="fig">Figure S14</xref>). The directory structure outlines a vertical hierarchy starting at the developmental stages, then branching downwards through neuron, C-PHATE, contact and synapse data. A python script can be invoked to traverse the directory tree and parse the files, writing to the database accordingly. This enables verification of the ingested data and quick search times through the datasets to identify the related items. The architecture uses Geppetto backend and frontend (<xref ref-type="bibr" rid="c7">Cantarelli et al. 2018</xref>). (B) The backend uses a Postgres Database to store underlying data, a Persistent Storage Volume that houses and serves static assets, and the User Interface is a React application that filters, sorts, and searches through the Neurons to be added to an interactive canvas. (C) A variable number of Virtual Machines run the frontend and backend application code, scaling as needed to accommodate traffic. The frontend React/Javascript bundle that is delivered to the (D) client, rendering the neuron data and assets, and a NodeJS application that exposes a JSON API, serving the neuron data and assets based on user interactions.</p></caption>
<graphic xlink:href="609993v2_figS13.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS14" position="float" fig-type="figure">
<label>Supplementary Figure S14.</label>
<caption><title>NeuroSCAN data model.</title>
<p>(A) Reference scheme for B-F; Instance refers to the category (e.g., B, Neuron; C, Developmental Stage), which contains a name or identifier (id) for each object, lists of files associated with the instance (C, Developmental Stage does not have files), and metadata to further describe each instance, which is usually a string (str) or an integer (int). (B) The neuron name is the foundation for the Contacts, Synapses, and C-PHATE, which enables integration across each of these representations and across developmental stages (timepoints) with metadata from WormAtlas (wormatlas.org/MoW_built0.92/MoW.html). (C) The Developmental Stages are named by the larval stages (L1, L2, L3, L4, Adult), and the metadata captures the list of timepoints within those developmental stages (i.e., L1, 0 hours post hatching, and L1, 5 hours post hatching). (D) C-PHATE objects are named with a list of Neurons. (E) Contacts link to the Neuron names (Neuron A and Neuron B nomenclature in <xref rid="figS5" ref-type="fig">Figure S5</xref>), and metadata annotates the weight or the number of pixels of contact quantified in the source Electron Microscopy micrographs. (F) Synapses link to the Neuron names (Pre, Post, type, and section described in <xref rid="figS7" ref-type="fig">Figure S7</xref>).</p></caption>
<graphic xlink:href="609993v2_figS14.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s11" sec-type="supplementary-material">
<title>Supplementary Videos</title>
<supplementary-material id="d1e2250">
<label>Video S1.</label>
<caption>
<title>Visualization of hierarchical relationships using C-PHATE plots in NeuroSCAN.</title>
<p>The process for rendering a C-PHATE plot at the L4 stage (36 hours post hatching) with the real-time loading speed. In the viewer, 3-D visualization of a C-PHATE plot (shades of cyan), which is rotated to show the dome-shape of the plots and to orient the plot to correspond to <xref rid="fig2" ref-type="fig">Figures 2</xref> and <xref rid="fig4" ref-type="fig">4</xref>. The highlight functionality is used to show the spheres containing AIM (teal), then PVQ (teal). The spheres of the first iterations, containing AIM and PVQ, are identified, selected and colored magenta. The AVF neurons are highlighted in teal, and the first AIM and AVF containing clusters are identified, selected and colored yellow. The first clusters containing AIML, AVF and PVQL are identified and colored green. Neurons in the left yellow and magenta clusters are reconstructed with a right click on the sphere and “Add to new viewer” selection.</p>
</caption>
<media xlink:href="supplements/609993_file03.mp4"/>
</supplementary-material>
<supplementary-material id="d1e2271">
<label>Video S2.</label>
<caption>
<title>Analysis of AIM, PVQ and AVF neuronal morphologies in developmental datasets.</title>
<p>3-D visualizations of AIM (Purple), PVQ (Orange) and AVF (Green) at (Left viewer) L1 (5 hours post hatching) and (Right viewer) L3 (27 hours post hatching) in NeuroSCAN. Note that at L1, AVF has not grown into the nerve ring, therefore, only AIM and PVQ are present, but by L3, the AVF neurons have grown between the AIM and PVQ neurons.</p>
</caption>
<media xlink:href="supplements/609993_file04.mov"/>
</supplementary-material>
<supplementary-material id="d1e2285">
<label>Video S3.</label>
<caption>
<title>Navigating NeuroSCAN features that enable integration of Neurons, Contacts and Synapses across developmental datasets.</title>
<p>Upon first opening NeuroSCAN, a tutorial will launch (<xref rid="figS8" ref-type="fig">Figure S8</xref>). In the NeuroSCAN menu one can read about NeuroSCAN, access the tutorial, and navigate to the embryonic promoter database (<xref rid="figS8" ref-type="fig">Figure S8</xref>). The video shows the user searching neurons (AIM and PVQ) and adding neurons to the viewers (<xref rid="figS10" ref-type="fig">Figure S10</xref>). Side-by-side viewers with AIML, AIMR, and PVQL enable comparisons across developmental stages (L1, 0 hours post hatching and L4, 36 hours post hatching). Also shown in the video are the use of the in-viewer toolbar (<xref rid="figS11" ref-type="fig">Figure S11</xref>) and navigation menu (<xref rid="figS12" ref-type="fig">Figure S12</xref>) for object exploration.</p>
</caption>
<media xlink:href="supplements/609993_file05.mp4"/>
</supplementary-material>
<supplementary-material id="d1e2315">
<label>Video S4.</label>
<caption>
<title>Exploring Contacts and Synapses using NeuroSCAN.</title>
<p>Video of user navigating the tools of NeuroSCAN to examine synapses and contact profiles to yield results as in (<xref rid="figS7" ref-type="fig">Figures S7</xref> and S9). AIM neurons (Transparent Purple), AIM (Purple)-PVQ synaptic sites (Orange), and AIM-PVQ contact sites (Orange) at L1 (5 hours post hatching) are added into Viewer 1. AIM neurons (Transparent Purple), AIM(Purple)-PVQ synaptic sites (Orange), and AIM-PVQ contact sites (Orange), AVF (Green)-AIM synaptic sites, and AVF-AIM contact sites (Green) at L3 (27 hours post hatching) are added into Viewer 2. Contact sites and synaptic sites are compared across developmental stages by hiding AIM neurons. All contact sites for AIM are added for L1 (5 hours post hatching) into Viewer 3.</p>
</caption>
<media xlink:href="supplements/609993_file06.mp4"/>
</supplementary-material>
</sec>
<sec id="s12" sec-type="supplementary-material">
<title>Supplementary Tables</title>
<supplementary-material id="d1e2338">
<label>Supplemental Table 1</label>
<caption>
<p>Nerve ring regions, resolutions, and pixel threshold distances used to calculate adjacency matrices and to create contact sites for each dataset.</p>
</caption>
<media xlink:href="supplements/609993_file07.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2350">
<label>Supplemental Table 2</label>
<caption>
<p>Scaling factors and rotation corrections for 3-D representations of Neurons, Contacts and Synapses for each dataset.</p>
</caption>
<media xlink:href="supplements/609993_file08.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2362">
<label>Supplemental Table 3</label>
<caption>
<p>Stratum 1 (Red) Sankey diagrams of clustered neurons for each Diffusion Condensation iteration in each dataset.</p>
</caption>
<media xlink:href="supplements/609993_file09.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2374">
<label>Supplemental Table 4</label>
<caption>
<p>Stratum 2 (Purple) Sankey diagrams of clustered neurons for each Diffusion Condensation iteration in each dataset.</p>
</caption>
<media xlink:href="supplements/609993_file10.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2387">
<label>Supplemental Table 5</label>
<caption>
<p>Stratum 3 (Blue) Sankey diagrams of clustered neurons for each Diffusion Condensation iteration in each dataset.</p>
</caption>
<media xlink:href="supplements/609993_file11.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2399">
<label>Supplemental Table 6</label>
<caption>
<p>Stratum 4 (Green) Sankey diagrams of clustered neurons for each Diffusion Condensation iteration in each dataset.</p>
</caption>
<media xlink:href="supplements/609993_file12.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2411">
<label>Supplemental Table 7</label>
<caption>
<p>Sankey diagrams of AIM, PVQ and AVF containing clusters for each Diffusion Condensation iteration in each dataset.</p>
</caption>
<media xlink:href="supplements/609993_file13.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2423">
<label>Supplemental Table 8</label>
<caption>
<p>L1 (0 hours post hatching) adjacency counts and searchable counter for summed adjacencies. Type the name of a “Neuron of Interest” (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p>
</caption>
<media xlink:href="supplements/609993_file14.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2435">
<label>Supplemental Table 9</label>
<caption>
<p>L1 (5 hours post hatching) adjacency counts and searchable counter for summed adjacencies. Type the name of a “Neuron of Interest” (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p>
</caption>
<media xlink:href="supplements/609993_file15.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2447">
<label>Supplemental Table 10</label>
<caption>
<p>L2 (23 hours post hatching) adjacency counts and searchable counter for summed adjacencies. Type the name of a “Neuron of Interest” (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p>
</caption>
<media xlink:href="supplements/609993_file16.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2460">
<label>Supplemental Table 11</label>
<caption>
<p>L3 (27 hours post hatching) adjacency counts and searchable counter for summed adjacencies. Type the name of a “Neuron of Interest” (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p>
</caption>
<media xlink:href="supplements/609993_file17.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2472">
<label>Supplemental Table 12</label>
<caption>
<p>L4 (36 hours post hatching) adjacency counts and searchable counter for summed adjacencies. Type the name of a “Neuron of Interest” (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p>
</caption>
<media xlink:href="supplements/609993_file18.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e2484">
<label>Supplemental Table 13</label>
<caption>
<p>Adult (48 hours post hatching) adjacency counts and searchable counter for summed adjacencies. Type the name of a “Neuron of Interest” (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p>
</caption>
<media xlink:href="supplements/609993_file19.xlsx"/>
</supplementary-material>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Altun</surname>, <given-names>Z F</given-names></string-name>, <string-name><surname>Herndon</surname>, <given-names>L A</given-names></string-name>, <string-name><surname>Wolkow</surname>, <given-names>C A</given-names></string-name>, <string-name><surname>Crocker</surname>, <given-names>C</given-names></string-name>, <string-name><surname>Lints</surname>, <given-names>R</given-names></string-name>, <string-name><surname>Hall</surname>, <given-names>D H</given-names></string-name> (<string-name><surname>ed</surname> <given-names>s</given-names></string-name></person-group>), <source>WormAtlas</source>; <year>2002</year>. <ext-link ext-link-type="uri" xlink:href="http://www.wormatlas.org">http://www.wormatlas.org</ext-link>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>AU Duncan</surname> <given-names>LH</given-names></string-name>, <string-name><surname>AU Moyle</surname> <given-names>MW</given-names></string-name>, <string-name><surname>AU Shao</surname> <given-names>L</given-names></string-name>, <string-name><surname>AU Sengupta</surname> <given-names>T</given-names></string-name>, <string-name><surname>AU Ikegami</surname> <given-names>R</given-names></string-name>, <string-name><surname>AU Kumar</surname> <given-names>A</given-names></string-name>, <string-name><surname>AU Guo</surname> <given-names>M</given-names></string-name>, <string-name><surname>AU Christensen</surname> <given-names>R</given-names></string-name>, <string-name><surname>AU Santella</surname> <given-names>A</given-names></string-name>, <string-name><surname>AU Bao</surname> <given-names>Z</given-names></string-name>, <string-name><surname>AU Shroff</surname> <given-names>H</given-names></string-name>, <string-name><surname>AU Mohler</surname> <given-names>W</given-names></string-name>, <string-name><surname>AU Colón-Ramos</surname> <given-names>DA.</given-names></string-name></person-group> <chapter-title>Isotropic Light-Sheet Microscopy and Automated Cell Lineage Analyses to Catalogue Caenorhabditis elegans Embryogenesis with Subcellular Resolution</chapter-title>. <source>JoVE</source>. <year>2019</year> <month>Jun</month>; (<issue>148</issue>):<fpage>e59533</fpage>. <ext-link ext-link-type="uri" xlink:href="https://www.jove.com/t/59533">https://www.jove.com/t/59533</ext-link>, doi: <pub-id pub-id-type="doi">10.3791/59533</pub-id>, publisher: <publisher-name>MyJoVE Corp</publisher-name>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barabási</surname> <given-names>DL</given-names></string-name>, <string-name><surname>Bianconi</surname> <given-names>G</given-names></string-name>, <string-name><surname>Bullmore</surname> <given-names>E</given-names></string-name>, <string-name><surname>Burgess</surname> <given-names>M</given-names></string-name>, <string-name><surname>Chung</surname> <given-names>S</given-names></string-name>, <string-name><surname>Eliassi-Rad</surname> <given-names>T</given-names></string-name>, <string-name><surname>George</surname> <given-names>D</given-names></string-name>, <string-name><surname>Kovács</surname> <given-names>IA</given-names></string-name>, <string-name><surname>Makse</surname> <given-names>H</given-names></string-name>, <string-name><surname>Nichols</surname> <given-names>TE</given-names></string-name>, <string-name><surname>Papadimitriou</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O</given-names></string-name>, <string-name><surname>Stachenfeld</surname> <given-names>K</given-names></string-name>, <string-name><surname>Toroczkai</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Towlson</surname> <given-names>EK</given-names></string-name>, <string-name><surname>Zador</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Zeng</surname> <given-names>H</given-names></string-name>, <string-name><surname>Barabási</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Bernard</surname> <given-names>A</given-names></string-name>, <string-name><surname>Buzsáki</surname> <given-names>G.</given-names></string-name></person-group> <article-title>Neuroscience Needs Network Science</article-title>. <source>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</source>. <year>2023</year> <month>Aug</month>; <volume>43</volume>(<issue>34</issue>):<fpage>5989</fpage>–<lpage>5995</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1014-23.2023</pub-id>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brittin</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Cook</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Hall</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Emmons</surname> <given-names>SW</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>N.</given-names></string-name></person-group> <article-title>A multi-scale brain map derived from whole-brain volumetric reconstructions</article-title>. <source>Nature</source>. <year>2021</year> <month>Mar</month>; <volume>591</volume>(<issue>7848</issue>):<fpage>105</fpage>–<lpage>110</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41586-021-03284-x</pub-id>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Brittin</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Cook</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Hall</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Emmons</surname> <given-names>SW</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>N.</given-names></string-name></person-group> <article-title>Volumetric reconstruction of main Caenorhabditis elegans neuropil at two different time points</article-title>. <source>bioRxiv</source>. <year>2018</year>; p. <fpage>485771</fpage>. doi: <pub-id pub-id-type="doi">10.1101/485771</pub-id>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brugnone</surname> <given-names>N</given-names></string-name>, <string-name><surname>Gonopolskiy</surname> <given-names>A</given-names></string-name>, <string-name><surname>Moyle</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Kuchroo</surname> <given-names>M</given-names></string-name>, <string-name><surname>van Dijk</surname> <given-names>D</given-names></string-name>, <string-name><surname>Moon</surname> <given-names>KR</given-names></string-name>, <string-name><surname>Colon-Ramos</surname> <given-names>D</given-names></string-name>, <string-name><surname>Wolf</surname> <given-names>G</given-names></string-name>, <string-name><surname>Hirn</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Krishnaswamy</surname> <given-names>S.</given-names></string-name></person-group> <article-title>Coarse Graining of Data via Inhomogeneous Diffusion Condensation</article-title>. <source>Proc IEEE Int Conf Big Data</source>. <year>2019</year> <month>Dec</month>; 2019:<fpage>2624</fpage>–<lpage>2633</lpage>. doi: <pub-id pub-id-type="doi">10.1109/BigData47090.2019.9006013</pub-id>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cantarelli</surname> <given-names>M</given-names></string-name>, <string-name><surname>Marin</surname> <given-names>B</given-names></string-name>, <string-name><surname>Quintana</surname> <given-names>A</given-names></string-name>, <string-name><surname>Earnshaw</surname> <given-names>M</given-names></string-name>, <string-name><surname>Court</surname> <given-names>R</given-names></string-name>, <string-name><surname>Gleeson</surname> <given-names>P</given-names></string-name>, <string-name><surname>Dura-Bernal</surname> <given-names>S</given-names></string-name>, <string-name><surname>Silver</surname> <given-names>RA</given-names></string-name>, <string-name><surname>Idili</surname> <given-names>G.</given-names></string-name></person-group> <article-title>Geppetto: a reusable modular open platform for exploring neuroscience data and models</article-title>. <source>Philosophical transactions of the Royal Society of London Series B, Biological sciences</source>. <year>2018</year> <month>Sep</month>; <volume>373</volume>(<issue>1758</issue>). doi: <pub-id pub-id-type="doi">10.1098/rstb.2017.0380</pub-id>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Choi</surname> <given-names>YK</given-names></string-name>, <string-name><surname>Feng</surname> <given-names>L</given-names></string-name>, <string-name><surname>Jeong</surname> <given-names>WK</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Connecto-informatics at the mesoscale: current advances in image processing and analysis for mapping the brain connectivity</article-title>. <source>Brain Informatics</source>. <year>2024</year> <month>Jun</month>; <volume>11</volume>(<issue>1</issue>):<fpage>15</fpage>. <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11150223/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11150223/</ext-link>, doi: <pub-id pub-id-type="doi">10.1186/s40708-024-00228-9</pub-id>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname> <given-names>FS</given-names></string-name>, <string-name><surname>Fink</surname> <given-names>L.</given-names></string-name></person-group> <article-title>The Human Genome Project</article-title>. <source>Alcohol health and research world</source>. <year>1995</year>; <volume>19</volume>(<issue>3</issue>):<fpage>190</fpage>–<lpage>195</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Collinson</surname> <given-names>LM</given-names></string-name>, <string-name><surname>Bosch</surname> <given-names>C</given-names></string-name>, <string-name><surname>Bullen</surname> <given-names>A</given-names></string-name>, <string-name><surname>Burden</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Carzaniga</surname> <given-names>R</given-names></string-name>, <string-name><surname>Cheng</surname> <given-names>C</given-names></string-name>, <string-name><surname>Darrow</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Fletcher</surname> <given-names>G</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>E</given-names></string-name>, <string-name><surname>Narayan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Peddie</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Winn</surname> <given-names>M</given-names></string-name>, <string-name><surname>Wood</surname> <given-names>C</given-names></string-name>, <string-name><surname>Patwardhan</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kleywegt</surname> <given-names>GJ</given-names></string-name>, <string-name><surname>Verkade</surname> <given-names>P.</given-names></string-name></person-group> <chapter-title>Volume EM: a quiet revolution takes shape</chapter-title>. <source>Nature Methods</source>. <year>2023</year> <month>Jun</month>; <volume>20</volume>(<issue>6</issue>):<fpage>777</fpage>–<lpage>782</lpage>. <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41592-023-01861-8">https://www.nature.com/articles/s41592-023-01861-8</ext-link>, doi: <pub-id pub-id-type="doi">10.1038/s41592-023-01861-8</pub-id>, publisher: <publisher-name>Nature Publishing Group</publisher-name>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Colón-Ramos</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Margeta</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Shen</surname> <given-names>K.</given-names></string-name></person-group> <article-title>Glia promote local synaptogenesis through UNC-6 (netrin) signaling in C. elegans</article-title>.<source>Science (New York, NY)</source>. <year>2007</year> <month>Oct</month>; <volume>318</volume>(<issue>5847</issue>):<fpage>103</fpage>–<lpage>106</lpage>. doi: <pub-id pub-id-type="doi">10.1126/science.1143762</pub-id>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cook</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Jarrell</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Brittin</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Bloniarz</surname> <given-names>AE</given-names></string-name>, <string-name><surname>Yakovlev</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Nguyen</surname> <given-names>KCQ</given-names></string-name>, <string-name><surname>Tang</surname> <given-names>LTH</given-names></string-name>, <string-name><surname>Bayer</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Duerr</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Bülow</surname> <given-names>HE</given-names></string-name>, <string-name><surname>Hobert</surname> <given-names>O</given-names></string-name>, <string-name><surname>Hall</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Emmons</surname> <given-names>SW</given-names></string-name></person-group>. <article-title>Whole-animal connectomes of both Caenorhabditis elegans sexes</article-title>. <source>Nature</source>. <year>2019</year> <month>Jul</month>; <volume>571</volume>(<issue>7763</issue>):<fpage>63</fpage>–<lpage>71</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-019-1352-7</pub-id>, doi: <pub-id pub-id-type="doi">10.1038/s41586-019-1352-7</pub-id>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Dorkenwald</surname> <given-names>S</given-names></string-name>, <string-name><surname>Matsliah</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sterling</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Schlegel</surname> <given-names>P</given-names></string-name>, <string-name><given-names>Yu</given-names> <surname>Sc</surname></string-name>, <string-name><surname>McKellar</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Lin</surname> <given-names>A</given-names></string-name>, <string-name><surname>Costa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Eichler</surname> <given-names>K</given-names></string-name>, <string-name><surname>Yin</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Silversmith</surname> <given-names>W</given-names></string-name>, <string-name><surname>Schneider-Mizell</surname> <given-names>C</given-names></string-name>, <string-name><surname>Jordan</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Brittain</surname> <given-names>D</given-names></string-name>, <string-name><surname>Halageri</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kuehner</surname> <given-names>K</given-names></string-name>, <string-name><surname>Ogedengbe</surname> <given-names>O</given-names></string-name>, <string-name><surname>Morey</surname> <given-names>R</given-names></string-name>, <string-name><surname>Gager</surname> <given-names>J</given-names></string-name>, <string-name><surname>Kruk</surname> <given-names>K</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Neuronal wiring diagram of an adult brain</article-title>. <source>bioRxiv</source>. <year>2023</year> <month>Jan</month>; p. 2023.06.27.546656. <ext-link ext-link-type="uri" xlink:href="http://biorxiv.org/content/early/2023/07/11/2023.06.27.546656.abstract">http://biorxiv.org/content/early/2023/07/11/2023.06.27.546656.abstract</ext-link>, doi: <pub-id pub-id-type="doi">10.1101/2023.06.27.546656</pub-id>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Eberle</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Zeidler</surname> <given-names>D.</given-names></string-name></person-group> <chapter-title>Multi-Beam Scanning Electron Microscopy for High-Throughput Imaging in Connectomics Research</chapter-title>. <source>Frontiers in Neuroanatomy</source>. <year>2018</year> <month>Dec</month>; <volume>12</volume>. <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/journals/neuroanatomy/articles/10.3389/fnana.2018.00112/full">https://www.frontiersin.org/journals/neuroanatomy/articles/10.3389/fnana.2018.00112/full</ext-link>, doi: <pub-id pub-id-type="doi">10.3389/fnana.2018.00112</pub-id>, publisher: <publisher-name>Frontiers</publisher-name>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fenyves</surname> <given-names>BG</given-names></string-name>, <string-name><surname>Szilágyi</surname> <given-names>GS</given-names></string-name>, <string-name><surname>Vassy</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Sőti</surname> <given-names>C</given-names></string-name>, <string-name><surname>Csermely</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Synaptic polarity and sign-balance prediction using gene expression data in the Caenorhabditis elegans chemical synapse neuronal connectome network</article-title>. <source>PLOS Computational Biology</source>. <year>2020</year> <month>Dec</month>; <volume>16</volume>(<issue>12</issue>):<fpage>e1007974</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1007974</pub-id>, doi: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1007974</pub-id>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Galili</surname> <given-names>DS</given-names></string-name>, <string-name><surname>Jefferis</surname> <given-names>GS</given-names></string-name>, <string-name><surname>Costa</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Connectomics and the neural basis of behaviour</article-title>. <source>Current opinion in insect science</source>. <year>2022</year> <month>Dec</month>; <volume>54</volume>:<fpage>100968</fpage>. <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7614087/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7614087/</ext-link>, doi: <pub-id pub-id-type="doi">10.1016/j.cois.2022.100968</pub-id>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heinrich</surname> <given-names>L</given-names></string-name>, <string-name><surname>Bennett</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ackerman</surname> <given-names>D</given-names></string-name>, <string-name><surname>Park</surname> <given-names>W</given-names></string-name>, <string-name><surname>Bogovic</surname> <given-names>J</given-names></string-name>, <string-name><surname>Eckstein</surname> <given-names>N</given-names></string-name>, <string-name><surname>Petruncio</surname> <given-names>A</given-names></string-name>, <string-name><surname>Clements</surname> <given-names>J</given-names></string-name>, <string-name><surname>Pang</surname> <given-names>S</given-names></string-name>, <string-name><surname>Xu</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Funke</surname> <given-names>J</given-names></string-name>, <string-name><surname>Korff</surname> <given-names>W</given-names></string-name>, <string-name><surname>Hess</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Lippincott-Schwartz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Saalfeld</surname> <given-names>S</given-names></string-name>, <string-name><surname>Weigel</surname> <given-names>AV</given-names></string-name>, <collab>COSEM Project Team</collab></person-group>. <article-title>Whole-cell organelle segmentation in volume electron microscopy</article-title>. <source>Nature</source>. <year>2021</year> <month>Nov</month>; <volume>599</volume>(<issue>7883</issue>):<fpage>141</fpage>–<lpage>146</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41586-021-03977-3</pub-id>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Kaiser</surname> <given-names>M.</given-names></string-name></person-group> <chapter-title>Connectomes: from a sparsity of networks to large-scale databases</chapter-title>. <source>Frontiers in Neuroinformatics</source>. <year>2023</year> <month>Jun</month>; <volume>17</volume>. <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/journals/neuroinformatics/articles/10.3389/fninf.2023.1170337/full">https://www.frontiersin.org/journals/neuroinformatics/articles/10.3389/fninf.2023.1170337/full</ext-link>, doi: <pub-id pub-id-type="doi">10.3389/fninf.2023.1170337</pub-id>, publisher: <publisher-name>Frontiers</publisher-name>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kasthuri</surname> <given-names>N</given-names></string-name>, <string-name><surname>Hayworth</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Berger</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Schalek</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Conchello</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Knowles-Barley</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>D</given-names></string-name>, <string-name><surname>Vázquez-Reina</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kaynig</surname> <given-names>V</given-names></string-name>, <string-name><surname>Jones</surname> <given-names>TR</given-names></string-name>, <string-name><surname>Roberts</surname> <given-names>M</given-names></string-name>, <string-name><surname>Morgan</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Tapia</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Seung</surname> <given-names>HS</given-names></string-name>, <string-name><surname>Roncal</surname> <given-names>WG</given-names></string-name>, <string-name><surname>Vogelstein</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Burns</surname> <given-names>R</given-names></string-name>, <string-name><surname>Sussman</surname> <given-names>DL</given-names></string-name>, <string-name><surname>Priebe</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Pfister</surname> <given-names>H</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Saturated Reconstruction of a Volume of Neocortex</article-title>. <source>Cell</source>. <year>2015</year> <month>Jul</month>; <volume>162</volume>(<issue>3</issue>):<fpage>648</fpage>–<lpage>661</lpage>. <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S0092867415008247">https://www.sciencedirect.com/science/article/pii/S0092867415008247</ext-link>, doi: <pub-id pub-id-type="doi">10.1016/j.cell.2015.06.054</pub-id>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lichtman</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Pfister</surname> <given-names>H</given-names></string-name>, <string-name><surname>Shavit</surname> <given-names>N.</given-names></string-name></person-group> <chapter-title>The big data challenges of connectomics</chapter-title>. <source>Nature Neuroscience</source>. <year>2014</year> <month>Nov</month>; <volume>17</volume>(<issue>11</issue>):<fpage>1448</fpage>–<lpage>1454</lpage>. <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/nn.3837">https://www.nature.com/articles/nn.3837</ext-link>, doi: <pub-id pub-id-type="doi">10.1038/nn.3837</pub-id>, publisher: <publisher-name>Nature Publishing Group</publisher-name>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moon</surname> <given-names>KR</given-names></string-name>, <string-name><surname>van Dijk</surname> <given-names>D</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Gigante</surname> <given-names>S</given-names></string-name>, <string-name><surname>Burkhardt</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>WS</given-names></string-name>, <string-name><surname>Yim</surname> <given-names>K</given-names></string-name>, <string-name><given-names>Elzen</given-names> <surname>Avd</surname></string-name>, <string-name><surname>Hirn</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Coifman</surname> <given-names>RR</given-names></string-name>, <string-name><surname>Ivanova</surname> <given-names>NB</given-names></string-name>, <string-name><surname>Wolf</surname> <given-names>G</given-names></string-name>, <string-name><surname>Krishnaswamy</surname> <given-names>S.</given-names></string-name></person-group> <article-title>Visualizing structure and transitions in high-dimensional biological data</article-title>. <source>Nature Biotechnology</source>. <year>2019</year> <month>Dec</month>; <volume>37</volume>(<issue>12</issue>):<fpage>1482</fpage>–<lpage>1492</lpage>. <pub-id pub-id-type="doi">10.1038/s41587-019-0336-3</pub-id>, doi: <pub-id pub-id-type="doi">10.1038/s41587-019-0336-3</pub-id>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moyle</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Barnes</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Kuchroo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gonopolskiy</surname> <given-names>A</given-names></string-name>, <string-name><surname>Duncan</surname> <given-names>LH</given-names></string-name>, <string-name><surname>Sengupta</surname> <given-names>T</given-names></string-name>, <string-name><surname>Shao</surname> <given-names>L</given-names></string-name>, <string-name><surname>Guo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Santella</surname> <given-names>A</given-names></string-name>, <string-name><surname>Christensen</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kumar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Moon</surname> <given-names>KR</given-names></string-name>, <string-name><surname>Wolf</surname> <given-names>G</given-names></string-name>, <string-name><surname>Krishnaswamy</surname> <given-names>S</given-names></string-name>, <string-name><surname>Bao</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Shroff</surname> <given-names>H</given-names></string-name>, <string-name><surname>Mohler</surname> <given-names>WA</given-names></string-name>, <string-name><surname>Colón-Ramos</surname> <given-names>DA.</given-names></string-name></person-group> <article-title>Structural and developmental principles of neuropil assembly in C. elegans</article-title>. <source>Nature</source>. <year>2021</year> <month>Mar</month>; <volume>591</volume>(<issue>7848</issue>):<fpage>99</fpage>– <lpage>104</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41586-020-03169-5</pub-id>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Packer</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Zhu</surname> <given-names>Q</given-names></string-name>, <string-name><surname>Huynh</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sivaramakrishnan</surname> <given-names>P</given-names></string-name>, <string-name><surname>Preston</surname> <given-names>E</given-names></string-name>, <string-name><surname>Dueck</surname> <given-names>H</given-names></string-name>, <string-name><surname>Stefanik</surname> <given-names>D</given-names></string-name>, <string-name><surname>Tan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Trapnell</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>J</given-names></string-name>, <string-name><surname>Waterston</surname> <given-names>RH</given-names></string-name>, <string-name><surname>Murray</surname> <given-names>JI</given-names></string-name></person-group>. <chapter-title>A lineage-resolved molecular atlas of C. elegans embryogenesis at single-cell resolution</chapter-title>. <source>Science (New York, NY)</source>. <year>2019</year> <month>Sep</month>; <volume>365</volume>(<issue>6459</issue>). doi: <pub-id pub-id-type="doi">10.1126/science.aax1971</pub-id>, place: <publisher-loc>United States</publisher-loc>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Perez</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Seyedhosseini</surname> <given-names>M</given-names></string-name>, <string-name><surname>Deerinck</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Bushong</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Panda</surname> <given-names>S</given-names></string-name>, <string-name><surname>Tasdizen</surname> <given-names>T</given-names></string-name>, <string-name><surname>Ellisman</surname> <given-names>MH</given-names></string-name></person-group>. <chapter-title>A work?ow for the automatic segmentation of organelles in electron microscopy image stacks</chapter-title>. <source>Frontiers in Neuroanatomy</source>. <year>2014</year> <month>Nov</month>; <volume>8</volume>. <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/journals/neuroanatomy/articles/10.3389/fnana.2014.00126/full">https://www.frontiersin.org/journals/neuroanatomy/articles/10.3389/fnana.2014.00126/full</ext-link>, doi: <pub-id pub-id-type="doi">10.3389/fnana.2014.00126</pub-id>, publisher: <publisher-name>Frontiers</publisher-name>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Phelps</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Hildebrand</surname> <given-names>DGC</given-names></string-name>, <string-name><surname>Graham</surname> <given-names>BJ</given-names></string-name>, <string-name><surname>Kuan</surname> <given-names>AT</given-names></string-name>, <string-name><surname>Thomas</surname> <given-names>LA</given-names></string-name>, <string-name><surname>Nguyen</surname> <given-names>TM</given-names></string-name>, <string-name><surname>Buhmann</surname> <given-names>J</given-names></string-name>, <string-name><surname>Azevedo</surname> <given-names>AW</given-names></string-name>, <string-name><surname>Sustar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Agrawal</surname> <given-names>S</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Shanny</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Funke</surname> <given-names>J</given-names></string-name>, <string-name><surname>Tuthill</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>WCA</given-names></string-name></person-group>. <chapter-title>Reconstruction of motor control circuits in adult Drosophila using automated transmission electron microscopy</chapter-title>. <source>Cell</source>. <year>2021</year> <month>Feb</month>; <volume>184</volume>(<issue>3</issue>):<fpage>759</fpage>–<lpage>774</lpage>.e18. <ext-link ext-link-type="uri" xlink:href="https://www.cell.com/cell/abstract/S0092-8674(20)31683-4">https://www.cell.com/cell/abstract/S0092-8674(20)31683-4</ext-link>, doi: <pub-id pub-id-type="doi">10.1016/j.cell.2020.12.013</pub-id>, publisher: <publisher-name>Elsevier</publisher-name>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Randi</surname> <given-names>F</given-names></string-name>, <string-name><surname>Sharma</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Dvali</surname> <given-names>S</given-names></string-name>, <string-name><surname>Leifer</surname> <given-names>AM</given-names></string-name></person-group>. <article-title>Neural signal propagation atlas of Caenorhabditis elegans</article-title>. <source>Nature</source>. <year>2023</year> <month>Nov</month>; <volume>623</volume>(<issue>7986</issue>):<fpage>406</fpage>–<lpage>414</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-023-06683-4</pub-id>, doi: <pub-id pub-id-type="doi">10.1038/s41586-023-06683-4</pub-id>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rapti</surname> <given-names>G</given-names></string-name>, <string-name><surname>Li</surname> <given-names>C</given-names></string-name>, <string-name><surname>Shan</surname> <given-names>A</given-names></string-name>, <string-name><surname>Lu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Shaham</surname> <given-names>S.</given-names></string-name></person-group> <article-title>Glia initiate brain assembly through noncanonical Chimaerin-Furin axon guidance in C. elegans</article-title>. <source>Nature Neuroscience</source>. <year>2017</year> <month>Oct</month>; <volume>20</volume>(<issue>10</issue>):<fpage>1350</fpage>–<lpage>1360</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nn.4630</pub-id>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Rivlin</surname> <given-names>PK</given-names></string-name>, <string-name><surname>Januszewski</surname> <given-names>M</given-names></string-name>, <string-name><surname>Longden</surname> <given-names>KD</given-names></string-name>, <string-name><surname>Neace</surname> <given-names>E</given-names></string-name>, <string-name><surname>Scheffer</surname> <given-names>LK</given-names></string-name>, <string-name><surname>Ordish</surname> <given-names>C</given-names></string-name>, <string-name><surname>Clements</surname> <given-names>J</given-names></string-name>, <string-name><surname>Phillips</surname> <given-names>E</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>N</given-names></string-name>, <string-name><surname>Takemura</surname> <given-names>S</given-names></string-name>, <string-name><surname>Umayam</surname> <given-names>L</given-names></string-name>, <string-name><surname>Walsh</surname> <given-names>C</given-names></string-name>, <string-name><surname>Yakal</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Plaza</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Berg</surname> <given-names>S</given-names></string-name></person-group>, <article-title>Connectomic Analysis of Mitochondria in the Central Brain of Drosophila</article-title>. <source>bioRxiv</source>; <year>2024</year>. <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2024.04.21.590464v1">https://www.biorxiv.org/content/10.1101/2024.04.21.590464v1</ext-link>, doi: <pub-id pub-id-type="doi">10.1101/2024.04.21.590464</pub-id>, pages: 2024.04.21.590464 Section: New Results.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schmid</surname> <given-names>B</given-names></string-name>, <string-name><surname>Schindelin</surname> <given-names>J</given-names></string-name>, <string-name><surname>Cardona</surname> <given-names>A</given-names></string-name>, <string-name><surname>Longair</surname> <given-names>M</given-names></string-name>, <string-name><surname>Heisenberg</surname> <given-names>M.</given-names></string-name></person-group> <article-title>A high-level 3D visualization API for Java and ImageJ</article-title>. <source>BMC Bioinformatics</source>. <year>2010</year> <month>May</month>; <volume>11</volume>(<issue>1</issue>):<fpage>274</fpage>. <pub-id pub-id-type="doi">10.1186/1471-2105-11-274</pub-id>, doi: <pub-id pub-id-type="doi">10.1186/1471-2105-11-274</pub-id>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stein</surname> <given-names>L</given-names></string-name>, <string-name><surname>Sternberg</surname> <given-names>P</given-names></string-name>, <string-name><surname>Durbin</surname> <given-names>R</given-names></string-name>, <string-name><surname>Thierry-Mieg</surname> <given-names>J</given-names></string-name>, <string-name><surname>Spieth</surname> <given-names>J.</given-names></string-name></person-group> <article-title>WormBase: network access to the genome and biology of Caenorhabditis elegans</article-title>. <source>Nucleic acids research</source>. <year>2001</year> <month>Jan</month>; <volume>29</volume>(<issue>1</issue>):<fpage>82</fpage>–<lpage>86</lpage>. doi: <pub-id pub-id-type="doi">10.1093/nar/29.1.82</pub-id>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname> <given-names>H</given-names></string-name>, <string-name><surname>Hobert</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Temporal transitions in the postembryonic nervous system of the nematode Caenorhab-ditis elegans: Recent insights and open questions</article-title>. <source>Special Issue: Temporal patterning in the CNS</source>. <year>2023</year> <month>Jun</month>; <volume>142</volume>:<fpage>67</fpage>–<lpage>80</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.semcdb.2022.05.029</pub-id>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Swanson</surname> <given-names>LW</given-names></string-name>, <string-name><surname>Lichtman</surname> <given-names>JW</given-names></string-name></person-group>. <article-title>From cajal to connectome and beyond</article-title>. <source>Annual Review of Neuroscience</source>. <year>2016</year>; <volume>39</volume>:<fpage>197</fpage>–<lpage>216</lpage>. doi: <pub-id pub-id-type="doi">10.1146/annurev-neuro-071714-033954</pub-id>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Taylor</surname> <given-names>SR</given-names></string-name>, <string-name><surname>Santpere</surname> <given-names>G</given-names></string-name>, <string-name><surname>Weinreb</surname> <given-names>A</given-names></string-name>, <string-name><surname>Barrett</surname> <given-names>A</given-names></string-name>, <string-name><surname>Reilly</surname> <given-names>MB</given-names></string-name>, <string-name><surname>Xu</surname> <given-names>C</given-names></string-name>, <string-name><surname>Varol</surname> <given-names>E</given-names></string-name>, <string-name><surname>Oikonomou</surname> <given-names>P</given-names></string-name>, <string-name><surname>Glenwinkel</surname> <given-names>L</given-names></string-name>, <string-name><surname>McWhirter</surname> <given-names>R</given-names></string-name>, <string-name><surname>Poff</surname> <given-names>A</given-names></string-name>, <string-name><surname>Basavaraju</surname> <given-names>M</given-names></string-name>, <string-name><surname>Rafi</surname> <given-names>I</given-names></string-name>, <string-name><surname>Yemini</surname> <given-names>E</given-names></string-name>, <string-name><surname>Cook</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Abrams</surname> <given-names>A</given-names></string-name>, <string-name><surname>Vidal</surname> <given-names>B</given-names></string-name>, <string-name><surname>Cros</surname> <given-names>C</given-names></string-name>, <string-name><surname>Tavazoie</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sestan</surname> <given-names>N</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Molecular topography of an entire nervous system</article-title>. <source>Cell</source>. <year>2021</year> <month>Aug</month>; <volume>184</volume>(<issue>16</issue>):<fpage>4329</fpage>–<lpage>4347.e23.</lpage> doi: <pub-id pub-id-type="doi">10.1016/j.cell.2021.06.023</pub-id>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Toga</surname> <given-names>AW</given-names></string-name>, <string-name><surname>Clark</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Thompson</surname> <given-names>PM</given-names></string-name>, <string-name><surname>Shattuck</surname> <given-names>DW</given-names></string-name>, <string-name><surname>Van Horn</surname> <given-names>JD</given-names></string-name></person-group>. <article-title>Mapping the Human Connectome</article-title>. <source>Neurosurgery</source>. <year>2012</year> <month>Jul</month>; <volume>71</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>5</lpage>. <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3555558/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3555558/</ext-link>, doi: <pub-id pub-id-type="doi">10.1227/NEU.0b013e318258e9ff</pub-id>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wang</surname> <given-names>C</given-names></string-name>, <string-name><surname>Vidal</surname> <given-names>B</given-names></string-name>, <string-name><surname>Sural</surname> <given-names>S</given-names></string-name>, <string-name><surname>Loer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Aguilar</surname> <given-names>GR</given-names></string-name>, <string-name><surname>Merritt</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Toker</surname> <given-names>IA</given-names></string-name>, <string-name><surname>Vogt</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Cros</surname> <given-names>C</given-names></string-name>, <string-name><surname>Hobert</surname> <given-names>O.</given-names></string-name></person-group> <chapter-title>A neurotransmitter atlas ofC</chapter-title>. <source>elegansmales and hermaphrodites</source>.. <year>2023</year> <month>Dec</month>; <pub-id pub-id-type="doi">10.1101/2023.12.24.573258</pub-id>, doi: <pub-id pub-id-type="doi">10.1101/2023.12.24.573258</pub-id>, publisher: <publisher-name>Cold Spring Harbor Laboratory</publisher-name>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>White</surname> <given-names>JG</given-names></string-name>, <string-name><surname>Southgate</surname> <given-names>E</given-names></string-name>, <string-name><surname>Thomson</surname> <given-names>JN</given-names></string-name>, <string-name><surname>Brenner</surname> <given-names>S.</given-names></string-name></person-group> <article-title>The structure of the nervous system of the nematode Caenorhabditis elegans</article-title>. <source>Philosophical Transactions of the Royal Society of London B, Biological Sciences</source>. <year>1986</year>; <volume>314</volume>(<issue>1165</issue>):<fpage>1</fpage>–<lpage>340</lpage>. doi: doi:<pub-id pub-id-type="doi">10.1098/rstb.1986.0056</pub-id>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Witvliet</surname> <given-names>D</given-names></string-name>, <string-name><surname>Mulcahy</surname> <given-names>B</given-names></string-name>, <string-name><surname>Mitchell</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Meirovitch</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Berger</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Koh</surname> <given-names>WX</given-names></string-name>, <string-name><surname>Parvathala</surname> <given-names>R</given-names></string-name>, <string-name><surname>Holmyard</surname> <given-names>D</given-names></string-name>, <string-name><surname>Schalek</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Shavit</surname> <given-names>N</given-names></string-name>, <string-name><surname>Chisholm</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Lichtman</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Samuel</surname> <given-names>ADT</given-names></string-name>, <string-name><surname>Zhen</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Connectomes across development reveal principles of brain maturation</article-title>. <source>Nature</source>. <year>2021</year> <month>Aug</month>; <volume>596</volume>(<issue>7871</issue>):<fpage>257</fpage>–<lpage>261</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41586-021-03778-8</pub-id>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Hayworth</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Lu</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Grob</surname> <given-names>P</given-names></string-name>, <string-name><surname>Hassan</surname> <given-names>AM</given-names></string-name>, <string-name><surname>García-Cerdán</surname> <given-names>JG</given-names></string-name>, <string-name><surname>Niyogi</surname> <given-names>KK</given-names></string-name>, <string-name><surname>Nogales</surname> <given-names>E</given-names></string-name>, <string-name><surname>Weinberg</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Hess</surname> <given-names>HF</given-names></string-name></person-group>. <article-title>Enhanced FIB-SEM systems for large-volume 3D imaging</article-title>. <source>eLife</source>. <year>2017</year> <month>May</month>; <volume>6</volume>:<elocation-id>e25916</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.25916</pub-id>, doi: <pub-id pub-id-type="doi">10.7554/eLife.25916</pub-id>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Pang</surname> <given-names>S</given-names></string-name>, <string-name><surname>Shtengel</surname> <given-names>G</given-names></string-name>, <string-name><surname>Müller</surname> <given-names>A</given-names></string-name>, <string-name><surname>Ritter</surname> <given-names>AT</given-names></string-name>, <string-name><surname>Hoffman</surname> <given-names>HK</given-names></string-name>, <string-name><surname>Takemura</surname> <given-names>SY</given-names></string-name>, <string-name><surname>Lu</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Pasolli</surname> <given-names>HA</given-names></string-name>, <string-name><surname>Iyer</surname> <given-names>N</given-names></string-name>, <string-name><surname>Chung</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bennett</surname> <given-names>D</given-names></string-name>, <string-name><surname>Weigel</surname> <given-names>AV</given-names></string-name>, <string-name><surname>Freeman</surname> <given-names>M</given-names></string-name>, <string-name><surname>van Engelenburg</surname> <given-names>SB</given-names></string-name>, <string-name><surname>Walther</surname> <given-names>TC</given-names></string-name>, <string-name><surname>Farese</surname> <given-names>RV</given-names></string-name>, <string-name><surname>Lippincott-Schwartz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Mellman</surname> <given-names>I</given-names></string-name>, <string-name><surname>Solimena</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>An open-access volume electron microscopy atlas of whole cells and tissues</article-title>. <source>Nature</source>. <year>2021</year> <month>Nov</month>; <volume>599</volume>(<issue>7883</issue>):<fpage>147</fpage>–<lpage>151</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41586-021-03992-4</pub-id>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zheng</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Lauritzen</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Perlman</surname> <given-names>E</given-names></string-name>, <string-name><surname>Robinson</surname> <given-names>CG</given-names></string-name>, <string-name><surname>Nichols</surname> <given-names>M</given-names></string-name>, <string-name><surname>Milkie</surname> <given-names>D</given-names></string-name>, <string-name><surname>Torrens</surname> <given-names>O</given-names></string-name>, <string-name><surname>Price</surname> <given-names>J</given-names></string-name>, <string-name><surname>Fisher</surname> <given-names>CB</given-names></string-name>, <string-name><surname>Sharifi</surname> <given-names>N</given-names></string-name>, <string-name><surname>Calle-Schuler</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Kmecova</surname> <given-names>L</given-names></string-name>, <string-name><surname>Ali</surname> <given-names>IJ</given-names></string-name>, <string-name><surname>Karsh</surname> <given-names>B</given-names></string-name>, <string-name><surname>Trautman</surname> <given-names>ET</given-names></string-name>, <string-name><surname>Bogovic</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Hanslovsky</surname> <given-names>P</given-names></string-name>, <string-name><surname>Jefferis</surname> <given-names>GSXE</given-names></string-name>, <string-name><surname>Kazhdan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Khairy</surname> <given-names>K</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>A Complete Electron Microscopy Volume of the Brain of Adult Drosophila melanogaster</article-title>. <source>Cell</source>. <year>2018</year> <month>Jul</month>; <volume>174</volume>(<issue>3</issue>):<fpage>730</fpage>–<lpage>743.e22.</lpage> <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6063995/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6063995/</ext-link>, doi: <pub-id pub-id-type="doi">10.1016/j.cell.2018.06.019</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103977.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Kratsios</surname>
<given-names>Paschalis</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Chicago</institution>
</institution-wrap>
<city>Chicago</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>NeuroSCAN is an accessible and interactive tool for streamlined observation of neuronal morphology, membrane contact, and synaptic connectivity across developmental stages in the nematode C. elegans. This <bold>important</bold> tool relies on <bold>solid</bold> electron microscopy datasets. This resource will be of high interest to C. elegans researchers interested in nervous system wiring and circuit function.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103977.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors present NeuroSCAN, an accessible and interactive tool for visualizing and summarizing data from multiple previously annotated C. elegans connectomes. NeuroSCAN provides a useful entry point for streamlined observation of neuronal morphology, and the membrane contacts and synaptic connectivity between neurons across developmental stages and individual connectomes readily extracted from existing data.</p>
<p>Strengths:</p>
<p>Koonce et al. have generated a web-based visualization tool for exploring C. elegans neuronal morphology, contact area between neurons, and synaptic connectivity data. Here, the authors integrate volumetric segmentation of neurons and visualization of contact area patterns of individual neurons generated from Diffusion Condensation and C-PHATE embedding based on previous work from adult volumetric electron microscopy (vEM) data, extended to available vEM data for earlier developmental stages, which effectively summarizes modularity within the collated C. elegans contactomes to date. Overall, NeuroSCAN's relative ease of use for generating visualizations, its ability to quickly toggle between developmental stages, and its integration of a concise visualization of individual neurons' contact patterns strengthen its utility.</p>
<p>Weaknesses:</p>
<p>NeuroSCAN provides an accessible and convenient platform. However, many of the characteristics of NeuroSCAN overlap with that of an existing tool for visualizing connectomics data, Neuroglancer, which is a widely-used and shared platform with data from other organisms. The authors do not make clear their motivation for generating this new tool rather than building on a system that has already collated previous connectomics data. Although the field will benefit from any tool that collates connectomics data and makes it more accessible and user-friendly, such a tool is only useful if it is kept up-to-date, and if data formatting for submitting electron microscopy data to be added to the tool is made clear. It is unclear from this manuscript whether NeuroSCAN will be updated with recently published and future C. elegans connectomes, or how additional datasets can be submitted to be added in the future.</p>
<p>The interface for visualizing contacts and synapses would be improved with better user access to the quantitative underlying data. When contact areas or synapses are added to the viewer, adding statistics on the magnitude of the contact area, the number of synapses, and the rank of these values among the neuron's top connections, would make the viewer more useful for hypothesis generation. Furthermore, synapses are currently listed individually, with names that are not very legible to the web user. Grouping them by pre- and postsynaptic neurons and linking these groups across developmental stages would also be an improvement.</p>
<p>While the DC/C-PHATE visualizations are a useful tool for the user, it is difficult to understand when grouping or splitting of cell contact patterns is biologically significant. DC is a deterministic algorithm applied to a contactome from a single organism, and the authors do not provide quantitative metrics of distances between individual neurons or a number of DC iterations on the C-PHATE plot, nor is the selection process for the threshold for DC described in this manuscript. In the application of DC/C-PHATE to larval stage nerve ring strata organization shown by the authors, qualitative observations of C-PHATE plots colored based on adult data seem to be the only evidence shown for persistent strata during development (Figure 3) or changing architectural motifs across stages (Figure 4). Quantitation of differences in neuron position within the DC hierarchy, or differences in modularity across stages, is needed to support these conclusions. Furthermore, illustrating the quantitative differences in C-PHATE plots used to make these conclusions will provide a more instructive guide for users of NeuroSCAN in generating future hypotheses.</p>
<p>While the case studies presented by the authors help to highlight the utility of the different visualizations offered by the NeuroSCAN platform, the authors need to be more careful with the claims they make from these correlative observations. For example, in Figure 4, the authors use C-PHATE clustering patterns to make conclusions about changes in clustering patterns of individual neurons across development based on single animal datasets. In this and many other cases presented in this study with the limited existing datasets, it is difficult to differentiate between developmental changes and individual variability between the neurite positions, contacts, and synapse differences within these data. This caveat needs to be clearly addressed.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103977.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The past five years have seen the publication of both new (Witvliet et al., 2021) and newly analyzed (Cook et al., 2019; Moyle et al., 2021; Brittin et al., 2021) data for the C. elegans connectome. The increase in data availability for a single species allows researchers to examine variability due to both stochastic events and changes over development. The quantity of these data is huge. To help the community make these data more accessible, the authors present a new online tool that allows the examination of 3D models for C. elegans neurons in the central neuropil across development. In addition to visualizing the overall structure of the neuronal processes and locations of synapses, the NeuroSCAN tool also allows users to probe into the C-PHATE visualization results, which this group previously pioneered to describe similarities in neuron adjacency (Moyle et al., 2021).</p>
<p>Strengths:</p>
<p>The ability to visualize the data from both a connectomics and contactomics perspective across developmental time has significant power. The original C. elegans connectome (White et al., 1986) presented their circuits as line drawings with chemical and electrical synapses indicated through arrows and bars. While these line drawings remain incredibly useful, they were also necessary simplifications for a 2D publication and they lack details of the complex architecture seen within each EM image. Koonce et al take advantage of segmented image data of each neuronal process within the nerve ring to create a web interface where users can visualize 3D models for their neuron of choice. The C-PHATE visualization allows users to explore similarities among different neurons in terms of adjacency and then go directly to the 3D model for these neurons. The 3D models it generates are beautiful and will likely be showing up in many future presentations and publications. The tool doesn't require any additional downloading and is open source.</p>
<p>Weaknesses:</p>
<p>While it's impossible to create one tool that will satisfy all potential users, I found myself wanting to have numbers associated with the data. For example, knowing the number of connections or the total surface area of contacts between individual neurons wasn't possible through the viewer, which limits the utility of taking deep analytical dives. While connectivity data are readily accessible through other interfaces such as Nemanode and WormWiring, a more thorough integration may be helpful to some users.</p>
<p>There were several issues with the user interface that made it a bit clunky to use. For example, as I added additional neurons to the filter search box, the loading time got longer and longer. I ran an experiment uploading all of the amphid neurons, one pair at a time. Each additional neuron pair added an additional 5-10 seconds to the loading. By the time I got to the last pair, it took over a minute to load. Issues like these, some of which may be unavoidable given the size of the data, could be conveyed through better documentation. I did not find the tutorial very helpful and the supplementary movies lacked any voiceover, so it wasn't always clear what they were trying to show.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103977.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work provides graphical tools for reconstructing the detailed anatomy of a nervous system from a series of sections imaged by electron microscopy. Contact between neuronal processes can direct outgrowth and is necessary for connectivity and, thus function. A bioinformatic approach is used to group neurons according to shared features (e.g., contact, synapses) in a hierarchy of &quot;relatedness&quot; that can be interrogated at each step. In this work, Koonze et al analyze vEM data sets for the C. elegans nerve ring (NR), a dense fascicle of processes from181 neurons. In a bioinformatic approach, the clustering algorithm Diffusion Condensation (DC) groups neurons according to similar cell biological features in iterations that remove chunks of differences in feature data with each step ultimately merging all NR neurons in one cluster. DC results are displayed with C-Phate a 3D visualization tool to produce a trajectory that can be interrogated for cell identities and other features at each iterative step. In previous work by these authors, this approach was utilized to identify subgroups of neuronal processes or &quot;strata&quot; in the NR that can be grouped by physical contact and connectivity. Here they expand their analysis to include a series of available vEM data sets across C. elegans larval development. This approach suggests that strata initially established during embryonic development are largely preserved in the adult. Importantly, exceptions involving stage-specific reorganization of neuronal placement in specific strata were also detected. A case study featured in the paper demonstrates the utility of this approach for visualizing the integration of newly generated neurons into the existing NR anatomy. Visualization tools used in this work are publicly available at NeuroSCAN.</p>
<p>Strengths:</p>
<p>A web-based app, NeuroSCAN, that individual researchers can use to interrogate the structure and organization of the C. elegans nerve ring across development</p>
<p>Weaknesses:</p>
<p>In the opinion of this reviewer, only minor revisions are required.</p>
</body>
</sub-article>
</article>