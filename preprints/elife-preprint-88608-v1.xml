<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">88608</article-id>
<article-id pub-id-type="doi">10.7554/eLife.88608</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.88608.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Differentiation and Integration of Competing Memories: A Neural Network Model</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ritvo</surname>
<given-names>Victoria J. H.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref></contrib>
<contrib contrib-type="author">
<name>
<surname>Nguyen</surname>
<given-names>Alex</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Turk-Browne</surname>
<given-names>Nicholas B.</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5887-9682</contrib-id>
<name>
<surname>Norman</surname>
<given-names>Kenneth A.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Psychology, Princeton University;</institution></aff>
<aff id="a2"><label>2</label><institution>Princeton Neuroscience Institute, Princeton University;</institution></aff>
<aff id="a3"><label>3</label><institution>Department of Psychology, Yale University;</institution></aff>
<aff id="a4"><label>4</label><institution>Wu Tsai Institute, Yale University</institution></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Schlichting</surname>
<given-names>Margaret L</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country>Canada</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label><bold>For correspondence:</bold> <email>knorman@princeton.edu</email> (KAN)</corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-06-14">
<day>14</day>
<month>06</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP88608</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-04-18">
<day>18</day>
<month>04</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-04-13">
<day>13</day>
<month>04</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.04.02.535239"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Ritvo et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Ritvo et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-88608-v1.pdf"/>
<abstract>
<title>Abstract</title><p>What determines when neural representations of memories move together (integrate) or apart (differentiate)? Classic supervised learning models posit that, when two stimuli predict similar outcomes, their representations should integrate. However, these models have recently been challenged by studies showing that pairing two stimuli with a shared associate can sometimes cause differentiation, depending on the parameters of the study and the brain region being examined. Here, we provide a purely unsupervised neural network model that can explain these and other related findings. The model can exhibit integration or differentiation depending on the amount of activity allowed to spread to competitors — inactive memories are not modified, connections to moderately active competitors are weakened (leading to differentiation), and connections to highly active competitors are strengthened (leading to integration). The model also makes several novel predictions — most importantly, that differentiation will be rapid and asymmetric. Overall, these modeling results provide a computational explanation for a diverse set of seemingly contradictory empirical findings in the memory literature, as well as new insights into the dynamics at play during learning.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Updated references</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>As we learn, our neural representations change: The representations of some memories move to-gether (i.e., they integrate), allowing us to generalize, whereas the representations of other memories move apart (i.e., they differentiate), allowing us to discriminate. In this way, our memory system plays a delicate balancing act to create the complicated and vast array of knowledge we hold. But ultimately, learning itself is a very simple process: strengthening or weakening individual neural connections. How can a simple learning rule on the level of individual neural connections account for both differentiation and integration of entire memories, and what factors lead to both outcomes?</p>
<p>Classic supervised learning models (<bold><italic><xref ref-type="bibr" rid="c39">Rumelhart et al., 1985</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c18">Gluck and Myers, 1993</xref></italic></bold>) provide one potential solution. These theories posit that the brain adjusts representations to predict outcomes in the world: When two stimuli predict similar outcomes, their representations become more similar; when they predict different outcomes, their representations become more distinct. Numerous fMRI studies have obtained evidence supporting these theories, by utilizing representational similarity analysis to track how the patterns evoked by similar stimuli change over time (e.g., <bold><italic><xref ref-type="bibr" rid="c40">Schapiro et al., 2013</xref></italic></bold>, <bold><italic>2016</italic></bold>; <bold><italic><xref ref-type="bibr" rid="c47">Tompary and Davachi, 2017</xref></italic></bold>).</p>
<p>However, other studies have found that linking stimuli to shared associates can lead to differentiation rather than integration. For instance, in one fMRI study, differentiation was observed in the hippocampus when participants were tasked with predicting the same face in response to two similar scenes (i.e. two barns), so much so that the two scenes became less neurally similar to each other than they were to unrelated stimuli (<bold><italic><xref ref-type="bibr" rid="c16">Favila et al., 2016</xref></italic></bold>; for related findings, see <bold><italic><xref ref-type="bibr" rid="c44">Schlichting et al., 2015</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c29">Molitor et al., 2021</xref></italic></bold>; for reviews, see <bold><italic><xref ref-type="bibr" rid="c7">Brunec et al., 2020</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c15">Duncan and Schlichting, 2018</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c38">Ritvo et al., 2019</xref></italic></bold>).</p>
<p>Findings of this sort present a challenge to supervised learning models, which predict that the connection weights underlying these memories should be adjusted to make them more (not less) similar to each other. This kind of “similarity reversal”, whereby stimuli with higher levels of featural similarity are assigned <italic>less</italic> similar hippocampal representations, has now been observed in a wide range of studies (e.g., <bold><italic>Favila et al., 2016</italic></bold>; <bold><italic>Schlichting et al., 2015</italic></bold>; <bold><italic>Molitor et al., 2021</italic></bold>; <bold><italic><xref ref-type="bibr" rid="c8">Chanales et al., 2017</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c13">Dimsdale-Zucker et al., 2018</xref></italic></bold>; <bold><italic>Ballard et al., 2019</italic></bold>; <bold><italic><xref ref-type="bibr" rid="c49">Wanjia et al., 2021</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c52">Zeithamova et al., 2018</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c22">Jiang et al., 2020</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c17">Fernandez et al., 2023</xref></italic></bold>).</p>
<sec id="s1a">
<title>Nonmonotonic Plasticity Hypothesis</title>
<p>How can we make sense of these findings? Supervised learning algorithms cannot explain the aforementioned results on their own, so they need to be supplemented by other learning principles. We previously argued (<bold><italic>Ritvo et al., 2019</italic></bold>) that learning algorithms positing a U-shaped relation-ship between neural activity and synaptic weight change — where low levels of activity at retrieval lead to no change, moderate levels of activity lead to synaptic weakening, and high levels of activity lead to synaptic strengthening — may be able to account for these results; the Bienenstock-Cooper-Munro (BCM) learning rule (<bold><italic><xref ref-type="bibr" rid="c6">Bienenstock et al., 1982</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c10">Cooper, 2004</xref></italic></bold>) is the most well-known learning algorithm with this property, but other algorithms with this property have also been proposed (<bold><italic>Nor-man et al., 2006</italic></bold>; <bold><italic><xref ref-type="bibr" rid="c12">Diederich and Opper, 1987</xref></italic></bold>). We refer to the U-shaped learning function posited by this type of algorithm as the nonmonotonic plasticity hypothesis (NMPH) (<bold><italic><xref ref-type="bibr" rid="c11">Detre et al., 2013</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c30">Newman and Norman, 2010</xref></italic></bold>).</p>
<p>In addition to explaining how individual memories get stronger and weaker, the NMPH also explains how memory representations change with respect to each other as a function of competition during retrieval (<bold><italic><xref ref-type="bibr" rid="c21">Hulbert and Norman, 2015</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c31">Norman et al., 2006</xref></italic></bold>). If the activity of a competing memory is low while retrieving a target memory (<bold><italic><xref rid="fig1" ref-type="fig">Figure 1</xref></italic></bold>C), the NMPH predicts no representational change. If competitor activity is moderate (<bold><italic><xref rid="fig1" ref-type="fig">Figure 1</xref></italic></bold>B), the connections to the shared units will be weakened, leading to differentiation. If competitor activity is high (<bold><italic><xref rid="fig1" ref-type="fig">Figure 1</xref></italic></bold>A), the connections to the shared units will be strengthened, leading to integration. Consequently, the NMPH may provide a unified explanation for the divergent studies discussed above: Depending on the amount of excitation allowed to spread to the competitor (which may be affected by task demands, neural inhibition levels, and the similarity of stimuli, among other things), learning may result in no change, differentiation, or integration.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Nonmonotonic Plasticity Hypothesis: This figure is taken from <xref ref-type="bibr" rid="c38">Ritvo et al. (2019)</xref>. A has been linked to X, and B has some initial hidden-layer overlap with A. In this network, activity is allowed to spread bidirectionally. When B is presented along with X (corresponding to a BX study trial), activity can spread downward from X to the hidden-layer units associated with A, and also — from there — to the input-layer representation of A. (A) If activity spreads strongly to the input and hidden representations of A, integration of A and B occurs due to strengthening of connections between all of the strongly activated features (green connections indicate strengthened weights; AB integration can be seen by noting the increase in the number of hidden units receiving projections from both A and B). (B) If activity spreads only moderately to the input and hidden representations of A, differentiation of A and B occurs due to weakening of connections between the moderately activated features of A and the strongly activated features of B (green and red connections indicate weights that are strengthened and weakened, respectively; AB differentiation can be seen by noting the decrease in the number of hidden units receiving strong connections from both A and B — in particular, the middle hidden unit no longer receives a strong connection from A). (C) If activity does not spread to the features of A, then neither integration nor differentiation occurs.</p></caption>
<graphic xlink:href="535239v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s1b">
<title>Research Goal</title>
<p>In this paper, we present a neural network model that instantiates the aforementioned NMPH learning principles, with the goal of assessing how well these principles can account for extant data on when differentiation and integration occur. In <bold><italic>Ritvo et al.</italic></bold> (<bold><italic>2019</italic></bold>), we provided a sketch of how certain findings could potentially be explained in terms of the NMPH. However, intuitions about how a complex system should behave are not always accurate in practice, and verbally stated theories can contain ambiguities or internal contradictions that are only exposed when building a working model. Building a model also allows us to generate more detailed predictions (i.e., we can use the model to see what follows from a core set of principles). Relatedly, there are likely boundary conditions on how a model behaves (i.e., it will show a pattern of results in some conditions but not others). Here, we use the model to characterize these boundary conditions, which (in turn) can be translated into new, testable predictions.</p>
<p>We use the model to simulate three experiments: 1) <bold><italic><xref ref-type="bibr" rid="c9">Chanales et al.</xref></italic></bold> (<bold><italic>2021</italic></bold>), which looked at how the amount of stimulus similarity affected the distortion of color memories; 2) <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>), which looked at representational change for items that were paired with the same or different associates; and 3) <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>), which looked at how the learning curriculum (whether pairs were presented in a blocked or interleaved fashion) modulated representational change in different brain regions. We chose these three experiments because each reported that similar stimuli (neurally) differentiate or (behaviorally) are remembered as being less similar than they actually are, and because they allow us to explore three different ways in which the amount of competitor activity can be modulated.</p>
<p>The model can account for the results of these studies, and it provides several novel insights. Most importantly, the model shows that differentiation must happen quickly (or it will not happen at all), and that representational change effects are often asymmetric (i.e., one item’s representation changes but the other stays the same).</p>
<p>The following section provides an overview of general properties of the model. Later sections describe how we implemented the model separately for the three studies.</p>
</sec>
<sec id="s1c">
<title>Basic Network Properties</title>
<p>Our goal was to build the simplest possible model that would allow us to explore the role of the NMPH in driving representational change. The model was constructed such that it <italic>only</italic> used unsupervised, U-shaped learning and not supervised learning. Importantly, we do not think that unsupervised, U-shaped learning function is a replacement for error-driven learning; instead, we view it as a supplementary tool the brain uses to reduce interference of competitors (<bold><italic>Ritvo et al., 2019</italic></bold>). Nonetheless, we intentionally omitted supervised learning in order to explore whether unsupervised, U-shaped on its own would be sufficient to account for extant findings on differentiation and integration.</p>
<p>Because we were specifically interested in the way competition affects learning, we decided to focus on the key moment <italic>after</italic> the memories have been formed, when they first come into competition with each other. Consequently, we pre-wired the initial connections into the network for each stimulus, rather than the allowing the connections to self-organize through learning (see <italic>Methods</italic> for details). Doing so meant we could have control over the exact level of competition between pairmates. We then used the model to simulate different studies, with the goal of assessing how different manipulations that affect competitor activity modulate representational change. In the interest of keeping the simulations simple, we modeled a single task from each study rather than modeling all of them comprehensively.</p>
</sec>
<sec id="s1d">
<title>Model Architecture</title>
<p>The model was built using the Emergent simulation framework (<bold><italic>Aisa et al., 2008</italic></bold>). All versions of the model have the same basic architecture (<bold><italic><xref rid="fig2" ref-type="fig">Figure 2</xref></italic></bold>; see the following sections for how the model was adapted for each version, and the <italic>Methods</italic> section for the details of all parameters).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Basic network architecture: The characteristics of the model common to all versions we tested, with hidden-and input-layer activity for pairmate A. Black arrows indicate projections common to all versions of the model. All projections were fully connected. Pre-wired, stronger connections between the input A unit (top row of item layer) and hidden A units (purple) are shown, and pre-wired, stronger connections between the input B unit (bottom row of item layer) and hidden B units (pink) are shown. The category unit is pre-wired to connect strongly to all hidden A and B units. Hidden A units have strong connections to other hidden A units (not shown); the same is true for hidden B units. Pre-wired, stronger connections also exist between hidden and output layers (not shown). The arrangement of these hidden-to-output connections varies for each version of the model.</p></caption>
<graphic xlink:href="535239v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We wanted to include the minimal set of layers needed to account for the data. Importantly, the model is meant to be as generic as possible, so none of the layers are meant to correspond to a particular brain region (we discuss possible anatomical correspondences in the <italic>Discussion</italic> section). With those points in mind, we built the model to include four layers: category, item, hidden, and output. The category and item layers are input layers that represent the sensory or semantic features of the presented stimuli; generally speaking, we use the category layer to represent features that are shared across multiple stimuli, and we use the item layer to represent features that are unique to particular stimuli. The hidden layer contains the model’s internal representation of these stimuli, and the output layer represents either additional sensory features of the input stimulus, or else other stimuli that are associated with the input stimulus. In all models, the category and item layers are bidirectionally connected to the hidden layer; the hidden layer is bidirectionally connected to the output layer; and the hidden layer also has recurrent connections back to itself. All of these connections are modifiable through learning. Note that the hidden layer has modifiable connections to all layers in the network (including itself), which makes it ideally positioned to bind together the features of individual stimuli.</p>
<p>Each version of the model learns two pairmates, which are stimuli (binary vectors) represented by units in the input layers. The presentation of a stimulus involves activating a single unit in each of the input layers (i.e., the category and item layers). Pairmates share the same unit in the category layer, but differ in their item-layer unit.</p>
<p>We labeled the item-layer units such that the unit in the top row was associated with pairmate A and the unit in the bottom row was associated with pairmate B. Since either pairmate could be shown first, we refer to them as pairmate 1 or 2 when the order is relevant: Pairmate 1 is whichever pairmate is shown on the first trial and pairmate 2 is the item shown second.</p>
<p>All projections as described above have weak, randomly-sampled weight values, but we additionally pre-built some structured knowledge into the network. The item-layer input units have pre-wired, stronger connections to a selection of six pre-assigned “pairmate A” hidden units and six pre-assigned “pairmate B” units. The A and B hidden representations overlap to some degree (for instance, with two units shared, as shown in <bold><italic><xref rid="fig2" ref-type="fig">Figure 2</xref></italic></bold>). We decided to arrange the hidden layer along a single dimension so that the amount of overlap could be easily visualized and interpreted.</p>
<p>Hidden units representing each individual item start out strongly interconnected (that is, the six pairmate A units are linked together by maximally strong recurrent connections, as are the six pairmate B units). We also pre-wired some stronger connections between these hidden A and B units and the output units, but the setup of the hidden-to-output pre-wired connections depends on the modeled experiment.</p>
</sec>
<sec id="s1e">
<title>Inhibitory Dynamics</title>
<p>Within a layer, inhibitory competition between units was enforced through an adapted version of the k-winners-take-all (kWTA) algorithm (<bold><italic><xref ref-type="bibr" rid="c34">O’Reilly and Munakata, 2000</xref></italic></bold>) (see <italic>Methods</italic>) which limits the amount of activity in a layer to at most <italic>k</italic> units. The kWTA algorithm provides a useful way of capturing the “set-point” quality of inhibitory neurons without requiring the inclusion of these neurons directly.</p>
<p>The main method we use to allow activity to spread to the competitor is through inhibitory oscillations. Prior work has argued that inhibitory oscillations could play a key role in this kind of competition-dependent learning (<bold><italic><xref ref-type="bibr" rid="c32">Norman et al., 2006</xref></italic></bold>, <bold><italic>2007</italic></bold>; <bold><italic><xref ref-type="bibr" rid="c45">Singh et al., 2022</xref></italic></bold>). Depending on how much excitation a competing memory is receiving, lowering the level of inhibition can allow competing memories that are inactive at baseline levels of inhibition to become moderately active (causing their connections to the target memory to be weakened) or even strongly active (causing their connections to the target memory to be strengthened). Our model implements oscillations through a sinusoidal function which lowers and raises inhibition over the course of the trial, allowing competitors to “pop up” when inhibition is lower.</p>
</sec>
<sec id="s1f">
<title>Learning</title>
<p>For each projection where learning occurs (bidirectionally between the input and hidden layers, the hidden layer to itself, and the hidden to output layer), we specified the parameters for a U-shaped learning function to allow weakening or strengthening. Once the U-shaped learning function for each projection in each version of the model was specified, we did not change it for any of the various conditions. Details of this function can be found in the <italic>Methods</italic> section.</p>
</sec>
<sec id="s1g">
<title>Competition</title>
<p>Constructing the network in this way allows us to precisely control the amount of competition between pairmates. There are several ways beside amplitude of oscillations to alter the amount of excitation spreading to the competitor. For instance, competitor activity could be modulated by altering the pre-wired weights to force the hidden-layer representations for A and B to share more units. Each version of the model (for each experiment) relies on a different method to modulate the amount of competitor activity.</p>
</sec>
</sec>
<sec id="s2">
<title>Model of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>): Repulsion and Attraction of Color Memories</title>
<sec id="s2a">
<title>Key Experimental Findings</title>
<p>The first experiment we modeled was <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>). The study was inspired by recent neuroimaging studies showing “similarity reversals”, wherein boosting stimulus similarity led to reduced neural similarity in the hippocampus (<bold><italic>Favila et al., 2016</italic></bold>; <bold><italic>Schlichting et al., 2015</italic></bold>; <bold><italic>Molitor et al., 2021</italic></bold>; <bold><italic>Chanales et al., 2017</italic></bold>; <bold><italic>Dimsdale-Zucker et al., 2018</italic></bold>; <bold><italic>Ballard et al., 2019</italic></bold>; <bold><italic>Wanjia et al., 2021</italic></bold>; <bold><italic>Zeithamova et al., 2018</italic></bold>; <bold><italic>Jiang et al., 2020</italic></bold>). <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) tested whether a similar “repulsion” effect is observed with respect to how the specific features of competing events are retrieved. In their experiments, participants learned associations between objects and faces (<bold><italic>Figure 3</italic></bold>A). Specifically, participants studied pairs of objects that were identical except for their color value; each of these object “pairmates” was associated with a unique face. Participants’ memory was tested in several ways; in one of these tests — the color recall task — the face was shown as a cue alongside the colorless object, and participants were instructed to report the color of the object on a continuous color wheel.</p>
<p><bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) found that, for low levels of pairmate color similarity (i.e., 72° and 48° color difference), participants were able to recall the colors accurately when cued with a face and an object. However, when color similarity was increased (i.e., 24° color difference), the color reports were biased <italic>away</italic> from the pairmate, leading to a “repulsion” effect. For instance, if the pairmates consisted of a red jacket and a red-but-slightly-orange jacket, repulsion would mean that the slightly-orange jacket would be recalled as less red and more yellow than it actually was. When the color similarity was increased even further (i.e., 6° color difference), the repulsion effects were eliminated (<bold><italic><xref rid="fig3" ref-type="fig">Figure 3</xref></italic></bold>B). For a related result showing repulsion with continuously varying face features (gender, age) instead of color, see <bold><italic><xref ref-type="bibr" rid="c14">Drascher and Kuhl</xref></italic></bold> (<bold><italic>2022</italic></bold>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Modeling <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>): (A) Participants in <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) learned to associate objects and faces (faces not shown here due to bioRxiv rules). The objects consisted of pairs that were identical except for their color value, and the difference between pairmate color values was systematically manipulated to adjust competition. Color memory was tested in a task where the face and colorless object were given as a cue, and participants had to use a continuous color wheel to report the color of the object. Color reports could be biased toward (+) or away from the competitor (-). (B) When color similarity was low (48°), color reports were accurate. When color similarity was raised to a moderate level (24°), repulsionoccurred, such that color reports were biased systematically away from the competitor. When color similarity was raised further (6°), the repulsion effect was eliminated. (C) To model this study, we used the network structure described in <italic>Basic Network Properties</italic>, with the following modifications: This model additionally has a non-modifiable recurrent projection in the output layer, to represent the continuous nature of the color space: Each output unit was pre-wired with fixed, maximally strong weights connecting it to the seven units on either side of it (one such set of connections is shown to the output unit colored in green); background output-to-output connections (outside of these seven neighboring units) were set up to be fixed, weak, and random. The hidden layer additionally was initialized to have maximally strong (but learnable) one-to-one connections with units in the output layer, thereby ensuring that the color “topography” of the output layer was reflected in the hidden layer. Each of the six hidden A units were connected in an all-to-all fashion to the six pre-assigned A units in the output layer via maximally strong, pre-wired weights (purple lines). The same arrangement was made for the hidden B units (pink lines). Other connections between the output and hidden layers were initialized to lower values. In the figure, activity is shown after pairmate A is presented — the recurrent output-to-output connections let activity spread to units on either side. (D) We included six conditions in this model, corresponding to different numbers of shared units in the hidden and output layers. Three conditions are shown here. The conditions are labeled by the number of hidden/output units shared by A and B. Thus, one unit is shared by A and B in 1/6, two units are shared by A and B in 2/6, and so on. Increased overlap in the hidden and output layers is meant to reflect higher levels of color similarity in the experiment. We included overlap types from 0/6 to 5/6.</p></caption>
<graphic xlink:href="535239v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2b">
<title>Potential NMPH Explanation</title>
<p>Typical error-driven learning would not predict this outcome, because it would adjust weights to align the guess more closely with the true outcome, leading to no repulsion effects. In contrast, the NMPH potentially explains the results of this study well; as the authors note, “the relationship between similarity and the repulsion effect followed an inverted-U-shape function, suggesting a sweet spot at which repulsion occurs” (<bold><italic>Chanales et al., 2021</italic></bold>).</p>
<p>The amount of color similarity provides a way of modulating the amount of excitation that can flow to the competitor’s neural representation. When color similarity is lower (i.e., 72° and 48°), the competing pairmate is less likely to come to mind. Consequently, the competitor’s activity will be on the low/left side of the U-shaped function (<bold><italic><xref rid="fig1" ref-type="fig">Figure 1</xref></italic></bold>C). No weakening or strengthening will occur for the competitor, and both pairmate representations remain intact.</p>
<p>However, when color similarity is higher (i.e., 24°), the additional color overlap means the memories compete more. When the red jacket is shown, the competing red-but-slightly-orange jacket may come to mind moderately, so it falls in the dip of the U-shaped function. If this occurs, the NMPH predicts that the two pairmates will show differentiation, resulting in repulsion in color space.</p>
<p>When color overlap is highest (i.e., 6°), the repulsion effect was eliminated. The NMPH could explain this result in terms of the competitor getting so much excitation from the high similarity that it falls on the high/right side of the U-shaped function, in the direction of integration (or “attraction” for the behavioral reports of color). <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) did not observe an attraction effect, but this can be explained in terms of the similarity of the pairmates in this condition (at 6° of color separation, there is a limit on how much more similar the color reports could become, given the precision of manual responses).</p>
</sec>
</sec>
<sec id="s3">
<title>Model Set-up</title>
<sec id="s3a">
<title>Model Architecture</title>
<p>To model this task (<bold><italic><xref rid="fig3" ref-type="fig">Figure 3</xref></italic></bold>C), we used the two input layers (i.e., category and item) to represent the colorless object and face associates, respectively. To represent a particular stimulus, we activated a single unit in each of the input layers; pairmates share the same unit in the object layer (i.e., “jacket”), but differ in the unit for the face layer (i.e., “face-for-jacket-A” and “face-for-jacket B”). The output layer represents the color-selective units. Units that are closer to each other can be thought of as representing colors that are more similar to each other.</p>
</sec>
<sec id="s3b">
<title>Knowledge Built into the Network</title>
<p>As described in <italic>Basic Network Properties</italic>, each of the two input face units is pre-wired to connect strongly to the six corresponding hidden units (either the six hidden A units, or the six hidden B units). In this version of our model, we added several extra pre-wired connections, specifically, recurrent output-to-output connections (although we did not include learning for this projection). Neighboring units were pre-wired to have stronger connections, to instantiate the idea that color is represented in a continuous way in the brain (<bold><italic><xref ref-type="bibr" rid="c20">Hanazawa et al., 2000</xref></italic></bold>; <bold><italic>Komatsu et al., 1992</italic></bold>).</p>
<p>The six hidden A units were connected to the corresponding six units in the output layer in an all-to-all fashion via maximally strong weights (such that each A hidden unit was connected to each A output unit); an analogous arrangement was made for the units representing pairmate B. Additionally, each non-pairmate unit in the hidden layer was pre-wired to have a maximally strong connection with the unit directly above it in the output layer. Arranging the units in this way (so the hidden layer matches the “topography” of the output layer) makes it easier to interpret the types of distortion that occur in the hidden layer.</p>
</sec>
<sec id="s3c">
<title>Manipulation of Competitor Activity</title>
<p>In this experiment, competition is manipulated through the level of color similarity in each condition. We operationalized this by adjusting the level of overlap between the hidden (and output) color A and B units. One advantage of modeling is that, because there is no constraint on experiment length, we were able to sample a wider range of overlap types than the actual study, which was limited to three conditions per experiment. Instead, we used six overlap conditions in the model. For all conditions, the two pairmates were each assigned six units in the hidden layer. However, for the different overlap conditions, we pre-wired the weights from the input layers to the hidden layer so that the two pairmates differed in the number of hidden-layer units that were shared (note that this overlap manipulation was also reflected in the output layer, because of the pre-wired connections between the hidden and output layers described above).</p>
<p>We labeled the six conditions based on the number of overlapping units between the pairmates (which varied) and the number of total units per pairmate (which was always six): 0/6 overlap means that the two pairmates are side-by-side but share zero units; 1/6 overlap means they share one unit out of six each; 2/6 overlap means they share two units out of six each, and so on.</p>
</sec>
<sec id="s3d">
<title>Task</title>
<p>The task simulated in the model is a simplified version of the paradigm used in <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>). Specifically, we focused on the color recall task, where the colorless object was shown alongside the face cue, and the participant had to report the object’s color on a color wheel. To model this, the external input is clamped to the network (object and face units), and activity is allowed to flow through the hidden layer to the color layer so the network can make a color “guess”. We ran a test epoch after each training epoch so we could track the representations of pairmates A and B over time.</p>
<p>As described in <italic>Basic Network Properties</italic>, inhibitory oscillations allow units that are inactive at baseline levels of inhibition to “pop up” toward the end of the trial. This is important for allowing potential competitor units to activate. There is no “correct” color shown to the network, and all learning is based purely on an unsupervised U-shaped learning rule that factors in the coactivity of presynaptic and postsynaptic units (see <italic>Methods</italic> for parameter details).</p>
</sec>
</sec>
<sec id="s4">
<title>Results</title>
<sec id="s4a">
<title>Effects of Color Similarity on Color Recall and Neural Representations</title>
<p><bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) showed that, as color similarity was raised, a repulsion effect occurred where the colors of pairmates were remembered as being less similar to each other than they were in reality. When color similarity was raised even further, this repulsion effect went away. In our model, we expected to find a similar U-shaped pattern as hidden-layer overlap increased.</p>
<p>To measure repulsion, we operationalized the color memory “report” as the center-of-mass of activity in the color output layer at test. Because the topography of the output layer is meaningful for this version of the model (with nearby units representing similar colors), we could measure color attraction and repulsion by the change in the distance between the centers-of-mass (<bold><italic><xref rid="fig4" ref-type="fig">Figure 4</xref></italic></bold>A): If A and B undergo attraction after learning, the distance between the color centers-of-mass should decrease. If A and B undergo repulsion, the distance should increase.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Model of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>), Results: (A) The distance (number of units apart) between the centers-of-mass of output activity for A and B is used to measure repulsion vs. attraction. The gray bar indicates what the color difference would be after learning if no change happens from before (gray dots) to after (black dots) learning; above the gray bar indicates repulsion and below indicates attraction. For lower levels of overlap (0/6 and 1/6), color distance remains unchanged. For a medium level of overlap (2/6), repulsion occurs, shown by the increase in the number of units between A and B. For higher levels of overlap (3/6, 4/6, and 5/6), attraction occurs, shown by the decrease in the number of units between A and B. (B) Color error (output-layer distance between the “guess” and “correct” centers-of-mass) is shown for each pairmate and condition (negative values indicate repulsion). When repulsion occurs (2/6), the change is driven by a distortion of pairmate 2, whereas pairmate 1 is unaffected. (C) Pairmate similarity is measured by the correlation of the hidden-layer patterns before and after learning. Here, above the gray line indicates integration and below indicates repulsion. The within-pair correlation decreases (differentiation) when competitor overlap is moderate (2/6). Within-pair correlation increases (integration) when competitor overlap is higher (3/6, 4/6, and 5/6). (D) Four hidden-layer activity patterns from a sample run in the 2/6 condition are shown: pairmate 1<sub>before</sub>, pairmate 1<sub>after</sub>, pairmate 2<sub>before</sub>, and pairmate 2<sub>after</sub>. The subscripts refer to the state of the memory before/after the learning that occurs in the color recall task; pairmate 1 designates the first of the pairmates to be presented during color recall. Brighter colors indicate the unit is more active. In this run, pairmate 1 stays in place and pairmate 2 distorts away from pairmate 1. (E) Multidimensional scaling (MDS) plots for each condition are shown, to illustrate the pattern of representational change in the hidden layer. The same four patterns as in <bold><italic><xref rid="fig4" ref-type="fig">Figure 4</xref></italic></bold>D are plotted for each run. A jitter was applied to all points, and distance between pairmate 1<sub>before</sub> and pairmate 2<sub>before</sub> was adjusted to reflect increasing baseline similarity. Asymmetry in distortion can be seen in 2/6 by the movement of pairmate 2<sub>after</sub> away from pairmate 1. In conditions that integrate, most runs lead to symmetric distortion, although some runs in the 3/6 condition lead to asymmetric integration, where pairmate 2 moves toward pairmate 1<sub>before</sub>. For panels A, B, and C, error bars indicate the 95% confidence interval around the mean.</p></caption>
<graphic xlink:href="535239v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We found no difference in the color center-of-mass before and after training in the 0/6 and 1/6 conditions. As similarity increased to the 2/6 condition, the distance between the centers-of-mass increased after learning, indicating repulsion. When similarity increased further to the 3/6, 4/6, and 5/6 conditions, the distance between the centers-of-mass decreased with learning, indicating attraction. The overall pattern of results here mirrors what was found in the <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) study: Low levels of color similarity were associated with no change in color perception, moderate levels of color similarity were associated with repulsion, and the repulsion effect went away when color similarity increased further.</p>
<p>The only salient difference between the simulation results and the experiment results is that our repulsion effects cross over into attraction for the highest levels of similarity, whereas <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) did not observe attraction effects. It is possible that <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) would have observed an attraction effect if they had sampled the color similarity space more densely (i.e., somewhere between 24°, where they observed repulsion, and 6°, where they observed neither attraction nor repulsion). As a practical matter, it may have been difficult for <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) to observe attraction in the 6° condition given that color similarity was so high to begin with (i.e., there was no more room for the objects to “attract”).</p>
<p>We also measured representational change in the model’s hidden layer, by computing the Pearson correlation of the patterns of activity evoked by A and B in the hidden layer from before to after learning in the color recall test. If no representational change occurred, then this within-pair correlation should not change over time. In contrast, differentiation (or integration) would result in a decrease (or increase) in within-pair correlation over time.</p>
<p>We found that representational change tracked the repulsion/attraction results (<bold><italic><xref rid="fig4" ref-type="fig">Figure 4</xref></italic></bold>C): Lower overlap (i.e., 0/6 and 1/6), which did not lead to any change in color recall, also did not lead to change in the hidden layer; moderate overlap (i.e., 2/6), which showed repulsion in color recall, also showed a decrease in within-pair correlation (differentiation); and higher overlap (3/6, 4/6, and 5/6), which showed attraction in color recall, also showed an increase in within-pair correlation (integration). The association between behavioral repulsion/attraction and neural differentiation/integration that we observed in the model aligns well with results from <bold><italic><xref ref-type="bibr" rid="c53">Zhao et al</xref>.</italic></bold> (<bold><italic>2021</italic></bold>). They used a similar paradigm to <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) and found that the level of distortion of color memories was predicted by the amount of neural differentiation for those pairmates in parietal cortex (<bold><italic>Zhao et al., 2021</italic></bold>).</p>
<p>Crucially, we can inspect the model to see why it gives rise to the pattern of results outlined above. In the low-overlap conditions (0/6, 1/6), the competitor did not activate enough during target recall to trigger any competition-dependent learning (see Video 1). When color similarity increased in the 2/6 condition, the competitor pop-up during target recall was high enough for co-activity between shared units and unique competitor units to fall into the dip of the U-shaped function, severing the connections between these units. On the next trial, when the competitor was presented, the unique parts of the competitor activated in the hidden layer but — because of the severing that occurred on the previous trial — the formerly shared units did not. Because the activity “set point” for the hidden layer (determined by the kWTA algorithm) involves having 6 units active, and the unique parts of the competitor only take up 4 of these 6 units, this leaves room for activity to spread to additional units. Given the topographic projections in the output layer, the model is biased to “pick up” units that are adjacent in color space to the currently active units; because activity cannot flow easily from the competitor back to the target (as a result of the aforementioned severing of connections), it flows instead <italic>away</italic> from the target, activating two additional units, which are then incorporated into the competitor representation. This sequence of events (first a severing of the shared units, then a shift away from the target) completes the process of neural differentiation, and is what leads to the behavioral repulsion effect in color recall (because the center-of-mass of the color representation has now shifted away from the target) — the full sequence of events is illustrated in Video 2. Lastly, when similarity increased further (to 3/6 units or above), competitor pop-up increased — the co-activity between the shared units and the unique competitor units now falls on the right side of the U-shaped function, strengthening the connections between these units (instead of being severed). This strengthening leads to neural integration and and behavioral attraction in color space, as shown in Video 3.</p>
<p>In summary, this version of our model qualitatively replicates the key pattern of results in <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>), whereby increasing color similarity led to a repulsion effect in color recall, which went away as similarity increased further. The reasons why the model gives rise to these effects align well with the <italic>Potential NMPH Explanation</italic> provided earlier: Higher color similarity in-creases competitor activity, which first leads to differentiation of the underlying representations, and then — as competitor activity increases further — to integration of these representations.</p>
</sec>
<sec id="s4b">
<title>Asymmetry of Representational Change</title>
<p>A striking feature of the model is that the repulsion effect in the 2/6 condition is <italic>asymmetric</italic>: One pairmate anchors in place and the other pairmate shifts its color representation. <bold><italic><xref rid="fig4" ref-type="fig">Figure 4</xref></italic></bold>B illustrates this asymmetry, by tracking how the center-of-mass for both pairmates changes over time in the output layer. Specifically, for each pairmate, we calculated the difference between the center-of-mass at the end of learning compared to the initial center-of-mass. A distortion away from the competitor is coded as negative, and toward the competitor is positive. When repulsion occurred in the 2/6 condition, the item shown first (pairmate 1) anchored in place (i.e., the final color report was unchanged and accurate), whereas the item shown second (pairmate 2) moved away from its competitor.</p>
<p>This asymmetry was also observed in the hidden layer (<bold><italic><xref rid="fig4" ref-type="fig">Figure 4</xref></italic></bold>D and E). In <bold><italic><xref rid="fig4" ref-type="fig">Figure 4</xref></italic></bold>E, we used multidimensional scaling (MDS) to visualize how the hidden-layer representations changed over time. MDS represents patterns of hidden-layer activity as points in a 2D plot, such that the distance between each pair of points corresponds to the Euclidean distance between their hidden-layer patterns. We made an MDS plot for four patterns per run: the initial hidden-layer pattern for the item shown first (“pairmate 1<sub>before</sub>”), the initial hidden-layer pattern for the item shown second (“pairmate 2<sub>before</sub>”), the final hidden-layer pattern for the item shown first (“pairmate 1<sub>after</sub>”), and the final hidden-layer pattern for the item shown second (“pairmate 2<sub>after</sub>”). Since the 0/6 and 1/6 conditions did not give rise to representational change, the MDS plot unsurprisingly shows that the before and after patterns of both pairmates remain unchanged. For the 2/6 condition (which shows differentiation), the pairmate 1<sub>before</sub> item remains clustered around pairmate 1<sub>after</sub>. However, pairmate 2<sub>after</sub> distorts, becoming relatively more dissimilar to pairmate 1, indicating that the differentiation is driven by pairmate 2 distorting away from its competitor. This asymmetry in differentiation arises for reasons described in the previous section — when pairmate 2 pops up as a competitor during recall of pairmate 1, the unique units of pairmate 2 are severed from the units that it (formerly) shared with pairmate 1, allowing it to acquire new units elsewhere given the inhibitory set point. After pairmate 2 has shifted away from pairmate 1, they are no longer in competition, so there is no need for pairmate 1 to adjust its representation and it stays in its original location in representational space (see Video 2).</p>
<p>In our model, the asymmetry in differentiation manifested as a clear order effect — pairmate 1 anchors in place and pairmate 2 shifts away from pairmate 1. It is important to remember, however, this effect is contingent on pairmate 2 popping up as a competitor when pairmate 1 is first shown as a target. If the dynamics had played out differently, then different results might be obtained. For example, if pairmate 2 does not pop up as a competitor when pairmate 1 is first presented, and instead pairmate 1 pops up as a competitor when pairmate 2 is first presented, we would expect the opposite pattern of results (i.e., pairmate 2 will anchor in place and pairmate 1 will shift away from pairmate 2). We return to these points, and their implications for empirically testing the model’s predictions about asymmetry, in the <italic>Discussion</italic> section.</p>
</sec>
<sec id="s4c">
<title>Two Kinds of Integration</title>
<p>We also observed that integration could take two different forms, symmetric and asymmetric (<bold><italic>Figure 4</italic></bold>B and 4E). In this version of the model, the symmetric integration is more common. This can be seen in the MDS plots for conditions 3/6, 4/6, and 5/6: Both pairmate 1<sub>after</sub> and pairmate 2<sub>after</sub> mutually move toward each other. This is because both pairmates end up connecting to all the units that were previously connected to either pairmate individually. Essentially, the hidden units for pairmate 1 and pairmate 2 are “tied” in terms of strength of excitation, so they are all allowed to be active at once (see <italic>Activity and Inhibitory Dynamics</italic> in the <italic>Methods</italic>). However, in the 3/6 condition, some runs show asymmetric integration where pairmate 2 distorts toward pairmate 1. (<bold><italic><xref rid="fig4" ref-type="fig">Figure 4</xref></italic></bold>E).</p>
<p>Whether symmetric or asymmetric integration occurs depends on the relative strengths of competitor-to-competitor connections compared to competitor-to-shared connections after the first trial (<bold><italic><xref rid="fig5" ref-type="fig">Figure 5</xref></italic></bold>). Generally, competitor-to-competitor coactivity is less than competitor-to-shared coactivity, which is less than target-to-shared coactivity. In the 2/6 condition (<bold><italic><xref rid="fig5" ref-type="fig">Figure 5</xref></italic></bold>A), competitor-to-competitor coactivities fall on the left side of the U-shaped function, and remain unchanged. In the 4/6 and 5/6 conditions, because competitor activity is so high, competitor-to-competitor coactivities fall on the right side of the U-shaped function (<bold><italic><xref rid="fig5" ref-type="fig">Figure 5</xref></italic></bold>B). It follows, then, that there is some overlap amount where competitor-to-competitor coactivities fall in the dip of the U-shaped function (<bold><italic><xref rid="fig5" ref-type="fig">Figure 5</xref></italic></bold>C). This is what happens in some runs in the 3/6 condition: On trial 1, some competitor-to-competitor connections (i.e., internal connections within pairmate 2) are severed, while — at the same time — competitor-to-shared connections are strengthened. On the next trial, when the model is asked to recall pairmate 2, activity flows out of the pairmate 2 represen-tation into the shared units, which are connected to the representations of both pairmate 1 and pairmate 2. Because the representation of pairmate 2 has been weakened by the severing of its internal connections, while the representation of pairmate 1 is still strong, the representation of pairmate 1 outcompetes the representation of pairmate 2 (i.e., pairmate 1 receives substantially more excitation via recurrent connections than pairmate 2) and the neural pattern in the hidden layer “flips over” to match the original pairmate 1 representation. This hidden-layer pattern is then associated with the pairmate 2 input, resulting in asymmetric integration — from this point forward, both pairmate 2 and pairmate 1 evoke the original pairmate 1 representation (see Video 4) Thus, two kinds of integration can occur — one where both pairmates pick up all units that initially belonged to either pairmate (symmetric), and one where pairmate 2 moves toward pairmate 1 (asymmetric). Generally, as competitor activity is raised, competitor-to-competitor coactivity is raised, and it is more likely the integration will become symmetric.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><p>Schematic of coactivities on Trial 1: Generally, competitor-to-competitor coactivity is less than competitor-to-shared coactivity, which is less than target-to-target coactivity. (A) Schematic of the typical arrangement of coactivity in the hidden-to-hidden connections and item-to-hidden connections in the 2/6 condition. The competitor-to-shared connections are severed because they fall in the dip of the U-shaped function, which leads to differentiation. (B) Typical arrangement of coactivity in the higher overlap conditions, 4/6 and 5/6. All connection types are on the right side of the U-shaped function, leading to integration. Specifically, all units connect to each other more strongly, leading units previously associated with either pairmate A or B to join together. (C) As competitor pop-up increases, moving from the situation depicted in panel A to B, it is possible for competitor-to-competitor coactivity to fall into the dip of the U-shaped function. If enough competitor-to-competitor connections weaken, while competitor-to-shared connections strengthen, this imbalance can lead to an asymmetric form of integration where pairmate 2 moves toward pairmate 1 (see text for details). This happens in some runs of the 3/6 overlap condition.</p></caption>
<graphic xlink:href="535239v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s4d">
<title>Differentiation Requires a High Learning Rate but Integration Does Not</title>
<p>We found that differentiation requires a high learning rate. In our model, the change in connection weights on each trial is multiplied by a learning rate (<italic>LRate</italic>), which is usually set to 1. Lowering the <italic>LRate</italic> value, consequently, leads to smaller learning increments. When we cycle through <italic>LRate</italic> values for all projections other than the output-to-output connection (where <italic>LRate</italic> is zero), we find that differentiation fails to occur in the 2/6 condition if <italic>LRate</italic> is too low (<bold><italic><xref rid="fig6" ref-type="fig">Figure 6</xref></italic></bold>A): If the competitor-to-shared connections are not fully severed on Trial 1, the (formerly) shared units may still receive enough excitation to strongly activate when the model is asked to recall pairmate 2 on Trial 2. This can lead to two possible outcomes: Sometimes the activity pattern in the hidden layer ends up matching the original pairmate 2 representation (i.e., the shared units are co-active with the unique pairmate 2 units), resulting in a “re-forming” of the original representation. In other cases, asymmetric integration occurs: If shared-to-pairmate-2 connections have weakened somewhat, while the shared-to-pairmate-1 connections are still strong, then spreading activity from the (reactivated) shared units on Trial 2 can lead to the original pairmate 1 hidden-layer representation outcompeting the original pairmate 2 hidden-layer representation, in which case the pairmate 2 inputs will become associated with the original pairmate 1 hidden-layer representation. See Video 5 for illustrations of both possible outcomes. These two outcomes can also be seen in <bold><italic><xref rid="fig6" ref-type="fig">Figure 6</xref></italic></bold>B, which shows learning across trials for individual model runs (with different random seeds) as a function of <italic>LRate</italic>. A useful analogy may be escape velocity from astrophysics. Spaceships need to be going a certain speed to escape the pull of gravity. Similarly, the competitor representation needs to get a certain distance away from its pairmate in one trial, or else it will get “pulled back in”.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Learning Rate and Representational Change: (A) The learning rate (<italic>LRate</italic>) parameter was adjusted and the within-pair correlation in the hidden layer was calculated for each overlap condition. Error bars indicate the 95% confidence interval around the mean. The default <italic>LRate</italic> for simulations in this paper is 1. In the low overlap conditions (0/6 and 1/6), adjusting the <italic>LRate</italic> has no impact on representational change. In the 2/6 condition, differentiation does not occur if the <italic>LRate</italic> is lowered. In the high overlap conditions (3/6, 4/6, and 5/6), adjusting the <italic>LRate</italic> has no impact on representational change. (B) For each <italic>LRate</italic> value tested, the within-pair correlation over time in the 2/6 condition is shown, where each line is a separate run. When <italic>LRate</italic> is set to 0.50 or higher, some model runs show abrupt, strong differentiation, resulting in negative within-pair correlation values; these negative values indicate that the hidden representation of one pairmate specifically excludes units that belong to the other pairmate.</p></caption>
<graphic xlink:href="535239v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>A corollary of the fact that differentiation requires a high learning rate is that, when it does happen in the model, it happens abruptly. After competitor-to-shared connections are weakened, this can have two possible effects. If the learning rate is high enough to sever the competitor-to-shared connections, differentiation will be evident the next time the competitor is presented. If the amount of weakening is insufficient, the formerly shared units will be reactivated and no differentiation will occur. The abruptness of differentiation can be seen in <bold><italic><xref rid="fig6" ref-type="fig">Figure 6</xref></italic></bold>B: When the learning rate is high enough to cause differentiation, it always happens between the first and second epochs of training. The prediction that differentiation should be abrupt is also supported by empirical studies. For instance, <bold><italic>Wanjia et al.</italic></bold> (<bold><italic>2021</italic></bold>) showed that behavioral expressions of successful learning are coupled with a temporally abrupt, stimulus-specific decorrelation of CA3/dentate gyrus activity patterns for highly similar memories.</p>
<p>In contrast to these results showing that differentiation requires a large <italic>LRate</italic>, the integration effects observed in the higher-overlap conditions do not depend on <italic>LRate</italic>. Once two items are close enough to each other in representational space to strongly coactivate, a positive feedback loop ensues: Any learning that occurs (no matter how small) will pull the competitor closer to the target, making them even more likely to strongly coactivate (and thus further integrate) in the future.</p>
</sec>
<sec id="s4e">
<title>Take-Home Lessons</title>
<p>Our model of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) shows that the NMPH can explain the results observed in the study, namely that moderate color similarity can lead to repulsion and that, if color similarity is increased beyond that point, the repulsion is eliminated. Furthermore, our model shows how the behavioral changes in this paradigm are linked to differentiation and integration of the underlying neural representations. The simulations also enrich our NMPH account of these phenomena in several ways, beyond the verbal account provided in <bold><italic>Ritvo et al.</italic></bold> (<bold><italic>2019</italic></bold>). In particular, the simulations expose some important boundary conditions for when representational change can occur according to the NMPH (e.g., that differentiation depends on a large learning rate, but integration does not), and the simulations provide a more nuanced account of exactly how representations change (e.g., that differentiation driven by the NMPH is always asymmetric, whereas integration is sometimes asymmetric and sometimes symmetric).</p>
<p>There are several aspects of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) left unaddressed by our model. For instance, they interleaved the color recall task (simulated here) with an associative memory test (not simu-lated here) where a colored object appeared as a cue and participants had to select the associated face. Our goal was to show how the simplest form of their paradigm could lead to the distortion effects that were observed; future simulations can assess whether these other experiment details affect the predictions of the model.</p>
</sec>
</sec>
<sec id="s5">
<title>Model of <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>): Similar and Different Predictive Associations</title>
<sec id="s5a">
<title>Key Experimental Findings</title>
<p><bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>) provided neural evidence for differentiation following competition, using a shared associate to induce competition between pairmates. In this study (<bold><italic><xref rid="fig7" ref-type="fig">Figure 7</xref></italic></bold>A), participants were instructed to learn scene-face associations. Later, during the repeated face-test task, participants were shown a scene and asked to pick the correct face from a bank of faces. Scenes were made up of highly similar pairs (e.g., two bridges, two barns). Sometimes, two paired scenes predicted the same face, sometimes different faces, and sometimes no face at all (in the latter case, the paired scenes appeared in the study task and not the face-test task). Participants were never explicitly told that some scene pairs shared a common face associate.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><p>Modeling <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>): (A) Participants learned to associate individual scenes with faces (faces not shown here due to bioRxiv rules). Each scene had a pairmate (another, similar image from the same scene category, e.g., another barn), and categories were not re-used across pairs (e.g., if the stimulus set included a pair of barns, then none of the other scenes would be barns). Pairmates could be associated with the same face, different faces, or no face at all (not shown). Participants were scanned while looking at each individual scene in order to get a measure of neural representations for each scene. (B) Neural similarity was measured by correlating scene-evoked patterns of fMRI activity. A scene pair difference score was calculated by subtracting non-pairmate similarity from pairmate similarity; this measure shows the relative representational distance of pairmates. Results for the different-face and same-face condition in the hippocampus are shown here: Linking scenes to the same face led to a negative scene pair difference score, indicating that scenes became less similar to each other than they were to non-pairmates (differentiation). (C) To model this study, we used the same basic structure that was described in <italic>Basic Network Properties</italic>. In this model, the category layer represents the type of scene (e.g., barn, bridge, etc.), and the item layer represents an individual scene. The output layer represents the face associate. Activity shown is for pairmate A in the same-face condition. Category-to-hidden, item-to-hidden and hidden-to-hidden connections are pre-wired similarly to the 2/6 condition of our model of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) (see <bold><italic><xref rid="fig2" ref-type="fig">Figure 2</xref></italic></bold>). The hidden A and B units have random, low-strength connections to all output units, but are additionally pre-wired to connect strongly to either one or two units in the output layer. In the different-face condition, hidden A and B units are pre-wired to connect to two different face units, but in the same-face condition, they are pre-wired to connect to the same face unit. (D) This model has two conditions: same face and different face. The only difference between conditions is whether the hidden A and B units connect to the same or different face unit in the output layer.</p></caption>
<graphic xlink:href="535239v2_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>When the two scenes predicted different faces, the hippocampal representations for each scene were relatively orthogonalized — hippocampal representations of the two pairmate scenes were just as similar to each other as to non-pairmate scenes. However, when the two scenes predicted the same face, differentiation resulted, such that the hippocampal representations of the two pairmate scenes were less similar to each other than to non-pairmate scenes (<bold><italic><xref rid="fig7" ref-type="fig">Figure 7</xref></italic></bold>B).</p>
</sec>
<sec id="s5b">
<title>Potential NMPH Explanation</title>
<p>As noted earlier, these results contradict supervised learning models, which predict that pairing two stimuli with the same associate would lead to integration, not differentiation. The NMPH, however, can potentially explain these results: Linking the pairmates to a shared face associate provides an additional pathway for activity to spread from the target to the competitor (i.e., activity can spread from scene A, to the shared face, to scene B). If competitor activity falls on the left side of the U-shaped function in the different-face condition, then the extra spreading activity in the same-face condition could push the activity of the competitor into the “dip” of the function, leading to differentiation.</p>
</sec>
<sec id="s5c">
<title>Model Set Up</title>
<sec id="s5c1">
<title>Model Architecture</title>
<p>Our model of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) can be adapted for <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>). Instead of mapping from an object and face to a color, as in <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>), the <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>) study involves learning mappings between scenes and faces. Also, the way in which competition is manipulated is different across the studies: In <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>), competition is manipulated by varying the similarity of the stimuli (specifically, the color difference of the objects), whereas in <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>), competition is manipulated by varying whether pairmate scenes are linked to the same vs. different face.</p>
<p>To adapt our model for <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>), the interpretation of each layer must be altered to fit the new paradigm (<bold><italic><xref rid="fig7" ref-type="fig">Figure 7</xref></italic></bold>C). The category layer now represents the category for the scene pairmates (e.g., barn, bridge, etc.). The item layer represents the individual scene (e.g., where A represents barn1 and B represents barn2). Just as before, the input for each stimulus is composed of two units (one in each of the two input layers); the category-layer unit is consistent for A and B, but the item-layer unit differs.</p>
<p>The output layer in this model represents the face associate, such that each individual outputlayer unit could be thought of as a single face. For this model, the ordering of units in the output layer is not meaningful — two units next to each other in the output layer are no more similar than to any other units.</p>
</sec>
</sec>
<sec id="s5d">
<title>Knowledge Built Into the Network</title>
<p>As before, we were interested in the moment that competition first happens, so we pre-wired connections as if some initial learning had occurred. We pre-wired the connections between the hidden layer and both input layers (and from hidden layer to itself) to be similar to the 2/6 condition of our model of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>), so there is some baseline amount of overlap between A and B (i.e., reflecting the similar-looking scenes).</p>
<p>To mimic the learning of scene-face associates, all hidden A units are connected to a single unit in the face layer, and all hidden B units are connected to a single unit in the face layer. In the different-face condition, A and B hidden units are connected to different face units, to reflect that the two scenes were predictive of two separate faces. In the same-face condition, A and B hidden units connect to the same face unit, to reflect that A and B predict the same face.</p>
</sec>
<sec id="s5e">
<title>Manipulation of Competitor Activity</title>
<p>Competitor activity is modulated by the similarity of predictive consequences in this version of the model — i.e., whether the hidden units for pairmates A and B are pre-wired to connect strongly to the same unit or different units in the output layer. Stronger connections to the same face unit should provide an extra conduit for excitation to flow to the competitor units.</p>
</sec>
<sec id="s5f">
<title>Task</title>
<p>The task performed by the model was to guess the face associated with each scene. We clamped the external input for the scenes and allowed activity to spread through the hidden layer to the output layer so it could make a guess for the correct face. No correct answer was shown, and no error-driven learning was used. Although the exact parameter values used in this simulation were slightly different from the values used in the previous simulation (see <italic>Methods</italic> for details), inhibition and oscillations were implemented in the same way as before.</p>
</sec>
<sec id="s5g">
<title>Results</title>
<p>For this study, the key dependent measure was representational change within the hidden layer. Specifically, we sought to capture the hippocampal pattern similarity results reported by <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>).</p>
<sec id="s5g1">
<title>Differentiation and Integration</title>
<p>The different-face condition in this model led to no representational change (see Video 6) whereas the same-face condition led to differentiation (see Video 7), as measured using within-pair correlation (<bold><italic><xref rid="fig8" ref-type="fig">Figure 8</xref></italic></bold>A). Differentiation is indicated by the fact that new units are added that did not previously belong to either pairmate. In this version of the model, the topography of the hidden layer is not meaningful other than the units assigned to A and B, so the new units that are added to the representation could be on either side. The reason why the model shows differentiation in the same-face condition (but not in the different-face condition) aligns with the <italic>Potential NMPH Explanation</italic> provided earlier: The shared face associate in the same-face condition provides an conduit for extra activity to spread to the competitor scene pairmate, leading to moderate activity that triggers differentiation.</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><p>Model of <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>), Results: (A) Within-pair correlation between A and B hidden layer representations before and after learning. Error bars indicate the 95% confidence interval around the mean. In the same-face condition, the within-pair correlation is reduced after learning, indicating differentiation. (B) Activity patterns of both pairmates in the hidden layer before and after learning for a sample “same-face” run are shown. Asymmetry in distortion can be seen in how pairmate 1’s representation is unchanged and pairmate 2 picks up additional units that did not previously belong to either item (note that there is no topography in the hidden layer in this simulation, so we would not expect the newly-acquired hidden units to fall on one side or the other of the layer). (C) MDS plots for each condition illustrate representational change in the hidden layer. The differentiation in the same-face condition is asymmetric: Pairmate 2<sub>after</sub> generally moves further away from pairmate 1 in representational space, while pairmate 1 generally does not change.</p></caption>
<graphic xlink:href="535239v2_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s5g2">
<title>Asymmetry of Representational Change</title>
<p>The representational change in the hidden layer shows the same kind of asymmetry that occurred in our model of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) (<bold><italic><xref rid="fig8" ref-type="fig">Figure 8</xref></italic></bold>B, C): In the same-face condition, pairmate 1 typically anchors in place, whereas pairmate 2 acquires new units that did not previously belong to either either pairmate (<bold><italic><xref rid="fig8" ref-type="fig">Figure 8</xref></italic></bold>B), resulting in it shifting away from pairmate 1 (<bold><italic><xref rid="fig8" ref-type="fig">Figure 8</xref></italic></bold>C). Although this pattern is present on most runs, the MDS plot also shows that some runs fail to differentiate and instead show integration (see the <italic>Discussion</italic> for an explanation of how conditions that usually lead to differentiation may sometimes lead to integration instead). Note that the neural measure of differentiation used by <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>) does not speak to the question of whether representational change was symmetric or asymmetric in their experiment — to measure the (a)symmetry of representation change, it is necessary to take “snapshots” of the representations both before and after learning (e.g., <bold><italic><xref ref-type="bibr" rid="c41">Schapiro et al., 2012</xref></italic></bold>), but the method used by <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>) only looked at post-learning snapshots (comparing the neural similarity of pairmates and non-pairmates). We return in the <italic>Discussion</italic> to this question of how to test predictions about asymmetric differentiation.</p>
</sec>
<sec id="s5g3">
<title>Differentiation Requires a High Learning Rate</title>
<p>As in our model of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>), we again found that a high <italic>LRate</italic> is needed for differentiation. Specifically, lowering <italic>LRate</italic> below its standard value (e.g., to a value of 0.10) eliminated the differentiation effect in the same-face condition. Changing the learning rate did not impact the different-face condition. In this condition, the pop-up is low enough that all competitor-to-shared connections on Trial 1 fall on the left side of the U-shaped function, so no weight change occurs, regardless of the learning rate setting.</p>
</sec>
<sec id="s5g4">
<title>Take-Home Lessons</title>
<p>This simulation demonstrates that the NMPH can explain the results of <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>), where learning about stimuli that share a paired associate can lead to differentiation. The model shows how linking items with the same or different associates can modulate competitor activity and, through this, modulate representational change. As in our simulation of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>), we found that the NMPH-mediated differentiation was asymmetric and required a high learning rate, leading to abrupt representational change.</p>
</sec>
</sec>
</sec>
<sec id="s6">
<title>Model of <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>): Blocked and Interleaved Learning</title>
<sec id="s6a">
<title>Key Experimental Findings</title>
<p>For our third simulation, we focused on a study by <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>). This study examined how the learning curriculum affects representational change in different brain regions. Participants learned to link novel objects with a common associate (i.e., AX and BX). Sometimes these associates were presented in a blocked fashion (all AX before any BX) and sometimes they were presented in an interleaved fashion (<bold><italic><xref rid="fig9" ref-type="fig">Figure 9</xref></italic></bold>A).</p>
<fig id="fig9" position="float" orientation="portrait" fig-type="figure">
<label>Figure 9.</label>
<caption><p>Modeling <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>): (A) Participants in <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>) learned to link novel objects with a common associate (i.e., AX and BX). Sometimes these associates were learned in a blocked design (i.e., all AX before any BX), and sometimes they were learned in an interleaved design. The items were shown side-by-side, and participants were not explicitly told the structure of the shared items. Before and after learning, participants were scanned while observing each item alone, in order to get a measure of the neural representation of each object. (B) Some brain regions (e.g., right posterior hippocampus) showed differentiation for both blocked and interleaved conditions, some regions (e.g., left mPFC) showed integration for both conditions, and other regions (e.g., right anterior hippocampus) showed integration in the blocked condition but differentiation in the interleaved condition. (C) To model this study, we used the network structure described in <italic>Basic Network Properties</italic>, with the following modifications: The structure of the network was similar to the same-face condition in our model of <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>) (see <bold><italic><xref rid="fig7" ref-type="fig">Figure 7</xref></italic></bold>), except we altered the connection strength from units in the hidden layer to the output unit corresponding to the shared item (“item X”) to simulate what would happen depending on the learning curriculum. In both conditions, the pre-wired connection linking the “item B” hidden units to the “item X” output unit is set to .7. In the interleaved condition, the connection linking the “item A” hidden units to the “item X” output unit is set to .8, to reflect some amount of initial AX learning. In the blocked condition, the connection linking the “item A” hidden units to the “item X” output unit is set a higher value (.999), to reflect extra AX learning.</p></caption>
<graphic xlink:href="535239v2_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The analysis focused on the hippocampus, the medial prefrontal cortex (mPFC), and the inferior frontal gyrus (IFG). Some brain regions (e.g., right posterior hippocampus) showed differentiation for both blocked and interleaved conditions, some regions (e.g., left mPFC) showed integration for both conditions, and others (e.g., right anterior hippocampus) showed integration in the blocked condition but differentiation in the interleaved condition (<bold><italic><xref rid="fig9" ref-type="fig">Figure 9</xref></italic></bold>B).</p>
</sec>
<sec id="s6b">
<title>Potential NMPH Explanation</title>
<p>The NMPH can potentially explain how the results differ by brain region, since the overall level of inhibition in a region can limit the competitor’s activity. For instance, regions that tend to show differentiation (like posterior hippocampus) have sparser activity (<bold><italic>Barnes et al., 1990</italic></bold>). Higher in-hibition in these areas could cause the activity of the competitor to fall into the moderate range, leading to differentiation. For regions with lower inhibition, competitor activity may fall into the high range, leading to integration.</p>
<p>The result that some regions (e.g., right anterior hippocampus) show differentiation in the interleaved condition and integration in the blocked condition could also be explained by the NMPH. By the first BX trial, we would expect that the connections between A and X would be much stronger in the blocked condition (after many AX trials) compared to the interleaved condition (after one or a few AX trials). This stronger A-X connection could allow more activity to flow from B through X to the A competitor. Consequently, competitor activity in the blocked condition would fall farther to the right of the U-shaped function compared to the interleaved condition, allowing for integration in the blocked condition but differentiation in the interleaved condition.</p>
</sec>
<sec id="s6c">
<title>Model Set Up</title>
<sec id="s6c1">
<title>Model Architecture</title>
<p>In <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>), A, B, and X were all individual pictures of objects shown in the same fashion; the only difference is that X was paired with two distinct items (A and B) but A and B were only paired with one other item (X). We decided to represent A and B pairmates in the input layer and X as a single unit in the output layer. Concretely, we represented A and B in the input layer by having a unique (single) unit in the item layer for each of A and B; the same (single) unit is active in the category layer for both stimuli (it can be thought of as representing the category of “novel objects” to which both A and B belong). Putting A and B in the same layer, where their representations directly compete, captures the fact that A and B were mutually exclusive (i.e., they were never viewed together). Putting X in a different layer made it easier for the model to represent X at the same time as A or B. Note that, because connections in the model are bidirectional and symmetric in strength, the X output was able to influence activity elsewhere in the network, which proves to be critical for the learning effects described below. This approach also makes the isomorphism to <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>) clearer — just as a shared face associate in that study served as a conduit for activity to spread to the scene pairmate, the shared X object associate in <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>) serves as a conduit for activity to spread between B and A pairmates.</p>
</sec>
<sec id="s6c2">
<title>Knowledge Built into the Network</title>
<p>The connections between layers for this model are similar to the connections we used in the same-face condition in our model of <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>). Since both A and B have a shared associate (X), all hidden A and B units are connected to the same unit in the output layer. However, we adjusted the connection strength to the shared X unit in order to simulate blocked or interleaved learning (see <bold><italic><xref rid="fig9" ref-type="fig">Figure 9</xref></italic></bold>C caption for details).</p>
</sec>
<sec id="s6c3">
<title>Modulation of Competitor Activity</title>
<p>We hypothesized that competition would be modulated by the blocked vs. interleaved manipulation. If AX and BX are learned in a blocked design, then the connections between A (in the hidden layer) and X (in the output layer) will be stronger before the first BX trial than in the interleaved condition. That extra strength can provide a pathway for more excitation to flow from X to A during BX trials. In our simulations, we operationalized this difference by varying the strength of the connection between A units (in the hidden layer) and X units (in the output layer; see <bold><italic><xref rid="fig9" ref-type="fig">Figure 9</xref></italic></bold> caption for details).</p>
</sec>
<sec id="s6c4">
<title>Task</title>
<p>External inputs corresponding to the A or B stimuli (given by the two input layers) are clamped, and activity is allowed to flow through the hidden layer to the output layer, producing a guess of its associate. This deviates somewhat from the task in the original study, which showed AX or BX stimuli side-by-side. We could have clamped the X external values so it would be shown rather than guessed, but we decided to let the activity flow through the network to be consistent with the other versions of our model. This change does not have any impact on the outcome of the simulation — X ends up being strongly active here even though it is not being externally clamped, so the dynamics of activity elsewhere in the network (and the resulting learning) end up the same as if external clamping had been applied.</p>
<p>In the blocked condition, we assume AX has been fully learned, so we start with a BX training trial and no AX trials follow. To be consistent, we also start the interleaved condition with a BX training trial; however, in the interleaved condition, both AX and BX may follow after that initial BX trial.</p>
<p>Although the exact values of parameters used in this simulation were slightly different than the values used in the previous simulations (see <italic>Methods</italic> for details), inhibition and oscillations were implemented in the same manner as before.</p>
</sec>
<sec id="s6c5">
<title>Modulation of Inhibitory Dynamics</title>
<p>For this version of our model, we added an extra manipulation. To model the fact that some brain regions showed overall differentiation and others overall integration, we varied the amplitude of the inhibitory oscillations in the hidden layer. If the amplitude of the sinusoidal function on inhibition is larger (or smaller), then the competitor is allowed to pop up more (or less), affecting the outcome of learning. We first present results from a version of the model where the amplitude is set to an intermediate level (0.0623); we also present results from model variants where we allowed less competitor pop-up (by lowering the oscillation amplitude to 0.0535) and more competitor pop-up (by raising the oscillation amplitude to 0.09), in order to simulate representational change in brain regions that have more or fewer restrictions on competitor activity.</p>
</sec>
</sec>
<sec id="s6d">
<title>Results</title>
<sec id="s6d1">
<title>Differentiation and Integration</title>
<p>Examining the correlation between the hidden-layer representations of A and B, we found that the interleaved condition leads to differentiation (see Video 8) whereas the blocked condition (where the AX connection is stronger) leads to integration (see Video 9) (<bold><italic><xref rid="fig10" ref-type="fig">Figure 10</xref></italic></bold>A). The reason why the model shows this pattern of results aligns with the <italic>Potential NMPH Explanation</italic> provided earlier: Because the X output unit is more strongly connected to A’s hidden-layer representation in the blocked condition, more activity spreads from B via X to A in the blocked condition. This increased competitor activity results in the two representations integrating (as opposed to differentiating).</p>
<fig id="fig10" position="float" orientation="portrait" fig-type="figure">
<label>Figure 10.</label>
<caption><p>Model of <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>), Results: In this model, pairmate B is always the stimulus shown first during the competitive learning part of the simulation (after initial AX learning), so we refer to pairmate B as “pairmate 1” in the figure and to pairmate A as “pairmate 2”. (A) Within-pair correlation between hidden-layer A and B representations is shown before and after learning. In the interleaved condition, the within-pair correlation is reduced after learning, indicating differentiation. In the blocked condition, the within-pair correlation increases, indicating integration. (B) Activity patterns of both pairmates in the hidden layer before and after learning are shown for a sample run in the interleaved condition. Asymmetry in distortion can be seen in how pairmate 2, but not pairmate 1, picks up additional units that did not previously belong to either representation. (C) MDS plots for each condition illustrate the pattern of representational change in the hidden layer. In the blocked condition, the pairmates integrate and move toward each other. This integration is mostly symmetric, but on many trials it is asymmetric: Pairmate 2 moves toward pairmate 1 rather than pairmates 1 and 2 meeting in the middle. In the interleaved condition, asymmetric differentiation occurs: Pairmate 2 moves away from pairmate 1. (D) To investigate how these results vary across brain regions with different inhibitory dynamics, we manipulated the inhibitory oscillation amplitude to change the amount of competitor pop-up. No parameters other than the inhibitory oscillation level were changed. When oscillation strength is reduced from its baseline value, less competitor pop-up happens, and the blocked, but not interleaved, condition leads to differentiation. When the oscillation amount is raised above baseline, more competitor pop-up happens, and both conditions lead to integration. For panels A and D, error bars indicate the 95% confidence intervals around the mean.</p></caption>
<graphic xlink:href="535239v2_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s6d2">
<title>Asymmetry of Representational Change</title>
<p>The results of this simulation again indicate that differentiation is asymmetric. <bold><italic><xref rid="fig10" ref-type="fig">Figure 10</xref></italic></bold>B shows a single run in the interleaved condition: Pairmate 1 anchors in place and pairmate 2 picks up units that did not previously belong to either representation. The MDS plot (<bold><italic><xref rid="fig10" ref-type="fig">Figure 10</xref></italic></bold>C) shows how, in the interleaved condition, pairmate 2 consistently shifts away from pairmate 1.</p>
<p>The MDS results from the blocked condition show that integration is mostly symmetric, but there are many runs that show asymmetric integration (just like in the 3/6 condition of our model of <bold><italic>Chanales et al., 2021</italic></bold>). The reason for asymmetric integration is the same here: Sometimes not all of the competitor-to-competitor coactivity values reach the right side of the U-shaped function, and connections that fall into the “dip” of the U-shaped function are weakened. When these competitor-to-competitor connections weaken and the competitor-to-shared connections strengthen, this imbalance can cause pairmate 2 to flip from its original representation to sharing pairmate 1’s original representation.</p>
</sec>
<sec id="s6d3">
<title>Differentiation Requires a High Learning Rate, but Integration Does Not</title>
<p>Just as in our previous simulations, a high learning rate is needed for differentiation. Specifically, lowering <italic>LRate</italic> below its standard value (e.g., to a value of 0.1) eliminated differentiation in the interleaved condition. Lowering the learning rate to 0.1 did not, however, eliminate the integration observed in the blocked condition.</p>
</sec>
<sec id="s6d4">
<title>Adjusting Oscillation Amount Changes Representational Change</title>
<p>In this model, we additionally adjusted the amplitude of inhibitory oscillations, to simulate different inhibitory dynamics across brain regions (<bold><italic><xref rid="fig10" ref-type="fig">Figure 10</xref></italic></bold>D). When the competitor was less able to activate (as a result of lower inhibitory oscillations), only the blocked condition led to differentiation. When the competitor was allowed to activate more (because of higher inhibitory oscillations), both conditions led to integration. These simulations provide an “in principle” account of how differences in levels of inhibition across brain regions can modulate representational change.</p>
<p>It is worth emphasizing that — in this simulation, as in our simulation of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) — manipulations that raise competitor activity (here, increasing oscillation strength) are associated with a transition from no representational change to differentiation to integration; this is a straight-forward consequence of the U shape of the NMPH curve. Notably, this appears to be inconsistent with some recent results from <bold><italic>Molitor et al.</italic></bold> (<bold><italic>2021</italic></bold>), who used a paradigm similar to <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>) and measured competitor activity with a multivariate fMRI pattern classifier. <bold><italic>Molitor et al.</italic></bold> (<bold><italic>2021</italic></bold>) found that — in a combined DG / CA2,3 hippocampal ROI — lower levels of competitor activity were associated with integration and higher levels of competitor activity were associated with differentiation. Although there are several potential ways that any single finding of this sort could be explained away (see, e.g., <bold><italic><xref ref-type="bibr" rid="c46">Tarder-Stoll et al., 2021</xref></italic></bold>), such a pattern of results could prove troublesome for the model if it turns out to be reliable across studies.</p>
</sec>
</sec>
<sec id="s6e">
<title>Take-Home Lessons</title>
<p>This version of our model shows that the NMPH can account for the results of <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>), where the learning paradigm (blocked or interleaved) had been shown to affect represen-tational change. Additionally, the model reveals how the inhibitory dynamics of different brain regions can affect these outcomes. As in the other versions of our model, when differentiation occurs, it is both asymmetric and requires a high learning rate.</p>
</sec>
</sec>
<sec id="s7">
<title>Discussion</title>
<p>Recent studies have presented a challenge to supervised learning models, showing that linking items to a shared associate can result in differentiation rather than integration. The goal of the current research was to instantiate our unsupervised-learning account of representational change in a neural network model and assess how well it can account for extant data on differentiation and integration. We simulated three studies, each of which modulated the amount of competitor activity in different ways: <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) modulated competitor activity with stimulus similarity; <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>) modulated competitor activity through the use of shared (vs. unshared) predictive consequences; and <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>) modulated competitor activity by organizing learning in a blocked or interleaved order. The <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>) model also explored the effects of (simulated) regional differences in the strength of local inhibition, and the <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) model additionally explored the effect of varying the learning rate.</p>
<p>Our model provides an existence proof that a network imbued with NMPH learning can explain these findings. Using unsupervised NMPH learning alone, we showed how: 1) Increasing the similarity of color memories leads progressively to a repulsion effect and then an attraction effect; 2) pairing two stimuli with the same associate can lead to differentiation; and 3) learning in an interleaved vs. blocked fashion can lead to differentiation and integration, respectively, and that changing inhibitory dynamics can affect these outcomes. In addition to qualitatively replicating the results from the studies we simulated, our model gives rise to several novel predictions — most notably, that differentiation requires a rapid learning rate and is asymmetric.</p>
<sec id="s7a">
<title>Differentiation Requires a High Learning Rate and Is Sensitive to Activity Dynamics</title>
<p>Our model predicts that a high learning rate is required for differentiation: As shown in our simulation of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>), if connections between the unique features of the competitor and the (formerly) shared features are not sufficiently weakened after one trial, the shared features will be strongly reactivated when the competitor is next presented; in the model, this reactivation of shared features leads to either restrengthening of the previously-weakened connections (“un-doing” the differentiation) or integration of the target and competitor memories.</p>
<p>We also found that differentiation is highly sensitive to activity dynamics. Anything that affects how strongly the competitor comes to mind can impact the kinds of representational change that are observed. We used a variety of methods to influence how strongly competitors come to mind in the three models, but this is shown particularly clearly in the simulation of <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>) where we modulated the oscillation amplitude. The results from this simulation show that the direction of representational change (i.e., differentiation vs. integration) within a given condition (interleaved or blocked) can switch depending on how much the competitor comes to mind.</p>
<p>These results have implications for where to look for differentiation in the brain. Our finding that differentiation requires a high learning rate suggests that differentiation will be more evident in the hippocampus than in neocortex, insofar as hippocampus is thought to have a higher learning rate than neocortex (<bold><italic><xref ref-type="bibr" rid="c27">McClelland et al., 1995</xref></italic></bold>). In keeping with this prediction, numerous studies have found differentiation effects in hippocampus but not in neocortical regions involved in sensory processing (e.g., <bold><italic>Chanales et al., 2017</italic></bold>; <bold><italic>Favila et al., 2016</italic></bold>; <bold><italic>Zeithamova et al., 2018</italic></bold>). These modeling results further suggest that, in cases where differentiation has been observed in neocortex (e.g., <bold><italic>Schlichting et al., 2015</italic></bold>, who found differentiation in anterior mPFC and other neocortical regions), these neocortical differentiation effects may be “propped up” by top-down feedback from differentiated representations in the hippocampus. This implies that disruptions of hippocampal processing (e.g., lesions, stimulation) will eliminate these neocortical differentiation effects; we plan to test this prediction in future work.</p>
<p>Additionally, the simulations where we adjusted the oscillation amount (using our model of <bold><italic>Schlichting et al., 2015</italic></bold>) imply that differentiation will be most evident in brain regions where it is relatively hard to activate competitors. Given the U shape of the NMPH learning rule, limiting competitor activity makes it less likely that plasticity will “cross over” from weakening (and differentiation) to strengthening (and integration). Thus, within the hippocampus, subregions with sparser activity (e.g., dentate gyrus, and to a lesser extent, CA3; <bold><italic>Barnes et al., 1990</italic></bold>; <bold><italic><xref ref-type="bibr" rid="c19">GoodSmith et al., 2017</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c50">West et al., 1991</xref></italic></bold>) will be more prone to differentiation. There is strong empirical support for this prediction. For example, <bold><italic><xref ref-type="bibr" rid="c48">Wammes et al</xref>.</italic></bold> (<bold><italic>2022</italic></bold>) manipulated the similarity of stimuli in a statistical learning experiment and found that moderate levels of visual similarity were associated with significant differentiation in the dentate gyrus but not other subregions. Also, numerous studies have found greater differentiation in dentate gyrus / CA3 than in CA1 (e.g., <bold><italic>Dimsdale-Zucker et al., 2018</italic></bold>; <bold><italic>Wanjia et al., 2021</italic></bold>; <bold><italic>Molitor et al., 2021</italic></bold>; <bold><italic>Kim et al., 2017</italic></bold>; but see <bold><italic><xref ref-type="bibr" rid="c54">Zheng et al., 2021</xref></italic></bold>).</p>
<p>A corollary of the model’s prediction that a high learning rate is required for differentiation is that, when differentiation does occur, it should happen abruptly. That is, when the preconditions for differentiation (fast learning, moderate competitor activity) are met, differentiation should be fully evident the next time the competitor is presented. In practice, testing this prediction about abrupt differentiation is challenging because it is not always clear <italic>when</italic> (in the time course of learning) to look for the abrupt change. For the sake of simplicity, we set up our model so the key moment of competition that drives differentiation occurs on the first trial. However, in actual experiments, the timing of this key moment of competition (and the ensuing differentiation) may vary across stimuli. For example, if a participant was inattentive the first time a stimulus was presented, this could delay the onset of competition. If each pair of items has an abrupt change at a different point in the experiment, it could look as though learning is gradual if the time courses of all pairs are averaged during analysis. For instance, <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) found that the percentage of color responses away from the pairmate (indicating repulsion) increased gradually over learning blocks; this could reflect a truly gradual change or it may be an aggregate of multiple abrupt changes occurring at different times.</p>
<p>One way to address this problem would be to model each item’s repulsion timecourse using either a gradual function or a step function and see which fits better. Another approach is to use converging behavioral data to identify the moment of differentiation, and then “time lock” the neural analysis to that moment. <bold><italic>Wanjia et al.</italic></bold> (<bold><italic>2021</italic></bold>) did exactly this: They identified the moment when participants were first able to confidently recall the correct associates that had been linked to a set of pairmates (visually similar scenes, as in <bold><italic>Favila et al., 2016</italic></bold>), and then looked before and after that moment at the neural similarity of the pairmates. As predicted by our model, differentiation was not evident before this point, and it was clearly evident after this point. Yet another approach would be to use neural activity to identify the trial when a competitor first activates, and then look for dif-ferentiation after this point. There are several practical challenges with this approach, however. One challenge is that, although moderate activity is predicted to lead to differentiation, stronger activity is predicted to lead to integration, and there is no <italic>a priori</italic> way to determine whether a given level of measured activity (e.g., using fMRI decoding) corresponds to the moderate-activity or high-activity portion of the U-shaped curve (<bold><italic>Ritvo et al., 2019</italic></bold>). Another issue is that, for similar pairmates, it can be difficult to tease them apart neurally (e.g., if you are looking at one barn, it can be difficult to sensitively detect additional neural activity of a competing, similar barn). One way to address this challenge is to link pairmates to associates from other categories (e.g., linking one pairmate to a scene and other pairmate to a face), and then look for activity of the associated category (e.g., during viewing of the face-linked pairmate, look for scene activity as a proxy for retrieval of the scene-linked pairmate); for an example of this approach see <bold><italic>Molitor et al.</italic></bold> (<bold><italic>2021</italic></bold>).</p>
</sec>
<sec id="s7b">
<title>Asymmetry of Representational Change</title>
<p>Our model predicts that representational change will often be asymmetric. Specifically, the model predicts that differentiation will always be asymmetric, such that the item that first pops up as a competitor is the one that distorts. By contrast, integration in the model is sometimes symmetric and sometimes asymmetric (such that the hidden-layer representation of one item flips to the hidden-layer representation of the other).</p>
<p>As discussed earlier, testing predictions about asymmetric representational change requires a measurement of how much <italic>each individual item</italic> has moved as a result of learning. To make this measurement, it is necessary to collect both pre-learning and post-learning snapshots for each pairmate; although some fMRI studies of differentiation have done this (<bold><italic>Wammes et al., 2022</italic></bold>; <bold><italic>Schlichting et al., 2015</italic></bold>; <bold><italic><xref ref-type="bibr" rid="c43">Schapiro et al., 2012</xref></italic></bold>; <bold><italic>Kim et al., 2017</italic></bold>; <bold><italic>Molitor et al., 2021</italic></bold>; <bold><italic>Wanjia et al., 2021</italic></bold>), others have not (<bold><italic>Chanales et al., 2017</italic></bold>; <bold><italic>Favila et al., 2016</italic></bold>; <bold><italic>Dimsdale-Zucker et al., 2018</italic></bold>; <bold><italic>Zeithamova et al., 2018</italic></bold>). Importantly, even with a pre-post comparison, there is still the matter of determining which pairmate will anchor and which will distort. Our model predicts that the pairmate that pops up first as the competitor is the one that will distort, but in practice it is not trivial to identify which pairmate will pop up first. For example, we simplified our simulation of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) by pre-wiring strong memories for both pairmates before presenting one of the pairmates (pairmate 1) to the network. In this situation, pairmate 2 pops up as a competitor when pairmate 1 is studied, so pairmate 2 repels away from pairmate 1 and not vice versa (<bold><italic><xref rid="fig4" ref-type="fig">Figure 4</xref></italic></bold>B). However, in the actual <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) experiments, encoding strength can vary across trials for numerous reasons (e.g., fluctuating attention); if pairmate 1 is the first to establish a strong representation, it will pop up and distort when pairmate 2 is next studied, but if pairmate 2 is the first to establish a strong representation, it will pop up and distort when pairmate 1 is next studied. This kind of encoding variability makes it difficult to predict <italic>a priori</italic> which item in a given pair will distort in the actual <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) study.</p>
<p>One way to predict the asymmetry is to use a paradigm where we can be more confident which item will be the first to pop up as a competitor. For instance, an AX-BX paradigm using blocked trials like the one used by <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>) may be useful, because all AX trials occur before any BX trials. As such, we can expect that A will pop up as a competitor in response to B (and thus be the memory that distorts) and not vice versa. Studies that rely on the retrieval practice paradigm (or the reverse retrieval-induced forgetting paradigm) to look at representational change (<bold><italic>Hulbert and <xref ref-type="bibr" rid="c33">Norman, 2015</xref></italic></bold>) may also be useful, because one item in each pair (Rp+) undergoes retrieval practice whereas the other (Rp-) item does not (it is either restudied, or not presented at all during the retrieval practice phase). This arrangement makes it more likely that the Rpitem will pop up as a competitor in response to the Rp+ item than vice versa. Another approach would be to use neural activity to predict which item would distort. For instance, competitor activity could be measured on a trial-by-trial basis as pairmates are studied to determine which pairmate is the first to pop up as a competitor; this approach would face the same challenges noted above (i.e., the difficulty of teasing apart target-related activity from competitor-related activity, which could possibly be addressed using the approach described by <bold><italic>Molitor et al., 2021</italic></bold>, and the difficulty of determining whether activity is moderate or strong, which is less easily addressed).</p>
<p>The asymmetry of differentiation also has implications for how to measure differentiation effects more generally, even when one is not trying to detect asymmetry. In paradigms like <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>), our model predicts that only one item in each pair will repel. This implies that, if you measure repulsion by looking at all items (i.e., both items in a pair), you will be averaging across the pairmate that moved and the pairmate that stayed put, weakening the measured effect. Statistically, it is more powerful to use designs where there is a way of predicting <italic>a priori</italic> which item will shift and which will anchor, so you can focus on the subset of items that shift without “diluting” the analysis by including items that anchor.</p>
</sec>
<sec id="s7c">
<title>Limitations and Open Questions</title>
<p>Our model can account for differentiation and integration across several scenarios. We think this provides important computational support for the NMPH explanation of representational change, and useful predictions for future work. Nonetheless, there are several ways our model can be extended in the future.</p>
<p>We intentionally kept our model very simple in order to create a “sandbox” to explore the dynamics at play during learning. We used no initial study task for our model, and we instead opted for pre-wired connections in order to precisely manipulate the initial hidden-layer overlap between the pairmates and the relative strengths of their representations.</p>
<p>Rather than skipping initial stimulus learning and focusing on the first moment that competition happens, future work can investigate the trials leading up to this moment in the course of learning. For instance, our model of <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>) instantiates interleaved vs. blocked learning by changing the initial weights connecting the hidden layer to the unit representing the shared associate in the output layer. Future models could instead show stimuli in a blocked or interleaved fashion with learning turned on, which should lead to the kind of weights we pre-wired into the model.</p>
<p>The model could also be expanded to be more biologically realistic. For example, instantiating the NMPH in a more detailed model of the hippocampus (e.g., <bold><italic>Schapiro et al., 2017</italic></bold>; <bold><italic>Norman and <xref ref-type="bibr" rid="c35">O’Reilly, 2003</xref></italic></bold>) would allow us to simulate the contributions of different hippocampal subfields to representational change (e.g., contrasting the monosynaptic and trisynaptic pathways; <bold><italic>Schapiro et al., 2017</italic></bold>). Extending this further, building a model that incorporates both hippocampal and neocortical regions would make it possible to explore how NMPH learning in the hippocampus can support neocortical learning. Although our simulations suggest that neocortex on its own cannot enact differentiation via NMPH learning (due to neocortex’s slow learning rate, which causes it to “relapse” and reabsorb formerly shared units), we hypothesize that — in the longer term — hippocampus may be able to act as a teacher to support long-lasting differentiation within neocortex. Specifically, we hypothesize that — once differentiated hippocampal representations have been formed — these representations can provide a source of top-down activity to the unique features of the corresponding neocortical representations (e.g., unique features of the similar barns in <bold><italic>Favila et al., 2016</italic></bold>). This hippocampally-mediated attention to unique features in neocortex may help neocortex (gradually) learn to represent and leverage subtle differences between pairmates. We will explore these ideas in future simulations.</p>
<p>Also, our keep-things-simple approach led us to focus on NMPH learning in these simulations; in future work, we plan to explore how NMPH interacts with error-driven (supervised) learning. As discussed in the <italic>Introduction</italic>, supervised learning is not sufficient to explain effects modeled here. However, there is widespread agreement that error-driven learning happens in the brain (although its mechanisms are still under active investigation; <bold><italic><xref ref-type="bibr" rid="c37">Richards et al., 2019</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c36">Payeur et al., 2021</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c25">Lillicrap et al., 2020</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c51">Whittington and Bogacz, 2019</xref></italic></bold>), and it may interact with and/or complement the NMPH principles explored here in interesting ways. In the computer vision literature, supplementing supervised learning algorithms with unsupervised learning algorithms (some of which are very similar to the NMPH, in that they pull together the representations of strongly similar items and push apart the embeddings of moderately similar items; <bold><italic><xref ref-type="bibr" rid="c55">Zhuang et al., 2019</xref></italic></bold>) can boost model performance in some circumstances (<bold><italic><xref ref-type="bibr" rid="c56">Zhuang et al., 2021</xref></italic></bold>). However, mixing unsupervised with supervised learning in models of neocortex has a substantial drawback: Once an unsupervised learning algorithm has decided that two stimuli are similar enough to pull together their representations, it can be very difficult to pull them apart again, even if this needs to be done to solve a task; this point was initially demonstrated in the domain of auditory learning by <bold><italic><xref ref-type="bibr" rid="c28">McClelland et al</xref>.</italic></bold> (<bold><italic>1999</italic></bold>) and <bold><italic><xref ref-type="bibr" rid="c26">McCandliss et al</xref>.</italic></bold> (<bold><italic>2002</italic></bold>). In this situation, hippocampal differentiation (which is <italic>not</italic> part of extant computer vision models) may play a key role in helping neocortex avoid this kind of “premature collapse” of representations. In future work, we also plan to explore the influence of other biologically inspired learning principles, including the principle of metaplasticity (whereby the transition points between strengthening and weakening are adjusted as a function of activity), which has previously been shown to play an important role in NMPH-style learning (<bold><italic><xref ref-type="bibr" rid="c5">Bear, 2003</xref></italic></bold>).</p>
<p>Yet another direction to explore is how cognitive control and attention modulate representational change. The simulations described in this paper provide an existence proof of how — if the conditions are right (e.g., moderate competitor activity, suitably high learning rate) — differentiation can occur automatically, without participants having to deliberately focus their attention on discriminative features of the pairmates. However, it is surely the case that attention can modulate these learning effects (<bold><italic>Amer and Davachi, 2023</italic></bold>; see the <italic>Practical Advice</italic> section in the <italic>Methods</italic> for a brief discussion of this point).</p>
</sec>
</sec>
<sec id="s8">
<title>Summary</title>
<p>The model presented in this paper provides a concrete computational instantiation of the NMPH account of representational change set forth in <bold><italic>Ritvo et al.</italic></bold> (<bold><italic>2019</italic></bold>). By modulating competitor activity in different ways (by varying stimulus similarity, presence of shared associates, learning curriculum, and inhibitory dynamics) and tracking how this affects learning, our model serves several purposes: It provides an “existence proof” of how the NMPH can explain otherwise-puzzling findings regarding representational change (e.g., why linking to a shared associate can promote differentiation); it provides principled new explanations of certain patterns in the literature (e.g., why differentiation is more frequently observed in the hippocampus than in neocortex); and it makes novel, testable predictions (e.g., regarding the asymmetry of differentiation). Although more work remains to be done to explore the consequences of this U-shaped learning function for representational change, we hope our model can be useful in framing future modeling and empirical research on learning.</p>
</sec>
<sec id="s9">
<title>Methods</title>
<sec id="s9a">
<title>Model Architecture</title>
<p>We built our computational model using the Leabra algorithm (<bold><italic>O’Reilly et al., 2012</italic></bold>) within the Emergent neural network simulation software (<bold><italic>Aisa et al., 2008</italic></bold>), which is written in the programming language Go. We constructed the model as described in <italic>Basic Network Properties</italic>, and adapted the parameters to model the three individual studies.</p>
</sec>
<sec id="s9b">
<title>Approach to Parameterization and Data Fitting</title>
<p>The overall goal of this modeling work is to account for key empirical regularities regarding differentiation and integration and to establish boundary conditions on these regularities. As such, the modeling work described below focuses more on qualitative fits to general properties of the data space than on quantitative fits to results from specific studies. Automatic parameter optimization is not feasible for this kind of model, given the large number of model parameters and the highly interactive, nonlinear nature of competitive dynamics in the model; consequently, model fitting was done by hand.</p>
<p>While the core model architecture and dynamics were the same for all three simulations, the specific parameters that we used differed in small ways across the three simulations. The need to make these parameter adjustments is a consequence of the small-scale nature of the model. In a more realistic, large-scale model with more stored knowledge, changing the structure of what is being learned in the to-be-simulated paradigm would not meaningfully affect the overall knowledge state of the model (adding two memories if you already have thousands is not a big deal) and thus would not require parameter changes. However, if you are starting with a “blank brain”, the exact way that you structure the to-be-learned memories matters; for example, having a topographic color projection to represent repulsion effects in our simulation of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>) can have large effects on network dynamics that require “downstream” adjustments in other parameters.</p>
<p>To generate the results shown in the figures here, we ran the model 50 times, each time starting with a different random seed. Results plots show the mean level of performance across model runs and the 95% confidence interval around the mean.</p>
<sec id="s9b1">
<title>Activity and Inhibitory Dynamics</title>
<p>Emergent simplifies the discrete on-off firing of individual neurons into a rate code approximation where a unit’s activity can range from 0 to 1; this rate code reflects the unit’s current level of excitatory and inhibitory inputs. A given unit M’s excitatory input is a function of the activity of all other units N connected to it, weighted by the strengths of the connections between the N units and M. The function relating excitatory input to activity (after accounting for inhibition; see below and <bold><italic>O’Reilly et al., 2012</italic></bold>) is S-shaped and bounded between 0 to 1, where the steepness of the function is modulated by a gain factor. Lowering the gain creates a more graded response, which enables moderate pop up of competitor units. The gain for each layer is written in <bold><italic><xref rid="tbl1" ref-type="table">Table 1</xref></italic></bold> (<italic>XX1 Gain</italic>), along with the other activity and inhibitory parameters for these models. When an external input is clamped to a layer, the external input is multiplied by a <italic>Clamp Gain</italic> factor, which modulates how strongly it should contribute to activity compared to other excitatory inputs that the unit is receiving (from elsewhere in the network).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><p>Parameters for layer inhibitory and activity dynamics. <italic>kWTA Point</italic> = a value between 0 and 1, which indicates how far toward the <italic>k</italic> + 1<sup><italic>th</italic></sup> unit to place the current inhibitory level (the higher <italic>kWTA Point</italic>, the lower the inhibition value). <italic>Target Diff</italic> = the threshold for determining whether units after the <italic>k</italic><sup><italic>th</italic></sup> unit should be allowed to be active (see text). <italic>Osc</italic> = the amplitude of the oscillation function that multiplies the overall inhibition level of the layer. Note that for the model of <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>), we tested three different hidden-layer oscillation amounts: 0.0623, .0525 and .09. <italic>XX1 Gain</italic> = the multiplier on the S-shaped activity function, where lower values means that activity will be more graded. <italic>Clamp Gain</italic> multiplies the external input, modifying how strongly it contributes to the activity of the layer.</p></caption>
<graphic xlink:href="535239v2_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>A unit’s activity is also modulated by the inhibitory dynamics in the layer. We implemented inhibition using a variant of the <italic>k-winners take all</italic> (kWTA) algorithm (<bold><italic>O’Reilly and Munakata, 2000</italic></bold>). This algorithm imposes a “set point”-like behavior on inhibition, ensuring that at most <italic>k</italic> units are allowed to activate in a layer. In the standard version of the kWTA algorithm, the units in a layer are ranked in terms of the amount of inhibition that would be needed to put that unit at the threshold of activating, given its current excitatory input. Then, inhibition is set such that only the <italic>k</italic> highestranked units are able to reach the activity threshold.</p>
<p>In our simulations, we adjusted the kWTA algorithm to give the model the ability to activate more than <italic>k</italic> units in certain circumstances (<bold><italic><xref rid="fig11" ref-type="fig">Figure 11</xref></italic></bold>). This flexibility is helpful for integration: Allowing more than <italic>k</italic> units to be active makes it possible for the model to incorporate units from both pairmates into the new, integrated representation. To provide this flexibility, we adjusted the kWTA algorithm to allow units that are tied in the ranking (within a threshold amount reflected by the <italic>Target Diff</italic> parameter) to activate as well. We also included a cap on the total number of units allowed to activate even with the tie (reflected by the <italic><bold>K_M</bold>ax</italic> parameter). So if <italic>k</italic> = 6 and <italic><bold>K_M</bold>ax</italic> = 10, the top 6 units will be allowed to activate, as well as optionally any units beyond the top 6 that are tied (within some threshold specified by <italic>Target Diff</italic>), but no more than 10 units can be active.</p>
<fig id="fig11" position="float" orientation="portrait" fig-type="figure">
<label>Figure 11.</label>
<caption><p>Schematic of adjusted KWTA algorithm. Units are ranked according to the amount of inhibition that would be needed to put the unit at threshold of activity. This is proportional to excitation: The more excitation the unit receives, the more inhibition is needed to cancel out the excitation and put the unit at threshold. In the classic KWTA algorithm, inhibition is set such that only the <italic>k</italic> highest ranked units activate. We added a <italic>Target Diff</italic> parameter to potentially allow more units to activate, if units are “tied” with the <italic>k</italic><sup><italic>th</italic></sup> unit. If a unit below the <italic>k</italic><sup><italic>th</italic></sup> unit in the rank ordering of units is within <italic>Target Diff</italic> of the <italic>k</italic><sup><italic>th</italic></sup> unit, then it is considered to be “tied” with the <italic>k</italic><sup><italic>th</italic></sup> unit, and it is allowed to activate. In this example, the 6th, 7th, and 8th unit are tied in the ranking, because the difference is less than <italic>Target Diff</italic>. Consequently, inhibition is set such that 8 units activate.</p></caption>
<graphic xlink:href="535239v2_fig11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Note that, in addition to allowing more than <italic>k</italic> units to be active, this modification also helps to solve an issue with the classic implementation of kWTA that emerges when the inhibition needed to put the <italic>k</italic><sup><italic>th</italic></sup> unit at threshold is very close to the value needed for the <italic>k</italic> + 1<sup><italic>th</italic></sup> unit. In the classic implementation of kWTA, this situation results in the <italic>k</italic><sup><italic>th</italic></sup>unit’s activity being very close to zero (since it is only slightly above threshold); effectively, fewer than <italic>k</italic> units end up being active. This issue would occur, for example, with the configuration of values shown in <bold><italic><xref rid="fig11" ref-type="fig">Figure 11</xref></italic></bold>; with classic kWTA, the 5th and 6th units would be just above threshold and thus barely active. This issue can make it difficult for the competitor to pick up new units in conditions that lead to differentiation (because the new units often receive very similar levels of excitation). With the modified kWTA algorithm, the model is free to find a “break point” beyond the <italic>k</italic><sup><italic>th</italic></sup> unit that allows the new units to be more robustly active.</p>
<p>Lastly, inhibition is modulated by oscillations; these inhibitory oscillations play a key role in regulating the amount of competitor activity. The layer’s inhibition is initially constant (determined by the kWTA calculation described above), and then at cycle 125 is varied according to a sine wave (with amplitude set by the parameter <italic>Osc</italic>) until the end of the trial at cycle 200. Concretely, inhibition is sinusoidally raised above baseline from cycles 125 to 163, and then lowered below baseline from cycles 164 to 200. The raising of inhibition does not have much impact on the network activity (because the external clamping is strong enough to offset the raising of inhibition), but lowering the inhibition allows the competitors to activate.</p>
</sec>
<sec id="s9b2">
<title>Projections Between Layers</title>
<p>The weight of any given connection between two units could range from 0 to 1. The two input layers are connected to the hidden layer, which is in turn connected to the output layer. The hidden layer also has recurrent connections. Generally the output layer does not have recurrent connections, except for our model of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>), where we included fixed-strength recurrent output-to-output connections to simulate topographically-organized color representations. All projections were bidirectional: Activity was allowed to flow forwards and backwards through the network. Parameters for each bidirectional projection were identical except for the <italic>Wt Scale</italic>, which indicated the overall strength of the projection from one layer to another.</p>
<p>All layers that were connected were connected fully — that is, all units in one layer were connected to all units in the other layer. Most of these connections were random and low in magnitude, except for a set of pre-wired connections that were stronger, as described in <italic>Basic Network Properties</italic>. Any pre-wired connections that differed between versions of the model are included in the sections of this paper on the set up of each model. All pre-wired, non-random connections were set to have a strength of 0.99 unless otherwise indicated. The parameters for the random connections are shown in <bold><italic><xref rid="tbl2" ref-type="table">Table 2</xref></italic></bold>.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><p>Projection parameters: <italic>Wt Range</italic> = range of the uniform distribution used to initialize the random weights between each projection (range does not include the maximally strong pre-wired connections described in the text, which were set to 0.99 unless stated otherwise). <italic>Wt Scale</italic> = the scaling of the projection, operationalized as an absolute multiplier on the weights in the projection.</p></caption>
<graphic xlink:href="535239v2_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>The random low-level connections constitute one of two sources of variance in the model, the other being the trial order for most simulations (described below in <italic>Stimulus Presentation</italic>).</p>
</sec>
<sec id="s9b3">
<title>A Note on Prewiring Representations</title>
<p>In our model, our practice of “prewiring” memory representations for the A and B pairmates serves two functions. In some cases, it is meant to stand in for actual training (as in the blocked / inter-leaved manipulation; the connections supporting the AX association are prewired to be stronger in the blocked condition than in the interleaved condition). However, the other, more fundamental role of prewiring is to ensure that the A and B input patterns evoke well-defined representations in the hidden layer. In the real brain, this happens automatically because the weight landscape has been extensively sculpted by both experience and evolution. In our small-scale model, we are effectively starting with a “blank brain”; in the absence of prewiring, the A and B inputs would activate an overly diffuse representation that does not support good memory performance. As such, prewiring in our model is necessary for proper functioning. The presence of prewired A and B representations should therefore not be interpreted as reflecting a particular training history (except in the blocked / interleaved case above); rather, these prewired representations constitute the minimum step we would take to ensure sensible competitive dynamics in our small-scale model.</p>
</sec>
</sec>
<sec id="s9c">
<title>Learning</title>
<p>We used only unsupervised NMPH learning in this model since we wanted to test whether the NMPH was sufficient to produce the representational changes observed in these experiments. Each of the projections in the model could be modified through learning, except for the topographic output-to-output projection in the model of <bold><italic>Chanales et al.</italic></bold> (<bold><italic>2021</italic></bold>).</p>
<p>After each training trial, connection weights were adjusted based on the activity of the units on that trial. For each pair of connected units, the coactivity is computed as the product of both units’ short-term average activity. The U-shaped function is defined by five parameters (<bold><italic><xref rid="fig12" ref-type="fig">Figure 12</xref></italic></bold>), and is applied to this coactivity value to calculate the magnitude and direction of the weight change.</p>
<fig id="fig12" position="float" orientation="portrait" fig-type="figure">
<label>Figure 12.</label>
<caption><p>U-shaped learning function. <italic>DThr, D Rev</italic>, and <italic>T hr P</italic> are X-axis coordinates. <italic>D Rev M ag</italic> and <italic>D M ax M ag</italic> are Y-axis coordinates, and indicate the amount of peak weakening or strengthening.</p></caption>
<graphic xlink:href="535239v2_fig12.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>These five parameters were set separately for each projection in each model, such that — when moderate competitor pop-up occurred — the competitor-to-shared connections would be severed. All reciprocal connections (e.g., output-to-hidden and hidden-to-output) had identical U-shaped functions. Once the U-shaped function was set for a connection, those were the parameters used for all runs of the model, in all conditions. The parameters for each learning function can be found in <bold><italic><xref rid="tbl3" ref-type="table">Table 3</xref></italic></bold>.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><p>Learning parameters: All parameters are defined in <xref rid="fig12" ref-type="fig">Figure 12</xref>. All bidirectional connections used the same parameters for the U-shaped learning function (e.g., the parameters for item-to-hidden matched the parameters for hidden-to-item).</p></caption>
<graphic xlink:href="535239v2_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>To calculate the final change in weight, we took the weight change value obtained from the above U-shaped function and multiplied it by a scalar learning rate parameter, <italic>LRate</italic>. <italic>LRate</italic> was set to 1 for all of our simulations except for the simulations where we explicitly manipulated learning rate.</p>
</sec>
<sec id="s9d">
<title>Stimulus Presentation</title>
<p>Each model run included only two stimuli — pairmates A and B. This modeling choice reflects our assumption that the competitive dynamics of interest occur between pairmates and not across pairs (given that pairs are typically constructed to be dissimilar to other pairs and thus are not confusable with them). The middle unit in the category layer was active for both pairmates (reflecting input features shared between them) and distinct units in the item layer were active for pairmates A and B. These external inputs were the same for all models. Every epoch consisted of a single presentation of A and B, in a random order, except in our model of <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>) where B was always shown first (and, in the blocked condition, no A trials followed).</p>
<p>We ran a test epoch before the first training epoch to attain a “baseline” measure of the repre-sentations of A and B, and we ran another test epoch after each subsequent training epoch. The only difference between test and training epochs was that 1) test epochs included no oscillations, so we could get a pure guess for the state of the representation, and 2) connection weights were not adjusted at the end of test epochs (i.e., learning was turned off). We ran the model for 20 train/test epochs, and the final pattern of unit activity for each test epoch was recorded and used for the analyses.</p>
</sec>
<sec id="s9e">
<title>Practical Advice for Getting the Model to Show Differentiation</title>
<p>As discussed above, differentiation is highly sensitive to activity dynamics. To obtain differentiation, pairmate 2 (the competitor) must activate moderately on trial 1, and the following criteria must be met on trial 2:
<list list-type="order">
<list-item><p>On trial 2 (when pairmate 2 is presented), hidden-layer units that were initially shared between the pairmates cannot be reactivated.</p></list-item>
<list-item><p>On trial 2, the unique hidden-layer units associated with pairmate 2 must be reactivated. This seems straightforward, but meeting these conditions can be difficult. Sometimes the parameter adjustments needed to satisfy #1 make #2 harder to satisfy, and vice versa. Most of the failures to differentiate that we observed happened if these two conditions were not fully met.</p></list-item>
</list>
</p>
</sec>
<sec id="s9f">
<label>1.</label><title>On Trial 2, Pairmate 1 Hidden Units Cannot Be Reactivated</title>
<p>Even if some weakening of competitor-to-shared units has occurred on trial 1, it is possible for pairmate 1 units to activate on trial 2. If this happens, any initial differentiation effects are undone. This happens if the excitation for pairmate 1 units remains too high, and there are several potential reasons why this might occur.</p>
<p>We have discussed one potential cause already, when learning rate is low and the competitor-to-shared connections are only mildly weakened on trial 1. Additionally, if only some (but not all) competitor-to-shared connections weaken, the intact connections may reactivate pairmate 1 on trial 2, undoing any initial differentiation. For example, if variation in the random connection weights is too high, not all competitor units will pop up the same amount. This can lead to a situation where some of the competitor-to-competitor coactivity values are greater than some of the competitor-to-shared coactivity values, making it impossible to preserve within-competitor links while simultaneously severing links between competitor units and shared units (<bold><italic><xref rid="fig13" ref-type="fig">Figure 13</xref></italic></bold>).</p>
<fig id="fig13" position="float" orientation="portrait" fig-type="figure">
<label>Figure 13.</label>
<caption><p>How subtle changes to activity can affect representational change: (A) Two sample activity patterns in the hidden layer during the first trial are shown. Units are labelled as belonging to either pairmate 1, pairmate 2, or both, and vertical bars indicate activity level (along with activity values). A moderate amount of pop-up of pairmate 2 occurs, which should lead to differentiation if the competitor-to-shared connections are appropriately weakened. Although the two patterns are very similar, the bottom pattern has slightly more variable activity, which could arise if the level of random noise in the strengths of the hidden-to-hidden connections is higher. (B) A U-shaped function for each activity pattern is shown, with the coactivity for hidden-to-hidden connections plotted along the X axis. In the top example, all competitor-to-competitor coactivities are lower than all competitor-to-target/shared coactivities, which are in turn lower than all target/shared-to-target/shared coactivities. This means that it is possible to preserve all of the competitor-to-competitor connections while severing all of the connections to the shared units. However, in the bottom example, there is some interlacing of the coactivity values for competitor-to-competitor and competitor-to-target/shared connections; this scenario makes it impossible to fully preserve all competitor-to-competitor connections while severing all competitor-to-target/shared connections. With the U-shaped function shown here, the pattern of activity in the bottom example will result in sparing of some of the competitor-to-shared connections, making it less likely that differentiation will occur.</p></caption>
<graphic xlink:href="535239v2_fig13.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Another relevant parameter is the oscillation amplitude <italic>Osc</italic>, which can shift the placement of competitor-to-shared coactivity on the U-shaped function. If the oscillation is not set to the appropriate amplitude, the resulting level of competitor unit activity may not cause appropriate severing of competitor-to-shared connections. This can be seen in the results of our model of <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>): When the oscillation amount is adjusted, this can have strong effects on the representational changes that occur (<bold><italic><xref rid="fig10" ref-type="fig">Figure 10</xref></italic></bold>A and D).</p>
<p>Yet another factor to consider is how much excitation the hidden representation of pairmate 1 receives on trial 2. There are some projections that will always send excitation to pairmate 1 on trial 2, so some amount of excitation of the hidden pairmate 1 units is unavoidable. One projection for which this is true (for all models) is the category-to-hidden projection, since the category unit is part of both the A and B input patterns. Some of the models also have other units that maintain a connection to both A and B; for instance, in the shared-face condition of our model of <bold><italic>Favila et al.</italic></bold> (<bold><italic>2016</italic></bold>) and also our model of <bold><italic>Schlichting et al.</italic></bold> (<bold><italic>2015</italic></bold>), the shared output unit is connected to both items’ hidden representations. In the model, lowering the strengths of these projections (i.e., category-to-hidden, output-to-hidden) by adjusting the corresponding <italic>Wt Scale</italic> parameters will reduce the amount of excitation received by pairmate 1. In an actual experiment, participants could accomplish this by attending less to shared features. As noted earlier, selective attention is not <italic>necessary</italic> for differentiation to occur in our model, but this account suggests that attention could modulate the strength of differentiation effects by modulating the relative influence of shared vs. unique features (for discussion of potential mechanisms of these effects, see <bold><italic>Amer and Davachi, 2023</italic></bold>).</p>
<p>Learning that occurs in the category-hidden and output-hidden projections can also affect the relative amount of excitation received by the hidden representations of pairmate 1 and pairmate 2. On trial 1, if shared input/output features are strongly activated and unique hidden features of pairmate 2 are moderately activated, then NMPH learning can result in weakening of the connections between the shared input/output features and the unique hidden features of pairmate 2. If this occurs, then, on trial 2, shared input/output features will selectively send excitation to pairmate 1, but not pairmate 2, which further increases the odds that pairmate 1’s hidden representation will be activated (thwarting the differentiation effect). In our simulations, we were able to avoid this problem by using a small <italic>DRevMag</italic> value for projections from shared input/output features, which effectively reduces the amount of weakening that occurs for these projections.</p>
</sec>
<sec id="s9g">
<label>2.</label><title>On Trial 2, Unique Pairmate 2 Hidden Units Must Be Reactivated</title>
<p>If connections within the pairmate 2 representation are weakened too much on trial 1 (when it pops up as a competitor), then, when pairmate 2 is presented as the target on trial 2, its hidden representation will not be accessible (i.e., the model will fail to reactivate the unique parts of this hidden representation). When this happens, the hidden representation of pairmate 1 typically ends up being activated instead. This leads to the asymmetric form of integration, where the input units for pairmate 2 end up being linked to the hidden representation of pairmate 1.</p>
<p>Parameter adjustments that lower the amount of pop-up are helpful in addressing this issue; lowering pop-up shifts the competitor-to-competitor coactivities to the left on the U-shaped function, making it less likely that these connections will be weakened. For instance, decreasing the oscillation amount may be needed to make sure competitor-to-competitor connections are spared in trial 1. However, if the oscillation amount is decreased too much, it may also cause competitor-to-shared connections to be spared, as discussed in point #1 above. Successful differentiation requires “threading the needle” such that competitor-to-competitor connections are (relatively) spared but connections between competitor and shared units are severed.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements and Code Availability</title>
<p>The code for these simulations can be accessed at <ext-link ext-link-type="uri" xlink:href="https://github.com/PrincetonCompMemLab/neurodiff_simulations">https://github.com/PrincetonCompMemLab/neurodiff_simulations</ext-link>.</p>
<p>This work was supported by NIH R01 MH069456 awarded to K.A.N. and N.B.T-B.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Aisa</surname> <given-names>B</given-names></string-name>, <string-name><surname>Mingus</surname> <given-names>B</given-names></string-name>, <string-name><surname>O’Reilly</surname> <given-names>R</given-names></string-name>. <article-title>The emergent neural modeling system</article-title>. <source>Neural Networks</source>. <year>2008</year>; <volume>21</volume>(<issue>8</issue>):<fpage>1146</fpage>–<lpage>1152</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Amer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Davachi</surname> <given-names>L</given-names></string-name>. <article-title>Extra-hippocampal contributions to pattern separation</article-title>. <source>eLife</source>. <year>2023</year>; .</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Ballard</surname> <given-names>IC</given-names></string-name>, <string-name><surname>Wagner</surname> <given-names>AD</given-names></string-name>, <string-name><surname>McClure</surname> <given-names>SM</given-names></string-name>. <article-title>Hippocampal pattern separation supports reinforcement learning</article-title>. <source>Nature Communications</source>. <year>2019</year>; <volume>10</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Barnes</surname> <given-names>CA</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Mizumori</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Leonard</surname> <given-names>BW</given-names></string-name>, <string-name><surname>Lin</surname> <given-names>LH</given-names></string-name>. <article-title>Comparison of spatial and temporal character-istics of neuronal activity in sequential stages of hippocampal processing</article-title>. <source>Progress in Brain Research</source>. <year>1990</year>; <volume>83</volume>:<fpage>287</fpage>–<lpage>300</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Bear</surname> <given-names>MF</given-names></string-name>. <article-title>Bidirectional synaptic plasticity: from theory to reality</article-title>. <source>Philosophical Transactions of the Royal Society of London Series B: Biological Sciences</source>. <year>2003</year>; <volume>358</volume>(<issue>1432</issue>):<fpage>649</fpage>–<lpage>655</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Bienenstock</surname> <given-names>EL</given-names></string-name>, <string-name><surname>Cooper</surname> <given-names>LN</given-names></string-name>, <string-name><surname>Munro</surname> <given-names>PW</given-names></string-name>. <article-title>Theory for the development of neuron selectivity: orientation speci-ficity and binocular interaction in visual cortex</article-title>. <source>Journal of Neuroscience</source>. <year>1982</year>; <volume>2</volume>(<issue>1</issue>):<fpage>32</fpage>–<lpage>48</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Brunec</surname> <given-names>IK</given-names></string-name>, <string-name><surname>Robin</surname> <given-names>J</given-names></string-name>, <string-name><surname>Olsen</surname> <given-names>RK</given-names></string-name>, <string-name><surname>Moscovitch</surname> <given-names>M</given-names></string-name>, <string-name><surname>Barense</surname> <given-names>MD</given-names></string-name>. <article-title>Integration and differentiation of hippocampal memory traces</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source>. <year>2020</year>; .</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Chanales</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Oza</surname> <given-names>A</given-names></string-name>, <string-name><surname>Favila</surname> <given-names>SE</given-names></string-name>, <string-name><surname>Kuhl</surname> <given-names>BA</given-names></string-name>. <article-title>Overlap among spatial memories triggers repulsion of hippocampal representations</article-title>. <source>Current Biology</source>. <year>2017</year>; <volume>27</volume>(<issue>15</issue>):<fpage>2307</fpage>–<lpage>2317</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Chanales</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Tremblay-McGaw</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Drascher</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Kuhl</surname> <given-names>BA</given-names></string-name>. <article-title>Adaptive repulsion of long-term memory representations is triggered by event similarity</article-title>. <source>Psychological Science</source>. <year>2021</year>; <volume>32</volume>(<issue>5</issue>):<fpage>705</fpage>–<lpage>720</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Cooper</surname> <given-names>LN</given-names></string-name>. <article-title>Theory of cortical plasticity</article-title>. <source>World Scientific</source>; <year>2004</year>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Detre</surname> <given-names>GJ</given-names></string-name>, <string-name><surname>Natarajan</surname> <given-names>A</given-names></string-name>, <string-name><surname>Gershman</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Norman</surname> <given-names>KA</given-names></string-name>. <article-title>Moderate levels of activation lead to forgetting in the think/no-think paradigm</article-title>. <source>Neuropsychologia</source>. <year>2013</year>; <volume>51</volume>(<issue>12</issue>):<fpage>2371</fpage>–<lpage>2388</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Diederich</surname> <given-names>S</given-names></string-name>, <string-name><surname>Opper</surname> <given-names>M</given-names></string-name>. <article-title>Learning of correlated patterns in spin-glass networks by local learning rules</article-title>. <source>Physical Review Letters</source>. <year>1987</year>; <volume>58</volume>(<issue>9</issue>):<fpage>949</fpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Dimsdale-Zucker</surname> <given-names>HR</given-names></string-name>, <string-name><surname>Ritchey</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ekstrom</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Yonelinas</surname> <given-names>AP</given-names></string-name>, <string-name><surname>Ranganath</surname> <given-names>C</given-names></string-name>. <article-title>CA1 and CA3 differentially support spontaneous retrieval of episodic contexts within human hippocampal subfields</article-title>. <source>Nature Communications</source>. <year>2018</year>; <volume>9</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Drascher</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Kuhl</surname> <given-names>BA</given-names></string-name>. <article-title>Long-term memory interference is resolved via repulsion and precision along diagnostic memory dimensions</article-title>. <source>Psychonomic Bulletin &amp; Review</source>. <year>2022</year>; p. <fpage>1</fpage>–<lpage>15</lpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Duncan</surname> <given-names>KD</given-names></string-name>, <string-name><surname>Schlichting</surname> <given-names>ML</given-names></string-name>. <article-title>Hippocampal representations as a function of time, subregion, and brain state</article-title>. <source>Neurobiology of Learning and Memory</source>. <year>2018</year>; <volume>153</volume>:<fpage>40</fpage>–<lpage>56</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Favila</surname> <given-names>SE</given-names></string-name>, <string-name><surname>Chanales</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Kuhl</surname> <given-names>BA</given-names></string-name>. <article-title>Experience-dependent hippocampal pattern differentiation prevents interference during subsequent learning</article-title>. <source>Nature communications</source>. <year>2016</year>; <volume>7</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Fernandez</surname> <given-names>C</given-names></string-name>, <string-name><surname>Jiang</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>SF</given-names></string-name>, <string-name><surname>Choi</surname> <given-names>HL</given-names></string-name>, <string-name><surname>Wagner</surname> <given-names>AD</given-names></string-name>. <article-title>Representational integration and differentiation in the human hippocampus following goal-directed navigation</article-title>. <source>Elife</source>. <year>2023</year>; <volume>12</volume>:<issue>e80281</issue>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Gluck</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Myers</surname> <given-names>CE</given-names></string-name>. <article-title>Hippocampal mediation of stimulus representation: A computational theory</article-title>. <source>Hippocampus</source>. <year>1993</year>; <volume>3</volume>(<issue>4</issue>):<fpage>491</fpage>–<lpage>516</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>GoodSmith</surname> <given-names>D</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>X</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>SH</given-names></string-name>, <string-name><surname>Song</surname> <given-names>H</given-names></string-name>, <string-name><surname>Burgalossi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Christian</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Knierim</surname> <given-names>JJ</given-names></string-name>. <article-title>Spatial representations of granule cells and mossy cells of the dentate gyrus</article-title>. <source>Neuron</source>. <year>2017</year>; <volume>93</volume>(<issue>3</issue>):<fpage>677</fpage>–<lpage>690</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Hanazawa</surname> <given-names>A</given-names></string-name>, <string-name><surname>Komatsu</surname> <given-names>H</given-names></string-name>, <string-name><surname>Murakami</surname> <given-names>I</given-names></string-name>. <article-title>Neural selectivity for hue and saturation of colour in the primary visual cortex of the monkey</article-title>. <source>European Journal of Neuroscience</source>. <year>2000</year>; <volume>12</volume>(<issue>5</issue>):<fpage>1753</fpage>–<lpage>1763</lpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Hulbert</surname> <given-names>J</given-names></string-name>, <string-name><surname>Norman</surname> <given-names>K</given-names></string-name>. <article-title>Neural differentiation tracks improved recall of competing memories following interleaved study and retrieval practice</article-title>. <source>Cerebral Cortex</source>. <year>2015</year>; <volume>25</volume>(<issue>10</issue>):<fpage>3994</fpage>–<lpage>4008</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Jiang</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>SF</given-names></string-name>, <string-name><surname>Guo</surname> <given-names>W</given-names></string-name>, <string-name><surname>Fernandez</surname> <given-names>C</given-names></string-name>, <string-name><surname>Wagner</surname> <given-names>AD</given-names></string-name>. <article-title>Prefrontal reinstatement of contextual task demand is predicted by separable hippocampal patterns</article-title>. <source>Nature Communications</source>. <year>2020</year>; <volume>11</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Kim</surname> <given-names>G</given-names></string-name>, <string-name><surname>Norman</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Turk-Browne</surname> <given-names>NB</given-names></string-name>. <article-title>Neural differentiation of incorrectly predicted memories</article-title>. <source>Journal of Neuroscience</source>. <year>2017</year>; <volume>37</volume>(<issue>8</issue>):<fpage>2022</fpage>–<lpage>2031</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Komatsu</surname> <given-names>H</given-names></string-name>, <string-name><surname>Ideura</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Kaji</surname> <given-names>S</given-names></string-name>, <string-name><surname>Yamane</surname> <given-names>S</given-names></string-name>. <article-title>Color selectivity of neurons in the inferior temporal cortex of the awake macaque monkey</article-title>. <source>Journal of Neuroscience</source>. <year>1992</year>; <volume>12</volume>(<issue>2</issue>):<fpage>408</fpage>–<lpage>424</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Lillicrap</surname> <given-names>TP</given-names></string-name>, <string-name><surname>Santoro</surname> <given-names>A</given-names></string-name>, <string-name><surname>Marris</surname> <given-names>L</given-names></string-name>, <string-name><surname>Akerman</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Hinton</surname> <given-names>G</given-names></string-name>. <article-title>Backpropagation and the brain</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2020</year>; <volume>21</volume>(<issue>6</issue>):<fpage>335</fpage>–<lpage>346</lpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>McCandliss</surname> <given-names>BD</given-names></string-name>, <string-name><surname>Fiez</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Protopapas</surname> <given-names>A</given-names></string-name>, <string-name><surname>Conway</surname> <given-names>M</given-names></string-name>, <string-name><surname>McClelland</surname> <given-names>JL</given-names></string-name>. <article-title>Success and failure in teaching the [r]-[l] contrast to Japanese adults: Tests of a Hebbian model of plasticity and stabilization in spoken language perception. Cognitive, Affective</article-title>, <source>&amp; Behavioral Neuroscience</source>. <year>2002</year>; <volume>2</volume>(<issue>2</issue>):<fpage>89</fpage>–<lpage>108</lpage>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>McClelland</surname> <given-names>JL</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>, <string-name><surname>O’Reilly</surname> <given-names>RC</given-names></string-name>. <article-title>Why there are complementary learning systems in the hippocam-pus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title>. <source>Psychological Review</source>. <year>1995</year>; <volume>102</volume>(<issue>3</issue>):<fpage>419</fpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>McClelland</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Thomas</surname> <given-names>AG</given-names></string-name>, <string-name><surname>McCandliss</surname> <given-names>BD</given-names></string-name>, <string-name><surname>Fiez</surname> <given-names>JA</given-names></string-name>. <article-title>Understanding failures of learning: Hebbian learning, competition for representational space, and some preliminary experimental data</article-title>. <source>Progress in Brain Research</source>. <year>1999</year>; <volume>121</volume>:<fpage>75</fpage>–<lpage>80</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Molitor</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Sherrill</surname> <given-names>KR</given-names></string-name>, <string-name><surname>Morton</surname> <given-names>NW</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Preston</surname> <given-names>AR</given-names></string-name>. <article-title>Memory reactivation during learning simultaneously promotes dentate gyrus/CA2, 3 pattern differentiation and CA1 memory integration</article-title>. <source>Journal of Neuroscience</source>. <year>2021</year>; <volume>41</volume>(<issue>4</issue>):<fpage>726</fpage>–<lpage>738</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Newman</surname> <given-names>EL</given-names></string-name>, <string-name><surname>Norman</surname> <given-names>KA</given-names></string-name>. <article-title>Moderate excitation leads to weakening of perceptual representations</article-title>. <source>Cerebral Cortex</source>. <year>2010</year>; <volume>20</volume>(<issue>11</issue>):<fpage>2760</fpage>–<lpage>2770</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Norman</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Newman</surname> <given-names>E</given-names></string-name>, <string-name><surname>Detre</surname> <given-names>G</given-names></string-name>, <string-name><surname>Polyn</surname> <given-names>S</given-names></string-name>. <article-title>How inhibitory oscillations can train neural networks and punish competitors</article-title>. <source>Neural Computation</source>. <year>2006</year>; <volume>18</volume>(<issue>7</issue>):<fpage>1577</fpage>–<lpage>1610</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Norman</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Newman</surname> <given-names>EL</given-names></string-name>, <string-name><surname>Detre</surname> <given-names>G</given-names></string-name>. <article-title>A neural network model of retrieval-induced forgetting</article-title>. <source>Psychological Review</source>. <year>2007</year>; <volume>114</volume>(<issue>4</issue>):<fpage>887</fpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Norman</surname> <given-names>KA</given-names></string-name>, <string-name><surname>O’Reilly</surname> <given-names>RC</given-names></string-name>. <article-title>Modeling hippocampal and neocortical contributions to recognition memory: a complementary-learning-systems approach</article-title>. <source>Psychological Review</source>. <year>2003</year>; <volume>110</volume>(<issue>4</issue>):<fpage>611</fpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="other"><string-name><surname>O’Reilly</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Munakata</surname> <given-names>Y</given-names></string-name>. <source>Computational explorations in cognitive neuroscience: Understanding the mind by simulating the brain. MIT Press</source>; <year>2000</year>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="other"><string-name><surname>O’Reilly</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Munakata</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Hazy</surname> <given-names>TE</given-names></string-name>, <article-title>Contributors</article-title>. <source>Computational Cognitive Neuroscience</source>. Online Book, 4th Edition, URL: <ext-link ext-link-type="uri" xlink:href="https://CompCogNeuro.org">https://CompCogNeuro.org</ext-link><collab>;</collab> <year>2012</year>. <ext-link ext-link-type="uri" xlink:href="https://github.com/CompCogNeuro/ed4">https://github.com/CompCogNeuro/ed4</ext-link>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Payeur</surname> <given-names>A</given-names></string-name>, <string-name><surname>Guerguiev</surname> <given-names>J</given-names></string-name>, <string-name><surname>Zenke</surname> <given-names>F</given-names></string-name>, <string-name><surname>Richards</surname> <given-names>BA</given-names></string-name>, <string-name><surname>Naud</surname> <given-names>R</given-names></string-name>. <article-title>Burst-dependent synaptic plasticity can coordinate learning in hierarchical circuits</article-title>. <source>Nature Neuroscience</source>. <year>2021</year>; <volume>24</volume>(<issue>7</issue>):<fpage>1010</fpage>–<lpage>1019</lpage>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Richards</surname> <given-names>BA</given-names></string-name>, <string-name><surname>Lillicrap</surname> <given-names>TP</given-names></string-name>, <string-name><surname>Beaudoin</surname> <given-names>P</given-names></string-name>, <string-name><surname>Bengio</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Bogacz</surname> <given-names>R</given-names></string-name>, <string-name><surname>Christensen</surname> <given-names>A</given-names></string-name>, <string-name><surname>Clopath</surname> <given-names>C</given-names></string-name>, <string-name><surname>Costa</surname> <given-names>RP</given-names></string-name>, <string-name><surname>de Berker</surname> <given-names>A</given-names></string-name>, <string-name><surname>Ganguli</surname> <given-names>S</given-names></string-name>, <etal>et al.</etal> <article-title>A deep learning framework for neuroscience</article-title>. <source>Nature Neuroscience</source>. <year>2019</year>; <volume>22</volume>(<issue>11</issue>):<fpage>1761</fpage>– <lpage>1770</lpage>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Ritvo</surname> <given-names>VJH</given-names></string-name>, <string-name><surname>Turk-Browne</surname> <given-names>NB</given-names></string-name>, <string-name><surname>Norman</surname> <given-names>KA</given-names></string-name>. <article-title>Nonmonotonic plasticity: how memory retrieval drives learning</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2019</year>; <volume>23</volume>(<issue>9</issue>):<fpage>726</fpage>–<lpage>742</lpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Rumelhart</surname> <given-names>DE</given-names></string-name>, <string-name><surname>Hinton</surname> <given-names>GE</given-names></string-name>, <string-name><surname>Williams</surname> <given-names>RJ</given-names></string-name>. <article-title>Learning internal representations by error propagation</article-title>. <source>California Univ San Diego La Jolla Inst for Cognitive Science</source>; <year>1985</year>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Schapiro</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Kustner</surname> <given-names>LV</given-names></string-name>, <string-name><surname>Turk-Browne</surname> <given-names>NB</given-names></string-name>. <article-title>Shaping of object representations in the human medial temporal lobe based on temporal regularities</article-title>. <source>Current Biology</source>. <year>2012</year>; <volume>22</volume>(<issue>17</issue>):<fpage>1622</fpage>–<lpage>1627</lpage>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Schapiro</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Rogers</surname> <given-names>TT</given-names></string-name>, <string-name><surname>Cordova</surname> <given-names>NI</given-names></string-name>, <string-name><surname>Turk-Browne</surname> <given-names>NB</given-names></string-name>, <string-name><surname>Botvinick</surname> <given-names>MM</given-names></string-name>. <article-title>Neural representations of events arise from temporal community structure</article-title>. <source>Nature Neuroscience</source>. <year>2013</year>; <volume>16</volume>(<issue>4</issue>):<fpage>486</fpage>–<lpage>492</lpage>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Schapiro</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Turk-Browne</surname> <given-names>NB</given-names></string-name>, <string-name><surname>Botvinick</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Norman</surname> <given-names>KA</given-names></string-name>. <article-title>Complementary learning systems within the hip-pocampus: a neural network modelling approach to reconciling episodic memory with statistical learning</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>. <year>2017</year>; <volume>372</volume>(<issue>1711</issue>):<fpage>20160049</fpage>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Schapiro</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Turk-Browne</surname> <given-names>NB</given-names></string-name>, <string-name><surname>Norman</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Botvinick</surname> <given-names>MM</given-names></string-name>. <article-title>Statistical learning of temporal community structure in the hippocampus</article-title>. <source>Hippocampus</source>. <year>2016</year>; <volume>26</volume>(<issue>1</issue>):<fpage>3</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Schlichting</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Mumford</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Preston</surname> <given-names>AR</given-names></string-name>. <article-title>Learning-related representational changes reveal dissociable integration and separation signatures in the hippocampus and prefrontal cortex</article-title>. <source>Nature Communications</source>. <year>2015</year>; <volume>6</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="other"><string-name><surname>Singh</surname> <given-names>D</given-names></string-name>, <string-name><surname>Norman</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Schapiro</surname> <given-names>AC</given-names></string-name>. <article-title>A model of autonomous interactions between hippocampus and neocortex driving sleep-dependent memory consolidation</article-title>. <source>bioRxiv</source>. <year>2022</year>;.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Tarder-Stoll</surname> <given-names>H</given-names></string-name>, <string-name><surname>Gasser</surname> <given-names>C</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>W</given-names></string-name>, <string-name><surname>Dimsdale-Zucker</surname> <given-names>HR</given-names></string-name>. <article-title>Challenges in Understanding the Role of Reactivation in Modifying Hippocampal Representations</article-title>. <source>Journal of Neuroscience</source>. <year>2021</year>; <volume>41</volume>(<issue>22</issue>):<fpage>4750</fpage>–<lpage>4753</lpage>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Tompary</surname> <given-names>A</given-names></string-name>, <string-name><surname>Davachi</surname> <given-names>L</given-names></string-name>. <article-title>Consolidation promotes the emergence of representational overlap in the hippocampus and medial prefrontal cortex</article-title>. <source>Neuron</source>. <year>2017</year>; <volume>96</volume>(<issue>1</issue>):<fpage>228</fpage>–<lpage>241</lpage>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Wammes</surname> <given-names>J</given-names></string-name>, <string-name><surname>Norman</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Turk-Browne</surname> <given-names>N</given-names></string-name>. <article-title>Increasing stimulus similarity drives nonmonotonic representational change in hippocampus</article-title>. <source>Elife</source>. <year>2022</year>; <volume>11</volume>:<issue>e68344</issue>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Wanjia</surname> <given-names>G</given-names></string-name>, <string-name><surname>Favila</surname> <given-names>SE</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>G</given-names></string-name>, <string-name><surname>Molitor</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Kuhl</surname> <given-names>BA</given-names></string-name>. <article-title>Abrupt hippocampal remapping signals resolution of memory interference</article-title>. <source>Nature Communications</source>. <year>2021</year>; <volume>12</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>West</surname> <given-names>M</given-names></string-name>, <string-name><surname>Slomianka</surname> <given-names>L</given-names></string-name>, <string-name><surname>Gundersen</surname> <given-names>HJG</given-names></string-name>. <article-title>Unbiased stereological estimation of the total number of neurons in the subdivisions of the rat hippocampus using the optical fractionator</article-title>. <source>The Anatomical Record</source>. <year>1991</year>; <volume>231</volume>(<issue>4</issue>):<fpage>482</fpage>– <lpage>497</lpage>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><surname>Whittington</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Bogacz</surname> <given-names>R</given-names></string-name>. <article-title>Theories of error back-propagation in the brain</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2019</year>; <volume>23</volume>(<issue>3</issue>):<fpage>235</fpage>–<lpage>250</lpage>.</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Zeithamova</surname> <given-names>D</given-names></string-name>, <string-name><surname>Gelman</surname> <given-names>BD</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>L</given-names></string-name>, <string-name><surname>Preston</surname> <given-names>AR</given-names></string-name>. <article-title>Abstract representation of prospective reward in the hippocampus</article-title>. <source>Journal of Neuroscience</source>. <year>2018</year>; <volume>38</volume>(<issue>47</issue>):<fpage>10093</fpage>–<lpage>10101</lpage>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Zhao</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Chanales</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Kuhl</surname> <given-names>BA</given-names></string-name>. <article-title>Adaptive memory distortions are predicted by feature representations in parietal cortex</article-title>. <source>Journal of Neuroscience</source>. <year>2021</year>; <volume>41</volume>(<issue>13</issue>):<fpage>3014</fpage>–<lpage>3024</lpage>.</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><string-name><surname>Zheng</surname> <given-names>L</given-names></string-name>, <string-name><surname>Gao</surname> <given-names>Z</given-names></string-name>, <string-name><surname>McAvan</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Isham</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Ekstrom</surname> <given-names>AD</given-names></string-name>. <article-title>Partially overlapping spatial environments trigger reinstatement in hippocampus and schema representations in prefrontal cortex</article-title>. <source>Nature Communications</source>. <year>2021</year>; <volume>12</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>15</lpage>.</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><surname>Zhuang</surname> <given-names>C</given-names></string-name>, <string-name><surname>Yan</surname> <given-names>S</given-names></string-name>, <string-name><surname>Nayebi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Schrimpf</surname> <given-names>M</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>MC</given-names></string-name>, <string-name><surname>DiCarlo</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Yamins</surname> <given-names>DL</given-names></string-name>. <article-title>Unsupervised neural network models of the ventral visual stream</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2021</year>; <volume>118</volume>(<issue>3</issue>):<fpage>e2014196118</fpage>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="book"><string-name><surname>Zhuang</surname> <given-names>C</given-names></string-name>, <string-name><surname>Zhai</surname> <given-names>AL</given-names></string-name>, <source>Yamins D. Local aggregation for unsupervised learning of visual embeddings</source>. <publisher-loc>In</publisher-loc>: <publisher-name><italic>Proceedings of the IEEE/CVF International Conference on Computer Vision</italic></publisher-name>; <year>2019</year>. p. <fpage>6002</fpage>–<lpage>6012</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88608.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Schlichting</surname>
<given-names>Margaret L</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country>Canada</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This paper presents <bold>important</bold> computational modeling work that provides a mechanistic account for how memory representations become integrated or differentiated (i.e., having distinct neural representations despite being similar in content). The authors provide <bold>convincing</bold> evidence that simple unsupervised learning in a neural network model, which critically weakens connections of units that are moderately activated by multiple memories, can account for three empirical findings of differentiation in the literature. The paper also provides insightful discussion on the factors contributing to differentiation as opposed to integration, and makes new predictions for future empirical work.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88608.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Ritvo and colleagues present an impressive suite of simulations that can account for three findings of differentiation in the literature. This is important because differentiation-in which items that have some features in common, or share a common associate are less similar to one another than are unrelated items-is difficult to explain with classic supervised learning models, as these predict the opposite (i.e., an increase in similarity). A few of their key findings are that differentiation requires a high learning rate and low inhibitory oscillations, and is virtually always asymmetric in nature.</p>
<p>This paper was very clear and thoughtful-an absolute joy to read. The model is simple and elegant, and powerful enough to re-create many aspects of existing differentiation findings. The interrogation of the model and presentation of the findings were both extremely thorough. The potential for this model to be used to drive future work is huge. I have only a few comments for the authors, all of which are relatively minor.</p>
<p>1. I was struck by the fact that the &quot;zone&quot; of repulsion is quite narrow, compared with the zone of attraction. This was most notable in the modeling of Chanales et al. (i.e., just one of the six similarity levels yielded differentiation). Do the authors think this is a generalizable property of the model or phenomenon, or something idiosyncratic to do with the current investigation? It seems curious that differentiation findings (e.g., in hippocampus) are so robustly observed in the literature despite the mechanism seemingly requiring a very particular set of circumstances. I wonder if the authors could speculate on this point a bit-for example, might the differentiation zone be wider when competitor &quot;pop up&quot; is low (i.e., low inhibitory oscillations), which could help explain why it's often observed in hippocampus? This seems related a bit to the question about what makes something &quot;moderately&quot; active, or how could one ensure &quot;moderate&quot; activation if they were, say, designing an experiment looking at differentiation.</p>
<p>2. With real fMRI data we know that the actual correlation value doesn't matter all that much, and anti-correlations can be induced by things like preprocessing decisions. I am wondering if the important criterion in the model is that the correlations (e.g., as shown in Figure 6) go down from pre to post, versus that they are negative in sign during the post learning period. I would think that here, similar to in neural data, a decrease in correlation would be sufficient to conclude differentiation, but would love the authors' thoughts on that.</p>
<p>3. For the modeling of the Favila et al. study, the authors state that a high learning rate is required for differentiation of the same-face pairs. This made me wonder what happens in the low learning rate simulations. Does integration occur? This paradigm has a lot of overlap with acquired equivalence, and so I am thinking about whether these are the sorts of small differences (e.g., same-category scenes and perhaps a high learning rate) that bias the system to differentiate instead of integrate.</p>
<p>4. For the simulations of the Schlichting et al. study, the A and B appear to have overlap in the hidden layer based on Figure 9, despite there being no similarity between the A and B items in the study (in contrast to Favila et al., in which they were similar kinds of scenes, and Chanales et al., in which they were similar colors). Why was this decision made? Do the effects depend on some overlap within the hidden layer? (This doesn't seem to be explained in the paper that I saw though, so maybe just it's a visualization error?)</p>
<p>5. It seems as though there were no conditions under which the simulations produced differentiation in both the blocked and intermixed conditions, which Schlichting et al. observed in many regions (as the present authors note). Is there any way to reconcile this difference?</p>
<p>6. A general question about differentiation/repulsion and how it affects the hidden layer representation in the model: Is it the case that the representation is actually &quot;shifted&quot; or repelled over so it is no longer overlapping? Or do the shared connections just get pruned, such that the item that has more &quot;movement&quot; in representational space is represented by fewer units on the hidden layer (i.e., is reduced in size)? I think, if I understand correctly, that whether it gets shifted vs. reduce would depend on the strength of connections along the hidden layer, which would in turn depend on whether it represents some meaningful continuous dimension (like color) or not. But, if the connections within the hidden layer are relatively weak and it is the case that representations become reduced in size, would there be any anticipated consequences of this (e.g., cognitively/behaviorally)?</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88608.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This paper addresses an important computational problem in learning and memory. Why do related memory representations sometimes become more similar to each other (integration) and sometimes more distinct (differentiation)? Classic supervised learning models predict that shared associations should cause memories to integrate, but these models have recently been challenged by empirical data showing that shared associations can sometimes cause differentiation. The authors have previously proposed that unsupervised learning may account for these unintuitive data. Here, they follow up on this idea by actually implementing an unsupervised neural network model that updates the connections between memories based on the amount of coactivity between them. The goal of the authors' paper is to assess whether such a model can account for recent empirical data at odds with supervised learning accounts. For each empirical finding they wish to explain, the authors built a neural network model with a very simple architecture (two inputs layers, one hidden layer, and one output layer) and with prewired stimulus representations and associations. On each trial, a stimulus is presented to the model, and inhibitory oscillations allow competing memories to pop up. Pre-specified u-shaped learning rules are used to update the weights in the model, such that low coactivity leaves model connections unchanged, moderate coactivity weakens connections, and high coactivity strengthens connections. In each of the three models, the authors manipulate stimulus similarity (following Chanales et al), shared vs distinct associations (following Favila et al), or learning strength (a stand in for blocked versus interleaved learning schedule; following Schlichting et al) and evaluate how the model representations evolve over trials.</p>
<p>As a proof of principle, the authors succeed in demonstrating that unsupervised learning with a simple u-shaped rule can produce qualitative results in line with the empirical reports. For instance, they show that pairing two stimuli with a common associate (as in Favila et al) can lead to *differentiation* of the model representations. Demonstrating these effects isn't trivial and a formal modeling framework for doing so is a valuable contribution. Overall, the authors do a good job of both formally describing their model and giving readers a high level sense of how their critical model components work, though there are some places where the robustness of the model to different parameter choices is unclear. In some cases, the authors are very clear about this (e.g. the fast learning rate required to observe differentiation). However, in other instances, the paper would be strengthened by a clearer reporting of the critical parameter ranges. For instance, it's clear from the manipulation of oscillation strength in the model of Schlichting et al that this parameter can dramatically change the direction of the results. The authors do report the oscillation strength parameter values that they used in the other two models, but it is not clear how sensitive these models are to small changes in this value. Similarly, it's not clear whether the 2/6 hidden layer overlap (only explicitly manipulated in the model of Chanales et al) is required for the other two models to work. Finally, though the u-shaped learning rule is essential to this framework, the paper does little formal investigation of this learning rule. It seems obvious that allowing the u-shape to collapse too much toward a horizontal line would reduce the model's ability to account for empirical results, but there may be other more interesting features of the learning rule parameterization that are essential for the model to function properly.</p>
<p>There are a few other points that may limit the model's ability to clearly map onto or make predictions about empirical data. The model(s) seems very keen to integrate and do so more completely than the available empirical data suggest. For instance, there is a complete collapse of representations in half of the simulations in the Chanales et al model and the blocked simulation in the Schlichting et al model also seems to produce nearly complete integration. Even if the Chanales et al paper had observed some modest behavioral attraction effects, this model would seem to over-predict integration. The author's somewhat implicitly acknowledge this when they discuss the difficulty of producing differentiation (&quot;Practical Advice for Getting the Model to Show Differentiation&quot;) and not of producing integration, but don't address it head on. Second, the authors choice of strongly prewiring associations in the Chanales and Favila models makes it difficult to think about how their model maps onto experimental contexts where competition is presumably occurring while associations are only weakly learned. In the Chanales et al paper, for example, the object-face associations are not well learned in initial rounds of the color memory test. While the authors do justify their modeling choice and their reasons have merit, the manipulation of AX association strength in the Schlichting et al model also makes it clear that the association strength has a substantial effect on the model output. Given the effect of this manipulation, more clarity around this assumption for the other two models is needed.</p>
<p>Overall, this is strong and clearly described work that is likely to have a positive impact on computational and empirical work in learning and memory. While the authors have written about some of the ideas discussed in this paper previously, a fully implemented and openly available model is a clear advance that will benefit the field. It is not easy to translate a high-level description of a learning rule into a model that actually runs and behaves as expected. The fact that the authors have made all their code available makes it likely that other researchers will extend the model in numerous interesting ways, many of which the authors have discussed and highlighted in their paper.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88608.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This paper proposes a computational account for the phenomenon of pattern differentiation (i.e., items having distinct neural representations when they are similar). The computational model relies on a learning mechanism of the nonmonotonic plasticity hypothesis, fast learning rate and inhibitory oscillations. The relatively simple architecture of the model makes its dynamics accessible to the human mind. Furthermore, using similar model parameters, this model produces simulated data consistent with empirical data of pattern differentiation. The authors also provide insightful discussion on the factors contributing to differentiation as opposed to integration. The authors may consider the following to further strengthen this paper:</p>
<p>The model compares different levels of overlap at the hidden layer and reveals that partial overlap seems necessary to lead to differentiation. While I understand this approach from the perspective of modeling, I have concerns about whether this is how the human brain achieves differentiation. Specifically, if we view the hidden layer activation as a conjunctive representation of a pair that is the outcome of encoding, differentiation should precede the formation of the hidden layer activation pattern of the second pair. Instead, the model assumes such pattern already exists before differentiation. Maybe the authors indeed argue that mechanistically differentiation follows initial encoding that does not consider similarity with other memory traces?</p>
<p>Related to the point above, because the simulation setup is different from how differentiation actually occurs, I wonder how valid the prediction of asymmetric reconfiguration of hidden layer connectivity pattern is.</p>
<p>Although as the authors mentioned, there haven't been formal empirical tests of the relationship between learning speed and differentiation/integration, I am also wondering to what degree the prediction of fast learning being necessary for differentiation is consistent with current data. According to Figure 6, the learning rates lead to differentiation in the 2/6 condition achieved differentiation after just one-shot most of the time. On the other hand, For example, Guo et al (2021) showed that humans may need a few blocks of training and test to start showing differentiation.</p>
<p>Related to the point above, the high learning rate prediction also seems to be at odds with the finding that the cortex, which has slow learning (according to the theory of complementary learning systems), also shows differentiation in Wammes et al (2022).</p>
<p>More details about the learning dynamics would be helpful. For example, equation(s) showing how activation, learning rate and the NMPH function work together to change the weight of connections may be added. Without the information, it is unclear how each connection changes its value after each time point.</p>
<p>In the simulation, the NMPH function has two turning points. I wonder if that is necessary. On the right side of the function, strong activation leads to strengthening of the connectivity, which I assume will lead to stronger activation on the next time point. The model has an upper limit of connection strength to prevent connection from strengthening too much. The same idea can be applied to the left side of the function: instead of having two turning points, it can be a linear function such that low activation keeps weakening connection until the lower limit is reached. This way the NMPH function can take a simpler form (e.g., two line-segments if you think the weakening and strengthening take different rates) and may still simulate the data.</p>
</body>
</sub-article>
</article>