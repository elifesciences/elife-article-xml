<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">107163</article-id>
<article-id pub-id-type="doi">10.7554/eLife.107163</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.107163.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
</article-categories><title-group>
<article-title>Individuality transfer: Predicting human decision-making across tasks</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Higashi</surname>
<given-names>Hiroshi</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>higashi@comm.eng.osaka-u.ac.jp</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/035t8zc32</institution-id><institution>The University of Osaka</institution></institution-wrap>, <city>Osaka</city>, <country country="JP">Japan</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Li</surname>
<given-names>Jian</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country country="CN">China</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-06-27">
<day>27</day>
<month>06</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP107163</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-04-30">
<day>30</day>
<month>04</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-04-09">
<day>09</day>
<month>04</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.03.25.645375"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Higashi</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Higashi</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-107163-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Predicting an individual’s behaviour in one task based on their behaviour in a different task is a key challenge in modeling individual decision-making tendencies. We propose a novel framework that addresses this challenge by leveraging neural networks and introducing a concept we term the “individuality index.” This index, extracted from behaviour in a “source” task via an encoder network, captures an individual’s unique decision-making tendencies. A decoder network then utilizes this index to generate the weights of a task-specific neural network (a “task solver”), which predicts the individual’s behaviour in a “target” task. We demonstrate the effectiveness of our approach in two distinct decision-making tasks: a value-guided task and a perceptual task. Our framework offers a robust and generalizable approach for parameterizing individuality, providing a promising pathway toward computational modeling at the individual level—that is, replicating individuals in silico.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Correct typos; Abstract and Introduction revised to clarify our research purpose.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Humans (and other animals) exhibit substantial commonalities in their decision-making processes. However, considerable variability is also frequently observed in how individuals perform perceptual and cognitive decision-making tasks [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c1">1</xref>]. This variability arises from differences in underlying cognitive mechanisms. For example, individuals may vary in their ability or tendency to retain past experiences [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c8">8</xref>], respond to events with both speed and accuracy [<xref ref-type="bibr" rid="c52">52</xref>, <xref ref-type="bibr" rid="c45">45</xref>], or explore novel actions [<xref ref-type="bibr" rid="c17">17</xref>]. If these factors can be meaningfully disentangled, they would enable a concise characterization of individual decision-making processes, yielding a low-dimensional, parameterized representation of individuality. Such a representation could, in turn, be leveraged to predict future behaviours at an individual level. Shifting from population-level predictions to an individual-based approach would mark a significant advancement in domains where precise behaviour prediction is essential, such as social and cognitive sciences. Beyond prediction, this approach offers a framework for parametrizing and clustering individuals, thereby facilitating the visualization of behavioural heterogeneity, which has applications in psychiatric analysis [<xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c10">10</xref>]. Furthermore, this parameterization offers a promising pathway toward computational modeling at the individual level—that is, replicating the cognitive and functional characteristics of individuals <italic>in silico</italic> [<xref ref-type="bibr" rid="c41">41</xref>].</p>
<p>Cognitive modelling is a standard approach for reproducing and predicting human behaviour [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c57">57</xref>], often implemented within a reinforcement learning framework (e.g., [<xref ref-type="bibr" rid="c30">30</xref>, <xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c54">54</xref>]). However, because these cognitive models are manually designed by researchers, their ability to accurately fit behavioural data may be limited [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c13">13</xref>]. A data-driven approach using artificial neural networks (ANNs) offers an alternative [<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c33">33</xref>, <xref ref-type="bibr" rid="c39">39</xref>]. Unlike cognitive models, which rely on predefined behavioural assumptions [<xref ref-type="bibr" rid="c37">37</xref>], ANNs require minimal prior assumptions and can learn complex patterns directly from data. For instance, convolutional neural networks (CNNs) have successfully replicated human choices and reaction times in various visual tasks [<xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c15">15</xref>]. Similarly, recurrent neural networks (RNNs) [<xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c7">7</xref>] have been applied to model value-guided decision-making tasks such as the multi-armed bandit problem [<xref ref-type="bibr" rid="c56">56</xref>, <xref ref-type="bibr" rid="c10">10</xref>]. A promising approach to capturing individual decision-making tendencies while preserving behavioural consistency is to tune ANN weights using a parameterized representation of individuality.</p>
<p>This idea was first proposed by Dezfouli et al. [<xref ref-type="bibr" rid="c10">10</xref>], who employed an RNN to solve a two-armed bandit task. Their study utilized an autoencoder framework [<xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c48">48</xref>], in which behavioural recordings from a single session of the bandit task, performed by an individual, were fed into an encoder. The encoder produced a low-dimensional vector, interpreted as a latent representation of the individual. Similar to hypernetworks [<xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c22">22</xref>], a decoder then took this low-dimensional vector as input and generates the weights of the RNN. This framework successfully reproduced behavioural recordings from other sessions of the same bandit task while preserving individual characteristics. However, since this individuality transfer has only been validated within the bandit task, it remains unclear whether the extracted latent representation captures an individual’s intrinsic tendencies across a variety of tasks.</p>
<p>To address this question, we aim to make the low-dimensional representation— referred as <italic>individuality index</italic>—robust to variations across individuals and tasks, thereby enhancing its generalizability. Specifically, we propose a framework that predicts an individual’s behaviours, not only in the same task but also in similar yet distinct tasks and environments. If the individuality index indeed serves as a low-dimensional representation of an individual’s decision-making process, then extracting it from one task could facilitate the prediction of that individual’s behaviours in another.</p>
<p>In this study, we define the problem of <italic>individuality transfer across tasks</italic> as follows (also illustrated in <xref rid="fig1" ref-type="fig">Figure 1</xref>). We assume access to a behavioural dataset from multiple individuals performing two tasks: a <italic>source task</italic> and a <italic>target task</italic>. We train an encoder that takes behavioural data from the source task as input and outputs an individuality index. This index is then fed into a decoder, which generates the weights of an ANN, referred to as a <italic>task solver</italic>, that reproduces behaviours in the target task. For testing, a new individual provides behavioural data from the source task, allowing us to infer their individuality index. Using this index, a task solver is constructed to predict how the test individual will behave in the target task. Importantly, this prediction does not require any behavioural data from the test individual performing the target task. We refer to this framework as <italic>EIDT</italic>, an acronym for encoder, individuality index, decoder and task solver.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>The EIDT (encoder, individuality index, decoder, and task solver) framework for individuality transfer across tasks.</title>
<p>The encoder maps action(s) <italic>α</italic>, provided by an individual <italic>K</italic> performing a specific problem <italic>ϕ</italic> in the source task <italic>A</italic>, into an individuality index (represented as a point in the two-dimensional space in the center). The individual index is then fed into the decoder, which generates the weights for a task solver. The task solver predicts the behaviour of the same individual <italic>K</italic> in the target task <italic>B</italic>. During the training, a loss function evaluates the discrepancy between the predicted behaviour <inline-formula><inline-graphic xlink:href="645375v2_inline44.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and the actual recorded behaviour <italic>β</italic> of individual <italic>K</italic>. The encoder’s input is referred to as an <italic>action sequence</italic>, the form of which depends on task. For example, in a sequential Markov decision process (MDP) task, an action sequence consists of an environment (state transition probabilities) and a sequence of actions over multiple episodes. For a digit recognition task, it consists of a stimulus digit image and the corresponding chosen response.</p></caption>
<graphic xlink:href="645375v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We evaluated whether the proposed EIDT framework can effectively transfer individuality in both value-guided sequential decision-making tasks and perceptual decision-making tasks. To assess its generalizability across individuals, meaning its ability to predict the behaviour of previously unseen individuals, we tested the framework using a test participant pool that was not included in the dataset used for model training. To determine how well our framework captures each individual’s unique behavioural patterns, we compared the prediction performance of a task solver specifically designed for a given individual with the performance of task solvers designed for other individuals. Our results indicate that the proposed framework successfully mimics decision-making while accounting for individual differences.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Results</title>
<p>We evaluated our individuality transfer framework, which consists of an encoder, a decoder, a task solver, and an individuality index, using two transfer problems: a value-guided sequential decision-making task (an MDP task) and a perceptual decision-making task (a handwritten digit recognition task, referred to as the MNIST task). The dataset for both tasks include two or more distinct experimental settings. Since each human participant completed all settings, we tested transfer problems in which one setting served as the source task, while another served as the target task.</p>
<sec id="s2a">
<label>2.1</label>
<title>Markov decision process (MDP) task</title>
<p>The dataset consisted of behavioural data from 98 participants, as detailed in <xref ref-type="sec" rid="s4b2">Section 4.2.2</xref>. Participants performed the MDP task under two different conditions: a 2-step task and a 3-step task. Each participant completed three sequence blocks for both the 2- and 3-step tasks, with each sequence comprising 50 episodes. Thus, the dataset contained a total of <italic>N</italic> = 6 (sequences) <italic>×</italic> 98 (participants) = 588 (action sequences). For model training, sequence data from 70% of the participants (68 participants) were used to train the encoder and decoder. An additional 10% (10 participants) were designated as validation data, used to determine the optimal number of training iterations. The remaining 20% (20 participants) were allocated for evaluating the performance of the model.</p>
<sec id="s2a1">
<title>Neural network exhibits superior performance in behaviour prediction</title>
<p>We evaluated our model under two experimental situations, summarized in <xref rid="tbl1" ref-type="table">Table 1</xref>. The first situation, Situation SX (no transfer), does not involve individuality transfer across tasks. Since individuality is not explicitly considered in this situation, we designed average models as baselines, described below.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Simulated experimental situations.</title>
<p>The “Availability” column indicates data availability for a given participant pool and task during model training. In the “Participant pool” column, “train”, “valid”, and “test” refer to the training, validation, and test participant pools, respectively.</p></caption>
<graphic xlink:href="645375v2_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s2a2">
<title>Cognitive model (CG)</title>
<p>We implemented a cognitive model based on Q-learning, as detailed in <xref ref-type="sec" rid="s4b3">Section 4.2.3</xref>. The model parameters—including the learning rate <italic>q</italic><sub>lr</sub>, forgetting factor <italic>q</italic><sub>ff</sub>, discount rate <italic>q</italic><sub>dr</sub>, and inverse temperature <italic>q</italic><sub>it</sub>—were estimated using a maximum likelihood approach based on behavioural data from the target task in the training and validation participant pools. Using these estimated parameters, we constructed a Q-learning agent to predict the behaviour of participants in the test participant pool.</p>
</sec>
<sec id="s2a3">
<title>Task solver (TS)</title>
<p>We employed a task solver TS(·), as defined in (1). Instead of using the EIDT framework, the weights of the task solver network were directly trained using data from the training participant pool. To determine the optimal stopping point during training, we used early stopping based on the loss measured on the validation participant pool—training was terminated when the validation loss reached its minimum. The trained task solver was then used to predict the behaviour of participants in the test participant pool.</p>
<p>For further details on the model training procedure, refer to <xref ref-type="sec" rid="s4b4">Section 4.2.4</xref>.</p>
<p>Under Situation SX, we evaluated whether a neural network-based behaviour prediction model (i.e., the task solver) outperforms the cognitive model in predicting average performance across individuals. The result (<xref rid="fig2" ref-type="fig">Figure 2A</xref>) confirmed this. A two-way (model: CG/TS, task: 2/3) repeated-measures (RM) ANOVA with Greenhouse-Geisser correction (significant level was 0.05) revealed a significant effect of model (<italic>F</italic><sub>1,19</sub> = 29.944, <italic>p &lt;</italic> 0.001,<inline-formula><inline-graphic xlink:href="645375v2_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>), indicating that the task solver provided significantly better predictions than the cognitive model. We found no significant effect of task (<italic>F</italic><sub>1,19</sub> = 0.162, <italic>p</italic> = 0.692,<inline-formula><inline-graphic xlink:href="645375v2_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) and no significant interaction effect between model and task (<italic>F</italic><sub>1,19</sub> = 3.144, <italic>p</italic> = 0.092,<inline-formula><inline-graphic xlink:href="645375v2_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Prediction error results for the MDP task.</title>
<p><bold>A</bold> Under Situation SX. The box represents the interquartile range (IQR), with the central line indicating the median. Whiskers extend to the minimum and maximum values. Connected dots represent data from the same participant. <bold>B</bold> Under Situation SY. <bold>C</bold> Comparison between the transfer-to-original participant (Original) and transfer-to-other-participants (Others) settings.</p></caption>
<graphic xlink:href="645375v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2a4">
<title>EIDT framework excels in individuality transfer</title>
<p>Under Situation SY (transfer across tasks), we assumed that that behavioural data from the source task of the test participant pool could be leveraged to predict behaviour in the target task. This situation was designed to evaluate individuality transfer across tasks, which is the primary focus of this study. We tested two models:</p>
</sec>
<sec id="s2a5">
<title>Cognitive model (CG)</title>
<p>We implemented a Q-learning-based cognitive model, as described in <xref ref-type="sec" rid="s4b3">Section 4.2.3</xref>. The parameters (<italic>q</italic><sub>lr</sub>, <italic>q</italic><sub>ff</sub>, <italic>q</italic><sub>dr</sub>, and <italic>q</italic><sub>it</sub>) for a participant in the test pool were estimated using a maximum likelihood approach based on behavioural data from that participant’s source task. Using these estimated parameters, we constructed a Q-learning agent capable of solving the target task (not the source task) and used it to predict the participant’s behaviour in the target task.</p>
</sec>
<sec id="s2a6">
<title>EIDT</title>
<p>We employed our EIDT framework, which was trained using data from both and source and target tasks of the training participant pool. As with the TS model under Situation SX, data from the validation participant pool were used for early stopping during training. To predict behaviour in the target task for a participant <italic>K</italic> in the test participant pool, we first input each sequence from 𝒜<sub><italic>K</italic></sub> (behavioural data from participant <italic>K</italic> in task <italic>A</italic>) into the encoder. The individuality index for participant <italic>K</italic> was computed as the average: <inline-formula><inline-graphic xlink:href="645375v2_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The weights of the task solver for that participant were then generated using the decoder output: <inline-formula><inline-graphic xlink:href="645375v2_inline4a.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The task solver, incorporating these weights, was used to predict behaviour in response to a given problem <italic>ψ</italic> in <italic>ℬ</italic><sub><italic>K</italic></sub>.</p>
<p>For details on the model training procedure, refer to <xref ref-type="sec" rid="s4b4">Section 4.2.4</xref>.</p>
<p>We compared the prediction error between models, as shown in <xref rid="fig2" ref-type="fig">Figure 2B</xref>. A two-way (model: CG/EIDT, transfer task set: 2→3/3→2) RM ANOVA revealed significant effects of model (<italic>F</italic><sub>1,19</sub> = 21.372, <italic>p &lt;</italic> 0.001,<inline-formula><inline-graphic xlink:href="645375v2_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) and a significant interaction effect (<italic>F</italic><sub>1,19</sub> = 5.053, <italic>p</italic> = 0.037,<inline-formula><inline-graphic xlink:href="645375v2_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). However, there was no significant effect of transfer task set (<italic>F</italic><sub>1,19</sub> = 0.330, <italic>p</italic> = 0.573,<inline-formula><inline-graphic xlink:href="645375v2_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). Pairwise comparisons indicated that the cognitive model exhibited significantly greater prediction error than the EIDT model for both transfer task sets: 3→2 (<italic>t</italic><sub>19</sub> = 3.634, <italic>p</italic> = 0.002 with Bonferroni correction) and 2→3 (<italic>t</italic><sub>19</sub> = 4.254, <italic>p &lt;</italic> 0.001). These results demonstrate that the EIDT model predicts human behaviour more accurately—with a lower negative likelihood— than the cognitive model.</p>
</sec>
<sec id="s2a7">
<title>Individuality index forms clusters for each individual</title>
<p>We visualized the individuality indices in <xref rid="fig3" ref-type="fig">Figure 3</xref> and evaluated them using the within-individual and between-individual distances, as defined in <xref ref-type="sec" rid="s4d1">Section 4.4.1</xref>. For both transfer task sets, the within-individual distance was significantly shorter than the between-individual distance (<italic>t</italic><sub>19</sub> = −5.515, <italic>p &lt;</italic> 0.001 for 3→2 and <italic>t</italic><sub>19</sub> = −2.991, <italic>p</italic> = 0.008 for 2→3). Since the within-individual distance is shorter than the between-individual distance, the individuality indices from the same individual are positioned closer together in the individuality index space, forming a distinct cluster for each individual.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Individuality indices in the test participant pool for the MDP tasks.</title>
<p>Dots represent the average individuality index for each participant, while shaded areas show confidence ellipses, enclosing 98.9% of the points for each participant.</p></caption>
<graphic xlink:href="645375v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We also evaluated the extent to which the variables of the individuality index are disentangled, using the Pearson correlation coefficient. A test of the null hypothesis of uncorrelation showed that the two variables (<italic>z</italic><sub>0</sub> and <italic>z</italic><sub>1</sub>) are significantly correlated for the 3→2 transfer (<italic>r</italic> = 0.687, <italic>p &lt;</italic> 0.001) and the 2→3 transfer (<italic>r</italic> = −0.323, <italic>p</italic> = 0.012).</p>
</sec>
<sec id="s2a8">
<title>Individuality is preserved across tasks</title>
<p>We evaluated whether the models could predict unique behavioural patterns for each individual. To do so, we compared prediction accuracy for a given participant’s behaviour using a task solver trained specifically for that participant with its accuracy using task solvers trained for other participants. That is, we examined accuracy for the original task solver (Original) versus accuracy for other task solvers (Others). If the task solver effectively captures individuality, it should perform significantly better for Original than for Others. For details on this comparison, refer to <xref ref-type="sec" rid="s4d2">Section 4.4.2</xref>.</p>
<p>The cognitive model exhibited this tendency (<xref rid="fig2" ref-type="fig">Figure 2C</xref>, left). A two-way (transfer task set: 3→2/2→3, transfer-to participant(s): Original/Others) RM ANOVA revealed a significant effect of transfer task set (<italic>F</italic><sub>1,19</sub> = 5.383, <italic>p</italic> = 0.032,<inline-formula><inline-graphic xlink:href="645375v2_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) and a significant effect of transfer-to participant(s) (<italic>F</italic><sub>1,19</sub> = 25.169, <italic>p &lt;</italic> 0.001,<inline-formula><inline-graphic xlink:href="645375v2_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula>), while an interaction effect (<italic>F</italic><sub>1,19</sub> = 0.047, <italic>p</italic> = 0.831,<inline-formula><inline-graphic xlink:href="645375v2_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) was not significant.</p>
<p>The EIDT model exhibited a similar pattern (<xref rid="fig2" ref-type="fig">Figure 2C</xref>, right). A two-way RM ANOVA revealed a significant effect of transfer-to participant(s) (<italic>F</italic><sub>1,19</sub> = 26.976, <italic>p &lt;</italic> 0.001,<inline-formula><inline-graphic xlink:href="645375v2_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) and an interaction effect (<italic>F</italic><sub>1,19</sub> = 20.238, <italic>p &lt;</italic> 0.001,<inline-formula><inline-graphic xlink:href="645375v2_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). This did not show a significant effect for transfer task set (<italic>F</italic><sub>1,19</sub> = 0.201, <italic>p</italic> = 0.659,<inline-formula><inline-graphic xlink:href="645375v2_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). Bonferroni-corrected pairwise comparisons confirmed that prediction loss for Original was significantly lower for Others in both transfer task sets: 3→2 (<italic>t</italic><sub>19</sub> = 4.278, <italic>p &lt;</italic> 0.001) and 2→3 (<italic>t</italic><sub>19</sub> = 5.282, <italic>p &lt;</italic> 0.001). While the task solver, utilizing the individuality index of the original participant, predicted that participant’s behaviours more accurately than the cognitive model, it was less accurate in predicting the behaviour of other participants. This suggests that the EIDT model successfully captures individual characteristics, leading to personalized behaviour predictions.</p>
</sec>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Handwritten digit recognition (MNIST) task</title>
<p>The dataset was originally collected and published by Rafiei et al. [<xref ref-type="bibr" rid="c34">34</xref>]. It contains behavioural data from 60 human participants who performed a digit discrimination task. The experiment followed a 2 <italic>×</italic> 2 factorial design with two factors: task difficulty (easy versus difficult images, controlled by noise level) and speed pressure (accuracy versus speed focus, controlled by experimental instruction). This design resulted in four experimental settings; EA (easy, accuracy focus), ES (easy, speed focus), DA (difficult, accuracy focus), and DS (difficult, speed focus). Our individuality transfer experiments evaluated whether the proposed framework could transfer individuality from one setting to another. Each setting included 120 unique images, and each participant made a decision for each image twice, resulting in a total of 960 trials per participant. behavioural data from 70% of participants (42 participants) were used to train the encoder and decoder. Additional 10% of participants (6 participants) were assigned as validation data for early stopping during training. The remaining 20% of participants (12 participants) were used to evaluate model performance.</p>
<sec id="s2b1">
<title>Our average model outperforms a no-fitting model</title>
<p>Situation SX, a no transfer situation, was used to evaluate how well our task solver fits human behaviour compared to an existing model. Ideally, this comparison would involve models that can be explicitly fitted to human behaviour. However, no readily adaptable model was available. As an alternative, we used an average model, RTNet [<xref ref-type="bibr" rid="c34">34</xref>], which predicts human-like decisions and reaction times.</p>
<sec id="s2b1a">
<title>RTNet (RN)</title>
<p>RTNet accumulates evidence generated by a CNN (see <xref ref-type="sec" rid="s4c2">Section 4.3.2</xref>) to produce stochastic, human-like decisions and response times.</p>
</sec>
<sec id="s2b1b">
<title>Task solver (TS)</title>
<p>The task solver TS(), as defined in <xref ref-type="sec" rid="s4c">Section 4.3</xref>, was trained using data from the training participant pool.</p>
<p>Our results confirmed that the task solver with fitting outperforms RT-Net without fitting, as shown in <xref rid="fig4" ref-type="fig">Figure 4</xref>. A two-way (model: RN/TS, task: EA/ES/DA/DS) RM ANOVA revealed significant effects of model (<italic>F</italic><sub>3,33</sub> = 104.744, <italic>p &lt;</italic> 0.001, <inline-formula><inline-graphic xlink:href="645375v2_inline13a.gif" mimetype="image" mime-subtype="gif"/></inline-formula>), task (<italic>F</italic><sub>1,11</sub> = 322.550, <italic>p &lt;</italic> 0.001, <inline-formula><inline-graphic xlink:href="645375v2_inline14.gif" mimetype="image" mime-subtype="gif"/></inline-formula>), and their interaction (<italic>F</italic><sub>3,33</sub> = 72.733, <italic>p &lt;</italic> 0.001, <inline-formula><inline-graphic xlink:href="645375v2_inline15.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). Bonferroni-corrected pairwise comparisons showed significant differences between EA and DA, ES and DA, EA and DS, and ES and DS (<italic>p &lt;</italic> 0.001 for all). However, no significant differences were found between EA and ES or DA and DS. Re-production accuracy may correlate with the percentage of correct responses in the MNIST task. The original study [<xref ref-type="bibr" rid="c34">34</xref>] reported that human accuracy (and RTNets performance) depended on task difficulty but not on focus condition. In our case, the task solvers achieved correct response rates of 77.7% for EA, 79.0% for ES, 62.0% for DA, and 61.6% for DS. These results are consistent with those reported for RTNet and suggest that reproduction accuracy depends primarily on task difficulty, i.e., uncertainty in response.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><p>The prediction error under Situation SX (no transfer) in the MNIST task.</p></caption>
<graphic xlink:href="645375v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s2b2">
<title>Individuality index forms clusters for each individual</title>
<p>We visualized the individuality indices and evaluated them using the within-individual and between-individual distances (see Section S1, Supplementary materials). For most transfer task sets, the within-individual distance was significantly shorter than the between-individual distance, indicating that individuality indices from the same participant tended to cluster together. A test of the null hypothesis of no correlation revealed that the two variables of the individuality index (<italic>z</italic><sub>0</sub> and <italic>z</italic><sub>1</sub>) were significantly correlated for all transfer task sets.</p>
</sec>
<sec id="s2b3">
<title>Individuality preserves across tasks</title>
<p>Situation SY (transfer across tasks) was used to evaluate whether our EIDT model could predict the unique behaviour of each individual in an unexperienced (target) task. As in <xref ref-type="sec" rid="s2a">Section 2.1</xref>, we compared the prediction accuracy in the target task for a given participant using a task solver trained for that participant (Original) with its accuracy using task solvers trained for other participants (Others).</p>
<p>As shown in <xref rid="fig5" ref-type="fig">Figure 5A</xref>, the percentage of correct responses was approximately 78% for the easy difficulty level and 60% for the difficult level, aligning with the accuracy levels of human participants and RTNets [<xref ref-type="bibr" rid="c34">34</xref>] A two-way (transfer task set: 12 sets (see <italic>x</italic>-axis in <xref rid="fig5" ref-type="fig">Figure 5</xref>), transfer-to participant(s): Original/Others) RM ANOVA revealed a significant effect of transfer task set (<italic>F</italic><sub>1,121</sub> = 402.851, <italic>p &lt;</italic> 0.001,<inline-formula><inline-graphic xlink:href="645375v2_inline16.gif" mimetype="image" mime-subtype="gif"/></inline-formula>), no significant effect of transfer-to participant(s) (<italic>F</italic><sub>1,11</sub> = 0.999, <italic>p</italic> = 0.339,<inline-formula><inline-graphic xlink:href="645375v2_inline17.gif" mimetype="image" mime-subtype="gif"/></inline-formula>), and no significant interaction effect (<italic>F</italic><sub>1,121</sub> = 0.478, <italic>p</italic> = 0.718,<inline-formula><inline-graphic xlink:href="645375v2_inline18.gif" mimetype="image" mime-subtype="gif"/></inline-formula>).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Results for the transfer-to-original-participant (Original) and transfer-to-other-participants (Others) settings in the MNIST task.</title>
<p><bold>A</bold> Percentage of correct responses. <bold>B</bold> Prediction error (likelihood). <bold>C</bold> Percentage of matches to actual behaviour.</p></caption>
<graphic xlink:href="645375v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>A comparison using individual behavioural data revealed differences between Original and Others. <xref rid="fig5" ref-type="fig">Figure 5B</xref> shows the prediction accuracy for each task transfer set. A two-way RM ANOVA revealed significant effects of transfer task set (<italic>F</italic><sub>1,121</sub> = 84.899, <italic>p &lt;</italic> 0.001,<inline-formula><inline-graphic xlink:href="645375v2_inline19.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) and transfer-to participant(s) (<italic>F</italic><sub>1,11</sub> = 18.180, <italic>p</italic> = 0.001, <inline-formula><inline-graphic xlink:href="645375v2_inline20.gif" mimetype="image" mime-subtype="gif"/></inline-formula>), and a significant interaction effect (<italic>F</italic><sub>11,121</sub> = 2.665, <italic>p</italic> = 0.047, <inline-formula><inline-graphic xlink:href="645375v2_inline21.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). Bonferroni-corrected pairwise comparisons indicated that the prediction loss for Original was significantly lower than for Others in the transfer task sets of DA →EA, EA →ES, and DS →ES, and DA →DS. However, no significant differences were found in the other eight transfer sets (see Table S1, Supplementary materials). The percentage of matches to actual behaviour is shown in <xref rid="fig5" ref-type="fig">Figure 5C</xref>. A two-way RM ANOVA revealed significant effects of transfer task set (<italic>F</italic><sub>1,121</sub> = 113.049, <italic>p &lt;</italic> 0.001, <inline-formula><inline-graphic xlink:href="645375v2_inline21a.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) and transfer-to participant(s) (<italic>F</italic><sub>1,11</sub> = 14.626, <italic>p</italic> = 0.003, <inline-formula><inline-graphic xlink:href="645375v2_inline22.gif" mimetype="image" mime-subtype="gif"/></inline-formula>), and no significant interaction (<italic>F</italic><sub>11,121</sub> = 1.789, <italic>p</italic> = 0.143,<inline-formula><inline-graphic xlink:href="645375v2_inline23.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). These results for prediction error and percentage of matches indicate that a task solver specialized for a specific individual using the EIDT model does not predict well the behaviour of other individuals.</p>
<p><xref rid="fig6" ref-type="fig">Figure 6</xref> visualizes the percentage of correct responses for each digit in the MNIST tasks, highlighting behavioural tendencies reproduced by the model. For example, Participant #33 exhibited a lower percentage for digit 3 compared to other digits, which was captured by the model. Participant #47 showed a drastically lower percentage for digit 1, a pattern also reflected in the model’s predictions.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Percentage of correct responses for each stimulus digit in human behaviour and model predictions. Model predictions were conducted under the transfer experiment from Setting ES to Setting EA.</title></caption>
<graphic xlink:href="645375v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Discussion</title>
<p>We proposed an EIDT framework for modeling the unique decision-making process of each individual. This framework enables the transfer of an individuality index from a (source) task to a different (target) task, allowing a task solver predict behaviours in the target task. Several neural network techniques, such as autoencoders [<xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c48">48</xref>], hypernetworks [<xref ref-type="bibr" rid="c20">20</xref>], and learning-to-learn [<xref ref-type="bibr" rid="c53">53</xref>, <xref ref-type="bibr" rid="c43">43</xref>], facilitate this transfer. Our experiments, conducted on both value-guided sequential and perceptual decision-making tasks, demonstrated the potential of the proposed EIDT framework in individuality transfer across tasks.</p>
<sec id="s3a">
<title>EIDT framework transfers individuality across tasks</title>
<p>The EIDT framework was originally proposed by Dezfouli et al. [<xref ref-type="bibr" rid="c10">10</xref>] for a bandit task. Their model was designed to predict behaviour within a session performed by a given participant, leveraging behavioural data from other sessions for model training. We extended this idea in three key ways. First, we validated that the framework is effective for previously unseen individuals who were not included in model training. Although these individuals provided behavioural data in the source task to identify their individuality indices, their data were not used for model training. Second, we demonstrated that individuality indices can be transferred even when the source and target tasks differ, indicating that decision-making tendencies are transferable across tasks. Third, while the original work focused on value-guided tasks, we validated the framework’s applicability to perceptual decision-making tasks, specifically the MNIST task. These findings establish that the EIDT framework effectively captures individual differences across both tasks and individuals.</p>
</sec>
<sec id="s3b">
<title>Interpreting the individuality index remains challenging</title>
<p>The interpretation of the individuality index remains an open question. Since interpretation often requires task-specific considerations [<xref ref-type="bibr" rid="c13">13</xref>], it falls outside the primary scope of this study, whose aim is to develop a general framework for individuality transfer. Previous research [<xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c18">18</xref>] has explored associating neural network parameters with cognitive or functional meanings. Approaches such as disentangling techniques [<xref ref-type="bibr" rid="c2">2</xref>] and cognitive model integration [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c14">14</xref>] could aid in better understanding the cognitive and functional significance of the individuality index.</p>
<p>Regarding the individuality index, while disentanglement and separation losses [<xref ref-type="bibr" rid="c10">10</xref>] during the training of model training could enhance interpretability, we used only the reproduction loss, as defined in (5). Our results showed that the variables of the individuality index were correlated, suggesting that they do not independently influence behaviour. Although this dependency complicates the interpretation of the individuality index, we decided not to introduce explicit disentanglement constraints because interpretable parameters in cognitive models (e.g., [<xref ref-type="bibr" rid="c9">9</xref>]) are not necessarily independent (e.g., an individual with a high learning rate may also have a high inverse temperature [<xref ref-type="bibr" rid="c27">27</xref>], resulting these two parameters is represented with one variable).</p>
</sec>
<sec id="s3c">
<title>Why can the encoder extract individuality for unseen individuals?</title>
<p>Our experiments, which divided participants into training and test participant pools, demonstrated that the framework successfully extracts individuality for completely new individuals. This generalization likely relies on the fact that individuality indices form clusters and individuals similar to new participants exist in the training participant pool [<xref ref-type="bibr" rid="c57">57</xref>]. The success of individuality transfer in our study suggests that individuals can be clustered based on behavioural patterns. Behavioural clustering has been widely discussed in relation to psychiatric conditions, medication effects, and gender-based differences (e.g., [<xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c50">50</xref>, <xref ref-type="bibr" rid="c40">40</xref>]). Our results could contribute to a deeper discussion of behavioural characteristics by clustering not only these groups but also healthy controls.</p>
</sec>
<sec id="s3d">
<title>Which processes contribute to individuality?</title>
<p>In the MNIST task, we assumed that individuality emerged primarily from the decision-making process (implemented by an RNN [<xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c6">6</xref>]), rather than from the visual processing system (implemented by a CNN [<xref ref-type="bibr" rid="c55">55</xref>]). The CNN was pretrained, and the decoder did not tune its weights. Our results do not rule out the possibility that the visual system also exhibits individuality [<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c47">47</xref>]; however, they imply that individual differences in perceptual decision-making can be explained primarily by variations in decision-making system [<xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c21">21</xref>]. This assumption provides valuable insights for research on human perception.</p>
</sec>
<sec id="s3e">
<title>Limitations</title>
<p>One limitation is that the source and target tasks were relatively similar. Even the cognitive model, despite its lower prediction accuracy, captured individual tendencies to some extent. Thus, our findings do not fully evaluate the generalizability of individuality transfer across diverse task domains. To broaden applicability, future studies should validate transfer across more distinct tasks that share underlying principles of individuality.</p>
<p>The effectiveness of individuality transfer may be influenced by dataset volume. As discussed earlier, prediction performance may depend on whether similar individuals exist in the training participant pool. In our study, 100 participants were sufficient for effective transfer. However, tasks involving greater behavioural diversity may require a substantially larger dataset.</p>
<p>As discussed earlier, the interpretability of the individuality index requires further investigation. Furthermore, the optimal dimensionality of the individuality index remains unclear. This likely depends on the complexity of tasks involved—specifically, the number of factors needed to represent the diversity of behaviour observed in those tasks. While these factors have been explored in cognitive modeling research (e.g., [<xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c13">13</xref>]), a clear understanding at the individual level is still lacking. Integrating cognitive modeling with data-driven neural network approaches [<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c19">19</xref>] could help identify key factors underlying individual differences in decision-making.</p>
</sec>
<sec id="s3f">
<title>Future directions</title>
<p>To further generalize our framework, a large-scale dataset is necessary, as discussed in the limitations. This dataset should include a large number of participants to ensure prediction performance for diverse individuals [<xref ref-type="bibr" rid="c32">32</xref>]. All participants should perform the same set of tasks, which should include a variety of tasks [<xref ref-type="bibr" rid="c56">56</xref>]. Building upon our framework, where the encoder currently accepts action sequences from only a single task, a more generalizable encoder should be able to process behavioural data from multiple tasks to generate a more robust individuality index. To enhance encoder, a multi-head neural network architecture [<xref ref-type="bibr" rid="c4">4</xref>] could be utilized. A generalized individuality index would enable transfer to a wider variety of tasks and allow accurate and detailed parameterization of individuals using data from only a single task.</p>
<p>Robust and generalizable parameterization of individuality enables computational modeling at the individual level. This approach, in turn, makes it possible to replicate individuals’ cognitive and functional characteristics <italic>in silico</italic> [<xref ref-type="bibr" rid="c41">41</xref>]. We anticipate that it offers a promising pathway toward a new frontier: artificial intelligence endowed with individuality.</p>
</sec>
</sec>
<sec id="s4">
<label>4</label>
<title>Methods</title>
<sec id="s4a">
<label>4.1</label>
<title>General framework for individuality transfer across tasks</title>
<p>We formulate the problem of individuality transfer, which involves extracting an individuality index from a source task and predicting behaviour in a target task with preserving individuality. We consider two tasks, <italic>A</italic> and <italic>B</italic>, which are different but related. For example, task <italic>A</italic> might be a 2-step MDP task, while task <italic>B</italic> is a 3-step MDP task.</p>
<p>The individuality transfer across tasks is defined as follows. An individual <italic>K</italic> performs a problem within task <italic>A</italic>, with their behaviour recorded as 𝒜<sub><italic>K</italic></sub>. Our objective is to predict ℬ<sub><italic>K</italic></sub>, which represents <italic>K</italic>’s behaviour when performing task <italic>B</italic>. To achieve this, we extract an individuality index <bold><italic>z</italic></bold> from 𝒜<sub><italic>K</italic></sub>, capturing the individual’s behavioural characteristics. This index <bold><italic>z</italic></bold> is then used to construct a task solver, enabling it to mimic <italic>K</italic>’s behaviour in task <italic>B</italic>. Since task <italic>A</italic> provides data for estimating the individuality index and task <italic>B</italic> is the target of behaviour prediction, we refer to them as the source task and target task, respectively.</p>
<p>Our proposed framework for the individuality transfer consists of three modules:</p>
<p><bold>Task solver</bold> predicts behaviour in the target task <italic>B</italic>.</p>
<p><bold>Encder</bold> extracts the individuality index from the source task <italic>A</italic>.</p>
<p><bold>Decoder</bold> generates the weights of the task solver based on the individuality index.</p>
<p>These modules are illustrated in <xref rid="fig1" ref-type="fig">Figure 1</xref>. We refer to this framework as EIDT, an acronym for encoder, individuality index, decoder and task solver.</p>
<sec id="s4a1">
<label>4.1.1</label>
<title>Data representation</title>
<p>For training, we assume that behaviour data from a participant pool (𝒫<italic>K</italic> ∉ 𝒫), where each participant has performed both tasks <italic>A</italic> and <italic>B</italic>. These dataset are represented as 𝒜 = <italic>{</italic>𝒜<sub><italic>n</italic></sub><italic>}</italic><sub><italic>n</italic>∈<italic>P</italic></sub> and ℬ = <italic>{</italic>ℬ<sub><italic>n</italic></sub><italic>}</italic><sub><italic>n</italic>∈<italic>P</italic></sub>.</p>
<p>For each individual <italic>n</italic>, the set 𝒜<sub><italic>n</italic></sub> consists of one or more sets, each containing a problem instance <italic>ϕ</italic> (stimuli, task settings, or environment in task <italic>A</italic>) and a sequence of action(s) <italic>α</italic> (recorded behavioural responses). For example, in an MDP task, <italic>ϕ</italic> represents the Markov process (state-action-reward transition) and <italic>α</italic> consists of choices over multiple trials. In a simple object recognition task, <italic>ϕ</italic> is a visual stimulus and <italic>α</italic> is the participant’s response to the stimulus.</p>
<p>Similarly, ℬ<sub><italic>n</italic></sub> consists of a problem instance <italic>ψ</italic> and an action sequence <italic>β</italic>.</p>
</sec>
<sec id="s4a2">
<label>4.1.2</label>
<title>Task solver</title>
<p>The task solver predicts the action sequence for task <italic>B</italic> as
<disp-formula id="eqn1">
<graphic xlink:href="645375v2_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>ψ</italic> is a specific problem in task <italic>B</italic> and Θ<sub>TS</sub> represents the solver’s weights. The task solver architecture is tailored to task <italic>B</italic>. For example, in an MDP task, the task solver outputs a sequence of actions in response to <italic>ψ</italic>. In a simple object recognition task, it produces an action based on a visual stimulus <italic>ψ</italic>.</p>
</sec>
<sec id="s4a3">
<label>4.1.3</label>
<title>Encoder</title>
<p>The encoder processes an action sequence(s) <italic>α</italic> and generates an individuality index <bold><italic>z</italic></bold> ∈ ℝ<sup><italic>M</italic></sup> as
<disp-formula id="eqn2">
<graphic xlink:href="645375v2_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>ϕ</italic> is a problem in task <italic>A</italic>, Θ<sub>ENC</sub> represents the encoder’s weights, and <italic>M</italic> is the dimensionality of the individual index. The encoder architecture is task-specific and designed for task <italic>A</italic>.</p>
</sec>
<sec id="s4a4">
<label>4.1.4</label>
<title>Decoder</title>
<p>The decoder receives the individuality index <bold><italic>z</italic></bold> and generates the task solver’s weights as
<disp-formula id="eqn3">
<graphic xlink:href="645375v2_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where Θ<sub>DEC</sub> represents the decoder’s weights. Since the decoder determines the task solver’s weights, it functions as a hypernetwork [<xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c22">22</xref>].</p>
</sec>
<sec id="s4a5">
<label>4.1.5</label>
<title>Training objective</title>
<p>Although tasks <italic>A</italic> and <italic>B</italic> differ, an individual’s decision-making system remains consistent across tasks. We model this using the individuality index <bold><italic>z</italic></bold>, linking it to the task solver via the encoder and decoder. For training, we use behavioural dataset {𝒜<sub><italic>n</italic></sub>, <italic>ℬ</italic><sub><italic>n</italic></sub> <italic>}</italic><sub><italic>n</italic>∈<italic>𝒫</italic></sub> from a individual pool 𝒫.</p>
<p>Let <italic>α</italic> be an action sequence representing individual <italic>n</italic>’s behaviour on the source task, i.e., (<italic>α, ϕ</italic>) ∈ 𝒜<sub><italic>n</italic></sub>, <italic>n</italic> ∈ 𝒫. The individuality index is derived by <bold><italic>z</italic></bold> = ENC(<italic>α, ϕ</italic>; Θ<sub>ENC</sub>). The weights of the task solver are then given by Θ<sub>TS</sub> = DEC(<bold><italic>z</italic></bold>; Θ<sub>DEC</sub>). Subsequently, the task solver, with the given weights, predicts an action sequence for task <italic>B</italic> as <inline-formula><inline-graphic xlink:href="645375v2_inline24.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,where (<italic>β, ψ</italic>) ∈ <italic>B</italic><sub><italic>n</italic></sub>. We then measure the prediction error between <inline-formula><inline-graphic xlink:href="645375v2_inline25.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <italic>β</italic> as:
<disp-formula id="eqn4">
<graphic xlink:href="645375v2_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>β</italic> is an action sequence in ℬ<sub><italic>n</italic></sub> recorded along with the problem <italic>ψ</italic>, and <italic>O</italic>(·,·) is a suitable loss function (e.g., likelihood-based loss for probabilistic outputs). Using the datasets containing the behaviour of the individual pool 𝒫, the weights of the encoder and decoders, Θ<sub>ENC</sub> and Θ<sub>DEC</sub>, are optimized by minimizing the total loss:
<disp-formula id="eqn5">
<graphic xlink:href="645375v2_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
<p>This section provides a general formulation of individuality transfer across two tasks. For specific details on task architectures and loss functions, see <xref ref-type="sec" rid="s4b">Sections 4.2</xref> and <xref ref-type="sec" rid="s4c">4.3</xref>.</p>
</sec>
</sec>
<sec id="s4b">
<label>4.2</label>
<title>Experiment on MDP task</title>
<p>We validated our individuality transfer framework using two different decisionmaking tasks: the MDP task and the MNIST task. This section focuses on the MDP tasks, a dynamic multi-step decision-making task.</p>
<sec id="s4b1">
<label>4.2.1</label>
<title>Task</title>
<p>At the beginning of each episode, an initial state-cue is presented to the participant. For human participants, the state-cue is represented by animal images (<xref rid="fig7" ref-type="fig">Figure 7</xref>). For the cognitive model (Q-learning agent) and neural network-based model, the state-cue is represented numerically (e.g., (2, 1) for the first task state in the second choice). The participant makes a binary decision (denoted as action <italic>C</italic><sub>1</sub> or <italic>C</italic><sub>2</sub>) for each step. In the human experiment, these actions correspond to pressing the left or right cursor key. With a certain probability (either 0.8/0.2 or 0.6/0.4), known as the state-action transition probability, the participant transitions to one of two subsequent task states. This process repeats two times for the 2-step MDP task and three times in the 3-step MDP task. After the final step, the participant receives an outcome: either a reward (<italic>r</italic> = 1) or no reward (<italic>r</italic> = 0). For human participants, rewards were displayed as symbols, as shown in <xref rid="fig7" ref-type="fig">Figure 7</xref>. Each sequence from initial state-cue presentation to reward delivery constitutes an <italic>episode</italic>.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7:</label>
<caption><title>The 3-step MDP task.</title> 
<p><bold>A</bold>. Tree diagram illustrating state-action transitions. <bold>B</bold>. Flow of a single episode in the behavioural experiment for human participants.</p></caption>
<graphic xlink:href="645375v2_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The state-action transition probability <italic>T</italic> (<italic>s, a, s</italic><sup><italic>′</italic></sup>) from a task state <italic>s</italic> to a preceding state <italic>s</italic><sup><italic>′</italic></sup> given an action <italic>a</italic> varies gradually across episodes. With probability <italic>p</italic><sub>trans</sub>, one of the transition probabilities switches to a new set chosen from {(0.8, 0.2), (0.2, 0.8), (0.6, 0.4), (0.4, 0.6)}. Consequently, participants must adjust their decision-making strategy in response to these shifts in transition probabilities to maintain reward maximization.</p>
</sec>
<sec id="s4b2">
<label>4.2.2</label>
<title>Behavioural data collection</title>
<p>We recruited 123 participants via Prolific. All participants provided their informed consent online. This study was approved by the Committee for Human Research at the Graduate School of Engineering, The University of Osaka, and compiled with the Declaration of Helsinki. Participants received a base compensation of £4 for completing the entire experiment, A performance-based bonus (£0 to £2, average: £1) was awarded based on rewards earned in the MDP task.</p>
<p>Each participant completed 3 sequences for each step condition (2-step and 3-step MDP tasks), with each sequence comprising 50 episodes. The order of the 2-step and 3-step MDP tasks was randomized across sequences. State-cue assignment (animal images) were randomly determined for each sequence. Participants took a mandatory break (≥ 1 minute) between sequences.</p>
<p>To ensure data quality, we excluded participants based on response time, action bias, and task performance, as follows. Participants with an average response time was below 0.75 s or whose standard deviation of response time was over 10 s were excluded. Additionally, participants exhibiting a strong action bias (where 85% or more of actions were either left or right presses) were rejected. Furthermore, participants with an average reward below below (− 1.5 × interquartile range + first quantile) were excluded. This screening resulted in a final sample of 98 participants.</p>
</sec>
<sec id="s4b3">
<label>4.2.3</label>
<title>Cognitive model: Q-learning</title>
<p>To model decision-making in the MDP task, we employed a Q-learning agent [<xref ref-type="bibr" rid="c46">46</xref>]. At each step <italic>t</italic>, the agent was presented with the current task state <italic>s</italic><sub><italic>t</italic></sub> and selected an action <italic>a</italic><sub><italic>t</italic></sub>. The agent maintained <italic>Q</italic>-values, denoted as <italic>Q</italic>(<italic>s, a</italic>), for all state-action pairs, where <italic>s</italic> was a state of the set of all possible task states <italic>𝒮</italic> and <italic>a</italic> was an action of the set of available actions in that state 𝒞<sub><italic>s</italic></sub>. The probability of selecting action <italic>a</italic> was determined by a softmax policy:
<disp-formula id="eqn6">
<graphic xlink:href="645375v2_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>q</italic><sub>it</sub> <italic>&gt;</italic> 0 was a parameter called the inverse temperature or reward sensitivity, controlling the balance between exploration and exploitation.</p>
<p>After selecting action <italic>a</italic><sub><italic>t</italic></sub>, the agent received an outcome <italic>r</italic><sub><italic>t</italic></sub> ∈ 0, 1 and transitioned to a new state <italic>s</italic><sub><italic>t</italic>+1</sub>. The <italic>Q</italic>-value for the selected action was updated by
<disp-formula id="eqn7">
<graphic xlink:href="645375v2_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>q</italic><sub>lr</sub> ∈ (0, 1) was the learning rate, determining how much newly acquired information replaced existing knowledge, and <italic>q</italic><sub>dr</sub> ∈ (0, 1) was the discount rate, governing the extent to which future rewards influenced current decision. For actions not selected, the agent applied a forgetting factor <italic>q</italic><sub>ff</sub>, updating <italic>Q</italic>-values as
<disp-formula id="eqn8">
<graphic xlink:href="645375v2_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
for <inline-formula><inline-graphic xlink:href="645375v2_inline26.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
</sec>
<sec id="s4b4">
<label>4.2.4</label>
<title>EIDT model</title>
<p>This section describes the specific models used for individuality transfer in the MDP task.</p>
<sec id="s4b4a">
<title>Data representation</title>
<p>Since MDP tasks involve sequential decision-making, each action sequence consists of multiple actions within a single session. In our experiment, each participant completed <italic>L</italic> trials per session, with <italic>L</italic> = 100 for the 2-step task and <italic>L</italic> = 150 for the 3-step MDP task. The action sequence is represented as [(<italic>s</italic><sub>1</sub>, <italic>a</italic><sub>1</sub>, <italic>r</italic><sub>1</sub>), …, (<italic>s</italic><sub><italic>L</italic></sub>, <italic>a</italic><sub><italic>L</italic></sub>, <italic>r</italic><sub><italic>L</italic></sub>)], where, <italic>s</italic><sub><italic>t</italic></sub> denotes the task state at trial <italic>t, a</italic><sub><italic>t</italic></sub> ∈ <italic>C</italic> represents the action selected from the set <inline-formula><inline-graphic xlink:href="645375v2_inline27.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (with <italic>K</italic> = 2 in out task), and <italic>r</italic><sub><italic>t</italic></sub>∈{ 0, 1} indicates whether a reward was received. In the <italic>M</italic>-step MDP task described in <xref ref-type="sec" rid="s4b">Section 4.2</xref>, each task state is represented as (<italic>m, c</italic><sub><italic>m</italic></sub>), where <italic>m</italic> denotes the current step within the episode (<italic>m</italic> ∈ {1, …, <italic>M}</italic>) and <italic>c</italic><sub><italic>m</italic></sub> corresponds to the cue presented to the participant. The action sequence, denoted as <italic>α</italic> or <italic>β</italic>, consists of a sequence of selected actions (<italic>a</italic><sub>1</sub>, …, <italic>a</italic><sub><italic>L</italic></sub>), while a problem, denoted as <italic>ϕ</italic> or <italic>ψ</italic>, is represented as ((<italic>s</italic><sub>1</sub>, …, <italic>s</italic><sub><italic>L</italic></sub>), (<italic>r</italic><sub>1</sub>, …, <italic>r</italic><sub><italic>L</italic></sub>)).</p>
</sec>
<sec id="s4b4b">
<title>Task solver</title>
<p>Before describing the encoder and decoder, we define the architecture of the task solver, which generates actions for the <italic>M</italic>-step MDP task. The task solver is implemented using a gated recurrent unit (GRU) [<xref ref-type="bibr" rid="c7">7</xref>] with <italic>Q</italic> cells, where <italic>Q</italic> = 4 for the 2-step task and <italic>Q</italic> = 8 for the 3-step task. At time-step <italic>t</italic>, the GRU takes as input the previous hidden state <bold><italic>h</italic></bold><sub><italic>t</italic>−1</sub> ∈ ℝ<sup><italic>Q</italic></sup>, the previous task state <italic>s</italic><sub><italic>t</italic>−1</sub>, the previous action <italic>a</italic><sub><italic>t</italic>−1</sub>, the previous reward <italic>r</italic><sub><italic>t</italic>−1</sub>, and the current task state <italic>s</italic><sub><italic>t</italic></sub>. It then updates the hidden state as
<disp-formula id="eqn9">
<graphic xlink:href="645375v2_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where Φ represents the GRU’s weights. The updated hidden state is then used to predict the probability of selecting each action through a fully-connected feed forward layer:
<disp-formula id="eqn10">
<graphic xlink:href="645375v2_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <bold><italic>v</italic></bold><sub><italic>t</italic></sub> represents the logit scores for each action (unnormalised probabilities), and <bold><italic>W</italic></bold>∈ ℝ<sup><italic>K×Q</italic></sup> is the weight matrix. The probabilities of each action are computed using a softmax layer:
<disp-formula id="eqn11">
<graphic xlink:href="645375v2_eqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>π</italic>(<italic>a</italic><sub><italic>t</italic></sub> = <italic>C</italic><sub><italic>k</italic></sub>) represents the probability of selecting action <italic>C</italic><sub><italic>k</italic></sub> at time <italic>t</italic>, and [<bold><italic>v</italic></bold><sub><italic>t</italic></sub>]<sub><italic>i</italic></sub> denotes the <italic>i</italic>th element of <bold><italic>v</italic></bold><sub><italic>t</italic></sub>.</p>
<p>For input encoding, we used a 1-of-K scheme. The step of the MDP task is encoded as [<xref ref-type="bibr" rid="c1">1</xref>, 0, 0] for step 1, [0, 1, 0] for step 2, and [0, 0, 1] for step 3. Each task state <italic>s</italic><sub><italic>m</italic></sub> is represented as [<xref ref-type="bibr" rid="c1">1</xref>, 0] or [0, 1] to distinguish the two state cues at each step. The participant’s action is encoded as <italic>C</italic><sub>1</sub>: [<xref ref-type="bibr" rid="c1">1</xref>, 0] or <italic>C</italic><sub>2</sub>: [0, 1], while the reward is represented as 0: [<xref ref-type="bibr" rid="c1">1</xref>, 0] or 1: [0, 1]. These encodings are concatenated to form input sequences.</p>
<p>The task solver TS(<italic>ψ</italic>; Θ<sub>TS</sub>) generates a sequence of predicted action probabilities <inline-formula><inline-graphic xlink:href="645375v2_inline28.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,using the GRU, the fully-connected layer <bold><italic>W</italic></bold>, and the softmax layer. The problem <italic>ψ</italic> defines the MDP environment, specifying state transitions and reward outcomes in response to selected action.</p>
<p>To evaluate prediction accuracy, the loss function <inline-formula><inline-graphic xlink:href="645375v2_inline29.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, defined in (4), compares human-performed action <italic>{β, ψ}</italic> with those predicted by the task solver, <inline-formula><inline-graphic xlink:href="645375v2_inline29a.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Notably, the problem <italic>ψ</italic> is not executed with the task solver; instead, the task solver predicts action probabilities based on the same task state and reward history as in the human behavioural data.</p>
</sec>
<sec id="s4b4c">
<title>Encoder and decoder</title>
<p>The encoder ENC(<italic>α, ϕ</italic>; Θ<sub>ENC</sub>) extracts an individuality index <bold><italic>z</italic></bold> from a sequence of actions <italic>α</italic> corresponding to a given environment <italic>ϕ</italic>. The first module of the encoder is a GRU, similar to the task solver, with <italic>R</italic> = 32 cells. The final hidden state <bold><italic>h</italic></bold><sub><italic>L</italic></sub> ∈ ℝ<sup><italic>R</italic></sup> serves as the basis for computing the individuality index <bold><italic>z</italic></bold> ∈ ℝ<sup><italic>M</italic></sup> using a fully-connected feed-forward network with four layers <italic>d</italic>(·) as <bold><italic>z</italic></bold> = <italic>d</italic>(<bold><italic>h</italic></bold><sub><italic>L</italic></sub>).</p>
<p>The decoder takes the individuality index <bold><italic>z</italic></bold> as input and generates the weights for the task solver by Θ<sub>TS</sub> = DEC(<bold><italic>z</italic></bold>; Θ<sub>DEC</sub>). The decoder is implemented as a single-layer linear network.</p>
</sec>
</sec>
</sec>
<sec id="s4c">
<label>4.3</label>
<title>Experiment on MNIST task</title>
<p>This section describes the specific models used for individuality transfer in hand-written digit recognition (MNIST) task.</p>
<sec id="s4c1">
<label>4.3.1</label>
<title>Task</title>
<p>The dataset used in this experiment was originally collected and published by Rafiei et al. [<xref ref-type="bibr" rid="c34">34</xref>]. In this task, participants were presented with a stimulus image depicting a handwritten digit and were required to respond by pressing the corresponding number key, as illusrtaed <xref rid="fig1" ref-type="fig">Figure 1</xref>. For further details regarding the task design and data collection, refer to [<xref ref-type="bibr" rid="c34">34</xref>].</p>
</sec>
<sec id="s4c2">
<label>4.3.2</label>
<title>EIDT model</title>
<sec id="s4c2a">
<title>Data representation</title>
<p>An action sequence, denoted as <italic>α</italic> or <italic>β</italic>, consists of a single action <italic>a</italic> and its corresponding response time <italic>b</italic>. The associated problem, represented as <italic>ϕ</italic> or <italic>ψ</italic>, corresponds to a stimulus image. The action <italic>a</italic> is selected from a set {<italic>C</italic><sub>1</sub>, … <italic>C</italic><sub><italic>K</italic></sub>}. Since the task involves recognizing digits ranging from 0 to 9, the number of possible actions is <italic>K</italic> = 10. The stimulus image, <italic>ϕ</italic> or <italic>ψ</italic>, is an image of size <italic>H× W</italic>. In this experiment, we adopted the same resolution as [<xref ref-type="bibr" rid="c34">34</xref>], setting <italic>H</italic> = <italic>W</italic> = 227.</p>
</sec>
<sec id="s4c2b">
<title>Task solver</title>
<p>The task solver for the handwritten digit recognition task is based on the model proposed by [<xref ref-type="bibr" rid="c34">34</xref>]. Their model consists of a CNN and an evidence accumulation module. However, since their model represents average human behaviour and does not account for individuality differences, we replace the accumulation module with a GRU [<xref ref-type="bibr" rid="c6">6</xref>] to capture individuality. The CNN module processes the input image and produces an evidence vector <bold><italic>e</italic></bold> = CNN(<italic>ψ</italic>), where <bold><italic>e</italic></bold> ∈ ℝ<sup><italic>K</italic></sup> and CNN(·) is based on the AlexNet architecture [<xref ref-type="bibr" rid="c26">26</xref>]. The weights of the CNN are sampled from a Bayesian neural network (BNN), introducing stochasticity in the output. This stochasticity enables the models to generate human-like, probabilistic decisions.</p>
<p>The stimulus image is fed into the CNN <italic>S</italic> times, generating <italic>S</italic> evidence distributions <bold><italic>e</italic></bold><sub><italic>t</italic></sub> ∈ ℝ<sup><italic>K</italic></sup> at each time step <italic>t</italic> = 0, …, <italic>S</italic> −1. In this study, we set <italic>S</italic> = 16 to match the maximum response time, as described later. Since the CNN weights are stochastically sampled from the BNN, the CNN’s output varies even when the same image is input multiple times. To model individuality in decision-making, we introduce a GRU with <italic>Q</italic> cells (<italic>Q</italic> = 4 in our setup). The GRU receives as input the previous hidden state <bold><italic>h</italic></bold><sub><italic>t</italic>−1</sub> ∈ ℝ<sup><italic>Q</italic></sup> and the current evidence <bold><italic>e</italic></bold><sub><italic>t</italic></sub>, updating its hidden state as
<disp-formula id="eqn12">
<graphic xlink:href="645375v2_eqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where Φ represents the GRU’s network weights. The updated hidden state is passed through a dense layer (as defined in (10)) and a softmax layer (as defined in (11)) to generate the probability distribution over possible digit classifications [<italic>P</italic><sub><italic>t</italic></sub>(<italic>C</italic><sub>1</sub>), …, <italic>P</italic><sub><italic>t</italic></sub>(<italic>C</italic><sub><italic>K</italic></sub>)] at each time step <italic>t</italic>.</p>
<p>To evaluate the prediction error, we compare the action sequences generated by human participants {<italic>β, ψ}</italic> with those predicted by the task solver <inline-formula><inline-graphic xlink:href="645375v2_inline30.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,incorporating response times into these analysis. The actual response time <italic>b</italic> is converted into an integer time step <inline-formula><inline-graphic xlink:href="645375v2_inline31.gif" mimetype="image" mime-subtype="gif"/></inline-formula> using the formula: <inline-formula><inline-graphic xlink:href="645375v2_inline32.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.For example, a response time of <italic>b</italic> = 0.765 sec is converted to <inline-formula><inline-graphic xlink:href="645375v2_inline33.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.The likelihood of observed decision is then calculated as <inline-formula><inline-graphic xlink:href="645375v2_inline34.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,where <italic>a</italic> is the actual digit chosen by the participant.</p>
<p>In this task solver, the CNN (driven by BNN) models a visual processing system, while the RNN represents the decision-making system. We assume that the visual system (implemented by CNN and BNN) is shared across all individuals, whereas the decision-making system (implemented by RNN) captures individual differences. Based on this assumption, the CNN and BNN are pretrained using the MNIST dataset [<xref ref-type="bibr" rid="c26">26</xref>], and their weight distributions are fixed across individuals. The pretraining procedure followed the original methodology [<xref ref-type="bibr" rid="c34">34</xref>].</p>
</sec>
<sec id="s4c2c">
<title>Encoder and decoder</title>
<p>Since each action sequence contains only a single action, it does not form a true “sequence.” This makes it challenging to extract individuality from a single data point. To address this, the encoder takes a set of single action sequences as input rather than a single sequence. Specifically, the encoder <inline-formula><inline-graphic xlink:href="645375v2_inline35.gif" mimetype="image" mime-subtype="gif"/></inline-formula> extracts the individuality index <bold><italic>z</italic></bold> from <italic>U</italic> sets of stimulus images <italic>ϕ</italic><sub><italic>u</italic></sub> and their corresponding responses <italic>α</italic><sub><italic>u</italic></sub>, where <italic>u</italic> = 1, …, <italic>U</italic>.</p>
<p>Here, <italic>ϕ</italic><sub><italic>u</italic></sub> represent the stimulus presented in the <italic>u</italic>th trial, and <italic>α</italic><sub><italic>u</italic></sub> represents the corresponding response. The number of action sequences <italic>U</italic> corresponds to the number of samples available for each individual in the dataset. Since the outputs for these action sequences are just averaged, <italic>U</italic> can be adjusted flexibly. The encoder architecture consists of a single CNN module, a single GRU, and a fully-connected feed-forward network. The CNN module is identical to the one used in the task solver. Given an input <italic>ϕ</italic><sub><italic>u</italic></sub>, let <bold><italic>e</italic></bold><sub><italic>t</italic>,<italic>u</italic></sub> represent the evidence output from the CNN at time step <italic>t</italic>. The GRU, which consists <italic>R</italic> cells (<italic>R</italic> = 16 in our setup), updates its hidden state based on the previous state, the current CNN evidence, and an encoding of the response action by
<disp-formula id="eqn13">
<graphic xlink:href="645375v2_eqn13.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where Ψ represents the network weights. The function <inline-formula><inline-graphic xlink:href="645375v2_inline36.gif" mimetype="image" mime-subtype="gif"/></inline-formula> outputs the one-hot encoded action <italic>a</italic> if <inline-formula><inline-graphic xlink:href="645375v2_inline37.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,and zeros otherwise. The value <inline-formula><inline-graphic xlink:href="645375v2_inline38.gif" mimetype="image" mime-subtype="gif"/></inline-formula> represents the converted response time, obtained from the original response time <italic>b</italic> in the action sequence <italic>α</italic><sub><italic>u</italic></sub>. After processing all <italic>U</italic> sequences, the final hidden states are averaged across sequences: <inline-formula><inline-graphic xlink:href="645375v2_inline39.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.The individuality index is then computed as <bold><italic>z</italic></bold> = <italic>d</italic>(<bold><italic>h</italic></bold>), where <italic>d</italic>(·) represents a single-layer fully-connected feed-forward network. The decoder, implemented as a single linear layer, takes the individuality index <bold><italic>z</italic></bold> as input and outputs the weights for the task solver.</p>
</sec>
</sec>
</sec>
<sec id="s4d">
<label>4.4</label>
<title>Analysis</title>
<sec id="s4d1">
<label>4.4.1</label>
<title>Within- and between-individual distances for evaluating the individuality index</title>
<p>To evaluate the disentanglement of the individuality index, we computed two types of distances: within-individual distance and between-individual-distance. Let <bold><italic>z</italic></bold>(<italic>α, ϕ</italic>) denote the individuality index derived from an action sequence (<italic>α, ϕ</italic>). The within-individual distance quantifies the average distance between the individuality index for each action sequence and the average individuality index for a given individual. It is defined as
<disp-formula id="eqn14">
<graphic xlink:href="645375v2_eqn14.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="645375v2_inline40.gif" mimetype="image" mime-subtype="gif"/></inline-formula> represents the average individuality index for individual <italic>n</italic>, computed as <inline-formula><inline-graphic xlink:href="645375v2_inline41.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The between-individual distance measures the distance between the average individuality index for each individual and the overall average individuality index across all individuals. It is defined as
<disp-formula id="eqn15">
<graphic xlink:href="645375v2_eqn15.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="645375v2_inline42.gif" mimetype="image" mime-subtype="gif"/></inline-formula> represents the average individuality index across all individuals, given by <inline-formula><inline-graphic xlink:href="645375v2_inline43.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.If the within-individual distance <italic>κ</italic> is smaller than the between-individual distance <italic>λ</italic><sub><italic>n</italic></sub>, this suggests that the individuality indices derived from different behavioural data of individual <italic>n</italic> are closely clustered, indicating consistency in the captured decision-making tendencies. Comparing these distances provides insight into whether the individuality index effectively represents stable and distinctive characteristics of an individual’s decision-making process.</p>
</sec>
<sec id="s4d2">
<label>4.4.2</label>
<title>Evaluation for uniqueness in task solvers</title>
<p>To assess whether a task solver generates unique behaviour for a specific participant, we compared two prediction loss scores. The first score, referred to as Original, represents the standard prediction loss for a specific participant when using the task solver designed for that participant. It is formulated as
<disp-formula id="eqn16">
<graphic xlink:href="645375v2_eqn16.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where Θ<sub>ENC</sub> and Θ<sub>DEC</sub> are omitted for simplicity, as in (4). The second score, referred to as Others, measures the prediction loss for a specific participant when using task solvers designed for other participants. It is formulated as
<disp-formula id="eqn17">
<graphic xlink:href="645375v2_eqn17.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where 𝒫 represents the set of participant indices in the test participant pool. If the task solvers successfully captures the unique decision-making tendency of each participant, the Original score <italic>L</italic><sub><italic>K</italic></sub> should be lower than the Others score ϒ<sub><italic>K</italic></sub> for all participants <italic>K</italic> ∈ <italic>𝒫</italic>.</p>
</sec>
</sec>
</sec>

</body>
<back>
<sec id="s5" sec-type="data-availability">
<label>5</label>
<title>Data availability</title>
<p>The behavioural data for the MDP task has been made publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hgshrs/indiv_trans">https://github.com/hgshrs/indiv_trans</ext-link></p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>This work was supported in part by the Japan Society for the Promotion of Science (JSPS) KAKENHI, grant number 22H05163 and 24K15047, and Japan Science and Technology Agency (JST) Advanced International Collaborative Research Program (AdCORP), grant number JPMJKB2307.</p>
</ack>
<sec id="d1e2571" sec-type="additional-information">
<title>Additional information</title>
<sec id="s6">
<label>6</label>
<title>Code availability</title>
<p>All code and trained models have been made publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hgshrs/indiv_trans">https://github.com/hgshrs/indiv_trans</ext-link></p>
</sec>
<sec id="s7">
<title>Author contributions</title>
<p>H.H. designed and performed the research, collected and analyzed the data, and drafted and edited the paper.</p>
</sec>
</sec>
<sec id="suppd1e2571" sec-type="supplementary-material">
<title>Additional files</title>
<supplementary-material id="d1e2562">
<label>Supplemental materials</label>
<media xlink:href="supplements/645375_file02.pdf"/>
</supplementary-material>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N. J.</given-names> <surname>Boogert</surname></string-name>, <string-name><given-names>J. R.</given-names> <surname>Madden</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Morand-Ferron</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Thornton</surname></string-name></person-group>. <article-title>Measuring and understanding individual differences in cognition</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>, <volume>373</volume>(<issue>1756</issue>):<fpage>20170280</fpage>, <month>9</month> <year>2018</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>C. P.</given-names> <surname>Burgess</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Higgins</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Pal</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Matthey</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Watters</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Desjardins</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Lerchner</surname></string-name></person-group>. <article-title>Understanding disentangling in beta-VAE</article-title>. <source>arXiv</source>, (<pub-id pub-id-type="arxiv">1804.03599</pub-id>), <month>4</month> <year>2018</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. R.</given-names> <surname>Busemeyer</surname></string-name> and <string-name><given-names>J. C.</given-names> <surname>Stout</surname></string-name></person-group>. <article-title>A contribution of cognitive decision models to clinical assessment: Decomposing performance on the Bechara gambling task</article-title>. <source>Psychological Assessment</source>, <volume>14</volume>(<issue>3</issue>):<fpage>253</fpage>–<lpage>262</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Canizo</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Triguero</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Conde</surname></string-name>, and <string-name><given-names>E.</given-names> <surname>Onieva</surname></string-name></person-group>. <article-title>Multi-head CNN–RNN for multi-time series anomaly detection: An industrial case study</article-title>. <source>Neurocomputing</source>, <volume>363</volume>:<fpage>246</fpage>–<lpage>260</lpage>, <month>10</month> <year>2019</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. B.</given-names> <surname>Carroll</surname></string-name> and <string-name><given-names>S. E.</given-names> <surname>Maxwell</surname></string-name></person-group>. <article-title>Individual differences in cognitive abilities</article-title>. <source>Annual Review of Psychology</source>, <volume>30</volume>(<issue>1</issue>):<fpage>603</fpage>–<lpage>640</lpage>, <month>1</month> <year>1979</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.-A.</given-names> <surname>Cheng</surname></string-name>, <string-name><given-names>I. Felipe</given-names> <surname>Rodriguez</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Kar</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Watanabe</surname></string-name>, and <string-name><given-names>T.</given-names> <surname>Serre</surname></string-name></person-group>. <article-title>RTify: Aligning deep neural networks with human behavioral decisions</article-title>. In <source>Advances in Neural Information Processing Systems</source>, <year>2024</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Cho</surname></string-name>, <string-name><given-names>B.</given-names> <surname>van Merrienboer</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Gulcehre</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Bahdanau</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Bougares</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Schwenk</surname></string-name>, and <string-name><given-names>Y.</given-names> <surname>Bengio</surname></string-name></person-group>. <article-title>Learning phrase representations using RNN encoder–decoder for statistical machine translation</article-title>. In <conf-name>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</conf-name>, pages <fpage>1724</fpage>–<lpage>1734</lpage>, <publisher-loc>Stroudsburg, PA, USA</publisher-loc>, <year>2014</year>. <publisher-name>Association for Computational Linguistics</publisher-name>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. G. E.</given-names> <surname>Collins</surname></string-name> and <string-name><given-names>M. J.</given-names> <surname>Frank</surname></string-name></person-group>. <article-title>How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis</article-title>. <source>European Journal of Neuroscience</source>, <volume>35</volume>(<issue>7</issue>):<fpage>1024</fpage>–<lpage>1035</lpage>, <month>4</month> <year>2012</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N. D.</given-names> <surname>Daw</surname></string-name>, <string-name><given-names>S. J.</given-names> <surname>Gershman</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Seymour</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Dayan</surname></string-name>, and <string-name><given-names>R. J.</given-names> <surname>Dolan</surname></string-name></person-group>. <article-title>Model-based influences on humans’ choices and striatal prediction errors</article-title>. <source>Neuron</source>, <volume>69</volume>(<issue>6</issue>):<fpage>1204</fpage>–<lpage>1215</lpage>, <month>3</month> <year>2011</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Dezfouli</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Ashtiani</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Ghattas</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Nock</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Dayan</surname></string-name>, and <string-name><given-names>S. O.</given-names> <surname>Cheng</surname></string-name></person-group>. <article-title>Disentangled behavioral representations</article-title>. In <source>Advances in Neural Information Processing Systems</source>, <year>2019</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Dezfouli</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Griffiths</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Ramos</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Dayan</surname></string-name>, and <string-name><given-names>B. W.</given-names> <surname>Balleine</surname></string-name></person-group>. <article-title>Models that learn how humans learn: The case of decision-making and its disorders</article-title>. <source>PLOS Computational Biology</source>, <volume>15</volume>(<issue>6</issue>):<fpage>e1006903</fpage>, <month>6</month> <year>2019</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. D.</given-names> <surname>Duncan</surname></string-name> and <string-name><given-names>D.</given-names> <surname>Shohamy</surname></string-name></person-group>. <article-title>Memory states influence value-based decisions</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>145</volume>(<issue>11</issue>):<fpage>1420</fpage>–<lpage>1426</lpage>, <month>11</month> <year>2016</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. K.</given-names> <surname>Eckstein</surname></string-name>, <string-name><given-names>S. L.</given-names> <surname>Master</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Xia</surname></string-name>, <string-name><given-names>R. E.</given-names> <surname>Dahl</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Wilbrecht</surname></string-name>, and <string-name><given-names>A. G.</given-names> <surname>Collins</surname></string-name></person-group>. <article-title>The interpretation of computational model parameters depends on the context</article-title>. <source>eLife</source>, <volume>11</volume>:<elocation-id>75474</elocation-id>, <month>11</month> <year>2022</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>M. K.</given-names> <surname>Eckstein</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Summerfield</surname></string-name>, <string-name><given-names>N. D.</given-names> <surname>Daw</surname></string-name>, and <string-name><given-names>K. J.</given-names> <surname>Miller</surname></string-name></person-group>. <article-title>Predictive and interpretable: combining artificial neural networks and classic cognitive models to understand human learning and decision making</article-title>. In <conf-name>Proceedings of the 45th Annual Conference of the Cognitive Science Society</conf-name>, pages <fpage>928</fpage>– <lpage>935</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names> <surname>Fel</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Felipe</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Linsley</surname></string-name>, and <string-name><given-names>T.</given-names> <surname>Serre</surname></string-name></person-group>. <article-title>Harmonizing the object recognition strategies of deep neural networks with humans</article-title>. In <source>Advances in Neural Information Processing Systems</source>, <year>2022</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Fintz</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Osadchy</surname></string-name>, and <string-name><given-names>U.</given-names> <surname>Hertz</surname></string-name></person-group>. <article-title>Using deep learning to predict human decisions and using cognitive models to explain deep learning models</article-title>. <source>Scientific Reports</source>, <volume>12</volume>(<issue>1</issue>):<fpage>4736</fpage>, <month>3</month> <year>2022</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. J.</given-names> <surname>Frank</surname></string-name>, <string-name><given-names>B. B.</given-names> <surname>Doll</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Oas-Terpstra</surname></string-name>, and <string-name><given-names>F.</given-names> <surname>Moreno</surname></string-name></person-group>. <article-title>Prefrontal and striatal dopaminergic genes predict individual differences in exploration and exploitation</article-title>. <source>Nature Neuroscience</source>, <volume>12</volume>(<issue>8</issue>):<fpage>1062</fpage>–<lpage>1068</lpage>, <month>8</month> <year>2009</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names> <surname>Ger</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Nachmani</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Wolf</surname></string-name>, and <string-name><given-names>N.</given-names> <surname>Shahar</surname></string-name></person-group>. <article-title>Harnessing the flexibility of neural networks to predict dynamic theoretical parameters underlying human choice behavior</article-title>. <source>PLOS Computational Biology</source>, <volume>20</volume>(<issue>1</issue>):<fpage>e1011678</fpage>, <month>1</month> <year>2024</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names> <surname>Ger</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Shahar</surname></string-name>, and <string-name><given-names>N.</given-names> <surname>Shahar</surname></string-name></person-group>. <article-title>Using recurrent neural network to estimate irreducible stochasticity in human choice behavior</article-title>. <source>eLife</source>, <volume>13</volume>, <month>9</month> <year>2024</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Ha</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Dai</surname></string-name>, and <string-name><given-names>Q. V.</given-names> <surname>Le</surname></string-name></person-group>. <article-title>Hypernetworks</article-title>. <source>arXiv</source>, (<pub-id pub-id-type="arxiv">1609.09106</pub-id>), <month>9</month> <year>2016</year>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Kar</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Kubilius</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Schmidt</surname></string-name>, <string-name><given-names>E. B.</given-names> <surname>Issa</surname></string-name>, and <string-name><given-names>J. J.</given-names> <surname>DiCarlo</surname></string-name></person-group>. <article-title>Evidence that recurrent circuits are critical to the ventral stream’s execution of core object recognition behavior</article-title>. <source>Nature Neuroscience</source>, <volume>22</volume>(<issue>6</issue>):<fpage>974</fpage>–<lpage>983</lpage>, <month>6</month> <year>2019</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>T.</given-names> <surname>Karaletsos</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Dayan</surname></string-name>, and <string-name><given-names>Z.</given-names> <surname>Ghahramani</surname></string-name></person-group>. <article-title>Probabilistic metarepresentations of neural networks</article-title>. <source>arXiv</source>, (<pub-id pub-id-type="arxiv">1810.00555</pub-id>), <month>10</month> <year>2018</year>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Katahira</surname></string-name></person-group>. <article-title>The relation between reinforcement learning parameters and the influence of reinforcement history on choice behavior</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>66</volume>:<fpage>59</fpage>–<lpage>69</lpage>, <month>6</month> <year>2015</year>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Koivisto</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Railo</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Revonsuo</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Vanni</surname></string-name>, and <string-name><given-names>N.</given-names> <surname>Salminen-Vaparanta</surname></string-name></person-group>. <article-title>Recurrent processing in V1/V2 contributes to categorization of natural scenes</article-title>. <source>The Journal of Neuroscience</source>, <volume>31</volume>(<issue>7</issue>):<fpage>2488</fpage>–<lpage>2492</lpage>, <month>2</month> <year>2011</year>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Kriegeskorte</surname></string-name></person-group>. <article-title>Deep neural networks: A new framework for modeling biological vision and brain information processing</article-title>. <source>Annual Review of Vision Science</source>, <volume>1</volume>(<issue>1</issue>):<fpage>417</fpage>–<lpage>446</lpage>, <month>11</month> <year>2015</year>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Krizhevsky</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Sutskever</surname></string-name>, and <string-name><given-names>G. E.</given-names> <surname>Hinton</surname></string-name></person-group>. <article-title>ImageNet classification with deep convolutional neural networks</article-title>. In <source>Advances in Neural Information Processing Systems</source>, <year>2012</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>W.-H.</given-names> <surname>Lin</surname></string-name>, <string-name><given-names>A. M.</given-names> <surname>Clarke</surname></string-name>, <string-name><given-names>K. S.</given-names> <surname>Pilz</surname></string-name>, <string-name><given-names>M. H.</given-names> <surname>Herzog</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Kunchulia</surname></string-name></person-group>. <article-title>Intact reinforcement learning in healthy ageing</article-title>. <source>bioRXiv</source>, <month>5</month> <year>2023</year>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. J.</given-names> <surname>Miller</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Eckstein</surname></string-name>, <string-name><given-names>M. M.</given-names> <surname>Botvinick</surname></string-name>, and <string-name><given-names>Z.</given-names> <surname>Kurth-Nelson</surname></string-name></person-group>. <article-title>Cognitive model discovery via disentangled RNNs</article-title>. In <source>Advances in Neural Information Processing Systems</source>, pages <fpage>61377</fpage>–<lpage>61394</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. J.</given-names> <surname>Navarro</surname></string-name>, <string-name><given-names>T. L.</given-names> <surname>Griffiths</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Steyvers</surname></string-name>, and <string-name><given-names>M. D.</given-names> <surname>Lee</surname></string-name></person-group>. <article-title>Modeling individual differences using Dirichlet processes</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>50</volume>(<issue>2</issue>):<fpage>101</fpage>–<lpage>122</lpage>, <month>4</month> <year>2006</year>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. P.</given-names> <surname>O’Doherty</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Hampton</surname></string-name>, and <string-name><given-names>H.</given-names> <surname>Kim</surname></string-name></person-group>. <article-title>Model-based fMRI and its application to reward learning and decision making</article-title>. <source>Annals of the New York Academy of Sciences</source>, <volume>1104</volume>(<issue>1</issue>):<fpage>35</fpage>–<lpage>53</lpage>, <month>5</month> <year>2007</year>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. L.</given-names> <surname>Pedersen</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Frank</surname></string-name>, and <string-name><given-names>G.</given-names> <surname>Biele</surname></string-name></person-group>. <article-title>The drift diffusion model as the choice rule in reinforcement learning</article-title>. <source>Psychonomic Bulletin and Review</source>, <volume>24</volume>(<issue>4</issue>):<fpage>1234</fpage>–<lpage>1251</lpage>, <month>12</month> <year>2017</year>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. C.</given-names> <surname>Peterson</surname></string-name>, <string-name><given-names>D. D.</given-names> <surname>Bourgin</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Agrawal</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Reichman</surname></string-name>, and <string-name><given-names>T. L.</given-names> <surname>Griffiths</surname></string-name></person-group>. <article-title>Using large-scale experiments and machine learning to discover theories of human decision-making</article-title>. <source>Science</source>, <volume>372</volume>(<issue>6547</issue>):<fpage>1209</fpage>–<lpage>1214</lpage>, <month>6</month> <year>2021</year>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. T.</given-names> <surname>Radev</surname></string-name>, <string-name><given-names>U. K.</given-names> <surname>Mertens</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Voss</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Ardizzone</surname></string-name>, and <string-name><given-names>U.</given-names> <surname>Kothe</surname></string-name></person-group>. <article-title>BayesFlow: Learning complex stochastic models with invertible neural networks</article-title>. <source>IEEE Transactions on Neural Networks and Learning Systems</source>, <volume>33</volume>(<issue>4</issue>):<fpage>1452</fpage>–<lpage>1466</lpage>, <month>4</month> <year>2022</year>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F.</given-names> <surname>Rafiei</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Shekhar</surname></string-name>, and <string-name><given-names>D.</given-names> <surname>Rahnev</surname></string-name></person-group>. <article-title>The neural network RTNet exhibits the signatures of human perceptual decision-making</article-title>. <source>Nature Human Behaviour</source>, <volume>8</volume>(<issue>9</issue>):<fpage>1752</fpage>–<lpage>1770</lpage>, <month>7</month> <year>2024</year>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Rajalingham</surname></string-name>, <string-name><given-names>E. B.</given-names> <surname>Issa</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Bashivan</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Kar</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Schmidt</surname></string-name>, and <string-name><given-names>J. J.</given-names> <surname>DiCarlo</surname></string-name></person-group>. <article-title>Large-scale, high-resolution comparison of the core visual object recognition behavior of humans, monkeys, and state-of-the-art deep artificial neural networks</article-title>. <source>The Journal of Neuroscience</source>, <volume>38</volume>(<issue>33</issue>):<fpage>7255</fpage>–<lpage>7269</lpage>, <month>8</month> <year>2018</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Ratcliff</surname></string-name> and <string-name><given-names>G.</given-names> <surname>McKoon</surname></string-name></person-group>. <article-title>The diffusion decision model: Theory and data for two-choice decision tasks</article-title>. <source>Neural Computation</source>, <volume>20</volume>(<issue>4</issue>):<fpage>873</fpage>–<lpage>922</lpage>, <month>4</month> <year>2008</year>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Rmus</surname></string-name>, <string-name><given-names>T.-F.</given-names> <surname>Pan</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Xia</surname></string-name>, and <string-name><given-names>A. G. E.</given-names> <surname>Collins</surname></string-name></person-group>. <article-title>Artificial neural net-works for model identification and parameter estimation in computational cognitive models</article-title>. <source>PLOS Computational Biology</source>, <volume>20</volume>(<issue>5</issue>):<fpage>e1012119</fpage>, <month>5</month> <year>2024</year>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>D. E.</given-names> <surname>Rumelhart</surname></string-name> and <string-name><given-names>J. L.</given-names> <surname>McClelland</surname></string-name></person-group>. <chapter-title>Learning internal representations by error propagation</chapter-title>. In <source>Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations</source>, pages <fpage>318</fpage>–<lpage>362</lpage>. MIT Press, <year>1987</year>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Schaeffer</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Khona</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Meshulam</surname></string-name>, and <string-name><given-names>I.</given-names> <surname>Fiete</surname></string-name></person-group>. <article-title>Reverse-engineering recurrent neural network solutions to a hierarchical inference task for mice</article-title>. In <source>Advances in Neural Information Processing Systems</source>, <year>2020</year>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Sevy</surname></string-name>, <string-name><given-names>K. E.</given-names> <surname>Burdick</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Visweswaraiah</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Abdelmessih</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Lukin</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Yechiam</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Bechara</surname></string-name></person-group>. <article-title>Iowa gambling task in schizophrenia: A review and new data in patients with schizophrenia and co-occurring cannabis use disorders</article-title>. <source>Schizophrenia Research</source>, <volume>92</volume>(<issue>1-3</issue>):<fpage>74</fpage>–<lpage>84</lpage>, <month>5</month> <year>2007</year>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W.</given-names> <surname>Shengli</surname></string-name></person-group>. <article-title>Is human digital twin possible?</article-title> <source>Computer Methods and Programs in Biomedicine Update</source>, <volume>1</volume>:<fpage>100014</fpage>, <month>1</month> <year>2021</year>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Siegelmann</surname></string-name> and <string-name><given-names>E.</given-names> <surname>Sontag</surname></string-name></person-group>. <article-title>On the computational power of neural nets</article-title>. <source>Journal of Computer and System Sciences</source>, <volume>50</volume>(<issue>1</issue>):<fpage>132</fpage>–<lpage>150</lpage>, <month>2</month> <year>1995</year>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H. F.</given-names> <surname>Song</surname></string-name>, <string-name><given-names>G. R.</given-names> <surname>Yang</surname></string-name>, and <string-name><given-names>X.-J.</given-names> <surname>Wang</surname></string-name></person-group>. <article-title>Reward-based training of recurrent neural networks for cognitive and value-based tasks</article-title>. <source>eLife</source>, <volume>6</volume>, <month>1</month> <year>2017</year>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Song</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Niv</surname></string-name>, and <string-name><given-names>M. Bo</given-names> <surname>Cai</surname></string-name></person-group>. <article-title>Using recurrent neural networks to understand human reward learning</article-title>. In <conf-name>Proceedings of the Annual Meeting of the Cognitive Science Society</conf-name>, <volume>43</volume>, pages <fpage>1388</fpage>–<lpage>1394</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>C. J.</given-names> <surname>Spoerer</surname></string-name>, <string-name><given-names>T. C.</given-names> <surname>Kietzmann</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Mehrer</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Charest</surname></string-name>, and <string-name><given-names>N.</given-names> <surname>Kriegeskorte</surname></string-name></person-group>. <article-title>Recurrent neural networks can explain flexible trading of speed and accuracy in biological vision</article-title>. <source>PLOS Computational Biology</source>, <volume>16</volume>(<issue>10</issue>):<fpage>e1008215</fpage>, <month>10</month> <year>2020</year>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>R. S.</given-names> <surname>Sutton</surname></string-name> and <string-name><given-names>A. G.</given-names> <surname>Barto</surname></string-name></person-group>. <chapter-title>Reinforcement Learning: An Introduction</chapter-title>. <source>Adaptive Computation and Machine Learning</source>. <publisher-name>MIT Press</publisher-name>, <publisher-loc>Cambridge, MA</publisher-loc>, <year>1998</year>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Tang</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Schrimpf</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Lotter</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Moerman</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Paredes</surname></string-name>, <string-name><given-names>J. Ortega</given-names> <surname>Caro</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Hardesty</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Cox</surname></string-name>, and <string-name><given-names>G.</given-names> <surname>Kreiman</surname></string-name></person-group>. <article-title>Recurrent computations for visual pattern completion</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>115</volume>(<issue>35</issue>):<fpage>8835</fpage>–<lpage>8840</lpage>, <month>8</month> <year>2018</year>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>I.</given-names> <surname>Tolstikhin</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Bousquet</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Gelly</surname></string-name>, and <string-name><given-names>B.</given-names> <surname>Schoelkopf</surname></string-name></person-group>. <article-title>Wasserstein autoencoders</article-title>. <source>arXiv</source>, (<pub-id pub-id-type="arxiv">1711.01558</pub-id>), <month>11</month> <year>2017</year>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Tuzsus</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Brands</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Pappas</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Peters</surname></string-name></person-group>. <article-title>Exploration–exploitation mechanisms in recurrent neural networks and human learners in restless bandit problems</article-title>. <source>Computational Brain &amp; Behavior</source>, <month>5</month> <year>2024</year>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>van den Bos</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Homberg</surname></string-name>, and <string-name><given-names>L.</given-names> <surname>de Visser</surname></string-name></person-group>. <article-title>A critical review of sex differences in decision-making tasks: Focus on the Iowa gambling task</article-title>. <source>Behavioural Brain Research</source>, <volume>238</volume>(<issue>1</issue>):<fpage>95</fpage>–<lpage>108</lpage>, <month>2</month> <year>2013</year>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Vickers</surname></string-name></person-group>. <article-title>Evidence for an accumulator model of psychophysical discrimination</article-title>. <source>Ergonomics</source>, <volume>13</volume>(<issue>1</issue>):<fpage>37</fpage>–<lpage>58</lpage>, <month>4</month> <year>2007</year>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.-J.</given-names> <surname>Wagenmakers</surname></string-name> and <string-name><given-names>S.</given-names> <surname>Brown</surname></string-name></person-group>. <article-title>On the linear relation between the mean and the standard deviation of a response time distribution</article-title>. <source>Psychological Review</source>, <volume>114</volume>(<issue>3</issue>):<fpage>830</fpage>–<lpage>841</lpage>, <month>7</month> <year>2007</year>.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Shen</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Tino</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Welchman</surname></string-name>, and <string-name><given-names>Z.</given-names> <surname>Kourtzi</surname></string-name></person-group>. <article-title>Learning predictive statistics: strategies and brain mechanisms</article-title>. <source>The Journal of Neuroscience</source>, <volume>37</volume>(<issue>35</issue>):<fpage>0144</fpage>–<lpage>17</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. C.</given-names> <surname>Wilson</surname></string-name> and <string-name><given-names>A. G.</given-names> <surname>Collins</surname></string-name></person-group>. <article-title>Ten simple rules for the computational modeling of behavioral data</article-title>. <source>eLife</source>, <volume>8</volume>:<fpage>1</fpage>–<lpage>33</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. L. K.</given-names> <surname>Yamins</surname></string-name> and <string-name><given-names>J. J.</given-names> <surname>DiCarlo</surname></string-name></person-group>. <article-title>Using goal-driven deep learning models to understand sensory cortex</article-title>. <source>Nature Neuroscience</source>, <volume>19</volume>(<issue>3</issue>):<fpage>356</fpage>–<lpage>365</lpage>, <month>3</month> <year>2016</year>.</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G. R.</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>M. R.</given-names> <surname>Joglekar</surname></string-name>, <string-name><given-names>H. F.</given-names> <surname>Song</surname></string-name>, <string-name><given-names>W. T.</given-names> <surname>Newsome</surname></string-name>, and <string-name><given-names>X.-J.</given-names> <surname>Wang</surname></string-name></person-group>. <article-title>Task representations in neural networks trained to perform many cognitive tasks</article-title>. <source>Nature Neuroscience</source>, <volume>22</volume>(<issue>2</issue>):<fpage>297</fpage>–<lpage>306</lpage>, <month>2</month> <year>2019</year>.</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Yechiam</surname></string-name>, <string-name><given-names>J. R.</given-names> <surname>Busemeyer</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Stout</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Bechara</surname></string-name></person-group>. <article-title>Using cognitive models to map relations between neuropsychological disorders and human decision-making deficits</article-title>. <source>Psychological Science</source>, <volume>16</volume>(<issue>12</issue>):<fpage>973</fpage>–<lpage>978</lpage>, <month>12</month> <year>2005</year>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107163.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Jian</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents a <bold>useful</bold> framework to extract the individuality index to predict subjects' behavior in the target tasks. However, the evidence supporting such a framework is somewhat <bold>incomplete</bold> and would benefit from overall framing and clarity on its approaches. Overall, this study would be of interest to cognitive and AI researchers who work on cognitive models in general.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107163.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary</p>
<p>The manuscript presents EIDT, a framework that extracts an &quot;individuality index&quot; from a source task to predict a participant's behaviour in a related target task under different conditions. However, the evidence that it truly enables cross-task individuality transfer is not convincing.</p>
<p>Strengths</p>
<p>The EIDT framework is clearly explained, and the experimental design and results are generally well-described. The performance of the proposed method is tested on two distinct paradigms: a Markov Decision Process (MDP) task (comparing 2-step and 3-step versions) and a handwritten digit recognition (MNIST) task under various conditions of difficulty and speed pressure. The results indicate that the EIDT framework generally achieved lower prediction error compared to baseline models and that it was better at predicting a specific individual's behaviour when using their own individuality index compared to using indices from others.</p>
<p>Furthermore, the individuality index appeared to form distinct clusters for different individuals, and the framework was better at predicting a specific individual's behaviour when using their own derived index compared to using indices from other individuals.</p>
<p>Weaknesses</p>
<p>(1) Because the &quot;source&quot; and &quot;target&quot; tasks are merely parameter variations of the same paradigm, it is unclear whether EIDT achieves true cross-task transfer. The manuscript provides no measure of how consistent each participant's behaviour is across these variants (e.g., two- vs three-step MDP; easy vs difficult MNIST). Without this measure, the transfer results are hard to interpret. In fact, Figure 5 shows a notable drop in accuracy when transferring between the easy and difficult MNIST conditions, compared to transfers between accuracy-focused and speed-focused conditions. Does this discrepancy simply reflect larger within-participant behavioural differences between the easy and difficult settings? A direct analysis of intra-individual similarity for each task pair - and how that similarity is related to EIDT's transfer performance - is needed.</p>
<p>(2) Related to the previous comment, the individuality index is central to the framework, yet remains hard to interpret. It shows much greater within-participant variability in the MNIST experiment (Figure S1) than in the MDP experiment (Figure 3). Is such a difference meaningful? It is hard to know whether it reflects noisier data, greater behavioural flexibility, or limitations of the model.</p>
<p>(3) The authors suggests that the model's ability to generalize to new participants &quot;likely relies on the fact that individuality indices form clusters and individuals similar to new participants exist in the training participant pool&quot;. It would be helpful to directly test this hypothesis by quantifying the similarity (or distance) of each test participant's individuality index to the individuals or identified clusters within the training set, and assessing whether greater similarity (or closer proximity) to the clusters in the training set is associated with higher prediction accuracy for those individuals in the test set.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107163.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This paper introduces a framework for modeling individual differences in decision-making by learning a low-dimensional representation (the &quot;individuality index&quot;) from one task and using it to predict behaviour in a different task. The approach is evaluated on two types of tasks: a sequential value-based decision-making task and a perceptual decision task (MNIST). The model shows improved prediction accuracy when incorporating this learned representation compared to baseline models.</p>
<p>The motivation is solid, and the modelling approach is interesting, especially the use of individual embeddings to enable cross-task generalization. That said, several aspects of the evaluation and analysis could be strengthened.</p>
<p>(1) The MNIST SX baseline appears weak. RTNet isn't directly comparable in structure or training. A stronger baseline would involve training the GRU directly on the task without using the individuality index-e.g., by fixing the decoder head. This would provide a clearer picture of what the index contributes.</p>
<p>(2) Although the focus is on prediction, the framework could offer more insight into how behaviour in one task generalizes to another. For example, simulating predicted behaviours while varying the individuality index might help reveal what behavioural traits it encodes.</p>
<p>(3) It's not clear whether the model can reproduce human behaviour when acting on-policy. Simulating behaviour using the trained task solver and comparing it with actual participant data would help assess how well the model captures individual decision tendencies.</p>
<p>(4) Figures 3 and S1 aim to show that individuality indices from the same participant are closer together than those from different participants. However, this isn't fully convincing from the visualizations alone. Including a quantitative presentation would help support the claim.</p>
<p>(5) The transfer scenarios are often between very similar task conditions (e.g., different versions of MNIST or two-step vs three-step MDP). This limits the strength of the generalization claims. In particular, the effects in the MNIST experiment appear relatively modest, and the transfer is between experimental conditions within the same perceptual task. To better support the idea of generalizing behavioural traits across tasks, it would be valuable to include transfers across more structurally distinct tasks.</p>
<p>(6) For both experiments, it would help to show basic summaries of participants' behavioural performance. For example, in the MDP task, first-stage choice proportions based on transition types are commonly reported. These kinds of benchmarks provide useful context.</p>
<p>(7) For the MDP task, consider reporting the number or proportion of correct choices in addition to negative log-likelihood. This would make the results more interpretable.</p>
<p>(8) In Figure 5, what is the difference between the &quot;% correct&quot; and &quot;% match to behaviour&quot;? If so, it would help to clarify the distinction in the text or figure captions.</p>
<p>(9) For the cognitive model, it would be useful to report the fitted parameters (e.g., learning rate, inverse temperature) per individual. This can offer insight into what kinds of behavioural variability the individuality index might be capturing.</p>
<p>(10) A few of the terms and labels in the paper could be made more intuitive. For example, the name &quot;individuality index&quot; might give the impression of a scalar value rather than a latent vector, and the labels &quot;SX&quot; and &quot;SY&quot; are somewhat arbitrary. You might consider whether clearer or more descriptive alternatives would help readers follow the paper more easily.</p>
<p>(11) Please consider including training and validation curves for your models. These would help readers assess convergence, overfitting, and general training stability, especially given the complexity of the encoder-decoder architecture.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107163.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work presents a novel neural network-based framework for parameterizing individual differences in human behavior. Using two distinct decision-making experiments, the authors demonstrate the approach's potential and claims it can predict individual behavior (1) within the same task, (2) across different tasks, and (3) across individuals. While the goal of capturing individual variability is compelling and the potential applications are promising, the claims are weakly supported, and I find that the underlying problem is conceptually ill-defined.</p>
<p>Strengths:</p>
<p>The idea of using neural networks for parameterizing individual differences in human behavior is novel, and the potential applications can be impactful.</p>
<p>Weaknesses:</p>
<p>(1) To demonstrate the effectiveness of the approach, the authors compare a Q-learning cognitive model (for the MDP task) and RTNet (for the MNIST task) against the proposed framework. However, as I understand it, neither the cognitive model nor RTNet is designed to fit or account for individual variability. If that is the case, it is unclear why these models serve as appropriate baselines. Isn't it expected that a model explicitly fitted to individual data would outperform models that do not? If so, does the observed superiority of the proposed framework simply reflect the unsurprising benefit of fitting individual variability? I think the authors should either clarify why these models constitute fair control or validate the proposed approach against stronger and more appropriate baselines.</p>
<p>(2) It's not very clear in the results section what it means by having a shorter within-individual distance than between-individual distances. Related to the comment above, is there any control analysis performed for this? Also, this analysis appears to have nothing to do with predicting individual behavior. Is this evidence toward successfully parameterizing individual differences? Could this be task-dependent, especially since the transfer is evaluated on exceedingly similar tasks in both experiments? I think a bit more discussion of the motivation and implications of these results will help the reader in making sense of this analysis.</p>
<p>(3) The authors have to better define what exactly he meant by transferring across different &quot;tasks&quot; and testing the framework in &quot;more distinctive tasks&quot;. All presented evidence, taken at face value, demonstrated transferring across different &quot;conditions&quot; of the same task within the same experiment. It is unclear to me how generalizable the framework will be when applied to different tasks.</p>
<p>(4) Conceptually, it is also unclear to me how plausible it is that the framework could generalize across tasks spanning multiple cognitive domains (if that's what is meant by more distinctive). For instance, how can an individual's task performance on a Posner task predict task performance on the Cambridge face memory test? Which part of the framework could have enabled such a cross-domain prediction of task performance? I think these have to be at least discussed to some extent, since without it the future direction is meaningless.</p>
<p>(5) How is the negative log-likelihood, which seems to be the main metric for comparison, computed? Is this based on trial-by-trial response prediction or probability of responses, as what usually performed in cognitive modelling?</p>
<p>(6) None of the presented evidence is cross-validated. The authors should consider performing K-fold cross-validation on the train, test, and evaluation split of subjects to ensure robustness of the findings.</p>
<p>(7) The authors excluded 25 subjects (20% of the data) for different reasons. This is a substantial proportion, especially by the standards of what is typically observed in behavioral experiments. The authors should provide a clear justification for these exclusion criteria and, if possible, cite relevant studies that support the use of such stringent thresholds.</p>
<p>(8) The authors should do a better job of creating the figures and writing the figure captions. It is unclear which specific claim the authors are addressing with the figure. For example, what is the key message of Figure 2C regarding transfer within and across participants? Why are the stats presentation different between the Cognitive model and the EIDT framework plots? In Figure 3, it's unclear what these dots and clusters represent and how they support the authors' claim that the same individual forms clusters. And isn't this experiment have 98 subjects after exclusion, this plot has way less than 98 dots as far as I can tell. Furthermore, I find Figure 5 particularly confusing, as the underlying claim it is meant to illustrate is unclear. Clearer figures and more informative captions are needed to guide the reader effectively.</p>
<p>(9) I also find the writing somewhat difficult to follow. The subheadings are confusing, and it's often unclear which specific claim the authors are addressing. The presentation of results feels disorganized, making it hard to trace the evidence supporting each claim. Also, the excessive use of acronyms (e.g., SX, SY, CG, EA, ES, DA, DS) makes the text harder to parse. I recommend restructuring the results section to be clearer and significantly reducing the use of unnecessary acronyms.</p>
</body>
</sub-article>
</article>