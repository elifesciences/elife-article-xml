<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">95127</article-id>
<article-id pub-id-type="doi">10.7554/eLife.95127</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.95127.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.5</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Uncertainty-modulated prediction errors in cortical microcircuits</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4948-1864</contrib-id>
<name>
<surname>Wilmes</surname>
<given-names>Katharina A.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Petrovici</surname>
<given-names>Mihai A.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sachidhanandam</surname>
<given-names>Shankar</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Senn</surname>
<given-names>Walter</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Physiology, University of Bern</institution>, Bern, <country>Switzerland</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Keller</surname>
<given-names>Georg B</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Friedrich Miescher Institute</institution>
</institution-wrap>
<city>Basel</city>
<country>Switzerland</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>corresponding author: <email>katharina.wilmes@unibe.ch</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-02-27">
<day>27</day>
<month>02</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP95127</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-12-20">
<day>20</day>
<month>12</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-12-06">
<day>06</day>
<month>12</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.05.11.540393"/>
</event>
</pub-history>
<permissions>
<copyright-statement>Â© 2024, Wilmes et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Wilmes et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-95127-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Understanding the variability of the environment is essential to function in everyday life. The brain must hence take uncertainty into account when updating its internal model of the world. The basis for updating the model are prediction errors that arise from a difference between the current model and new sensory experiences. Although prediction error neurons have been identified in diverse brain areas, how uncertainty modulates these errors and hence learning is, however, unclear. Here, we use a normative approach to derive how uncertainty should modulate prediction errors and postulate that layer 2/3 neurons represent uncertainty-modulated prediction errors (UPE). We further hypothesise that the layer 2/3 circuit calculates the UPE through the subtractive and divisive inhibition by different inhibitory cell types. By implementing the calculation of UPEs in a microcircuit model, we show that different cell types can compute the means and variances of the stimulus distribution. With local activity-dependent plasticity rules, these computations can be learned context-dependently, and allow the prediction of upcoming stimuli and their distribution. Finally, the mechanism enables an organism to optimise its learning strategy via adaptive learning rates.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>First results section was revised with an example and to clarify our position within the literature.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Decades of cognitive research indicate that our brain maintains a model of the world, based on which it can make predictions about upcoming stimuli [<xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c7">7</xref>]. Predicting the sensory experience is useful for both perception and learning: Perception becomes more tolerant to uncertainty and noise when sensory information and predictions are integrated [<xref ref-type="bibr" rid="c43">43</xref>]. Learning can happen when predictions are compared to sensory information, as the resulting prediction error indicates how to improve the internal model. In both cases, the uncertainties (associated with both the sensory information and the internal model) should determine how much weight we give to the sensory information relative to the predictions, according to theoretical accounts. Behavioural and electrophysiological studies indicate that humans indeed estimate uncertainty and adjust their behaviour accordingly [<xref ref-type="bibr" rid="c43">43</xref>, <xref ref-type="bibr" rid="c58">58</xref>, <xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c33">33</xref>]. The neural mechanisms underlying uncertainty and prediction error computation are, however, less well understood. Recently, the activity of individual neurons of layer 2/3 cortical circuits in diverse cortical areas of mouse brains has been linked to prediction errors (visual, [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c64">64</xref>, <xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c18">18</xref>], auditory [<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c30">30</xref>], somatosensory [<xref ref-type="bibr" rid="c2">2</xref>], and posterior parietal [<xref ref-type="bibr" rid="c49">49</xref>]). Importantly, prediction errors could be associated with learning [<xref ref-type="bibr" rid="c27">27</xref>]. Prediction error neurons are embedded in neural circuits that consist of heterogeneous cell types, most of which are inhibitory. It has been suggested that prediction error activity results from an imbalance of excitatory and inhibitory inputs [<xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c22">22</xref>], and that the prediction is subtracted from the sensory input [see e.g. 50, 1], possibly mediated by so-called somatostatin-positive interneurons (SSTs) [<xref ref-type="bibr" rid="c1">1</xref>]. How uncertainty is influencing these computations has not yet been investigated. Prediction error neurons receive inputs from a diversity of inhibitory cell types (<xref rid="fig1" ref-type="fig">Fig. 1</xref>), the role of which is not completely understood. Here, we hypothesise that one role of inhibition is to modulate the prediction error neuron activity by uncertainty.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Distributed uncertainty-modulated prediction error computation in cortical circuits</title>
<p>A: A person who learned that buses are unreliable has a prior expectation, which can be described by a wide Gaussian distribution of expected bus arrival times. When the bus does not arrive at the scheduled time, this person is not surprised and remains calm, as everything happens according to their model of the world. On the other hand, a person who learned that buses are punctual, which can be described by a narrow distribution of arrival times, may notice that the bus is late and get nervous, as they expected the bus to be punctual. This person can learn from this experience. If they always took this particular bus, and their uncertainty estimate is accurate, the prediction error could indicate that the bus schedule changed. B: Models of uncertainty representation in cortex. Some models suggest that uncertainty is only represented in higher-level areas concerned with decision-making (left). In contrast, we propose that uncertainty is represented at each level of the cortical hierarchy (right, shown is the visual hierarchy as an example). C: a mouse learns the association between a sound (<italic>a</italic>) and a whisker deflection (<italic>s</italic>). The posterior parietal cortex (PPC) receives inputs from both somatosensory and auditory cortex. D: The whisker stimulus intensities are drawn from a Gaussian distribution with mean <italic>Î¼</italic> and standard deviation <italic>Ï</italic>. E: Positive prediction error circuit consisting of three cell types: layer 2/3 pyramidal cells (triangle), somatostatin-positive interneurons (SST, circle) and parvalbumin-positive interneurons (PV). SSTs represent the mean prediction, and PVs the variance. F: Negative prediction error circuit, similar to C, SST now represent the stimulus and the mean prediction is an excitatory input.</p></caption>
<graphic xlink:href="540393v5_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In this study, we use both analytical calculations and numerical simulations of rate-based circuit models with different inhibitory cell types to study circuit mechanisms leading to uncertainty-modulated prediction errors. First, we derive that uncertainty should divisively modulate prediction error activity and introduce uncertainty-modulated prediction errors (UPEs). We hypothesise that layer 2/3 prediction error neurons reflect such UPEs, and that different inhibitory cell types are involved in calculating the difference between predictions and stimuli compared to the uncertainty modulation. Based on experimental findings, we suggest that SSTs and PVs play the respective roles. We then derive biologically plausible plasticity rules that enable those cell types to learn the means and variances from their inputs. Notably, because the information about the stimulus distribution is stored in the connectivity, single inhibitory cells encode the means and variances of their inputs in a context-dependent manner. Layer 2/3 pyramidal cells in this model hence encode uncertainty-modulated prediction errors context-dependently. We show that error neurons can additionally implement out-of-distribution detection by amplifying large errors and reducing small errors with a nonlinear fI-curve (activation function). Finally, we demonstrate that UPEs effectively mediate an adjustable learning rate, which allows fast learning in high-certainty contexts and reduces the learning rate, thus suppressing fluctuations in uncertain contexts.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Normative theories suggests uncertainty-modulated prediction errors (UPEs)</title>
<p>In a complex, uncertain, and hence partly unpredictable world, it is impossible to avoid prediction errors. Some prediction errors will be the result of this variability or noise, other prediction errors will be the result of a change in the environment or new information. Ideally, only the latter should be used for learning, i.e., updating the current model of the world. The challenge our brain faces is to learn from prediction errors that result from new information, and less from prediction errors that result from noise. Hence, intuitively, if we learned that a kind of stimulus or context is very variable (high uncertainty), then a prediction error should have only little influence on our model. Consider a situation in which a person waits for a bus to arrive. If they learned that the bus is not reliable, another late arrival of the bus does not surprise them and does not change their model of the bus (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). If, on the contrary, they learned that the kind of stimulus or context is not very variable (low uncertainty), a prediction error should have a larger impact on their model. For example, if they learned that buses are reliable, they will notice that the bus is late and may use this information to update their model of the bus (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). This intuition of modulating prediction errors by the uncertainty associated with the stimulus or context is supported by both behavioural studies and normative theories of learning. Here we take the view that uncertainty is computed and represented on each level of the cortical hierarchy, from early sensory areas to higher level brain areas, as opposed to a task-specific uncertainty estimate at the level of decision-making in higher level brain areas (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>) [see this review for a comparison of these two accounts: 65].</p>
<p>Before we suggest how cortical circuits compute such uncertainty-modulated prediction errors, we consider the normative solution to a simple association that a mouse can learn. The setting we consider is to predict a somatosensory stimulus based on an auditory stimulus (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). The auditory stimulus a is fixed, and the subsequent somatosensory stimulus <italic>s</italic> is variable and sampled from a Gaussian distribution (sâ¼ ð© (<italic>Î¼, Ï</italic>), <xref rid="fig1" ref-type="fig">Fig. 1B</xref>). The optimal (maximum-likelihood) prediction is given by the mean of the stimulus distribution. Framed as an optimisation problem, the goal is to adapt the internal model of the mean <inline-formula><inline-graphic xlink:href="540393v5_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>such that the probability of observing samples <italic>s</italic> from the true distribution of whisker deflections is maximised given this model.</p>
<p>Hence, stochastic gradient ascent learning on the log likelihood suggests that with each observation <italic>s</italic>, the prediction, corresponding to the internal model of the mean, should be updated as follows to approach the maximum likelihood solution:
<disp-formula id="eqn1">
<graphic xlink:href="540393v5_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
According to this formulation, the update for the internal model should be the prediction error scaled inversely by the variance <italic>Ï</italic><sup>2</sup>. Therefore, we propose that prediction errors should be modulated by uncertainty.</p>
</sec>
<sec id="s2b">
<title>Computation of UPEs in cortical microcircuits</title>
<p>How can cortical microcircuits achieve uncertainty modulation? Prediction errors can be positive or negative, but neuronal firing rates are always positive. Because baseline firing rates are low in layer 2/3 pyramidal cells [e.g., 42], positive and negative prediction errors were suggested to be represented by distinct neuronal populations [<xref ref-type="bibr" rid="c31">31</xref>], which is in line with experimental data [<xref ref-type="bibr" rid="c26">26</xref>]. We, therefore, decompose the UPE into a positive UPE<sup>+</sup> and a negative UPE<sup>â</sup> component (<xref rid="fig1" ref-type="fig">Fig. 1C,D</xref>):
<disp-formula id="eqn2">
<graphic xlink:href="540393v5_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where ââ¦ â <sup>+</sup> denotes rectification at 0.</p>
<p>It has been suggested that error neurons compute prediction errors by subtracting the prediction from the stimulus input (or vice versa) [<xref ref-type="bibr" rid="c1">1</xref>]. Inhibitory interneurons provide the subtraction, resulting in an excitation-inhibition balance when they match [<xref ref-type="bibr" rid="c23">23</xref>]. To represent a UPE, error neurons need additionally be divisively modulated by the uncertainty. Depending on synaptic properties, such as reversal potentials, inhibitory neurons can have subtractive or divisive influences on their postsynaptic targets. Therefore, we propose that an inhibitory cell type that divisively modulates prediction error activity represents the uncertainty. We hypothesise, first, that in positive prediction error circuits, inhibitory interneurons with subtractive inhibitory effects represent the mean <italic>Î¼</italic> of the prediction. Second, we hypothesise that inhibitory interneurons with divisive inhibitory effects represent the uncertainty <italic>Ï</italic><sup>2</sup> of the prediction (<xref rid="fig1" ref-type="fig">Fig. 1C,D</xref>). A layer 2/3 pyramidal cell that receives these sources of inhibition then reflects the uncertainty-modulated prediction error.</p>
<p>More specifically, we propose that the SSTs are involved in the computation of the difference between predictions and stimuli, as suggested before [<xref ref-type="bibr" rid="c1">1</xref>], and that the PVs provide the uncertainty modulation. In line with this, prediction error neurons in layer 2/3 receive subtractive inhibition from somatostatin (SST) and divisive inhibition from parvalbumin (PV) interneurons [<xref ref-type="bibr" rid="c63">63</xref>]. However, SSTs can also have divisive effects, and PVs can have subtractive effects, dependent on circuit and postsynaptic properties [<xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c10">10</xref>].</p>
</sec>
<sec id="s2c">
<title>Local inhibitory cells learn to represent the mean and the variance given an associative cue</title>
<p>As discussed above, how much an individual sensory input contributes to updating the internal model should depend on the uncertainty associated with the sensory stimulus in its current context. Uncertainty estimation requires multiple stimulus samples. Therefore, our brain needs to have a context-dependent mechanism to estimate uncertainty from multiple past instances of the sensory input. Let us consider the simple example from above, in which a sound stimulus represents a context with a particular amount of uncertainty. Here, we investigate whether the presentation of the sound can elicit activity in the PVs that reflects the expected uncertainty of the situation. To investigate whether a sound can cause activity in SSTs and PVs that reflects the mean and the variance of the whisker stimulus distribution, respectively, we simulated a rate-based circuit model consisting of pyramidal cells and the relevant inhibitory cell types. This circuit receives both the sound and the whisker stimuli as inputs.</p>
</sec>
<sec id="s2d">
<title>SSTs learn to estimate the mean</title>
<p>With our circuit model, we first investigate whether SSTs can learn to represent the mean of the stimulus distribution. In this model, SSTs receive whisker stimulus inputs <italic>s</italic>, drawn from Gaussian distributions (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>), and an input from a higher level representation of the sound <italic>a</italic> (which is either on or off, see Methods). The connection weight from the sound representation to the SSTs is plastic according to a local activity-dependent plasticity rule. The aim of this rule is to minimise the difference between the activation of the SSTs caused by the sound input (which has to be learned) and the activation of the SSTs by the whisker stimulus (which nudges the SST activity in the right direction). The learning rule ensures that the auditory input itself causes SSTs to fire at the desired rate. After learning, the weight and the average SST firing rate reflect the mean of the presented whisker stimulus intensities (<xref rid="fig2" ref-type="fig">Fig. 2C-F</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>SSTs learn to represent the mean context-dependently</title>
<p>Illustration of the changes in the positive prediction error circuit. Thicker lines denote stronger weights. B: Two different tones (red, orange) are associated with two somatosensory stimulus distributions with different means (red: high, orange: low). C: SST firing rates (mean and std) during stimulus input. D: SST firing rates over time for low (orange) and high (red) stimulus means. E: Weights (mean and std) from sound <italic>a</italic> to SST for different values of <italic>Î¼</italic>. F: SST firing rates (mean and std) for different values of <italic>Î¼</italic>. Mean and std were computed over 1000 data points from timestep 9000 to 10000.</p></caption>
<graphic xlink:href="540393v5_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2e">
<title>PVs learn to estimate the variance context-dependently</title>
<p>We next addressed whether PVs can estimate and learn the variance locally. To estimate the variance of the whisker deflections <italic>s</italic>, the PVs have to estimate <italic>Ï</italic><sup>2</sup>[<italic>s</italic>] = ð¼<sub><italic>s</italic></sub>[(<italic>s</italic> â ð¼ [<italic>s</italic>])<sup>2</sup>] = ð¼<sub><italic>s</italic></sub>[(<italic>s</italic> â <italic>Î¼</italic>)<sup>2</sup>]. To do so, they need to have access to both the whisker stimulus <italic>s</italic> and the mean <italic>Î¼</italic>. PVs in PPC respond to sensory inputs in diverse cortical areas [S1: 53] and are inhibited by SSTs in layer 2/3, which we assumed to represent the mean. Finally, for calculating the variance, these inputs need to be squared. PVs were shown to integrate their inputs supralinearly [<xref ref-type="bibr" rid="c8">8</xref>], which could help PVs to approximately estimate the variance.</p>
<p>In our circuit model, we next tested whether the PVs can learn to represent the variance of an upcoming whisker stimulus based on a context provided by an auditory input (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>). Two different auditory inputs (<xref rid="fig3" ref-type="fig">Fig. 3B</xref> purple, green) are paired with two whisker stimulus distributions that differ in their variances (green: low, purple: high). The synaptic connection from the auditory input to the PVs is plastic according to the same local activity-dependent plasticity rule as the connection to the SSTs. With this learning rule, the weight onto the PV becomes proportional to <italic>Ï</italic> (<xref rid="fig3" ref-type="fig">Fig. 3C</xref>), such that the PV firing rate becomes proportional to <italic>Ï</italic><sup>2</sup> on average (<xref rid="fig3" ref-type="fig">Fig. 3D</xref>). The average PV firing rate is exactly proportional to <italic>Ï</italic><sup>2</sup> with a quadratic activation function <italic>Ï</italic><sub><italic>P V</italic></sub> (<italic>x</italic>) (<xref rid="fig3" ref-type="fig">Fig. 3D-F,H</xref>) and monotonically increasing with <italic>Ï</italic><sup>2</sup> with other choices of activation functions (Suppl. Fig. 9), both when the sound input is presented alone (<xref rid="fig3" ref-type="fig">Fig. 3D,E,H</xref>) or when paired with whisker stimulation (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>). Notably, a single PV neuron is sufficient for encoding variances of different contexts because the context-dependent <italic>Ï</italic> is stored in the connection weights.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>PVs learn to estimate the variance context-dependently.</title>
<p>A: Illustration of the changes in the positive prediction error circuit. Thicker lines denote stronger weights. B: Two different tones (purple, green) are associated with two somatosensory stimulus distributions with different variances (purple: high, green: low). C: Weights from sound <italic>a</italic> to PV over time for two different values of stimulus variance (high: <italic>Ï</italic> = 0.8 (purple), low: <italic>Ï</italic> = 0.4 (green)). D: PV firing rates over time given sound input (without stimulus input) for low (green) and high (purple) stimulus variance. E: PV firing rates (mean and std) given sound input for low and high stimulus variance. F: PV firing rates (mean and std) during sound and stimulus input. G: Weights (mean and std) from sound <italic>a</italic> to PV for different values of <italic>Ï</italic>. H: PV firing rates (mean and std) given sound input for different values of <italic>Ï</italic><sup>2</sup>. Mean and std were computed from 150000 data points from timestep 450000 to 600000.</p></caption>
<graphic xlink:href="540393v5_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To estimate the variance, the mean needs to be subtracted from the stimulus samples. A faithful mean subtraction is only ensured if the weights from the SSTs to the PVs (<italic>w</italic><sub>PV,SST</sub>) match the weights from the stimuli <italic>s</italic> to the PVs (<italic>w</italic><sub>PV,<italic>s</italic></sub>). The weight <italic>w</italic><sub>PV,SST</sub> can be learned to match the weight <italic>w</italic><sub>PV,<italic>s</italic></sub> with a local activity-dependent plasticity rule (see Suppl. Fig. 10 and Suppl. Methods).</p>
<p>The PVs can similarly estimate the uncertainty in negative prediction error circuits (Suppl. Fig. 11). In these circuits, SSTs represent the current sensory stimulus, and the mean prediction is an excitatory input to both negative prediction error neurons and PVs.</p>
</sec>
<sec id="s2f">
<title>Calculation of the UPE in Layer 2/3 error neurons</title>
<p>Layer 2/3 pyramidal cell dendrites can generate NMDA and calcium spikes, which cause a nonlinear integration of inputs. Such a nonlinear integration of inputs is convenient when the mean input changes and the current prediction differs strongly from the new mean of the stimulus distribution. In this case, the PV firing rate will increase for larger errors and inhibit error neurons more strongly than indicated by the learned variance estimate. The nonlinearity compensates for this increased inhibition by PVs, such that in the end, layer 2/3 cell activity reflects an uncertainty-modulated prediction error (<xref rid="fig4" ref-type="fig">Fig. 4E</xref>) in both negative (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>) and positive (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>) prediction error circuits. A stronger nonlinearity has an interesting effect: error neurons elicit much larger responses to outliers than to stimuli that match the predicted distributionâa cell-intrinsic form of <italic>out-of-distribution detection</italic>.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Calculation of the UPE in layer 2/3 error neurons</title>
<p>A: Illustration of the negative prediction error circuit. B: Illustration of the positive prediction error circuit. C: Illustration of error neuron with a nonlinear integration of inputs (<italic>k</italic> = 2). D: firing rate of the error neuron in the negative prediction error circuit (UPE<sup>â</sup>) as a function of <italic>Ï</italic> for two values of |<italic>s</italic>â <italic>Î¼</italic>| . E: Rates of both UPE<sup>+</sup> and UPE<sup>â</sup>-representing error neurons as a function of the difference between the stimulus and the mean (<italic>s</italic> â<italic>Î¼</italic>). F: firing rate of the error neuron in the positive prediction error circuit (UPE<sup>+</sup>) as a function of <italic>Ï</italic> for two values of |<italic>s</italic> â<italic>Î¼</italic>| . G: Illustration of an error neuron with a non-linear activation function <italic>k</italic> = 2.5. H-J: same as D-F for error neurons with <italic>k</italic> = 2.5.</p></caption>
<graphic xlink:href="540393v5_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To ensure a comparison between the stimulus and the prediction, the weights from the SSTs to the UPE neurons need to match the weights from the stimulus <italic>s</italic> to the UPE neuron and from the mean representation to the UPE neuron, respectively. With inhibitory plasticity (target-based, see Suppl. Methods), the weights from the SSTs can learn to match the incoming excitatory weights (Suppl. Fig. 12).</p>
</sec>
<sec id="s2g">
<title>Interactions between representation neurons and error neurons</title>
<p>The theoretical framework of predictive processing includes both prediction error neurons and representation neurons, the activity of which reflects the internal model and should hence be compared to the sensory information. To make predictions for the activity of representation neurons, we expand our circuit model with this additional cell type. We first show that a representation neuron R can learn a representation of the stimulus mean given inputs from L2/3 error neurons. The representation neuron receives inputs from positive and negative prediction error neurons and from a higher level representation of the sound <italic>a</italic> (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>). It sends its current mean estimate to the error circuits by either targeting the SSTs (in the positive circuit) or the pyramidal cells directly (in the negative circuit). Hence in this recurrent circuit, the SSTs inherit the mean representation instead of learning it. After learning, the weights from the sound to the representation neuron and the average firing rate of this representation neuron reflects the mean of the stimulus distribution (<xref rid="fig5" ref-type="fig">Fig. 5B,C</xref>).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Learning the mean representation with UPEs</title>
<p>A: Illustration of the circuit. A representation neuron (turquoise, R) receives input from both positive and negative prediction error circuits (UPE<sup>+</sup> and UPE<sup>â</sup>) and projects back to them (connectivity is simplified in the illustration, see Methods for the detailed connectivity matrix). The UPE<sup>â</sup> has a negative impact on the firing rate of the representation neuron (<italic>r</italic><sub><italic>R</italic></sub>). A weight <italic>w</italic><sub><italic>R,a</italic></sub> from the higher level representation of the sound <italic>a</italic> is learned. B: Weights from sound <italic>a</italic> to R over time for different values of <italic>Î¼</italic> (<italic>Î¼</italic>â [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c5">5</xref>]). C: R firing rates given sound input for different values of <italic>Î¼</italic> (mean and std over 50000 data points from timestep 50000 to 100000, the end of the simulation). D: Activity of the different cell types (PV: light green, R: turquiose, UPE: black) and whisker stimulus samples (grey dots) over time. Learning the mean representation with PVs (light green) reflecting the MSE at the beginning, which is compensated by nonlinear activation of L2/3 neurons (black). The evolution of the mean rate of neuron <italic>R</italic> (turquoise) is similar to the perfect case in E. E: Same colour code as in D. Inset shows comparison to D. Learning the mean representation assuming PVs (light green) perfectly represent the variance.</p></caption>
<graphic xlink:href="540393v5_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Second, we show that a circuit with prediction error neurons that exhibit NMDA spikes (as in <xref rid="fig4" ref-type="fig">Fig. 4</xref>) approximates an idealised circuit, in which the PV rate perfectly represents the variance (<xref rid="fig5" ref-type="fig">Fig. 5D,E</xref>, see inset for comparison of the two models). Also in this recurrent circuit, PVs learn to reflect the variance, as the weight from the sound representation <italic>a</italic> is learned to be proportional to <italic>Ï</italic> (Suppl. Fig. 13).</p>
</sec>
<sec id="s2h">
<title>Predictions for different cell types</title>
<p>Our model makes predictions for the activity of different cell types for positive and negative prediction errors (e.g. when a mouse receives whisker stimuli that are larger (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>, black) or smaller (<xref rid="fig6" ref-type="fig">Fig. 6G</xref>, grey) than expected) in contexts associated with different amounts of uncertainty (e.g., the high-uncertainty (purple) versus the low-uncertainty (green) context are associated with different sounds). Our model suggests that there are two types of interneurons that provide subtractive inhibition to the prediction error neurons (presumably SST subtypes): in the positive prediction error circuit (SST<sup>+</sup>), they signal the expected value of the whisker stimulus intensity (<xref rid="fig6" ref-type="fig">Fig. 6B,H</xref>). in the negative prediction error circuit (SST<sup>â</sup>) they signal the whisker stimulus intensity (<xref rid="fig6" ref-type="fig">Fig. 6C,I</xref>). We further predict that interneurons that divisively modulate prediction error neuron activity represent the uncertainty (presumably PVs). Those do not differ in their activity between positive and negative circuits and may even be shared across the two circuits: in both positive and negative prediction error circuits, these cells signal the variance (<xref rid="fig6" ref-type="fig">Fig. 6D,J</xref>). L2/3 pyramidal cells that encode prediction errors signal uncertainty-modulated positive prediction errors (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>) and uncertainty-modulated negative prediction errors (<xref rid="fig6" ref-type="fig">Fig. 6L</xref>), respectively. Finally, the existence of so-called internal representation neurons has been proposed [<xref ref-type="bibr" rid="c31">31</xref>]. In our case, those neurons represent the predicted mean of the associated whisker deflections. Our model predicts that upon presentation of an unexpected whisker stimulus, those internal representation neurons adjust their activity to represent the new whisker deflection depending on the variability of the associated whisker deflections: they adjust their activity more (given equal deviations from the mean) if the associated whisker deflections are less variable (see the next section and <xref rid="fig7" ref-type="fig">Fig. 7</xref>).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Cell-type specific experimentally testable predictions</title>
<p>A: Illustration of the two experienced stimulus distributions with different variances that are associated with two different sounds (green, purple). The presented mismatch stimulus (black) is larger than expected (positive prediction error). B-F: Firing rates of different cell types to positive prediction errors when a sound associated with high (purple) or low (green) uncertainty is presented. G: As in A. The presented mismatch stimulus (grey) is smaller than expected (negative prediction error). H-L: Firing rates of different cell types to the negative mismatch when a sound associated with high (purple) or low (green) uncertainty is presented.</p></caption>
<graphic xlink:href="540393v5_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7:</label>
<caption><title>Effective learning rate is automatically adjusted with UPEs</title>
<p>A,B: Firing rate over time of the representation neuron in a circuit with uncertainty-modulated prediction errors (gold) and in a circuit with unmodulated errors (black) in a low uncertainty setting and a high uncertainty setting (B), C: standard deviation of the firing rate of the representation neuron in the low uncertainty setting (inset has a different scale, outer axis scale matches the one in D), D: standard deviation of the firing rate of the representation neuron in the high uncertainty setting. E: Standard deviation of the firing rate <italic>r</italic><sub><italic>R</italic></sub> as a function of the standard deviation of the presented stimulus distribution <italic>Ï</italic><sub><italic>s</italic></sub>. Standard deviations were computed over 100000 data points from timestep 100000 to 200000</p></caption>
<graphic xlink:href="540393v5_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The following experimental results are compatible with our predictions: First, putative inhibitory neurons (narrow spiking units) in the macaque anterior cingulate cortex increased their firing rates in periods of high uncertainty [<xref ref-type="bibr" rid="c3">3</xref>]. These could correspond to the PVs in our model. Second, prediction error activity seems to be indeed lower for less predictable, and hence more uncertain, contexts: Mice trained in a predictable environment (where locomotion and visual flow match) were compared to mice trained in an unpredictable, uncertain environment [<xref ref-type="bibr" rid="c1">1</xref>, they saw a video of visual flow that was independent of their locomotion:]. Layer 2/3 activity towards mismatches in locomotion and visual flow was lower in the mice trained in the unpredictable environment.</p>
</sec>
<sec id="s2i">
<title>The effective learning rate is automatically adjusted with UPEs</title>
<p>To test whether UPEs can automatically adjust the effective learning rate of a downstream neural population, we looked at two contexts that differed in uncertainty and compared how the mean representation evolves with and without UPEs. Indeed, in a low-uncertainty setting, the mean representation can be learned faster with UPEs (in comparison to unmodulated, <xref rid="fig7" ref-type="fig">Fig. 7A,C</xref>). In a high-uncertainty setting, the effective learning rate is smaller, and the mean representation is less variable than in the unmodulated case (<xref rid="fig7" ref-type="fig">Fig. 7B,D</xref>). The standard deviation of the firing rate increases only sublinearly with the standard deviation of the inputs (<xref rid="fig7" ref-type="fig">Fig. 7E</xref>). In summary, uncertainty-modulation of prediction errors enables an adaptive learning rate modulation.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Based on normative theories, we propose that the brain uses uncertainty-modulated prediction errors. In particular, we hypothesise that layer 2/3 prediction error neurons represent prediction errors that are inversely modulated by uncertainty. Here we showed that different inhibitory cell types in layer 2/3 cortical circuits can compute means and variances and thereby enable pyramidal cells to represent uncertainty-modulated prediction errors. We further showed that the cells in the circuit are able to learn to predict the means and variances of their inputs with local activity-dependent plasticity rules. Our study makes experimentally testable predictions for the activity of different cell types, PV and SST interneurons, in particular, prediction error neurons and representation neurons. Finally, we showed that circuits with uncertainty-modulated prediction errors enable adaptive learning rates, resulting in fast learning when uncertainty is low and slow learning to avoid detrimental fluctuations when uncertainty is high.</p>
<p>Our theory has the following notable implications: The first implication concerns the hierarchical organisation of the brain. At each level of the hierarchy, we find similar canonical circuit motifs that receive both feedforward (from a lower level) and feedback (from a higher level, predictive) inputs that need to be integrated. We propose that uncertainty is computed on each level of the hierarchy. This enables uncertainty estimates specific to the processing level of a particular area. Experimental evidence is so far insufficient to favour this fully Bayesian account of uncertainty estimation over the idea that uncertainty is only computed on the level of decisions in higher level brain areas such as the parietal cortex [<xref ref-type="bibr" rid="c32">32</xref>], orbitofrontal cortex [<xref ref-type="bibr" rid="c41">41</xref>], or prefrontal cortex [<xref ref-type="bibr" rid="c52">52</xref>]. Our study provides a concrete suggestion for an implementation and, therefore, experimentally testable predictions. The Bayesian account has clear computational advantages for task-flexibility, information integration, active sensing, and learning (see [<xref ref-type="bibr" rid="c65">65</xref>] for a recent review of the two accounts). Additionally, adding uncertainty-modulated prediction errors from different hierarchical levels according to the predictive coding model [<xref ref-type="bibr" rid="c50">50</xref>, <xref ref-type="bibr" rid="c59">59</xref>] yields Bayes-optimal weighting of feedback and feedforward information, which can be reconciled with human behaviour [<xref ref-type="bibr" rid="c43">43</xref>]. Two further important implications result from storing uncertainty in the afferent connections to the PVs. First, this implies that the same PV cell can store different uncertainties depending on the context, which is encoded in the pre-synaptic activation. Second, fewer PVs than pyramidal cells are required for the mechanism, which is compatible with the 80/20 ratio of excitatory to inhibitory cells in the brain.</p>
<p>We claim that the uncertainty represented by PVs in our theoretical framework corresponds to <italic>expected uncertainty</italic> that results from noise or irreducible uncertainty in the stimuli and should therefore decrease the learning rate. Another common source of uncertainty are changes in the environment, also referred to as the <italic>unexpected uncertainty</italic>. In volatile environments with high unexpected uncertainty, the learning rate should increase. We suggest that vasointestinalpeptide-positive interneurons (VIPs) could be responsible for signalling the unexpected uncertainty, as they respond to reward, punishment and surprise [<xref ref-type="bibr" rid="c47">47</xref>], which can be indicators of high unexpected uncertainty. They provide potent disinhibition of pyramidal cells [<xref ref-type="bibr" rid="c45">45</xref>], and also inhibit PVs in layer 2/3 [<xref ref-type="bibr" rid="c46">46</xref>]. Hence, they could increase error activity resulting in a larger learning signal. In general, interneurons are innervated by different kinds of neuromodulators [<xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c48">48</xref>] and control pyramidal cellâs activity and plasticity [<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c62">62</xref>, <xref ref-type="bibr" rid="c61">61</xref>, <xref ref-type="bibr" rid="c60">60</xref>]. Therefore, neuromodulators could have powerful control over error neuron activity and hence perception and learning.</p>
<p>A diversity of proposals about the neural representation of uncertainty exist. For example, it has been suggested that uncertainty is represented in single neurons by the width [<xref ref-type="bibr" rid="c14">14</xref>], or amplitude of their responses [<xref ref-type="bibr" rid="c40">40</xref>], or implicitly via sampling [neural sampling hypothesis; 44, 5, 4], or rather than being represented by a single feature, can be decoded from the activity of an entire population [<xref ref-type="bibr" rid="c9">9</xref>]. While we suggest that PVs represent uncertainty to modulate prediction error responses, we do not claim that this is the sole representation of uncertainty in neuronal circuits.</p>
<p>Uncertainty estimation is relevant for Bayes-optimal integration of different sources of information, e.g., different modalities [multi-sensory integration; 12, 13] or priors and sensory information. Here, we present a circuit implementation for weighing sensory information according to its uncertainty. It has previously been suggested that Bayes-optimal multi-sensory integration could be achieved in single neurons [<xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c25">25</xref>]. Our proposal is complementary to this solution in that uncertainty-modulated errors can be forwarded to other cortical and subcortical circuits at different levels of the hierarchy, where they can be used for inference and learning. It further allows for a context-dependent integration of sensory inputs.</p>
<p>Multiple neurological disorders, such as autism spectrum disorder or schizophrenia, are associated with maladaptive contextual uncertainty-weighting of sensory and prior information [<xref ref-type="bibr" rid="c51">19</xref>, <xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c55">55</xref>]. These disorders are also associated with aberrant inhibition, e.g. ASD is associated with an excitation-inhibition imbalance [<xref ref-type="bibr" rid="c51">51</xref>] and reduced inhibition [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c16">16</xref>]. Interestingly, PV cells, in particular chandelier PV cells, were shown to be reduced in number and synaptic strength in ASD [<xref ref-type="bibr" rid="c28">28</xref>]. Our theory provides one possible explanation of how deficits in uncertainty-weighting on the behavioural level could be linked to altered PVs on the circuit level.</p>
<p>Finally, uncertainty-modulated errors could advance deep hierarchical neural networks. In addition to propagating gradients, propagating uncertainty may have advantages for learning. The additional information on uncertainty could enable calculating distances between distributions, which can provide an informative and parameter-independent metric for learning [e.g. natural gradient learning, 34].</p>
<p>To provide experimental predictions that are immediately testable, we suggested specific roles for SSTs and PVs, as they can subtractively and divisively modulate pyramidal cell activity, respectively. In principle, our theory more generally posits that any subtractive or divisive inhibition could implement the suggested computations. With the emerging data on inhibitory cell types, subtypes of SSTs and PVs or other cell types may turn out to play the proposed role.</p>
<p>To compare predictions and stimuli in a subtractive manner, the encoded prediction/stimulus needs to be translated into a direct variable code. In this framework, we assume that this can be achieved by the weight matrix defining the synaptic connections from the neural populations representing predictions and stimuli (possibly in a population code).</p>
<sec id="s3a">
<title>Conclusion</title>
<p>To conclude, we proposed that prediction error activity in layer 2/3 circuits is modulated by uncertainty and that the diversity of cell types in these circuits achieves the appropriate scaling of the prediction error activity. The proposed model is compatible with Bayes-optimal behaviour and makes predictions for future experiments.</p>
</sec>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Derivation of the UPE</title>
<p>The goal is to learn <inline-formula><inline-graphic xlink:href="540393v5_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> to maximise the log likelihood:
<disp-formula id="eqn3">
<graphic xlink:href="540393v5_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn4">
<graphic xlink:href="540393v5_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn5">
<graphic xlink:href="540393v5_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We consider the log likelihood for one sample <italic>s</italic> of the stimulus distribution:
<disp-formula id="eqn6">
<graphic xlink:href="540393v5_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Stochastic gradient ascent on the log likelihood gives the update for <inline-formula><inline-graphic xlink:href="540393v5_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>:
<disp-formula id="eqn7">
<graphic xlink:href="540393v5_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn8">
<graphic xlink:href="540393v5_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn9">
<graphic xlink:href="540393v5_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s4b">
<title>Circuit model</title>
<sec id="s4b1">
<title>Prediction error circuit</title>
<p>We modelled a circuit consisting of excitatory prediction error neurons in layer 2/3, and two inhibitory populations, corresponding to PV and SST interneurons.</p>
<p>Layer 2/3 pyramidal cells receive divisive inhibition from PVs [<xref ref-type="bibr" rid="c63">63</xref>]. We, hence, modelled the activity of prediction error neurons as
<disp-formula id="eqn10">
<graphic xlink:href="540393v5_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>Ï</italic>(<italic>x</italic>) is the activation function, defined in <xref ref-type="disp-formula" rid="eqn21">Eq. 21</xref>, <italic>I</italic><sub>dend</sub> = <italic>âw</italic><sub>UPE,s</sub> <italic>r</italic><sub>s</sub> â <italic>w</italic><sub>UPE,SST</sub> <italic>r</italic><sub>SST</sub><italic>â</italic><sup><italic>k</italic></sup> is the dendritic input current to the positive prediction error neuron (see section Neuronal dynamics below for <italic>r</italic><sub><italic>x</italic></sub> and for the negative prediction error neuron, and <xref rid="tbl1" ref-type="table">Table 1</xref> for <italic>w</italic><sub><italic>x</italic></sub>). The nonlinearity in the dendrite is determined by the exponent <italic>k</italic>, which is by default <italic>k</italic> = 2, unless otherwise specified as in <xref rid="fig4" ref-type="fig">Fig. 4G-J</xref>. <italic>I</italic><sub>0</sub> <italic>&gt;</italic> 1 is a constant ensuring that the divisive inhibition does not become excitatory, when <italic>Ï &lt;</italic> 1.0.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Parameters of the network.</title></caption>
<graphic xlink:href="540393v5_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>The PV firing rate is determined by the input from the sound representation <inline-formula><inline-graphic xlink:href="540393v5_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula>and the whisker stimuli, from which their mean is subtracted (<inline-formula><inline-graphic xlink:href="540393v5_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where the mean is given by <inline-formula><inline-graphic xlink:href="540393v5_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). The mean-subtracted whisker stimuli serve as a target for learning the weight from the sound representation to the PV <inline-formula><inline-graphic xlink:href="540393v5_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The PV firing rate evoles over time according to:
<disp-formula id="eqn11">
<graphic xlink:href="540393v5_eqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>Ï</italic><sub>PV</sub>(<italic>x</italic>) is a rectified quadratic activation function, defined in <xref ref-type="disp-formula" rid="eqn22">Eq. 22</xref>.</p>
<p>In the positive prediction error circuit, in which the SSTs learn to represent the mean, the SST activity is determined by
<disp-formula id="eqn12">
<graphic xlink:href="540393v5_eqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s4b2">
<title>Recurrent circuit model</title>
<p>In the recurrent circuit, shown in <xref rid="fig5" ref-type="fig">Fig. 5</xref>, we added an internal representation neuron to the circuit with firing rate <italic>r</italic><sub>R</sub>. In this circuit the SSTs inherit the mean representation from the representation neuron instead of learning it themselves. In this recurrent circuit, the firing rate of each population <italic>r</italic><sub><italic>i</italic></sub> where <italic>i</italic> [SST<sup>+</sup>, SST<sup>â</sup>, PV<sup>+</sup>, PV<sup>â</sup>, UPE<sup>+</sup>, UPE<sup>â</sup>, R] evolves over time according to the following neuronal dynamics. <italic>Ï</italic> denotes a rectified linear activation function with saturation, <italic>Ï</italic><sub><italic>P V</italic></sub> denotes a rectified quadratic activation function with saturation, defined in the section below.
<disp-formula id="eqn13">
<graphic xlink:href="540393v5_eqn13.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn14">
<graphic xlink:href="540393v5_eqn14.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn15">
<graphic xlink:href="540393v5_eqn15.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn16">
<graphic xlink:href="540393v5_eqn16.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn17">
<graphic xlink:href="540393v5_eqn17.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn18">
<graphic xlink:href="540393v5_eqn18.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn19">
<graphic xlink:href="540393v5_eqn19.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
</sec>
<sec id="s4c">
<title>Activation functions</title>
<p>
<disp-formula id="eqn21">
<graphic xlink:href="540393v5_eqn21.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
and
<disp-formula id="eqn22">
<graphic xlink:href="540393v5_eqn22.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
<sec id="s4c1">
<title>Inputs</title>
<p>The inputs to the circuit were the higher level representation of the sound <italic>a</italic>, which was either on (1.0) or off (0.0), and <italic>N</italic> samples from the Gaussian distribution of whisker stimulus intensities. Each whisker stimulus intensity was presented for <italic>D</italic> timesteps (see <xref rid="tbl2" ref-type="table">Table 2</xref>).</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><title>Inputs.</title></caption>
<graphic xlink:href="540393v5_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s4c2">
<title>Synaptic dynamics / Plasticity rules</title>
<p>Synapses from the higher level representation of the sound <italic>a</italic> to the SSTs, PVs, and to R were plastic according to the following activity-dependent plasticity rules [<xref ref-type="bibr" rid="c56">56</xref>].
<disp-formula id="eqn23">
<graphic xlink:href="540393v5_eqn23.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn24">
<graphic xlink:href="540393v5_eqn24.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn25">
<graphic xlink:href="540393v5_eqn25.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>Î·</italic><sub>PV</sub> = 0.01<italic>Î·</italic><sub><italic>R</italic></sub>.</p>
</sec>
<sec id="s4c3">
<title>Explanation of the synaptic dynamics</title>
<p>The connection weight from the sound representation to the SSTs <italic>w</italic><sub>SST,a</sub> is plastic according to the following local activity-dependent plasticity rule [<xref ref-type="bibr" rid="c56">56</xref>]:
<disp-formula id="eqn27">
<graphic xlink:href="540393v5_eqn27.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>Î·</italic> is the learning rate, <italic>r</italic><sub>a</sub> is the pre-synaptic firing rate, <italic>r</italic><sub>SST</sub> is the post-synaptic firing rate of the SSTs, <italic>Ï</italic>(<italic>x</italic>) is a rectified linear activation function of the SSTs, and the SST activity is determined by
<disp-formula id="eqn28">
<graphic xlink:href="540393v5_eqn28.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The SST activity is influenced (nudged with a factor <italic>Î²</italic>) by the somatosensory stimuli <italic>s</italic>, which provide targets for the desired SST activity. The learning rule ensures that the auditory input alone causes SSTs to fire at their target activity. As in the original proposal [<xref ref-type="bibr" rid="c56">56</xref>], the terms in the learning rule can be mapped to local neuronal variables, which could be represented by dendritic (<italic>w</italic><sub>SST,a</sub> <italic>r</italic><sub>a</sub>) and somatic (<italic>r</italic><sub>SST</sub>) activity.</p>
<p>The connection weight from the sound representation to the PVs <italic>w</italic><sub>PV,a</sub> is plastic according to the same local activitydependent plasticity rule as the SSTs [<xref ref-type="bibr" rid="c56">56</xref>]:
<disp-formula id="eqn29">
<graphic xlink:href="540393v5_eqn29.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The weight from the sound representation to the PV <inline-formula><inline-graphic xlink:href="540393v5_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula> approaches <italic>Ï</italic> (instead of <italic>Î¼</italic> as the weight to the SSTs), because the PV activity is a function of the mean-subtracted whisker stimuli (instead of the whisker stimuli as the SST activity), and for a Gaussian-distributed stimulus <italic>s</italic> â¼ <italic>ð©</italic> (<italic>s</italic>|<italic>Î¼, Ï</italic>), it holds that ð¼ [<italic>âs</italic> â <italic>Î¼â</italic><sup>+</sup>] â <italic>Ï</italic>.</p>
</sec>
<sec id="s4c4">
<title>Estimating the variance correctly</title>
<p>The PVs estimate the variance of the sensory input from the variance of the teaching input (<italic>s</italic>â <italic>Î¼</italic>), which nudges the membrane potential of the PVs with a nudging factor <italic>Î²</italic>. The nudging factor reduces the effective variance of the teaching input, such that in order to correctly estimate the variance, this reduction needs to be compensated by larger weights from the SSTs to the PVs (<italic>w</italic><sub>PV,SST</sub>) and from the sensory input to the PVs (<italic>w</italic><sub>PV,<italic>s</italic></sub>). To determine how strong the weights <italic>w</italic><sub><italic>s</italic></sub> = <italic>w</italic><sub>PV,SST</sub> = <italic>w</italic><sub>PV,<italic>s</italic></sub> need to be to compensate for the downscaling of the input variance by <italic>Î²</italic>, we require that ð¼ [<italic>wa</italic>]<sup>2</sup> = <italic>Ï</italic><sup>2</sup> when the average weight change ð¼ [â<italic>w</italic>] = 0. The learning rule for <italic>w</italic> is as follows:
<disp-formula id="eqn30">
<graphic xlink:href="540393v5_eqn30.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn31">
<graphic xlink:href="540393v5_eqn31.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="540393v5_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="540393v5_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p>Using that <italic>Ï</italic>(<italic>u</italic>) = <italic>u</italic><sup>2</sup>, the average weight change becomes:
<disp-formula id="eqn33">
<graphic xlink:href="540393v5_eqn33.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn34">
<graphic xlink:href="540393v5_eqn34.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn35">
<graphic xlink:href="540393v5_eqn35.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn36">
<graphic xlink:href="540393v5_eqn36.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn37">
<graphic xlink:href="540393v5_eqn37.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn38">
<graphic xlink:href="540393v5_eqn38.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Given our objective ð¼ [(<italic>wa</italic>)<sup>2</sup>] = <italic>Ï</italic><sup>2</sup>, we can write:
<disp-formula id="eqn40">
<graphic xlink:href="540393v5_eqn40.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Then for ð¼ [â<italic>w</italic>] = 0:
<disp-formula id="eqn42">
<graphic xlink:href="540393v5_eqn42.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn43">
<graphic xlink:href="540393v5_eqn43.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Here, we assumed that <italic>Ï</italic>(<italic>u</italic>) = <italic>u</italic><sup>2</sup> instead of <italic>Ï</italic>(<italic>u</italic>) = â <italic>u</italic> â <sup>2</sup>. To test how well this approximation holds, we simulated the circuit for different values of <italic>Î²</italic> and hence <italic>w</italic><sub><italic>s</italic></sub>, and plotted the PV firing rate <italic>r</italic><sub>PV</sub>(<italic>a</italic>) given the sound input <italic>a</italic> and the weight from <italic>a</italic> to PV, <italic>w</italic><sub>PV,<italic>a</italic></sub>, for different values of <italic>Î²</italic> (<xref rid="fig8" ref-type="fig">Fig. 8</xref>). This analysis shows that the approximation holds for small <italic>Î²</italic> up to a value of <italic>Î²</italic> = 0.2.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8:</label>
<caption><p>For small <italic>Î²</italic>, and <inline-formula><inline-graphic xlink:href="540393v5_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, the weight from <italic>a</italic> to PV approaches <italic>Ï</italic> and the PV firing rate approaches <italic>Ï</italic><sup>2</sup>.</p></caption>
<graphic xlink:href="540393v5_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s4c5">
<title>Simulation</title>
<p>We initialised the circuit with the initial weight configuration in <xref rid="tbl1" ref-type="table">Tables 1</xref> and <xref rid="tbl3" ref-type="table">3</xref> and neural firing rates were initialised to be 0 (<italic>r</italic><sub><italic>i</italic></sub>(0) = 0 with <italic>i</italic> â [SST<sup>+</sup>, SST<sup>â</sup>, PV<sup>+</sup>, PV<sup>â</sup>, UPE<sup>+</sup>, UPE<sup>â</sup>, R]). We then paired a constant tone input with N samples from the whisker stimulus distribution, the parameters of which we varied and are indicated in each Figure. Each whisker stimulus intensity was presented for <italic>D</italic> timesteps (see <xref rid="tbl2" ref-type="table">Table 2</xref>). All simulations were written in Python. Differential equations were numerically integrated with a time step of <italic>dt</italic> = 0.1.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><title>Parameters of the plasticity rules.</title></caption>
<graphic xlink:href="540393v5_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4:</label>
<caption><title>Parameters of simulations in <xref rid="fig2" ref-type="fig">Figs. 2</xref>-<xref rid="fig5" ref-type="fig">5</xref>.</title></caption>
<graphic xlink:href="540393v5_tbl4.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5:</label>
<caption><title>Parameters of the simulation in <xref rid="fig6" ref-type="fig">Fig. 6</xref>.</title></caption>
<graphic xlink:href="540393v5_tbl5.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s4c6">
<title>Eliciting responses to mismatches (<xref rid="fig4" ref-type="fig">Fig. 4</xref> and <xref rid="fig6" ref-type="fig">Fig. 6</xref>)</title>
<p>We first trained the circuit with 10000 stimulus samples to learn the variances in the a-to-PV weights. Then we presented different mismatch stimuli to calculate the error magnitude for each mismatch of magnitude <italic>s</italic> â <italic>Î¼</italic>.</p>
</sec>
<sec id="s4c7">
<title>Comparing the UPE circuit with an unmodulated circuit (<xref rid="fig7" ref-type="fig">Fig. 7</xref>)</title>
<p>To ensure a fair comparison, the unmodulated control has an effective learning rate that is the mean of the two effective learning rates in the uncertainty-modulated case.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Attinger</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>G. B.</given-names> <surname>Keller</surname></string-name>, <article-title>Visuomotor Coupling Shapes the Functional Development of Mouse Visual Cortex
</article-title> <source>Cell</source> <volume>169</volume>, <fpage>1291</fpage>â<lpage>1302</lpage>.e14, (<pub-id pub-id-type="doi">10.1016/j.cell.2017.05.023</pub-id>) (<year>2017</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Ayaz</surname></string-name> <etal>et al.</etal>, <article-title>Layer-specific integration of locomotion and sensory information in mouse barrel cortex</article-title> <source>Nature Communications</source> <volume>10</volume>, <fpage>2585</fpage>, (<pub-id pub-id-type="doi">10.1038/s41467-019-10564-8</pub-id>) (<year>2019</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><given-names>K. Banaie</given-names> <surname>Boroujeni</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Tiesinga</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Womelsdorf</surname></string-name>, <article-title>Interneuron-specific gamma synchronization indexes cue uncertainty and prediction errors in lateral prefrontal and anterior cingulate cortex</article-title> <source>eLife</source> <volume>10</volume>, ed. by <person-group person-group-type="editor"><string-name><given-names>S.</given-names> <surname>Haegens</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Frank</surname></string-name></person-group>, <fpage>e69111</fpage>, (<pub-id pub-id-type="doi">10.7554/eLife.69111</pub-id>) (<year>2021</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Berkes</surname></string-name>, <string-name><given-names>G.</given-names> <surname>OrbÃ¡n</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Lengyel</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Fiser</surname></string-name>, <article-title>Spontaneous Cortical Activity Reveals Hallmarks of an Optimal Internal Model of the Environment</article-title> <source>Science</source> <volume>331</volume>, <fpage>83</fpage>â<lpage>87</lpage>, eprint: <pub-id pub-id-type="doi">10.1126/science.1195870</pub-id>, (<ext-link ext-link-type="uri" xlink:href="https://www.science.org/doi/abs/10.1126/science.1195870">https://www.science.org/doi/abs/10.1126/science.1195870</ext-link>) (<year>2011</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><given-names>L.</given-names> <surname>Buesing</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Bill</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Nessler</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Maass</surname></string-name>, <article-title>Neural Dynamics as Sampling: A Model for Stochastic Computation in Recurrent Networks of Spiking Neurons</article-title>, <source>PLoS Comput Biol</source> <volume>7</volume>, <fpage>e1002211</fpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Cannon</surname></string-name>, <string-name><given-names>A. M.</given-names> <surname>OâBrien</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Bungert</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Sinha</surname></string-name>, <article-title>Prediction in Autism Spectrum Disorder: A Systematic Review of Empirical Evidence</article-title>, <source>Autism Res</source> <volume>14</volume> (<year>2021</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><given-names>M. X.</given-names> <surname>Cohen</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Wilmes</surname></string-name>, <string-name><given-names>I. v. d.</given-names> <surname>Vijver</surname></string-name>, <article-title>Cortical electrophysiological network dynamics of feedback learning</article-title>, <source>Trends Cogn Sci</source> <volume>15</volume>, <fpage>558</fpage>â<lpage>566</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><given-names>J. H.</given-names> <surname>Cornford</surname></string-name> <etal>et al.</etal>, <article-title>Dendritic NMDA receptors in parvalbumin neurons enable strong and stable neuronal assemblies</article-title> <source>eLife</source> <volume>8</volume>, ed. by <person-group person-group-type="editor"><string-name><given-names>M.</given-names> <surname>Bartos</surname></string-name>, <string-name><given-names>G. L.</given-names> <surname>Westbrook</surname></string-name></person-group>, <string-name><given-names>C.-C.</given-names> <surname>Lien</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Poncer</surname></string-name>, <fpage>e49872</fpage>, (<pub-id pub-id-type="doi">10.7554/eLife.49872</pub-id>) (<year>2019</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><given-names>G. P.</given-names> <surname>Dehaene</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Coen-Cagli</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Pouget</surname></string-name>, <article-title>Investigating the representation of uncertainty in neuronal circuits</article-title> <source>PLOS Computational Biology</source> <volume>17</volume>, <fpage>1</fpage>â<lpage>30</lpage>, (<pub-id pub-id-type="doi">10.1371/journal.pcbi.1008138</pub-id>) (<month>Feb</month>. <year>2021</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Dorsett</surname></string-name>, <string-name><given-names>B. D.</given-names> <surname>Philpot</surname></string-name>, <string-name><given-names>S. L.</given-names> <surname>Smith</surname></string-name>, <string-name><given-names>I. T.</given-names> <surname>Smith</surname></string-name>, <article-title>The Impact of SST and PV Interneurons on Nonlinear Synaptic Integration in the Neocortex</article-title>, <source>eNeuro</source> <volume>8</volume> (<year>2021</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><given-names>S. J.</given-names> <surname>Eliades</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Wang</surname></string-name>, <article-title>Neural substrates of vocalization feedback monitoring in primate auditory cortex</article-title> <source>Nature</source> <volume>453</volume>, <fpage>1102</fpage>â<lpage>1106</lpage>, (<pub-id pub-id-type="doi">10.1038/nature06910</pub-id>) (<year>2008</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><given-names>M. O.</given-names> <surname>Ernst</surname></string-name>, <string-name><given-names>M. S.</given-names> <surname>Banks</surname></string-name>, <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title> <source>Nature</source> <volume>415</volume>, <fpage>429</fpage>â<lpage>433</lpage>, (<pub-id pub-id-type="doi">10.1038/415429a</pub-id>) (<year>2002</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><given-names>C. R.</given-names> <surname>Fetsch</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Pouget</surname></string-name>, <string-name><given-names>G. C.</given-names> <surname>DeAngelis</surname></string-name>, <string-name><given-names>D. E.</given-names> <surname>Angelaki</surname></string-name>, <article-title>Neural correlates of reliability-based cue weighting during multisensory integration</article-title> <source>Nature Neuroscience</source> <volume>15</volume>, <fpage>146</fpage>â<lpage>154</lpage>, (<pub-id pub-id-type="doi">10.1038/nn.2983</pub-id>) (<year>2012</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><given-names>B. J.</given-names> <surname>Fischer</surname></string-name>, <string-name><given-names>J.</given-names> <surname>PeÃ±a</surname></string-name>, <article-title>Owl's behavior and neural representation predicted by Bayesian inference</article-title> <source>Nature Neuroscience</source> <volume>14</volume>, <fpage>1061</fpage>â<lpage>1066</lpage>, (<pub-id pub-id-type="doi">10.1038/nn.2872</pub-id>) (<year>2011</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Fiser</surname></string-name> <etal>et al.</etal>, <article-title>Experience-dependent spatial expectations in mouse visual cortex</article-title> <source>Nature Neuroscience</source> <volume>19</volume>, <fpage>1658</fpage> EP, (<pub-id pub-id-type="doi">10.1038/nn.4385</pub-id>) (<month>Sept</month>. <year>2016</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><given-names>W</given-names> <surname>Gaetz</surname></string-name> <etal>et al.</etal>, <article-title>GABA estimation in the brains of children on the autism spectrum: Measurement precision and regional cortical variation</article-title>, <source>Neuroimage</source> <volume>86</volume>, <fpage>1</fpage>â<lpage>9</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Gidon</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Segev</surname></string-name>, <article-title>Principles Governing the Operation of Synaptic Inhibition in Dendrites</article-title> <source>Neuron</source> <volume>75</volume>, <fpage>330</fpage>â<lpage>341</lpage>, (<pub-id pub-id-type="doi">10.1016/j.neuron.2012.05.015</pub-id>) (<year>2012</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="preprint"><string-name><given-names>C. J.</given-names> <surname>Gillon</surname></string-name> <etal>et al.</etal>, <article-title>Learning from unexpected events in the neocortical microcircuit</article-title> <source>bioRxiv</source> (<pub-id pub-id-type="doi">10.1101/2021.01.15.426915</pub-id>) (<year>2021</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Goris</surname></string-name> <etal>et al.</etal>, <article-title>Autistic traits are related to worse performance in a volatile reward learning task despite adaptive learning rates</article-title> <source>Autism</source> <volume>25</volume>, PMID: <pub-id pub-id-type="pmid">33030041</pub-id>, <fpage>440</fpage>â<lpage>451</lpage>, (<pub-id pub-id-type="doi">10.1177/1362361320962237</pub-id>) (<year>2021</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Goris</surname></string-name> <etal>et al.</etal>, <article-title>Interoception and Mental Health: A Roadmap</article-title>, <source>Biol Psychiatry Cogn Neurosci Neuroimaging</source> <volume>3</volume>, <fpage>667</fpage>â<lpage>674</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Harada</surname></string-name> <etal>et al.</etal>, <article-title>Non-Invasive Evaluation of the GABAergic/Glutamatergic System in Autistic Patients Observed by MEGA-Editing Proton MR Spectroscopy Using a Clinical 3 Tesla Instrument</article-title>, <source>J Autism Dev Disord</source> <volume>41</volume>, <fpage>447</fpage>â<lpage>454</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><given-names>L.</given-names> <surname>HertÃ¤g</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Clopath</surname></string-name>, <article-title>Prediction-error neurons in circuits with multiple neuron types: Formation, refinement, and functional implications</article-title>, <source>Proc Natl Acad Sci U S A</source> <volume>119</volume>, <fpage>e2115699119</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><given-names>L.</given-names> <surname>HertÃ¤g</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Sprekeler</surname></string-name>, <article-title>Learning prediction error neurons in a canonical interneuron circuit</article-title> <source>eLife</source> <volume>9</volume>, <fpage>e57541</fpage>, (<pub-id pub-id-type="doi">10.7554/eLife.57541</pub-id>) (<year>2020</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><given-names>J. S.</given-names> <surname>Isaacson</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Scanziani</surname></string-name>, <article-title>How Inhibition Shapes Cortical Activity</article-title> <source>Neuron</source> <volume>72</volume>, <fpage>231</fpage>â<lpage>243</lpage>, (<ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/">https://www.sciencedirect.com/science/article/pii/</ext-link> S0896627311008798) (<year>2011</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="preprint"><string-name><given-names>J.</given-names> <surname>Jordan</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Sacramento</surname></string-name>, <string-name><given-names>W. A. M.</given-names> <surname>Wybo</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>Petrovici</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Senn</surname></string-name>, <article-title>Learning Bayes-optimal dendritic opinion pooling</article-title>, <year>2022</year>, <source>arXiv</source>: 2104.13238 [q-bio.NC] <pub-id pub-id-type="doi">10.48550/arXiv.2104.13238</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><given-names>R.</given-names> <surname>Jordan</surname></string-name>, <string-name><given-names>G. B.</given-names> <surname>Keller</surname></string-name>, <article-title>Opposing Influence of Top-down and Bottom-up Input on Excitatory Layer 2/3 Neurons in Mouse Primary Visual Cortex</article-title> <source>Neuron</source> <volume>108</volume>, <fpage>1194</fpage>â<lpage>1206</lpage>.e5, (<ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S0896627320307480">https://www.sciencedirect.com/science/article/pii/S0896627320307480</ext-link>) (<year>2020</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><given-names>R.</given-names> <surname>Jordan</surname></string-name>, <string-name><given-names>G. B.</given-names> <surname>Keller</surname></string-name>, <article-title>The locus coeruleus broadcasts prediction errors across the cortex to promote sensorimotor plasticity</article-title>
<source>eLife</source> (<pub-id pub-id-type="doi">10.7554/elife.85111.2</pub-id>) (<year>2023</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Juarez</surname></string-name>, <string-name><given-names>V.</given-names> <surname>MartÃ­nez CerdeÃ±o</surname></string-name>, <article-title>Parvalbumin and parvalbumin chandelier interneurons in autism and other psychiatric disorders</article-title>, <source>Front Psychiatry</source> <volume>13</volume>, <fpage>913550</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><given-names>G. B.</given-names> <surname>Keller</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Bonhoeffer</surname></string-name>, <string-name><given-names>M.</given-names> <surname>HÃ¼bener</surname></string-name>, <article-title>Sensorimotor Mismatch Signals in Primary Visual Cortex of the Behaving Mouse</article-title> <source>Neuron</source> <volume>74</volume>, <fpage>809</fpage> â<lpage>815</lpage>, (<ext-link ext-link-type="uri" xlink:href="http://www.sciencedirect.com/science/article/pii/S0896627312003844">http://www.sciencedirect.com/science/article/pii/S0896627312003844</ext-link>) (<year>2012</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><given-names>G. B.</given-names> <surname>Keller</surname></string-name>, <string-name><given-names>R. H. R.</given-names> <surname>Hahnloser</surname></string-name>, <article-title>Neural processing of auditory feedback during vocal practice in a songbird</article-title> <source>Nature</source> <volume>457</volume>, <fpage>187</fpage>â<lpage>190</lpage>, (<pub-id pub-id-type="doi">10.1038/nature07467</pub-id>) (<year>2009</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><given-names>G. B.</given-names> <surname>Keller</surname></string-name>, <string-name><given-names>T. D.</given-names> <surname>Mrsic-Flogel</surname></string-name>, <article-title>Predictive Processing: A Canonical Cortical Computation</article-title> <source>Neuron</source> <volume>100</volume>, <fpage>424</fpage> â<lpage>435</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><given-names>R.</given-names> <surname>Kiani</surname></string-name>, <string-name><given-names>M. N.</given-names> <surname>Shadlen</surname></string-name>, <article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title>, <source>Science</source> <volume>324</volume>, <fpage>759</fpage>â<lpage>764</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><given-names>K. P.</given-names> <surname>KÃ¶rding</surname></string-name>, <string-name><given-names>D. M.</given-names> <surname>Wolpert</surname></string-name>, <article-title>Bayesian integration in sensorimotor learning</article-title> <source>Nature</source> <volume>427</volume>, <fpage>244</fpage>â<lpage>247</lpage>, (<pub-id pub-id-type="doi">10.1038/nature02169</pub-id>) (<year>2004</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Kreutzer</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Senn</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>Petrovici</surname></string-name>, <article-title>Natural-gradient learning for spiking neurons</article-title> <source>eLife</source> <volume>11</volume>, ed. by <person-group person-group-type="editor"><string-name><given-names>P.</given-names> <surname>Latham</surname></string-name>, <string-name><given-names>J. R.</given-names> <surname>Huguenard</surname></string-name></person-group>, <fpage>e66526</fpage>, (<pub-id pub-id-type="doi">10.7554/eLife.66526</pub-id>) (<year>2022</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Kveraga</surname></string-name>, <string-name><given-names>A. S.</given-names> <surname>Ghuman</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Bar</surname></string-name>, <article-title>Top-down predictions in the cognitive brain</article-title> <source>Brain and cognition</source> <volume>65</volume>, <fpage>145</fpage>â<lpage>168</lpage>, (<ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/17923222">https://pubmed.ncbi.nlm.nih.gov/17923222</ext-link>) (mNov. <year>2007</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><given-names>R. P.</given-names> <surname>Lawson</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Mathys</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Rees</surname></string-name>, <article-title>Adults with autism overestimate the volatility of the sensory environment</article-title> <source>Nature Neuroscience</source> <volume>20</volume>, <fpage>1293</fpage>â<lpage>1299</lpage>, (<pub-id pub-id-type="doi">10.1038/nn.4615</pub-id>) (<year>2017</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><given-names>R. P.</given-names> <surname>Lawson</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Rees</surname></string-name>, <string-name><given-names>K. J.</given-names> <surname>Friston</surname></string-name>, <article-title>An aberrant precision account of autism</article-title> <source>Frontiers in human neuroscience</source> <volume>8</volume>, <fpage>302</fpage>â<lpage>302</lpage>, (<ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/24860482">https://pubmed.ncbi.nlm.nih.gov/24860482</ext-link>) (mMay <year>2014</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><given-names>S.-H.</given-names> <surname>Lee</surname></string-name> <etal>et al.</etal>, <article-title>Activation of specific interneurons improves V1 feature selectivity and visual perception</article-title> <source>Nature</source> <volume>488</volume>, <fpage>379</fpage>â<lpage>383</lpage>, (<pub-id pub-id-type="doi">10.1038/nature11312</pub-id>) (<year>2012</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Kruglikov</surname></string-name>, <string-name><given-names>Z. J.</given-names> <surname>Huang</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Fishell</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Rudy</surname></string-name>, <article-title>A disinhibitory circuit mediates motor integration in the somatosensory cortex</article-title> <source>Nature Neuroscience</source> <volume>16</volume>, <fpage>1662</fpage>â<lpage>1670</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><given-names>W. J.</given-names> <surname>Ma</surname></string-name>, <string-name><given-names>J. M.</given-names> <surname>Beck</surname></string-name>, <string-name><given-names>P. E.</given-names> <surname>Latham</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Pouget</surname></string-name>, <article-title>Bayesian inference with probabilistic population codes</article-title> <source>Nature Neuroscience</source> <volume>9</volume>, <fpage>1432</fpage>â<lpage>1438</lpage>, (<pub-id pub-id-type="doi">10.1038/nn1790</pub-id>) (<year>2006</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Masset</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Ott</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Lak</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Hirokawa</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Kepecs</surname></string-name>, <article-title>Behavior- and Modality-General Representation of Confidence in Orbitofrontal Cortex</article-title> <source>Cell</source> <volume>182</volume>, <fpage>112</fpage>â<lpage>126</lpage>.e18, (<ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S0092867420306176">https://www.sciencedirect.com/science/article/pii/S0092867420306176</ext-link>) (<year>2020</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><given-names>C. M.</given-names> <surname>Niell</surname></string-name>, <string-name><given-names>M. P.</given-names> <surname>Stryker</surname></string-name>, <article-title>Highly Selective Receptive Fields in Mouse Visual Cortex</article-title> <source>Journal of Neuroscience</source> <volume>28</volume>, <fpage>7520</fpage>â<lpage>7536</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Payzan-LeNestour</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Bossaerts</surname></string-name>, <article-title>Risk, Unexpected Uncertainty, and Estimation Uncertainty: Bayesian Learning in Unstable Settings</article-title> <source>PLOS Computational Biology</source> <volume>7</volume>, <fpage>1</fpage>â<lpage>14</lpage>, (<pub-id pub-id-type="doi">10.1371/journal.pcbi.1001048</pub-id>) (<month>Jan</month>. <year>2011</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="preprint"><string-name><given-names>M. A.</given-names> <surname>Petrovici</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Bill</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Bytschok</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Schemmel</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Meier</surname></string-name>, <article-title>Stochastic inference with deterministic spiking neurons</article-title>, <year>2013</year>, <source>arXiv</source>: 1311.3211 [q-bio.NC] <pub-id pub-id-type="doi">10.48550/arXiv.1311.3211</pub-id>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><given-names>C. K.</given-names> <surname>Pfeffer</surname></string-name>, <article-title>Inhibitory Neurons: Vip Cells Hit the Brake on Inhibition</article-title> <source>Current Biology</source> <volume>24</volume>, <fpage>18</fpage>â<lpage>20</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><given-names>C. K.</given-names> <surname>Pfeffer</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Xue</surname></string-name>, <string-name><given-names>M.</given-names> <surname>He</surname></string-name>, <string-name><given-names>Z. J.</given-names> <surname>Huang</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Scanziani</surname></string-name>, <article-title>Inhibition of inhibition in visual cortex: the logic of connections between molecularly distinct interneurons</article-title> <source>Nature neuroscience</source> <volume>16</volume>, <fpage>1068</fpage>â<lpage>1076</lpage> (<month>Aug</month>. <year>2013</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><given-names>H.-J.</given-names> <surname>Pi</surname></string-name> <etal>et al.</etal>, <article-title>Cortical interneurons that specialize in disinhibitory control</article-title> <source>Nature</source> <volume>503</volume>, <fpage>521</fpage>â<lpage>524</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>PrÃ¶nneke</surname></string-name> <etal>et al.</etal>, <article-title>Characterizing VIP Neurons in the Barrel Cortex of VIPcre/tdTomato Mice Reveals Layer-Specific Differences</article-title> <source>Cerebral Cortex</source> <volume>25</volume>, <fpage>4854</fpage>â<lpage>4868</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="preprint"><string-name><given-names>C.</given-names> <surname>Raltschev</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Kasavica</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Leonardon</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Nevian</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Sachidhanandam</surname></string-name>, <article-title>Top-down modulation of sensory processing and mismatch in the mouse posterior parietal cortex</article-title> <source>bioRxiv</source>, (<pub-id pub-id-type="doi">10.1101/2023.05.11.540431</pub-id>) (<year>2023</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><given-names>R. P. N.</given-names> <surname>Rao</surname></string-name>, <string-name><given-names>D. H.</given-names> <surname>Ballard</surname></string-name>, <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects
</article-title> <source>Nature Neuroscience</source> <volume>2</volume>, <fpage>79</fpage>â<lpage>87</lpage>, (<pub-id pub-id-type="doi">10.1038/4580</pub-id>) (<year>1999</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><given-names>J. L. R.</given-names> <surname>Rubenstein</surname></string-name>, <string-name><given-names>M. M.</given-names> <surname>Merzenich</surname></string-name>, <article-title>Model of autism: increased ratio of excitation/inhibition in key neural systems</article-title>, <source>Genes, brain, and behavior</source> <volume>2</volume>, <fpage>255</fpage>â<lpage>267</lpage>, (https://pubmed.ncbi.nlm.nih.gov/14606691 <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6748642/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6748642/</ext-link>) (<year>2003</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><given-names>M. F. S.</given-names> <surname>Rushworth</surname></string-name>, <string-name><given-names>T. E. J.</given-names> <surname>Behrens</surname></string-name>, <article-title>Choice, uncertainty and value in prefrontal and cingulate cortex</article-title> <source>Nature Neuroscience</source> <volume>11</volume>, <fpage>389</fpage>â<lpage>397</lpage>, (<pub-id pub-id-type="doi">10.1038/nn2066</pub-id>) (<year>2008</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Sachidhanandam</surname></string-name>, <string-name><given-names>B. S.</given-names> <surname>Sermet</surname></string-name>, <string-name><given-names>C. C.</given-names> <surname>Petersen</surname></string-name>, <article-title>Parvalbumin-Expressing GABAergic Neurons in Mouse Barrel Cortex Contribute to Gating a Goal-Directed Sensorimotor Transformation</article-title> <source>Cell Reports</source> <volume>15</volume>, <fpage>700</fpage>â<lpage>706</lpage>, (<ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S2211124716303345">https://www.sciencedirect.com/science/article/pii/S2211124716303345</ext-link>) (<year>2016</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><string-name><given-names>B. A.</given-names> <surname>Seybold</surname></string-name>, <string-name><given-names>E. A.</given-names> <surname>Phillips</surname></string-name>, <string-name><given-names>C. E.</given-names> <surname>Schreiner</surname></string-name>, <string-name><given-names>A. R.</given-names> <surname>Hasenstaub</surname></string-name>, <article-title>Inhibitory Actions Unified by Network Integration</article-title> <source>Neuron</source> <volume>87</volume>, <fpage>1181</fpage>â<lpage>1192</lpage>, (<ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S0896627315007709">https://www.sciencedirect.com/science/article/pii/S0896627315007709</ext-link>) (<year>2015</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="preprint"><string-name><given-names>Z.</given-names> <surname>Shi</surname></string-name> <etal>et al.</etal>, <article-title>Beyond Prior Belief and Volatility: The Distinct Iterative Prior Updating Process in ASD</article-title> <source>bioRxiv</source>, (<pub-id pub-id-type="doi">10.1101/2022.01.21.477218</pub-id>) (<year>2022</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><given-names>R.</given-names> <surname>Urbanczik</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Senn</surname></string-name>, <article-title>Learning by the Dendritic Prediction of Somatic Spiking</article-title> <source>Neuron</source> <volume>81</volume>, <fpage>521</fpage>â<lpage>528</lpage>, (<ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S0896627313011276">https://www.sciencedirect.com/science/article/pii/S0896627313011276</ext-link>) (<year>2014</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Van de Cruys</surname></string-name> <etal>et al.</etal>, <article-title>Precise minds in uncertain worlds: predictive coding in autism</article-title>, <source>Psychol Rev</source> <volume>121</volume>, <fpage>649</fpage>â<lpage>675</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><given-names>A. R.</given-names> <surname>Walker</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Luque</surname></string-name>, <string-name><given-names>M. E.</given-names> <surname>Le Pelley</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Beesley</surname></string-name>, <article-title>The role of uncertainty in attentional and choice exploration</article-title> <source>Psychonomic Bulletin &amp; Review</source> <volume>26</volume>, <fpage>1911</fpage>â<lpage>1916</lpage>, (<pub-id pub-id-type="doi">10.3758/s13423-019-01653-2</pub-id>) (<year>2019</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><string-name><given-names>J. C. R.</given-names> <surname>Whittington</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Bogacz</surname></string-name>, <article-title>An Approximation of the Error Backpropagation Algorithm in a Predictive Coding Network with Local Hebbian Synaptic Plasticity</article-title>, <source>Neural Comput</source> <volume>29</volume>, <fpage>1229</fpage>â<lpage>1262</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><string-name><given-names>K. A.</given-names> <surname>Wilmes</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Clopath</surname></string-name>, <article-title>Inhibitory microcircuits for top-down plasticity of sensory representations</article-title> <source>Nature Communications</source> <volume>10</volume>, <fpage>5055</fpage>, (<pub-id pub-id-type="doi">10.1038/s41467-019-12972-2</pub-id>) (<year>2019</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><string-name><given-names>K. A.</given-names> <surname>Wilmes</surname></string-name>, <string-name><given-names>J.-H.</given-names> <surname>Schleimer</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Schreiber</surname></string-name>, <article-title>Spike-timing dependent inhibitory plasticity to learn a selective gating of backpropagating action potentials</article-title> <source>European Journal of Neuroscience</source> <volume>45</volume>, <fpage>1032</fpage>â<lpage>1043</lpage>, <pub-id pub-id-type="doi">10.1111/ejn.13326</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><string-name><given-names>K. A.</given-names> <surname>Wilmes</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Sprekeler</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Schreiber</surname></string-name>, <article-title>Inhibition as a Binary Switch for Excitatory Plasticity in Pyramidal Neurons</article-title> <source>PLoS Computational Biology</source> <volume>12</volume>, <fpage>e1004768</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><string-name><given-names>N. R.</given-names> <surname>Wilson</surname></string-name>, <string-name><given-names>C. A.</given-names> <surname>Runyan</surname></string-name>, <string-name><given-names>F. L.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Sur</surname></string-name>, <article-title>Division and subtraction by distinct cortical inhibitory networks in vivo</article-title>, <source>Nature</source> <volume>488</volume>, <fpage>343</fpage>â<lpage>348</lpage> (<year>2012</year>) <pub-id pub-id-type="doi">10.1038/nature11347</pub-id>.</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Zmarz</surname></string-name>, <string-name><given-names>G. B.</given-names> <surname>Keller</surname></string-name>, <article-title>Mismatch Receptive Fields in Mouse Visual Cortex</article-title>, <source>Neuron</source> <volume>92</volume>, <fpage>766</fpage>â<lpage>772</lpage> (<year>2016</year>) <pub-id pub-id-type="doi">10.1016/j.neuron.2016.09.057</pub-id>.</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><string-name><given-names>ÃdÃ¡m</given-names> <surname>Koblinger</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Fiser</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Lengyel</surname></string-name>, <article-title>Representations of uncertainty: where art thou?</article-title> <source>Current Opinion in Behavioral Sciences 38, Computational cognitive neuroscience</source>, <fpage>150</fpage>â<lpage>162</lpage>, (<pub-id pub-id-type="doi">10.1016/j.cobeha.2021.03.009</pub-id>) (<year>2021</year>).</mixed-citation></ref>
</ref-list>
<ack>
<title>Acknowledgements</title>
<p>We would like to thank Loreen HertÃ¤g and Sadra Sadeh for feedback on the manuscript. This work has received funding from the European Union 7th Framework Programme under grant agreement 604102 (HBP), the Horizon 2020 Framework Programme under grant agreements 720270, 785907 and 945539 (HBP) and the Manfred StÃ¤rk Foundation.</p>
</ack>
<sec id="s5">
<title>Competing Interests Statement</title>
<p>The authors declare that they have no competing interests.</p>
</sec>
<sec id="s6">
<title>Code availability</title>
<p>All simulation code used for this paper will be made available on GitHub upon publication (<ext-link ext-link-type="uri" xlink:href="https://github.com/k47h4/UPE">https://github.com/k47h4/UPE</ext-link>) and is attached to the submission as supplementary file for the reviewers.</p>
</sec>
<sec id="s7">
<title>Supplementary Information</title>
<sec id="s7a">
<title>Supplementary Methods</title>
<sec id="s7a1">
<title>Synaptic dynamics/plasticity rules</title>
<p>
<disp-formula id="eqn44">
<graphic xlink:href="540393v5_eqn44.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn45">
<graphic xlink:href="540393v5_eqn45.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn46">
<graphic xlink:href="540393v5_eqn46.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn47">
<graphic xlink:href="540393v5_eqn47.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn48">
<graphic xlink:href="540393v5_eqn48.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s7a2">
<title>Different choice of supralinear activation function for PV</title>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9:</label>
<caption><p>Learning the variance in the positive prediction error circuit with PVs with a power activation function (exponent = 3.0). A and B are analogous to <xref rid="fig3" ref-type="fig">Fig. 3G</xref> and <xref rid="fig3" ref-type="fig">H</xref>, and the circuit is the same except that the activation function of the PVs (<italic>Ï</italic><sub><italic>P V</italic></sub> (<italic>x</italic>)) has an exponent of 3.0 instead of 2.0. C and D are zoomed-out versions of A and B.</p></caption>
<graphic xlink:href="540393v5_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7a3">
<title>Plastic weights from SST to PV learn to match weights from <italic>s</italic> to PV</title>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure 10:</label>
<caption><p>With inhibitory plasticity, weights from SST to PV can be learned. This figure shows that the weight from SST to PV (<italic>w</italic><sub>PV,SST</sub>) is equal to the weight from <italic>s</italic> to PV (<italic>w</italic><sub>PV,<italic>s</italic></sub>). The inhibitory plasticity rule is described in the Supplementary Methods.</p></caption>
<graphic xlink:href="540393v5_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7a4">
<title>PVs learn the variance in the negative prediction error circuit</title>
<fig id="fig11" position="float" fig-type="figure">
<label>Figure 11:</label>
<caption><title>PVs learn to represent the variance given an associative cue in the negative prediction error circuit.</title>
<p>A: Illustration of the changes in the negative prediction error circuit. Thicker lines denote stronger weights. B: Two different tones (purple, green) are associated with two somatosensory stimulus distributions with different variances (purple: high, green: low). C: Weights from sound <italic>a</italic> to PV over time for two different values of stimulus variance (high: <italic>Ï</italic> = 0.8 (purple), low: <italic>Ï</italic> = 0.4 (green)). D: PV firing rates over time given sound input (without stimulus input) for low (green) and high (purple) stimulus variance. E: PV firing rates (mean and std) given sound input for low and high stimulus variance. F: PV firing rates (mean and std) during sound and stimulus input. G: Weights from sound <italic>a</italic> to PV for different values of <italic>Ï</italic> (mean and std). H: PV firing rates given sound input for different values of <italic>Ï</italic><sup>2</sup> (mean and std).</p></caption>
<graphic xlink:href="540393v5_fig11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7a5">
<title>Learning the weights from the SSTs to the prediction error neurons</title>
<fig id="fig12" position="float" fig-type="figure">
<label>Figure 12:</label>
<caption><p>Learning the weights from the SSTs to the UPE neurons. This figure shows that the weights from the SSTs to the UPEs in both the positive (left) and the negative (right) prediction error circuit can be learned with inhibitory plasticity to match the weights from the stimulus representation <italic>s</italic> to the UPEs. The inhibitory plasticity rule is described in the supplementary methods.</p></caption>
<graphic xlink:href="540393v5_fig12.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7a6">
<title>PV activity is proportional to the variance in the recurrent circuit</title>
<fig id="fig13" position="float" fig-type="figure">
<label>Figure 13:</label>
<caption><p>PV firing rates are proportional to the variance in the recurrent circuit model. Weights from <italic>a</italic> to PV as a function of <italic>Ï</italic> in the positive (A) and negative (C) prediction error subcircuit. PV firing rates as a function of <italic>Ï</italic><sup>2</sup> in the positive (B) and negative (D) prediction error circuit.</p></caption>
<graphic xlink:href="540393v5_fig13.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95127.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Keller</surname>
<given-names>Georg B</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Friedrich Miescher Institute</institution>
</institution-wrap>
<city>Basel</city>
<country>Switzerland</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> study introduces a new cortical circuit model for predictive processing. Simulations effectively illustrate that, with appropriate synaptic plasticity, a canonical layer 2/3 cortical circuit - comprising two classes of interneurons providing subtractive and divisive inhibition - can generate uncertainty-modulated prediction errors by pyramidal neurons. The model's effectiveness is supported by <bold>solid</bold> numerical analysis. Although the model is <bold>convincing</bold> and offers testable predictions, it currently lacks direct comparison to experimental data, and the presentation clarity could be improved. Nonetheless, the model is expected to be of great interest to those involved in cortical and predictive processing research.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95127.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
Wilmes and colleagues present a computational model of a cortical circuit for predictive processing which tackles the issue of how to learn predictions when different levels of uncertainty are present for the predicted sensory stimulus. When a predicted sensory outcome is highly variable, deviations from the average expected stimulus should evoke prediction errors that have less impact on updating the prediction of the mean stimulus. In the presented model, layer 2/3 pyramidal neurons represent either positive or negative prediction errors, SST neurons mediate the subtractive comparison between prediction and sensory input, and PV neurons represent the expected variance of sensory outcomes. PVs therefore can control the learning rate by divisively inhibiting prediction error neurons such that they are activated less, and exert less influence on updating predictions, under conditions of high uncertainty.</p>
<p>Strengths:</p>
<p>
The presented model is a very nice solution to altering the learning rate in a modality and context-specific way according to expected uncertainty and, importantly, the model makes clear, experimentally testable predictions for interneuron and pyramidal neuron activity. This is therefore an important piece of modelling work for those working on cortical and/or predictive processing and learning. The model is largely well-grounded in what we know of the cortical circuit.</p>
<p>Weaknesses:</p>
<p>
Currently, the model has not been challenged with experimental data, presumably because data from an adequate paradigm is not yet available. I therefore only have minor comments regarding the biological plausibility of the model:</p>
<p>Beyond the fact that some papers show SSTs mediate subtractive inhibition and PVs mediate divisive inhibition, the selection of interneuron types for the different roles could be argued further, given existing knowledge of their properties. For instance, is a high PV baseline firing rate, or broad sensory tuning that is often interpreted as a 'pooling' of pyramidal inputs, compatible with or predicted by the model?</p>
<p>On a related note, SSTs are thought to primarily target the apical dendrite, while PVs mediate perisomatic inhibition, so the different roles of the interneurons in the model make sense, particularly for negative PE neurons, where a top-down excitatory predicted mean is first subtractively compared with the sensory input, s, prior to division by the variance. However, sensory input is typically thought of as arising 'bottom-up', via layer 4, so the model may match the circuit anatomy less in the case of positive PE neurons, where the diagram shows 's' arising in a top-down manner. Do the authors have a justification for this choice?</p>
<p>In cortical circuits, assuming a 2:8 ratio of inhibitory to excitatory neurons, there are at least 10 pyramidal neurons to each SST and PV neuron. Pyramidal neurons are also typically much more selective about the type of sensory stimuli they respond to compared to these interneuron classes (e.g., Kerlin et al., 2012, Neuron). A nice feature of the proposed model is that the same interneurons can provide predictions of the mean and variance of the stimulus in a predictor-dependent manner. However, in a scenario where you have two types of sensory stimulus to predict (e.g., two different whiskers stimulated), with pyramidal neurons selective for prediction errors in one or the other, what does the model predict? Would you need specific SST and PV circuits for each type of predicted stimulus?</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95127.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
This computational modeling study addresses the observation that variable observations are interpreted differently depending on how much uncertainty an agent expects from its environment. That is, the same mismatch between a stimulus and an expected stimulus would be less significant, and specifically would represent a smaller prediction error, in an environment with a high degree of variability than in one where observations have historically been similar to each other. The authors show that if two different classes of inhibitory interneurons, the PV and SST cells, (1) encode different aspects of a stimulus distribution and (2) act in different (divisive vs. subtractive) ways, and if (3) synaptic weights evolve in a way that causes the impact of certain inputs to balance the firing rates of the targets of those inputs, then pyramidal neurons in layer 2/3 of canonical cortical circuits can indeed encode uncertainty-modulated prediction errors. To achieve this result, SST neurons learn to represent the mean of a stimulus distribution and PV neurons its variance.</p>
<p>The impact of uncertainty on prediction errors is an understudied topic, and this study provides an intriguing and elegant new framework for how this impact could be achieved and what effects it could produce. The ideas here differ from past proposals about how neuronal firing represents uncertainty. The developed theory is accompanied by several predictions for future experimental testing, including the existence of different forms of coding by different subclasses of PV interneurons, which target different sets of SST interneurons (as well as pyramidal cells). The authors are able to point to some experimental observations that are at least consistent with their computational results. The simulations shown demonstrate that if we accept its assumptions, then the authors' theory works very well: SSTs learn to represent the mean of a stimulus distribution, PVs learn to estimate its variance, firing rates of other model neurons scale as they should, and the level of uncertainty automatically tunes the learning rate, so that variable observations are less impactful in a high uncertainty setting.</p>
<p>Strengths:</p>
<p>
The ideas in this work are novel and elegant, and they are instantiated in a progression of simulations that demonstrate the behavior of the circuit. The framework used by the authors is biologically plausible and matches some known biological data. The results attained, as well as the assumptions that go into the theory, provide several predictions for future experimental testing.</p>
<p>Weaknesses:</p>
<p>
Overall, I found this manuscript to be frustrating to read and to try to understand in detail, especially the Results section from the UPE/Figure 4 part to the end and parts of the Methods section. I don't think the main ideas are so complicated, and it should be possible to provide a much clearer presentation.</p>
<p>For me, one source of confusion is the comparison across Figure 1EF, Figure 2A, Figure 3A, Figure 4AB, and Figure 5A. All of these are meant to be schematics of the same circuit (although with an extra neuron in Figure 5), yet other than Figures 1EF and 4AB, no two are the same! There should be a clear, consistent schematic used, with identical labeling of input sources, neuron types, etc. across all of these panels.</p>
<p>The flow of the Results section overall is clear until the ``Calculation of the UPE in Layer 2/3 error neurons' and Figure 4, where I find that things become significantly more confusing. The mention of NMDA and calcium spikes comes out of the blue, and it's not clear to me how this fits into the authors' theory. Moreover: Why would this property of pyramidal cells cause the PV firing rate to increase as stated? The authors refer to one set of weights (from SSTs to UPE) needing to match two targets (weights from s to UPE and weights from mean representation to UPE); how can one set of weights match two targets? Why do the authors mention ``out-of-distribution detection' here when that property is not explored later in the paper? (see also below for other comments on Figure 4)</p>
<p>Coming back to one of the points in the previous paragraph: How realistic is this exact matching of weights, as well as the weight matching that the theory requires in terms of the weights from the SSTs to the PVs and the weights from the stimuli to the PVs? This point should receive significant elaboration in the discussion, with biological evidence provided. I would not advocate for the authors' uncertainty prediction theory, despite its elegant aspects, without some evidence that this weight matching occurs in the brain. Also, the authors point out on page 3 that unlike their theory, &quot;...SSTs can also have divisive effects, and PVs can have subtractive effects, dependent on circuit and postsynaptic properties&quot;. This should be revisited in the Discussion, and the authors should explain why these effects are not problematic for their theory. In a similar vein, this work assumes the existence of two different populations of SST neurons with distinct UPE (pyramidal) targets. The Discussion doesn't say much about any evidence for this assumption, which should be more thoroughly discussed and justified.</p>
<p>Finally, I think this is a paper that would have been clearer if the equations had been interspersed within the results. Within the given format, I think the authors should include many more references to the Methods section, with specific equation numbers, where they are relevant throughout the Results section. The lack of clarity is certainly made worse by the current state of the Methods section, where there is far too much repetition and poor ordering of material throughout.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95127.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
The authors proposed a normative principle for how the brain's internal estimate of an observed sensory variable should be updated during each individual observation. In particular, they propose that the update size should be inversely proportional to the variance of the variable. They then proposed a microcircuit model of how such an update can be implemented, in particularly incorporating two types of interneurons and their subtractive and divisive inhibition onto pyramidal neurons. One type should represent the estimated mean while another represents the estimated variance. The authors used simulations to show that the model works as expected.</p>
<p>Strengths:</p>
<p>
The paper addresses two important issues: how uncertainty is represented and used in the brain, and the role of inhibitory neurons in neural computation. The proposed circuit and learning rules are simple enough to be plausible. They also work well for the designated purposes. The paper is also well-written and easy to follow.</p>
<p>Weaknesses:</p>
<p>
I have concerns with two aspects of this work.</p>
<p>(1) The optimality analysis leading to Eq (1) appears simplistic. The learning setting the authors describe (estimating the mean of a stationary Gaussian variable from a stream of observations) is a very basic problem in online learning/streaming algorithm literature. In this setting, the real &quot;optimal&quot; estimate is simply the arithmetic average of all samples seen so far. This can be implemented in an online manner with \hat{\mu}_{t} = \hat{\mu}_{t-1} +(s_t-\hat{\mu}_{t-1})/t. This is optimal in the sense that the estimator is always the maximum likelihood estimator given the samples seen up to time t. On the other hand, doing gradient descent only converges towards the MLE estimator after a large number of updates. Another critique is that while Eq (1) assumes an estimator of the mean (\hat{mu}), it assumes that the variance is already known. However, in the actual model, the variance also needs to be estimated, and a more sophisticated analysis thus needs to take into account the uncertainty of the variance estimate and so on. Finally, the idea that the update should be inverse to the variance is connected to the well-established idea in neuroscience that more evidence should be integrated over when uncertainty is high. For example, in models of two-alternative forced choices it is known to be optimal to have a longer reaction time when the evidence is noisier.</p>
<p>(2) While the incorporation of different inhibitory cell types into the model is appreciated, it appears to me that the computation performed by the circuit is not novel. Essentially the model implements a running average of the mean and a running average of the variance, and gates updates to the mean with the inverse variance estimate. I am not sure about how much new insight the proposed model adds to our understanding of cortical microcircuits.</p>
</body>
</sub-article>
</article>