<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">101506</article-id>
<article-id pub-id-type="doi">10.7554/eLife.101506</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.101506.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A conserved code for anatomy: Neurons throughout the brain embed robust signatures of their anatomical location into spike trains</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6405-2908</contrib-id>
<name>
<surname>Tolossa</surname>
<given-names>Gemechu B</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">∗</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8774-2303</contrib-id>
<name>
<surname>Schneider</surname>
<given-names>Aidan M</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">∗</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dyer</surname>
<given-names>Eva L</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5017-4090</contrib-id>
<name>
<surname>Hengen</surname>
<given-names>Keith B</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>khengen@wustl.edu</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01yc7t268</institution-id><institution>Department of Biology, Washington University in Saint Louis</institution></institution-wrap>, <city>Saint Louis</city>, <country>United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zkghx44</institution-id><institution>Department of Biomedical Engineering, Georgia Institute of Technology</institution></institution-wrap>, <city>Atlanta</city>, <country>United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Sharpee</surname>
<given-names>Tatyana O</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Salk Institute for Biological Studies</institution>
</institution-wrap>
<city>La Jolla</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Nelson</surname>
<given-names>Sacha B</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brandeis University</institution>
</institution-wrap>
<city>Waltham</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>∗</label><p>These authors contributed equally to this work</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-11-19">
<day>19</day>
<month>11</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP101506</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-07-30">
<day>30</day>
<month>07</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-07-31">
<day>31</day>
<month>07</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.07.11.603152"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Tolossa et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Tolossa et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-101506-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Neurons in the brain are known to encode diverse information through their spiking activity, primarily reflecting external stimuli and internal states. However, whether individual neurons also embed information about their own anatomical location within their spike patterns remains largely unexplored. Here, we show that machine learning models can predict a neuron’s anatomical location across multiple brain regions and structures based solely on its spiking activity. Analyzing high-density recordings from thousands of neurons in awake, behaving mice, we demonstrate that anatomical location can be reliably decoded from neuronal activity across various stimulus conditions, including drifting gratings, naturalistic movies, and spontaneous activity. Crucially, anatomical signatures generalize across animals and even across different research laboratories, suggesting a fundamental principle of neural organization. Examination of trained classifiers reveals that anatomical information is enriched in specific interspike intervals as well as responses to stimuli. Within the visual isocortex, anatomical embedding is robust at the level of layers and primary versus secondary but does not robustly separate individual secondary structures. In contrast, structures within the hippocampus and thalamus are robustly separable based on their spike patterns. Our findings reveal a generalizable dimension of the neural code, where anatomical information is multiplexed with the encoding of external stimuli and internal states. This discovery provides new insights into the relationship between brain structure and function, with broad implications for neurodevelopment, multimodal integration, and the interpretation of large-scale neuronal recordings. Immediately, it has potential as a strategy for in-vivo electrode localization.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Corrected small plotting error in Fig. 3, increased resolution of Allen Institute Logo in Fig. 7.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Foundational to any effort towards understanding the brain is a singular question: what information is carried in a neuron’s spiking? It is widely understood that the action potential is the unit of information exchange in the central nervous system. Adrian first recorded a single neuron’s action potential in 1928, establishing a rate code in sensory neurons [<xref ref-type="bibr" rid="c1">1</xref>]. In 1943, McCulloch and Pitts demonstrated that neuronal circuits could compute Boolean algebra [<xref ref-type="bibr" rid="c2">2</xref>], and 16 years later showed that the visual environment is conveyed to the brain by way of neuronal spike patterns [<xref ref-type="bibr" rid="c3">3</xref>]. Since then, the concept of a neural code has emerged— neuronal spiking is determined by inputs, including stimuli, and noise [<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c7">7</xref>]. In parallel works spanning 1899 to 1951, Cajal, Brodmann, and Penfield demonstrated diverse neuronal types that organize into anatomical loci, each with distinct functional contributions to sensation, perception, and behavior [<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c10">10</xref>]. In other words, information carried by neighboring neurons is likely to be similar in content, be it visual or interoceptive. However, much of our understanding of the neural code is derived from experimental designs that manipulate stimuli or measure behavior. This approach leaves innumerable other forms of biologically relevant features as potentially latent variables, such as reliable identifying information about the neuron itself. A complete understanding of these latent variables is essential for a complete understanding of a neuron’s role in the brain.</p>
<p>The null hypothesis is that the impact of anatomy on a neuron’s activity is either nonexistent or unremarkable. This is supported by three observations at the level of models. First, from a computational perspective, neurons’ outputs primarily reflect their inputs along with noise [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>]. Second, artificial recurrent neural networks, which also perform input integration, can emulate patterns of neural circuit activity and functions central to biology, including motor control [<xref ref-type="bibr" rid="c13">13</xref>] and visual processing [<xref ref-type="bibr" rid="c14">14</xref>]. Yet, such networks do not require the formalized structure that is a hallmark of brain organization. Finally, in deep neural networks, anatomy is only relevant insofar as progressively deeper layers are functionally distinct. Taken together, complex information processing is achievable with neither a strict concept of anatomy nor a computational encoding of anatomy.</p>
<p>However, there are three principal reasons to justify asking if neurons reliably embed their anatomical location in their spiking. First, recent work suggests that, in addition to stimulus information, neurons transmit their genetic identity [<xref ref-type="bibr" rid="c15">15</xref>]. Second, in contrast to artificial systems, there are conceptual reasons why a brain might benefit from a reliable neuron-level code for anatomy. For example, anatomical information is presumably crucial during neurodevelopment [<xref ref-type="bibr" rid="c16">16</xref>]. Likewise, such information could be valuable when parsing inputs during multimodal integration [<xref ref-type="bibr" rid="c17">17</xref>]. Finally, within a species, brain anatomy is highly stereotyped. Thus, it stands to reason that, should a neuron’s anatomy be embedded in its spike train, this embedding might generalize across individuals.</p>
<p>Historically, the classification of brain regions has utilized anatomical landmarks, functional outputs, and, more recently, genetic markers, creating a comprehensive map of neural diversity. There is evidence that neural activity may vary by region, although such observations are restricted to population-level statistics [<xref ref-type="bibr" rid="c18">18</xref>]. Specifically, patterns of neural activity evolve gradually across the anatomical landscape, influenced by gradients of synaptic weight [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c20">20</xref>], the autocorrelation timescale [<xref ref-type="bibr" rid="c21">21</xref>], and connectivity patterns [<xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c24">24</xref>]. While indicative of the brain’s complex architecture, these observations comprise subtle, statistical differences between populations rather than stark, unique signatures that could be used to classify an individual neuron with any confidence. Thus it is unclear whether different computational rules have evolved in functionally distinct circuits. Alternatively, subtle statistical changes could reflect methodological limitations to capturing the full spectrum of activity patterns that define distinct brain regions. Should robust, circuit-specific rules exist, their description would enable a more precise understanding of how regional variations contribute to the broader neural code, and sharpen our understanding of the brain’s computational organization.</p>
<p>Ultimately, the question can be distilled as, what is the minimum spatial scale at which neural activity patterns are reliably structured by the region of origin? Such patterns, should they exist, are most meaningful when identified at the level of single neurons. However, given the variance observed in any number of neuronal features—from tuning properties, to genetic cell type, to connectivity — it is unlikely that anatomy reliably determines neural activity at an obvious level, if at all. To address this, we employed a supervised machine learning approach to analyze publicly available datasets of high density, multi-region, single unit recordings in awake and behaving mice. To specifically evaluate whether anatomical information is embedded in the neuronal code, we examined the timing of spikes generated by well-isolated single units. We examined the possibility of anatomically-defined computational rules at four levels: 1) large-scale brain regions (hippocampus, midbrain, thalamus, and visual isocortex), 2) hippocampal structures (CA1, CA3, dentate gyrus, prosubiculum, and subiculum), 3) thalamic structures (ethmoid nucleus, dorsal lateral geniculate, lateral posterior nucleus, ventral medial geniculate, posterior complex, suprageniculate nucleus, ventral posteromedial nucleus), and 4) visual cortical structures (primary, anterolateral, anteromedial, lateral, posteromedial, rostrolateral). We find that traditional measures of neuronal activity (e.g. firing rate) alone are unable to reliably distinguish anatomical location. In contrast, using a multi-layer perceptron (MLP), we reveal that information about brain regions and structure is recoverable from more complete representations of single unit spiking (e.g. interspike interval distribution). Further, we demonstrate that learning the computational anatomical rules in one animal is sufficient to decode another, both within and across distinct research groups. These observations suggest a conserved code for anatomical origin in the output of individual neurons, and that, in modern datasets that span multiple regions, electrode localization can be assisted by spike timing.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Dataset and inclusion criteria</title>
<p>To evaluate whether individual neurons embed reliable information about their structural localization in their spike trains, we required consistently reproduced recordings of large numbers of single units distributed throughout numerous cortical and subcortical structures. Further, we reasoned that candidate recordings should involve only awake and behaving animals. Finally, while highly restricted and repetitive stimuli are frequently leveraged to average out noise [<xref ref-type="bibr" rid="c25">25</xref>], this approach increases the likelihood of overfitting in our case. Thus, we only considered datasets that contained diverse stimuli as well as spontaneous activity. Two open datasets from the Allen Institute meet these criteria, specifically 1) Brain Observatory and 2) Functional Connectivity [<xref ref-type="bibr" rid="c18">18</xref>]. These datasets comprise tens of thousands of neurons recorded with high density silicon probes (Neuropixels) in a total of <italic>N</italic> = 58 mice (BO <italic>N</italic> = 32, FC <italic>N</italic> = 26). We used the selections of drifting gratings and naturalistic movie [<xref ref-type="bibr" rid="c26">26</xref>] found in the Brain Observatory dataset, which were distinct from those in the Functional Connectivity dataset. Additionally, we used recordings of spontaneous activity during blank screen presentations from both the Brain Observatory and Functional Connectivity datasets. Raw data were spike sorted at the Allen Institute; because information transmission in the brain arises primarily from the timing of spiking and not waveforms (etc)., our studies involve only the timestamps of individual spikes from well-isolated units (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). These units were filtered according to objective quality metrics such as ISI violations, presence ratio and amplitude cutoff (see Methods). At the largest spatial division, neurons were assigned to four distinct brain regions; hippocampus, midbrain, thalamus, and visual cortices. Within regions, neurons were assigned to fine grained structures, for example CA1 hippocampus, lateral posterior thalamus, and anteromedial visual cortex (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). Note that midbrain neurons were not further classified by structure due to the relatively low number of neurons recorded there (to be considered at the structure level, we required a minimum of n = 150 neurons). We tested the possibility of a computational embedding of anatomical location at two levels of generalizability. In the transductive approach, all neurons from all animals were merged before splitting into a training set and a testing set. This arrangement preserves the capacity of a model to learn some within-animal features. In contrast, for the inductive approach, model training is performed on all neurons from a set of animals, and model testing is performed on neurons from entirely withheld animals. In this case, any successful learning must, by definition, be generalizable across animals (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Dimensionality reduction suggests a limited relationship between neuroanatomy and spike timing.</title>
<p><bold>A.</bold> Experimental pipeline. Left to right: Recording, raw data, extracted spike times, spiking time features (e.g., rates, CV), and model training protocols. The Allen Institute Visual Coding dataset comprises high density silicon extracellular recordings that span multiple brain regions and structures. During recording, mice were headfixed and presented with multiple visual stimuli, including drifting gratings. For supervised experiments, classifiers were either transductive—all neurons from all animals were mixed, and divided into train and test sets, or inductive— train and test sets were divided at the level of the animal. <bold>B.</bold> Brain regions and structures included in our analyses. (Left to right) Brain Regions: Hippocampus, Midbrain, Thalamus and Visual Cortex. Hippocampal Structures: CA1, CA3, Dentate Gyrus (DG), Prosubiculum (ProS), Subiculum (SUB). Thalamic Structures: Ethmoid Nucleus (Eth), Dorsal Lateral Geniculate (LGd), Lateral Posterior Nucleus (LP), Ventral Medial Geniculate (MGv), Posterior Complex (PO), Suprageniculate Nucleus (SGN), Ventral Posteromedial Nucleus (VPM). Visuocortical Structures: Anterolateral (VISal), Anteromedial (VISam), Lateral (VISl), Primary (VISp), Posteromedial (VISpm), Rostrolateral (VISrl). <bold>C.</bold> Unsupervised t-SNE plot of units recorded in each set of regions/structures. For each unit, 14 spiking metrics (see methods) describe the spike train, which is then placed in t-SNE, 2D scatterplot. Color scheme follows 1B. P-values are derived from a permutation test (shuffled control) of structure/region classifiability on the dimensionally-reduced space-see Unsupervised Analysis section of Methods</p></caption>
<graphic xlink:href="603152v3_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2b">
<title>Exploratory trends in spiking by region and structure across the population</title>
<p>Many studies have highlighted statistical differences in the activity of populations of neurons as a function of brain region and structure [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c29">29</xref>]. At face value, this raises the possibility that anatomy may have a powerful role in shaping spiking patterns. However, the existence of population-level differences does not necessarily imply that the anatomical location of an individual neuron can be reliably inferred from its spike train alone; especially in large datasets, even subtle regional differences in spiking may be significant. Put simply, statistically separable populations can exhibit extensive overlap [<xref ref-type="bibr" rid="c30">30</xref>]. Prior to considering patterns embedded in individual spike trains, we asked whether and to what extent anatomical location explains the diversity of spiking patterns when considered across the entire population of included neurons (n = 18,691 neurons from N = 32 mice). Specifically, we applied unsupervised analyses in which the dominant trends in data are learned first, and afterwards, the correspondence of trends to anatomical location is examined.</p>
<p>We examined three distinct representations of spiking activity: 1) a previously described collection of 14 well-established spiking metrics (e.g. firing rate, coefficient of variation, etc.) [<xref ref-type="bibr" rid="c15">15</xref>], 2) the distribution of interspike intervals (ISIs) (0-3 s, 100 uniform bins), and 3) the trial averaged PSTHs for each drifting grating condition (the collection of gratings included 8 orientations and 5 frequencies, PSTH was calculated in 100 msec bins across a 3 s trial). To ensure generalizability across unsupervised analyses, we employed three dimensionality reduction methods: 1) Principal Components Analysis (PCA) [<xref ref-type="bibr" rid="c31">31</xref>], 2) t-distributed Stochastic Neighbor Embedding (t-SNE) [<xref ref-type="bibr" rid="c32">32</xref>], and 3) Uniform Manifold Approximation and Projection (UMAP) [<xref ref-type="bibr" rid="c33">33</xref>]. The resultant scatter plots suggest that, depending on the combination of analytical method and included features, there are subtle but statistically significant influences of brain region and structure in these dimensionally-reduced spaces (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>, <xref rid="figs1" ref-type="fig">S1</xref>). However, across all 36 combinations of anatomical tasks, examined features, and analytical approaches, there was not a single example of a prominent grouping at the level of brain structure or brain region. These data may suggest that, examined as large populations, various features of neuronal spike timing may differ between regions, but that such differences are neither distinct nor robust. In this context, it is interesting to note that, despite rigidly stereotyped anatomy and structures defined by cell-type specific enrichment [<xref ref-type="bibr" rid="c34">34</xref>, <xref ref-type="bibr" rid="c35">35</xref>], hippocampal populations stood out for their anomalous lack of statistically significant partitioning between structures (<xref rid="figs1" ref-type="fig">Fig. S1</xref>).</p>
</sec>
<sec id="s2c">
<title>Separability of brain structures using established spiking metrics</title>
<p>Conservatively, it is possible that our unsupervised analysis (<xref rid="fig1" ref-type="fig">Fig. 1</xref>) reflects a true limit of the separability of structures based on spiking activity. However, by definition, unsupervised approaches reflect the most prominent trends (e.g. the largest sources of variance, in the case of PCA) in neuronal activity, which may or may not be related to anatomical location. As a result, it is possible that an analysis whose effectiveness is defined by the separability of region and structure may reveal more reliable anatomical rules. To test this possibility, we turned to a supervised approach. We asked whether, given the spiking activity of a single unit, could its region and/or structure be successfully predicted by a machine-learning model?</p>
<p>Broadly, in our initial supervised experiments we pooled units from all animals. Pooled neurons were divided into non-overlapping sets for training (60%), validation (20%), and testing (20%). Crucially, equal proportions of each animal’s neurons were maintained in each set. This architecture allowed us to seek patterns across all animals that generalize to unseen neurons from the same set of animals (<xref rid="fig1" ref-type="fig">Fig. 1A</xref> Computational Anatomy). Here, borrowed from machine-learning, we use the term <italic>transductive</italic> to describe this approach which can transfer patterns learned from neighboring neurons to unseen ones [<xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c37">37</xref>].</p>
<p>Model performance is quantified with balanced accuracy, which is the average prediction accuracy for each class (i.e., region or structure) [<xref ref-type="bibr" rid="c38">38</xref>]. Error is <italic>±</italic> SEM, and chance is 1/number of classes. To clearly indicate how models make errors between classes, we use confusion matrices— square heat maps where rows indicate true class labels and columns indicate predicted class labels. Note that diagonal entries represent the portion of units whose region/structure was correctly predicted. Entries off the diagonal display instances of the model’s “confusion”. An effective model will comprise a high balanced accuracy and show strong diagonal structure in the corresponding confusion matrix.</p>
<p>We first passed standard measures of neuronal activity to a simple model. Specifically, we trained logistic regressions to predict a unit’s region/structure from 14 statistical measures that comprised three categories: 1) standard statistics, such as mean or maximum firing rate, 2) measures of local variance, such as CV2, a temporally-constrained alternative to the coefficient of variation (CV) [<xref ref-type="bibr" rid="c39">39</xref>], and 3) spectral power, such as the delta band (0.1-4 Hz). Models were trained and tested in each of four prediction tasks: 1) brain regions, 2) hippocampal structures, 3) thalamic structures, and 4) visuocortical structures (<xref rid="fig2" ref-type="fig">Fig. 2A-D</xref>). In each of these tasks, we evaluated the effectiveness of the 14 features individually as well as in combination to predict the anatomical localization of individual neurons (<xref rid="fig2" ref-type="fig">Fig.2</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>A linear classifier can learn to predict single neuron location based on standard spiking metrics.</title>
<p><bold>A-D.</bold>, Balanced accuracy of logistic regression models trained to predict the anatomical location of single units based on each of 14 individual spiking metrics: Coefficient of Variation 2 (CV2), Local Variation (LV), Revised Local Variation (LVR), Mean Firing Rate (FR), Standard Deviation (Std Dev) of interspike intervals (ISIs), Coefficient of Variation (CV), Minimum ISI (Min ISI), Median ISI (Med ISI), Maximum ISI (Max ISI), power spectral density (PSD)-<italic>δ</italic> (Delta Band 0.1-4 Hz), PSD-<italic>θ</italic> (Theta Band 4-8 Hz), PSD-<italic>α</italic> (Alpha Band 8-12 Hz), PSD-<italic>β</italic> (Beta Band 12-40 Hz), PSD-<italic>γ</italic> (Gamma Band 40-100 Hz). Balanced accuracy expected by chance varies by task and is indicated by the dashed red line. Features on the x-axis are ordered by performance. Feature (bar) colors are assigned by the ordering in A (brain region task) and maintained for the structure tasks (B-D). This shows the extent to which individual features maintain their relative importance across tasks. <bold>E-H.</bold>, Confusion matrices from logistic regression models trained to predict unit location from the combination of all 14 spiking metrics. Each confusion matrix shows the average of 5 train/test splits of the data. The proportion is printed only in cells where proportion was greater than chance level (1/number of classes). Balanced accuracy for each task: Brain Regions = 52.91 <italic>±</italic>1.24; Hippocampal Structures = 44.10 <italic>±</italic>1.99; Thalamic Structures = 37.14 <italic>±</italic>2.57; Visuocortical Structures = 24.09 <italic>±</italic>1.46 (error is the SEM across 5 splits).</p></caption>
<graphic xlink:href="603152v3_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In all four tasks, the majority of individual spiking metrics supported weak but above-chance classification (<xref rid="fig2" ref-type="fig">Fig. 2A-D</xref>). In contrast to brain regions and hippocampal structures, the ability of the 14 metrics to reliably indicate different visuocortical structures was notably low. Ordered by their classification performance (<xref rid="fig2" ref-type="fig">Fig. 2A-D</xref>, x-axes), the arrangement of spiking metrics was highly task dependent. We examined the correlation of metric ordering— the order of classification effectiveness for the spiking metrics, from greatest to least— between the region task and the three structure tasks. We found a range of correlation from 0.03 to 0.73 (Spearman Rank Correlations-regions/VC: <italic>p</italic> = 0.0336, regions/TH: <italic>p</italic> = 0.0814, regions/HC: <italic>p</italic> = 0.7253), suggesting that the characteristics of the spike train that best discriminate regions are in some cases distinct from the characteristics used to discriminate structure. In combination, the 14 metrics substantially increased the overall balanced accuracy for each of the four tasks, although the visuocortical task remained challenging (<xref rid="fig2" ref-type="fig">Fig. 2E-H</xref>; Brain Regions Balanced Accuracy = 52.91 <italic>±</italic>1.24; Hippocampal Structures = 44.10 <italic>±</italic>1.99; Thalamic Structures = 37.14 <italic>±</italic>2.57; Visuocortical Structures = 24.09 <italic>±</italic>1.46). Perhaps unsurprisingly, classification of regions was more effective than the structures within them. Taken together, these results demonstrate an intermediate divisibility of regions and structures by logistic regression based on spiking metrics. Given that spiking metrics were predetermined and that logistic regression can only learn linearly discriminable features, it is possible that more robust anatomical information could emerge from the spike train with more complex learned representations.</p>
</sec>
<sec id="s2d">
<title>Flexible, non-linear embedding of anatomical information in neuronal spiking</title>
<p>The 14 spiking metrics were selected based on prior literature [<xref ref-type="bibr" rid="c15">15</xref>]. However, spike timing can vary along an enormous number of axes, many of which are not indicated by preselected features. To test the possibility that non-parametric, data-driven representations of a neuron’s spiking might contain additional, valuable information regarding anatomy, we considered the full collection of each neuron’s interspike intervals (ISIs), i.e., the time between two consecutive spikes. Prior work suggests the increased complexity of the ISI distribution is best captured by a nonlinear classification model [<xref ref-type="bibr" rid="c15">15</xref>]. Thus, we employed a multilayer perceptron (MLP). MLPs are relatively simple class of feedforward artificial neural network. Briefly, an MLP consists of an input layer, one or more hidden layers, and an output layer. Each layer is composed of interconnected nodes (artificial neurons) that process and transmit information via weighted connections and nonlinear activation functions. This enables MLPs to learn and model complex relationships between input features and output targets.</p>
<p>Broadly, MLPs were more successful in extracting anatomical information from spike trains than logistic regressions trained on spiking metrics (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>). Specifically, MLPs were trained transductively (which enables transfer of patterns learned from neurons to unseen neighbors) on each of three arrangements of spike times: 1) the entire distribution of ISIs generated during the presentation of drifting gratings (0-3 sec in 100 uniform bins), 2) each neuron’s average PSTH across all stimuli—essentially describing a cell’s mean response to stimuli, and 3) the concatenated mean PSTHs for each of the 40 combinations of drifting grating orientation and frequency. Across all four classification tasks (brain regions and three sets of structures), MLPs trained on the ISI distribution and concatenated PSTHs outperformed logistic regression models. Conversely, MLPs trained on the average PSTH (averaged across all drifting gratings without respect to orientation or frequency) exhibited reduced balanced accuracy (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). Together, these data suggest that the embedding of anatomical information in a neuron’s activity is recoverable when some form of precise information about spike time is available, and that anatomical information is degraded by averaging.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Anatomical information in spike trains is captured by nonlinear models that learn patterns in ISIs and stimulus-specific responses.</title>
<p><bold>A.</bold> Average balanced accuracy of transductive multi-layer perceptrons (MLPs) in classifying unit location in each task (rows) based on three representations of the spike train (columns). Chance is red, and peak balanced accuracy is blue. ISI dist—full distribution of ISIs; Avg PSTH—mean peristimulus time histogram across all trials; Cat PSTH—concatenation of PSTHs from all 40 stimuli (see methods). <bold>B.</bold> MLP sensitivity as a function of test data duration. Model was trained normally and tested on varying amounts of data from each of the four brain regions. <bold>C.</bold> Feature importance from models that classified anatomy based on ISI dist. Features are ISI ranges between 0 and 3 s in 10 msec bins. 5 splits and 100 iterations. Error is <italic>±</italic>1 SEM across 100 shuffles. High value ranges for each region are highlighted. <bold>D.</bold> Illustration of ISI mean, slope, and variance. <bold>E.</bold> Regional distributions of mean, slope, and variance within the highlighted range (in C) compared to averages from all other regions within that range (gray). Multiple comparisons corrected t-tests: <italic>p &gt;</italic>= 0.05, *: <italic>p &lt;</italic> 0.05, **: <italic>p &lt;</italic> 0.01, ***: <italic>p &lt;</italic> 0.001). <bold>F.</bold> Visuocortical structure information is enriched in subsets of stimuli. Each rectangle represents one of the 40 stimulus parameter combinations. Colors correspond to visuocortical structures, and the area of color shows the relative importance of that stimulus to model classification of the given structure. Cat PSTH model. Dashed boxes—exemplar stimulus conditions. <bold>G.</bold> PSTHs corresponding to structure/stimulus pair indicated in F. Specific structure PSTH shown in color. Average PSTH of all other structures shown in gray.</p></caption>
<graphic xlink:href="603152v3_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Due to their reliance on hidden layers, MLPs are prone to the black-box effect; deep models often offer limited insight into the underlying mechanisms of their performance. To elucidate the features of ISI distributions and PSTHs that MLPs use to infer a neuron’s anatomical location, we strategically manipulated three features of our data: 1) we varied input duration, 2) we permuted specific bands of the ISI distribution, and 3) we permuted neuronal responses to specific drifting grating orientation/frequency combinations.</p>
<p>We passed progressively reduced lengths of input data, ranging from 1,800 seconds down to 0.1 seconds, into the fully trained model and evaluated its sensitivity (true positive rate). This approach allowed us to assess the timescale of the anatomically informative patterns learned by the MLP. If short intervals of data reliably indicated anatomy, it would suggest that models learn to detect acute and reliable signatures. Conversely, if model sensitivity increased monotonically with time, it would indicate that anatomical information is temporally distributed and cumulative. Our manipulation of the test set duration robustly supported the latter hypothesis; sensitivity for all four brain regions increased as input data duration increased. In all conditions, the slope of the input duration versus sensitivity line was still positive at 1,800 seconds (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>).</p>
<p>ISIs vary extensively, from the biophysical minimum of the absolute refractory period to many seconds of silence. To test whether anatomical information might be enriched in specific temporal ISI windows, we assembled each neuron’s entire ISI distribution (0 - 3 s in 10 ms bins) and selectively permuted subsets of intervals before passing the distribution to the trained MLP for classification. We shuffled ISI counts across neurons within specific temporal windows (e.g., ISIs between 50 and 60 ms). This approach tested whether the MLP’s performance depended on viewing the entire ISI distribution or was enriched in a subset of patterns. Consistent with temporal tuning, certain subsets of ISIs were more important than others for MLP performance, with the critical time windows varying by brain region (<xref rid="fig3" ref-type="fig">Fig. 3C</xref>). For instance, very fast ISIs (<italic>&lt;∼</italic> 150 ms) were particularly valuable for identifying midbrain neurons, while ISIs of 200 - 600 ms made an outsized contribution to visual cortical classification.</p>
<p>To gain insight into how regional information could be enriched within these ISI ranges, we examined ISI distribution properties within each identified range, contrasting the region preferentially embedded in that range with all others. Across every region and range, there were subtle but statistically significant differences in the mean, variance, and slope of distributions (<xref rid="fig3" ref-type="fig">Fig. 3D,E</xref>). This suggests the presence of coarse features in regionally-relevant spiking patterns but does not rule out the contribution of a combination of multiple ISI ranges for reliable embedding.</p>
<p>Brain region, the coarsest anatomical classification task, was most effectively extracted from broad ISI distributions (65.29% Balanced Accuracy vs. 59.15% concatenated PSTH vs. 52.91% in spike metrics-based logistic regression, chance = 25%; <xref rid="fig3" ref-type="fig">Fig. 3A</xref>). In contrast, the discriminability of smaller and more numerous structures was greatest when MLPs were trained on detailed spike timing information (i.e., concatenated PSTHs; <xref rid="fig3" ref-type="fig">Fig. 3A</xref>, <xref rid="figs2" ref-type="fig">S2</xref>). Somewhat intuitively, the most robust embedding of visual cortical structures was obtained in conjunction with visual stimulus information (38.35% Balanced Accuracy vs. 25.84% ISI distribution vs. 24.09% in spike metrics-based logistic regression, chance = 17%; <xref rid="fig3" ref-type="fig">Fig. 3A</xref>, <xref rid="figs2" ref-type="fig">S2</xref>).</p>
<p>We next asked whether structure information might be conveyed by differing responses to specific stimuli. Analogous to our methods for ISIs, we shuffled the values of particular PSTHs (with specified orientation and frequency) across neurons prior to passing PSTHs to the trained MLP for structure classification. We found that information about each of the visuocortical structures was embedded in the response to multiple stimulus variants. In other words, the MLP learning of visuocortical structure was not characterised by responses to a single set of stimulus parameters (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>). However, despite the distributed nature of structure information, some stimuli carried more predictive value than others (<xref rid="fig3" ref-type="fig">Fig. 3G</xref>). Interestingly, despite PSTHs being defined by the presentation of visual stimuli, similar improvements were observed in hippocampal and thalamic structure tasks (Hippocampal structures: 44.16% Balanced Accuracy vs. 41.72% ISI distribution vs. 44.10% in spike metrics-based logistic regression, chance = 20%; Thalamic structures: 43.25% Balanced Accuracy vs. 39.15% ISI distribution vs. 37.14% in spike metrics-based logistic regression, chance = 14%; <xref rid="fig3" ref-type="fig">Fig. 3A</xref>, <xref rid="figs2" ref-type="fig">Fig.S2</xref>). This finding is noteworthy because, with the exception of the LGN, none of the constituent structures are primarily associated with visual processing.</p>
</sec>
<sec id="s2e">
<title>Anatomical codes generalize across animals and conditions</title>
<p>Our results demonstrate that anatomical information is embedded in the spike trains of single neurons. However, thus far, our results employ transductive models (which can learn patterns for unseen neurons from their immediate neighbors in the same animal). This raises the possibility that MLPs learned to identify animal-specific spiking patterns that do not generalize across individuals. As an example, if hippocampal neurons from animal <italic>n</italic> happen to be characterized by a specific rhythm, it is reasonable to assume that their neighbors, who happen to be withheld for the test set, exhibit similar activity. Transductive models are agnostic to whether such a pattern is anatomically meaningful and simply a one-off correlation that happens to be localized. To disambiguate these possibilities, we adopted an inductive approach in which the train- and test-sets are divided at the level of the entire animal. In other words, patterns are learned in one set of animals, and tested on another group of animals that is entirely new to the model (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>).</p>
<p>We trained and tested inductive models on the four classification tasks— brain regions, hippocampal structures, thalamic structures, and visuocortical structures– across two input conditions, general ISI distributions and concatenated PSTHs. The null hypothesis is that anatomical information generalizes within the animal but not to new animals. In support of the alternate—that anatomical embedding is a universal feature in the spike train–inductive models performed significantly above chance in seven out of eight conditions, and were statistically indistinguishable from the performance of transductive models for all four ISI-based tasks. In the four concatenated PSTH tasks, inductive models exhibited significantly lower balanced accuracy than transductive models, although they were still above chance in all but the hippocampal structures task (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>). These results suggest that stimulus dependent representations of anatomical location are predominately specific to the animal, while ISI distribution-based anatomical information is general across animals.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Spike time features that predict anatomy generalize across animals.</title>
<p><bold>A.</bold> Balanced accuracy (<italic>±</italic> SE) of multi layer perceptrons (MLPs) trained on ISI distributions and concatenated PSTHs in both inductive (withhold entire animals for testing) and transductive splits. Chance (red dashed line) varies by task. Linear mixed effects regression (ns/not significant: <italic>p &gt;</italic>= 0.05, *: <italic>p &lt;</italic> 0.05, **: <italic>p &lt;</italic> 0.01, ***: <italic>p &lt;</italic> 0.001). <bold>B.</bold> Left: Illustration of an example implanted silicon array spanning isocortex, hippocampus, and thalamus. Right: Brain region probability for the example implant shown on the left calculated by smoothing across neuron-based classifications. Colored background shows the consensus prediction as a function of neuron location (electrode number). <bold>C.</bold> Confusion matrix resulting from hierarchical (region then structure) inductive classification with smoothing. Matrix cells with proportion less than chance (1/number of classes) contain no text. Average balanced accuracy after smoothing (by task): Brain Regions = 89.47 <italic>±</italic> 2.98%; Hippocampal Structures = 51.01 <italic>±</italic> 4.50%; Thalamic Structures = 53.21 <italic>±</italic> 7.59%; Visuocortical Structures = 38.48 <italic>±</italic> 3.31% (error is the SEM across 5 splits). Overall balanced accuracy: 46.91<italic>±</italic> 1.90%.</p></caption>
<graphic xlink:href="603152v3_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2f">
<title>Single neuron classification errors can be corrected by population context</title>
<p>While the ISI-based inductive models demonstrate that generalizable anatomical information is carried in single unit spike trains, classification is imperfect. Note that the model classifies individual neurons via a winner-take-all approach. Even for correctly labeled neurons, the probability for the chosen class only needs to narrowly exceed the probability of other options. We next asked to what extent such uncertainty could be mitigated if the consensus was taken across a group of neurons, analogous to how the brain processes noisy information [<xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c41">41</xref>, <xref ref-type="bibr" rid="c42">42</xref>]. One possibility is that uncertainty is driven by shared noise amongst neighboring cells. Errors of this form could be amplified by a consensus vote. Alternatively, if incorrect classifications are stochastically distributed across a recording array, errors should be trivially correctable by considering the surrounding ensemble—a stray CA1 neuron should not be detected in the middle of CA3, for example. To test this, we added a second step following single unit classification. This step comprised the use of a Gaussian kernel to smooth anatomical probabilities across neurons recorded on neighboring electrodes.</p>
<p>In support of the stochastic error hypothesis, smoothing dramatically increased the balanced accuracy of MLPs in all four tasks. The brain region identification task improved from 65.10 <italic>±</italic> 1.77% to 89.47 <italic>±</italic> 2.98% compared to non-smoothed inductive models. The smoothed regional prediction probabilities across an individual probe from an example animal is shown in <xref rid="fig4" ref-type="fig">Fig. 4B</xref>. Similarly, the hippocampal task improved from 35.89 <italic>±</italic> 1.42% to 51.01 <italic>±</italic> 4.50%, the thalamic task improved from 32.79 <italic>±</italic> 2.37% to 53.21 <italic>±</italic> 7.59%, and the visuocortical task improved from 25.52 <italic>±</italic> 0.73% to 38.48 <italic>±</italic> 3.31% (<xref rid="figs5" ref-type="fig">Fig. S5</xref>, <xref rid="figs6" ref-type="fig">S6</xref>). This suggests that erroneously labeled neurons do not share anatomically-relevant spike patterns with nearby cells, and thus are amenable to consensus-based correction.</p>
<p>To this point, MLPs were trained and tested only on neurons related to an individual task. For example, MLPs trained on visuocortical structures were never exposed to thalamic neurons. To evaluate inductive models across the full set of regional and structural comparisons while capitalizing on smoothing of errors, we trained a hierarchical model that combined smoothed brain region classification with subsequent smoothed structure identification. Across all 19 labels (18 structures and midbrain), the hierarchical inductive model achieved a balanced accuracy of 46.91 <italic>±</italic> 1.90% (<xref rid="fig4" ref-type="fig">Fig. 4C</xref>). An observable effect of a hierarchical approach is that, because smoothed brain region classification is so effective, errors generally occur only between similar structures (VISl vs. VISal) rather than highly divergent ones (VISl vs. CA1). Here, only 5 out of the total 250 possible cross-regional errors occurred above chance (<xref rid="fig4" ref-type="fig">Fig. 4C</xref>). These data demonstrate that, with smoothing, a hierarchical model can extract surprisingly effective anatomical structure information from single neuron spike timing that generalizes to unseen animals. This further suggests that there is a latent neural code for anatomical location embedded within the spike train, a feature that could be practically applied to determining the brain region of a recording electrode without the need for post-hoc histology.</p>
</sec>
<sec id="s2g">
<title>Spike train embedding of visual superstructure and cortical layer</title>
<p>Even with smoothing, visuocortical structures remained the most challenging to classify. There are two possible explanations for this. First, it may be that there are truly no consistent differences in the organization of single unit spiking across visuocortical structures. Alternatively, there are true differences but our MLP-based approach fails to learn them. Although there are clear cytoarchitectural boundaries between primary visual cortex (VISp) and secondary visual areas, the differentiation of secondary visual areas is functionally determined [<xref ref-type="bibr" rid="c43">43</xref>, <xref ref-type="bibr" rid="c44">44</xref>]. We asked whether broadly defined superstructures, VISp and VISs—a combination of all secondary areas (VISal, VISam, VISl, VISpm, and VISrl)–increases the effectiveness of spike time-based classification (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>). We trained an MLP on VISp versus VISs, and, in this binarized context, observed a balanced accuracy of 79.98 <italic>±</italic>3.03 % (<xref rid="fig5" ref-type="fig">Fig. 5B</xref>). This effect which was driven by VISs, which achieved 96 % sensitivity. To understand if converting six visual structures into two superstructures truly improved discriminability, it is necessary to make the equivalent comparison in the more complex model. To achieve this, we simply took the results of the visuocortical task across 6 structures (<xref rid="figs6" ref-type="fig">Fig. S6</xref>, bottom left) and collapsed the secondary regions into a single class. Intriguingly, this yielded a balanced accuracy of 91.02 <italic>±</italic>0.95%, driven by VISp at 94.4 % sensitivity. A likely explanation is that, despite using resampling strategies to correct for class imbalance, VISp initially has more true units than any other structure in the 6-class task, incentivizing accurate classification of it. In contrast, for the binary classification, VISp has fewer units than all secondary structures combined (VISs), which instead incentivises classification of VISs. It seems VISp is a more effective classification target for this problem. These results support the notion the meaningful computational division in murine visuocortical regions is at the level of VISp versus secondary areas.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Primary vs secondary distinction and cortical layer are more evident in spike timing than individual structures.</title>
<p><bold>A.</bold> Illustration of visuocortical structures that can be grouped into primary versus secondary superstructures: VIS-am, -pm, -l, -al, -rl are grouped into secondary visual cortex (VISs) while VISp is primary visual cortex. <bold>B.</bold> Confusion matrix resulting from inductive classification of superstructure (with smoothing). Cells with proportion less than chance (1/number of classes) contain no text. Balanced accuracy is 79.98 <italic>±</italic>3.03% <bold>C.</bold> Left: Illustration of example array implanted across cortical layers. Right: Layer probability for the example implant shown on the left calculated by smoothing across neuron-based classifications. Colored background shows the consensus prediction as a function of neuron location (electrode number). <bold>D.</bold> Confusion matrix resulting from smoothed inductive classification of layer. Balanced accuracy is 62.59 <italic>±</italic>1.12%</p></caption>
<graphic xlink:href="603152v3_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Another major axis along which cortical neurons exhibit anatomical structure is layer. This aligns with recent evidence that indicates that cortical layers can be distinguished computationally, particularly in terms of cell types and tuning preferences [<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c46">46</xref>]. Thus, we hypothesized that cortical layer might be more reliably embedded in single unit spike times than visuocortical structure. Consistent with this, models trained on visuocortical neurons from all structures were able to robustly recover layer information (<xref rid="fig5" ref-type="fig">Fig. 5C,D</xref>). It is noteworthy that transductive and inductive models achieved similar balanced accuracies on both ISI distribution (inductive unsmoothed balanced accuracy: 46.43 <italic>±</italic>0.97%, inductive smoothed: 62.59 <italic>±</italic>1.13%, transductive unsmoothed: 46.52 <italic>±</italic>0.63%, transductive smoothed: 60.37 <italic>±</italic>2.64%) and concatenated PSTHs (inductive unsmoothed: 41.13 <italic>±</italic>1.28%, inductive smoothed: 52.16 <italic>±</italic>2.38%, transductive unsmoothed: 41.66 <italic>±</italic>0.51%, transductive smoothed: 52.35 <italic>±</italic>1.69%). However, cortical layer information was more robust in the broad ISI distribution, which outperformed concatenated PSTHs, even in transductive models. Also noteworthy is the fact that layer IV exhibited the greatest confusion (specifically, with adjacent layers), achieving a sensitivity of only 28%. These results suggest that general embeddings are more readily available for cortical layers than cortical structures.</p>
</sec>
<sec id="s2h">
<title>Anatomical embeddings generalize across experimental conditions</title>
<p>Drifting gratings, while widely embraced across decades of research in the visual system, are highly stereotyped and low dimensional compared to natural visual environments. As a result, the anatomical embeddings described thus far could require the repeated presentation of drifting gratings. In other words, it is reasonable to suggest that anatomical information embedded in single unit activity would be immediately obscured by a complex visual environment. To evaluate this, we trained new, inductive MLPs on single unit activity in the context of drifting gratings as well as two additional conditions: 1) the presentation of naturalistic movies (ten repeated presentations of a 120 s long excerpt from the film <italic>Touch of Evil</italic>), and 2) spontaneous activity (an unchanging gray screen) (<xref rid="fig6" ref-type="fig">Fig. 6</xref>). We then tested these MLPs on activity from all three conditions. This allowed us to ascertain a) whether anatomical information is available outside of the context of drifting gratings, and b) whether the anatomical information learned in one condition can generalize to another.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Anatomical information embedding in spike trains generalizes across diverse stimuli.</title>
<p>(Top Left) Schematic showing inductive train/test split along with visual stimuli: naturalistic movie, drifting gratings, spontaneous activity (i.e. gray screen). (Left Column) Grids showing Matthew’s Correlation Coefficient (MCC) values for pairs of training stimuli (grid rows) and testing stimuli (grid columns). Grid diagonals (top right to bottom left) represent train/test within the same stimuli. (Right Column) Confusion matrices corresponding to the each of the MCC grids in the left column.</p></caption>
<graphic xlink:href="603152v3_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We tested every pairing of train/test condition on each of 6 tasks: brain regions, hippocampal structures, thalamic structures, visuocortical structures, visuocortical layers, and visuocortical superstructures. Chance levels varied between 14.3 and 50 % across tasks. To facilitate inter-task comparisons, we quantified accuracy by employing Matthews Correlation Coefficient (MCC). MCC is a balanced measure that takes into account true and false positives and negatives, providing a reliable statistical measure especially for imbalanced datasets [<xref ref-type="bibr" rid="c47">47</xref>, <xref ref-type="bibr" rid="c48">48</xref>]. MCC values range from −1 to +1, with +1 representing perfect prediction, 0 indicating performance no better than random chance, and −1 signifying total disagreement between prediction and observation. Importantly, MCC is normalized by the number of categories, allowing for comparisons across tasks with different numbers of classes [<xref ref-type="bibr" rid="c49">49</xref>].</p>
<p>MLPs across almost every task and every pairing of train/test condition performed far above chance (MCC chance = 0) (<xref rid="fig6" ref-type="fig">Fig. 6</xref>, left column). MLPs tasked with brain region showed remarkable generalizability across stimuli (mean MCC = 0.90). This was followed by hippocampal structures (mean MCC = 0.46), visuocortical layers (mean MCC = 0.41), thalamic structures (mean MCC = 0.30), visuocortical superstructures (mean MCC = 0.26), and visuocortical structures (mean MCC = 0.18). Interestingly, the only instances of chance-level performance arose in the visuocortical superstructure task—MLPs chance (MCC = 0) when trained on drifting gratings and tested on either spontaneous activity or naturalistic movies. While this appears consistent with stimulus-specific embeddings, visuocortical MLPs trained on spontaneous activity were above chance when tested on drifting gratings. The same was true for those trained on naturalistic movies. Taken together, these data suggest that the embedding of anatomical information in single neuron activity is not abolished by complex visual stimuli or spontaneous activity, and that the embeddings learned in one context are not absent in other contexts. The visuocortical superstructure task results imply that, in some contexts, complex stimuli may produce more generalizable results than simple stimuli.</p>
<p>In each of the 54 combinations of task and train/test condition, there were diverse underlying patterns of MLP learning (<xref rid="fig6" ref-type="fig">Fig. 6</xref>, right column). Intuitively, instances with high MCC, such as those in the brain regions task, produced strong diagonal structure (where the predicted class aligns with the true class). Tasks resulting in lower MCC, such as the visuocortical structures, yielded slight diagonal structure in some cases, but were driven by a small number of accurate points. Across all six tasks, within-stimulus models (e.g., trained on spontaneous, tested on spontaneous) tended to produce significantly greater MCCs than across-stimulus models, although all were above chance (<xref rid="figs7" ref-type="fig">Fig. S7</xref>).</p>
</sec>
<sec id="s2i">
<title>Anatomical embeddings generalize across research laboratories</title>
<p>The results of inductive models trained and tested in mismatched conditions suggest that, amidst stimulus information, neuronal spike trains carry universal signatures of their anatomical location. If this were true, it should be possible to apply models trained on animals from one research group—in this case, the Allen Brain Observatory team— and decode neuronal anatomy from data generated at an independent location. In other words, the Allen-based model should predict a neuron’s anatomical location based on its spike train even if the recording was conducted in a different location and experimental context.</p>
<p>To test this, we required independently generated data that maintained two key features; 1) the spatiotemporal micro-scale resolution of the Allen Institute’s recordings, and 2) the anatomical breadth of the Allen Institute’s recordings. These criteria were satisfied by an open dataset from Steinmetz et al. [<xref ref-type="bibr" rid="c50">50</xref>], which comprise high density silicon recordings that span many of the same regions and structures examined in the Allen data. However, the Steinmetz et al. [<xref ref-type="bibr" rid="c50">50</xref>] experiments are markedly different, in that they comprise mice trained to carry out a decision making task. Summarily, the task involved observing a Gabor patch of fixed orientation (45°) and spatial frequency (0.1 cycles per degree) with varying contrast on either the left or right side, in response to which the mouse must turn a wheel toward the side with higher contrast[<xref ref-type="bibr" rid="c50">50</xref>]. Recall that the Allen data were recorded in the context of passive viewing (<xref rid="fig7" ref-type="fig">Fig. 7A</xref>).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7:</label>
<caption><title>Anatomical information embedded in spike trains generalizes across laboratories and protocols.</title>
<p><bold>A.</bold> Illustration of behavioral tasks employed by two laboratories: (left) Passive Viewing (Allen Institute) vs. (right) Active Decision-Making (Steinmetz et al.). In Active Decision-Making, the mouse spins a wheel in response to the location of the drifting grating presented on the screen. <bold>B.</bold> Bubble chart showing balanced accuracy of individual test set animals from the Steinmetz et al. The model was trained on Allen Institute data. Bubble size indicates the number of units recorded in the test animal. Black horizontal lines represent the median of the balanced accuracy distributions across the animals. Models are trained with either drifting gratings alone (purple) or a combination of drifting gratings, natural movies, and spontaneous/gray screen (green). Balanced accuracy across all Steinmetz et al. neurons: BR DG=80.46%, BR Mix: 81.28 %, HS DG: 40.07 %, HS Mix: 69.89 %, TS DG: 21.52 %, TS Mix: 58.22 %, VCS DG: 28.41 %, VCS Mix: 28.34 %, VCSS DG: 58 %, VCSS Mix: 59 %, VC Layers DG: 46.36 %, VC Layers Mix: 49.01 % where BR stands for brain regions, HS hippocampal structures, TS thalamic structures, VCS visual cortex structures, VCSS visual cortex superstructures, DG drifting gratings and Mix denotes the combined stimuli. <bold>C.</bold> Confusion matrices for prediction of hippocampal structures in Steinmetz et al. test set when trained on drifting gratings stimulus (left) vs. mixed stimuli (right) from the Allen Institute. <bold>D.</bold> Confusion matrices for prediction of thalamic structures in Steinmetz et al. test set when trained on drifting gratings stimulus (left) vs. mixed stimuli (right) from the Allen Institute.</p></caption>
<graphic xlink:href="603152v3_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We classified anatomy in Steinmetz et al. [<xref ref-type="bibr" rid="c50">50</xref>] data using two variants of our Allen-based models; one trained on ISI distributions recorded during the presentation of drifting gratings, and one trained on ISI distributions recorded in three conditions (drifting gratings, naturalistic movies, and spontaneous activity). Both models successfully predicted brain region above chance in every Steinmetz et al. animal (N = 10), with the exception of one animal in the drifting gratings model (mean balanced accuracy calculated across neurons, drifting gratings model—80.46%; combined stimuli—81.28%; <xref rid="fig7" ref-type="fig">Fig. 7B</xref>). At the level of structures, two general principles emerged: 1) models trained on combined stimuli were generally more effective than drifting gratings models— this is particularly evident when examining diagonal structure in the confusion matrices (<xref rid="fig7" ref-type="fig">Fig. 7B,C</xref>, <xref rid="figs8" ref-type="fig">S8</xref>), and 2) the visuocortical structures task did not transfer effectively between laboratories (drifting gratings model—28.41%, mixed model—28.34%). Hippocampal and thalamic structures as well as visuocortical layers were identifiable well above chance, especially in mixed models (drifting gratings/mixed models: hippocampal structures—40.07 / 69.89%; thalamic structures—21.52 / 58.22%; visuocortical layers—46.36 / 49.01%). Visuocortical superstructures were marginally identified, but only in the combined stimuli model (drifting gratings model—58.03%, mixed model—59.08%), as only one animal was above chance in the drifting gratings condition (<xref rid="fig7" ref-type="fig">Fig. 7B</xref>). Note that, due to differences in the recordings and number of units from the structures, each Steinmetz et al. task involved 4 classes, such that chance is 25 % with the exception of visuocortical structures (<italic>k</italic> = 5, chance = 20%) and visuocortical superstructures (<italic>k</italic> = 2, chance = 50%). Finally, error is not reported as there are no splits to test across in the Steinmetz et al. data; balanced accuracy is reported for the entire applicable dataset.</p>
<p>Taken together, these data suggest that information about a neuron’s anatomical location can be extracted from the time series of its spiking. This principle appears to apply to neurons from diverse structures across the telencephalon, diencephalon, and mesencephalon. Further, some of the rules by which this information is organized are shared across animals, and are not an artifact of a task or local protocol.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Understanding the information carried within a neuron’s spiking has been the subject of investigation for a century [<xref ref-type="bibr" rid="c1">1</xref>]. While it is well established that neuronal activity encodes stimuli, behavior, and cognitive processes [<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c5">5</xref>], the possibility that spike trains might also carry information about a neuron’s own anatomical identity has remained largely unexplored. Our study provides compelling evidence that such anatomical information is indeed embedded within neuronal spike patterns. Using machine learning approaches, we demonstrate that this embedding is robust across multiple spatial scales, from broad brain regions to specific structures and cortical layers. Crucially, these anatomical signatures generalize across animals, experimental conditions, and even research laboratories, suggesting a fundamental principle of neural organization. Our findings reveal a previously unrecognized dimension of the neural code, one that is multiplexed with the encoding of external stimuli and internal states [<xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c52">52</xref>, <xref ref-type="bibr" rid="c53">53</xref>]. These data advance an understanding of the relationship between structure and function in neural circuits, raising the possibility that structure is not ancillary to neuronal computation, but intrinsically embedded within it. Beyond fundamental scientific insight, our findings may be of benefit in various practical applications, such as the continued development of brain-machine interfaces and neuroprosthetics, as well as for the interpretation of large-scale neuronal recordings. Note, however, that a purely utilitarian goal, e.g., electrode localization in electrophysiological recordings, would be well served by considering additional features, such as extracellular waveforms [<xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c55">55</xref>], in addition to spike timing. While this approach holds promise for practical application, the inclusion of waveform information subverts the question of whether a neuron’s output—the timing of its spiking–contains an embedding of its location.</p>
<p>Clearly, there are powerful differences throughout the brain as a function of anatomy. There is extensive literature to describe this diversity at many levels, from gene expression gradients in hippocampal pyramidal neurons [<xref ref-type="bibr" rid="c35">35</xref>] to distinct connectivity patterns across cortical layers [<xref ref-type="bibr" rid="c24">24</xref>]. A complementary albeit smaller literature provides some indication that, at a coarse-grained level, similar gradients can be identified in neuronal activity. For example, examined at the level of the entire population, there are subtle but reliable differences in isocortical neuronal variability in functionally distinct cortical areas [<xref ref-type="bibr" rid="c27">27</xref>]. Similarly, considered as a population-level statistic, there is a cortical gradient of neuronal intrinsic timescale (a measure of how long a neuron’s activity remains correlated with itself over time) [<xref ref-type="bibr" rid="c21">21</xref>]. However, while the ability to detect statistical differences across a population demonstrates that anatomy bears some influence on brain activity, it does not suggest that anatomy can be extracted from a single neuron’s activity. This is exemplified by placing two observations side-by-side. First, single neuron firing rates are log-normally distributed. This means that within any given brain region, there is a wide range of firing rates, with a long tail of high-firing neurons. Second, the population-level distribution of firing rates varies slightly but significantly as a function of region [<xref ref-type="bibr" rid="c56">56</xref>, <xref ref-type="bibr" rid="c57">57</xref>]. The combination of these facts implies that while there may be detectable differences between regions at the population level, the extensive overlap in firing rate distributions makes it challenging, if not impossible, to determine a neuron’s anatomical origin based solely on its firing rate.</p>
<p>Here, we approach this problem from a fundamentally different perspective than the population-based paradigm. Capitalizing on 1) the availability of open, high density recordings across a plurality of brain regions, and 2) machine learning methods capable of learning complex, nonlinear relationships, we approach the problem at the level of single neuron classification. This approach has strengths and weaknesses. The principal strength is the revelation that anatomical information is embedded in the activity of individual neurons throughout the brain. The principal weakness is limited interpretability, a criticism widely raised when contemplating machine learning (even when addressing this issue, the ground-truth patterns can themselves be complex and non-intuitive, e.g.,<xref rid="fig3" ref-type="fig">Fig. 3</xref>). However, in exchange for simplicity, our approach is founded on establishing whether there exist spike train-based anatomical signatures that generalize across animals, experimental conditions, and research laboratories. That such signatures are readily identifiable indicates neurons are not mere conduits of stimulus-related information. While neurons can be described as ratevarying Poisson processes [<xref ref-type="bibr" rid="c7">7</xref>], it is increasingly clear that a more complete description should incorporate additional streams of information, such as transcriptomic cell type and anatomy across varying time scales [<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c58">58</xref>].</p>
<p>Our findings reveal a striking difference in the generalizability of anatomical information encoded in ISI distributions versus PSTHs. Specifically, inductive models trained on ISI distributions maintained performance levels comparable to their transductive counterparts across all tasks, while PSTH-based models showed a significant drop in performance when tested on new animals. This is perhaps surprising, given that stimulus response properties (such as receptive field size and response latency) are generally understood to exhibit some consistency across animals recorded under equivalent conditions [<xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c60">60</xref>, <xref ref-type="bibr" rid="c18">18</xref>]. Viewed through the lens of stimulus and response, PSTHs in the Allen Institute datasets are robust to slight differences in retinotopic locations across animals [<xref ref-type="bibr" rid="c18">18</xref>]. Despite this, our PSTH-based models performed poorly when trying to predict anatomical location in new animals under the same stimulus conditions. Thus, it is likely that stimulus-response information is semi-orthogonal to the embedding of anatomical location.</p>
<p>The difference in generalizability when comparing PSTH- and ISI-based models may reflect a fundamental distinction in the nature of information captured by these two representations of neural activity. ISI distributions encapsulate intrinsic properties of neuronal firing patterns that appear to be conserved across animals, potentially reflecting stable, anatomy-specific computational features. These might include cell-types and their resultant ion channel compositions [<xref ref-type="bibr" rid="c61">61</xref>, <xref ref-type="bibr" rid="c62">62</xref>], local circuit motifs [<xref ref-type="bibr" rid="c63">63</xref>, <xref ref-type="bibr" rid="c64">64</xref>], or homeostatic mechanisms that shape firing statistics independent of stimuli [<xref ref-type="bibr" rid="c65">65</xref>, <xref ref-type="bibr" rid="c66">66</xref>, <xref ref-type="bibr" rid="c67">67</xref>]. Crucially, these features are not inherently tied to a stimulus. In contrast, PSTHs involve studying the repeated presentation of the same stimulus. Despite this repetition, there is neuron and trial level variability [<xref ref-type="bibr" rid="c68">68</xref>, <xref ref-type="bibr" rid="c69">69</xref>]. Neuronal response variability to repeated stimuli often correlates among nearby neurons[<xref ref-type="bibr" rid="c70">70</xref>, <xref ref-type="bibr" rid="c71">71</xref>] and is influenced by local circuit connectivity and the animal’s cognitive factors such as attention [<xref ref-type="bibr" rid="c72">72</xref>, <xref ref-type="bibr" rid="c73">73</xref>]. Thus, transductive models may learn from variability in the training dataset that is highly informative in the test dataset. However, such variability would not carry across animals. The robustness of ISI-based anatomical embeddings across animals and even across laboratories underscores the fundamental nature of these anatomical fingerprints in neural activity, transcending individual differences and specific experimental paradigms.</p>
<p>Our analysis of visual isocortical structures offers intriguing insights into the computational organization of the murine visual system. While PSTH-based models performed well in classifying visual areas, suggesting stimulus-specific differences in neuronal responses across these regions, the overall classification accuracy remained relatively low compared to other brain areas. This finding aligns with previous studies that have demonstrated differences in orientation and spatial frequency tuning across mouse visual areas [<xref ref-type="bibr" rid="c74">74</xref>, <xref ref-type="bibr" rid="c75">75</xref>, <xref ref-type="bibr" rid="c76">76</xref>, <xref ref-type="bibr" rid="c77">77</xref>]. However, our results suggest that these differences, while statistically significant at the population level, may not translate into robust, neuron-specific computational signatures. The murky distinction between primary and secondary visual areas in mice is reflected in our data, with the most reliable discrimination occurring between primary visual cortex (VISp) and grouped secondary areas, rather than among individual secondary regions. Even this distinction, however, was not dramatic. Interestingly, we found that isocortical layers within visual areas were more readily distinguishable than the areas themselves, suggesting that laminar organization may play a more fundamental role in shaping neuronal computations than areal boundaries in mouse visual cortex. This hierarchical organization - from broad regions to superstructures (e.g., VISp vs. secondary areas) to substructures (layers) - provides a nuanced view of functional specialization in the mouse visual system. While numerous recent studies have indicated functional specialization of mouse higher visual areas beyond VISp [<xref ref-type="bibr" rid="c43">43</xref>, <xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c78">78</xref>], our data suggest that these specializations may not manifest as significant differences in single neuron spiking features across areas. This observation raises the possibility that secondary visual areas in mice may not be computationally distinct, at least in terms of their constituent neurons’ fundamental spiking patterns. The relative inability to classify the structure of visual cortical neurons may, in fact, reflect a genuine neurobiological feature: the computational properties of neurons in different visual areas may be largely indistinguishable based on spike timing alone.</p>
<p>It is reasonable to consider the possible mechanism and function of an anatomical information stream. It is not necessary that neurons explicitly impart anatomical location on the structure of spike timing. If all neurons are otherwise identical until cell type, connectivity, and stimulus are considered, then these would neatly describe the mechanism by which anatomy is imprinted in spiking. In this case, our ability to extract anatomical information from the spike train is reflective of cell type and connectivity—each important features of a neuron’s contribution to brain function. Independent of its mechanistic original, information about anatomical location, cell type, and/or connectivity in a spike train raises questions about possible utility. In other words, just because it is there, does it matter? The null hypothesis, in this case, is that anatomical information is epiphenomenal, an inevitable byproduct. However, the robustness of anatomical information across stimuli, animals, and even laboratories suggests a consistent selective pressure rather than a local consequence. Consider: recorded neurons represent a severe subsampling of the local population (<italic>&lt;</italic> 1%) [<xref ref-type="bibr" rid="c79">79</xref>]. Further, recordings are random in their local sampling, each neuron’s connectivity is unique [<xref ref-type="bibr" rid="c80">80</xref>], and vertebrate brains lack “identified neurons” characteristic of simple organisms [<xref ref-type="bibr" rid="c81">81</xref>]. Taken together, it seems unlikely that a single neuron’s happenstance imprinting of its unique connectivity should generalize across stimuli and animals. Could neurons use this information? Computational modeling demonstrates that individual neurons could learn to discriminate between complex temporal patterns of inputs [<xref ref-type="bibr" rid="c17">17</xref>]. This suggests that neurons could distinguish and selectively respond to inputs carrying different types of information, such as selectively attending to anatomically distinct inputs. The timescale of anatomical location embedding is also consistent with molecular mechanisms by which neurons integrate slow information, e.g., CaMKII [<xref ref-type="bibr" rid="c82">82</xref>].</p>
<p>While the technical barriers are daunting, the obvious experiment is to manipulate a neuron’s anatomical embedding while leaving stimulus information intact. Should this disrupt any aspect of sensation, perception, cognition, or behavior, the answer would be clear. If not, there is still great practical utility in an experimenter’s capacity to ascertain anatomy based on neuronal activity.</p>
<p>Our findings demonstrate that individual neurons embed information about their anatomical location in their spike patterns, with these anatomical embeddings conserved across animals and experimental conditions. This previously unrecognized aspect of neural coding raises questions about the relationship between brain structure and function at the single-neuron level. Future research will be crucial in determining whether and how different streams of information, including these anatomical embeddings, contribute to neural computation and the variegated functions of the brain.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Datasets</title>
<p>Neurodata Without Borders (NWB) files for the Allen Institute’s Visual Coding Neuropixels dataset were retrieved with AllenSDK [<xref ref-type="bibr" rid="c83">83</xref>]. Units passing the default filtering criteria of ISI violations <italic>&lt;</italic> 0.5, amplitude cutoff <italic>&lt;</italic> 0.1, and presence ratio <italic>&gt;</italic> 0.9 were selected for further analysis. Units with a firing rate below 0.1 Hz over the session were excluded.</p>
<p>Mice were head fixed and presented with visual stimuli for a roughly three-hour session [<xref ref-type="bibr" rid="c18">18</xref>]. The mice were shown one of the two slightly different visual stimulus sets:“Brain Observatory 1.1” (<italic>N</italic> = 32 animals) or “Functional Connectivity” (<italic>N</italic> = 28 animals) [<xref ref-type="bibr" rid="c84">84</xref>, <xref ref-type="bibr" rid="c85">85</xref>]. From these sessions, we retrieved spike times coincident with the presentation of drifting gratings and natural movie three from “Brain Observatory 1.1” and gray screen (spontaneous) from both sets. For each animal, 30 minutes of drifting gratings were presented. Each trial consisted of one second of gray screen followed by two seconds of drifting gratings. Gratings were varied in spatial orientation (0°, 45°, 90°, 135°, 180°, 225°, 270°, 315°) and temporal frequency (1, 2, 4, 8, and 15 Hz), but consistent in spatial frequency (0.04 cycles/degree) and contrast (80%) with 15 equivalent presentations of each particular stimulus. Separately, a sustained mean-luminance blank (gray) screen was presented during intervals between blocks of stimuli. In total, gray screen was presented in this manner for approximately 20 minutes to each animal. Natural movie three consisted of a 120-second clip from the opening scene of the movie <underline>Touch of Evil</underline> repeated 10 times. After passing through the criteria above, there were 18,961 units for drifting gratings and natural movie three (visual cortex = 9,402, hippocampus = 4,301, thalamus = 4,068, and midbrain= 920) while the spontaneous stimulus contains 37,458 units (visual cortex = 18,514, hippocampus = 10,337, thalamus = 6,625, and midbrain = 1,982). In order to have at least 30 units in the test for each split, we removed classes (regions or structures) from the dataset if they contained less than 150 units. We also removed units with ambiguous structure assignment such as ‘VIS’ or ‘TH’. The final number of units in each structure (for drifting gratings and natural movie three) is as summarized in <xref rid="tbl1" ref-type="table">Table 1</xref>. The spontaneous (blank screen) stimulus has more units from the “Functional Connectivity” dataset in addition to the units from the “Brain Observatory.”</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Number of included single units as a function of brain structure: Allen Institute data</title></caption>
<graphic xlink:href="603152v3_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>The dataset provides labels for each unit’s brain structure as ecephys structure acronym, determined through a combination of stereotactic targeting, histology, common coordinate framework (CCF) mapping, and intrinsic signal imaging (particularly for visual cortical areas) [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c85">85</xref>]. For our larger brain region prediction tasks, we grouped the provided brain structures into a higher hierarchy based on the Allen Brain Atlas ontology’s structure tree [<xref ref-type="bibr" rid="c86">86</xref>]. However, the publicly available units’ metadata does not include layer information. To address this for cortical units, we mapped the CCF coordinates of each unit onto a finer-grained parcellation (25 <italic>µ</italic>m) level within the ontology, enabling the extraction of layer labels. There were 1,229 units, 1,601 units, 3,046 units, and 1,057 units in layer 2, 4, 5, and 6 respectively for drifting gratings and natural movie three.</p>
<p>To generalize across experimental conditions, we used a dataset from Steinmetz et al. [<xref ref-type="bibr" rid="c50">50</xref>], which generally inspired the experiments used in the International Brain Laboratory (IBL) datasets. The mice were shown drifting gratings (oriented at 45<italic><sup>◦</sup></italic> and spatial frequency of 0.1 cycles per degree) of varying contrast. The tasks were divided into an average of four second trials and involved presentation of auditory cue, wheel turning and reward presentation with inter-trial intervals of gray screen [<xref ref-type="bibr" rid="c50">50</xref>]. The experimental sessions also involved passive stimulus presentation after the behavioral sessions [<xref ref-type="bibr" rid="c50">50</xref>]. We did not restrict our analysis to any interval, but used all the available spikes in the experiments. The data is collected from 10 mice and 39 sessions with each session potentially resulting in different units from the same mice. The units (or clusters) have structure labels or anatomical locations which was determined by combining electrophysiological features, histology and CCF mapping [<xref ref-type="bibr" rid="c50">50</xref>]. To extract layer information, we used the same method as with the Allen Institute’s dataset: mapping the CCF coordinates to higher resolution parcellation using the Allen CCF reference space. We observed that some brain structure labels provided in the dataset did not match the coordinate mappings, possibly due to manual adjustments. Since accurate layer extraction required the provided structures to overlap with the CCF-mapped structures, we decided to use only those units where the labels matched. In addition, we removed the structures that were not in the training set, i.e., structures not found in our final Allen dataset. This resulted in 8,219 units with the number of units units in each structure as summarized in <xref rid="tbl2" ref-type="table">Table 2</xref>.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><title>Number of included single units as a function of brain structure: Steinmetz et al. data</title></caption>
<graphic xlink:href="603152v3_tbl2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s4b">
<title>Unsupervised Analysis</title>
<p>Unsupervised dimensionality reductions across spiking features utilized python implementations of principal component analysis (PCA) [<xref ref-type="bibr" rid="c87">87</xref>], t-distributed Stochastic Neighbor Embedding (TSNE) [<xref ref-type="bibr" rid="c87">87</xref>], and Uniform Manifold Approximation and Projection (UMAP) [<xref ref-type="bibr" rid="c33">33</xref>]. Features to be dimensionally reduced were either a collection of established spiking metrics [<xref ref-type="bibr" rid="c15">15</xref>] (see Logistic Regression section for more details), ISI distributions (100 uniform bins between 0 and 3 s; see Multi-Layer Perceptron section), and averaged PSTHs (100 uniform bins over the 3 second span of a trial; see Multi-Layer Perceptron section) for each stimulus condition grouped/concatenated together.</p>
<p>To appropriately tune the hyperparameters of t-SNE and UMAP, we performed a grid search over a broad range of values and selected the hyperparameter combination which maximized the separability of region/structures for a task. Specifically, we selected parameters which yielded optimal training balanced accuracy (no units held out) of a logistic regression classifier on the primary two dimensions of the reduced space.</p>
<p>To evaluate the significance of region/structure separation in these spaces we compared these optimal balanced accuracies with the balanced accuracies obtained after 1,000 random shuffling of the region/structure labels prior to training the logistic regression. We sought to evaluate whether the relationship (relative distances) between regions/structures was preserved between classes across feature sets and dimensionality reduction methods. First, we created histograms of the distribution of scores along the primary axis of the dimensionality reduction for each region/structure. For each pair of regions/structures we calculated the Wasserstein distance between their histograms. We plotted the results as triangular distance matrices to show that these relationships are largely unconserved across feature sets and dimensionality reduction methods.</p>
</sec>
<sec id="s4c">
<title>Dataset Splitting</title>
<p>To properly optimize our supervised models while ensuring generalizability to unseen data we performed a standard split into train, validation, and test sets (with an approximate 60/20/20 ratio with respect to the number of neurons). To ensure the full dataset was evaluated, we extracted five stratified samples such that each unit was included in the validation set in one of these splits, and separately included in the test set in another split. This is intuitively similar to a 5-fold cross validation.</p>
<p>In a transductive split, for each animal, 60% of the neurons were allocated to train, 20% of the neurons were in the validation set, and 20% were allocated to the test set. We sought to ensure classes (i.e. regions/structures) were represented appropriately in each set. If 20% of the dataset was class A, we attempted to stratify our sets such that <italic>∼</italic>20% of the train set was class A, <italic>∼</italic>20% of the validation set was class A, and <italic>∼</italic>20% of the test set was class A.</p>
<p>In an inductive split, all neurons from 60% of the animals were allocated to train, all neurons from 20% of the animals were allocated to validation, and all neurons from 20% of the animals were allocated to the test set.</p>
<p>For the generalization across experimental conditions, 80% of the Allen units were allocated to a training set, while 20% were used as validation set. All of the Steinmetz et al. units in the final dataset were used as test set.</p>
</sec>
<sec id="s4d">
<title>Logistic Regression</title>
<p>Summary statistics based on spike times during drifting gratings presentation were obtained and used as features for a logistic regression implemented in scikit-learn [<xref ref-type="bibr" rid="c87">87</xref>]. This workflow largely follows our prior work [<xref ref-type="bibr" rid="c15">15</xref>]. The logistic regression used L2-regularization and 1E-4 tolerance stopping criterion. When possible, interspike intervals were used to compute these statistics instead of binned spike counts. The following standard statistics were computed: mean firing rate, standard deviation of ISI, median ISI, maximum ISI, minimum ISI, coefficient of variation. Oscillatory activity of the spike train was captured using the power spectral density (PSD) from a periodogram using scipy.signal [<xref ref-type="bibr" rid="c88">88</xref>]. The mean value was calculated within each of the following bands (<italic>&lt;</italic> 4 Hz, 4-8 Hz, 8-12 Hz, 12-40 Hz, 40-100 Hz) and the ratio of each band’s power to the power across all bands <italic>&lt;</italic> 100 Hz was used as a feature. Local variability in the spike train was captured through the CV2, LV, and LVR statistics (as implemented in Elephant) [<xref ref-type="bibr" rid="c89">89</xref>]. These statistics were used first individually, and second aggregated to predict each class (structure/region) for a task.</p>
</sec>
<sec id="s4e">
<title>Multi-layer Perceptron</title>
<p>For each task, an MLP was implemented in scikit-learn [<xref ref-type="bibr" rid="c87">87</xref>] with a designated set of features to represent the spike train. Features were either: 1) interspike intervals (ISIs) distribution 2) averaged peri-stimulus histogram (PSTH) or 3) concatenated PSTHs.</p>
<p>To calculate ISI distribution for a neuron under specific stimulus, we converted all the spike times of that neuron during the stimulus’s presentation into ISIs. Then, we created 100 uniform bins between 1 ms and 3 s and counted the neuron’s ISIs in each bin. This resulted in 300 features of ISI “distribution” for each neuron. Finally, we performed min-max normalization, where for each neuron, the maximum value across all bins was set to 1, and the minimum value was set to 0.</p>
<p>The average and concatenated PSTHs were calculated for the drifting grating stimulus. For the average PSTH, we aligned all spikes around the stimulus presentation (1 s before the stimulus presentation and 2 s of stimulus presentation) for each neuron. Then, we created 100 uniform bins over 3 s and counted the number of spikes in each bin for each trial. Then, we averaged the values in each bin across all trials. This resulted in 300 features for each neuron. Finally, we performed min-max normalization, where the maximum value across all bins was set to 1, and the minimum value was set to 0. For the concatenated PSTH, a PSTH was calculated separately for each combination of the drifting grating’s parameters, i.e., temporal frequency and orientation. Similar to the average PSTH, we aligned the spikes around the stimulus presentation and performed a binned spike count for 30 uniform bins between 0 and 3 s. We then constructed the PSTH by taking mean across the number of trials. As each combination of the drifting grating’s parameter was repeated 15 times during the experiment, the PSTHs are mean of 15 trials. Similar to the ISI distribution and average PSTH, we performed a min-max normalization for each neuron. This operation took place on each PSTH prior to concatenation. Given that there were 40 parameter combinations and 30 bins for each combination, this resulted in 1,200 features per neuron.</p>
<p>For each task, a Bayesian hyperparameter optimization (HyperOpt package) [<xref ref-type="bibr" rid="c90">90</xref>] was used to tune hyperparameters (<xref rid="tbl3" ref-type="table">Table 3</xref>) such that they maximized balanced accuracy on the validation set. To mitigate the effect of class imbalance in our dataset, we treated resampling as a hyperparameter and evaluated undersampling, oversampling, and data augmentation. We found that the synthetic minority oversampling technique (SMOTE) [<xref ref-type="bibr" rid="c91">91</xref>], a data augmentation approach, yielded optimal performance on validation sets. Therefore classes were resampled with SMOTE in all cases unless otherwise specified. A different model was trained and tuned for each of five splits to avoid data leakages. For our inductive predictions across datasets (Allen to Steinmetz et al.) tasks, to ensure that the training data encompassed the relevant anatomical representations present in the Steinmetz et al. dataset, we trained models on a subset of Allen dataset that included only brain structures that are also present in the Steinmetz et al. dataset.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><title>MLP Hyperparameters</title></caption>
<graphic xlink:href="603152v3_tbl3.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>Consistent with prior work [<xref ref-type="bibr" rid="c15">15</xref>], an MLP with a single hidden layer was generally found to perform better than an MLP with multiple hidden layers. The number of nodes for this hidden layer was optimized. Alpha is the L2 regularization term. Beta 1 is the exponential decay rate for estimates of first moment vector in the Adam optimizer. All unmentioned hyperparameters took on default values from sklearn.</p>
<p>To identify the features contributing to the models’ learning, we employed permutation feature importance, which measures the extent to which shuffling a specific feature across samples increases the model’s prediction error [<xref ref-type="bibr" rid="c92">92</xref>]. To quantify the feature importance of a specific inter-spike interval (ISI) distribution bin for predicting a particular brain region or structure, we first estimated the model’s error for the original features, given that the neurons originated from that specific brain region or structure. Then, for those neurons, we randomly permuted (shuffled) a specific bin of the ISI distribution across all samples (neurons) and estimated the model’s error for the permuted features. The difference between the original and the permuted features’ error represents the feature importance for that specific bin and region/structure. We repeated this process 100 times for all bins in the ISI distribution, each region/structure, and across the five splits. The feature importance is the mean across the split and repetitions. We followed a similar approach for the concatenated PSTH.</p>
</sec>
<sec id="s4f">
<title>Smoothing</title>
<p>For some tasks, predictions were spatially smoothed to improve predictions by leveraging the spatial arrangements of recording channels to weight the influence of nearby units on each prediction. First, neurons (units) were grouped by session and probe to ensure the smoothing was applied within the same probe and session. Second, the predicted probabilities for each class were averaged for all neurons sorted to a particular electrode. Electrodes with no neurons detected were ignored for the purposes of this smoothing. Third, for each electrode, the spatial proximity of nearby units was leveraged by calculating a Gaussian weight. For an electrode, the weight for each nearby unit was determined using a normal distribution centered on the current unit’s electrode index (i.e. a linear approximation of the electrode geometry) with a standard deviation equal to the smoothing window. The probability density function (PDF) of the normal distribution was used to compute these weights. The class probabilities for each nearby unit were multiplied by their respective weights. The weighted probabilities were then summed and normalized by the sum of the weights to produce the smoothed prediction for each class for that electrode. The process was repeated for all electrodes. To determine an optimal standard deviation of the Gaussian kernel, we used Hyperopt to maximize balanced accuracy on the validation set.</p>
</sec>
<sec id="s4g">
<title>Models performance metrics and statistical tests</title>
<p>In order to quantify the models’ performances, we mainly used balanced accuracy, which is the macro average of recall (true positive rate) per class [<xref ref-type="bibr" rid="c38">38</xref>]. Chance-level is 1/number of classes. In some cases, we used the Matthews Correlation Coefficient (MCC). This measure considers true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). It provides a balanced measure, useful even with imbalanced datasets, with a value ranging from −1 (total disagreement) to 1 (perfect prediction) [<xref ref-type="bibr" rid="c47">47</xref>, <xref ref-type="bibr" rid="c48">48</xref>]. 0 represents chance-level (which is adjusted to the number of classes). As most of our tasks were multiclass classification, we used a multi-class version of MCC [<xref ref-type="bibr" rid="c87">87</xref>, <xref ref-type="bibr" rid="c93">93</xref>].</p>
<p>Given a confusion matrix <italic>C</italic> for <italic>N</italic> classes, the following intermediate variables are defined:
<disp-formula>
<graphic xlink:href="603152v3_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>The multi-class MCC is defined as:
<disp-formula>
<graphic xlink:href="603152v3_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>In all cases, the statistical test and level of significance are indicated in the relevant sections of the main text and figure legends. In most cases, linear mixed effects models are employed with subsequent ANOVA for main effect and post-hoc EMMeans with Tukey test for pairwise comparisons. The implementation was in R (lmer) [<xref ref-type="bibr" rid="c94">94</xref>]. In some cases, multiple T-tests with Bonferroni correction (as appropriate) was employed. The implementation was in Python (scipy.stats) [<xref ref-type="bibr" rid="c88">88</xref>].</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We would like to thank the Allen Institute for generating and sharing the Visual Coding datasets. We would like to thank Dr. Josh Siegle for technical insights into the Allen datasets and his helpful perspective on our work. We would also like to thank Dr. Nick Steinmetz for sharing data and technical advice.</p>
</ack>
<sec id="s5">
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Figure S1:</label>
<caption><title>Unsupervised analysis of spiking activity.</title>
<p>Left columns (scatters) show three methods of unsupervised dimensionality reduction (2D): principal component analysis (PCA), t-distributed Stochastic Neighbor Embedding (t-SNE), and Uniform Manifold Approximation and Projection (UMAP). Right columns (Wasserstein distance matrices) show quantification of the distance between anatomical groupings in the corresponding scatter plots on the left. Distance is calculated in the primary dimension for each plot. Rows denote three separate representations of unit activity: 14 pre determined spike metrics (e.g., firing rate), the full ISI distribution, or concatenated PSTHs. Note that within a task (e.g., Brain Regions), there is not a consistent pattern in the distance matrices, suggesting that any structure in the scatterplots is circumstantial. Colors in scatter plots correspond to anatomical labels on the matrices. Horizontal lines separate tasks. P-values in bottom right corner of plots refer to a permutation test of a logistic regression classifier’s training accuracy for accurate prediction of region/structure labels (relative to shuffled) based on plot coordinates for all individual units.</p></caption>
<graphic xlink:href="603152v3_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Figure S2:</label>
<caption><title>Unsmoothed transductive classification: confusion matrices.</title>
<p>Confusion matrices for MLP models using a transductive train/test split are shown. Matrices for four classification tasks (rows) and three different spiking activity representations (columns) are shown. Note that in the transductive condition, all neurons across animals are pooled and divided into train/test splits, such that there is a within-animal aspect to classifier learning. In individual matrices, the proportion of true instances of a particular class (columns) are distributed across a row reflecting the distribution of MLP predictions. Correct classifications fall along the diagonal from top left to bottom right. The confusion matrices’ labels, provided in the first column, are consistent in subsequent columns. Average (across the 5 splits) balanced accuracy (expressed as percent) for each task across the features from left to right: Regions (65.29, 53.96, 59.15), Hippocampus (41.72, 35.51, 44.16), Thalamus (39.15, 31.91, 43.25), Visual Ctx (25.84, 28.84, 38.35)</p></caption>
<graphic xlink:href="603152v3_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Figure S3:</label>
<caption><title>MLP-based model sensitivity as a function of input duration.</title>
<p>Models were trained normally as tested with varying amounts (durations) of input data. In all but one example, model performance increases as a function of input size (duration). The exception is in the visuocortical task, the secondary structure, VISam, declines with time. This reflects the model’s failure to learn a robust pattern. Three tasks are shown: <bold>A.</bold> Hippocampal Structures, <bold>B.</bold> Thalamic structures, and <bold>C.</bold> Visuocortical structures.</p></caption>
<graphic xlink:href="603152v3_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Figure S4:</label>
<caption><title>Interpretation of hippocampal and thalamic MLPs.</title>
<p><bold>A</bold> Hippocampal structure information is enriched in subsets of stimuli. Each rectangle represents one of the 40 stimulus parameter combinations. Colors correspond to hippocampal structures, and the area of color shows the relative importance of that stimulus to model classification of the given structure. Cat PSTH model. Dashed boxes—exemplar stimulus conditions. <bold>B.</bold> PSTHs corresponding to structure/stimulus pair indicated in A. Specific structure PSTH shown in color. Average PSTH of all other structures shown in gray. <bold>C,D.</bold> Same as A and B except for thalamic neurons and structures.</p></caption>
<graphic xlink:href="603152v3_figs4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>Figure S5:</label>
<caption><title>Unsmoothed inductive classification: confusion matrices.</title>
<p>Confusion matrices for MLP models using an inductive train/test split are shown. Note that in the inductive condition, models are trained on all neurons from a subset of animals, and tested on all neurons from a withheld group of animals. This eliminates any possibility of learning a local solution within animal. Matrices for four classification tasks (rows) and three different spiking activity representations (columns) are shown. In individual matrices, the proportion of true instances of a particular class (columns) are distributed across a row reflecting the distribution of MLP predictions. Correct classifications fall along the diagonal from top left to bottom right. The confusion matrices’ labels, provided in the first column, are consistent in subsequent columns. Average (across the 5 splits) balanced accuracy values (in %) for each task across the features from left to right: Regions (65.10, 51.72, 49.16), Hippocampus (35.89, 26.39, 21.50), Thalamus (32.79, 26.28, 21.72), Visual Ctx (25.52, 25.83, 26.51)</p></caption>
<graphic xlink:href="603152v3_figs5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs6" position="float" orientation="portrait" fig-type="figure">
<label>Figure S6:</label>
<caption><title>Smoothed inductive classification: confusion matrices.</title>
<p>Confusion matrices for MLP models using an inductive (across animals) train/test split are shown. Note that in the inductive condition, models are trained on all neurons from a subset of animals, and tested on all neurons from a withheld group of animals. This eliminates any possibility of learning a local solution within animal. Matrices for four classification tasks (rows) and three different spiking activity representations (columns) are shown. In individual matrices, the proportion of true instances of a particular class (columns) are distributed across a row reflecting the distribution of MLP predictions. Correct classifications fall along the diagonal from top left to bottom right. The confusion matrices’ labels, provided in the first column, are consistent in subsequent columns. Average (across the 5 splits) balanced accuracy values (in %) for each task across the features from left to right: Regions (89.47, 67.95, 63.92), Hippocampus (51.01, 39.31, 25.84), Thalamus (53.21, 35.38, 24.81), Visual Ctx (38.48, 44.66, 43.97)</p></caption>
<graphic xlink:href="603152v3_figs6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs7" position="float" orientation="portrait" fig-type="figure">
<label>Figure S7:</label>
<caption><title>The effect of training and testing within and across stimulus conditions.</title>
<p>For each classification task (e.g., Brain Regions), the bar chart shows the mean MCC value with standard error for models trained and tested on the same stimulus condition (e.g. train: drifting gratings &amp; test: drifting gratings; train: natural movie &amp; test: natural movie) in gray. In black, MCC of models trained and tested on different stimuli (e.g. train: drifting gratings &amp; test: spontaneous; train: natural movies &amp; test: drifting gratings). Linear mixed effects. (ns/not significant: <italic>p &gt;</italic>= 0.05, *: <italic>p &lt;</italic> 0.05, **: <italic>p &lt;</italic> 0.01, ***: <italic>p &lt;</italic> 0.001)</p></caption>
<graphic xlink:href="603152v3_figs7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs8" position="float" orientation="portrait" fig-type="figure">
<label>Figure S8:</label>
<caption><title>Train/test across laboratories: Allen-to-Steinmetz et al. confusion matrices.</title>
<p>6 tasks are displayed. The y-axis label denotes the task (e.g, Regions), and the column label denotes the training condition (drifting gratings or mixed stimuli). All models involve training on the Allen Institute data and testing on Steinmetz et al. data. Mixed stimuli models are trained on neuronal activity recorded during the presentation of drifting gratings, natural movies, and spontaneous activity. Balanced accuracy corresponding to each confusion matrix: BR DG=80.46%, BR Mix: 81.28 %, HS DG: 40.07 %, HS Mix: 69.89 %, TS DG: 21.52 %, TS Mix: 58.22 %, VCS DG: 28.41 %, VCS Mix: 28.34 %, VCSS DG: 58 %, VCSS Mix: 59 %, VC Layers DG: 46.36 %, VC Layers Mix: 49.01 % where BR stands for brain regions, HS hippocampal structures, TS thalamic structures, VCS visual cortex structures, VCSS visual cortex superstructures, DG drifting gratings and Mix denotes the combined stimuli.</p></caption>
<graphic xlink:href="603152v3_figs8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E. D.</given-names> <surname>Adrian</surname></string-name> and <string-name><given-names>D. W.</given-names> <surname>Bronk</surname></string-name></person-group>. “<article-title>The discharge of impulses in motor nerve fibres: Part I. Impulses in single fibres of the phrenic nerve</article-title>.” In: <source>The Journal of Physiology</source> <volume>66</volume>.<issue>1</issue> (<month>Sept.</month> <year>1928</year>), pp. <fpage>81</fpage>–<lpage>101</lpage>. issn: <issn>1469-7793</issn>. doi: <pub-id pub-id-type="doi">10.1113/jphysiol.1928.sp002509</pub-id>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Warren S.</given-names> <surname>McCulloch</surname></string-name> and <string-name><given-names>Walter</given-names> <surname>Pitts</surname></string-name></person-group>. “<article-title>A logical calculus of the ideas immanent in nervous activity</article-title>.” In: <source>The Bulletin of Mathematical Biophysics</source> <volume>5</volume>.<issue>4</issue> (<month>Dec.</month> <year>1943</year>), pp. <fpage>115</fpage>–<lpage>133</lpage>. issn: <issn>1522-9602</issn>. doi: <pub-id pub-id-type="doi">10.1007/bf02478259</pub-id>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J</given-names> <surname>Lettvin</surname></string-name> <etal>et al.</etal></person-group> “<article-title>What the frog’s eye tells the frog’s brain</article-title>.” In: <source>Proc. IRE</source> <volume>47</volume>.<issue>11</issue> (<month>Nov.</month> <year>1959</year>), pp. <fpage>1940</fpage>–<lpage>1951</lpage>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Aldo Faisal</surname></string-name>, <string-name><given-names>Luc P. J.</given-names> <surname>Selen</surname></string-name>, and <string-name><given-names>Daniel M.</given-names> <surname>Wolpert</surname></string-name></person-group>. “<article-title>Noise in the nervous system</article-title>.” In: <source>Nature Reviews Neuroscience</source> <volume>9</volume>.<issue>4</issue> (<month>Apr.</month> <year>2008</year>), pp. <fpage>292</fpage>–<lpage>303</lpage>. issn: <issn>1471-0048</issn>. doi: <pub-id pub-id-type="doi">10.1038/nrn2258</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Wulfram</given-names> <surname>Gerstner</surname></string-name> <etal>et al.</etal></person-group> <source>Neuronal Dynamics: From Single Neurons to Networks and Models of Cognition</source>. <publisher-name>Cambridge University Press</publisher-name>, July <year>2014</year>. isbn: <isbn>9781107447615</isbn>. doi: <pub-id pub-id-type="doi">10.1017/cbo9781107447615</pub-id>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Zachary F.</given-names> <surname>Mainen</surname></string-name> and <string-name><given-names>Terrence J.</given-names> <surname>Sejnowski</surname></string-name></person-group>. “<article-title>Reliability of Spike Timing in Neocortical Neurons</article-title>.” In: <source>Science</source> <volume>268</volume>.<issue>5216</issue> (June <year>1995</year>), pp. <fpage>1503</fpage>–<lpage>1506</lpage>. issn: <issn>1095-9203</issn>. doi: <pub-id pub-id-type="doi">10.1126/science.7770778</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>WR</given-names> <surname>Softky</surname></string-name> and <string-name><given-names>C</given-names> <surname>Koch</surname></string-name></person-group>. “<article-title>The highly irregular firing of cortical cells is inconsistent with temporal integration of random EPSPs</article-title>.” In: <source>The Journal of Neuroscience</source> <volume>13</volume>.<issue>1</issue> (<month>Jan.</month> <year>1993</year>), pp. <fpage>334</fpage>–<lpage>350</lpage>. issn: <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/jneurosci.13-01-00334.1993</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Santiago</given-names> <surname>Ramón y Cajal</surname></string-name></person-group>. <source>Textura del Sistema Nervioso del Hombre y de los Vertebrados</source>. <publisher-loc>Madrid</publisher-loc>: <publisher-name>Moya</publisher-name>, <year>1904</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Korbinian</given-names> <surname>Brodmann</surname></string-name></person-group>. <source>Vergleichende Lokalisationslehre der Großhirnrinde in ihren Prinzipien dargestellt auf Grund des Zellenbaues</source>. <publisher-loc>Leipzig</publisher-loc>: <publisher-name>Barth</publisher-name>, <year>1909</year>. url: <ext-link ext-link-type="uri" xlink:href="https://archive.org/details/b28062449">https://archive.org/details/b28062449</ext-link>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Wilder</given-names> <surname>Penfield</surname></string-name> and <string-name><given-names>Herbert</given-names> <surname>Jasper</surname></string-name></person-group>. <source>Epilepsy and the Functional Anatomy of the Human Brain</source>. <publisher-loc>Boston</publisher-loc>: <publisher-name>Little, Brown and Company</publisher-name>, <year>1951</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Michael N.</given-names> <surname>Shadlen</surname></string-name> and <string-name><given-names>William T.</given-names> <surname>Newsome</surname></string-name></person-group>. “<article-title>Noise, neural codes and cortical organization</article-title>.” In: <source>Current Opinion in Neurobiology</source> <volume>4</volume>.<issue>4</issue> (<month>Aug.</month> <year>1994</year>), pp. <fpage>569</fpage>–<lpage>579</lpage>. issn: <issn>0959-4388</issn>. doi: <pub-id pub-id-type="doi">10.1016/0959-4388(94)90059-0</pub-id>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Michael</given-names> <surname>London</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Sensitivity to perturbations in vivo implies high noise and suggests rate coding in cortex</article-title>.” In: <source>Nature</source> <volume>466</volume>.<issue>7302</issue> (July <year>2010</year>), pp. <fpage>123</fpage>–<lpage>127</lpage>. issn: <issn>1476-4687</issn>. doi: <pub-id pub-id-type="doi">10.1038/nature09086</pub-id>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Chethan</given-names> <surname>Pandarinath</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Inferring single-trial neural population dynamics using sequential auto-encoders</article-title>.” In: <source>Nature Methods</source> <volume>15</volume>.<issue>10</issue> (<month>Sept.</month> <year>2018</year>), pp. <fpage>805</fpage>–<lpage>815</lpage>. issn: <issn>1548-7105</issn>. doi: <pub-id pub-id-type="doi">10.1038/s41592-018-0109-9</pub-id>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yash</given-names> <surname>Sawant</surname></string-name> <etal>et al.</etal></person-group> “<article-title>A Midbrain Inspired Recurrent Neural Network Model for Robust Change Detection</article-title>.” In: <source>The Journal of Neuroscience</source> <volume>42</volume>.<issue>44</issue> (<month>Sept.</month> <year>2022</year>), pp. <fpage>8262</fpage>–<lpage>8283</lpage>. issn: <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/jneurosci.0164-22.2022</pub-id>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Aidan</given-names> <surname>Schneider</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Transcriptomic cell type structures in vivo neuronal activity across multiple timescales</article-title>.” In: <source>Cell Reports</source> <volume>42</volume>.<issue>4</issue> (<month>Apr.</month> <year>2023</year>). PMCID: <pub-id pub-id-type="pmcid">PMC10539488</pub-id>, p. <fpage>112318</fpage>. issn: <issue>2211-1247</issue>. doi: <pub-id pub-id-type="doi">10.1016/j.celrep.2023.112318</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N</given-names> <surname>Patel</surname></string-name> and <string-name><given-names>MM</given-names> <surname>Poo</surname></string-name></person-group>. “<article-title>Orientation of neurite growth by extracellular electric fields</article-title>.” In: <source>The Journal of Neuroscience</source> <volume>2</volume>.<issue>4</issue> (<month>Apr.</month> <year>1982</year>), pp. <fpage>483</fpage>–<lpage>496</lpage>. issn: <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/jneurosci.02-04-00483.1982</pub-id>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Robert</given-names> <surname>Gütig</surname></string-name> and <string-name><given-names>Haim</given-names> <surname>Sompolinsky</surname></string-name></person-group>. “<article-title>The tempotron: a neuron that learns spike timing–based decisions</article-title>.” In: <source>Nature Neuroscience</source> <volume>9</volume>.<issue>3</issue> (<month>Feb.</month> <year>2006</year>), pp. <fpage>420</fpage>–<lpage>428</lpage>. issn: <issn>1546-1726</issn>. doi: <pub-id pub-id-type="doi">10.1038/nn1643</pub-id>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Joshua H.</given-names> <surname>Siegle</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Survey of spiking in the mouse visual system reveals functional hierarchy</article-title>.” In: <source>Nature</source> <volume>592</volume>.<issue>7852</issue> (<month>Jan.</month> <year>2021</year>), pp. <fpage>86</fpage>–<lpage>92</lpage>. issn: <issn>1476-4687</issn>. doi: <pub-id pub-id-type="doi">10.1038/s41586-020-03171-x</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>G. N.</given-names> <surname>Elston</surname></string-name></person-group>. “<chapter-title>Specialization of the neocortical pyramidal cell during primate evolution</chapter-title>.” In: <source>Evolution of Nervous Systems</source>. Ed. by <person-group person-group-type="editor"><string-name><given-names>Jon H.</given-names> <surname>Kaas</surname></string-name></person-group>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Elsevier</publisher-name>, <year>2007</year>, pp. <fpage>191</fpage>–<lpage>242</lpage>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Rajan</given-names> <surname>Chaudhuri</surname></string-name> <etal>et al.</etal></person-group> “<article-title>A large-scale circuit mechanism for hierarchical dynamical processing in the primate cortex</article-title>.” In: <source>Neuron</source> <volume>88</volume> (<year>2015</year>), pp. <fpage>419</fpage>–<lpage>431</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.008</pub-id>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>John D</given-names> <surname>Murray</surname></string-name> <etal>et al.</etal></person-group> “<article-title>A hierarchy of intrinsic timescales across primate cortex</article-title>.” In: <source>Nature Neuroscience</source> <volume>17</volume>.<issue>12</issue> (<month>Nov.</month> <year>2014</year>), pp. <fpage>1661</fpage>–<lpage>1663</lpage>. issn: <issn>1546-1726</issn>. doi: <pub-id pub-id-type="doi">10.1038/nn.3862</pub-id>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. H.</given-names> <surname>Maunsell</surname></string-name> and <string-name><given-names>D. C.</given-names> <surname>Van Essen</surname></string-name></person-group>. “<article-title>The connections of the middle temporal visual area (MT) and their relationship to a cortical hierarchy in the macaque monkey</article-title>.” In: <source>Journal of Neuroscience</source> <volume>3</volume> (<year>1983</year>), pp. <fpage>2563</fpage>–<lpage>2586</lpage>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Răzvan</given-names> <surname>Gămănůt</surname></string-name>, <etal>et al.</etal></person-group> “<article-title>The mouse cortical connectome, characterized by an ultra-dense cortical graph, maintains specificity by distinct connectivity profiles</article-title>.” In: <source>Neuron</source> <volume>97</volume> (<year>2018</year>), pp. <fpage>698</fpage>–<lpage>715</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.010</pub-id>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Julie A.</given-names> <surname>Harris</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Hierarchical organization of cortical and thalamic connectivity</article-title>.” In: <source>Nature</source> <volume>575</volume> (<year>2019</year>), pp. <fpage>195</fpage>–<lpage>202</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41586-019-1716-z</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Daniel J</given-names> <surname>Millman</surname></string-name> <etal>et al.</etal></person-group> “<article-title>VIP interneurons in mouse primary visual cortex selectively enhance responses to weak but specific stimuli</article-title>.” In: <source>eLife</source> <volume>9</volume> (<month>Oct.</month> <year>2020</year>). issn: <issn>2050-084X</issn>. doi: <pub-id pub-id-type="doi">10.7554/elife.55130</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="other"><source>Touch of Evil</source>. Film. <year>1958</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Shigeru</given-names> <surname>Shinomoto</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Relating Neuronal Firing Patterns to Functional Differentiation of Cerebral Cortex</article-title>.” In: <source>PLoS Computational Biology</source> <volume>5</volume>.<issue>7</issue> (July <year>2009</year>) <fpage>e1000433</fpage>. issn: <issn>1553-7358</issn>. doi: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1000433</pub-id>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yasuhiro</given-names> <surname>Mochizuki</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Similarity in Neuronal Firing Regimes across Mammalian Species</article-title>.” In: <source>The Journal of Neuroscience</source> <volume>36</volume>.<issue>21</issue> (May <year>2016</year>), pp. <fpage>5736</fpage>–<lpage>5747</lpage>. issn: <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/jneurosci.0230-16.2016</pub-id>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name></person-group>. “<article-title>Theory of the Multiregional Neocortex: Large-Scale Neural Dynamics and Distributed Cognition</article-title>.” In: <source>Annual Review of Neuroscience</source> <volume>45</volume>.<issue>1</issue> (July <year>2022</year>), pp. <fpage>533</fpage>–<lpage>560</lpage>. issn: <issn>1545-4126</issn>. doi: <pub-id pub-id-type="doi">10.1146/annurev-neuro-110920-035434</pub-id>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Trevor</given-names> <surname>Hastie</surname></string-name>, <string-name><given-names>Robert</given-names> <surname>Tibshirani</surname></string-name>, and <string-name><given-names>Jerome</given-names> <surname>Friedman</surname></string-name></person-group>. <source>The Elements of Statistical Learning</source>. <publisher-name>Springer New York</publisher-name>, <year>2009</year>. isbn: <isbn>9780387848587</isbn>. doi: <pub-id pub-id-type="doi">10.1007/978-0-387-84858-7</pub-id>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Karl</given-names> <surname>Pearson</surname></string-name></person-group>. “<article-title>On Lines and Planes of Closest Fit to Systems of Points in Space</article-title>.” In: <source>Philosophical Magazine</source> <volume>2</volume>.<issue>11</issue> (<year>1901</year>), pp. <fpage>559</fpage>–<lpage>572</lpage>. doi: <pub-id pub-id-type="doi">10.1080/14786440109462720</pub-id>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L.J.P.</given-names> <surname>van der Maaten</surname></string-name> and <string-name><given-names>G.E.</given-names> <surname>Hinton</surname></string-name></person-group>. “<article-title>Visualizing Data using t-SNE</article-title>.” In: <source>Journal of Machine Learning Research</source> <volume>9</volume> (<year>2008</year>), pp. <fpage>2579</fpage>–<lpage>2605</lpage>. url: <ext-link ext-link-type="uri" xlink:href="http://www.jmlr.org/papers/v9/vandermaaten08a.html">http://www.jmlr.org/papers/v9/vandermaaten08a.html</ext-link>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Leland</given-names> <surname>McInnes</surname></string-name>, <string-name><given-names>John</given-names> <surname>Healy</surname></string-name>, and <string-name><given-names>James</given-names> <surname>Melville</surname></string-name></person-group>. “<article-title>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</article-title>.” <source>arXiv</source> <elocation-id>arXiv:1802.03426</elocation-id> (<year>2018</year>). url: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1802.03426">https://arxiv.org/abs/1802.03426</ext-link>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Shozo</given-names> <surname>Jinno</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Neuronal Diversity in GABAergic Long-Range Projections from the Hippocampus</article-title>.” In: <source>The Journal of Neuroscience</source> <volume>27</volume>.<issue>33</issue> (<month>Aug.</month> <year>2007</year>), pp. <fpage>8790</fpage>–<lpage>8804</lpage>. issn: <issn>1529-2401</issn>. doi:<pub-id pub-id-type="doi">10.1523/jneurosci.1847-07.2007</pub-id>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mark S.</given-names> <surname>Cembrowski</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Spatial Gene-Expression Gradients Underlie Prominent Heterogeneity of CA1 Pyramidal Neurons</article-title>.” In: <source>Neuron</source> <volume>89</volume>.<issue>2</issue> (<month>Jan.</month> <year>2016</year>), pp. <fpage>351</fpage>–<lpage>368</lpage>. issn: <issn>0896-6273</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2015.12.013</pub-id>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Sinno Jialin</given-names> <surname>Pan</surname></string-name> and <string-name><given-names>Qiang</given-names> <surname>Yang</surname></string-name></person-group>. “<article-title>A Survey on Transfer Learning</article-title>.” In: <source>IEEE Transactions on Knowledge and Data Engineering</source> <volume>22</volume>.<issue>10</issue> (<year>2010</year>), pp. <fpage>1345</fpage>–<lpage>1359</lpage>. doi: <pub-id pub-id-type="doi">10.1109/TKDE.2009.191</pub-id>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Vladimir N.</given-names> <surname>Vapnik</surname></string-name></person-group>. <source>Statistical Learning Theory</source>. <publisher-name>Wiley-Interscience</publisher-name>, <year>1998</year>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Kay H.</given-names> <surname>Brodersen</surname></string-name> <etal>et al.</etal></person-group> “<article-title>The balanced accuracy and its posterior distribution</article-title>.” In: <source>Proceedings of the 20th International Conference on Pattern Recognition (ICPR)</source> (<year>2010</year>), pp. <fpage>3121</fpage>–<lpage>3124</lpage>. doi: <pub-id pub-id-type="doi">10.1109/ICPR.2010.764</pub-id>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.R.</given-names> <surname>Holt</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Comparison of discharge variability in vitro and in vivo in cat visual cortex neurons</article-title>.” In: <source>Journal of Neurophysiology</source> <volume>75</volume>.<issue>5</issue> (<year>1996</year>), pp. <fpage>1806</fpage>–<lpage>1814</lpage>. doi: <pub-id pub-id-type="doi">10.1152/jn.1996.75.5.1806</pub-id>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alexa</given-names> <surname>Riehle</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Spike Synchronization and Rate Modulation Differentially Involved in Motor Cortical Function</article-title>.” In: <source>Science</source> <volume>278</volume>.<issue>5345</issue> (<month>Dec.</month> <year>1997</year>), pp. <fpage>1950</fpage>–<lpage>1953</lpage>. issn: <issn>1095-9203</issn>. doi: <pub-id pub-id-type="doi">10.1126/science.278.5345.1950</pub-id>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Wolfgang</given-names> <surname>Maass</surname></string-name></person-group>. “<article-title>On the Computational Power of Winner-Take-All</article-title>.” In: <source>Neural Computation</source> <volume>12</volume>.<issue>11</issue> (<month>Nov.</month> <year>2000</year>), pp. <fpage>2519</fpage>–<lpage>2535</lpage>. issn: <issn>1530-888X</issn>. doi: <pub-id pub-id-type="doi">10.1162/089976600300014827</pub-id>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Luciano</given-names> <surname>Paz</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Confidence through consensus: a neural mechanism for uncertainty monitoring</article-title>.” In: <source>Scientific Reports</source> <volume>6</volume>.<issue>1</issue> (<month>Feb.</month> <year>2016</year>). issn: <issn>2045-2322</issn>. doi: <pub-id pub-id-type="doi">10.1038/srep21830</pub-id>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Quanxin</given-names> <surname>Wang</surname></string-name> and <string-name><given-names>Andreas</given-names> <surname>Burkhalter</surname></string-name></person-group>. “<article-title>Area map of mouse visual cortex</article-title>.” In: <source>Journal of Comparative Neurology</source> <volume>502</volume>.<issue>3</issue> (<month>Mar.</month> <year>2007</year>), pp. <fpage>339</fpage>–<lpage>357</lpage>. issn: <issn>1096-9861</issn>. doi: <pub-id pub-id-type="doi">10.1002/cne.21286</pub-id>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Lindsey L.</given-names> <surname>Glickfeld</surname></string-name> and <string-name><given-names>Shawn R.</given-names> <surname>Olsen</surname></string-name></person-group>. “<article-title>Higher-Order Areas of the Mouse Visual Cortex</article-title>.” In: <source>Annual Review of Vision Science</source> <volume>3</volume>.<issue>1</issue> (<month>Sept.</month> <year>2017</year>), pp. <fpage>251</fpage>–<lpage>273</lpage>. issn: <issn>2374-4650</issn>. doi: <pub-id pub-id-type="doi">10.1146/annurev-vision-102016-061331</pub-id>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Eric Kenji</given-names> <surname>Lee</surname></string-name> <etal>et al.</etal></person-group> “<article-title>PhysMAP - interpretablein vivoneuronal cell type identification using multi-modal analysis of electrophysiological data</article-title>.” <source>bioRxiv</source> (<month>Feb.</month> <year>2024</year>). doi: <pub-id pub-id-type="doi">10.1101/2024.02.28.582461</pub-id>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Helen</given-names> <surname>Wang</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Diversity in spatial frequency, temporal frequency, and speed tuning across mouse visual cortical areas and layers</article-title>.” In: <source>Journal of Comparative Neurology</source> <volume>530</volume>.<issue>18</issue> (<month>Sept.</month> <year>2022</year>), pp. <fpage>3226</fpage>–<lpage>3247</lpage>. issn: <issn>1096-9861</issn>. doi: <pub-id pub-id-type="doi">10.1002/cne.25404</pub-id>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Davide</given-names> <surname>Chicco</surname></string-name> and <string-name><given-names>Giuseppe</given-names> <surname>Jurman</surname></string-name></person-group>. “<article-title>The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation</article-title>.” In: <source>BMC genomics</source> <volume>21</volume>.<issue>1</issue> (<year>2020</year>), p. <fpage>6</fpage>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Sabri</given-names> <surname>Boughorbel</surname></string-name>, <string-name><given-names>Fethi</given-names> <surname>Jarray</surname></string-name>, and <string-name><given-names>Mohammed</given-names> <surname>El-Anbari</surname></string-name></person-group>. “<article-title>Optimal classifier for imbalanced data using Matthews Correlation Coefficient metric</article-title>.” In: <source>PloS one</source> <volume>12</volume>.<issue>6</issue> (<year>2017</year>), <fpage>e0177678</fpage>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Giuseppe</given-names> <surname>Jurman</surname></string-name>, <string-name><given-names>Samantha</given-names> <surname>Riccadonna</surname></string-name>, and <string-name><given-names>Cesare</given-names> <surname>Furlanello</surname></string-name></person-group>. “<article-title>A comparison of MCC and CEN error measures in multi-class prediction</article-title>.” In: <source>PloS one</source> <volume>7</volume>.<issue>8</issue> (<year>2012</year>), <fpage>e41882</fpage>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Nicholas A.</given-names> <surname>Steinmetz</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Distributed coding of choice, action and engagement across the mouse brain</article-title>.” In: <source>Nature</source> <volume>576</volume>.<issue>7786</issue> (<month>Nov.</month> <year>2019</year>), pp. <fpage>266</fpage>–<lpage>273</lpage>. issn: <issn>1476-4687</issn>. doi: <pub-id pub-id-type="doi">10.1038/s41586-019-1787-x</pub-id>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B</given-names> <surname>Olshausen</surname></string-name> and <string-name><given-names>D</given-names> <surname>Field</surname></string-name></person-group>. “<article-title>Sparse coding of sensory inputs</article-title>.” In: <source>Current Opinion in Neurobiology</source> <volume>14</volume>.<issue>4</issue> (<month>Aug.</month> <year>2004</year>), pp. <fpage>481</fpage>–<lpage>487</lpage>. issn: <issn>0959-4388</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.conb.2004.07.007</pub-id>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Kenneth D.</given-names> <surname>Harris</surname></string-name> and <string-name><given-names>Alexander</given-names> <surname>Thiele</surname></string-name></person-group>. “<article-title>Cortical state and attention</article-title>.” In: <source>Nature Reviews Neuroscience</source> <volume>12</volume>.<issue>9</issue> (<month>Aug.</month> <year>2011</year>), pp. <fpage>509</fpage>–<lpage>523</lpage>. issn: <issn>1471-0048</issn>. doi: <pub-id pub-id-type="doi">10.1038/nrn3084</pub-id>.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>David F.</given-names> <surname>Parks</surname></string-name> <etal>et al.</etal></person-group> “<article-title>A non-oscillatory, millisecond-scale embedding of brain state provides insight into behavior</article-title>.” <source>bioRxiv</source> (June <year>2023</year>). PMCID: <pub-id pub-id-type="pmcid">PMC10274881</pub-id>. doi: <pub-id pub-id-type="doi">10.1101/2023.06.09.544399</pub-id>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alessio P.</given-names> <surname>Buccino</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Combining biophysical modeling and deep learning for multielectrode array neuron localization and classification</article-title>.” In: <source>Journal of Neurophysiology</source> <volume>120</volume>.<issue>3</issue> (<month>Sept.</month> <year>2018</year>), pp. <fpage>1212</fpage>–<lpage>1232</lpage>. issn: <issn>1522-1598</issn>. doi: <pub-id pub-id-type="doi">10.1152/jn.00210.2018</pub-id>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Xiaoxuan</given-names> <surname>Jia</surname></string-name> <etal>et al.</etal></person-group> “<article-title>High-density extracellular probes reveal dendritic backpropagation and facilitate neuron classification</article-title>.” In: <source>Journal of Neurophysiology</source> <volume>121</volume>.<issue>5</issue> (May <year>2019</year>), pp. <fpage>1831</fpage>–<lpage>1847</lpage>. issn: <issn>1522-1598</issn>. doi: <pub-id pub-id-type="doi">10.1152/jn.00680.2018</pub-id>.</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alex</given-names> <surname>Roxin</surname></string-name> <etal>et al.</etal></person-group> “<article-title>On the Distribution of Firing Rates in Networks of Cortical Neurons</article-title>.” In: <source>The Journal of Neuroscience</source> <volume>31</volume>.<issue>45</issue> (<month>Nov.</month> <year>2011</year>), pp. <fpage>16217</fpage>–<lpage>16226</lpage>. issn: <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/jneurosci.1677-11.2011</pub-id>.</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Kenji</given-names> <surname>Mizuseki</surname></string-name> and <string-name><given-names>György</given-names> <surname>Buzsáki</surname></string-name></person-group>. “<article-title>Preconfigured, Skewed Distribution of Firing Rates in the Hippocampus and Entorhinal Cortex</article-title>.” In: <source>Cell Reports</source> <volume>4</volume>.<issue>5</issue> (<month>Sept.</month> <year>2013</year>), pp. <fpage>1010</fpage>–<lpage>1021</lpage>. issn: <issn>2211-1247</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.celrep.2013.07.039</pub-id>.</mixed-citation></ref>
<ref id="c58"><label>[58]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Lu</given-names> <surname>Mi</surname></string-name> <etal>et al.</etal> “.” In: . Ed. by  <etal>et al.</etal></person-group><chapter-title>Learning Time-Invariant Representations for Individual Neurons from Population Dynamics</chapter-title>.” In: <source>Advances in Neural Information Processing Systems</source>. Ed. by <person-group person-group-type="editor"><string-name><given-names>A.</given-names> <surname>Oh</surname></string-name></person-group>  Vol. <volume>36</volume>. <publisher-name>Curran Associates, Inc</publisher-name>., <year>2023</year>, pp. <fpage>46007</fpage>–<lpage>46026</lpage>. url: <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper_files/paper/2023/file/9032e5c9ec394ce768a2fa9bdc56af6c-Paper-Conference.pdf">https://proceedings.neurips.cc/paper_files/paper/2023/file/9032e5c9ec394ce768a2fa9bdc56af6c-Paper-Conference.pdf</ext-link>.</mixed-citation></ref>
<ref id="c59"><label>[59]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Cristopher M.</given-names> <surname>Niell</surname></string-name> and <string-name><given-names>Michael P.</given-names> <surname>Stryker</surname></string-name></person-group>. “<article-title>Highly Selective Receptive Fields in Mouse Visual Cortex</article-title>.” In: <source>The Journal of Neuroscience</source> <volume>28</volume>.<issue>30</issue> (July <year>2008</year>), pp. <fpage>7520</fpage>–<lpage>7536</lpage>. issn: <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/jneurosci.0623-08.2008</pub-id>.</mixed-citation></ref>
<ref id="c60"><label>[60]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Matthew T.</given-names> <surname>Schmolesky</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Signal Timing Across the Macaque Visual System</article-title>.” In: <source>Journal of Neurophysiology</source> <volume>79</volume>.<issue>6</issue> (June <year>1998</year>), pp. <fpage>3272</fpage>–<lpage>3278</lpage>. issn: <issn>1522-1598</issn>. doi: <pub-id pub-id-type="doi">10.1152/jn.1998.79.6.3272</pub-id>.</mixed-citation></ref>
<ref id="c61"><label>[61]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Amit</given-names> <surname>Zeisel</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Molecular Architecture of the Mouse Nervous System</article-title>.” In: <source>Cell</source> <volume>174</volume>.<issue>4</issue> (<month>Aug.</month> <year>2018</year>), <fpage>999</fpage>–<lpage>1014.e22.</lpage> issn: <issn>0092-8674</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.cell.2018.06.021</pub-id>.</mixed-citation></ref>
<ref id="c62"><label>[62]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Arpiar</given-names> <surname>Saunders</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Molecular Diversity and Specializations among the Cells of the Adult Mouse Brain</article-title>.” In: <source>Cell</source> <volume>174</volume>.<issue>4</issue> (<month>Aug.</month> <year>2018</year>), <fpage>1015</fpage>–<lpage>1030.e16.</lpage> issn: <issn>0092-8674</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.cell.2018.07.028</pub-id>.</mixed-citation></ref>
<ref id="c63"><label>[63]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Oliver</given-names> <surname>Braganza</surname></string-name> and <string-name><given-names>Heinz</given-names> <surname>Beck</surname></string-name></person-group>. “<article-title>The Circuit Motif as a Conceptual Tool for Multilevel Neuroscience</article-title>.” In: <source>Trends in Neurosciences</source> <volume>41</volume>.<issue>3</issue> (<month>Mar.</month> <year>2018</year>), pp. <fpage>128</fpage>–<lpage>136</lpage>. issn: <issn>0166-2236</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.tins.2018.01.002</pub-id>.</mixed-citation></ref>
<ref id="c64"><label>[64]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Liqun</given-names> <surname>Luo</surname></string-name></person-group>. “<article-title>Architectures of neuronal circuits</article-title>.” In: <source>Science</source> <volume>373</volume>.<issue>6559</issue> (<month>Sept.</month> <year>2021</year>). issn: <issn>1095-9203</issn>. doi: <pub-id pub-id-type="doi">10.1126/science.abg7285</pub-id>.</mixed-citation></ref>
<ref id="c65"><label>[65]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Keith B.</given-names> <surname>Hengen</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Firing Rate Homeostasis in Visual Cortex of Freely Behaving Rodents</article-title>.” In: <source>Neuron</source> <volume>80</volume>.<issue>2</issue> (<month>Oct.</month> <year>2013</year>), pp. <fpage>335</fpage>–<lpage>342</lpage>. issn: <issn>0896-6273</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2013.08.038</pub-id>.</mixed-citation></ref>
<ref id="c66"><label>[66]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Keith B.</given-names> <surname>Hengen</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Neuronal Firing Rate Homeostasis Is Inhibited by Sleep and Promoted by Wake</article-title>.” In: <source>Cell</source> <volume>165</volume>.<issue>1</issue> (<month>Mar.</month> <year>2016</year>), pp. <fpage>180</fpage>–<lpage>191</lpage>. issn: <issn>0092-8674</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.cell.2016.01.046</pub-id>.</mixed-citation></ref>
<ref id="c67"><label>[67]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Zhengyu</given-names> <surname>Ma</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Cortical Circuit Dynamics Are Homeostatically Tuned to Criticality In Vivo</article-title>.” In: <source>Neuron</source> <volume>104</volume>.<issue>4</issue> (<month>Nov.</month> <year>2019</year>). PMCID: <pub-id pub-id-type="pmcid">PMC6934140</pub-id>, <fpage>655</fpage>–<lpage>664.e4.</lpage> issn: <issn>0896-6273</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2019.08.031</pub-id>.</mixed-citation></ref>
<ref id="c68"><label>[68]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alfonso</given-names> <surname>Renart</surname></string-name> and <string-name><given-names>Christian K</given-names> <surname>Machens</surname></string-name></person-group>. “<article-title>Variability in neural activity and behavior</article-title>.” In: <source>Current Opinion in Neurobiology</source> <volume>25</volume> (<month>Apr.</month> <year>2014</year>), pp. <fpage>211</fpage>–<lpage>220</lpage>. issn: <issn>0959-4388</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.conb.2014.02.013</pub-id>.</mixed-citation></ref>
<ref id="c69"><label>[69]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Marlene R</given-names> <surname>Cohen</surname></string-name> and <string-name><given-names>Adam</given-names> <surname>Kohn</surname></string-name></person-group>. “<article-title>Measuring and interpreting neuronal correlations</article-title>.” In: <source>Nature Neuroscience</source> <volume>14</volume>.<issue>7</issue> (June <year>2011</year>), pp. <fpage>811</fpage>–<lpage>819</lpage>. issn: <issn>1546-1726</issn>. doi: <pub-id pub-id-type="doi">10.1038/nn.2842</pub-id>.</mixed-citation></ref>
<ref id="c70"><label>[70]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Matthew A.</given-names> <surname>Smith</surname></string-name> and <string-name><given-names>Adam</given-names> <surname>Kohn</surname></string-name></person-group>. “<article-title>Spatial and Temporal Scales of Neuronal Correlation in Primary Visual Cortex</article-title>.” In: <source>The Journal of Neuroscience</source> <volume>28</volume>.<issue>48</issue> (<month>Nov.</month> <year>2008</year>), pp. <fpage>12591</fpage>–<lpage>12603</lpage>. issn: <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/jneurosci.2929-08.2008</pub-id>.</mixed-citation></ref>
<ref id="c71"><label>[71]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Matthew A.</given-names> <surname>Smith</surname></string-name> and <string-name><given-names>Marc A.</given-names> <surname>Sommer</surname></string-name></person-group>. “<article-title>Spatial and Temporal Scales of Neuronal Correlation in Visual Area V4</article-title>.” In: <source>The Journal of Neuroscience</source> <volume>33</volume>.<issue>12</issue> (<month>Mar.</month> <year>2013</year>), pp. <fpage>5422</fpage>–<lpage>5432</lpage>. issn: <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/jneurosci.4782-12.2013</pub-id>.</mixed-citation></ref>
<ref id="c72"><label>[72]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Robert</given-names> <surname>Rosenbaum</surname></string-name> <etal>et al.</etal></person-group> “<article-title>The spatial structure of correlated neuronal variability</article-title>.” In: <source>Nature Neuroscience</source> <volume>20</volume>.<issue>1</issue> (<month>Oct.</month> <year>2016</year>), pp. <fpage>107</fpage>–<lpage>114</lpage>. issn: <issn>1546-1726</issn>. doi: <pub-id pub-id-type="doi">10.1038/nn.4433</pub-id>.</mixed-citation></ref>
<ref id="c73"><label>[73]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Douglas A</given-names> <surname>Ruff</surname></string-name> and <string-name><given-names>Marlene R</given-names> <surname>Cohen</surname></string-name></person-group>. “<article-title>Attention can either increase or decrease spike count correlations in visual cortex</article-title>.” In: <source>Nature Neuroscience</source> <volume>17</volume>.<issue>11</issue> (<month>Oct.</month> <year>2014</year>), pp. <fpage>1591</fpage>–<lpage>1597</lpage>. issn: <issn>1546-1726</issn>. doi: <pub-id pub-id-type="doi">10.1038/nn.3835</pub-id>.</mixed-citation></ref>
<ref id="c74"><label>[74]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>James H.</given-names> <surname>Marshel</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Functional Specialization of Seven Mouse Visual Cortical Areas</article-title>.” In: <source>Neuron</source> <volume>72</volume>.<issue>6</issue> (<month>Dec.</month> <year>2011</year>), pp. <fpage>1040</fpage>–<lpage>1054</lpage>. issn: <issn>0896-6273</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2011.12.004</pub-id>.</mixed-citation></ref>
<ref id="c75"><label>[75]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mark L.</given-names> <surname>Andermann</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Functional Specialization of Mouse Higher Visual Cortical Areas</article-title>.” In: <source>Neuron</source> <volume>72</volume>.<issue>6</issue> (<month>Dec.</month> <year>2011</year>), pp. <fpage>1025</fpage>–<lpage>1039</lpage>. issn: <issn>0896-6273</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2011.11.013</pub-id>.</mixed-citation></ref>
<ref id="c76"><label>[76]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. M.</given-names> <surname>Roth</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Helmchen</surname></string-name>, and <string-name><given-names>B. M.</given-names> <surname>Kampa</surname></string-name></person-group>. “<article-title>Distinct Functional Properties of Primary and Posteromedial Visual Area of Mouse Neocortex</article-title>.” In: <source>Journal of Neuroscience</source> <volume>32</volume>.<issue>28</issue> (July <year>2012</year>), pp. <fpage>9716</fpage>–<lpage>9726</lpage>. issn: <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/jneurosci.0110-12.2012</pub-id>.</mixed-citation></ref>
<ref id="c77"><label>[77]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Inbal</given-names> <surname>Ayzenshtat</surname></string-name>, <string-name><given-names>Jesse</given-names> <surname>Jackson</surname></string-name>, and <string-name><given-names>Rafael</given-names> <surname>Yuste</surname></string-name></person-group>. “<article-title>Orientation Tuning Depends on Spatial Frequency in Mouse Visual Cortex</article-title>.” <source>eneuro</source> <volume>3</volume>.<issue>5</issue> (<month>Sept.</month> <year>2016</year>), <elocation-id>ENEURO.0217–16.2016</elocation-id>. issn: <issn>2373-2822</issn>. doi: <pub-id pub-id-type="doi">10.1523/eneuro.0217-16.2016</pub-id>.</mixed-citation></ref>
<ref id="c78"><label>[78]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mari Ganesh</given-names> <surname>Kumar</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Functional parcellation of mouse visual cortex using statistical techniques reveals response-dependent clustering of cortical processing areas</article-title>.” In: <source>PLOS Computational Biology</source> <volume>17</volume>.<issue>2</issue> (<month>Feb.</month> <year>2021</year>). <fpage>e1008548</fpage>. issn: <issn>1553-7358</issn>. doi: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1008548</pub-id>.</mixed-citation></ref>
<ref id="c79"><label>[79]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Nicholas A</given-names> <surname>Steinmetz</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Challenges and opportunities for large-scale electrophysiology with Neuropixels probes</article-title>.” In: <source>Current Opinion in Neurobiology</source> <volume>50</volume> (June <year>2018</year>), pp. <fpage>92</fpage>–<lpage>100</lpage>. issn: <issn>0959-4388</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.conb.2018.01.009</pub-id>.</mixed-citation></ref>
<ref id="c80"><label>[80]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H</given-names> <surname>Sebastian Seung</surname></string-name></person-group>. “<article-title>Neuroscience: Towards functional connectomics</article-title>.” en. In: <source>Nature</source> <volume>471</volume>.<issue>7337</issue> (<month>Mar.</month> <year>2011</year>), pp. <fpage>170</fpage>–<lpage>172</lpage>.</mixed-citation></ref>
<ref id="c81"><label>[81]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Eve</given-names> <surname>Marder</surname></string-name> and <string-name><given-names>Dirk</given-names> <surname>Bucher</surname></string-name></person-group>. “<article-title>Understanding circuit dynamics using the stomatogastric nervous system of lobsters and crabs</article-title>.” en. In: <source>Annu. Rev. Physiol</source>. <volume>69</volume>.<issue>1</issue> (<year>2007</year>), pp. <fpage>291</fpage>–<lpage>316</lpage>.</mixed-citation></ref>
<ref id="c82"><label>[82]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>John</given-names> <surname>Lisman</surname></string-name>, <string-name><given-names>Howard</given-names> <surname>Schulman</surname></string-name>, and <string-name><given-names>Hollis</given-names> <surname>Cline</surname></string-name></person-group>. “<article-title>The molecular basis of CaMKII function in synaptic and behavioural memory</article-title>.” In: <source>Nature Reviews Neuroscience</source> <volume>3</volume>.<issue>3</issue> (<month>Mar.</month> <year>2002</year>), pp. <fpage>175</fpage>–<lpage>190</lpage>. issn: <issn>1471-0048</issn>. doi: <pub-id pub-id-type="doi">10.1038/nrn753</pub-id>.</mixed-citation></ref>
<ref id="c83"><label>[83]</label><mixed-citation publication-type="software"><person-group person-group-type="author"><collab>Allen Institute for Brain Science</collab></person-group>. <source>AllenSDK</source>. <year>2019</year>. url: <ext-link ext-link-type="uri" xlink:href="https://allensdk.readthedocs.io/en/latest/">https://allensdk.readthedocs.io/en/latest/</ext-link>.</mixed-citation></ref>
<ref id="c84"><label>[84]</label><mixed-citation publication-type="data"><person-group person-group-type="author"><collab>Allen Institute MindScope Program</collab></person-group>. <source>Allen Brain Observatory – Neuropixels Visual Coding [dataset]</source>. <year>2019</year>. url: <ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/explore/circuits">https://portal.brain-map.org/explore/circuits</ext-link>.</mixed-citation></ref>
<ref id="c85"><label>[85]</label><mixed-citation publication-type="report"><person-group person-group-type="author"><collab>Allen Institute MindScope Program</collab></person-group>. <source>Allen Brain Observatory – Neuropixels Visual Coding</source>. <publisher-name>Allen Institute for Brain Science</publisher-name> <year>2019</year>. url: <ext-link ext-link-type="uri" xlink:href="https://brainmapportal-live-4cc80a57cd6e400d854-f7fdcae.divio-media.net/filer_public/80/75/8075a100-ca64-429a-b39a-569121b612b2/neuropixels_visual_coding_-_white_paper_v10.pdf">https://brainmapportal-live-4cc80a57cd6e400d854-f7fdcae.divio-media.net/filer_public/80/75/8075a100-ca64-429a-b39a-569121b612b2/neuropixels_visual_coding_-_white_paper_v10.pdf</ext-link>.</mixed-citation></ref>
<ref id="c86"><label>[86]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Quanxin</given-names> <surname>Wang</surname></string-name> <etal>et al.</etal></person-group> “<article-title>The Allen Mouse Brain Common Coordinate Framework: A 3D Reference Atlas</article-title>.” In: <source>Cell</source> <volume>181</volume>.<issue>4</issue> (May <year>2020</year>), <fpage>936</fpage>–<lpage>953.e20.</lpage> issn: <issn>0092-8674</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.cell.2020.04.007</pub-id>.</mixed-citation></ref>
<ref id="c87"><label>[87]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F.</given-names> <surname>Pedregosa</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Scikit-learn: Machine Learning in Python</article-title>.” In: <source>Journal of Machine Learning Research</source> <volume>12</volume> (<year>2011</year>), pp. <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation></ref>
<ref id="c88"><label>[88]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Pauli</given-names> <surname>Virtanen</surname></string-name> <etal>et al.</etal></person-group> “<article-title>SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python</article-title>.” In: <source>Nature Methods</source> <volume>17</volume> (<year>2020</year>), pp. <fpage>261</fpage>–<lpage>272</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id>.</mixed-citation></ref>
<ref id="c89"><label>[89]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Denker</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Yegenoglu</surname></string-name>, and <string-name><given-names>S.</given-names> <surname>Grün</surname></string-name></person-group>. “<article-title>Collaborative HPC-enabled workflows on the HBP Collaboratory using the Elephant framework</article-title>.” In: <source>Neuroinformatics</source> <volume>2018</volume>. <year>2018</year>, <fpage>P19</fpage>. doi: <pub-id pub-id-type="doi">10.12751/incf.ni2018.0019</pub-id>. url: <ext-link ext-link-type="uri" xlink:href="https://abstracts.g-node.org/conference/NI2018/abstracts#/uuid/023bec4e-0c35-4563-81ce-2c6fac282abd">https://abstracts.g-node.org/conference/NI2018/abstracts#/uuid/023bec4e-0c35-4563-81ce-2c6fac282abd</ext-link>.</mixed-citation></ref>
<ref id="c90"><label>[90]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>James</given-names> <surname>Bergstra</surname></string-name>, <string-name><given-names>Daniel</given-names> <surname>Yamins</surname></string-name>, and <string-name><given-names>David D.</given-names> <surname>Cox</surname></string-name></person-group>. “<article-title>Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures</article-title>.” In: <source>Proceedings of the 30th International Conference on Machine Learning (ICML 2013)</source>. June <year>2013</year>, pp. <fpage>I-115</fpage>–<lpage>I-123</lpage>.</mixed-citation></ref>
<ref id="c91"><label>[91]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>Nitesh V.</given-names> <surname>Chawla</surname></string-name> <etal>et al.</etal></person-group> “<chapter-title>SMOTE: Synthetic Minority Over-sampling Technique</chapter-title>.” In: <conf-name>Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining (KDD 2002)</conf-name>. <publisher-name>ACM</publisher-name>. <year>2002</year>, pp. <fpage>106</fpage>–<lpage>113</lpage>.</mixed-citation></ref>
<ref id="c92"><label>[92]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Aaron</given-names> <surname>Fisher</surname></string-name>, <string-name><given-names>Cynthia</given-names> <surname>Rudin</surname></string-name>, and <string-name><given-names>Francesca</given-names> <surname>Dominici</surname></string-name></person-group>. “<article-title>All Models are Wrong, but Many are Useful: Learning a Variable’s Importance by Studying an Entire Class of Prediction Models Simultaneously</article-title>.” <source>arXiv</source> (<year>2018</year>). doi: <pub-id pub-id-type="doi">10.48550/ARXIV.1801.01489</pub-id>. url: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1801.01489">https://arxiv.org/abs/1801.01489</ext-link>.</mixed-citation></ref>
<ref id="c93"><label>[93]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Gorodkin</surname></string-name></person-group>. “<article-title>Comparing two K-category assignments by a K-category correlation coefficient</article-title>.” In: <source>Computational Biology and Chemistry</source> <volume>28</volume>.<issue>5–6</issue> (<month>Dec.</month> <year>2004</year>), pp. <fpage>367</fpage>–<lpage>374</lpage>. issn: <issn>1476-9271</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.compbiolchem.2004.09.006</pub-id>.</mixed-citation></ref>
<ref id="c94"><label>[94]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Douglas</given-names> <surname>Bates</surname></string-name> <etal>et al.</etal></person-group> “<article-title>Fitting Linear Mixed-Effects Models Using lme4</article-title>.” In: <source>Journal of Statistical Software</source> <volume>67</volume>.<issue>1</issue> (<year>2015</year>), pp. <fpage>1</fpage>–<lpage>48</lpage>. doi: <pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101506.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Sharpee</surname>
<given-names>Tatyana O</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Salk Institute for Biological Studies</institution>
</institution-wrap>
<city>La Jolla</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>This article reports a <bold>useful</bold> set of findings on how electrophysiological response properties of neurons correlate with their position in the brain. The evidence currently remains <bold>incomplete</bold>, with reviewers making specific suggestions for how clustering needs to be redone. The manuscript would also benefit from a more focused presentation of results and the removal of incorrect claims about recording biases.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101506.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The paper by Tolossa et al. presents classification studies that aim to predict the anatomical location of a neuron from the statistics of its in-vivo firing pattern. They study two types of statistics (ISI distribution, PSTH) and try to predict the location at different resolutions (region, subregion, cortical layer).</p>
<p>Strengths:</p>
<p>This paper provides a systematic quantification of the single-neuron firing vs location relationship.</p>
<p>The quality of the classification setup seems high.</p>
<p>The paper uncovers that, at the single neuron level, the firing pattern of a neuron carries some information on the neuron's anatomical location, although the predictive accuracy is not high enough to rely on this relationship in most cases.</p>
<p>Weaknesses:</p>
<p>As the authors mention in the Discussion, it is not clear whether the observed differences in firing are epiphenomenal. If the anatomical location information is useful to the neuron, to what extent can this be inferred from the vicinity of the synaptic site, based on the neurotransmitter and neuromodulator identities? Why would the neuron need to dynamically update its prediction of the anatomical location of its pre-synaptic partner based on activity when that location is static, and if that information is genetically encoded in synaptic proteins, etc (e.g., the type of the synaptic site)? Note that the neuron does not need to classify all possible locations to guess the location of its pre-synaptic partner because it may only receive input from a subset of locations. If an argument on activity-based estimation being more advantageous to the neuron than synaptic site-based estimation cannot be made, I believe limiting the scope of the paper (e.g., in the Introduction) to an epiphenomenal observation and its quantification will improve the scientific quality.Life Assessment</p>
<p>This article reports a useful set of findings on how electrophysiological response properties of neurons correlate with their position in the brain. The evidence currently remains incomplete, with reviewers making specific suggestions for how clustering needs to be redone. The manuscript would also benefit from a more focused presentation of results and the removal of incorrect claims about recording biases.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101506.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this manuscript, Tolossa et al. analyze Inter-spike intervals from various freely available datasets from the Allen Institute and from a dataset from Steinmetz et al. They show that they can modestly decode between gross brain regions (Visual vs. Hippocampus vs. Thalamus), and modestly separate sub-areas within brain regions (DG vs. CA1 or various visual brain areas).</p>
<p>Strengths:</p>
<p>The paper is reasonably well written, and the definitions are quite well done. For example, the authors clearly explained transductive vs. inductive inference in their decoders. E.g., transductive learning allows the decoder to learn features from each animal, whereas inductive inference focuses on withheld animals and prioritizes the learning of generalizable features.</p>
<p>Weaknesses:</p>
<p>However, even with some of these positive aspects, I still found the manuscript to be a laundry list of results, where some results are overly explained and not particularly compelling or interesting, whereas interesting results are not strongly described or emphasized. The overall problem is that the study is not cohesive, and the authors need to either come up with a tool or demonstrate a scientific finding. The current version attempts to split the middle and thus is not as impactful as it could be.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101506.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Tolossa</surname>
<given-names>Gemechu B</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6405-2908</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Schneider</surname>
<given-names>Aidan M</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8774-2303</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Dyer</surname>
<given-names>Eva L</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hengen</surname>
<given-names>Keith B</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5017-4090</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>Summary:</p>
<p>The paper by Tolossa et al. presents classification studies that aim to predict the anatomical location of a neuron from the statistics of its in-vivo firing pattern. They study two types of statistics (ISI distribution, PSTH) and try to predict the location at different resolutions (region, subregion, cortical layer).</p>
<p>Strengths:</p>
<p>This paper provides a systematic quantification of the single-neuron firing vs location relationship.</p>
<p>The quality of the classification setup seems high.</p>
<p>The paper uncovers that, at the single neuron level, the firing pattern of a neuron carries some information on the neuron's anatomical location, although the predictive accuracy is not high enough to rely on this relationship in most cases.</p>
</disp-quote>
<p>Thank you for your thoughtful feedback. The level of predictive accuracy offered by our current approach, while far above chance, is insufficient for electrode localization in most cases. Although, we speculate that our results represent a lower limit on possible performance—future improvements are almost certain as larger datasets are generated, more diverse features of neural activity are employed, and more advanced ML tools are implemented. We note that the current performance indicates a far more reliable embedding of anatomy in spiking than precedented by the modest statistical significance previously described in the literature. It would have been impossible to achieve this without the tremendous resources provided by the Allen Institute. In our revision, we will clarify that major performance improvements are both possible and probable.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>As the authors mention in the Discussion, it is not clear whether the observed differences in firing are epiphenomenal. If the anatomical location information is useful to the neuron, to what extent can this be inferred from the vicinity of the synaptic site, based on the neurotransmitter and neuromodulator identities? Why would the neuron need to dynamically update its prediction of the anatomical location of its pre-synaptic partner based on activity when that location is static, and if that information is genetically encoded in synaptic proteins, etc (e.g., the type of the synaptic site)? Note that the neuron does not need to classify all possible locations to guess the location of its pre-synaptic partner because it may only receive input from a subset of locations.  If an argument on activity-based estimation being more advantageous to the neuron than synaptic site-based estimation cannot be made, I believe limiting the scope of the paper (e.g., in the Introduction) to an epiphenomenal observation and its quantification will improve the scientific quality.</p>
</disp-quote>
<p>Summarily, in response to the two reviewers, we will minimize our discussion of this question in the revision. However, given that our results are either epiphenomenal or functional, we feel that it is important to indicate these possibilities, even if this indication is succinct and conservative.</p>
<p>In pursuit of a more concise revision, we will not expand our discussion to accommodate this interesting conversation with the reviewer, but we are excited to briefly offer our perspective here.</p>
<p>Regarding the epiphenomenal nature of our observations: this is a complex question that would be challenging but not impossible to validate experimentally. It has been previously established that neurons, especially those that integrate inputs from a variety of regions and are involved in diverse functions, could benefit from mechanisms for dynamically parsing inputs (Gutig, Sompolinsky 2006). Neurotransmitter and neuromodulator identities may indeed convey some information about presynaptic neuron location (e.g., NE may originate from the locus coeruleus). However, hypothetically, the binding of a neurotransmitter only bears on the postsynaptic neuron via ionic current, or second messenger activity. Postsynaptic neurons do not consume or otherwise endocytose the neurotransmitter, thus the ability of a neuron to “know” the presynaptic identity is a function of induced postsynaptic activity. Certainly, there are multiple streams of information that can provide insight into anatomical location all taking the ultimate form of neural activity and membrane dynamics. This would be broadly consistent with (for example) reward prediction error which is evident in dopamine release, firing rates, spiking patterns, and oscillatory rhythms.</p>
<p>We could imagine a possible role for the embedding of location in spiking patterns. It is important to note that many neurons in neighboring areas share common neurotransmitters (e.g., glutamate, GABA). Neurons receiving input from multiple regions with similar neurotransmitter profiles could benefit from additional information in the spiking patterns for distinguishing input sources, especially for multimodal integration. For instance, an inferior parietal lobule neuron or microcircuit could be downstream from both auditory cortex (listening) and Broca’s area (speaking). Imagine an individual is in a crowded coffee shop waiting for their drink order to be called while speaking to their friend. In this scenario, it may be important to recognize region-specific activity and thus selectively attend to it. Thus, it is unlikely that neurons actively update a “location prediction,” but rather that location-related information is passively embedded in spike patterning and this might be dynamically leveraged in computation. We emphasize that this is a simplified conceptual example and not a hypothesis that we test in the paper. This conversation, however, is a wonderful example of the thought experiments that we hope will grow from this type of work.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>Summary:</p>
<p>In this manuscript, Tolossa et al. analyze Inter-spike intervals from various freely available datasets from the Allen Institute and from a dataset from Steinmetz et al. They show that they can modestly decode between gross brain regions (Visual vs. Hippocampus vs. Thalamus), and modestly separate sub-areas within brain regions (DG vs. CA1 or various visual brain areas).</p>
<p>Strengths:</p>
<p>The paper is reasonably well written, and the definitions are quite well done. For example, the authors clearly explained transductive vs. inductive inference in their decoders. E.g., transductive learning allows the decoder to learn features from each animal, whereas inductive inference focuses on withheld animals and prioritizes the learning of generalizable features.</p>
</disp-quote>
<p>Thank you!</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>However, even with some of these positive aspects, I still found the manuscript to be a laundry list of results, where some results are overly explained and not particularly compelling or interesting, whereas interesting results are not strongly described or emphasized. The overall problem is that the study is not cohesive, and the authors need to either come up with a tool or demonstrate a scientific finding. The current version attempts to split the middle and thus is not as impactful as it could be</p>
</disp-quote>
<p>In our revision, we will endeavor to present our results in line with your suggestions. Thank you for the careful and thorough feedback that will improve the readability of our manuscript. We strove to be complete in establishing the logic leading to our ultimate finding—that a robust code for anatomical location can be extracted from single neuron spike trains, but not from more traditional descriptions of neural activity. Our detection of this code, albeit not perfect in performance, is, in most cases, both far above chance levels and is robust to animal identity and laboratory of origin. Our presentation of these results is cohesive in as much as we sequentially establish a series of results that build towards a concluding set of experiments. We start by establishing a baseline via standard measurements and then explore more challenging problems through more complex models that build toward our final test.  Based on your feedback, we will contract and expand elements of this sequence.</p>
<p>While our findings raise the possibility of developing a computational tool for electrode localization, pending additional features and/or datasets, our current focus is on establishing the neurobiological principle of anatomical embedding in spike trains. The purpose of briefly mentioning a possible application is that we hope to encourage those engaged in machine-learning on multi-modal neural data that this problem is tractable, yet still open. Based on your feedback, we will clarify that the focus of our current work is not an introduction of a new tool.</p>
</body>
</sub-article>
</article>