<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">106694</article-id>
<article-id pub-id-type="doi">10.7554/eLife.106694</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106694.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Trial-level Representational Similarity Analysis</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5494-925X</contrib-id>
<name>
<surname>Huang</surname>
<given-names>Shenyang</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Howard</surname>
<given-names>Cortney M</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bogdan</surname>
<given-names>Paul C</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Morales-Torres</surname>
<given-names>Ricardo</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Slayton</surname>
<given-names>Matthew</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cabeza</surname>
<given-names>Roberto</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5943-0756</contrib-id>
<name>
<surname>Davis</surname>
<given-names>Simon W</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<email>simon.davis@duke.edu</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Psychology &amp; Neuroscience, Duke University</institution></institution-wrap>, <city>Durham</city>, <country country="US">United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Neurology, Duke University School of Medicine</institution></institution-wrap>, <city>Durham</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Schapiro</surname>
<given-names>Anna C</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>*</label><p>These authors contributed equally; order was decided based on a coin flip.</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-06-06">
<day>06</day>
<month>06</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP106694</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-03-27">
<day>27</day>
<month>03</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-04-01">
<day>01</day>
<month>04</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.03.27.645646"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Huang et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Huang et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-106694-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Neural representation refers to the brain activity that stands in for one’s cognitive experience, and in cognitive neuroscience, the principal method to studying neural representations is representational similarity analysis (RSA). The classic RSA (cRSA) approach examines the overall quality of representations across numerous items by assessing the correspondence between two representational similarity matrices (RSMs): one based on a theoretical model of stimulus similarity and the other based on similarity in measured neural data. However, because cRSA cannot model representation at the level of individual trials, it is fundamentally limited in its ability to assess subject-, stimulus-, and trial-level variances that all influence representation. Here, we formally introduce trial-level RSA (tRSA), an analytical framework that estimates the strength of neural representation for singular experimental trials and evaluates hypotheses using multi-level models. First, we verified the correspondence between tRSA and cRSA in quantifying the overall representation strength across all trials. Second, we compared the statistical inferences drawn from both approaches using simulated data that reflected a wide range of scenarios. Compared to cRSA, the multi-level framework of tRSA was both more theoretically appropriate and significantly sensitive to true effects. Third, using real fMRI datasets, we further demonstrated several issues with cRSA, to which tRSA was more robust. Finally, we presented some novel findings of neural representations that could only be assessed with tRSA and not cRSA. In summary, tRSA proves to be a robust and versatile analytical approach for cognitive neuroscience and beyond.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Since the start of any systematic examination of the mind, the concept of <italic>representation</italic> has provided a link between the external world and the content of mental life (<xref ref-type="bibr" rid="c16">Brentano, 1874</xref>). Current perspectives in cognitive science have defined representations as brain activity patterns that convey some behaviorally relevant content, which could be sensory perception, memory, concept knowledge, or social relations (<xref ref-type="bibr" rid="c55">Kriegeskorte &amp; Diedrichsen, 2019</xref>). One of the central approaches for evaluating information represented in the brain is representational similarity analysis (RSA), an analytical approach that queries the representational geometry of the brain in terms of its alignment with the representational geometry of some cognitive model (<xref ref-type="bibr" rid="c57">Kriegeskorte et al., 2008</xref>; <xref ref-type="bibr" rid="c56">Kriegeskorte &amp; Kievit, 2013</xref>). The RSA approach has demonstrated utility across many domains of cognitive neuroscience research, such as visual perception (<xref ref-type="bibr" rid="c49">Jozranjbar et al., 2023</xref>), episodic memory (<xref ref-type="bibr" rid="c100">Xue, 2018</xref>), concept knowledge (<xref ref-type="bibr" rid="c12">Bauer &amp; Just, 2019</xref>), social information (<xref ref-type="bibr" rid="c34">Freeman et al., 2018</xref>), and cognitive control (Freund, Etzel, et al., 2021). Despite its proven success, we argue that the classic RSA approach, henceforth cRSA, has several limitations in efficacy across various experimental scenarios, due to its inability to reflect the proper multi-level variance structure within the data. In this paper, we present an advancement termed trial-level RSA, or tRSA.</p>
<p>In cognitive neuroscience, cRSA is most commonly implemented to evaluate the representational geometry of a neural system by comparing it to some model of cognition. A typical implementation of cRSA involves four main steps (see <xref rid="fig1" ref-type="fig">Figure 1</xref>). First, brain activity responses to a series of <italic>N</italic> trials are compared against each other (typically using correlation distance, or 1 - Pearson’s r) to form an <italic>N×N</italic> representational similarity matrix, or RSM<sub>brain</sub>.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Representational Similarity Analysis (RSA).</title>
<p>Steps for classic RSA (cRSA) and trial-level RSA (tRSA). <bold>A)</bold> Neural Representational Similarity Matrix (RSM<sub>brain</sub>) is generated by correlating multi-voxel activity patterns across all trials within a Region of Interest (ROI), reflecting similarity between neural responses. <bold>B)</bold> Model Representational Similarity Matrix (RSM<sub>model</sub>) is constructed by correlating of-interest stimulus properties across all trials. <bold>C)</bold> First-Level cRSA (top) and tRSA (bottom). For cRSA, the lower triangular parts (black outline) of RSM<sub>brain</sub> and RSM<sub>model</sub> are compared, producing a single summary statistic (e.g., Spearman’s rho) across all trials. For tRSA, representational similarity values from RSM<sub>brain</sub> and RSM<sub>model</sub> for the same trial (e.g., tennis ball; red dashed outline) are compared, producing a single representational strength estimate for that trial. <bold>D)</bold> Second-Level analysis for cRSA and tRSA. In cRSA, subject-level r values are submitted to a one-sample t-test to assess whether the values reliably exceed zero. In tRSA, a linear random effects model with random effects for subject and stimulus is fit, and hypothesis testing determines whether the estimated intercept is significantly greater than zero.</p></caption>
<graphic xlink:href="645646v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Second, a hypothesis of how this brain system ought to respond — a cognitive model — is created in the form of a model RSM, or RSM<sub>model</sub>. This RSM<sub>model</sub> can be created based on objective features of the stimuli (e.g., image brightness, category membership), subject ratings or behaviors (e.g., pleasantness, memory success), or outputs from computational models (e.g., neuron activations in artificial neural networks, semantic embeddings from large language models). Third, values from the lower (or equivalently, upper) triangular parts of both RSM<sub>brain</sub> and RSM<sub>model</sub> are retrieved, vectorized, and compared. This RSM<sub>brain</sub>-RSM<sub>model</sub> comparison focuses on the similarity between the two representational geometries, which is typically measured by Spearman’s rank correlation (<xref ref-type="bibr" rid="c57">Kriegeskorte et al., 2008</xref>) but alternatives have also been proposed (<xref ref-type="bibr" rid="c15">Bobadilla-Suarez et al., 2020</xref>; <xref ref-type="bibr" rid="c27">Diedrichsen et al., 2021</xref>; <xref ref-type="bibr" rid="c95">Walther et al., 2016</xref>). This similarity measure is referred to as a first-level RSA score or <italic>representational strength</italic>.</p>
<p>Fourth, once the above procedures are completed for each subject and condition, the first-level measures of representation are submitted to a second-level hypothesis testing for statistical inferences — often using general linear models such as t-test and ANOVA. One notable feature of cRSA is that the representational geometries are compared to one another in their entireties in step 3, and this step produces as a single measure of representational strength collapsing across all experimental trials. In other words, cRSA estimates cannot be interpreted for specific experimental trials or stimuli; rather, they only reflect how strongly the studied neural system represents for the entire set of items, limiting the realm of possible research questions. Most critically, as trial-level information is collapsed in cRSA, multiple sources of variance become intractable, yet these ignored variances could render subsequent second-level analyses susceptible to erroneous inferences.</p>
<p>A behavioral or neural measure in a single experimental trial consists of meaningful variances from four distinct sources: <italic>condition-level</italic> (experimental task manipulations such as cognitive load and emotional valence)<italic>, subject-level</italic> (individual differences in perceptual acuity, prior knowledge, or other cognitive faculties)<italic>, stimulus-level</italic> (features of the stimuli with behavioral or neural relevance), and <italic>trial-level</italic> (physiological and nuisance variables affecting measurement). To explain the variance in this measure, the appropriate statistical model should reflect said multi-level variance structure. However, the cRSA approach only does so imperfectly with three major limitations, which we detail below.</p>
<p>First, the heterogeneity of subject- and/or condition-level variances in real datasets adversely impacts the sensitivity and reliability of cRSA. One of the fundamental assumptions of general linear models (step 4 of cRSA; see <xref rid="fig1" ref-type="fig">Figure 1D</xref>) is <italic>homoscedasticity</italic> or homogeneity of variance — that is, all residuals should have equal variance. This assumption is often violated in real datasets. The variance of first-level cRSA scores depends largely on the number of observations (see <xref rid="fig2" ref-type="fig">Figure 2</xref>), but this trial count can be highly variable across subjects or conditions, resulting in <italic>heteroscedasticity</italic>. This issue is prevalent in studies where trials are selected and grouped based on subject behavior, such as in memory or attention tasks. In those cases, treating cRSA scores obtained from 100 trials and those obtained from 20 trials as having equal variance would violate the homoscedasticity assumption and lead to unreliable results. One suggested remedy of the issue is equating the number of trials via random subsampling conditions with more trials (<xref ref-type="bibr" rid="c28">Dimsdale-Zucker &amp; Ranganath, 2018</xref>); however, this solution comes with the cost of not making full use of the rich information from those low-variance conditions and may not be ideal when the number of trials is highly unbalanced.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Trial count influences the reliability of correlations.</title>
<p>The spread of correlation estimates (y-axis) varies nonlinearly with the number of observations, or trial count (x-axis). Trial count ranges from 10 to 200 with increments of 1. For each trial count, observations were drawn from a bivariate normal distribution with the given ground truth Pearson correlation, and their empirical Pearson correlation coefficient was computed. Ten random samples were drawn for each trial count and ground truth combination. Both ground truth and estimated values in the scatter plots are Fisher-transformed (z).</p></caption>
<graphic xlink:href="645646v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Second, cRSA is unable to model stimulus-level variance. Most studies present subjects with a fixed set of stimuli, which are supposedly samples representative of some broader category. In this case, using cRSA brings about two issues. For one, stimuli can vary in a wealth of properties. Object images, for example, vary in terms of image complexity, concept frequency, and memorability, all of which can affect both behavior and neural activity in important and systematic ways (<xref ref-type="bibr" rid="c7">Bainbridge et al., 2017</xref>; <xref ref-type="bibr" rid="c41">Hovhannisyan et al., 2021</xref>; <xref ref-type="bibr" rid="c70">Naspi et al., 2021</xref>). To mitigate this issue, one might explicitly manipulate the distribution of relevant stimulus properties or cross-validate cRSA results on subsets of stimuli (Freund, Bugg, et al., 2021).</p>
<p>Nevertheless, neither solution could address the second issue, which is the fact that the same stimuli are presented to multiple subjects. To properly address this stimulus-level dependence in the data and generalize the results beyond the fixed stimulus set, one must model stimulus identity as random effects, for the very same reason subjects are specified as random effects (<xref ref-type="bibr" rid="c19">Chen et al., 2021</xref>; <xref ref-type="bibr" rid="c101">Yarkoni, 2022</xref>). However, this solution is not accessible for cRSA since its current implementation stipulates the collapsing of stimulus information across trials (step 3 of cRSA; see <xref rid="fig1" ref-type="fig">Figure 1C</xref>).</p>
<p>Third, cRSA is not well-suited for testing the influence of stimulus-level or trial-level properties on neural representations. For example, it may be desirable to explicitly test or control for how certain stimulus-level properties (e.g., memorability) or trial-level recordings (e.g., cardiac cycle, pupil dilation) affect neural representations (<xref ref-type="bibr" rid="c22">Critchley &amp; Garfinkel, 2018</xref>; <xref ref-type="bibr" rid="c91">van der Wel &amp; van Steenbergen, 2018</xref>). One strategy to analyze the effects of those stimulus- or trial-level continuous variables is to discretize them into categories (e.g., low vs. medium vs. high); however, discretization inevitably leads to a loss of information, reduced statistical power, and potentially misleading outcomes (<xref ref-type="bibr" rid="c20">Cohen, 1983</xref>; <xref ref-type="bibr" rid="c63">MacCallum et al., 2002</xref>). Alternatively, one could construct additional RSMs for the covariates and then compare all RSMs using a partial correlation or multiple regression framework, yet the statistical interpretations become much less straightforward after the conversion. For instance, even though a univariate random variable <italic>v</italic>, such as pleasantness ratings, can be conveniently converted to an RSM using pairwise distance metrics (<xref ref-type="bibr" rid="c96">Weaverdyck et al., 2020</xref>), the very same RSM would also be derived from the opposite random variable −<italic>v</italic>, leaving uncertain of the directionality of any findings with the RSM (see also <xref ref-type="bibr" rid="c8">Bainbridge &amp; Rissman, 2018</xref>).</p>
<p>Here, we propose an original method for evaluating the neural representation of information at the level of individual experimental trials: <italic>trial-level RSA</italic> or <italic>tRSA</italic>. In this approach, instead of deriving a single measure of the similarity between RSM<sub>model</sub> and RSM<sub>brain</sub>, we compute a series of similarity measures on a trial-by-trial (row-by-row or column-by-column) basis (<xref ref-type="bibr" rid="c24">Davis et al., 2021</xref>). For instance, the representational strength in the first trial is calculated as the similarity between the first row of RSM<sub>model</sub> and the first row of RSM<sub>brain</sub> (see <xref rid="fig1" ref-type="fig">Figure 1C</xref>). We argue that our novel tRSA approach addresses all of the aforementioned limitations of cRSA: it can properly account for the multi-level variance structure in the data, affords generalizability beyond the fixed stimulus set, and allows one to test stimulus- or trial-level modulations of neural representations in a straightforward way. In this paper, we assessed the efficacy of tRSA in comparison with cRSA using data from simulations representing a wide range of possible experimental scenarios (Experiment 1) and data from an extant real fMRI study (Experiment 2). In both experiments, our results demonstrated enhanced sensitivity, robustness, and flexibility with analyzing neural representations using the tRSA approach.</p>
</sec>
<sec id="s2">
<title>Methods</title>
<sec id="s2a">
<title>Experiment 1: cRSA and tRSA comparisons in simulated data</title>
<p>Experiment 1 consisted of three main parts. First, we validated the similarity between tRSA and cRSA results in assessing the general representational strength across all trials. In other words, we established that tRSA can carry out the main purpose of cRSA. Second, we compared the statistical inferences generated by each approach in a set of synthetic within-subject studies with two conditions. Third, we demonstrated tRSA’s unique capability of assessing continuous modulators of representational strength in a set of synthetic scenarios. A host of parameters were varied to ensure the robustness of the comparisons in all three parts, such as the trial count, subject sample size, and effect size.</p>
<sec id="s2a1">
<title>Estimating overall representational strength</title>
<p>We first set out to validate that tRSA indeed measures <italic>representation</italic> similarly to cRSA, and we conducted a series of simulations to compare the estimates of RSM<sub>model</sub>-RSM<sub>brain</sub> similarity obtained from both methods. Assuming an experimental design with <italic>n</italic> = 200 trials, we sampled <italic>n</italic>(<italic>n</italic> − 1)/2 = 19900 pairs of values from a bivariate normal distribution, with their Pearson correlation fixed at some given value via the ‘MASS 7.3-60.2’ package (<xref ref-type="bibr" rid="c92">Venables et al., 2002</xref>) in R 4.4.1 (<xref ref-type="bibr" rid="c76">R Core Team, 2024</xref>). The two vectors were rearranged as the lower triangular part of two <italic>n</italic> × <italic>n</italic> matrices, and the upper triangular parts were filled out accordingly to yield two symmetric matrices <italic>M</italic> and <italic>S</italic>, with which we conducted both cRSA and tRSA. With cRSA, overall representational strength was estimated as the Fisher-transformed Pearson correlation coefficient of the lower triangular parts of the two matrices, which was always equal to the ground truth parameter <italic>z</italic>. With tRSA, the representational strength for a given trial <italic>i</italic> was computed as the Fisher-transformed Pearson correlation coefficient between two row vectors, <italic>M</italic><sub><italic>i</italic>·</sub> and <italic>S</italic><sub><italic>i</italic>·</sub>, barring entries on the diagonal (see <xref rid="fig1" ref-type="fig">Figure 1C, Bottom</xref>). The tRSA values for all trials were then averaged to yield an estimate of overall representational strength comparable to that from cRSA. Note that Fisher transformation of correlation coefficients was always applied such that the distribution of values is more approximately normal (<xref ref-type="bibr" rid="c87">Silver &amp; Dunlap, 1987</xref>). This set of procedures was repeated for 10,000 iterations, for each ground truth parameter <italic>z</italic> ranging from −0.2 to 0.6 with increments of 0.1.</p>
<p>To adhere to the mathematical constraints of correlation-based RSMs (i.e., positive semidefinite), we next simulated <italic>activity patterns</italic>, from which RSMs were derived. Specifically, assuming an experiment with <italic>n</italic> trials and <italic>q</italic> measurement channels (e.g., voxels), we sampled a set of <italic>n</italic> ⋅ <italic>q</italic> values from a univariate standard normal distribution N(0,1), and another set of <italic>n</italic> ⋅ <italic>q</italic> values from a univariate normal distribution N(0, <italic>σ</italic><sup>2</sup>). Both vectors were rearranged into matrices of <italic>n</italic> rows and <italic>q</italic> columns, yielding a <italic>ground truth activity</italic> pattern and a <italic>noise</italic> pattern. The summation of these two patterns yielded a <italic>measured</italic> pattern. Two RSMs were then generated from the ground truth pattern (RSM<sub>model</sub>) and the measured pattern (RSM<sub>brain</sub>) using Pearson’s correlation, with which cRSA and tRSA were conducted separately. This set of procedures was repeated for 10,000 iterations with different random samples. The following parameter values were used for reported results: <italic>q</italic> = 500, <italic>n</italic> ∈ {10, 15, 20, 25, 30, 40, 50, 100}, <italic>σ</italic><sup>2</sup> ranging from 0.8 to 2.0 with increments of 0.2.</p>
<p>We next assessed the correspondence between tRSA and cRSA in the presence of discrete conditions, which is often seen in real studies. Assuming a simple experimental design with two conditions, A and B, consisting of <italic>n</italic><sub><italic>A</italic></sub> and <italic>n</italic><sub><italic>B</italic></sub> trials, respectively, we generated a ground truth activity pattern with <italic>n</italic><sub><italic>A</italic></sub> + <italic>n</italic><sub><italic>B</italic></sub> rows and <italic>m</italic> columns in the same way as before. Then, we generated two noise patterns, which were controlled by parameters <italic>σ</italic><sub><italic>A</italic></sub> and <italic>σ</italic><sub><italic>B</italic></sub>, respectively, one for each condition. The measured pattern was again computed as the summation of ground truth and noise. cRSA was conducted separately for trials in each condition. Critically, tRSA was conducted in an <italic>across-condition</italic> fashion: we generated RSMs with all <italic>n</italic><sub><italic>A</italic></sub> + <italic>n</italic><sub><italic>B</italic></sub> trials, obtained <italic>n</italic><sub><italic>A</italic></sub> + <italic>n</italic><sub><italic>B</italic></sub> tRSA values as previously described, and then split the values into two sets based on the condition each trial belonged to. Finally, as before, we computed the average of tRSA values separately for Conditions A and B to allow comparisons with cRSA values. This set of procedures was repeated for 10,000 iterations with different random samples. We assessed the influence of three factors: sample size, balance, and noise level, with the following parameter values: <italic>q</italic> = 500, <italic>n</italic><sub><italic>A</italic></sub>, <italic>n</italic><sub><italic>B</italic></sub> ∈ {20,80,320}, <italic>σ</italic><sub><italic>A</italic></sub>, <italic>σ</italic><sub><italic>B</italic></sub> ∈ {1,2}.</p>
<p>Of note, tRSA could conceivably also be conducted in a <italic>within-condition</italic> fashion, whereby one would generate two separate sets of RSMs according to condition, i.e., one set of <italic>n</italic><sub><italic>A</italic></sub> × <italic>n</italic><sub><italic>A</italic></sub> RSMs for Condition A and another set of <italic>n</italic><sub><italic>B</italic></sub> × <italic>n</italic><sub><italic>B</italic></sub> RSMs for Condition B, and then compute the two sets of <italic>within-condition</italic> tRSA values separately. We hereby advocate for the use of <italic>across-condition</italic> tRSA — which we have used in previous studies (<xref ref-type="bibr" rid="c24">Davis et al., 2021</xref>; <xref ref-type="bibr" rid="c42">Howard et al., 2024</xref>; S. Huang, <xref ref-type="bibr" rid="c42">Howard, et al., 2024</xref>; <xref ref-type="bibr" rid="c71">Naspi et al., 2023</xref>) — over within-condition tRSA. Comparisons of the statistical properties of within-condition and across-condition tRSA approaches are discussed in <bold>Appendix 1</bold>.</p>
</sec>
<sec id="s2a2">
<title>Statistical inferences from tRSA and cRSA</title>
<sec id="s2a2a">
<title>Modeling discrete conditions</title>
<p>The essential theoretical advantage of tRSA over cRSA is that representational strength can be estimated at the level of experimental trials, which would allow us to properly capture the multi-level variance structure in the data. To demonstrate this benefit, four sources of variances were hypothesized: condition, subject, stimulus, and trial. Condition-level variance denotes the effect of experimental conditions or manipulations on representation, with each condition receiving its own noise-level parameter <italic>σ<sub>cond,k</sub></italic>. This is the focal effect of interest for this simulation.</p>
<p>Additionally, subject-level variance denotes individual differences in the quality of representation across <italic>m</italic> subjects, with each subject receiving one’s own noise-level parameter <italic>σ<sub>subj,i</sub></italic>. A within-subject design is common in real experiments and is thus assumed here, where each subject received all experimental conditions. Stimulus-level variance denotes the diversity of stimuli that may result in some being represented more strongly than others, with each stimulus receiving its own noise level parameter <italic>σ<sub>stim,j</sub></italic>. The subject-level and stimulus-level variances were fully crossed, i.e., all subjects were assumed to view all stimuli exactly once (condition counterbalanced) during the experiment. Finally, trial-level variance denotes random fluctuations in the signal across the experiment and is controlled by a single noise-level parameter <italic>σ<sub>trial</sub></italic>. Therefore, for a given event of subject <italic>i</italic> responding to stimulus <italic>j</italic> in condition <italic>k</italic>, we computed its noise level as:
<disp-formula>
<graphic xlink:href="645646v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Notably, this multi-level variance structure replaced the fixed noise parameters <italic>σ</italic><sub><italic>A</italic></sub>, <italic>σ</italic><sub><italic>B</italic></sub>, while all other procedures remained the same as the previous simulation. The entire set of procedures was repeated for 10,000 iterations. The base simulation parameters were as follows:
<list list-type="bullet">
<list-item><p>Experimental design: <italic>q</italic> = 500, <italic>m</italic> = 40, <italic>n</italic><sub><italic>A</italic></sub> = <italic>n</italic><sub><italic>B</italic></sub> = 100, and</p></list-item>
<list-item><p>Multi-level variance: <italic>σ<sub>cond</sub></italic> ∈ {1,1.2}, <italic>σ<sub>subj</sub></italic>∼ N(0, 0.5<sup>2</sup>), <italic>σ<sub>stim</sub></italic> ∼ N(0, 0.2<sup>2</sup>), <italic>σ<sub>trial</sub></italic> = 2.</p>
<p>To assess the robustness of RSA methods in different situations that could occur in real data, we introduced a number of variations to the base design:</p></list-item>
<list-item><p>Number of subjects: <italic>m</italic> ∈ {10, 20, 40, 80, 160, 320}.</p></list-item>
<list-item><p>Trial count per subject: <italic>n<sub>trial</sub></italic> ∈ {20, 30, 46, 70, 100, 250, 220, 330, 500}.</p></list-item>
<list-item><p>Trial count ratio: <italic>n</italic><sub><italic>A</italic></sub> ∈ {20, 40, 60, . . ., 180}, <italic>n</italic><sub><italic>B</italic></sub> = 200 − <italic>n</italic><sub><italic>A</italic></sub>.</p></list-item>
<list-item><p>Variance in trial count ratio across subjects: <italic>σ</italic><sub><italic>n</italic></sub> ∈ {0, 1, 2, 4, 8, 16, 32, 64, 128}. Actual trial counts were drawn from a truncated normal distribution, <italic>n</italic><sub><italic>A</italic></sub> ∼ <italic>truncN</italic>(100, <italic>σ</italic><sub><italic>n</italic></sub>, 10, 190), <italic>n</italic><sub><italic>B</italic></sub> = 200 − <italic>n</italic><sub><italic>A</italic></sub>.</p></list-item>
<list-item><p>Effect size: condition-level noise <italic>σ<sub>cond,A/B</sub></italic> ∈ {1.00, 1.05, 1.10, . . ., 1.30}. Greater differences in the condition-level noise correspond to larger condition effects.</p></list-item>
</list></p>
<p>Following data generation, condition-level representational strength was estimated using cRSA and trial-level representational strength was estimated using tRSA. We focused on the statistical inferences of the effect of conditions, namely <italic>b</italic><sub><italic>B</italic>−<italic>A</italic></sub>. To this end, cRSA estimates were submitted to a paired-sample t-test. Critically, tRSA estimates were submitted to a mixed-effects model that is theoretically appropriate for the multi-level variance structure in the data (<xref ref-type="bibr" rid="c5">Baayen et al., 2008</xref>; <xref ref-type="bibr" rid="c19">Chen et al., 2021</xref>). Specifically, a linear mixed-effects model with a fixed effect of condition and random effects of both subjects and stimuli were fitted to tRSA estimates via the ‘lme4 1.1-35.3’ package in R (<xref ref-type="bibr" rid="c11">Bates et al., 2015</xref>), and p-values were estimated using Satterthwaites’s method via the ‘lmerTest 3.1-3’ package (<xref ref-type="bibr" rid="c59">Kuznetsova et al., 2017</xref>).</p>
<p>Given data generated with <italic>σ<sub>cond,A</sub></italic> = <italic>σ<sub>cond,B</sub></italic>, the correct inference should be a failure to reject the null hypothesis of <italic>b</italic><sub><italic>B</italic>−<italic>A</italic></sub> = 0; any significant (<italic>p</italic> &lt; 0.05) result in either direction was considered a false positive or Type I error. Given data generated with <italic>σ<sub>cond,A</sub></italic> &gt; <italic>σ<sub>cond,B</sub></italic>, the inference was considered correct if it rejected the null hypothesis of <italic>b</italic><sub><italic>B</italic>−<italic>A</italic></sub> = 0 and yielded the expected sign of the estimated contrast (<italic>b</italic><sub><italic>B</italic>−<italic>A</italic></sub> &gt; 0). A significant result with the reverse sign of the estimated contrast (<italic>b</italic><sub><italic>B</italic>−<italic>A</italic></sub> &lt; 0) was considered a Type I error, and a nonsignificant (<italic>p</italic> ≥ 0.05) result was considered a false negative or Type II error. Error rates were computed for each RSA method and were compared against the null hypothesis of equal proportions between methods.</p>
</sec>
<sec id="s2a2b">
<title>Modeling continuous modulators</title>
<p>In addition to discrete experimental conditions, we also simulated data reflecting scenarios in which representational strength varies continuously with some modulator. For example, one may be interested in the effects of continuous variables such as image complexity and memorability (stimulus-level) or reaction time (trial-level). In this case, <italic>σ<sub>trial</sub></italic> was no longer a constant throughout the experiment but a trial-level variable. For a given event of subject <italic>i</italic> responding to stimulus <italic>j</italic> in trial <italic>k</italic>, we computed its noise level as:
<disp-formula>
<graphic xlink:href="645646v1_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
To capture the effect of this trial-level variable, we generated a random variable <italic>v<sub>measured</sub></italic> that reflects a trial-level measurement with construct validity <italic>r<sub>val</sub></italic> = Cor(<italic>v</italic><sub>measured</sub>, <italic>σ<sub>trial</sub></italic>), which was restricted to be a nonpositive value. When <italic>r<sub>val</sub></italic> = 0, <italic>r<sub>measured</sub></italic> carries no information of the underlying <italic>σ<sub>trial</sub></italic> and should not predict trial-level representational strength. When <italic>r<sub>val</sub></italic> &lt; 0, <italic>r<sub>measured</sub></italic> is inversely related to trial-level noise and should positively predict trial-level representational strength. The entire set of procedures was repeated for 10,000 iterations. The base simulation parameters were as follows:
<list list-type="bullet">
<list-item><p>Experimental design: <italic>q</italic> = 500, <italic>m</italic> = 40, <italic>n</italic> = 200, and</p></list-item>
<list-item><p>Variance structure: <italic>r<sub>val</sub></italic> ∈ {0, −0.1}, <italic>σ<sub>subj</sub></italic>∼ N(0, 0.5<sup>2</sup>), <italic>σ<sub>stim</sub></italic> ∼ N(0, 0.2<sup>2</sup>), <italic>σ<sub>trial</sub></italic> = 2. As before, we introduced a number of variations, as follows:</p></list-item>
<list-item><p>Number of subjects: <italic>m</italic> ∈ {10, 20, 40, 80, 160, 320}.</p></list-item>
<list-item><p>Number of trials per subject: <italic>n<sub>trial</sub></italic> ∈ {20, 30, 46, 70, 100, 250, 220, 330, 500}.</p></list-item>
<list-item><p>Variance in the number of trials per subject: <italic>σ</italic><sub><italic>n</italic></sub> ∈ {0, 20, 40, . . ., 160}. Actual trial counts were drawn from a truncated normal distribution, <italic>n</italic> ∼ <italic>truncN</italic>(<italic>n</italic>, <italic>σ</italic><sub><italic>n</italic></sub>, 20, <italic>n</italic>).</p></list-item>
<list-item><p>Effect size: <italic>r<sub>val</sub></italic> ∈ {−0.10, −0.09, . . ., 0.00}. More negative values of <italic>r<sub>val</sub></italic> should result in greater representational strength.</p></list-item>
</list>
Following data generation, two conditions were created for each subject based on a median split (A=low <italic>r<sub>measured</sub></italic>, B=high <italic>r<sub>measured</sub></italic>), and we tested cRSA and tRSA models as described in the previous simulation, focusing on <italic>b</italic><sub><italic>B</italic>−<italic>A</italic></sub>. Furthermore, we additionally modeled trial-level representational strength as a function of <italic>r<sub>measured</sub></italic> directly, using a linear mixed-effects model of tRSA estimates with a fixed effect of <italic>r<sub>measured</sub></italic> and random effects of both subjects and stimuli. Given data generated with <italic>r<sub>val</sub></italic> = 0, the correct inference should be a failure to reject the null hypothesis of <italic>b</italic> = 0 in both discrete and continuous models; any significant (<italic>p</italic> &lt; 0.05) result in either direction was considered a false positive or Type I error. Given data generated with <italic>r<sub>val</sub></italic> &lt; 0, the inference was considered correct if it rejected the null hypothesis of <italic>b</italic> = 0 and yielded the expected sign of the estimated contrast or slope <italic>b</italic> &gt; 0. A significant result with the reverse sign of the estimated contrast or slope (<italic>b</italic> &lt; 0) was considered a Type I error, and a nonsignificant (<italic>p</italic> ≥ 0.05) result was considered a false negative or Type II error. Error rates were computed for each RSA method and were compared against the null hypothesis of equal proportions between methods.</p>
</sec>
</sec>
</sec>
<sec id="s2b">
<title>Experiment 2: cRSA and tRSA comparisons in fMRI data</title>
<p>Experiment 2 proceeded in 3 steps. First, we assessed how the impact of subject-level variance in heterogeneity of trial ratios amongst two critical conditions (“Hits” and “Misses”) can lead to biased estimates of representational strength. Second, we examined the impact of modeling trial-level variance on both representational strength during Object Naming, as well as Mnemonic Strength during a memory retrieval task. Lastly, stimulus-level estimates of representational strength were related to object memorability — an analysis that is not directly accessible to cRSA.</p>
<sec id="s2b1">
<title>Data acquisition</title>
<sec id="s2b1a">
<title>Participants</title>
<p>A total of 38 adults, aged 18 to 30, participated in this study on a voluntary basis and received monetary compensation for their time. Eligibility criteria required participants to be native or fluent English speakers, with no history of significant neurological or psychiatric conditions, and not taking medications that could affect cognitive function or cerebral blood flow (except for antihypertensive agents). All participants provided written informed consent before the start of the study. Six participants did not complete the study and were excluded from the analysis.</p>
<p>Additionally, two participants were excluded from the Memory Retrieval analyses due to poor memory performance. The final sample included 32 participants (21 women and 11 men) for the Object Perception task and 30 participants (19 women and 11 men) for the Memory Retrieval task.</p>
</sec>
<sec id="s2b1b">
<title>Experimental design</title>
<p>An expansive outline of the study design for the tasks described below can be found in (S. Huang, Bogdan, et al., 2024); here we briefly review relevant details pertinent to our application of trial-level RSA for a subset of that data. Data from two experimental datasets were used, including an Object Perception dataset and a Memory dataset (<xref rid="fig7" ref-type="fig">Figures 7A</xref><bold> and </bold><xref rid="fig8" ref-type="fig">8A</xref>). In the Object Perception task, participants were shown images of 114 unique everyday objects on a white background. The corresponding label presented underneath each object and participants were asked to rate how well the label described the object on a four-point scale. The main purposes of this rating task was to make sure that participants assess the meaning of the objects and to verify that these objects are indeed familiar to them (mean rating = 3.59). The objects were presented for 4 seconds, followed by a jittered fixation cross with an average duration of 4 seconds. In the memory task, a Memory Encoding session took place at least 7 days after Object Perception. During Encoding, participants viewed images of 114 unique real-world scenes along with the 114 objects they had seen in session 1. In each trial, participants were shown a scene image for 3 seconds, followed by a jittered empty box indicating the continuation of the trial, which lasted for an average of 3 seconds, and finally an object image for 4 seconds. During the object presentation, participants rated “how likely it is to find the object in the scene” on a 4-point scale (1 = “very unlikely,” 2 = “somewhat unlikely,” 3 = “somewhat likely,” 4 = “very likely”). Each trial was separated by a jittered fixation cross with an average duration of 4 seconds. Memory Retrieval consisted of three scanning runs, each with 38 trials, lasting approximately 9 minutes and 12 seconds. Memory Retrieval took place one day after Memory Encoding and involved testing participants’ memory of the objects. In the main Memory Retrieval task, participants were presented with 144 labels of real-world objects, of which 114 were labels for previously seen objects and 30 were unrelated novel distractors. In a subsequent Perceptual Memory Retrieval task participants were shown 126 images of real-world objects (96 old images, 18 were different exemplar images of old objects, and 12 images of unrelated novel objects). Participants were asked to determine whether the image was old, similar, or new. All analyses in the current study pertained to fMRI data from Object Perception and the main Memory Retrieval tasks, as well as behavioral data from the Perceptual Memory Retrieval task.</p>
</sec>
<sec id="s2b1c">
<title>MRI data acquisition</title>
<p>MRI data were collected using a 3T GE MR750 Scanner equipped with an 8-channel head coil at the Brain Imaging and Analysis Center (BIAC) at Duke University. Each MRI session began with a localizer scan, during which 3-plane (straight axial/coronal/sagittal) faster spin echo images were obtained. A high-resolution T1-weighted (T1w) structural scan was then acquired, consisting of 96 axial slices parallel to the AC-PC plane, with voxel dimensions of 0.9 × 0.9 × 1.9 mm³. This was followed by blood-oxygenation-level-dependent (BOLD) functional scans using a whole-brain gradient-echo echo planar imaging sequence (repetition time = 2000 ms, echo time = 30 ms, field of view = 192 mm, 36 oblique slices with voxel dimensions of 3 x 3 x 3 mm³). Task instructions and stimuli were delivered using the PsychToolbox program (<xref ref-type="bibr" rid="c53">Kleiner et al., 2007</xref>) and projected onto a mirror at the back of the scanner bore. Participants responded using a four-button fiber-optic response box. To reduce scanner noise, participants wore earplugs, and MRI-compatible lenses were provided when necessary to correct vision. Foam padding was placed inside the head coil to minimize head movement.</p>
</sec>
</sec>
<sec id="s2b2">
<title>Data analysis</title>
<sec id="s2b2a">
<title>MRI data preprocessing</title>
<p>fMRIPrep 23.0.1 (<xref ref-type="bibr" rid="c29">Esteban et al., 2019</xref>, <xref ref-type="bibr" rid="c30">2023</xref>) was used to preprocess structural and functional MRI data, as well as generating text descriptions of preprocessing details, which were condensed below. T1w structural images collected across all MRI sessions for the same participant were corrected for intensity non-uniformity with ‘N4BiasFieldCorrection’ (<xref ref-type="bibr" rid="c89">Tustison et al., 2010</xref>) from ANTs 2.3.3 (<xref ref-type="bibr" rid="c4">Avants et al., 2011</xref>). The T1w-reference was skull-stripped with a Nipype implementation of the ‘antsBrainExtraction.sh’ workflow from ANTs, using OASIS30ANTs as target template. Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM), and gray-matter (GM) was performed on the brain-extracted T1w using ‘fast’ from FSL (<xref ref-type="bibr" rid="c103">Zhang et al., 2001</xref>). An anatomical T1w-reference map was computed after registration of T1w images using ‘mri_robust_templatè from FreeSurfer 7.3.2 (<xref ref-type="bibr" rid="c77">Reuter et al., 2010</xref>). Brain surfaces were reconstructed using ‘recon-all’ from FreeSurfer 7.3.2 (<xref ref-type="bibr" rid="c23">Dale et al., 1999</xref>), and the brain mask estimated previously was refined with a custom variation of the method to reconcile ANTs-derived and FreeSurfer-derived segmentations of the cortical gray-matter of Mindboggle (<xref ref-type="bibr" rid="c52">Klein et al., 2017</xref>). Volume-based spatial normalization to the ICBM 152 Nonlinear Asymmetrical template version 2009c standard space was performed through nonlinear registration with ‘antsRegistration’ from ANTs 2.3.3, using brain-extracted versions of both T1w reference and the T1w template.</p>
<p>BOLD functional data across all sessions and runs were preprocessed collectively. A reference volume and its skull-stripped version were generated using a custom methodology of fMRIPrep. Head-motion parameters with respect to the BOLD reference were estimated, followed by spatiotemporal filtering using ‘mcflirt’ from FSL (<xref ref-type="bibr" rid="c48">Jenkinson et al., 2002</xref>). BOLD runs were slice-time corrected to 0.972s (0.5 of slice acquisition range 0s-1.94s) using ‘3dTshift’ from AFNI (<xref ref-type="bibr" rid="c21">Cox &amp; Hyde, 1997</xref>). The BOLD time-series were resampled onto their original, native space by applying the transforms to correct for head-motion. The BOLD reference was then co-registered to the T1w reference using boundary-based registration via ‘bbregister’ from FreeSurfer (<xref ref-type="bibr" rid="c38">Greve &amp; Fischl, 2009</xref>). Co-registration was configured with six degrees of freedom. Confounding time-series calculated based on the preprocessed BOLD included: root mean square displacement (RMSD) between frames (<xref ref-type="bibr" rid="c48">Jenkinson et al., 2002</xref>), absolute sum of relative framewise displacement (FD) (<xref ref-type="bibr" rid="c74">Power et al., 2014</xref>), and the derivative of root mean square variance over voxels (DVARS) (<xref ref-type="bibr" rid="c74">Power et al., 2014</xref>), as well as global signals extracted within CSF, WM, and the whole-brain mask. Additionally, a set of physiological regressors were extracted to allow for component-based noise correction (CompCor) (<xref ref-type="bibr" rid="c14">Behzadi et al., 2007</xref>).</p>
<p>Principal components were estimated after high-pass filtering the preprocessed BOLD time-series (using a discrete cosine filter with 128s cut-off) for the two CompCor variants: temporal (tCompCor) and anatomical (aCompCor). tCompCor components were calculated from the top 2% variable voxels within the brain mask. For aCompCor, three probabilistic masks (CSF, WM and combined CSF+WM) were generated in anatomical space. For each CompCor decomposition, the k components with the largest singular values that cumulatively explained at least 50% of variance across the nuisance mask (CSF, WM, combined, or temporal) were retained. The BOLD time-series were resampled into standard space with a spatial resolution of 2 × 2 × 2 mm<sup>3</sup> or 97 × 115 × 97 voxels. First, a reference volume and its skull-stripped version were generated using a custom methodology of fMRIPrep. All resamplings can be performed with a single interpolation step by composing all the pertinent transformations (i.e., head-motion transform matrices, susceptibility distortion correction when available, and co-registrations to anatomical and output spaces). Gridded (volumetric) resamplings were performed using ‘antsApplyTransforms’ (ANTs), configured with Lanczos interpolation to minimize the smoothing effects of other kernels (<xref ref-type="bibr" rid="c61">Lanczos, 1964</xref>). Non-gridded (surface) resamplings were performed using ‘mri_vol2surf’ (FreeSurfer).</p>
</sec>
<sec id="s2b2b">
<title>Single-trial modeling</title>
<p>Neural activity in gray matter (GM) voxels for each object presentation event was estimated using first-level least squares separate general linear models (<xref ref-type="bibr" rid="c69">Mumford et al., 2012</xref>) constructed with SPM12 (<xref ref-type="bibr" rid="c37">Friston et al., 2006</xref>) and custom MATLAB scripts. Subject-specific GM masks were generated by binarizing the fMRIPrep-derived probabilistic masks with a threshold set to exclude voxels with 80% probability of CSF or WM. Each model included a regressor for the event of interest along with a regressor for all other objects. Both regressors were convolved with the canonical double-Gamma hemodynamic response function, including their temporal and dispersion derivatives to account for variations in the timing of the peak response.</p>
<p>Covariates of no interest included global signal, WM signal, CSF signal, FD, DVARS, RMSD, and six motion parameters related to translation and rotation. A high-pass temporal filter with a cutoff of 128 seconds was applied, and the AR(1) model was used to correct for autocorrelation. These first-level models yielded regression coefficients (betas) that estimated voxel-level neural activity corresponding to a single trial. Trials with FD greater than 1mm either before or during the trial were excluded (range: 0-28). Additionally, runs with more than 25% motion trials were excluded. In total, 1 Object Perception run, and 3 Memory Retrieval runs were excluded.</p>
</sec>
<sec id="s2b2c">
<title>Behavioral Analyses</title>
<p>Trials for which participants gave no response in the Object Perception (mean 5) or the main Memory Retrieval (mean 4) were excluded from all analyses involving fMRI data at Perception and Memory Retrieval tasks respectively. As our primary behavioral measure, we assessed the memory performance for the object labels. Participants demonstrated variability in their ability to distinguish between old and new objects, as well as in their decision criteria, making direct comparisons of raw responses challenging. To address these biases, we performed a receiver-operating characteristics (ROC) analysis using ‘yardstick 1.3.1’ (<xref ref-type="bibr" rid="c58">Kuhn et al., 2024</xref>) in R. This analysis allowed us to categorize Hit and Miss trials by determining whether counting only “4” responses or both “3” and “4” responses as “old” yielded the best decision outcome (i.e., closest to 100% true positive and 0% false positive). The outcome of this analysis was then used to compute the sensitivity index (d’) of recognition. Adjusted hit rates were used to determine adherence to the task and sufficient fMRI data during Memory Retrieval.</p>
<p>Behavioral analyses categorized each trial during Memory Retrieval as either a “Hit” or “Miss” for the purpose of categorizing the conditions in the fMRI data. This analysis determined whether counting only “4” responses or both “3” and “4” responses as “old” produced the most accurate decision outcome (i.e., closest to 100% true positive and 0% false positive). In total, data from 8 participants were adjusted to consider only “4” responses as “hit” trials. The results were then used to calculate the sensitivity index (d’) of recognition within each subjective congruency condition and the corrected hit rate. Participants with post-adjustment hit rates below 40% were considered to have low adherence to the task and were excluded from all subsequent analyses. The number of included trials per participant for perception (mean = 110), ROC values (mean = 0.78), the count of hit trials (mean =76) as well as the corrected hit rate (mean = 0.70), are detailed in <xref rid="apptbl4" ref-type="table">Appendix 2 Table 4</xref>.</p>
</sec>
<sec id="s2b2d">
<title>Neural Representational Similarity Matrices</title>
<p>Models for neural pattern similarity (RSM<sub>brain</sub>) were constructed using both the Object Perception study and the main Memory Retrieval task. Twenty six regions from the Human Brainnetome Atlas (<xref ref-type="bibr" rid="c31">Fan et al., 2016</xref>), focusing on eight areas within the lateral occipital cortex (LOC), 14 areas within the inferior temporal cortex (ITC), and four areas in the inferior parietal cortex (IPL, combining IPL sub regions into lateral posterior and anterior regions), as these regions are critically involved in visual representations during object perception and memory retrieval (<xref ref-type="bibr" rid="c24">Davis et al., 2021</xref>; <xref ref-type="bibr" rid="c33">Favila et al., 2020</xref>; <xref ref-type="bibr" rid="c42">Howard et al., 2024</xref>; <xref ref-type="bibr" rid="c62">Long &amp; Kuhl, 2021</xref>). For each of these 26 regions, we constructed similarity matrices of voxel activation patterns across stimuli with custom scripts in MATLAB and SPM12 (<xref ref-type="bibr" rid="c37">Friston et al., 2006</xref>). This was done by vectorizing the voxel-level activation values within each region and calculating their correlations using Pearson’s r, excluding all within-run comparisons. While each cell in a RSM<sub>model</sub> reflects the similarity in stimulus properties, each cell in the 114×114 RSM<sub>brain</sub> represents the similarity in activation patterns across different stimuli (<xref rid="fig1" ref-type="fig">Figure 1A</xref>).</p>
</sec>
<sec id="s2b2e">
<title>Model Representational Similarity Matrix</title>
<p>The C2 layer of the Hierarchical Model of object recognition (HMAX) was used to capture visual similarity between the 114 objects. The PsyTorch implementation of the HMAX model was used and contains four sequential stages, each with their own output: S1, C1, S2, and C2. The S1 layer applies Gabor filters to the input image across multiple scales and orientations. The Gabor filters capture edge-like features such as bars and gratings. The output consists of feature maps that highlight these basic visual components. Following the S1 layer, the C1 layer performs local max pooling over the S1 feature maps. This operation introduces some degree of invariance to position and scale. By selecting the maximum response within localized regions, the C1 layer reduces the spatial resolution while retaining the most salient features. The stages S2 and C2 build upon this foundation using similar pooling mechanisms. Specifically, S2 units pool information from the C1 stage using linear filters and function as radial basis functions, responding most strongly to specific prototype input patterns. These prototypes are derived from random fragments extracted from a set of natural images, independent of the stimuli used in this study. The C2 layer then pools outputs from S2 units using a MAX operation, which provides a degree of position and scale tolerance, allowing for robust representation of visual objects. This global pooling results in a feature vector that is highly invariant to position and scale, capturing the presence of complex features regardless of their location in the input image. The C2 layer’s output serves as a compact representation of the visual input (<xref ref-type="bibr" rid="c57">Kriegeskorte et al., 2008</xref>; <xref ref-type="bibr" rid="c78">Riesenhuber &amp; Poggio, 1999</xref>, <xref ref-type="bibr" rid="c79">2002</xref>; <xref ref-type="bibr" rid="c85">Serre et al., 2005</xref>, <xref ref-type="bibr" rid="c84">2007</xref>; <xref ref-type="bibr" rid="c88">Sufikarimi &amp; Mohammadi, 2020</xref>).</p>
<p>Features from the C2 layer of the HMAX model were used to create the model RSM. Pairwise similarity between images was computed using Pearson’s correlation coefficient (r), measuring the relationship between their C2 feature vectors. These values were organized into a 114×114 RSM, where each cell represented the similarity between two images. The resulting RSM<sub>model</sub> provided a structured representation of visual similarity, with higher correlations indicating shared complex features (<xref rid="fig1" ref-type="fig">Figure 1B</xref>).</p>
</sec>
<sec id="s2b2f">
<title>Classic Representational Similarity Analysis (cRSA)</title>
<p>We conducted cRSA using data from both the Object Perception dataset and the Memory Retrieval dataset. For Object Perception, we estimated participants’ classic representational strength in each of the 26 regions of interest by calculating Spearman’s rho between the RSM<sub>brain</sub> and the RSM<sub>model</sub>, while excluding within-run comparisons and the diagonal cells of the matrices (see <xref rid="fig1" ref-type="fig">Figure 1C, Top</xref>). We then assessed the strength and reliability of visual representations across participants using one-sample t-tests (testing Fisher-transformed rho &gt; 0) for each of the 26 regions, applying a false discovery rate (FDR) correction with a threshold of q = 0.05.</p>
<p>To evaluate cRSA’s performance in detecting differences in representational strength between conditions, we analyzed data from the main Memory Retrieval task, focusing on old items. An RSM<sub>brain</sub> for each of the 26 regions of interest was parsed into two separate RSMs: one containing data from “Hit” trials and the other from “Miss” trials. Similarly, the model RSMs were split based on participant responses. We then calculated Spearman’s rhos for the Hit and Miss conditions by correlating RSM<sub>brain</sub> and RSM<sub>model</sub>, again excluding within-run comparisons and the diagonal cells of the matrices. These subject-specific representational strength measures were subsequently Fisher-transformed and analyzed using paired-sample t-tests.</p>
<p>Regions showing significantly higher representational strength for Hit trials compared to Miss trials, after FDR correction with q &lt; 0.05, were identified as <italic>mnemonic representation regions</italic>.</p>
<p>To assess the impact of unbalanced trial counts on mnemonic representational strength, we calculated a Contrast Variance Factor (CVF) for each participant in regions showing evidence of mnemonic representation (p &lt; 0.05, uncorrected). The participant contrast score was determined by subtracting the Miss representational strength (<italic>R</italic><sub><italic>i,M</italic></sub>) from the Hit representational strength (<italic>R</italic><sub><italic>i,H</italic></sub>).
<disp-formula>
<graphic xlink:href="645646v1_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Next, we computed the mean difference D̄ across all participants:
<disp-formula>
<graphic xlink:href="645646v1_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
To quantify how much each participant’s mnemonic representational strength in each ROI deviated from the mean (thus inflating the contrast variance), we calculated the normalized absolute difference between the participant contrast score (<italic>D</italic><sub><italic>i</italic></sub>) and the average contrast score (D̄):
<disp-formula>
<graphic xlink:href="645646v1_ueqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Finally, to evaluate the influence of unbalanced trial counts on the variance factor, we correlated the participant CVF averaged across regions with the ratio of Hit trial count (<italic>N</italic><sub><italic>i</italic>,<italic>H</italic></sub>) to Miss trial count (<italic>N</italic><sub><italic>i</italic>,<italic>M</italic></sub>).
<disp-formula>
<graphic xlink:href="645646v1_ueqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s2b2g">
<title>Trial-Level Representational Similarity Analysis (tRSA)</title>
<p>The tRSA approach used the same model and neural RSMs from the Object Perception dataset and the main Memory Retrieval dataset as described above. However, instead of correlating the two matrices in their entirety, correlations were computed on a row-by-row basis, excluding within-run similarities and the diagonal cells of the matrices (see <xref rid="fig1" ref-type="fig">Figure 1C, Bottom</xref>). The trial-level estimates from both phases were then fitted to a series of mixed-effects models using the ‘lme4’ package in R (<xref ref-type="bibr" rid="c76">R Core Team, 2024</xref>) with restricted maximum likelihood methods. These fitted models were then evaluated using the Akaike Information Criterion (AIC) to determine the optimal random effect structure (<xref ref-type="bibr" rid="c66">Meteyard &amp; Davies, 2020</xref>; <xref ref-type="bibr" rid="c73">Park et al., 2020</xref>). To further validate model selection (<xref ref-type="bibr" rid="c64">Matuschek et al., 2017</xref>), models were refit using maximum likelihood estimation and subjected to model selection via log-likelihood ratio tests (LRTs). The average AICs and the results of the LRTs are reported in <xref rid="apptbl5" ref-type="table">Appendix 2 Table 5</xref>. Restricted maximum likelihood models with the selected random effects structure were further analyzed using the ‘lmerTest’ package. Denominator degrees of freedom were estimated using Satterthwaite’s method (<xref ref-type="bibr" rid="c83">Satterthwaite, 1946</xref>), and fixed effects were tested using t-tests with an alpha level of 0.05, corrected for false discovery rate (FDR) to account for multiple comparisons.</p>
<p>To estimate tRSA representational strength, trial-level estimates from the Object Perception dataset were fit to a mixed-effects model with random intercepts for Participant and Stimulus. Estimated intercepts (b &gt; 0) were used to identify representational regions. For detecting tRSA mnemonic representations in the main Memory Retrieval task, instead of constructing separate Hit and Miss RSMs, row-wise correlations were performed across all trials in the matrices (i.e., across-condition tRSA). This approach allows for trial-level estimates of representational strength that can be subsequently categorized as “Hit” or “Miss” and analyzed using a series of mixed-effects models. The model for mnemonic representation data included the fixed effect of Memory Success (Hit vs. Miss trials) and random intercepts for Participant and Stimulus.</p>
</sec>
<sec id="s2b2h">
<title>Examining continuous modulators of representation</title>
<p>The capacity of tRSA in examining stimulus-level variance modulating representation was assessed. For each item, a memorability score was calculated as the average response across participants (on a scale of 1-4 for the main Memory Retrieval and 1-3 for Perceptual Retrieval), normalized by the maximum possible value (4 for main retrieval and 3 for perceptual retrieval). This approach produced two stimulus-specific continuous variables indicating the overall confidence with which each item would be recalled. We refer to these measures as Conceptual Memorability and Item Memorability (perceptual). The Item Memorability measure was used as an of-interest fixed effect for trial-level representational strength estimates from the Object Perception dataset. Additional fixed nuisance variables included Conceptual Memorability, fMRI run, and trial-level reaction time. Random intercepts for Participant and Stimulus were also included.</p>
</sec>
</sec>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>Experiment 1: cRSA and tRSA comparisons in simulated data</title>
<sec id="s3a1">
<title>Basic statistical properties of tRSA estimates</title>
<p>To understand the statistical properties of representational strength estimates obtained via cRSA and tRSA, we first simulated datasets with a wide range of ground truth representational strengths. With fixed ground truth correlation between two <italic>symmetric matrices</italic> (i.e., fixed cRSA value), our simulations indicated that tRSA could produce reliable estimates of overall representational strength comparable to cRSA. Specifically, the average of trial-level estimates from tRSA centered around cRSA when the ground truth is zero correlation; as the magnitude of the ground truth increased, there appeared to be a bias toward slightly larger magnitudes. Despite this, the spread of tRSA estimates remained small, with a tight range of [0.599, 0.604] around the ground truth of 0.600 (see <xref rid="fig3" ref-type="fig">Figure 3A</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Correspondence between classic and trial-level RSA.</title>
<p><bold>A)</bold> Histograms of representational strength estimates obtained by averaging tRSA values. Each histogram depicted 10,000 iterations. Representational similarity matrices (RSMs) were simulated based on known ground truth representational strength values (cRSA). Solid vertical lines indicate the mean of the observations, and dashed vertical lines indicate the ground truth representational strength. <bold>B)</bold> Scatter plots of overall representational strength estimates, based on simulated activity patterns, produced by cRSA (x-axis) and tRSA (y-axis). Trial count (n) and measurement noise level (σ<sup>2</sup>) were both varied. 50 iterations were performed for each parameter combination. Solid slopes indicate where tRSA equaled cRSA (y = x). <bold>C)</bold> Histograms of overall representational strength estimates, based on simulated activity patterns for two separate conditions, produced by cRSA (gray) and across-condition tRSA (orange). Each histogram depicted 10,000 iterations. Trial counts were varied; for example, “20 : 80” means that Condition A contained 20 trials and Condition B contained 80 trials, which was an unbalanced scenario. Effect sizes were also varied, such that the ground truth representational strength would be equal between conditions (“A = B”) or stronger in Condition B (“A &lt; B”). <bold>D)</bold> Histograms of condition differences in representational strength values in <bold>C</bold>.</p></caption>
<graphic xlink:href="645646v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>A limitation of this simulation is that the symmetric matrices were randomly generated without being guaranteed to be mathematically valid similarity matrices (i.e., positive semidefinite). For example, [[1, 1, 1], [1, 1, −1], [1, −1, 1]] is symmetric but is not a valid correlation RSM, since it is impossible to satisfy <italic>a</italic> = <italic>b</italic> = <italic>c</italic> (row 1) and <italic>a</italic> = <italic>b</italic> = −<italic>c</italic> (row 2) unless <italic>a</italic> = <italic>b</italic> = <italic>c</italic> = 0, in which case the Pearson correlation is undefined. Similarly, RSMs using distance metrics such as Euclidean distance must satisfy the triangle inequality, i.e., <italic>d<sub>xy</sub></italic> + <italic>d<sub>xz</sub></italic> ≥ <italic>d<sub>yz</sub></italic>. Moreover, it is difficult to implement the multi-level variance structure directly on RSMs; rather, those variances are theorized to operate directly on the underlying <italic>activity patterns</italic>. To adhere to the mathematical constraints on similarity matrices and for better correspondence to real implementations, we simulated activity patterns from which RSMs were then derived and used to estimate representational strength. Notably, while it is difficult to fix the ground truth representational strength, we manipulated the statistical dependence between the activity patterns — and by extension, between RSM<sub>brain</sub> and RSM<sub>model</sub> — by injecting varying levels of measurement noise (<italic>σ</italic><sup>2</sup>). Simulations indicated that increasing measurement noise indeed reduced estimates of representational strength by both cRSA and tRSA (see <xref rid="fig3" ref-type="fig">Figure 3B</xref>). Also as expected, greater trial counts led to more stable estimates for both methods. Most importantly, a strong positive correlation between cRSA and tRSA estimates can be observed even in the “noisiest” simulation (i.e., <italic>n</italic> = 10, <italic>σ</italic><sup>2</sup> = 2; Intercept b<sub>0</sub> = 0.00, SE = 0.01, t = 0.33, p = 0.74; Slope b<sub>cRSA</sub> = 1.00, SE = 0.02, t = 64.95, p &lt; 0.001). These results demonstrated the close numerical correspondence between tRSA and cRSA in estimating the overall representational strength of a given system across all trials.</p>
</sec>
<sec id="s3a2">
<title>Discrete conditions</title>
<p>Oftentimes, researchers are interested in not only representational strength <italic>per se</italic>, but also how representation <italic>changes</italic> with other factors like experimental manipulations (e.g., “easy” vs. “hard”), behavioral performance (e.g., “remembered” vs. “forgotten”), or some combination. Analyzing these differences with cRSA entails partitioning the data to generate separate condition-specific RSMs. Subsequently, an intuitive version of <italic>within-condition</italic> tRSA can be computed using those RSMs, and its estimates would closely track cRSA estimates, as we have demonstrated in the previous section. Instead, we advocate for <italic>across-condition</italic> tRSA: full RSMs are used for computing trial-level representational strength, and the estimates are then split by conditions as necessary. For a direct comparison of <italic>within-</italic> and <italic>across-condition</italic> tRSA, see <bold>Appendix 1</bold>.</p>
<p>Here, we examined the correspondence of <italic>across-condition</italic> tRSA with cRSA in a wide range of scenarios where data can be meaningfully split into two subsets. Specifically, we assessed the influence of three important factors that may vary widely across studies: <italic>raw trial counts</italic>, <italic>balance of trial counts</italic>, and <italic>effect sizes</italic>. Because cRSA was performed separately for each condition, changes in the trial count or effect size of Condition B had no influence on cRSA estimates for Condition A. However, they indeed affected estimates obtained from <italic>across-condition</italic> tRSA, where all experimental trials were used for representational strength estimation.</p>
<p>Specifically, all else being equal, increasing the trial count in Condition B from 20 to 80 or from 80 to 320 improved the reliability of tRSA estimates in Condition A (see <xref rid="fig3" ref-type="fig">Figure 3C</xref><bold>, Rows 1 and 3</bold>). Additionally, increasing the noise level for Condition A to be higher than that for Condition B led to reduced tRSA estimates in Condition B as well. These effects were also reflected in the condition difference in tRSA estimates (see <xref rid="fig3" ref-type="fig">Figure 3D</xref>). Moreover, it is critical to note that tRSA appeared to be more reliable than cRSA in almost all simulated scenarios, especially in terms of the estimated difference between conditions. These findings suggest that tRSA may be more sensitive to true effects and at lower risk of false positives, i.e., reduced Type II and Type I error rates in formal statistical tests.</p>
</sec>
<sec id="s3a3">
<title>Contrasting conditions</title>
<p>The next set of simulations compared across-condition tRSA to cRSA in terms of statistical inferences, focusing on the difference in representational strength between two conditions as a typical effect of interest in many empirical studies. We implemented the condition differences by altering two condition-level noise parameters, where more noise would result in lower representational strength. The statistical significance of the condition difference <italic>b</italic><sub><italic>B</italic>−<italic>A</italic></sub> was estimated by a paired-sample t-test for cRSA and by a linear mixed-effects model for tRSA, using a threshold of α = 0.05. Depending on whether the two conditions ought to have the same quality of representation, outcomes were classified as true positives, true negatives, false positives (Type I error), or false negatives (Type II error). The performance of cRSA and tRSA were quantified with their specificity (1 - Type I error rate) and sensitivity (1 - Type II error rate).</p>
<p>We first examined how cRSA and tRSA performed with effects of different sizes, under a base within-subject experimental design consisting of 40 subjects and 200 unique stimuli randomly and evenly split between two conditions. Across 10,000 simulations, cRSA and tRSA were comparable in terms of specificity, with both Type I error rates neighboring around the nominal 5%. As the true condition difference increased, the sensitivity of both methods also increased accordingly. Importantly, tRSA were significantly more sensitive to true effects than cRSA in a range of simulated scenarios, consistent with our hypothesis (see <xref rid="fig4" ref-type="fig">Figure 4</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Testing condition differences in representational strength with varying effect sizes.</title>
<p>The effect size of the condition difference in representation was manipulated by changing the noise level in each condition in small increments, with higher noise levels corresponding to lower ground truth representational strengths. When the noise level was the same for both conditions, Type I error rates (red) were computed as the proportion of significant contrasts across 10,000 iterations, regardless of sign of the estimate. Otherwise, proportions were computed separately for effects of the correct sign (+, or B&gt;A; blue) and of the incorrect sign (-, or B&lt;A). Asterisks indicate the significance level of the test of equal proportions between simulation results from cRSA (left) and tRSA (right). Significance annotation: *** p &lt; 0.001, ** p &lt; 0.01, * p &lt; 0.05.</p></caption>
<graphic xlink:href="645646v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We further probed the robustness of cRSA and tRSA across datasets that varied in several important experimental design factors, namely the number of participants, trial counts per participant, and the balance of trial counts. In terms of specificity, our simulations did not suggest an effect of those manipulated factors, as the proportions of significant contrasts yielded by both cRSA and tRSA did not significantly deviate from the nominal alpha level of 5%. Tests of significant contrast proportions reported by cRSA and by tRSA also failed to reject the null hypothesis of equal proportions (<italic>p</italic> &gt; 0.05), suggesting similarly acceptable Type I error rates of both approaches (see <xref rid="fig5" ref-type="fig">Figure 5, Left</xref>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Testing condition differences in representational strength with varying designs.</title>
<p>The robustness of cRSA and tRSA were assessed in several variations of a base experimental design consisting of 40 subjects and 200 unique stimuli (randomly and evenly split into two sets). Simulations varied in <bold>A)</bold> number of subjects, <bold>B)</bold> trial count per subject, <bold>C)</bold> the ratio of trial counts between two conditions (with a fixed total), and <bold>D)</bold> the variance of trial count ratios across participants (even split overall). In each simulation, the statistical significance of the condition difference in representational strength was determined by a paired-sample t-test for cRSA and a linear mixed-effects model for tRSA, with α = 0.05. The proportion of significant contrasts was computed across 10,000 iterations. Type I error rates were computed regardless of the direction of the contrast. Type II error rates were computed only for the correct contrast (i.e., B &gt; A). Error bars indicate standard errors. In the left column, dashed horizontal lines mark the nominal α level of 0.05, and dotted horizontal lines mark the critical values beyond which the estimated proportion would be significantly different from α. Asterisks indicate the significance of the deviation in error rates between cRSA and tRSA results, *** p &lt; 0.001, ** p &lt; 0.01, * p &lt; 0.05.</p></caption>
<graphic xlink:href="645646v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In terms of sensitivity, our simulations revealed large impacts of all manipulated parameters. Increasing the number of subjects or the trial count per subject improved the sensitivity of true effects, benefiting both cRSA and tRSA substantially. Tests comparing the sensitivity of tRSA and cRSA suggested an advantage of tRSA at small-to-medium sample sizes of up to at least 40 subjects, and at medium trial counts of between 100 and 220 trials per subject (see <xref rid="fig5" ref-type="fig">Figure 5A-B, Right</xref>). We additionally tested variabilities in trial counts that may occur in real experiments. In one set of simulations, the total trial count was fixed at 200 but the ratio of trial counts between conditions varied consistently across subjects (i.e., systematic imbalance; <xref rid="fig5" ref-type="fig">Figure 5C</xref>). In another set of simulations, while trial counts were kept approximately equal between conditions <italic>on average</italic>, subject-specific ratios varied (<xref rid="fig5" ref-type="fig">Figure 5D</xref>). In both scenarios, increasing heterogeneity in trial counts resulted in substantially reduced sensitivity for cRSA. This result was expected: the reliability of cRSA estimates depends largely on trial counts (<xref rid="fig2" ref-type="fig">Figure 2</xref>), which violated the homoscedasticity assumption of the subsequent paired-sample t-test. In the meantime, with trial-level estimates of representational strength from tRSA, the subsequent mixed-effects models were able to properly handle this variance in trial count. Indeed, our simulations validated that tRSA was more robust to extreme scenarios and always significantly outperformed cRSA in sensitivity (see <xref rid="fig5" ref-type="fig">Figure 5C-D, Right</xref>).</p>
</sec>
<sec id="s3a4">
<title>Continuously varying effects</title>
<p>A crucial advantage of tRSA over cRSA is that this approach offers a straightforward way to model representational strength as a function of stimulus- or trial-level measures, such as image complexity and subjective familiarity. While these measures could be discretized into a much smaller number of bins (e.g., “low” and “high”), they are better treated as continuous variables to preserve meaningful variance. To simulate these scenarios, we generated data such that true representational strength monotonically decreased with an underlying continuous noise variable <italic>σ<sub>trial</sub></italic> that was measured by <italic>r<sub>measured</sub></italic> with construct validity <italic>r<sub>val</sub></italic> = <italic>Cor</italic>(<italic>r<sub>measured</sub></italic>, <italic>σ<sub>trial</sub></italic>). To perform cRSA, trials were post-hoc split into two conditions by performing a median split on <italic>r<sub>measured</sub></italic> for each participant. Statistical inferences were again drawn for the difference in representational strength between the two conditions, using both cRSA and tRSA<sub>discrete</sub>. In addition, we also assessed the performance of tRSA<sub>continuous</sub>, where representational strength was directly predicted by the measured continuous variable <italic>r<sub>measured</sub></italic> without discretization.</p>
<p>Specificity and sensitivity were first examined for datasets with various effect sizes. Across 10,000 iterations, cRSA had a Type I error rate (i.e., when <italic>r<sub>val</sub></italic> = 0) close to the nominal rate of 5%, while both tRSA<sub>discrete</sub> and tRSA<sub>continuous</sub> showed significantly improved specificity (see <xref rid="fig6" ref-type="fig">Figure 6A</xref>). As construct validity and effect size of the trial-level measurement increased (i.e., more negative <italic>r<sub>val</sub></italic>), sensitivity expectedly improved for all methods. Relative to cRSA, tRSA<sub>continuous</sub> appeared to show slightly lower sensitivity for small effects (e.g., <italic>r<sub>val</sub></italic> = −0.01), though it was also more conservative than cRSA with a lower chance of declaring significance in the incorrect direction (B&lt;A). Moreover, tRSA<sub>continuous</sub> was the most sensitive method for moderate effects (e.g., <italic>r<sub>val</sub></italic> = −0.04). We further probed the robustness of cRSA and tRSA across datasets that varied widely in the number of subjects and trial counts. Overall, we observed that the Type I error rates were stable around the nominal 5% for cRSA, as expected. However, both tRSA<sub>discrete</sub> and tRSA<sub>continuous</sub> demonstrated significantly enhanced specificity across all manipulations (see <xref rid="fig6" ref-type="fig">Figure 6B-D, Left</xref>). Sensitivity expectedly improved for all three approaches with increasing subject numbers and trial counts and hit the ceiling with enough samples, though tRSA<sub>continuous</sub> significantly outperformed other methods at smaller sample sizes, such as 10 participants with 200 trials each or 40 participants with 30 trials each (see <xref rid="fig6" ref-type="fig">Figure 6B-C, Right</xref>). Additionally, we simulated scenarios in which subject-level trial counts were variable (e.g., missingness, exclusions), resulting in not only a reduction of total sample size but also additional variance in any subject-level estimates. The sensitivity of cRSA dropped substantially with this change because cRSA does not account for such variance, while tRSA-based inferences were minimally impacted (see <xref rid="fig6" ref-type="fig">Figure 6D, Right</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Testing continuous modulations of representational strength with varying designs.</title>
<p>The robustness of cRSA and tRSA were assessed in several variations of a base experimental design consisting of 40 subjects and 200 unique stimuli presented once for each subject. Simulations varied in <bold>A)</bold> the true effect size of representational strength, <bold>B)</bold> number of subjects, <bold>C)</bold> trial count per subject, and <bold>D)</bold> the variance of trial count across subjects (assuming a fixed total). Three statistical tests were performed in each simulation: a paired- sample t-test on the difference between “high” and “low” conditions (median-split of r<sub>measured</sub>) for cRSA, a linear mixed-effects model on the same condition difference for tRSA<sub>discrete</sub>, and a linear mixed-effects model on the effect of continuous variable r<sub>measured</sub> for tRSA<sub>continuous</sub>. Statistical significance was determined with α = 0.05. The proportion of significant results was computed across 10,000 iterations. Type I error rates were computed regardless of the sign of the estimate. Type II error rates were computed only for the correct sign (+). Error bars indicate standard errors. In the left column for <bold>B</bold> through <bold>D</bold>, dashed horizontal lines mark the nominal α level of 0.05, and dotted horizontal lines mark the critical values beyond which the estimated proportion would be significantly different from α. Asterisks indicate the significance level of the test of equal proportions between each tRSA approach and cRSA, *** p &lt; 0.001, ** p &lt; 0.01, * p &lt; 0.05.</p></caption>
<graphic xlink:href="645646v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3a5">
<title>Summary of Experiment 1</title>
<p>Collectively, our simulations offered three key insights into the commonalities and distinctions between our novel tRSA and the commonly implemented cRSA approaches. First, when the goal is to quantify the overall representational strength of the entire set of trials, tRSA produces estimates highly similar to those generated by cRSA. In other words, little information is lost in performing the trial-level computations (<xref rid="fig3" ref-type="fig">Figure 3</xref>). Second, tRSA is robust to variances that cRSA is agnostic to, such as imbalances in trial count between conditions and variability in trial count ratios across subjects. In almost all cases tRSA significantly outperformed cRSA in sensitivity (<xref rid="fig5" ref-type="fig">Figure 5</xref>). This outcome was expected, as the collapsing of trials in cRSA inevitably leads to the loss of important information regarding meaningful variances from other levels; tRSA is capable of properly modelling the multi-level variance structure. Third, tRSA is uniquely advantageous when neural representations are to be linked to continuous variables, rather than discrete conditions. The voided need for post-hoc discretization prevents additional loss of meaningful variance from the modulators, and tRSA<sub>continuous</sub> demonstrated significantly enhanced specificity and sensitivity over cRSA in a wide range of scenarios (<xref rid="fig6" ref-type="fig">Figure 6</xref>).</p>
</sec>
</sec>
<sec id="s3b">
<title>Experiment 2: cRSA and tRSA comparison in fMRI data</title>
<sec id="s3b1">
<title>Trial-level RSA estimates for Perceptual and Mnemonic Processing</title>
<p>The first goal of Experiment 2 was to compare the results from tRSA and cRSA approaches obtained from real fMRI data. We used fMRI data collected when participants implicitly named 114 colored images of everyday objects in a white background (Object Perception; see <xref rid="fig7" ref-type="fig">Figure 7A</xref>). Estimates of regional representational strength in the tRSA models were compared with mean cRSA values across participants, for each region of interest. Unsurprisingly, the tRSA model estimates and the cRSA mean correlation values demonstrated similar distributions (<xref rid="fig7" ref-type="fig">Figure 7B</xref>) and were highly correlated (<xref rid="fig7" ref-type="fig">Figure 7C</xref>). Critically, however, the two approaches yielded different results in terms of statistically significant regions. Specifically, the cRSA approach identified four significant regions in the LOC during Object Perception, whereas the tRSA approach identified two additional regions within the LOC (<xref rid="tbl1" ref-type="table">Table 1</xref>, <xref rid="fig7" ref-type="fig">Figure 7D</xref>, and <xref rid="fig7" ref-type="fig">Figure 7E</xref>). This discrepancy indicated the ability of tRSA to more accurately and robustly identify representational regions.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>tRSA outperforms cRSA in identifying representational regions during object perception.</title>
<p><bold>A)</bold> Visualization of the Object Perception Task. The fMRI task required participants to view 114 labeled objects and rate how well the labels describe the objects on a scale of 1 to 4 (mean 3.59). <bold>B)</bold> Density plots (y-axis) of regional representational strengths (x-axis) for tRSA (model estimates, dark) and cRSA (mean correlation values, light). Regions with significant representational strength greater than zero (q &lt; 0.05) are highlighted in red. <bold>C)</bold> Scatter plot showing the correlation between regional representational strengths from tRSA (model estimates, y-axis) and cRSA (mean correlation values, x-axis). Regions with significant tRSA representation are highlighted in red, and those significant in cRSA are outlined in red. The representational strength measures are highly correlated across regions (r = 0.98, p &lt; 0.001). <bold>D)</bold> Bar graph of t-statistics for each of the 26 regions of interest. Representation t-statistics (y-axis) from cRSA (light) and tRSA (dark) across 26 regions of interest (x-axis). Regions significant after FDR correction (q &lt; 0.05) are highlighted in red. <bold>E)</bold> Brain regions with significant representation. Regions in light red were identified by the tRSA and cRSA. Regions in dark red were identified by the tRSA method only.</p></caption>
<graphic xlink:href="645646v1_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Representation regions identified by cRSA and tRSA.</title></caption>
<graphic xlink:href="645646v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="645646v1_tbl1a.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="645646v1_tbl1b.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s3b2">
<title>Subject-level variance not accounted for by cRSA</title>
<p>The second goal of Experiment 2 was to demonstrate the utility of tRSA in accounting for the heterogeneity in subject-level variance. In the main Memory Retrieval task, experimental trials were categorized as “Hit” or “Miss” based on participants’ memory success, and the exact number of trials in each condition varied widely across participants (<xref rid="fig8" ref-type="fig">Figure 8A, Bottom</xref>).</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Unmodeled within- and between-participant variance in cRSA for mnemonic representations.</title>
<p><bold>A)</bold> Top: Visualization of the main memory task. Participant recognition and judgement confidence was tested for 144 concepts (114 “old”, 30 “new”). <bold>Bottom:</bold> Stacked bar plots with the number of “Hit” (blue) and “Miss” (gray) trials (y- axes) for each participant (x-axis). Participants were sorted by their hit to miss ratio in descending order. <bold>B)</bold> Density plots of cRSA representational strength (y-axes) across the 26 ROIs (x-axes) for Hits (blue) and Misses (gray) for each participant, sorted by descending Hit-to-Miss count ratio. The Hit-to-Miss ratios were displayed in the top-left corner of each subplot, with the font color transitioning from blue (indicating more Hits) to gray (indicating more Misses). <bold>C)</bold> Scatter plot illustrating the influence of the Hit-to-Miss ratio (x-axis) on the participant CVFs (y-axis). The Spearman’s correlation was significant, with a coefficient of 0.45 and a p-value of 0.016. Two participants are marked X and were excluded from this correlation as their Hit-to Miss ratio is less than 1. <bold>D)</bold> Density plots (y-axis) of cRSA representational strength across participants for Hits (blue) and Misses (gray). <bold>E)</bold> Regions exhibiting significant cRSA mnemonic representation (Hits &gt; Misses). Regions highlighted in blue were significant after FDR correction with q &lt; 0.05. Regions in gray were significant at p &lt; 0.05 but did not survive FDR correction.</p></caption>
<graphic xlink:href="645646v1_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Importantly, the difference in the number of trials had a strong impact on the estimation of representational strength (see <xref rid="fig2" ref-type="fig">Figure 2</xref>). Participants with fewer trials in a given condition exhibited a noticeably wider distribution of representational strength values across ROIs in that condition, indicating that trial count was a substantial source of across-subject variance indeed (see <xref rid="fig8" ref-type="fig">Figure 8B</xref>). Moreover, trial count was also negatively associated with the standard deviation of representational strengths across ROIs, for both Hit trials (rho = -0.37, <italic>p</italic> = 0.043) and Miss trials (rho = -0.71, <italic>p</italic> &lt; 0.001). However, this subject-level variance is often not accounted for in subsequent group-level t-test or ANOVA, which assumes that each participant contributes equally reliable estimates (i.e., homoscedasticity). Indeed, CVFs were much higher for participants with more extreme Hit to Miss trial counts (rho = 0.45, p = 0.016; see <xref rid="fig8" ref-type="fig">Figure 8C</xref>).</p>
<p>This issue of neglected heteroscedasticity remains when conditional contrasts (e.g., Hit minus Miss) are computed. Given the nonlinear relationship between trial counts and the reliability of correlations (see <xref rid="fig2" ref-type="fig">Figure 2</xref>), a more extreme trial imbalance (e.g., 100 Hits and 10 Misses, versus 70 Hits and 40 Misses) would also lead to a less reliable estimate of the difference. To demonstrate this issue in real fMRI data, we computed the CVF for each participant, measuring how much their Hit-Miss contrast in representational strength estimates deviated from the group mean. Indeed, CVFs were much higher for participants with more extreme Hit to Miss trial counts (rho = 0.45, p = 0.016; see <xref rid="fig8" ref-type="fig">Figure 8C</xref>). Critically, the two participants with Hit to Miss ratios &lt; 1 were excluded from this correlation (since in those cases we would expect an increased CVF), but their data points are included in the corresponding figure for transparency.</p>
<p>Additionally, the distributions of representational strengths for Hits and Misses across participants were unequal. Since most participants had more Hit trials than Miss trials (Hit-to-Miss Ratio mean = 3.7, median = 3.1), the distribution of representational strength values was broader for misses compared to hits (<xref rid="fig8" ref-type="fig">Figure 8D</xref>). Ultimately, results from cRSA revealed significant mnemonic representation in one right LOC region and one right anterior ITC region, with two additional ITC regions showing trend-level significance (<xref rid="tbl2" ref-type="table">Table 2</xref>, <xref rid="fig8" ref-type="fig">Figure 8E</xref>); these outcomes were revisited in comparison to the tRSA approach below. Together, these results demonstrate that cRSA failed to model the across-subject variance in real fMRI data, which stemmed from the inevitable variability in trial count ratios affecting the reliability of each participant’s cRSA contrast estimates. The violation of statistical assumptions challenged the interpretability of standard t-tests in detecting representational regions.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title>Mnemonic representation regions identified by cRSA and tRSA.</title></caption>
<graphic xlink:href="645646v1_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="645646v1_tbl2a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s3b3">
<title>Subject-level variance accounted for by tRSA</title>
<p>We also sought to assess how the tRSA approach would improve the estimates of representational strength for memory success. The mixed-effects models used to test tRSA mnemonic representations supporting retrieval identified four significant mnemonic representation regions: one in the right LOC and three in the right ITC (<xref rid="tbl2" ref-type="table">Table 2</xref>, <xref rid="fig9" ref-type="fig">Figure 9A</xref>, and <xref rid="fig9" ref-type="fig">Figure 9B</xref>). While the t-statistics for tRSA and cRSA showed a correlation across ROIs (<xref rid="fig9" ref-type="fig">Figure 9C</xref>), the tRSA approach, which produced trial-level estimates of representational strength, was able to detect mnemonic representation regions that the cRSA approach did not. This result demonstrated the enhanced sensitivity of tRSA in identifying subtle differences in representational strength. Moreover, a region in the LOC, initially considered a mnemonic representation region by the cRSA method — largely due to data from participants with low miss trial counts (<xref rid="apptbl4" ref-type="table">Appendix 2 Table 4</xref>) — was correctly excluded from being classified as such by tRSA (<xref rid="fig9" ref-type="fig">Figure 9A</xref>, <xref rid="fig9" ref-type="fig">Figure 9B</xref>). This result highlighted tRSA’s improved specificity in the identification of true mnemonic representation regions by reducing potential biases introduced by variances in trial counts that went neglected by cRSA.</p>
<fig id="fig9" position="float" orientation="portrait" fig-type="figure">
<label>Figure 9.</label>
<caption><title>tRSA outperforms cRSA in detecting mnemonic representations.</title>
<p><bold>A)</bold> Bar graph of t Statistics for each of the 26 regions of interest. Mnemonic representation t-statistics (y-axis) from cRSA (light) and tRSA (dark) across 26 regions of interest (x-axis). Regions that are significant after FDR correction (q &lt; 0.05) are highlighted in blue. <bold>B)</bold> Brain regions with significant mnemonic representation identified by tRSA are shown in blue. The region that was significant in cRSA but not in tRSA is depicted in light blue. <bold>C)</bold> Scatter plot of t-statistics calculated from tRSA (y-axis) and cRSA (x-axis), showing a significant Pearson correlation (r = 0.49, p = 0.010). Significant tRSA regions are highlighted in blue. Significant cRSA regions are outlined in light blue.</p></caption>
<graphic xlink:href="645646v1_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3b4">
<title>Estimations of continuous modulators</title>
<p>Our final goal was to assess the utility of tRSA in testing hypotheses regarding continuous modulators of representational strength. Here, we focused on the effect of item memorability, a stimulus-level variable (see <xref rid="fig10" ref-type="fig">Figure 10A</xref>). The tRSA approach successfully detected continuous, stimulus-level modulation of representational strength during Object Perception, when participants were engaged in basic-level naming of color objects displayed on a white background; notably, no memory task was engaged before or during this phase of the experiment. Four regions within the LOC showed significant modulation by Perceptual Memorability, a measure based on average responses in the Perceptual Retrieval task (see <xref rid="tbl3" ref-type="table">Table 3</xref><bold> and </bold><xref rid="fig10" ref-type="fig">Figure 10B</xref>). While not the explicit focus of this analysis, the analyses also identified significant effects of the nuisance variables, Conceptual Memorability, and reaction time in five regions of interest (<xref ref-type="table" rid="apptbl6">Appendix 2 Table 6</xref>) within the LOC. These regions are often associated with processing the constituent categories or visual features of an object (<xref ref-type="bibr" rid="c90">Tyler et al., 2013</xref>), and consistent with the view that the memorability of images can be predicted by statistical properties of semantic features (<xref ref-type="bibr" rid="c6">Bainbridge, 2022</xref>; <xref ref-type="bibr" rid="c41">Hovhannisyan et al., 2021</xref>; <xref ref-type="bibr" rid="c54">Kramer et al., 2023</xref>).</p>
<fig id="fig10" position="float" orientation="portrait" fig-type="figure">
<label>Figure 10.</label>
<caption><title>tRSA captures stimulus-level modulations on representation.</title>
<p><bold>A)</bold> Distribution of Item Memorability. Density plot of memorability values demonstrates a wide distribution of memorability scores (i.e., the average confidence of remembering a particular item). This stimulus-level variance is an underexplored target of representational analyses. <bold>B)</bold> Cortical representational effects of Memorability. Relationship between item-level Memorability and representational strength, as assessed with tRSA, for each of the 26 regions of interest. Trial-level representational strength estimates from Object Perception were significantly modulated by a continuous, stimulus- level measure of Item Memorability in four regions (blue). The t-statistics for this modulation were plotted (y-axis) across regions of interest (x-axis).</p></caption>
<graphic xlink:href="645646v1_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><title>Continuous modulation in tRSA.</title></caption>
<graphic xlink:href="645646v1_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="645646v1_tbl3a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s3b5">
<title>Summary of Experiment 2</title>
<p>Three key takeaways from Experiment 2 mirrored those from Experiment 1. First, while access to ground truths was not possible with empirical fMRI datasets, results from tRSA and cRSA approaches showed a relatively high degree of correspondence as before (<xref rid="fig7" ref-type="fig">Figure 7C</xref>).</p>
<p>Nonetheless, modeling trial-level estimates from tRSA showed improved sensitivity to neural representations in the Object Perception dataset, as the tRSA model was able to weigh study subjects with different numbers of trials appropriately (<xref rid="fig7" ref-type="fig">Figure 7D</xref>). Second, in the Memory Retrieval dataset, participants had unbalanced and heterogenous distributions of trial counts in two conditions (“Hits” and “Misses”), as expected with any psychological task focusing on subject performance (<xref rid="fig8" ref-type="fig">Figure 8A</xref>). The outcome of tRSA’s improved characterization can be seen in multiple empirical outcomes: tRSA was able to detect mnemonic representation regions that the cRSA approach missed (improved; sensitivity <xref rid="fig9" ref-type="fig">Figure 9B</xref>), and afforded more appropriate weighting of participant’s contrast estimates while maintaining similar outcome statistics as cRSA (<xref rid="fig9" ref-type="fig">Figure 9C</xref>). Third, tRSA supported the investigation of research questions that cannot be readily addressed with cRSA, namely the trial- or stimulus-level modulations of representational strength. We demonstrated this point using Item Memorability — a stable stimulus property that is thought to contribute to memory independently of task context, experimental context, or individual differences. Representational strength in several regions in the ventral stream varied continuously with stimulus-level memorability (<xref rid="fig10" ref-type="fig">Figure 10B</xref>). Moreover, model-fits became the strongest when the models also incorporated trial-level variables such as fMRI run and reaction time. These findings showed that the representational strength estimates produced by tRSA indeed captured the multi-level variance structure in the data and that tRSA can be implemented to study item-specific or trial-level modulators of representational strength effectively.</p>
</sec>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>This paper formally presents tRSA — a novel technique for evaluating the strength of neural representation at the level of individual experimental trials. The performance of tRSA was evaluated and compared to that of cRSA using both simulations (Experiment 1) and empirical fMRI datasets (Experiment 2). Three principal insights can be drawn from these analyses. First, tRSA produces highly similar estimates of <italic>overall</italic> representational strength as cRSA such this new approach comes with little cost in efficacy. Second, tRSA is robust to subject-level variances that would be neglected by cRSA, namely the trial count differences across subjects. With both simulations and empirical datasets, tRSA demonstrated enhanced sensitivity over cRSA in detecting true effects. Third, tRSA provides an opportunity to examine continuous modulators of representational strength with decent specificity and sensitivity. With the empirical fMRI dataset, we demonstrated that tRSA was able to detect significant associations between representational strength and item-level memorability, as well as trial-level nuisance variables. Below we discuss the methodological and conceptual implications of the tRSA approach for the field of cognitive neuroscience and beyond.</p>
<sec id="s4a">
<title>Similarities between cRSA and tRSA</title>
<p>Since the advent of cRSA, the method has been widely implemented in studies of neural representations with great success (<xref ref-type="bibr" rid="c28">Dimsdale-Zucker &amp; Ranganath, 2018</xref>; <xref ref-type="bibr" rid="c57">Kriegeskorte et al., 2008</xref>). Our first and foremost objective was to ensure that our novel tRSA technique produces estimates of representational strength that are comparable to cRSA. This objective was achieved in both Experiment 1 (simulations) and Experiment 2 (real fMRI data). Simulations suggested that tRSA and cRSA estimates reacted in very similar ways to manipulations of the number of subjects, trial counts, and noise level. While some numerical differences were observed when tRSA was computed across different conditions and compared to within-condition cRSA, the range of divergences remained small and did not adversely impact subsequent statistical testing. Analyses with real fMRI datasets corroborated their correspondence, showing highly similar distributions of estimated representational strength across the brain. These results confirm that our novel tRSA approach performs at least no worse than cRSA. In other words, researchers can confidently replace their existing cRSA analyses with the tRSA framework, not having to be concerned about the loss of information or inferior statistical performance. In general, our analyses with both simulations and real fMRI datasets demonstrated several important advantages of tRSA over cRSA in a wide range of scenarios.</p>
</sec>
<sec id="s4b">
<title>Methodological significance</title>
<p>Statistically, tRSA is designed to properly capture the multi-level variance structure in the data, yielding improved specificity and sensitivity. An important motivation of ours for devising this novel tRSA technique accords with a steady emergence in many scientific fields that advocates for proper treatments of the multi-level variance structure in the data (<xref ref-type="bibr" rid="c25">Dedrick et al., 2009</xref>; <xref ref-type="bibr" rid="c99">Winter &amp; Grice, 2021</xref>; <xref ref-type="bibr" rid="c101">Yarkoni, 2022</xref>). As laid out in the Introduction, we argue that (at least) four independent sources of variance contribute to how strongly a given neural system represents a single event (e.g., looking at an image of “basketball”): condition-level, subject-level, stimulus-level, and trial-level.</p>
<p><italic>Subject-level variance</italic> was a major focus of analysis in both Experiments. Research subjects are samples (ideally, random and representative) drawn from some population of interest. Barring quantifiable individual differences that may be relevant to the cognitive functions being studied (e.g., age, education, personality traits), subjects are considered to vary randomly around the population-level mean, which is often the focus of analysis. In cRSA, subject-level estimates of representational strength or condition differences are typically entered into a general linear model where homoscedasticity is assumed (e.g., t-test). However, this assumption is easily violated due to heterogeneity in subject-level trial counts, resulting in unreliable model outputs. Indeed, artificially induced variability in trial counts led to catastrophic reductions in the sensitivity of cRSA (Experiment 1). Empirical studies that select trials based on subjective performance or expect to have extensive missingness or exclusions must be wary of this problem, as we demonstrated the same issue of cRSA using real fMRI data from an episodic memory study (Experiment 2). Critically, tRSA proved to be more robust to this subject-level heteroscedasticity issue in both Experiments, for trial count information was available to the subsequent models with subjects entered as random factors (<xref ref-type="bibr" rid="c101">Yarkoni, 2022</xref>).</p>
<p><italic>Stimulus-level variance</italic> was another focus of our investigations. A major advantage of RSA over multivariate pattern classification techniques is that it allows the use of “condition-rich” experimental designs with large and diverse collections of stimuli, so long as meaningful hypotheses can be constructed in the form of an RSM<sub>model</sub> (<xref ref-type="bibr" rid="c57">Kriegeskorte et al., 2008</xref>). For instance, using an RSM<sub>model</sub> based on human similarity judgments, past work has implemented RSA on neuroimaging data collected with nearly two thousand unique natural object images (THINGS database; <xref ref-type="bibr" rid="c40">Hebart et al., 2023</xref>). Various stimulus properties have also been the target of neural representation research, such as the real-world size of objects (T. <xref ref-type="bibr" rid="c47">Huang et al., 2022</xref>), the geographical location of landmarks (<xref ref-type="bibr" rid="c68">Morton et al., 2021</xref>), or more abstractly, visual and semantic features of naturalistic images (<xref ref-type="bibr" rid="c26">Devereux et al., 2018</xref>; <xref ref-type="bibr" rid="c50">Jozwik et al., 2023</xref>; <xref ref-type="bibr" rid="c70">Naspi et al., 2021</xref>). Despite such prevalent appreciation for the neurocognitive relevance of stimulus properties, cRSA does not account for the fact that the same stimulus (e.g., “basketball”) is seen by multiple subjects and produces statistically dependent data. With tRSA, this issue is at least partially addressed by modeling stimulus identity as random effects, resulting in generalizability and reliability (<xref ref-type="bibr" rid="c19">Chen et al., 2021</xref>; <xref ref-type="bibr" rid="c101">Yarkoni, 2022</xref>). Admittedly, a complete resolution of this stimulus-as-fixed-effect fallacy would require stimulus information to be incorporated in any preceding procedures, including first-level models of fMRI data (<xref ref-type="bibr" rid="c97">Westfall et al., 2017</xref>); while beyond the scope of the current paper, these relevant analytical pipelines may be integrated for a full solution of the fallacy. Furthermore, as demonstrated in Experiment 2, tRSA supports the straightforward investigation of how representational strength varies with stimulus-level properties such as memorability. With the flexibility of tRSA, future studies may freely explore other interesting stimulus-level research questions.</p>
<p>Of note, in the current paper, we only examined experimental designs where each unique stimulus is presented once, i.e., no repetitions. Repetitions are sometimes included as targets to which participants should respond, in order to promote engagement level (<xref ref-type="bibr" rid="c1">Allen et al., 2022</xref>; <xref ref-type="bibr" rid="c17">Chang et al., 2019</xref>; <xref ref-type="bibr" rid="c60">Lahner et al., 2024</xref>). Additionally, some preprocessing or modeling procedures use repetitions to improve the accuracy of their estimates of neural activity responses and representations (<xref ref-type="bibr" rid="c18">Charest et al., 2018</xref>; <xref ref-type="bibr" rid="c75">Prince et al., 2022</xref>), though the effectiveness of this approach may depend on various other factors (<xref ref-type="bibr" rid="c81">Ritchie et al., 2021</xref>).</p>
<p>Importantly, repetitions have been found to robustly induce neural activity adaptation or <italic>repetition suppression</italic> in task-relevant brain regions (<xref ref-type="bibr" rid="c10">Barron et al., 2016</xref>; <xref ref-type="bibr" rid="c39">Grill-Spector et al., 2006</xref>), and this phenomenon has profound impacts on multi-voxel activity patterns as well (<xref ref-type="bibr" rid="c65">Mazurchuk et al., 2023</xref>). While beyond the scope of the current paper, we briefly mention two possible treatments of stimulus repetitions in implementing tRSA. For one, repetitions can be collapsed in first-level models of brain recordings for more reliable estimations of stimulus-specific neural activations; in this case, any subsequent analyses including tRSA can simply proceed as if individual stimuli are only presented once. Alternatively, repetitions can also be kept as separate events for which individual tRSA estimates are assigned; this option allows one to probe the stability of neural representations across time and repetitions. In either case, our tRSA approach can flexibly suit the various goals of research.</p>
<p><italic>Trial-level variance</italic> refers to the effect on the estimations of neural representations by factors that vary from trial to trial. For example, attention level fluctuates during the task and changes the fidelity of neural representations (<xref ref-type="bibr" rid="c2">Aly &amp; Turk-Browne, 2016</xref>; <xref ref-type="bibr" rid="c82">Rothlein et al., 2018</xref>). Like stimulus-level variance, trial-level variance is not accounted for by cRSA as the comparison of RSMs collapses across trials. In our simulations, we demonstrated that tRSA can indeed capture trial-level variance and reliably estimate its effect on representational strength (Experiment 1). In a real fMRI dataset, we found that reaction time, a trial-level nuisance variable, also had statistically significant effects on representational strength (Experiment 2). In addition, past research has found that pure physiological changes in pupillary size, cardiac rhythm, and respiration may also influence both neural and cognitive processes (<xref ref-type="bibr" rid="c22">Critchley &amp; Garfinkel, 2018</xref>; <xref ref-type="bibr" rid="c91">van der Wel &amp; van Steenbergen, 2018</xref>). While a portion of those effects could be due to the incomplete removal of artifacts during signal preprocessing, some physiological changes may also have intriguing neurocognitive relevance that is worth exploring in future studies.</p>
</sec>
<sec id="s4c">
<title>Conceptual significance</title>
<p>Fundamentally, approaching RSA at the level of individual trials is an advancement in terms of not only <italic>methodology</italic> (discussed above) but also <italic>conceptualization</italic>. The notion of <italic>neural representation</italic>, albeit used more broadly than the phrase is intended to, emphasizes the link between the representee (contents being represented, such as stimuli or memories) and its representative (alternative format of the content, such as neural activity) (<xref ref-type="bibr" rid="c9">Baker et al., 2022</xref>; <xref ref-type="bibr" rid="c32">Favela &amp; Machery, 2023</xref>; <xref ref-type="bibr" rid="c93">Vilarroya, 2017</xref>). Collapsing trial-level information in its formulation, cRSA could only indicate the quality of a <italic>kind</italic> of representation or the <italic>overall</italic> representational strength across events. Instead, tRSA provides a measure that directly corresponds to the conceptualization of representation, with each trial or event receiving its own estimated representational strength. This level of analysis is consistent with previous studies that focused on quantifying the similarity of multi-voxel activity patterns across different trials (S. Huang, Faul, et al., 2024; <xref ref-type="bibr" rid="c98">Wing et al., 2020</xref>; <xref ref-type="bibr" rid="c102">Yu et al., 2024</xref>) and at different stages of memory (<xref ref-type="bibr" rid="c80">Ritchey et al., 2013</xref>; <xref ref-type="bibr" rid="c86">Shao et al., 2023</xref>). As such, tRSA provides a versatile tool for inquiring about many different brain-behavior relationships at an appropriate level of analysis and with straightforward interpretations (<xref ref-type="bibr" rid="c13">Becker et al., 2024</xref>; <xref ref-type="bibr" rid="c42">Howard et al., 2024</xref>; <xref ref-type="bibr" rid="c67">Morales-Torres et al., 2024</xref>; <xref ref-type="bibr" rid="c71">Naspi et al., 2023</xref>; <xref ref-type="bibr" rid="c72">Pacheco-Estefan et al., 2024</xref>). Notably, tRSA is not limited to neuroimaging data; past research has also implemented this approach to perform item-specific analyses on behavioral data (<xref ref-type="bibr" rid="c94">Walsh &amp; Rissman, 2023</xref>).</p>
<p>At a broader level, the tRSA approach also engenders a host of other innovative techniques. The emerging research on representational connectivity focuses on the intersection of representational information and functional connectivity analyses, and seeks to uncover new multivariate views on how concepts are distributed across the brain (<xref ref-type="bibr" rid="c3">Anzellotti &amp; Coutanche, 2018</xref>). Using the tRSA approach, trial-level representational strength values from any pair of brain regions may be correlated to yield their model-based representational connectivity (S. Huang, De Brigard, et al., 2024; <xref ref-type="bibr" rid="c51">Karimi-Rouzbahani et al., 2022</xref>). Trial-level representational strength values may also be combined with other trial-level measures of neural activity such as univariate activation to probe diverse inter-regional interactions that are theoretically motivated (S. Huang, <xref ref-type="bibr" rid="c42">Howard, et al., 2024</xref>).</p>
</sec>
</sec>
<sec id="s5">
<title>Conclusion</title>
<p>We present a comprehensive overview and diagnostics of a trial-level approach to representational similarity analysis, termed tRSA. With both simulations and real fMRI datasets, we have demonstrated that tRSA properly captures the multi-level variance structure in the data, shows improved and robust specificity and sensitivity, and offers flexible modeling options. We believe that tRSA is an important advancement of the generic RSA implementation, both methodologically and conceptually, and we hope that this innovation provides a versatile and useful tool for digging deeper into the fascinating complexity of cognition.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>This study was supported by the National Institute of Health grant numbers: R01-AG066901, R21-AG058161, and R01-AG075417.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Allen</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>St-Yves</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Breedlove</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Prince</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Dowdle</surname>, <given-names>L. T.</given-names></string-name>, <string-name><surname>Nau</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Caron</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Pestilli</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Charest</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Hutchinson</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Naselaris</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Kay</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2022</year>). <article-title>A massive 7T fMRI dataset to bridge cognitive neuroscience and artificial intelligence</article-title>. <source>Nature Neuroscience</source>, <volume>25</volume>(<issue>1</issue>), <fpage>116</fpage>–<lpage>126</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-021-00962-x</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aly</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Turk-Browne</surname>, <given-names>N. B</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Attention Stabilizes Representations in the Human Hippocampus</article-title>. <source>Cerebral Cortex</source>, <volume>26</volume>(<issue>2</issue>), <fpage>783</fpage>–<lpage>796</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhv041</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anzellotti</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Coutanche</surname>, <given-names>M. N</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Beyond Functional Connectivity: Investigating Networks of Multivariate Representations</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>22</volume>(<issue>3</issue>), <fpage>258</fpage>–<lpage>269</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2017.12.002</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Avants</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Tustison</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Cook</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Klein</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Gee</surname>, <given-names>J. C</given-names></string-name></person-group>. (<year>2011</year>). <article-title>A reproducible evaluation of ANTs similarity metric performance in brain image registration</article-title>. <source>NeuroImage</source>, <volume>54</volume>(<issue>3</issue>), <fpage>2033</fpage>–<lpage>2044</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.09.025</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baayen</surname>, <given-names>R. H.</given-names></string-name>, <string-name><surname>Davidson</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Bates</surname>, <given-names>D. M</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Mixed-effects modeling with crossed random effects for subjects and items</article-title>. <source>Journal of Memory and Language</source>, <volume>59</volume>(<issue>4</issue>), <fpage>390</fpage>–<lpage>412</lpage>. <pub-id pub-id-type="doi">10.1016/j.jml.2007.12.005</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bainbridge</surname>, <given-names>W. A</given-names></string-name></person-group>. (<year>2022</year>). <chapter-title>Memorability: Reconceptualizing memory as a visual attribute</chapter-title>. In <source>Visual Memory</source>. <publisher-name>Routledge</publisher-name>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bainbridge</surname>, <given-names>W. A.</given-names></string-name>, <string-name><surname>Dilks</surname>, <given-names>D. D.</given-names></string-name>, &amp; <string-name><surname>Oliva</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Memorability: A stimulus-driven perceptual neural signature distinctive from memory</article-title>. <source>NeuroImage</source>, <volume>149</volume>, <fpage>141</fpage>–<lpage>152</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.01.063</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bainbridge</surname>, <given-names>W. A.</given-names></string-name>, &amp; <string-name><surname>Rissman</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Dissociating neural markers of stimulus memorability and subjective recognition during episodic retrieval</article-title>. <source>Scientific Reports</source>, <volume>8</volume>(<issue>1</issue>), <fpage>8679</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-018-26467-5</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baker</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Lansdell</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Kording</surname>, <given-names>K. P</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Three aspects of representation in neuroscience</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>26</volume>(<issue>11</issue>), <fpage>942</fpage>–<lpage>958</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2022.08.014</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barron</surname>, <given-names>H. C.</given-names></string-name>, <string-name><surname>Garvert</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Repetition suppression: A means to index neural representations using BOLD?</article-title> <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>, <volume>371</volume>(<issue>1705</issue>), <fpage>20150355</fpage>. <pub-id pub-id-type="doi">10.1098/rstb.2015.0355</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bates</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Mächler</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bolker</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Walker</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Fitting Linear Mixed-Effects Models Using lme4</article-title>. <source>Journal of Statistical Software</source>, <volume>67</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>48</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bauer</surname>, <given-names>A. J.</given-names></string-name>, &amp; <string-name><surname>Just</surname>, <given-names>M. A.</given-names></string-name></person-group> (<year>2019</year>). <chapter-title>Neural Representations of Concept Knowledge</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>G. I.</given-names> <surname>de Zubicaray</surname></string-name> &amp; <string-name><given-names>N. O.</given-names> <surname>Schiller</surname></string-name></person-group> (Eds.), <source>The Oxford Handbook of Neurolinguistics</source> (p. <fpage>0</fpage>). <publisher-name>Oxford University Press</publisher-name>. <pub-id pub-id-type="doi">10.1093/oxfordhb/9780190672027.013.21</pub-id></mixed-citation></ref>
    <ref id="c13"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Becker</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sommer</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Cabeza</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Neural Mechanisms of Creative Problem Solving—From Representational Change to Memory Formation</article-title> <source>bioRxiv</source> <pub-id pub-id-type="doi">10.1101/2023.06.13.544774</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behzadi</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Restom</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Liau</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Liu</surname>, <given-names>T. T</given-names></string-name></person-group>. (<year>2007</year>). <article-title>A component based noise correction method (CompCor) for BOLD and perfusion based fMRI</article-title>. <source>NeuroImage</source>, <volume>37</volume>(<issue>1</issue>), <fpage>90</fpage>–<lpage>101</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.042</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bobadilla-Suarez</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Ahlheim</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Mehrotra</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Panos</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Love</surname>, <given-names>B. C</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Measures of Neural Similarity</article-title>. <source>Computational Brain &amp; Behavior</source>, <volume>3</volume>(<issue>4</issue>), <fpage>369</fpage>–<lpage>383</lpage>. <pub-id pub-id-type="doi">10.1007/s42113-019-00068-5</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Brentano</surname>, <given-names>F</given-names></string-name></person-group>. (<year>1874</year>). <source>Psychology From an Empirical Standpoint</source>. <publisher-name>Routledge</publisher-name>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chang</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Pyles</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Marcus</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gupta</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Tarr</surname>, <given-names>M. J.</given-names></string-name>, &amp; <string-name><surname>Aminoff</surname>, <given-names>E. M</given-names></string-name></person-group>. (<year>2019</year>). <article-title>BOLD5000, a public fMRI dataset while viewing 5000 visual images</article-title>. <source>Scientific Data</source>, <volume>6</volume>(<issue>1</issue>), <fpage>49</fpage>. <pub-id pub-id-type="doi">10.1038/s41597-019-0052-3</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charest</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Kay</surname>, <given-names>K. N</given-names></string-name></person-group>. (<year>2018</year>). <article-title>GLMdenoise improves multivariate pattern analysis of fMRI data</article-title>. <source>NeuroImage</source>, <volume>183</volume>, <fpage>606</fpage>–<lpage>616</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.08.064</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Padmala</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Taylor</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Cox</surname>, <given-names>R. W.</given-names></string-name>, &amp; <string-name><surname>Pessoa</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2021</year>). <article-title>To pool or not to pool: Can we ignore cross-trial variability in FMRI?</article-title> <source>NeuroImage</source>, <volume>225</volume>, <fpage>117496</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117496</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cohen</surname>, <given-names>J</given-names></string-name></person-group>. (<year>1983</year>). <article-title>The cost of dichotomization</article-title>. <source>Applied Psychological Measurement</source>, <volume>7</volume>(<issue>3</issue>), <fpage>249</fpage>–<lpage>253</lpage>. <pub-id pub-id-type="doi">10.1177/014662168300700301</pub-id></mixed-citation></ref>
    <ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cox</surname>, <given-names>R. W.</given-names></string-name>, &amp; <string-name><surname>Hyde</surname>, <given-names>J. S</given-names></string-name></person-group>. (<year>1997</year>). <article-title>Software tools for analysis and visualization of fMRI data</article-title>. <source>NMR in Biomedicine</source>, <volume>10</volume>(<issue>4–5</issue>), <fpage>171</fpage>–<lpage>178</lpage>. <pub-id pub-id-type="doi">10.1002/(SICI)1099-1492(199706/08)10:4/5&lt;171::AID-NBM453&gt;3.0.CO;2-L</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Critchley</surname>, <given-names>H. D.</given-names></string-name>, &amp; <string-name><surname>Garfinkel</surname>, <given-names>S. N</given-names></string-name></person-group>. (<year>2018</year>). <article-title>The influence of physiological signals on cognition</article-title>. <source>Current Opinion in Behavioral Sciences</source>, <volume>19</volume>, <fpage>13</fpage>–<lpage>18</lpage>. <pub-id pub-id-type="doi">10.1016/j.cobeha.2017.08.014</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dale</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Fischl</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Sereno</surname>, <given-names>M. I</given-names></string-name></person-group>. (<year>1999</year>). <article-title>Cortical Surface-Based Analysis: I. Segmentation and Surface Reconstruction</article-title>. <source>NeuroImage</source>, <volume>9</volume>(<issue>2</issue>), <fpage>179</fpage>–<lpage>194</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.1998.0395</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Davis</surname>, <given-names>S. W.</given-names></string-name>, <string-name><surname>Geib</surname>, <given-names>B. R.</given-names></string-name>, <string-name><surname>Wing</surname>, <given-names>E. A.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>W.-C.</given-names></string-name>, <string-name><surname>Hovhannisyan</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Monge</surname>, <given-names>Z. A.</given-names></string-name>, &amp; <string-name><surname>Cabeza</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Visual and Semantic Representations Predict Subsequent Memory in Perceptual and Conceptual Memory Tests</article-title>. <source>Cerebral Cortex</source>, <volume>31</volume>(<issue>2</issue>), <fpage>974</fpage>–<lpage>992</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhaa269</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dedrick</surname>, <given-names>R. F.</given-names></string-name>, <string-name><surname>Ferron</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Hess</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Hogarty</surname>, <given-names>K. Y.</given-names></string-name>, <string-name><surname>Kromrey</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Lang</surname>, <given-names>T. R.</given-names></string-name>, <string-name><surname>Niles</surname>, <given-names>J. D.</given-names></string-name>, &amp; <string-name><surname>Lee</surname>, <given-names>R. S</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Multilevel Modeling: A Review of Methodological Issues and Applications</article-title>. <source>Review of Educational Research</source>, <volume>79</volume>(<issue>1</issue>), <fpage>69</fpage>–<lpage>102</lpage>. <pub-id pub-id-type="doi">10.3102/0034654308325581</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Devereux</surname>, <given-names>B. J.</given-names></string-name>, <string-name><surname>Clarke</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Tyler</surname>, <given-names>L. K</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Integrated deep visual and semantic attractor neural networks predict fMRI pattern-information along the ventral object processing pathway</article-title>. <source>Scientific Reports</source>, <volume>8</volume>(<issue>1</issue>), <pub-id pub-id-type="doi">10.1038/s41598-018-28865-1</pub-id></mixed-citation></ref>
    <ref id="c27"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Diedrichsen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Berlot</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Mur</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Schütt</surname>, <given-names>H. H.</given-names></string-name>, <string-name><surname>Shahbazi</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Kriegeskorte</surname>, <given-names>N</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Comparing representational geometries using whitened unbiased-distance-matrix similarity</article-title>. <source>arXiv</source>. <pub-id pub-id-type="doi">10.48550/arXiv.2007.02789</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Dimsdale-Zucker</surname>, <given-names>H. R.</given-names></string-name>, &amp; <string-name><surname>Ranganath</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2018</year>). <chapter-title>Representational Similarity Analyses: A Practical Guide for Functional MRI Applications</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>D.</given-names> <surname>Manahan-Vaughan</surname></string-name></person-group> (Ed.), <source>Handbook of Behavioral Neuroscience</source> (Vol. <volume>28</volume>, pp. <fpage>509</fpage>–<lpage>525</lpage>). <publisher-name>Elsevier</publisher-name>. <pub-id pub-id-type="doi">10.1016/B978-0-12-812028-6.00027-6</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esteban</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Markiewicz</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Blair</surname>, <given-names>R. W.</given-names></string-name>, <string-name><surname>Moodie</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Isik</surname>, <given-names>A. I.</given-names></string-name>, <string-name><surname>Erramuzpe</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kent</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Goncalves</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>DuPre</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Oya</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Ghosh</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Wright</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Durnez</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, &amp; <string-name><surname>Gorgolewski</surname>, <given-names>K. J</given-names></string-name></person-group>. (<year>2019</year>). <article-title>fMRIPrep: A robust preprocessing pipeline for functional MRI</article-title>. <source>Nature Methods</source>, <volume>16</volume>(<issue>1</issue>), <fpage>Article 1</fpage>. <pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id></mixed-citation></ref>
    <ref id="c30"><mixed-citation publication-type="software"><person-group person-group-type="author"><string-name><surname>Esteban</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Markiewicz</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Goncalves</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Provins</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Salo</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kent</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>DuPre</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ciric</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Pinsard</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Blair</surname>, <given-names>R. W.</given-names></string-name>, <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, &amp; <string-name><surname>Gorgolewski</surname>, <given-names>K. J</given-names></string-name></person-group>. (<year>2023</year>). <article-title>fMRIPrep: A robust preprocessing pipeline for functional MRI</article-title> <version>Version 23.0.1</version> <source>Zenodo</source>. <pub-id pub-id-type="doi">10.5281/zenodo.11123262</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fan</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Zhuo</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Chu</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Xie</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Laird</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Fox</surname>, <given-names>P. T.</given-names></string-name>, <string-name><surname>Eickhoff</surname>, <given-names>S. B.</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Jiang</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2016</year>). <article-title>The Human Brainnetome Atlas: A New Brain Atlas Based on Connectional Architecture</article-title>. <source>Cerebral Cortex</source>, <volume>26</volume>(<issue>8</issue>), <fpage>3508</fpage>– <lpage>3526</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhw157</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Favela</surname>, <given-names>L. H.</given-names></string-name>, &amp; <string-name><surname>Machery</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Investigating the concept of representation in the neural and psychological sciences</article-title>. <source>Frontiers in Psychology</source>, <volume>14</volume>. <pub-id pub-id-type="doi">10.3389/fpsyg.2023.1165622</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Favila</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Kuhl</surname>, <given-names>B. A</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Transforming the Concept of Memory Reactivation</article-title>. <source>Trends in Neurosciences</source>, <volume>43</volume>(<issue>12</issue>), <fpage>939</fpage>–<lpage>950</lpage>. <pub-id pub-id-type="doi">10.1016/j.tins.2020.09.006</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freeman</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Stolier</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Brooks</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Stillerman</surname>, <given-names>B. S</given-names></string-name></person-group>. (<year>2018</year>). <article-title>The neural representational geometry of social perception</article-title>. <source>Current Opinion in Psychology</source>, <volume>24</volume>, <fpage>83</fpage>–<lpage>91</lpage>. <pub-id pub-id-type="doi">10.1016/j.copsyc.2018.10.003</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freund</surname>, <given-names>M. C.</given-names></string-name>, <string-name><surname>Bugg</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name><surname>Braver</surname>, <given-names>T. S</given-names></string-name></person-group>. (<year>2021</year>). <article-title>A Representational Similarity Analysis of Cognitive Control during Color-Word Stroop</article-title>. <source>Journal of Neuroscience</source>, <volume>41</volume>(<issue>35</issue>), <fpage>7388</fpage>– <lpage>7402</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2956-20.2021</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freund</surname>, <given-names>M. C.</given-names></string-name>, <string-name><surname>Etzel</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Braver</surname>, <given-names>T. S</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Neural Coding of Cognitive Control: The Representational Similarity Analysis Approach</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>25</volume>(<issue>7</issue>), <fpage>622</fpage>–<lpage>638</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2021.03.011</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Ashburner</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Kiebel</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Nichols</surname>, <given-names>T. E.</given-names></string-name>, &amp; <string-name><surname>Penny</surname>, <given-names>W. D</given-names></string-name></person-group>. (Eds.). (<year>2006</year>). <source>Statistical parametric mapping: The analysis of functional brain images</source> (<edition>1</edition>st ed.). <publisher-name>Academic Press</publisher-name>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Greve</surname>, <given-names>D. N.</given-names></string-name>, &amp; <string-name><surname>Fischl</surname>, <given-names>B</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Accurate and robust brain image alignment using boundary-based registration</article-title>. <source>NeuroImage</source>, <volume>48</volume>(<issue>1</issue>), <fpage>63</fpage>–<lpage>72</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.06.060</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Grill-Spector</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Henson</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Martin</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Repetition and the brain: Neural models of stimulus-specific effects</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>10</volume>(<issue>1</issue>), <fpage>14</fpage>–<lpage>23</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2005.11.006</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hebart</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Contier</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Teichmann</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Rockter</surname>, <given-names>A. H.</given-names></string-name>, <string-name><surname>Zheng</surname>, <given-names>C. Y.</given-names></string-name>, <string-name><surname>Kidder</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Corriveau</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Vaziri-Pashkam</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Baker</surname>, <given-names>C. I</given-names></string-name></person-group>. (<year>2023</year>). <article-title>THINGS-data, a multimodal collection of large-scale datasets for investigating object representations in human brain and behavior</article-title>. <source>eLife</source>, <volume>12</volume>, <elocation-id>e82580</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.82580</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hovhannisyan</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Clarke</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Geib</surname>, <given-names>B. R.</given-names></string-name>, <string-name><surname>Cicchinelli</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Monge</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Worth</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Szymanski</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Cabeza</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Davis</surname>, <given-names>S. W</given-names></string-name></person-group>. (<year>2021</year>). <article-title>The visual and semantic features that predict object memory: Concept property norms for 1,000 object images</article-title>. <source>Memory &amp; Cognition</source>, <volume>49</volume>(<issue>4</issue>), <fpage>712</fpage>–<lpage>731</lpage>. <pub-id pub-id-type="doi">10.3758/s13421-020-01130-5</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Howard</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hovhannisyan</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Cabeza</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Davis</surname>, <given-names>S. W</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Differential Mnemonic Contributions of Cortical Representations during Encoding and Retrieval</article-title>. <source>Journal of Cognitive Neuroscience</source>, 1–29. <pub-id pub-id-type="doi">10.1162/jocn_a_02227</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Bogdan</surname>, <given-names>P. C.</given-names></string-name>, <string-name><surname>Howard</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Gillette</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Deng</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Welch</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>McAllister</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Giovanello</surname>, <given-names>K. S.</given-names></string-name>, <string-name><surname>Davis</surname>, <given-names>S. W.</given-names></string-name>, &amp; <string-name><surname>Cabeza</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Cortico-hippocampal interactions underlie schema-supported memory encoding in older adults</article-title> <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2024.09.18.613755</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>De Brigard</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Cabeza</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Davis</surname>, <given-names>S. W.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Connectivity analyses for task-based fMRI</article-title>. <source>Physics of Life Reviews</source>, <volume>49</volume>, <fpage>139</fpage>–<lpage>156</lpage>. <pub-id pub-id-type="doi">10.1016/j.plrev.2024.04.012</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Faul</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Parikh</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>LaBar</surname>, <given-names>K. S.</given-names></string-name>, &amp; <string-name><surname>De Brigard</surname>, <given-names>F.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Counterfactual thinking induces different neural patterns of memory modification in anxious individuals</article-title>. <source>Scientific Reports</source>, <volume>14</volume>(<issue>1</issue>), <fpage>10630</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-024-61545-x</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Howard</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Hovhannisyan</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ritchey</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Cabeza</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Davis</surname>, <given-names>S. W</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Hippocampal Functions Modulate Transfer-Appropriate Cortical Representations Supporting Subsequent Memory</article-title>. <source>Journal of Neuroscience</source>, <volume>44</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1135-23.2023</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Liu</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Real-world size of objects serves as an axis of object space</article-title>. <source>Communications Biology</source>, <volume>5</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1038/s42003-022-03711-3</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bannister</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brady</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Smith</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2002</year>). <article-title>Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images</article-title>. <source>NeuroImage</source>, <volume>17</volume>(<issue>2</issue>), <fpage>825</fpage>–<lpage>841</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.2002.1132</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jozranjbar</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Kristjánsson</surname>, <given-names>Á.</given-names></string-name>, <string-name><surname>Starrfelt</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Gerlach</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Sigurdardottir</surname>, <given-names>H. M</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Using representational similarity analysis to reveal category and process specificity in visual object recognition</article-title>. <source>Cortex</source>, <volume>166</volume>, <fpage>172</fpage>–<lpage>187</lpage>. <pub-id pub-id-type="doi">10.1016/j.cortex.2023.05.012</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jozwik</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Kietzmann</surname>, <given-names>T. C.</given-names></string-name>, <string-name><surname>Cichy</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Mur</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Deep Neural Networks and Visuo-Semantic Models Explain Complementary Components of Human Ventral-Stream Representational Dynamics</article-title>. <source>Journal of Neuroscience</source>, <volume>43</volume>(<issue>10</issue>), <fpage>1731</fpage>– <lpage>1741</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1424-22.2022</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Karimi-Rouzbahani</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Woolgar</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Henson</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Nili</surname>, <given-names>H</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Caveats and Nuances of Model-Based and Model-Free Representational Connectivity Analysis</article-title>. <source>Frontiers in Neuroscience</source>, <volume>16</volume>. <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/article/10.3389/fnins.2022.755988">https://www.frontiersin.org/article/10.3389/fnins.2022.755988</ext-link></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Klein</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ghosh</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Bao</surname>, <given-names>F. S.</given-names></string-name>, <string-name><surname>Giard</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Häme</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Stavsky</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Rossa</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Reuter</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Neto</surname>, <given-names>E. C.</given-names></string-name>, &amp; <string-name><surname>Keshavan</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Mindboggling morphometry of human brains</article-title>. <source>PLOS Computational Biology</source>, <volume>13</volume>(<issue>2</issue>), <fpage>e1005350</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005350</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kleiner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Brainard</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Pelli</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2007</year>). <article-title>What’s new in Psychtoolbox-3?</article-title> <source>Perception</source>, <volume>36</volume>(<issue>14</issue>), <fpage>1</fpage>–<lpage>16</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kramer</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Hebart</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Baker</surname>, <given-names>C. I.</given-names></string-name>, &amp; <string-name><surname>Bainbridge</surname>, <given-names>W. A</given-names></string-name></person-group>. (<year>2023</year>). <article-title>The features underlying the memorability of objects</article-title>. <source>Science Advances</source>, <volume>9</volume>(<issue>17</issue>), <fpage>eadd2981</fpage>. <pub-id pub-id-type="doi">10.1126/sciadv.add2981</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Diedrichsen</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Peeling the Onion of Brain Representations</article-title>. <source>Annual Review of Neuroscience</source>, <volume>42</volume>(<issue>1</issue>), <fpage>407</fpage>–<lpage>432</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-neuro-080317-061906</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Kievit</surname>, <given-names>R. A</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Representational geometry: Integrating cognition, computation, and the brain</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>17</volume>(<issue>8</issue>), <fpage>401</fpage>–<lpage>412</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2013.06.007</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Mur</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Bandettini</surname>, <given-names>P. A</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Representational similarity analysis— Connecting the branches of systems neuroscience</article-title>. <source>Frontiers in Systems Neuroscience</source>, <volume>2</volume>. <pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id></mixed-citation></ref>
    <ref id="c58"><mixed-citation publication-type="software"><person-group person-group-type="author"><string-name><surname>Kuhn</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Vaughan</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Hvitfeldt</surname>, <given-names>E.</given-names></string-name></person-group> (<year>2024</year>). <article-title>yardstick: Tidy Characterizations of Model Performance</article-title> (<version>Version 1.3.1</version>) <source>GitHub</source>. <ext-link ext-link-type="uri" xlink:href="https://github.com/tidymodels/yardstick">https://github.com/tidymodels/yardstick</ext-link></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kuznetsova</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brockhoff</surname>, <given-names>P. B.</given-names></string-name>, &amp; <string-name><surname>Christensen</surname>, <given-names>R. H. B</given-names></string-name></person-group>. (<year>2017</year>). <article-title>lmerTest Package: Tests in Linear Mixed Effects Models</article-title>. <source>Journal of Statistical Software</source>, <volume>82</volume>(<issue>13</issue>). <pub-id pub-id-type="doi">10.18637/jss.v082.i13</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lahner</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Dwivedi</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Iamshchinina</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Graumann</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Lascelles</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Roig</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Gifford</surname>, <given-names>A. T.</given-names></string-name>, <string-name><surname>Pan</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Jin</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Ratan Murty</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Kay</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Oliva</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Cichy</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Modeling short visual events through the BOLD moments video fMRI dataset and metadata</article-title>. <source>Nature Communications</source>, <volume>15</volume>(<issue>1</issue>), <fpage>6241</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-024-50310-3</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lanczos</surname>, <given-names>C.</given-names></string-name></person-group> (<year>1964</year>). <article-title>Evaluation of Noisy Data</article-title>. <source>Journal of the Society for Industrial and Applied Mathematics Series B Numerical Analysis</source>, <volume>1</volume>(<issue>1</issue>), 76–85. <pub-id pub-id-type="doi">10.1137/0701007</pub-id></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Long</surname>, <given-names>N. M.</given-names></string-name>, &amp; <string-name><surname>Kuhl</surname>, <given-names>B. A</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Cortical Representations of Visual Stimuli Shift Locations with Changes in Memory States</article-title>. <source>Current Biology</source>. <pub-id pub-id-type="doi">10.1016/j.cub.2021.01.004</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>MacCallum</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Preacher</surname>, <given-names>K. J.</given-names></string-name>, &amp; <string-name><surname>Rucker</surname>, <given-names>D. D</given-names></string-name></person-group>. (<year>2002</year>). <article-title>On the practice of dichotomization of quantitative variables</article-title>. <source>Psychological Methods</source>, <volume>7</volume>(<issue>1</issue>), <fpage>19</fpage>–<lpage>40</lpage>. <pub-id pub-id-type="doi">10.1037/1082-989X.7.1.19</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Matuschek</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Kliegl</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Vasishth</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Baayen</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Bates</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Balancing Type I error and power in linear mixed models</article-title>. <source>Journal of Memory and Language</source>, <volume>94</volume>, <fpage>305</fpage>–<lpage>315</lpage>. <pub-id pub-id-type="doi">10.1016/j.jml.2017.01.001</pub-id></mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mazurchuk</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Conant</surname>, <given-names>L. L.</given-names></string-name>, <string-name><surname>Tong</surname>, <given-names>J.-Q.</given-names></string-name>, <string-name><surname>Binder</surname>, <given-names>J. R.</given-names></string-name>, &amp; <string-name><surname>Fernandino</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Stimulus repetition and sample size considerations in item-level representational similarity analysis</article-title>. <source>Language, Cognition and Neuroscience</source>, <volume>0</volume>(<issue>0</issue>), <fpage>1</fpage>–<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1080/23273798.2023.2232903</pub-id></mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meteyard</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Davies</surname>, <given-names>R. A. I</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Best practice guidance for linear mixed-effects models in psychological science</article-title>. <source>Journal of Memory and Language</source>, <volume>112</volume>, <fpage>104092</fpage>. <pub-id pub-id-type="doi">10.1016/j.jml.2020.104092</pub-id></mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Morales-Torres</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Wing</surname>, <given-names>E. A.</given-names></string-name>, <string-name><surname>Deng</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Davis</surname>, <given-names>S. W.</given-names></string-name>, &amp; <string-name><surname>Cabeza</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Visual Recognition Memory of Scenes Is Driven by Categorical, Not Sensory, Visual Representations</article-title>. <source>Journal of Neuroscience</source>, <volume>44</volume>(<issue>21</issue>). <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1479-23.2024</pub-id></mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Morton</surname>, <given-names>N. W.</given-names></string-name>, <string-name><surname>Zippi</surname>, <given-names>E. L.</given-names></string-name>, <string-name><surname>Noh</surname>, <given-names>S. M.</given-names></string-name>, &amp; <string-name><surname>Preston</surname>, <given-names>A. R</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Semantic Knowledge of Famous People and Places Is Represented in Hippocampus and Distinct Cortical Networks</article-title>. <source>Journal of Neuroscience</source>, <volume>41</volume>(<issue>12</issue>), <fpage>2762</fpage>–<lpage>2779</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2034-19.2021</pub-id></mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mumford</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Turner</surname>, <given-names>B. O.</given-names></string-name>, <string-name><surname>Ashby</surname>, <given-names>F. G.</given-names></string-name>, &amp; <string-name><surname>Poldrack</surname>, <given-names>R. A</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses</article-title>. <source>NeuroImage</source>, <volume>59</volume>(<issue>3</issue>), <fpage>2636</fpage>–<lpage>2643</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.08.076</pub-id></mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Naspi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Hoffman</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Devereux</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Thejll-Madsen</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Doumas</surname>, <given-names>L. A. A.</given-names></string-name>, &amp; <string-name><surname>Morcom</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Multiple dimensions of semantic and perceptual similarity contribute to mnemonic discrimination for pictures</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>47</volume>(<issue>12</issue>), <fpage>1903</fpage>–<lpage>1923</lpage>. <pub-id pub-id-type="doi">10.1037/xlm0001032</pub-id></mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Naspi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Stensholt</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Karlsson</surname>, <given-names>A. E.</given-names></string-name>, <string-name><surname>Monge</surname>, <given-names>Z. A.</given-names></string-name>, &amp; <string-name><surname>Cabeza</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Effects of Aging on Successful Object Encoding: Enhanced Semantic Representations Compensate for Impaired Visual Representations</article-title>. <source>Journal of Neuroscience</source>, <volume>43</volume>(<issue>44</issue>), <fpage>7337</fpage>–<lpage>7350</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2265-22.2023</pub-id></mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pacheco-Estefan</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Fellner</surname>, <given-names>M.-C.</given-names></string-name>, <string-name><surname>Kunz</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Reinacher</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Roy</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Brandt</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Schulze-Bonhage</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Xue</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Axmacher</surname>, <given-names>N</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Maintenance and transformation of representational formats during working memory prioritization</article-title>. <source>Nature Communications</source>, <volume>15</volume>(<issue>1</issue>), <fpage>8234</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-024-52541-w</pub-id></mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Park</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Cardwell</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Yu</surname>, <given-names>H.-T</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Specifying the Random Effect Structure in Linear Mixed Effect Models for Analyzing Psycholinguistic Data</article-title>. <source>Methodology</source>, <volume>16</volume>(<issue>2</issue>), <fpage>Article 2</fpage>. <pub-id pub-id-type="doi">10.5964/meth.2809</pub-id></mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Power</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Mitra</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Laumann</surname>, <given-names>T. O.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>A. Z.</given-names></string-name>, <string-name><surname>Schlaggar</surname>, <given-names>B. L.</given-names></string-name>, &amp; <string-name><surname>Petersen</surname>, <given-names>S. E</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Methods to detect, characterize, and remove motion artifact in resting state fMRI</article-title>. <source>NeuroImage</source>, <volume>84</volume>, <fpage>320</fpage>–<lpage>341</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.048</pub-id></mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Prince</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Charest</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Kurzawski</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Pyles</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Tarr</surname>, <given-names>M. J.</given-names></string-name>, &amp; <string-name><surname>Kay</surname>, <given-names>K. N</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Improving the accuracy of single-trial fMRI response estimates using GLMsingle</article-title>. <source>eLife</source>, <volume>11</volume>, <elocation-id>e77599</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.77599</pub-id></mixed-citation></ref>
    <ref id="c76"><mixed-citation publication-type="software"><person-group person-group-type="author"><collab>R Core Team</collab>, <collab>R Foundation for Statistical Computing</collab></person-group><year>2024</year>). <source>R: A Language and Environment for Statistical Computing</source> <version>Version 4.4.1</version> <ext-link ext-link-type="uri" xlink:href="https://www.R-project.org/">https://www.R-project.org/</ext-link></mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reuter</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Rosas</surname>, <given-names>H. D.</given-names></string-name>, &amp; <string-name><surname>Fischl</surname>, <given-names>B</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Highly accurate inverse consistent registration: A robust approach</article-title>. <source>NeuroImage</source>, <volume>53</volume>(<issue>4</issue>), <fpage>1181</fpage>–<lpage>1196</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.07.020</pub-id></mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Riesenhuber</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Poggio</surname>, <given-names>T</given-names></string-name></person-group>. (<year>1999</year>). <article-title>Hierarchical models of object recognition in cortex</article-title>. <source>Nature Neuroscience</source>, <volume>2</volume>(<issue>11</issue>), <fpage>1019</fpage>–<lpage>1025</lpage>. <pub-id pub-id-type="doi">10.1038/14819</pub-id></mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Riesenhuber</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Poggio</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2002</year>). <article-title>Neural mechanisms of object recognition</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>12</volume>(<issue>2</issue>), <fpage>162</fpage>–<lpage>168</lpage>. <pub-id pub-id-type="doi">10.1016/S0959-4388(02)00304-5</pub-id></mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ritchey</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wing</surname>, <given-names>E. A.</given-names></string-name>, <string-name><surname>LaBar</surname>, <given-names>K. S.</given-names></string-name>, &amp; <string-name><surname>Cabeza</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Neural Similarity Between Encoding and Retrieval is Related to Memory Via Hippocampal Interactions</article-title>. <source>Cerebral Cortex</source>, <volume>23</volume>(<issue>12</issue>), <fpage>2818</fpage>–<lpage>2828</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhs258</pub-id></mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ritchie</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Lee Masson</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Bracci</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Op de Beeck</surname>, <given-names>H. P.</given-names></string-name></person-group> (<year>2021</year>). <article-title>The unreliable influence of multivariate noise normalization on the reliability of neural dissimilarity</article-title>. <source>NeuroImage</source>, <volume>245</volume>, <fpage>118686</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118686</pub-id></mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rothlein</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>DeGutis</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Esterman</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Attentional Fluctuations Influence the Neural Fidelity and Connectivity of Stimulus Representations</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>30</volume>(<issue>9</issue>), <fpage>1209</fpage>–<lpage>1228</lpage>. <pub-id pub-id-type="doi">10.1162/jocn_a_01306</pub-id></mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Satterthwaite</surname>, <given-names>F. E</given-names></string-name></person-group>. (<year>1946</year>). <article-title>An Approximate Distribution of Estimates of Variance Components</article-title>. <source>Biometrics Bulletin</source>, <volume>2</volume>(<issue>6</issue>), <fpage>110</fpage>–<lpage>114</lpage>. <pub-id pub-id-type="doi">10.2307/3002019</pub-id></mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Serre</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Oliva</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Poggio</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2007</year>). <article-title>A feedforward architecture accounts for rapid categorization</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>104</volume>(<issue>15</issue>), <fpage>6424</fpage>–<lpage>6429</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0700622104</pub-id></mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Serre</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Wolf</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Poggio</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2005</year>). <article-title>Object recognition with features inspired by visual cortex</article-title>. <conf-name>IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)</conf-name>, <fpage>994</fpage>–<lpage>1000</lpage> vol. <volume>2</volume>. <pub-id pub-id-type="doi">10.1109/CVPR.2005.254</pub-id></mixed-citation></ref>
<ref id="c86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shao</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Loftus</surname>, <given-names>E. F.</given-names></string-name>, &amp; <string-name><surname>Zhu</surname>, <given-names>B</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Cross-stage neural pattern similarity in the hippocampus predicts false memory derived from post-event inaccurate information</article-title>. <source>Nature Communications</source>, <volume>14</volume>(<issue>1</issue>), <fpage>Article 1</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-023-38046-y</pub-id></mixed-citation></ref>
<ref id="c87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Silver</surname>, <given-names>N. C.</given-names></string-name>, &amp; <string-name><surname>Dunlap</surname>, <given-names>W. P</given-names></string-name></person-group>. (<year>1987</year>). <article-title>Averaging correlation coefficients: Should Fisher’s z transformation be used?</article-title> <source>Journal of Applied Psychology</source>, <volume>72</volume>, <fpage>146</fpage>–<lpage>148</lpage>. <pub-id pub-id-type="doi">10.1037/0021-9010.72.1.146</pub-id></mixed-citation></ref>
<ref id="c88"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sufikarimi</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Mohammadi</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Role of the secondary visual cortex in HMAX model for object recognition</article-title>. <source>Cognitive Systems Research</source>, <volume>64</volume>, <fpage>15</fpage>–<lpage>28</lpage>. <pub-id pub-id-type="doi">10.1016/j.cogsys.2020.07.001</pub-id></mixed-citation></ref>
<ref id="c89"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tustison</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Avants</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Cook</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Zheng</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Egan</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yushkevich</surname>, <given-names>P. A.</given-names></string-name>, &amp; <string-name><surname>Gee</surname>, <given-names>J. C</given-names></string-name>. (). . , (), –. <collab>IEEE Transactions on Medical Imaging</collab></person-group><year>2010</year>). <article-title>N4ITK: Improved N3 Bias Correction</article-title>. <source>IEEE Transactions on Medical Imaging</source>, <volume>29</volume>(<issue>6</issue>), <fpage>1310</fpage>–<lpage>1320</lpage>. . <pub-id pub-id-type="doi">10.1109/TMI.2010.2046908</pub-id></mixed-citation></ref>
<ref id="c90"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tyler</surname>, <given-names>L. K.</given-names></string-name>, <string-name><surname>Chiu</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Zhuang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Randall</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Devereux</surname>, <given-names>B. J.</given-names></string-name>, <string-name><surname>Wright</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Clarke</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Taylor</surname>, <given-names>K. I</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Objects and Categories: Feature Statistics and Object Processing in the Ventral Stream</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>25</volume>(<issue>10</issue>), <fpage>1723</fpage>–<lpage>1735</lpage>. <pub-id pub-id-type="doi">10.1162/jocn_a_00419</pub-id></mixed-citation></ref>
<ref id="c91"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van der Wel</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>van Steenbergen</surname>, <given-names>H.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Pupil dilation as an index of effort in cognitive control tasks: A review</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>25</volume>(<issue>6</issue>), <fpage>2005</fpage>–<lpage>2015</lpage>. <pub-id pub-id-type="doi">10.3758/s13423-018-1432-y</pub-id></mixed-citation></ref>
<ref id="c92"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Venables</surname>, <given-names>W. N.</given-names></string-name>, <string-name><surname>Ripley</surname>, <given-names>B. D.</given-names></string-name>, &amp; <string-name><surname>Venables</surname>, <given-names>W. N</given-names></string-name></person-group>. (<year>2002</year>). <source>Modern applied statistics with S</source> (<edition>4</edition>th ed). <publisher-name>Springer</publisher-name>.</mixed-citation></ref>
<ref id="c93"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vilarroya</surname>, <given-names>O</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Neural Representation. A Survey-Based Analysis of the Notion</article-title>. <source>Frontiers in Psychology</source>, <volume>8</volume>. <pub-id pub-id-type="doi">10.3389/fpsyg.2017.01458</pub-id></mixed-citation></ref>
<ref id="c94"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walsh</surname>, <given-names>C. R.</given-names></string-name>, &amp; <string-name><surname>Rissman</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Behavioral representational similarity analysis reveals how episodic learning is influenced by and reshapes semantic memory</article-title>. <source>Nature Communications</source>, <volume>14</volume>(<issue>1</issue>), <fpage>Article 1</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-023-42770-w</pub-id></mixed-citation></ref>
<ref id="c95"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walther</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Nili</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Ejaz</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Alink</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Diedrichsen</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Reliability of dissimilarity measures for multi-voxel pattern analysis</article-title>. <source>NeuroImage</source>, <volume>137</volume>, <fpage>188</fpage>–<lpage>200</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.12.012</pub-id></mixed-citation></ref>
<ref id="c96"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weaverdyck</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>Lieberman</surname>, <given-names>M. D.</given-names></string-name>, &amp; <string-name><surname>Parkinson</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Tools of the Trade Multivoxel pattern analysis in fMRI: A practical introduction for social and affective neuroscientists</article-title>. <source>Social Cognitive and Affective Neuroscience</source>, <volume>15</volume>(<issue>4</issue>), <fpage>487</fpage>–<lpage>509</lpage>. <pub-id pub-id-type="doi">10.1093/scan/nsaa057</pub-id></mixed-citation></ref>
<ref id="c97"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Westfall</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Nichols</surname>, <given-names>T. E.</given-names></string-name>, &amp; <string-name><surname>Yarkoni</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Fixing the stimulus-as-fixed-effect fallacy in task fMRI</article-title>. <source>Wellcome Open Research</source>, <volume>1</volume>, <fpage>23</fpage>. <pub-id pub-id-type="doi">10.12688/wellcomeopenres.10298.2</pub-id></mixed-citation></ref>
<ref id="c98"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wing</surname>, <given-names>E. A.</given-names></string-name>, <string-name><surname>Geib</surname>, <given-names>B. R.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>W.-C.</given-names></string-name>, <string-name><surname>Monge</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Davis</surname>, <given-names>S. W.</given-names></string-name>, &amp; <string-name><surname>Cabeza</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Cortical Overlap and Cortical-Hippocampal Interactions Predict Subsequent True and False Memory</article-title>. <source>Journal of Neuroscience</source>, <volume>40</volume>(<issue>9</issue>), <fpage>1920</fpage>–<lpage>1930</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1766-19.2020</pub-id></mixed-citation></ref>
<ref id="c99"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Winter</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Grice</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Independence and generalizability in linguistics</article-title>. <source>Linguistics</source>, <volume>59</volume>(<issue>5</issue>), <fpage>1251</fpage>–<lpage>1277</lpage>. <pub-id pub-id-type="doi">10.1515/ling-2019-0049</pub-id></mixed-citation></ref>
<ref id="c100"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xue</surname>, <given-names>G</given-names></string-name></person-group>. (<year>2018</year>). <article-title>The Neural Representations Underlying Human Episodic Memory</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>22</volume>(<issue>6</issue>), <fpage>544</fpage>–<lpage>561</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2018.03.004</pub-id></mixed-citation></ref>
<ref id="c101"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yarkoni</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2022</year>). <article-title>The generalizability crisis</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>45</volume>, <fpage>e1</fpage>. <pub-id pub-id-type="doi">10.1017/S0140525X20001685</pub-id></mixed-citation></ref>
<ref id="c102"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Howard</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Hovhannisyan</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Clarke</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Cabeza</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Davis</surname>, <given-names>S. W</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Subsequent Memory Effects in Cortical Pattern Similarity Differ by Semantic Class</article-title>. <source>Journal of Cognitive Neuroscience</source>, 1–12. <pub-id pub-id-type="doi">10.1162/jocn_a_02238</pub-id></mixed-citation></ref>
<ref id="c103"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Brady</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Smith</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm</article-title>. <source>IEEE Transactions on Medical Imaging</source>, <volume>20</volume>(<issue>1</issue>), <fpage>45</fpage>–<lpage>57</lpage>. <pub-id pub-id-type="doi">10.1109/42.906424</pub-id></mixed-citation></ref>
</ref-list>
<app-group>
<title>Appendices</title>
<app id="app1">
<label>Appendix 1.</label>
<title>Comparing across-condition and within-condition tRSA</title>
<p>Given discrete experimental conditions, tRSA could be formulated either within each condition or across all conditions. In <italic>within-condition</italic> tRSA, one would generate condition-specific RSMs, e.g., one set of <italic>n</italic><sub><italic>A</italic></sub> × <italic>n</italic><sub><italic>A</italic></sub> RSMs for Condition A and another set of <italic>n</italic><sub><italic>B</italic></sub> × <italic>n</italic><sub><italic>B</italic></sub> RSMs for Condition B, and compute the two sets of <italic>within-condition</italic> tRSA values separately. These tRSA estimates are then subjected to subsequent analysis. In <italic>across-condition</italic> tRSA, RSMs are generated across all trials in all conditions, and tRSA estimates are computed as if there were no multiple conditions. Then, tRSA estimates are categorized based on the condition they belong to in any subsequent analysis.</p>
<p>We advocate for the use of across-condition tRSA for its enhanced statistical reliability over within-condition tRSA. One major limitation of within-condition tRSA is its vulnerability to small and variable trial counts. Suppose that a condition contains <italic>n</italic> trials, cRSA would use <italic>n</italic>(<italic>n</italic> − 1)/2 observations to compute its estimate, whereas within-condition tRSA could only use <italic>n</italic> − 1 observations. This effective sample size could turn out to be fairly small and variable in practice (see <xref rid="fig8" ref-type="fig">Figure 8A, Bottom</xref>), resulting in unreliable estimates (see <xref rid="fig2" ref-type="fig">Figure 2</xref>). On the contrary, across-condition tRSA suffers much less from this issue, since most experiments should have been designed to have an adequate total trial count.</p>
<p>Another theoretical advantage of across-condition tRSA is that it better corresponds to tRSA<sub>continuous</sub>, i.e., analyses in which trial-level representational strength estimates are hypothesized to be modulated by some continuous variable such as memorability or reaction time. In both across-condition tRSA and tRSA<sub>continuous</sub>, full RSMs are used to estimate representational strength before any discrete condition effect or continuous modulation effect is assessed.</p>
<p><xref rid="figa1" ref-type="fig">Appendix 1 Figure 11</xref> below summarizes the differences between within-condition and across-condition tRSA outcomes in a series of simulations. Notably, while within-condition tRSA estimates showed better numerical correspondence with cRSA estimates, they are less reliable than across-condition tRSA, as evidenced by the wider spread of estimates.</p>
<fig id="figa1" position="float" orientation="portrait" fig-type="figure">
<label>Appendix 1 Figure 11.</label>
<caption><title>Comparing across-condition and within-condition tRSA.</title>
<p>Each cell depicts descriptive statistics of different RSA methods from 10,000 simulations. Cells differ in raw trial counts (20, 80, or 320 in a given condition), balance of trial counts between conditions (balanced or unbalanced), and effect (A = B, A &gt; B, or A &lt; B). In each cell, the top scatter plots depict condition-level tRSA estimates (y-axis; blue, within-condition; orange, across-condition) against cRSA estimates (x-axis), whereas the bottom scatter plots depict the standard deviations of trial-level representational strength estimates from across-condition tRSA (y-axis) and within-condition tRSA (x-axis).</p></caption>
<graphic xlink:href="645646v1_figa1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</app>
<app id="app2">
<label>Appendix 2.</label>
<title>Supporting data and results for Experiment 2</title>
<table-wrap id="apptbl4" orientation="portrait" position="float">
<label>Appendix 2 Table 4.</label>
<caption><title>Behavioral results. Bold indicates participants excluded from Conceptual Retrieval Analyses.</title></caption>
<graphic xlink:href="645646v1_apptbl4.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="645646v1_apptbl4a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="apptbl5" orientation="portrait" position="float">
<label>Appendix 2 Table 5.</label>
<caption><title>Model selection using 3 criteria: Akaike information criterion (AIC), Bayesian information criterion (BIC), and log-liklihood ratio testing (LRT).</title></caption>
<graphic xlink:href="645646v1_apptbl5.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="645646v1_apptbl5a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="apptbl6" orientation="portrait" position="float">
<label>Appendix 2 Table 6.</label>
<caption><title>Significant nuisance effects in memorability model.</title></caption>
<graphic xlink:href="645646v1_apptbl6.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="645646v1_apptbl6a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</app>
</app-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106694.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Schapiro</surname>
<given-names>Anna C</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study proposes a potentially <bold>useful</bold> improvement on a popular fMRI method for quantifying representational similarity in brain measurements by focusing on representational strength at the single trial level and adding linear mixed effects modeling for group-level inference. The manuscript demonstrates increased sensitivity with no loss of precision compared to more classic versions of the method. However, the framing of the work with respect to these prior approaches is <bold>incomplete</bold>, several assumptions are insufficiently motivated, and it is unclear to what extent the approach would generalize to other paradigms.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106694.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The paper presents a novel method for RSA, called trial-level RSA (tRSA). The method first constructs a trial x trial representation dissimilarity matrix using correlation distances, assuming that (as in the empirical example) each trial has a unique stimulus. Whereas &quot;classical RSA&quot; correlates the entire upper triangular matrix of the RDM / RSM to a model RDM / RSM, tRSA first calculates the correlation to the model RDM per row, and then averages these values. The paper claims that tRSA has increased sensitivity and greater flexibility than classical RSA.</p>
<p>Strengths &amp; Weaknesses:</p>
<p>I have to admit that it took a few hours of intense work to understand this paper and to even figure out where the authors were coming from. The problem setting, nomenclature, and simulation methods presented in this paper do not conform to the notation common in the field, are often contradictory, and are usually hard to understand. Most importantly, the problem that the paper is trying to solve seems to me to be quite specific to the particular memory study in question, and is very different from the normal setting of model-comparative RSA that I (and I think other readers) may be more familiar with.</p>
<p>Main issues:</p>
<p>(1) The definition of &quot;classical RSA&quot; that the authors are using is very narrow. The group around Niko Kriegeskorte has developed RSA over the last 10 years, addressing many of the perceived limitations of the technique. For example, cross-validated distance measures (Walther et al. 2016; Nili et al. 2014; Diedrichsen et al. 2021) effectively deal with an uneven number of trials per condition and unequal amounts of measurement noise across trials. Different RDM comparators (Diedrichsen et al. 2021) and statistical methods for generalization across stimuli (Schütt et al. 2023) have been developed, addressing shortcomings in sensitivity. Finally, both a Bayesian variant of RSA (Pattern component modelling, (Diedrichsen, Yokoi, and Arbuckle 2018) and an encoding model (Naselaris et al. 2011) can effectively deal with continuous variables or features across time points or trials in a framework that is very related to RSA (Diedrichsen and Kriegeskorte 2017). The author may not consider these newer developments to be classical, but they are in common use and certainly provide the solution to the problems raised in this paper in the setting of model-comparative RSA in which there is more than one repetition per stimulus.</p>
<p>(2) The stated problem of the paper is to estimate &quot;representational strength&quot; in different regions or conditions. With this, the authors define the correlation of the brain RDM with a model RDM. This metric conflates a number of factors, namely the variances of the stimulus-specific patterns, the variance of the noise, the true differences between different dissimilarities, and the match between the assumed model and the data-generating model. It took me a long time to figure out that the authors are trying to solve a quite different problem in a quite different setting from the model-comparative approach to RSA that I would consider &quot;classical&quot; (Diedrichsen et al. 2021; Diedrichsen and Kriegeskorte 2017). In this approach, one is trying to test whether local activity patterns are better explained by representation model A or model B, and to estimate the degree to which the representation can be fully explained. In this framework, it is common practice to measure each stimulus at least 2 times, to be able to estimate the variance of noise patterns and the variance of signal patterns directly. Using this setting, I would define 'representational strength&quot; very differently from the authors. Assume (using LaTeX notation) that the activity patterns $y_j,n$ for stimulus j, measurement n, are composed of a true stimulus-related pattern ($u_j$) and a trial-specific noise pattern ($e_j,n$). As a measure of the strength of representation (or pattern), I would use an unbiased estimate of the variance of the true stimulus-specific patterns across voxels and stimuli ($\sigma^2_{u}$). This estimator can be obtained by correlating patterns of the same stimuli across repeated measures, or equivalently, by averaging the cross-validated Euclidean distances (or with spatial prewhitening, Mahalanobis distances) across all stimulus pairs. In contrast, the current paper addresses a specific problem in a quite specific experimental design in which there is only one repetition per stimulus. This means that the authors have no direct way of distinguishing true stimulus patterns from noise processes. The trick that the authors apply here is to assume that the brain data comes from the assumed model RDM (a somewhat sketchy assumption IMO) and that everything that reduces this correlation must be measurement noise. I can now see why tRSA does make some sense for this particular question in this memory study. However, in the more common model-comparative RSA setting, having only one repetition per stimulus in the experiment would be quite a fatal design flaw. Thus, the paper would do better if the authors could spell the specific problem addressed by their method right in the beginning, rather than trying to set up tRSA as a general alternative to &quot;classical RSA&quot;.</p>
<p>(3) The notation in the paper is often conflicting and should be clarified. The actual true and measured activity patterns should receive a unique notation that is distinct from the variances of these patterns across voxels. I assume that $\sigma_ijk$ is the noise variances (not standard deviation)? Normally, variances are denoted with $\sigma^2$. Also, if these are variances, they cannot come from a normal distribution as indicated on page 10. Finally, multi-level models are usually defined at the level of means (i.e., patterns) rather than at the level of variances (as they seem to be done here).</p>
<p>(4) In the first set of simulations, the authors sampled both model and brain RSM by drawing each cell (similarity) of the matrix from an independent bivariate normal distribution. As the authors note themselves, this way of producing RSMs violates the constraint that correlation matrices need to be positive semi-definite. Likely more seriously, it also ignores the fact that the different elements of the upper triangular part of a correlation matrix are not independent from each other (Diedrichsen et al. 2021). Therefore, it is not clear that this simulation is close enough to reality to provide any valuable insight and should be removed from the paper, along with the extensive discussion about why this simulation setting is plainly wrong (page 21). This would shorten and clarify the paper.</p>
<p>(5) If I understand the second simulation setting correctly, the true pattern for each stimulus was generated as an NxP matrix of i.i.d. standard normal variables. Thus, there is no condition-specific pattern at all, only condition-specific noise/signal variances. It is not clear how the tRSA would be biased if there were a condition-specific pattern (which, in reality, there usually is). Because of the i.i.d. assumption of the true signal, the correlations between all stimulus pairs within conditions are close to zero (and only differ from it by the fact that you are using a finite number of voxels). If you added a condition-specific pattern, the across-condition RSA would lead to much higher &quot;representational strength&quot; estimates than a within-condition RSA, with obvious problems and biases.</p>
<p>(6) The trial-level brain RDM to model Spearman correlations was analyzed using a mixed effects model. However, given the symmetry of the RDM, the correlations coming from different rows of the matrix are not independent, which is an assumption of the mixed effect model. This does not seem to induce an increase in Type I errors in the conditions studied, but there is no clear justification for this procedure, which needs to be justified.</p>
<p>(7) For the empirical data, it is not clear to me to what degree the &quot;representational strength&quot; of cRSA and tRSA is actually comparable. In cRSA, the Spearman correlation assesses whether the distances in the data RSM are ranked in the same order as in the model. For tRSA, the comparison is made for every row of the RSM, which introduces a larger degree of flexibility (possibly explaining the higher correlations in the first simulation). Thus, could the gains presented in Figure 7D not simply arise from the fact that you are testing different questions? A clearer theoretical analysis of the difference between the average row-wise Spearman correlation and the matrix-wise Spearman correlation is urgently needed. The behavior will likely vary with the structure of the true model RDM/RSM.</p>
<p>(8) For the real data, there are a number of additional sources of bias that need to be considered for the analysis. What if there are not only condition-specific differences in noise variance, but also a condition-specific pattern? Given that the stimuli were measured in 3 different imaging runs, you cannot assume that all measurement noise is i.i.d. - stimuli from the same run will likely have a higher correlation with each other.</p>
<p>(9) The discussion should be rewritten in light of the fact that the setting considered here is very different from the model-comparative RSA in which one usually has multiple measurements per stimulus per subject. In this setting, existing approaches such as RSA or PCM do indeed allow for the full modelling of differences in the &quot;representational strength&quot; - i.e., pattern variance across subjects, conditions, and stimuli. Cross-validated distances provide a powerful tool to control for differences in measurement noise variances and possible covariances in measurement noise across trials, which has many distinct advantages and is conceptually very different from the approach taken here. One of the main limitations of tRSA is the assumption that the model RDM is actually the true brain RDM, which may not be the case. Thus, in theory, there could be a different model RDM, in which representational strength measures would be very different. These differences should be explained more fully, hopefully leading to a more accessible paper.</p>
<p>References:</p>
<p>Diedrichsen, J., Berlot, E., Mur, M., Schütt, H. H., Shahbazi, M., &amp; Kriegeskorte, N. (2021). Comparing representational geometries using whitened unbiased-distance-matrix similarity. Neurons, Behavior, Data and Theory, 5(3). <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2007.02789">https://arxiv.org/abs/2007.02789</ext-link></p>
<p>Diedrichsen, J., &amp; Kriegeskorte, N. (2017). Representational models: A common framework for understanding encoding, pattern-component, and representational-similarity analysis. PLoS Computational Biology, 13(4), e1005508.</p>
<p>Diedrichsen, J., Yokoi, A., &amp; Arbuckle, S. A. (2018). Pattern component modeling: A flexible approach for understanding the representational structure of brain activity patterns. NeuroImage, 180, 119-133.</p>
<p>Naselaris, T., Kay, K. N., Nishimoto, S., &amp; Gallant, J. L. (2011). Encoding and decoding in fMRI. NeuroImage, 56(2), 400-410.</p>
<p>Nili, H., Wingfield, C., Walther, A., Su, L., Marslen-Wilson, W., &amp; Kriegeskorte, N. (2014). A toolbox for representational similarity analysis. PLoS Computational Biology, 10(4), e1003553.</p>
<p>Schütt, H. H., Kipnis, A. D., Diedrichsen, J., &amp; Kriegeskorte, N. (2023). Statistical inference on representational geometries. ELife, 12. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.82566">https://doi.org/10.7554/eLife.82566</ext-link></p>
<p>Walther, A., Nili, H., Ejaz, N., Alink, A., Kriegeskorte, N., &amp; Diedrichsen, J. (2016). Reliability of dissimilarity measures for multi-voxel pattern analysis. NeuroImage, 137, 188-200.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106694.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This methods paper proposes two changes to classic RSA, a popular method to probe neural representation in neuroimaging experiments: computing RSA at row/column level of RDM, and using mixed linear modeling to compute second-level statistics, using the individual row/columns to estimate a random effect of stimulus. The benefit of the new method is demonstrated using simulations and a re-analysis of a prior fMRI dataset on object perception and memory encoding.</p>
<p>Strengths:</p>
<p>(1) The paper is clearly written and features clear illustrations of the proposed method.</p>
<p>(2) The combination of simulation and real data works well, with the same factors being examined in both simulations and real data, resulting in a convincing demonstration of the benefits of tRSA in realistic experimental scenarios.</p>
<p>(3) I find the author's claim that tRSA is a promising approach to perform more complete modeling of cogneuro data, but also to conceptualize representation at the single trial/event level (cf Discussion section on P42), quite appealing.</p>
<p>Weaknesses:</p>
<p>(1) While I generally welcome the contribution (see above), I take some issue with the accusatory tone of the manuscript in the Introduction. The text there (using words such as 'ignored variances', 'errouneous inferences', 'one must', 'not well-suited', 'misleading') appears aimed at turning cRSA in a 'straw man' with many limitations that other researchers have not recognized but that the new proposed method supposedly resolves. This can be written in a more nuanced, constructive manner without accusing the numerous users of this popular method of ignorance.</p>
<p>(2) The described limitations are also not entirely correct, in my view: for example, statistical inference in cRSA is not always done using classic parametric statistics such as t-tests (cf Figure 1): the rsatoolbox paper by Nili et al. (2014) outlines non-parametric alternatives based on permutation tests, bootstrapping and sign tests, which are commonly used in the field. Nor has RSA ever been conducted at the row/column level (here referred to by the authors as 'trial level'; cf King et al., 2018).</p>
<p>(3) One of the advantages of cRSA is its simplicity. Adding linear mixed effects modeling to RSA introduces a host of additional 'analysis parameters' pertaining to the choice of the model setup (random effects, fixed effects, interactions, what error terms to use) - how should future users of tRSA navigate this?</p>
<p>(4) Here, only a single real fMRI dataset is used with a quite complicated experimental design for the memory part; it's not clear if there is any benefit of using tRSA on a simpler real dataset. What's the benefit of tRSA in classic RSA datasets (e.g., Kriegeskorte et al., 2008), with fixed stimulus conditions and no behavior?</p>
<p>(5) The cells of an RDM/RSM reflect pairwise comparisons between response patterns (typically a brain but can be any system; cf Sucholutsky et al., 2023). Because the response patterns are repeatedly compared, the cells of this matrix are not independent of one another. Does this raise issues with the validity of the linear mixed effects model? Does it assume the observations are linearly independent?</p>
<p>(6) The manuscript assumes the reader is familiar with technical statistical terms such as Type I/II error, sensitivity, specificity, homoscedasticity assumptions, as well as linear mixed models (fixed effects, random effects, etc). I am concerned that this jargon makes the paper difficult to understand for a broad readership or even researchers currently using cRSA that might be interested in trying tRSA.</p>
<p>(7) I could not find any statement on data availability or code availability. Given that the manuscript reuses prior data and proposes a new method, making data and code/tutorials openly available would greatly enhance the potential impact and utility for the community.</p>
<p>References</p>
<p>King, M. L., Groen, I. I., Steel, A., Kravitz, D. J., &amp; Baker, C. I. (2019). Similarity judgments and cortical visual responses reflect different properties of object and scene categories in naturalistic images. NeuroImage, 197, 368-382.</p>
<p>Kriegeskorte, N., Mur, M., Ruff, D. A., Kiani, R., Bodurka, J., Esteky, H., ... &amp; Bandettini, P. A. (2008). Matching categorical object representations in inferior temporal cortex of man and monkey. Neuron, 60(6), 1126-1141.</p>
<p>Nili, H., Wingfield, C., Walther, A., Su, L., Marslen-Wilson, W., &amp; Kriegeskorte, N. (2014). A toolbox for representational similarity analysis. PLoS computational biology, 10(4), e1003553.</p>
<p>Sucholutsky, I., Muttenthaler, L., Weller, A., Peng, A., Bobu, A., Kim, B., ... &amp; Griffiths, T. L. (2023). Getting aligned on representational alignment. arXiv preprint arXiv:2310.13018.</p>
</body>
</sub-article>
</article>