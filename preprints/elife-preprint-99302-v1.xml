<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">99302</article-id>
<article-id pub-id-type="doi">10.7554/eLife.99302</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.99302.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Decoding the Cognitive map: Learning place cells and remapping</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9004-4995</contrib-id>
<name>
<surname>Pettersen</surname>
<given-names>Markus Borud</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8932-5706</contrib-id>
<name>
<surname>Schøyen</surname>
<given-names>Vemund Sigmundson</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8138-3995</contrib-id>
<name>
<surname>Malthe-Sørenssen</surname>
<given-names>Anders</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4262-5549</contrib-id>
<name>
<surname>Lepperød</surname>
<given-names>Mikkel Elle</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Simula Research Laboratory</institution></aff>
<aff id="a2"><label>2</label><institution>University of Oslo, Department of Biosciences</institution></aff>
<aff id="a3"><label>3</label><institution>University of Oslo, Department of Physics</institution></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Bhalla</surname>
<given-names>Upinder S</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Centre for Biological Sciences</institution>
</institution-wrap>
<city>Bangalore</city>
<country>India</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding author, <email>mikkel@simula.no</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-07-17">
<day>17</day>
<month>07</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP99302</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-05-08">
<day>08</day>
<month>05</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-03-25">
<day>25</day>
<month>03</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.03.14.585049"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Pettersen et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Pettersen et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-99302-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Hippocampal place cells are known for their spatially selective firing and are believed to encode an animal’s location while forming part of a cognitive map of space. These cells exhibit marked tuning curve and rate changes when an animal’s environment is sufficiently manipulated, in a process known as remapping. Place cells are accompanied by many other spatially tuned cells such as border cells and grid cells, but how these cells interact during navigation and remapping is unknown. In this work, we build a normative place cell model wherein a neural network is tasked with accurate position reconstruction and path integration. Motivated by the notion of a cognitive map, the network’s position is estimated directly from its learned representations. To obtain a position estimate, we propose a non-trainable decoding scheme applied to network output units, inspired by the localized firing patterns of place cells. We find that output units learn place-like spatial representations, while upstream recurrent units become boundary-tuned. When the network is trained to perform the same task in multiple simulated environments, its place-like units learn to remap like biological place cells, displaying global, geometric and rate remapping. These remapping abilities appear to be supported by rate changes in upstream units. While the model does not learn grid-like units, its place cell centers form clusters organized in a hexagonal lattice in open fields. When we decode the center locations of CA1 place fields in mice, we find a similar clustering tendency. This suggests a potential mechanism for the interaction between place cells, border cells, and grid cells. Our model provides a normative framework for learning spatial representations previously reserved for biological place cells, providing new insight into place cell field formation and remapping.</p>
</abstract>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>To further evaluate the predictions of our proposed model of place field distribution, we added a comparison to experimental data, which corroborates our findings.</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/bioAI-Oslo/VPC">https://github.com/bioAI-Oslo/VPC</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Being able to accurately determine your location in an environment is an essential skill shared by any navigating system, both animal and machine. Hippocampal place cells [<xref ref-type="bibr" rid="c1">1</xref>] are believed to be crucial for this ability in animals. Place cells get their name from their distinct spatial tuning: A single place cell only tends to fire in select locations within a given recording environment [<xref ref-type="bibr" rid="c2">2</xref>], [<xref ref-type="bibr" rid="c3">3</xref>].</p>
<p>When an animal is moved between different recording arenas, or a familiar environment is significantly manipulated, place cells can undergo global remapping [<xref ref-type="bibr" rid="c4">4</xref>], wherein spatial responses are uncorrelated across environments. For less severe changes to the environment (e.g., mild changes in smell or color), place cells can also exhibit less drastic tuning curve changes in the form of partial [<xref ref-type="bibr" rid="c5">5</xref>], rate [<xref ref-type="bibr" rid="c6">6</xref>] and orientation [<xref ref-type="bibr" rid="c7">7</xref>] remapping. Furthermore, geometric modifications of a recording environment elicit distinct place field changes. For example, elongating an environment induces field elongation [<xref ref-type="bibr" rid="c8">8</xref>]. Adding a novel wall to a familiar environment may spur so-called field doubling [<xref ref-type="bibr" rid="c9">9</xref>], where a second place field emerges, situated at the same distance from the new wall as the field used to be to from original.</p>
<p>Since the discovery of place cells, a range of other neuron types with navigational behavior correlates have been discovered experimentally. These include head direction cells [<xref ref-type="bibr" rid="c10">10</xref>], grid cells [<xref ref-type="bibr" rid="c11">11</xref>], border cells [<xref ref-type="bibr" rid="c12">12</xref>], [<xref ref-type="bibr" rid="c13">13</xref>], band cells [<xref ref-type="bibr" rid="c14">14</xref>] and object vector cells [<xref ref-type="bibr" rid="c15">15</xref>]. Some of these spatial cells can also exhibit changes in their firing profile when an animal is moved between different recording arenas or a familiar environment is sufficiently manipulated [<xref ref-type="bibr" rid="c10">10</xref>], [<xref ref-type="bibr" rid="c16">16</xref>].</p>
<p>How does the orchestra of spatial cell types observed in the brain cooperate to do navigation? One popular theory posits that spatial cells collectively set up cognitive maps of the animal’s surroundings [<xref ref-type="bibr" rid="c17">17</xref>]–[<xref ref-type="bibr" rid="c19">19</xref>]. In the past, the term cognitive map has been used colloquially, referring to everything from a neural representation of geometry to charts of social relationships [<xref ref-type="bibr" rid="c17">17</xref>], [<xref ref-type="bibr" rid="c19">19</xref>]– [<xref ref-type="bibr" rid="c22">22</xref>]. In this work, we make the intuitive notion of a spatial cognitive map precise by proposing a mathematical definition of it. As we will show, this definition serves as a foundation for developing models of spatial cell types and can be used to describe several normative models in the literature.</p>
<p>A range of models have already been proposed in an attempt to explain the striking spatial tuning and remapping behaviors exhibited by place cells. One prominent theory holds that place cell activity results from upstream input from grid cells in the medial Entorhinal Cortex (mEC) [<xref ref-type="bibr" rid="c5">5</xref>], [<xref ref-type="bibr" rid="c23">23</xref>], [<xref ref-type="bibr" rid="c24">24</xref>]. However, there are several experimental findings that challenge this so-called forward theory. For instance, place cells tend to mature prior to grid cells in rodent development [<xref ref-type="bibr" rid="c25">25</xref>], [<xref ref-type="bibr" rid="c26">26</xref>]. Also, place cell inactivation has been associated with abolished grid cell activity, rather than the other way around [<xref ref-type="bibr" rid="c27">27</xref>]. Another approach is to suggest that non-grid spatial cells are responsible [<xref ref-type="bibr" rid="c9">9</xref>], [<xref ref-type="bibr" rid="c27">27</xref>], [<xref ref-type="bibr" rid="c28">28</xref>]. However, the exact origins of place fields and their remapping behavior remain undetermined.</p>
<p>How, then, would one go about modeling place cells in a way that allows for <italic>discovering</italic> how place fields emerge, how remapping occurs, and how different cell types relate? An exciting recent alternative is to leverage normative models of the Hippocampus and surrounding regions, using neural networks optimized for a navigation task. When trained, such models learn tuning profiles similar to their biological counterparts [<xref ref-type="bibr" rid="c22">22</xref>], [<xref ref-type="bibr" rid="c29">29</xref>]–[<xref ref-type="bibr" rid="c35">35</xref>]. To the best of our knowledge, however, no normative models have tackled the problem of directly learning place cell formation and remapping. Only some address remapping, but do so for other cell types or brain regions [<xref ref-type="bibr" rid="c22">22</xref>], [<xref ref-type="bibr" rid="c35">35</xref>]–[<xref ref-type="bibr" rid="c37">37</xref>].</p>
<p>Using our definition of a cognitive map, we therefore propose a normative model of spatial navigation with the flexibility required to study place cells and remapping in one framework. In our model, the output representations of a neural network are decoded into a position estimate. Simultaneously, the network is tasked with accurate position reconstruction while path integrating. Crucially, the non-trainable decoding operation is inspired by the localized firing patterns of place cells, but with minimal constraints on their individual tuning profile, and their population coding properties.</p>
<p>We find that our model learns representations with spatial tuning profiles similar to those found in the mammalian brain, including place units in the downstream output layer and predominantly border-tuned units in the upstream recurrent layer. We thus find that border representations are the main spatially tuned basis for forming place cell representations, aligning with previous mechanistic theories of place cell formation from border cells [<xref ref-type="bibr" rid="c9">9</xref>].</p>
<p>Interestingly, our model does not learn grid-like representations despite being able to path integrate. Thus, our work raises questions about the necessity of grid cells for path integration. However, we find that the centers of the learned place fields arrange on a hexagonal lattice in open arenas. This indicates that although grid-like cells are not necessary to form place cells, optimal position decoding still dictates hexagonal symmetry. Inspired by this, we decode center locations for CA1 place fields in mice (data provided by [<xref ref-type="bibr" rid="c38">38</xref>]), and find that biological place cells exhibit clustering, in a similar manner as our model.</p>
<p>We train our model in multiple environments and observe that the network learns global, rate and geometric remapping akin to biological place cells. We find that remapping in the place-like units of the network can be understood as a consequence of sparse input from near-independent sets of upstream, rate-remapping boundary-tuned units. Thus, we show that border cell input can explain not only place field formation, but also remapping.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Results</title>
<sec id="s2a">
<label>2.1</label>
<title>Decoding the Cognitive Map</title>
<p>The foundation for the proposed place cell model is a learned cognitive map of space. We define a spatial cognitive map as a (vector-valued) function <bold>û</bold> <italic>∈</italic> ℝ<sup><italic>N</italic></sup> that minimizes
<disp-formula id="eqn1">
<graphic xlink:href="585049v2_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <bold>u</bold>(<bold>x</bold><sub><italic>t</italic></sub>) <italic>∈</italic> ℝ<sup><italic>M</italic></sup> is some target spatial representation at a true location <bold>x</bold><sub><italic>t</italic></sub> (e.g. <italic>∈</italic> ℝ<sup>2</sup>) at a particular time <italic>t</italic>, while <bold>û</bold> is the learned representation, constrained according to some conditions <italic>R</italic>. Lastly, <bold>z</bold><sub><italic>t</italic></sub> is a latent position estimate corresponding to <bold>x</bold><sub><italic>t</italic></sub>. In our case, we consider a recurrently connected neural network architecture navigating along simulated trajectories. As such, <bold>z</bold><sub><italic>t</italic></sub> can be thought of as the network’s (internal) position estimate at a particular trajectory step, formed by integrating earlier locations and velocities. For details, refer to Model &amp; Objective.</p>
<p>Each entry in <bold>û</bold> can be viewed as the firing rate of a unit in an ensemble of <italic>N</italic> simulated neurons. On the other hand, <bold>u</bold> is an alternative representation of the space that we wish to represent. In machine learning terms, <italic>ℒ</italic> is the loss function, while <italic>R</italic> is a regularization term. In our case, we want <italic>ℒ</italic> to gauge the similarity between the learned and target representations, and for <italic>R</italic> to impose biological constraints on the learned <bold>û</bold>.</p>
<p>The target representation <bold>u</bold> does not need to be of the same dimensionality as <bold>û</bold>, or even particularly biologically plausible. This is evident in several prominent models in the literature [<xref ref-type="bibr" rid="c29">29</xref>]–[<xref ref-type="bibr" rid="c31">31</xref>], [<xref ref-type="bibr" rid="c39">39</xref>] which can be accomodated by the proposed definition in <xref ref-type="disp-formula" rid="eqn1">Eq. (1)</xref> (see A Taxonomy of Cognitive Maps for complete descriptions). As an example, Cueva <italic>et al</italic>. trained a recurrent neural network (RNN) to minimize the mean squared error between a Cartesian coordinate target representation and a predicted coordinate decoded from the neural network [<xref ref-type="bibr" rid="c29">29</xref>]. Remarkably, by adding biologically plausible constraints (including “energy” constraints and noise injection) to this network, the authors found that the learned representations resembled biological (albeit square) grid cells.</p>
<p>As the goal of this work is to arrive at a model of place cells, we will denote the learned representation as <bold>p</bold>. We take <bold>p</bold> to be produced by a neural network with non-negative firing rates, whose architecture is illustrated in <xref rid="fig1" ref-type="fig">Fig. 1a</xref>). Specifically, the network features recurrently connected units (with states <bold>g</bold>) that project onto output units (with states <bold>p</bold>), in loose analogy to the connectivity of the Entorhinal Cortex and CA1 subfield of the Hippocampus [<xref ref-type="bibr" rid="c4">4</xref>], [<xref ref-type="bibr" rid="c40">40</xref>].</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>The model and task.</title>
<p>a) Overview of the decoding approach: Given a simulated trajectory with coordinates <bold>x</bold>, the output states of the network are decoded in terms of their spatial center locations <bold><italic>µ</italic></bold>, which in turn are used to decode an estimate of the current location <inline-formula><inline-graphic xlink:href="585049v2_inline17.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The network is trained to minimize the squared difference between true and decoded positions. b) Illustration of the proposed decoding procedure. For a single unit, the center location is estimated as the average location, weighted by the unit activity along a trajectory. By iterating this procedure, every unit can be assigned a center location. A location can then be estimated as the average center location, weighted by the activity of the corresponding unit at a particular time. Repeating this for every timestep, full trajectories can be reconstructed. c) The investigated geometries, each with an example simulated trajectory. Each environment is labelled by its context signal (one-hot vector). d) Illustration of the network architecture and inputs. <bold>g</bold> features recurrently connected units, while <bold>p</bold> receives densely connected feedforward input from <bold>g</bold>. When moved between environments, the state of the RNN is maintained (<bold>g</bold><sub>prev</sub>). The input <bold>v</bold> denotes Cartesian velocities along simulated trajectories, while <bold>c</bold> is a constant (in time and space) context signal.</p></caption>
<graphic xlink:href="585049v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We constrain the “energy” of the learned representation by imposing an L1 penalty on its magnitude, use Cartesian coordinates as our target representation, and the mean squared error as our loss. In other words,
<disp-formula id="eqn2">
<graphic xlink:href="585049v2_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <bold>x</bold><sub><italic>t</italic></sub> is a true Cartesian coordinate, | · | <sub><italic>p</italic></sub> denotes the <italic>p</italic>-norm and <italic>λ</italic> is a regularization hyperparameter. Crucially, however, Cartesian coordinates are not predicted directly by the network, but are decoded from the population activity of the output layer. This decoder is non-trainable and inspired by the localized firing profile of place cells. Concretely, we form a position estimate directly from the population activity, according to
<disp-formula id="eqn3">
<graphic xlink:href="585049v2_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>ε</italic> is a small constant to prevent zero-division, while
<disp-formula id="eqn4">
<graphic xlink:href="585049v2_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
is the estimated <italic>center</italic> of a given output unit. Note that the decoding essentially just consists of two soft maximum operations: <xref ref-type="disp-formula" rid="eqn4">Eq. (4)</xref> estimates the location of a cell’s maximal activity and <xref ref-type="disp-formula" rid="eqn3">Eq. (3)</xref> yields a predicted position using a weighted average (i.e. an approximate center of mass) of unit activity and their corresponding center locations.</p>
<p>Intuitively, if one cell is highly active at a particular location, its center location will be pulled toward that position. If the centers of the entire ensemble can be established, a position estimate can then be formed as a weighted (by firing rate) sum of the ensemble activity. If multiple units in a particular region of space are co-active, the position estimate is pulled towards the (weighted) average of their center locations. This approach allows us to extract a position estimate directly from the neural ensemble without knowing the shape or firing characteristics of a given unit.</p>
<p><xref rid="fig1" ref-type="fig">Fig. 1a</xref>) provides a high-level overview of the proposed decoding scheme and the network explored in this work, and <xref rid="fig1" ref-type="fig">Fig. 1b</xref>) provides a more detailed account of how output unit activity is decoded to estimate the network’s position.</p>
<p>The network is tasked with minimizing <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref> while simultaneously path integrating (see 4.1 for details) along simulated trajectories in six distinct environments. Each environment, along with example trajectories is shown in <xref rid="fig1" ref-type="fig">Fig. 1c</xref>). To discriminate between environments the network is also provided with a constant context signal that uniquely identifies the geometry. An overview of the network architecture and inputs is given in <xref rid="fig1" ref-type="fig">Fig. 1d</xref>), and each context signal in inset in <xref rid="fig1" ref-type="fig">Fig. 1c</xref>).</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Learned Representations and Remapping</title>
<p>With a model in place, we proceed by investigating the learned representations and behaviors of the trained network. <xref rid="fig2" ref-type="fig">Fig. 2a</xref>) shows the evolution of the decoding error (the average Euclidean distance between true and predicted trajectories) as a function of training time for the RNN. The validation set error closely trails the training error, and appears to converge around 0.15. The error is computed as an average over all six environments and over full trajectories (time). Thus, the decoding error includes initial timesteps, where the network has no positional information. Disentangled errors for each environment and along trajectories (time) can be seen in supplementary Fig. A1, showing how different environments have different error profiles, and how errors decrease after some initial exploration. This can also be seen in <xref rid="fig2" ref-type="fig">Fig. 2b</xref>), which showcases a slice of a true and corresponding predicted trajectory for timesteps 250 to 400 in the square environment.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Trained network performance and representations.</title>
<p>a) Euclidean distance (error) between target and reconstructed trajectories over training time. Shown is the error for both training and validation datasets. b) A slice (timesteps 250 to 400) of a decoded trajectory (dashed, red) and the corresponding target trajectory (black). c) Ratemaps for the 16 output units with the largest mean activity, in the square environment. d) Same as c), but for recurrent units.</p></caption>
<graphic xlink:href="585049v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Having established that network predictions align with target trajectories (confirming that the network has learned to path integrate), we consider the learned representations of the network. <xref rid="fig2" ref-type="fig">Fig. 2c</xref>) displays ratemaps of the 16 most active output units in the square environment. Notably, the responses of these units resemble biological place cell tuning curves. The learned place fields appear unimodal, isotropic and with a monotonically decaying firing rate from its center, much like a Gaussian profile. However, some units display more irregular fields, especially near boundaries and corners. Responses of the most active recurrent units resemble biological border cells (<xref rid="fig2" ref-type="fig">Fig. 2d</xref>)).</p>
<p>For both the output and recurrent layers, a large fraction of units are silent, or display no clear spatial tuning (see <xref ref-type="fig" rid="figA2">Fig. A2</xref> and <xref ref-type="fig" rid="figA3">A3</xref> for ratemaps in all environments). For example, in the square arena, approximately half of all output units are silent.</p>
<p>Interestingly, when comparing network spatial responses across environments, units display changes in their tuning curve. This effect can be clearly observed in unit ratemaps shown in <xref rid="fig3" ref-type="fig">Fig. 3a</xref>). In the numerical experiment, the trained network is first run in the square environment (A), before being moved to the square with a central wall (B), and subsequently returned to the original square (A’). Visually, many output units exhibit marked shifts in their preferred firing location when the network is moved between contexts (i.e. transfers A to B or B to A’). However, returning to the original context appears to cause fields to revert to their original preferred firing locations. Besides firing location modifications, units also exhibit distinct rate changes.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Comparing representations across environments.</title>
<p>a) Top: The network is run in a familiar square environment (A), transferred to the square with a central wall (B) and revisits the original square (A’). The network state persists between environments, and starting locations are randomly drawn. Bottom: i) Ratemaps for a subset of recurrent units (<bold>g</bold>) with largest minimum mean rate across arenas. Rows represent unit activity, with max rate inset on the right. ii) Same as i), for output units. b) Distribution of spatial correlations comparing ratemaps from active units across similar contexts (A, A’) and distinct contexts (A, B). Shuffled distributions are randomly paired units across environments. The dashed red line indicates the 95th percentile of the shuffled distribution. c) Distribution of rate overlaps for all units with non-zero activity in any environment. d) Distribution of rate differences. e) Ratemap population vector correlations for units with nonzero activity at every timestep for transitions (timestep 500) from A to B.</p></caption>
<graphic xlink:href="585049v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Besides output units, recurrently connected units also display remapping behaviors when the network is moved between environments. As shown in the unit ratemaps of <xref rid="fig3" ref-type="fig">Fig. 3a</xref>) i), boundary units also exhibit rate changes. In particular, several units are silenced when moving between conditions. However, none of the included units exhibit changes in their preferred firing location. Thus, <italic>recurrent units appear to remap mainly through pronounced rate changes</italic>.</p>
<p>These observations are supported by multiple analyses (<xref rid="fig3" ref-type="fig">Fig. 3b-e</xref>)). In particular, the distribution of output unit spatial correlations across different environments (A and B) matches that expected from a shuffled distribution. Conversely, correlations comparing different visits of the same environment (A and A’) are different from a shuffled distribution (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>)). This behavior is consistent with global remapping behavior [<xref ref-type="bibr" rid="c4">4</xref>], [<xref ref-type="bibr" rid="c6">6</xref>]. Notably, the network’s remapping occurs with fixed weights (i.e., after training).</p>
<p>Rate overlaps (<xref rid="fig3" ref-type="fig">Fig. 3c</xref>)) display similar distributional properties: Comparing across environments yields rate overlaps resembling those from a shuffled distribution, and comparing similar environments yields higher rate overlaps.</p>
<p>Rate differences (<xref rid="fig3" ref-type="fig">Fig. 3d</xref>)) also follow the same trend. In this case, the difference in rates between A and A’ are chiefly zero-centered and approximately symmetric, suggesting that there are only small rate changes when revisiting an environment. The rate difference between environments (and between shuffled units), is also roughly symmetric. However, in this case the distribution is bimodal with peaks corresponding to maximally different rates. Thus, a large number of output units are active in only one environment. Again, the distribution of differences between distinct contexts closely trails a shuffled distribution.</p>
<p>As shown in <xref rid="fig3" ref-type="fig">Fig. 3e</xref>), ratemap population vector correlations mirror the transition between environments, both for recurrent units and output units. Included are correlations for the transition from A to B (at timestep 500). Notably, there is a sharp drop-off in correlation at the transfer time, demonstrating that population vectors are uncorrelated between environments for both unit types. Conversely, ratemaps are highly correlated within an environment. However, there is a time delay before maximum correlation is achieved.</p>
<p>Together, these findings show that the model learns place- and border like spatial representations. Moreover, output units exhibit global remapping between contexts, whereas recurrent units mainly rate remap.</p>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Effects of Geometric Manipulations</title>
<p>In addition to remapping between different contexts, we show that manipulating familiar geometries induces distinct representational changes. In particular, <xref rid="fig4" ref-type="fig">Fig. 4a</xref>) shows how unit ratemaps respond as the familiar square environment is elongated horizontally. Intriguingly, the learned place-like fields of the output units appear to expand with the arena. For sufficient elongation, responses even appear to split, with an additional, albeit weaker firing field emerging ( e.g. lower right output unit). Elongation behavior has also been observed in biological place cells in similar experiments [<xref ref-type="bibr" rid="c8">8</xref>].</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Effects of geometric manipulations on learned representations while maintaining the original context signal.</title>
<p>a) Ratemaps of 9 recurrent (<bold>g</bold>) and output units (<bold>p</bold>) during horizontal elongation of a familiar square context. The top inset indicates the geometry and context signal (A), as well as manipulation of the environment (horizontal stretch by factors of 2 and 3). b) Similar to a), but the geometric manipulation consists of filling in the central hole of the familiar context (square with central hole, context B). c) Similar to a), but for joint horizontal and vertical elongation. d) Similar to c), but for uniform expansion of a familiar circular environment (C).</p></caption>
<graphic xlink:href="585049v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Expanding the square also elicits a distinct response in recurrent units: Unit firing fields extend to the newly accessible region, while maintaining their affinity for boundaries. A similar effect can be observed in <xref rid="fig4" ref-type="fig">Fig. 4b</xref>), where the central hole is removed from a familiar geometry. In this case, both recurrent and output units perform field completion by extending existing firing fields to previously unseen regions. This shows that the network is capable of generalizing to never-before seen regions of space.</p>
<p>Finally, we also considered the effects of expanding environments in a symmetric fashion. Included are results for the familiar square (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>)) and circular (<xref rid="fig4" ref-type="fig">Fig. 4d</xref>)) environments. Unlike the single-axis expansion in <xref rid="fig4" ref-type="fig">Fig. 4a</xref>), network representations expand symmetrically in response to uniform expansion. However, some output units display distinct field doubling (see both <xref rid="fig4" ref-type="fig">Fig. 4c</xref>), bottom right, and <xref rid="fig4" ref-type="fig">Fig. 4d</xref>), middle row). For large expansions (3x), output responses become more irregular. However, in the square environment, there are still visible subpeaks within unit ratemaps. Also notable is the fact that some output units reflect their main boundary input (with greater activity near one boundary). Recurrent units, on the other hand, largely maintain their firing profile. In the circular environment, some output units display an almost center surround-like profile (e.g. middle row, two rightmost units). This peculiar tuning pattern is an experimentally testable prediction of our model.</p>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Contexts are Attractive</title>
<p>We have demonstrated that the RNN exhibits signs of global remapping between different familiar contexts, and field changes when a familiar geometry is altered. In this section, we further explore the behavior of the network when perturbing its internal states out of its normal operating range. Finally, we also discover possible mechanisms supporting the network’s remapping ability.</p>
<p>The first analysis consists of injecting noise into the recurrent state of the network, to determine whether it exhibits attractor-like behavior. <xref rid="fig5" ref-type="fig">Fig. 5</xref> shows resulting ratemap population vector correlations for an 800-step trajectories in the square context, when noise is injected at the midpoint of the sequence. When no noise is injected (<italic>σ</italic> = 0), both recurrent units (<xref rid="fig5" ref-type="fig">Fig. 5a</xref>)) and output units (<xref rid="fig5" ref-type="fig">Fig. 5b</xref>)) quickly settle into a stable, high correlation state. Unit ratemaps reveal that this state corresponds to network units firing at their preferred locations.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Effects of noise injection during navigation.</title>
<p>a) Ratemap population vector Pearson correlation between timepoints of 800-step trajectories in the square environment. At timestep 400, additive Gaussian noise (with standard deviation <italic>σ</italic>) is injected into the recurrent state (<bold>g</bold>). The top row shows correlations for different noise levels (<italic>σ</italic> = 0, 0.01, 0.1, and 1.0). The bottom row features ratemaps of the four units with largest mean activity, at different timepoints. Ratemaps are shown for <italic>σ</italic> = 0 and <italic>σ</italic> = 1.0. b) Same as a), but for output units (<bold>p</bold>).</p></caption>
<graphic xlink:href="585049v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>When noise is injected, ratemap correlations temporarily decrease, before the network settles back into a steady-state configuration. Importantly, states before, and long after noise injection are highly correlated. We observe that this is the case even for large amounts of injected noise, as can be seen from unit ratemaps for <italic>σ</italic> = 1.0. We also observe that the time required to reach a steady state increases in proportion to the amount of noise injected. Thus, even though the network was trained without noise, it appears robust even to large perturbations. This suggests that the learned solutions form an approximate attractor.</p>
<p>To further explore the network’s behavior, we applied dimensionality reduction techniques to network states along a single trajectory visiting all geometries (and contexts).</p>
<p>Remarkably, we find that a low-dimensional projection of the recurrent state captures the shape of each traversed environment. The top row of <xref rid="fig6" ref-type="fig">Fig. 6a</xref>) showcases a 3D projection of the recurrent state, where each point is color coded by the visited environment. Besides reflecting the shape of the environment, the low-dimensional projection also showcases transitions between environments. For output units (bottom row of <xref rid="fig6" ref-type="fig">Fig. 6a</xref>)), the low-dimensional projection consists of intersecting hyperplanes, that appear to maintain some of the structure of the original geometry. For example, states produced in the square with a central hole, appears to maintain a central void in the low-dimensional projection. The difference between recurrent and output states may reflect the pronounced sparsity of the recurrent layer, as well as the observed reuse of output units during remapping. In other words, a large number of recurrent units are mutually silent across environments, which could make for easily separable states. In contrast, a larger fraction of output units are used, and reused, across environments leading to entangled and less separable states.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Low-dimensional behavior of the trained recurrent network.</title>
<p>a) Low-dimesional UMAP projection of the recurrent (top) and output unit (bottom) activity for a trajectory visiting all six environments. The color of a point in the cloud indicates the corresponding environment b) Fractional and cumulative explained variance using PCA for recurrent units for each environment. c) similar to b) but for output units. (color scheme as in a)). d) Eigenvalue spectrum of the recurrent weight matrix. The unit circle (gray) is inset for reference. e) Jitter plots of context weights corresponding to each environment. For every environment, the weight to each recurrent unit is indicated. f) Pearson correlation between context weights corresponding to different environments.</p></caption>
<graphic xlink:href="585049v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Using PCA, we find that the recurrent states of the network within an environment can be well described using just a few principal components (4 principal components explains <italic>&gt;</italic>90 % of the variance). For reference, <xref rid="fig6" ref-type="fig">Fig. 6b</xref>) showcases the fraction of explained variance, as well as the cumulative variance of the recurrent state. However, the same is not true for the full trajectory visiting all environments (requiring around 20 principal components to achieve a similar amount of explained variance). This hints that the multi-environment representation can be factorized into several independent, low-dimensional representations, possibly one for each environment.</p>
<p>A similar trend is evident for output unit responses (shown in <xref rid="fig6" ref-type="fig">Fig. 6c</xref>)). However, in this case, a larger number of units is needed to explain a substantial fraction of the state variance for each environment (<italic>&gt;</italic> 25 for approximately 70-90 % explained variance) with noticeable differences between environments. Also, almost all (<italic>&gt;</italic> 75, out of a 100) principal components are required to account for the full output state across environments. It thus appears that more, independent units are active within a given environment, and that all 100 units are involved in encoding the full set of environments.</p>
<p>To begin exploring possible mechanisms supporting remapping, and the apparent independence of network states across environments, we investigated the weights of the recurrent layer. <xref rid="fig6" ref-type="fig">Fig. 6d</xref>) shows the eigenvalues of the recurrent weight matrix. It has several eigenvalues with above-unit magnitude. In other words, the RNN is potentially unstable. However, as shown in <xref ref-type="fig" rid="figA1">Fig. A1</xref>, the network exhibits stable decoding errors, even for very long sequences. Moreover, we know from <xref rid="fig5" ref-type="fig">Fig. 5</xref> that the network is stable in the face of transient noise injection. One possibility is that large eigenvalues are associated with remapping where unstable eigenvectors are used to transition between discrete attractors representing distinct environments.</p>
<p>How then, does the network switch between representations? While a complete description depends on the non-linear behavior of the full RNN, we observe a relationship within the context input weights that could shed light on the behavior in the network. Concretely, we find that a large proportion of context weights are negative (<xref rid="fig6" ref-type="fig">Fig. 6e</xref>)), and the rows of this matrix are largely uncorrelated (<xref rid="fig6" ref-type="fig">Fig. 6f</xref>)). Thus, the context signal (which is non-negative) could inhibit independent sets of units, leading to sparse and orthogonal recurrent units across environments through rate changes.</p>
</sec>
<sec id="s2e">
<label>2.5</label>
<title>Distribution of Learned Centers</title>
<p>Experimentally, place fields appear be irregularly distributed throughout large environments with a small increase in the number of fields near boundaries [<xref ref-type="bibr" rid="c41">41</xref>]. Place field phases have also been shown to correlate with the peak firing locations of grid cells [<xref ref-type="bibr" rid="c22">22</xref>]. We therefore explore whether there is structure to the spatial arrangement of the model’s learned place fields.</p>
<p><xref rid="fig7" ref-type="fig">Fig. 7a</xref>) shows the arrangement of decoded centers for all units, collected over 100 long-sequence trajectories, in each environment. In other words, for each cell in the population, their centers are decoded 100 times, one for each trajectory. Surprisingly, we find that the decoded centers tend to reside on the vertices of a semi-hexagonal grid, especially in larger symmetrical geometries. This effect is especially evident in the square and large square environments. However, in all environments, this grid structure exhibits distortions, and in case of an anisotropic environment (the rectangle), the grid is clearly elongated along the horizontal axis. Our findings accord with the notion that place fields are likely to reside on the vertices of a hexagonal grid [<xref ref-type="bibr" rid="c22">22</xref>]. However, our model does not feature any grid-like units.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7:</label>
<caption><p>a) All center locations for each unit in every geometry, decoded from 100, 30000-timestep trajectories for units with high spatial information. b) Center locations and marginal distributions of centers in each environment, for active units along a single trajectory. c) Displacement of centers between environments for units with high spatial information. Every unit is color coded by its spatial location in the environment on the diagonal. For each row, the distribution of the included units are shown in every other environment. d) Same as c), but for all units. e) Experimental CA1 place field centers decoded from ratemaps for a mouse foraging in a square 75<italic>×</italic>75 cm environment (left) and corresponding kernel density estimate (right). f) Ripley’s H for the field centers in e) and random (uniform) distributions on the same 15<italic>×</italic>15 grid as in e). The shaded region indicates two standard deviations for 100 random samplings of the grid.</p></caption>
<graphic xlink:href="585049v2_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In <xref rid="fig7" ref-type="fig">Fig. 7b</xref>) we display an example decoding of centers along with their one-dimensional marginal distributions. We find that the centers seem to cluster somewhat along the borders of the environment, similar to experimental observations in [<xref ref-type="bibr" rid="c41">41</xref>]. Unlike the aggregate over multiple trajectories, the single-trajectory decoding does not reveal an equally pronounced hexagonal arrangement.</p>
<p>Besides exhibiting a striking hexagonal arrangement within an environment, we also observe that there is no apparent pattern to the transformation between environments. This once again supports the finding that units undergo global-type remapping between environments (see <xref rid="fig7" ref-type="fig">Fig. 7c-d</xref>)) where color coding is relative to position in environment along diagonal).</p>
<p>To investigate whether fields in biological place cells display center clustering similar to our model, we decoded the field centers of 225 CA1 place cells (data provided by [<xref ref-type="bibr" rid="c38">38</xref>]), see Ripley’s H &amp; Clustering for details. <xref rid="fig7" ref-type="fig">Figure 7e</xref>) shows the distribution of place field centers, and a corresponding kernel density estimate. We can see that field centers cluster near boundaries. Moreover, there appears to be a tendency for the clusters to arrange in a hexagonal fashion, similar to our computational findings.</p>
<p>To further quantify the regularity in the spatial arrangement of field centers we considered Ripley’s H function. <xref rid="fig7" ref-type="fig">Figure 7f</xref>) shows Ripley’s H for the field centers, as well as a random baseline sampled on a 15<italic>×</italic>15 grid matching the experimental ratemap resolution. We find that Ripley’s H is larger for the experimental data than for the random uniform samples. This indicates that the place field centers cluster more than expected (outside two standard deviations) for uniform sampling. The clustering is stronger at small distances and intermediate ones (0-5 cm and around 7-12 cm). We also observed similar clustering for other animals, but none exhibited a similarly pronounced spatial arrangement in the kernel density estimate (see Experimental Phase Distributions for more).</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Discussion &amp; Conclusion</title>
<p>In this work, we have proposed a neural network model that forms place-like spatial representations by decoding learned cognitive maps. Remarkably, the trained network exhibits a range of behaviors previously reserved for biological place cells, including global remapping across environments and field deformation during geometric manipulations of familiar arenas. Besides reproducing existing place cell experiments, our model makes some surprising predictions.</p>
<p>Our first prediction is that border-type input is sufficient to explain not only place field formation, but also place cell global remapping. While a strong relationship between border cells and place cells has been argued previously [<xref ref-type="bibr" rid="c9">9</xref>], [<xref ref-type="bibr" rid="c28">28</xref>], possible influences on Hippocampal remapping remain relatively unexplored. In our model, we find that place cell remapping arises as a result of sparse input from independent cell assemblies, enacted through strong boundary cell rate changes. Current experimental evidence suggests that border cells largely maintain their firing rate during conditions that elicit place cell remapping [<xref ref-type="bibr" rid="c12">12</xref>], [<xref ref-type="bibr" rid="c13">13</xref>]. However, we find that the border code is highly sparse, and so only a small number of such rate-remapping, boundary-type cells would actually be required. Thus, investigating whether border cells <italic>can</italic> display rate changes could be an interesting avenue for future research.</p>
<p>While it could be that border cells in the brain do not (rate) remap, a border-to-place model could still be viable through alternate pathways, such as via gating mechanisms. In this case, a boundary signal projected onto downstream place cells could be gated by contextual signals originating from the lateral Entorhinal Cortex (lEC). Jeffery demonstrated that a gated grid cell input signal could give rise to biologically plausible, place-like spatial signals [<xref ref-type="bibr" rid="c5">5</xref>]. In a similar way, gated boundary input could conceivably account for not only place field formation and boundary-selectivity, but also remapping.</p>
<p>Given the range of place cell behaviors our model reproduces, we hold that the border-to-place model it learns should be taken seriously. However, it is worth noting that there are still place behaviors unaccounted for in our work. For instance, we do not observe field doubling when walls are inserted in familiar environments (results not shown), as observed in vivo [<xref ref-type="bibr" rid="c9">9</xref>]. However, it is reasonable to suspect that this is due to the lack of sensory information available to the network, as there is no way for the network to detect novel walls. Therefore, adding boundary-selective sensory input to our network could conceivable uncover even more place cells behavior. This is also supported by the fact that Uria <italic>et al</italic>. observed field doubling in the responses of their model, which utilizes visual input. Thus, adding other sensory modalities may be a fruitful extension of the current model.</p>
<p>A related missing feature, is the lack of multiple firing fields as expressed by biological place cells, particularly in large recording environments [<xref ref-type="bibr" rid="c3">3</xref>]. While our network does exhibit more firing fields when familiar contexts are expanded, place cells can reliably exhibit multiple fields, likely as part of a coding strategy. In contrast, our decoding operation only extracts a single center location, which may limit the expressivity of the network. Future work could therefore consider alternative decoding approaches that place even less strict requirements on learned representations.</p>
<p>Our second surprising finding is the model’s conspicuous lack of grid cells. As already mentioned, grid cells have been proposed as a possible precursor to place cells [<xref ref-type="bibr" rid="c5">5</xref>], [<xref ref-type="bibr" rid="c23">23</xref>], [<xref ref-type="bibr" rid="c24">24</xref>]. Grid cells are also often posited as being important for path integration [<xref ref-type="bibr" rid="c11">11</xref>], [<xref ref-type="bibr" rid="c42">42</xref>], [<xref ref-type="bibr" rid="c43">43</xref>]. Accurate path integration is especially important in the absence of location-specific cues such as landmarks. The only pieces of information available to our model is a velocity signal, an environment-identifying context signal, and a weak, implicit boundary signal (since trajectories cannot exit environment boundaries). As such, there is no explicit sensory information, and path integration is required to solve the position reconstruction task. If grid cells are optimized chiefly for path integration, one would expect that the model learned grid-like solutions. As our model only learns border-type recurrent representations, our findings raise question concerning the necessity of grid cells for path integration, as well as the causal relationship between place cells and grid cells. That grid cells may not be required to do path integration has also been shown in other recent normative models [<xref ref-type="bibr" rid="c36">36</xref>].</p>
<p>While the lack of grid cells in this model is interesting, it does not disqualify grid cells from serving as a neural substrate for path integration. Rather, it suggests that path integration may also be performed by other, non-grid spatial cells, and/or that grid cells may serve additional computational purposes. If grid cells are involved during path integration, our findings indicate that additional tasks and constraints are necessary for learning such representations. This possibility has been explored in recent normative models, in which several constraints have been proposed for learning grid-like solutions. Examples include constraints concerning population vector magnitude, conformal isometry [<xref ref-type="bibr" rid="c32">32</xref>], [<xref ref-type="bibr" rid="c34">34</xref>], [<xref ref-type="bibr" rid="c44">44</xref>], capacity, spatial separation and path invariance [<xref ref-type="bibr" rid="c34">34</xref>]. That our model performs path integration without grid cells, and that a myriad of independent constraints are sufficient for grid-like units to emerge in other models, presents strong computational evidence that grid cells are not solely defined by path integration, and that path integration is not only reserved for grid cells.</p>
<p>Besides functional constraints, an important consideration when building neural network models is their architecture. In our model, information primarily flows from recurrently connected, mECtype units, to CA1-type units by feedforward projections. However, CA1 responses also feed back to the Entorhinal Cortex, via the Subiculum [<xref ref-type="bibr" rid="c40">40</xref>]. Such a loop structure is explored in [<xref ref-type="bibr" rid="c27">27</xref>], which also makes use of nongrid spatial cells to inform place field formation, similar to our findings. Incorporating a feedback pathway (from output units to recurrent units) could allow for exploring the connection between grid cells, place cells and remapping.</p>
<p>While our model does not produce grid-like <italic>representations</italic>, we do observe a striking, grid-like structure in the arrangement of output unit centers. Notably, these centers arrange hexagonally in arenas with open interiors, such as the large square. While a hexagonal placement of field centers has yet to be uncovered experimentally, Whittington <italic>et al</italic>. showed that place cell phases are correlated with grid cell peak locations across environments [<xref ref-type="bibr" rid="c22">22</xref>]. Because the network has learned this particular arrangement to optimize position reconstruction, a hexagonal phase pattern may be optimal for decoding one’s position, even in diverse geometries. This is also supported by the fact that we observe clustering in the center locations of CA1 place fields in mice data obtained in [<xref ref-type="bibr" rid="c38">38</xref>]. While all the animals we analyzed seem to have clustering around the edges, those with dense exploration in the middle of the environment seems to show clustering in the middle as well. In the future, larger recordings and in different animals could help solidify whether place field center clustering is a robust and ubiquitous phenomenon.</p>
<p>A hexagonal place field arrangement also suggests a possible connection between boundary, place, and grid cells. Boundary-tuned cells could inform place cell pattern formation, which in turn guides grid cell patterns. Such a border-to-place-to-grid cell model could explain grid cell behavior in non-standard or changing environments. For example, grid cells can exhibit (temporary) pattern elongation in novel environments [<xref ref-type="bibr" rid="c45">45</xref>]. This grid elongation could be induced by field elongation in place cells, which in turn is caused by boundary field continuation. Besides temporary rescaling, grid patterns are also permanently influenced by environment geometry [<xref ref-type="bibr" rid="c46">46</xref>], hinting that grid cells receive boundary-dependent input. Furthermore, it has been suggested that border cells serve an error-correcting function for grid cells during navigation [<xref ref-type="bibr" rid="c47">47</xref>]. In a boundary-to-place-to-grid model, grid error correction could arise from place-cell inputs informed by boundary responses, or from border cells directly.</p>
<p>In summary, our proposed model, with its notion of a spatial cognitive map and fixed decoding, allows for exploring place cell formation and remapping. In particular, we find that learned place-like representations are formed by boundary input from upstream recurrent units. Global remapping arises from sparse input from differentially activated boundary units. Our work has important implications for understanding Hippocampal remapping, place field formation, as well as the place cell-grid cell system.</p>
</sec>
<sec id="s4">
<label>4</label>
<title>Methods</title>
<sec id="s4a">
<label>Code Availability</label>
<p>Code to reproduce models, datasets and numerical experiments is available from <ext-link ext-link-type="uri" xlink:href="https://github.com/bioAI-Oslo/VPC">https://github.com/bioAI-Oslo/VPC</ext-link>.</p>
<sec id="s4a1">
<label>4.1</label>
<title>Model &amp; Objective</title>
<p>In this work, we trained a recurrent neural network to solve the proposed position reconstruction task <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref> using stochastic gradient descent. As the proposed objective function does not impose explicit constraints on the functional form or spatial arrangement of the learned representations, we trained the network in a small set of diverse geometries (see <xref rid="fig1" ref-type="fig">Fig. 1c</xref>) for an illustration). This was done to explore whether the network could learn different representations in different rooms, as a way of optimally encoding the space.</p>
<p>The recurrent network was only given velocity information as input and, therefore, had to learn to perform path integration in order to minimize the position reconstruction task. Concretely, the path integration task consisted of predicting self-position along simulated trajectories. For each trajectory, the network was initialized at a random location in the environment, without initial position information (see 4.2 for initialization details). At every time step <italic>t</italic> along a trajectory, the network received a Cartesian velocity signal <bold>v</bold><sub><italic>t</italic></sub>, mimicking biological self-motion information. Denoting a particular point along a trajectory parameterized by time as <bold>x</bold><sub><italic>t</italic></sub>, the decoded position of the network was
<disp-formula id="eqn5">
<graphic xlink:href="585049v2_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <bold>z</bold><sub><italic>t</italic></sub> is the network’s latent estimate of position at time <italic>t</italic>, formed by integration of previous positions and velocities. In our case, output states <bold>p</bold><sub><italic>t</italic></sub> are computed as rectified linear combinations of an upstream recurrent layer (see 4.2 for a description). Meanwhile,
<disp-formula id="eqn6">
<graphic xlink:href="585049v2_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
is the center location estimate for output unit <italic>i</italic>, formed using the network states during navigation.</p>
<p>Lastly, we provided the network with a constant one-hot context signal at every timestep, as a token for identifying the environment. The input at time <italic>t</italic> was therefore a concatenation of <bold>v</bold><sub><italic>t</italic></sub> and a time-independent context signal <bold>c</bold>. See <xref rid="fig1" ref-type="fig">Fig. 1d</xref>) for an illustration.</p>
</sec>
<sec id="s4a2">
<label>4.2</label>
<title>Neural Network Architecture and Training</title>
<p>In this work, we consider a one-layer vanilla recurrent neural network (RNN) featuring <italic>N</italic><sub><italic>g</italic></sub> = 500 units. These recurrent units project linearly onto an output layer consisting of <italic>N</italic><sub><italic>p</italic></sub> = 100 units. Both recurrent and output units were equipped with ReLU activation functions and no added bias.</p>
<p>At time <italic>t</italic>, the hidden state of the recurrent layer was given by
<disp-formula id="eqn7">
<graphic xlink:href="585049v2_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="585049v2_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is a matrix of recurrent weights, and <inline-formula><inline-graphic xlink:href="585049v2_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> a matrix of input weights, with <bold>u</bold><sub><italic>t</italic></sub> being the input at time <italic>t</italic>, and <italic>N</italic><sub><italic>I</italic></sub> the dimensionality of the input signal. The input consisted of a concatenation of a velocity signal and a six-entry, one-hot context signal, i.e. <bold>u</bold><sub><italic>t</italic></sub> = cat(<bold>v</bold><sub><italic>t</italic></sub>, <bold>c</bold>). Subsequently, output states were computed according to
<disp-formula id="ueqn1">
<graphic xlink:href="585049v2_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="585049v2_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is a weight matrix.</p>
<p>Feedforward weights were all initialized according to a uniform distribution 𝒰(<italic>−k</italic><sub><italic>i</italic></sub>, <italic>k</italic><sub><italic>i</italic></sub>), where <inline-formula><inline-graphic xlink:href="585049v2_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> with <italic>N</italic><sub><italic>i</italic></sub> being the number of inputs to that layer. For the recurrent layer, the RNN weight matrix was initialized to the identity. This was done to mitigate vanishing/exploding gradients caused by the long sequence lengths used for training, as suggested by Le <italic>et al</italic>. [<xref ref-type="bibr" rid="c48">48</xref>].</p>
<p>To explore network dynamics when transitioning between different environments, we trained the recurrent network in a <italic>stateful</italic> fashion. This involved maintaining the recurrent state from the end of one trajectory, and using it as the initial state along a new trajectory. For each transition, the new environment and the starting location within that environment were sampled randomly (and uniformly). The network state is initially set to all-zero, providing no positional information at the start of any trajectory. While the network state was carried between different environments, gradient calculations were truncated at the end of each episode. To ensure stability, the network state was reset every ten trajectories, to an all-zero initial state.</p>
<p>Because the network is not provided with initial position information (all-zero initial state), the network has to infer its location within an environment (the identity of which is known due to the context-input) based on its geometry, e.g. through border interactions. This requires a large sample (long trajectory) of the geometry. The recurrent network was therefore trained on trajectories of sequence length <italic>T</italic> = 500. The minibatch size used for gradient descent was 64. Because of statefulness, the network therefore experienced effective sequences of 5000 timesteps during training. However, no gradient information was carried between subsequent trajectories.</p>
<p>For implementing models, we used the PyTorch python library [<xref ref-type="bibr" rid="c49">49</xref>]. We used the Adam optimizer [<xref ref-type="bibr" rid="c50">50</xref>] for training, with a learning rate of 10<sup><italic>−</italic>4</sup> and otherwise default parameters [<xref ref-type="bibr" rid="c49">49</xref>]. The network was trained for a total of 100 epochs using the training dataset detailed in 4.3. To regularize the network, we applied an L1 penalty to the recurrent network states, i.e. <bold>g</bold>. The associated L1 hyperparameter <italic>λ</italic> was set to 10.</p>
</sec>
<sec id="s4a3">
<label>4.3</label>
<title>Trajectory Simulation and Datasets</title>
<p>Networks were trained using simulated datasets of trajectories traversing 2D geometries. The starting location of a trajectory was sampled randomly and uniformly within an environment. To sample points uniformly from non-square geometries, a rejection sampling strategy was used: First, points were sampled according to a uniform distribution, whose support was given by the smallest rectangle that completely covered the given geometry. Then, ray casting was done to determine whether points were in the interior of the geometry. Concretely, a horizontal ray was cast from a given point and the number of intersections with the enclosure walls was determined. If the number of intersections was odd, the point was accepted as being inside the environment. If the number of intersections was even, the point was resampled. This procedure was iterated until the desired number of samples was obtained. Note that the interior determination method only works for extended objects, such as holes. Therefore, to add thin environment boundaries (infinitely thin walls), we simply superimposed two boundaries with no spatial separation.</p>
<p>To approximate the semi-smooth motions of foraging rodents, trajectory steps were generated by drawing step sizes according to a Rayleigh distribution with <italic>σ</italic> = 0.5, and heading direction from a von Mises distribution centered at the previous heading with scale parameter <italic>κ</italic> = 4. To ensure that the random walk remained within the geometry, we checked whether a proposed step intersected with any of the environment walls. If an intersection was detected, the heading direction was resampled until an allowed step was achieved. This procedure was iterated until the desired amount of timesteps was achieved. Note that step sizes were not resampled. This procedure yields smooth trajectories, with inherent turning away from boundaries. Trajectory positions were generated using a forward Euler integration scheme, with timestep d<italic>t</italic> = 0.1.</p>
<p>For computational efficiency, the network was trained and evaluated on precomputed datasets of trajectories. The full dataset contained 15000 trajectories, each of which was 500 timesteps long. Of these, 80 % was reserved for training, and the remaining 20 % for validation. In both datasets, an equal number of samples were included for every environment. All analyses were conducted using newly generated test trajectories.</p>
</sec>
<sec id="s4a4">
<label>4.4</label>
<title>Contexts and Geometries</title>
<p>To explore the possibility of the model learning to remap, we trained networks in multiple distinct environments, each labeled by a unique, one-hot context vector. The included geometries were square, circular and rectangular. In addition, we also included a large square, a square with a thin, central dividing wall, and finally, a square with a central hole. Each geometry and associated context signal is illustrated in <xref rid="fig1" ref-type="fig">Fig. 1c</xref>).</p>
</sec>
<sec id="s4a5">
<label>4.5</label>
<title>Numerical Experiments</title>
<sec id="s4a5a">
<label>4.5.1</label>
<title>Remapping Experiments</title>
<p>We conducted two remapping experiments to study whether the behavior of the trained neural networks aligned with those observed experimentally in rodents. The first consisted of running the trained network (with frozen weights) in multiple familiar geometries, similar to canonical remapping experiments [<xref ref-type="bibr" rid="c4">4</xref>], [<xref ref-type="bibr" rid="c16">16</xref>]. Referring to <xref rid="fig3" ref-type="fig">Fig. 3a</xref>) we ran the trained recurrent network along 25000-timestep sequences, that initially visited the square environment. Then, the network was transferred to the square with a central wall, before being returned to the square environment. For each trajectory, the starting position was sampled randomly within the geometry, and the state of the network was maintained between environments. The initial state of the network in the first environment was set to the zero vector.</p>
<p>The second set of experiments was designed to explore the consequences of geometric manipulations of familiar environments on the learned spatial representations. To do so, we ran the trained network (with fixed weights) in elongated versions of the familiar environments, similar to the experimental setup in O’Keefe <italic>et al</italic>. [<xref ref-type="bibr" rid="c8">8</xref>].</p>
<p>The first of these trials involved running the trained RNN in the square environment, with the appropriate context. However, during inference the environment walls were elongated by factors of 2 and 3 compared to their original length. For reference, <xref rid="fig4" ref-type="fig">Fig. 4a</xref>) illustrates the environment rescaling protocol.</p>
<p>The second trial concerned the effects of extending a familiar environment to previously unseen locations. Concretely, this experiment entailed transforming the environment with a central hole, into a square environment, while retaining the original context signal. In other words, the four walls of the central hole were removed, allowing movement in previously inaccessible parts of the arena.The third trial featured rescaling of the square environment into a larger square, i.e. proportional scaling in both horizontal and vertical directions while maintaining the context cue of the square environment. Again, wall lengths were scaled by factors of 2 and 3. The final geometric manipulation involved expanding the circular environment uniformly, again by factors of 2 and 3, respectively.</p>
</sec>
</sec>
<sec id="s4a6">
<label>4.6</label>
<title>Attractor Dynamics and Noise Injection</title>
<p>To investigate whether the learned representations exhibited attractor-like behavior, we performed a noise-injection experiment. The experiment consisted of evaluating the trained RNN on 1000, 800-timestep trajectories within the square environment. At the midpoint of the trajectory Gaussian noise was injected into the recurrent state. This perturbed state was subsequently rectified, before the network was run normally for the remainder of the trajectory. We performed the same experiment for multiple noise levels <italic>σ</italic> ={ 0.0, 0.01, 0.1, 1 }, where <italic>σ</italic> determines the scale of the normal distribution used for noise generation. The state of the RNN directly after noise injection could therefore be described as
<disp-formula id="ueqn2">
<graphic xlink:href="585049v2_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <bold><italic>χ</italic></bold> is a vector of random variables, drawn from a multivariate normal distribution. <italic>τ</italic> denotes the time of noise injection, taken to be timestep 400, while [·]<sub>+</sub> is a rectification operation.</p>
<p>To assess whether the representation was stable, and whether the state of the network was attractive, we computed ratemap population vector correlations (see 5 for details) between every timepoint in the sequence for each noise level.</p>
</sec>
<sec id="s4a7">
<label>4.7</label>
<title>Low Dimensional Representations and Explainability</title>
<p>To better understand the behavior of the recurrent network, we performed PCA, alongside dimensionality reduction using UMAP [<xref ref-type="bibr" rid="c51">51</xref>]. PCA was done on the recurrent and output states of the network as it was run on long (10000 timesteps in each environment) trajectories that visited every environment sequentially. For each environment transition, the state of the network was maintained. PCA was performed for each environment separately, as well as for the full trajectory visiting every environment. As an example, for a trajectory of length <italic>T</italic>, the output activity <inline-formula><inline-graphic xlink:href="585049v2_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula> was projected to a a low-dimensional representation<inline-formula><inline-graphic xlink:href="585049v2_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, with <italic>n</italic><sub><italic>pca</italic></sub> being the number of principal components.</p>
<p>The dimensionality reduction consisted of performing UMAP [<xref ref-type="bibr" rid="c51">51</xref>] on the states of the network along the full trajectory. This was done to explore whether network activity resided on a low-dimensional manifold. Population activity at each timepoint was subsequently projected down to three dimensions, yielding a dimensionality-reduced vector representing the full network activity at a particular point along the trajectory.</p>
<p>To further explore the dynamics of the network, we computed the eigenvalue spectrum of the recurrent weight matrix. Finally, we computed Pearson correlation coefficients between columns of the input weight matrix corresponding to different context signals.</p>
</sec>
</sec></sec>
<sec id="s5">
<label>5</label>
<title>Analyses</title>
<p>To compare the representational similarity of the network output across environments and time, we performed several analyses using unit ratemaps.</p>
<sec id="s5a">
<label>5.1</label>
<title>Ratemaps</title>
<p>Ratemaps of unit activity were computed by discretizing environments into bins. The rate was then determined by dividing unit activity by the number of visitations to that bin along a single trajectory. Unless otherwise specified, ratemaps were formed using 25000-timestep trajectories. For long-sequence experiments, a burn-in period of 500 initial timesteps was excluded from ratemap creation. This was done to only include the steady-state behavior of the network. For the remapping dynamics in <xref rid="fig3" ref-type="fig">Fig. 3e</xref>), ratemaps were created by aggregating responses over 500 distinct, 800-timestep trajectories.</p>
</sec>
<sec id="s5b">
<label>5.2</label>
<title>Spatial Correlation</title>
<p>Following [<xref ref-type="bibr" rid="c16">16</xref>], we computed unitwise ratemap spatial correlations to investigate possible remapping behavior. For a single unit, the spatial correlation was calculated by computing the Pearson correlation coefficient between flattened unit ratemaps. We considered the correlations between the square environment, and the square with a central wall, due to their geometric similarity. In other words, the ratemap of a unit in the square environment was correlated with its ratemap in the square with a central wall environment. This procedure was repeated for all units that were active (exhibited nonzero activity) in both environments, and a distribution of spatial correlations was formed. As a baseline, a shuffled distribution was computed by correlating every active unit with every other active unit, across environments. Finally, correlations were computed for relative ratemap rotations of 0, 90, 180 and 270 degrees, and the maximimal correlation reported. This was done to account for the possibility that remapping consisted of a rigid rotation in space.</p>
</sec>
<sec id="s5c">
<label>5.3</label>
<title>Ratemap Population Vector Correlation</title>
<p>To compare the representational similarity of entire unit populations at different timepoints (as in <xref rid="fig5" ref-type="fig">Fig. 5</xref>), we computed the Pearson correlation between ratemap population vectors at different times. A ratemap population vector was constructed by stacking the flattened ratemaps of every unit into a single array of dimension <italic>N</italic><sub><italic>units</italic></sub> <italic>· N</italic><sub><italic>x</italic></sub> <italic>· N</italic><sub><italic>y</italic></sub> with <italic>N</italic><sub><italic>units</italic></sub> being the number of units in the relevant layer, and <italic>N</italic><sub><italic>x</italic></sub> = <italic>N</italic><sub><italic>y</italic></sub> = 16 is the number of bins along the canonical <italic>x, y</italic> directions. Using Astropy [<xref ref-type="bibr" rid="c52">52</xref>], Gaussian smoothing with NaN interpolation was used to fill in unvisited regions. The smoothing kernel standard deviation was one pixel.</p>
<p>For the experiment featuring transfers between different environments (<xref rid="fig3" ref-type="fig">Fig. 3e</xref>)), only units with nonzero activity in one or more environments were included in the population vector.</p>
</sec>
<sec id="s5d">
<label>5.4</label>
<title>Rate Overlap &amp; Difference</title>
<p>As a measure of rate changes between conditions, we computed the rate overlap [<xref ref-type="bibr" rid="c4">4</xref>], and rate difference. Considering two conditions (e.g. comparing across two environments), rate overlap was computed by dividing the mean activity in the least active condition by that in the most active. Only units that were active in at least one condition were included in the analysis.</p>
<p>The rate difference was computed by simply subtracting the activity in one condition by that in another, and dividing by the sum of activity in both conditions. This measure is similar to the rate difference used in [<xref ref-type="bibr" rid="c6">6</xref>], but maintains the sign of the difference. As with the rate overlap, only units that were active in at least one condition were included.</p>
<p>For both the overlap and difference, a shuffled distribution was formed by randomly pairing units across conditions. For both quantities, pairings were performed 1000 times.</p>
</sec>
<sec id="s5e">
<label>5.5</label>
<title>Spatial Information</title>
<p>To select the most place-like units for the phase distribution visualization, we computed the spatial information content [<xref ref-type="bibr" rid="c53">53</xref>] of all units. Using unit ratemaps of <italic>M</italic> bins, the spatial information of a single unit was computed as
<disp-formula id="ueqn3">
<graphic xlink:href="585049v2_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>p</italic><sub><italic>i</italic></sub> is the occupancy of bin <italic>i, f</italic><sub><italic>i</italic></sub> the firing rate in that bin, while <inline-formula><inline-graphic xlink:href="585049v2_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the unit’s average firing rate over all bins. High spatial information units were subsequently selected as those whose spatial information were above the 2.5th percentile in all environments.</p>
</sec>
<sec id="s5f">
<label>5.6</label>
<title>Ripley’s H &amp; Clustering</title>
<p>To asses whether biological place fields exhibit non-uniform clustering, we computed Ripley’s H statistic [<xref ref-type="bibr" rid="c54">54</xref>] for the center locations of real place cells [<xref ref-type="bibr" rid="c38">38</xref>].</p>
<p>For a set of <italic>N</italic> points, we computed Ripley’s H in two steps: First, we determined Ripley’s K, which counts the average number of points within a distance <italic>R</italic> of a point, given by
<disp-formula id="ueqn4">
<graphic xlink:href="585049v2_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <bold>x</bold> and <bold>y</bold> are distinct points, |Ω| is the area of the domain Ω encompassing the set of points, while <bold>1</bold> is the indicator function. <italic>f</italic> (<bold>x, y</bold>) is a boundary correction factor, to account for a lack of observations outside the region Ω. We followed Lagache <italic>et al</italic>. and take
<disp-formula id="ueqn5">
<graphic xlink:href="585049v2_ueqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
with
<disp-formula id="ueqn6">
<graphic xlink:href="585049v2_ueqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>∂b</italic>(<bold>x</bold>, | <bold>x</bold><italic>−</italic> <bold>y</bold>|) is the circumference of a ball centered at <bold>x</bold> of radius |<bold>x</bold><italic>−</italic><bold>y</bold>|, and the denominator the circumference of the part of the ball that is inside the geometry. We used the Shapely Python library [<xref ref-type="bibr" rid="c55">55</xref>] for computing intersections between balls and the enclosing geometry.</p>
<p>The second step was to normalize and center Ripley’s K, obtaining Ripley’s H, given by
<disp-formula id="ueqn7">
<graphic xlink:href="585049v2_ueqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
For our analysis, we computed Ripley’s H for center locations of place cells in mice traversing a 75<italic>×</italic>75 cm square environment [<xref ref-type="bibr" rid="c38">38</xref>] over four distinct recording days. Centers, in this case, were decoded as the maximum firing location in 15<italic>×</italic>15 smoothed ratemaps. A total of 225 cells were included, corresponding to cells with spatial information above the 70th percentile. For each cell, the ratemap corresponding to the recording day with largest spatial information was selected.</p>
<p>As a baseline, Ripley’s H was computed for 100 sets of 225 points, sampled randomly and uniformly on a 15<italic>×</italic>15 square grid, matching the spatial discretization of the ratemaps used. For both baseline and real data, ball radii were varied from <italic>ε</italic> = 10<sup><italic>−</italic>8</sup> to approximately 26.5 cm, corresponding to a quarter of the square’s diagonal.</p>
<p>To visualize possible clustering of place fields, we computed Gaussian kernel density estimates of decoded field centers. This procedure was repeated for all animals, and only centers of cells with spatial information above the 70th percentile were included. For all kernel density estimates, the bandwidth parameter was set to 0.2, and kernels were evaluated on 64<italic>×</italic>64 grids. See [<xref ref-type="bibr" rid="c38">38</xref>] for details on ratemap creation and experiments.</p>
</sec>
</sec>
</body>
<back>
<ack>
<label>6</label>
<title>Acknowledgements</title>
<p>We would like to thank J. Quinn Lee and Mark Brandon of McGill University as well as their co-authors, for graciously sharing their data with us. We hope others follow their example of open and helpful collaboration.</p>
</ack>
<sec id="s10">
<label>7</label>
<title>Author Contributions</title>
<p>MBP conceived the original model, did simulations and wrote the article. VSS developed the model, did simulations and wrote the article. AMS developed the model and wrote the article. MEL developed the model, supervised the process, and wrote the article.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name> and <string-name><given-names>J.</given-names> <surname>Dostrovsky</surname></string-name>, “<article-title>The Hippocampus as a Spatial Map. Preliminary Evidence from Unit Activity in the Freely-Moving Rat</article-title>,” <source>Brain Research</source>, vol. <volume>34</volume>, no. <issue>1</issue>, pp. <fpage>171</fpage>–<lpage>175</lpage>, <month>Nov</month>. <year>1971</year>, ISSN: <issn>00068993</issn>. doi: <pub-id pub-id-type="doi">10.1016/0006-8993(71)90358-1</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/0006899371903581">https://linkinghub.elsevier.com/retrieve/pii/0006899371903581</ext-link> (visited on 02/03/2022).</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>, “<article-title>Place units in the hippocampus of the freely moving rat</article-title>,” en, <source>Experimental Neurology</source>, vol. <volume>51</volume>, no. <issue>1</issue>, pp. <fpage>78</fpage>–<lpage>109</lpage>, <month>Jan</month>. <year>1976</year>, ISSN: <issn>00144886</issn>. doi: <pub-id pub-id-type="doi">10.1016/0014-4886(76)90055-8</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/0014488676900558">https://linkinghub.elsevier.com/retrieve/pii/0014488676900558</ext-link> (visited on 10/20/2023).</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Park</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Dvorak</surname></string-name>, and <string-name><given-names>A. A.</given-names> <surname>Fenton</surname></string-name>, “<article-title>Ensemble Place Codes in Hippocampus: CA1, CA3, and Dentate Gyrus Place Cells Have Multiple Place Fields in Large Environments</article-title>,” en, <source>PLoS ONE</source>, vol. <volume>6</volume>, no. <issue>7</issue>, <person-group person-group-type="editor"><string-name><given-names>C. T.</given-names> <surname>Dickson</surname></string-name></person-group>, Ed., <fpage>e22349</fpage>, <month>Jul</month>. <year>2011</year>, ISSN: <issn>1932-6203</issn>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0022349</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://dx.plos.org/10.1371/journal.pone.0022349">https://dx.plos.org/10.1371/journal.pone.0022349</ext-link> (visited on 10/20/2023).</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Leutgeb</surname></string-name>, <string-name><given-names>J. K.</given-names> <surname>Leutgeb</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Treves</surname></string-name>, <string-name><given-names>M.-B.</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>, “<article-title>Distinct Ensemble Codes in Hippocampal Areas CA3 and CA1</article-title>,” <source>Science</source>, vol. <volume>305</volume>, no. <issue>5688</issue>, pp. <fpage>1295</fpage>–<lpage>1298</lpage>, <month>Aug</month>. <year>2004</year>, ISSN: <issn>0036-8075</issn>, <issn>1095-9203</issn>. doi: <pub-id pub-id-type="doi">10.1126/science.1100265</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>K. J.</given-names> <surname>Jeffery</surname></string-name>, “<article-title>Place Cells, Grid Cells, Attractors, and Remapping</article-title>,” <source>Neural Plasticity</source>, vol. <volume>2011</volume>, pp. <fpage>1</fpage>–<lpage>11</lpage>, <year>2011</year>, ISSN: <issn>2090-5904</issn>, <issn>1687-5443</issn>. doi: <pub-id pub-id-type="doi">10.1155/2011/182602</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://www.hindawi.com/journals/np/2011/182602/">http://www.hindawi.com/journals/np/2011/182602/</ext-link> (visited on 01/31/2022).</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Leutgeb</surname></string-name>, <string-name><given-names>J. K.</given-names> <surname>Leutgeb</surname></string-name>, <string-name><given-names>C. A.</given-names> <surname>Barnes</surname></string-name>, <string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>, <string-name><given-names>B. L.</given-names> <surname>McNaughton</surname></string-name>, and <string-name><given-names>M.-B.</given-names> <surname>Moser</surname></string-name>, “<article-title>Independent Codes for Spatial and Episodic Memory in Hippocampal Neuronal Ensembles</article-title>,” en, <source>Science</source>, vol. <volume>309</volume>, no. <issue>5734</issue>, pp. <fpage>619</fpage>–<lpage>623</lpage>, <month>Jul</month>. <year>2005</year>, ISSN: <issn>0036-8075</issn>, <issn>1095-9203</issn>. doi: <pub-id pub-id-type="doi">10.1126/science.1114037</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.science.org/doi/10.1126/science.1114037">https://www.science.org/doi/10.1126/science.1114037</ext-link> (visited on 11/02/2023).</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>R.</given-names> <surname>Muller</surname></string-name> and <string-name><given-names>J.</given-names> <surname>Kubie</surname></string-name>, “<article-title>The effects of changes in the environment on the spatial firing of hippocampal complex-spike cells</article-title>,” en, <source>The Journal of Neuroscience</source>, vol. <volume>7</volume>, no. <issue>7</issue>, pp. <fpage>1951</fpage>–<lpage>1968</lpage>, <month>Jul</month>. <year>1987</year>, ISSN: <issn>0270-6474</issn>, <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.07-07-01951.1987</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.07-07-01951.1987">https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.07-07-01951.1987</ext-link> (visited on 10/09/2023).</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name> and <string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name>, “<article-title>Geometric Determinants of the Place Fields of Hippocampal Neurons</article-title>,” <source>Nature</source>, vol. <volume>381</volume>, no. <issue>6581</issue>, pp. <fpage>425</fpage>–<lpage>428</lpage>, <month>May</month> <year>1996</year>, ISSN: <issn>0028-0836</issn>, <issn>1476-4687</issn>. doi: <pub-id pub-id-type="doi">10.1038/381425a0</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/articles/381425a0">http://www.nature.com/articles/381425a0</ext-link> (visited on 04/29/2022).</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Lever</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Hayman</surname></string-name>, <etal>et al.</etal>, “<article-title>The Boundary Vector Cell Model of Place Cell Firing and Spatial Memory</article-title>,” <source>Reviews in the Neurosciences</source>, vol. <volume>17</volume>, no. <issue>1-2</issue>, <month>Jan</month>. <year>2006</year>, ISSN: <issn>2191-0200</issn>, <issn>0334-1763</issn>. doi: <pub-id pub-id-type="doi">10.1515/REVNEURO.2006.17.1-2.71</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.degruyter.com/document/doi/10.1515/REVNEURO.2006.17.1-2.71/html">https://www.degruyter.com/document/doi/10.1515/REVNEURO.2006.17.1-2.71/html</ext-link> (visited on 11/18/2022).</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Taube</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Muller</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Ranck</surname></string-name>, “<article-title>Head-Direction Cells Recorded from the Postsubiculum in Freely Moving Rats. I. Description and Quantitative Analysis</article-title>,” <source>The Journal of Neuroscience</source>, vol. <volume>10</volume>, no. <issue>2</issue>, pp. <fpage>420</fpage>–<lpage>435</lpage>, <month>Feb</month>. <year>1990</year>, ISSN: <issn>0270-6474</issn>, <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.10-02-00420.1990</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.10-02-00420.1990">https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.10-02-00420.1990</ext-link> (visited on 03/31/2022).</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Hafting</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Fyhn</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Molden</surname></string-name>, <string-name><given-names>M.-B.</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>, “<article-title>Microstructure of a spatial map in the entorhinal cortex</article-title>,” <source>Nature</source>, vol. <volume>436</volume>, no. <issue>7052</issue>, pp. <fpage>801</fpage>–<lpage>806</lpage>, <year>2005</year>, ISSN: <issn>0028-0836</issn>, <issn>1476-4687</issn>. doi: <pub-id pub-id-type="doi">10.1038/nature03721</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/articles/nature03721">http://www.nature.com/articles/nature03721</ext-link> (visited on 02/04/2022).</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Lever</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Burton</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Jeewajee</surname></string-name>, <string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>, and <string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name>, “<article-title>Boundary Vector Cells in the Subiculum of the Hippocampal Formation</article-title>,” en, <source>Journal of Neuroscience</source>, vol. <volume>29</volume>, no. <issue>31</issue>, pp. <fpage>9771</fpage>–<lpage>9777</lpage>, <month>Aug</month>. <year>2009</year>, ISSN: <issn>0270-6474</issn>, <issn>1529-2401</issn>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1319-09.2009</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1319-09.2009">https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1319-09.2009</ext-link> (visited on 12/08/2022).</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Solstad</surname></string-name>, <string-name><given-names>C. N.</given-names> <surname>Boccara</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Kropff</surname></string-name>, <string-name><given-names>M.-B.</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>, “<article-title>Representation of Geometric Borders in the Entorhinal Cortex</article-title>,” en, <source>Science</source>, vol. <volume>322</volume>, no. <issue>5909</issue>, pp. <fpage>1865</fpage>–<lpage>1868</lpage>, <month>Dec</month>. <year>2008</year>, ISSN: <issn>0036-8075</issn>, <issn>1095-9203</issn>. doi: <pub-id pub-id-type="doi">10.1126/science.1166466</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.science.org/doi/10.1126/science.1166466">https://www.science.org/doi/10.1126/science.1166466</ext-link> (visited on 03/28/2023).</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Krupic</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>, “<article-title>Neural Representations of Location Composed of Spatially Periodic Bands</article-title>,” en, <source>Science</source>, vol. <volume>337</volume>, no. <issue>6096</issue>, pp. <fpage>853</fpage>–<lpage>857</lpage>, <month>Aug</month>. <year>2012</year>, ISSN: <issn>0036-8075</issn>, <issn>1095-9203</issn>. doi: <pub-id pub-id-type="doi">10.1126/science.1222403</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.science.org/doi/10.1126/science.1222403">https://www.science.org/doi/10.1126/science.1222403</ext-link> (visited on 10/06/2023).</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>Ø. A.</given-names> <surname>Høydal</surname></string-name>, <string-name><given-names>E. R.</given-names> <surname>Skytøen</surname></string-name>, <string-name><given-names>S. O.</given-names> <surname>Andersson</surname></string-name>, <string-name><given-names>M.-B.</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>, “<article-title>Object-vector coding in the medial entorhinal cortex</article-title>,” en, <source>Nature</source>, vol. <volume>568</volume>, no. <issue>7752</issue>, pp. <fpage>400</fpage>–<lpage>404</lpage>, <month>Apr</month>. <year>2019</year>, ISSN: <issn>0028-0836</issn>, <issn>1476-4687</issn>. doi: <pub-id pub-id-type="doi">10.1038/s41586-019-1077-7</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41586-019-1077-7">https://www.nature.com/articles/s41586-019-1077-7</ext-link> (visited on 10/06/2023).</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Fyhn</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Hafting</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Treves</surname></string-name>, <string-name><given-names>M.-B.</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>, “<article-title>Hippocampal Remapping and Grid Realignment in Entorhinal Cortex</article-title>,” <source>Nature</source>, vol. <volume>446</volume>, no. <issue>7132</issue>, pp. <fpage>190</fpage>–<lpage>194</lpage>, <month>Mar</month>. <year>2007</year>, ISSN: <issn>0028-0836</issn>, <issn>1476-4687</issn>. doi: <pub-id pub-id-type="doi">10.1038/nature05601</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/articles/nature05601">http://www.nature.com/articles/nature05601</ext-link> (visited on 02/02/2022).</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>E. C.</given-names> <surname>Tolman</surname></string-name>, “<article-title>Cognitive maps in rats and men</article-title>.,” en, <source>Psychological Review</source>, vol. <volume>55</volume>, no. <issue>4</issue>, pp. <fpage>189</fpage>–<lpage>208</lpage>, <year>1948</year>, ISSN: <issn>1939-1471</issn>, <issn>0033-295X</issn>. doi: <pub-id pub-id-type="doi">10.1037/h0061626</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://doi.apa.org/getdoi.cfm?doi=10.1037/h0061626">http://doi.apa.org/getdoi.cfm?doi=10.1037/h0061626</ext-link> (visited on 11/04/2022).</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="book"><string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name> and <string-name><given-names>L.</given-names> <surname>Nadel</surname></string-name>, <source>The Hippocampus as a Cognitive Map</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>, <year>1978</year>, ISBN: <isbn>0-19-857206-9</isbn>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>T. E.</given-names> <surname>Behrens</surname></string-name>, <string-name><given-names>T. H.</given-names> <surname>Muller</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Whittington</surname></string-name>, <etal>et al.</etal>, “<article-title>What Is a Cognitive Map? Organizing Knowledge for Flexible Behavior</article-title>,” en, <source>Neuron</source>, vol. <volume>100</volume>, no. <issue>2</issue>, pp. <fpage>490</fpage>–<lpage>509</lpage>, <month>Oct</month>. <year>2018</year>, ISSN: <issn>08966273</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.002</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S0896627318308560">https://linkinghub.elsevier.com/retrieve/pii/S0896627318308560</ext-link> (visited on 11/24/2022).</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><given-names>R. M.</given-names> <surname>Tavares</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Mendelsohn</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Grossman</surname></string-name>, <etal>et al.</etal>, “<article-title>A Map for Social Navigation in the Human Brain</article-title>,” en, <source>Neuron</source>, vol. <volume>87</volume>, no. <issue>1</issue>, pp. <fpage>231</fpage>–<lpage>243</lpage>, <month>Jul</month>. <year>2015</year>, ISSN: <issn>08966273</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.011</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S0896627315005243">https://linkinghub.elsevier.com/retrieve/pii/S0896627315005243</ext-link> (visited on 03/11/2024).</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>Aronov</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Nevers</surname></string-name>, and <string-name><given-names>D. W.</given-names> <surname>Tank</surname></string-name>, “<article-title>Mapping of a non-spatial dimension by the hippocampal–entorhinal circuit</article-title>,” en, <source>Nature</source>, vol. <volume>543</volume>, no. <issue>7647</issue>, pp. <fpage>719</fpage>–<lpage>722</lpage>, <month>Mar</month>. <year>2017</year>, ISSN: <issn>0028-0836</issn>, <issn>1476-4687</issn>. doi: <pub-id pub-id-type="doi">10.1038/nature21692</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/nature21692">https://www.nature.com/articles/nature21692</ext-link> (visited on 03/11/2024).</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><given-names>J. C.</given-names> <surname>Whittington</surname></string-name>, <string-name><given-names>T. H.</given-names> <surname>Muller</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Mark</surname></string-name>, <etal>et al.</etal>, “<article-title>The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation</article-title>,” en, <source>Cell</source>, vol. <volume>183</volume>, no. <issue>5</issue>, <fpage>1249</fpage>–<lpage>1263.e23</lpage>, <month>Nov</month>. <year>2020</year>, ISSN: <issn>00928674</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S009286742031388X">https://linkinghub.elsevier.com/retrieve/pii/S009286742031388X</ext-link> (visited on 11/04/2022).</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Kropff</surname></string-name>, and <string-name><given-names>M.-B.</given-names> <surname>Moser</surname></string-name>, “<article-title>Place Cells, Grid Cells, and the Brain’s Spatial Representation System</article-title>,” en, <source>Annual Review of Neuroscience</source>, vol. <volume>31</volume>, no. <issue>1</issue>, pp. <fpage>69</fpage>–<lpage>89</lpage>, <month>Jul</month>. <year>2008</year>, ISSN: <issn>0147-006X</issn>, <issn>1545-4126</issn>. doi: <pub-id pub-id-type="doi">10.1146/annurev.neuro.31.061307.090723</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.annualreviews.org/doi/10.1146/annurev.neuro.31.061307.090723">https://www.annualreviews.org/doi/10.1146/annurev.neuro.31.061307.090723</ext-link> (visited on 02/21/2024).</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Solstad</surname></string-name>, <string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>G. T.</given-names> <surname>Einevoll</surname></string-name>, “<article-title>From Grid Cells to Place Cells: A Mathematical Model</article-title>,” <source>Hippocampus</source>, vol. <volume>16</volume>, no. <issue>12</issue>, pp. <fpage>1026</fpage>–<lpage>1031</lpage>, <month>Dec</month>. <year>2006</year>, ISSN: <issn>10509631</issn>, <issn>10981063</issn>. doi: <pub-id pub-id-type="doi">10.1002/hipo.20244</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://onlinelibrary.wiley.com/doi/10.1002/hipo.20244">https://onlinelibrary.wiley.com/doi/10.1002/hipo.20244</ext-link> (visited on 02/14/2022).</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><given-names>R. F.</given-names> <surname>Langston</surname></string-name>, <string-name><given-names>J. A.</given-names> <surname>Ainge</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Couey</surname></string-name>, <etal>et al.</etal>, “<article-title>Development of the Spatial Representation System in the Rat</article-title>,” <source>Science</source>, vol. <volume>328</volume>, no. <issue>5985</issue>, pp. <fpage>1576</fpage>–<lpage>1580</lpage>, <month>Jun</month>. <year>2010</year>, ISSN: <issn>0036-8075</issn>, <issn>1095-9203</issn>. doi: <pub-id pub-id-type="doi">10.1126/science.1188210</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.science.org/doi/10.1126/science.1188210">https://www.science.org/doi/10.1126/science.1188210</ext-link> (visited on 05/19/2022).</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><given-names>T. J.</given-names> <surname>Wills</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Cacucci</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>, “<article-title>Development of the Hippocampal Cognitive Map in Preweanling Rats</article-title>,” <source>Science</source>, vol. <volume>328</volume>, no. <issue>5985</issue>, pp. <fpage>1573</fpage>–<lpage>1576</lpage>, <month>Jun</month>. <year>2010</year>, ISSN: <issn>0036-8075</issn>, <issn>1095-9203</issn>. doi: <pub-id pub-id-type="doi">10.1126/science.1188224</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.science.org/doi/10.1126/science.1188224">https://www.science.org/doi/10.1126/science.1188224</ext-link> (visited on 02/01/2022).</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="web"><string-name><given-names>G.</given-names> <surname>Morris</surname></string-name> and <string-name><given-names>D.</given-names> <surname>Derdikman</surname></string-name>, “<article-title>The Chicken and Egg Problem of Grid Cells and Place Cells</article-title>,” <source>Trends in Cognitive Sciences, S1364661322002832</source>, <month>Nov</month>. <year>2022</year>, ISSN: <issn>13646613</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.tics.2022.11.003</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S1364661322002832">https://linkinghub.elsevier.com/retrieve/pii/S1364661322002832</ext-link> (visited on 12/02/2022).</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Hartley</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Lever</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Cacucci</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>, “<article-title>Modeling place fields in terms of the cortical inputs to the hippocampus</article-title>,” en, <source>Hippocampus</source>, vol. <volume>10</volume>, no. <issue>4</issue>, pp. <fpage>369</fpage>–<lpage>379</lpage>, <year>2000</year>, ISSN: <issn>1050-9631</issn>, <issn>1098-1063</issn>. doi: <pub-id pub-id-type="doi">10.1002/1098-1063(2000)10:4&lt;369::AID-HIPO3&gt;3.0.CO;2-0</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://onlinelibrary.wiley.com/doi/10.1002/1098-1063(2000)10:4%3C369::AID-HIPO3%3E3.0.CO;2-0">https://onlinelibrary.wiley.com/doi/10.1002/1098-1063(2000)10:4%3C369::AID-HIPO3%3E3.0.CO;2-0</ext-link> (visited on 03/04/2024).</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="web"><string-name><given-names>C. J.</given-names> <surname>Cueva</surname></string-name> and <string-name><given-names>X.-X.</given-names> <surname>Wei</surname></string-name>, “<source>Emergence of Grid-like Representations by Training Recurrent Neural Networks to Perform Spatial Localization</source>,” <pub-id pub-id-type="arxiv">1803.07770</pub-id>, <month>Mar</month>. <year>2018</year>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1803.07770">http://arxiv.org/abs/1803.07770</ext-link> (visited on 04/21/2022).</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Banino</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Uria</surname></string-name>, <etal>et al.</etal>, “<article-title>Vector-Based Navigation Using Grid-like Representations in Artificial Agents</article-title>,” <source>Nature</source>, vol. <volume>557</volume>, no. <issue>7705</issue>, pp. <fpage>429</fpage>–<lpage>433</lpage>, <month>May</month> <year>2018</year>, ISSN: <issn>0028-0836</issn>, <issn>1476-4687</issn>. doi: <pub-id pub-id-type="doi">10.1038/s41586-018-0102-6</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/articles/s41586-018-0102-6">http://www.nature.com/articles/s41586-018-0102-6</ext-link> (visited on 02/04/2022).</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="web"><string-name><given-names>B.</given-names> <surname>Sorscher</surname></string-name>, <string-name><given-names>G. C.</given-names> <surname>Mel</surname></string-name>, <string-name><given-names>S. A.</given-names> <surname>Ocko</surname></string-name>, <string-name><given-names>L. M.</given-names> <surname>Giocomo</surname></string-name>, and <string-name><given-names>S.</given-names> <surname>Ganguli</surname></string-name>, “<article-title>A unified theory for the computational and mechanistic origins of grid cells</article-title>,” en, <source>Neuron</source>, S0896627322009072, <month>Oct</month>. <year>2022</year>, ISSN: <issn>08966273</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2022.10.003</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S0896627322009072">https://linkinghub.elsevier.com/retrieve/pii/S0896627322009072</ext-link> (visited on 12/13/2022).</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="other"><string-name><given-names>D.</given-names> <surname>Xu</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Gao</surname></string-name>, <string-name><given-names>W.-H.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>X.-X.</given-names> <surname>Wei</surname></string-name>, and <string-name><given-names>Y. N.</given-names> <surname>Wu</surname></string-name>, <source>Conformal Isometry of Lie Group Representation in Recurrent Network of Grid Cells</source>, eprint: 2210.02684, <year>2022</year>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="web"><string-name><given-names>W.</given-names> <surname>Dorrell</surname></string-name>, <string-name><given-names>P. E.</given-names> <surname>Latham</surname></string-name>, <string-name><given-names>T. E. J.</given-names> <surname>Behrens</surname></string-name>, and <string-name><given-names>J. C. R.</given-names> <surname>Whittington</surname></string-name>, <source>Actionable Neural Representations: Grid Cells from Minimal Constraints</source>, <pub-id pub-id-type="arxiv">2209.15563</pub-id> [q-bio], <month>Sep</month>. <year>2022</year>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2209.15563">http://arxiv.org/abs/2209.15563</ext-link> (visited on 10/11/2022).</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="web"><string-name><given-names>R.</given-names> <surname>Schaeffer</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Khona</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Ma</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Eyzaguirre</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Koyejo</surname></string-name>, and <string-name><given-names>I. R.</given-names> <surname>Fiete</surname></string-name>, “<source>Self-Supervised Learning of Representations for Space Generates Multi-Modular Grid Cells</source>,” <year>2023</year>, Publisher: arXiv Version Number: 1. doi: <pub-id pub-id-type="doi">10.48550/ARXIV.2311.02316</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2311.02316">https://arxiv.org/abs/2311.02316</ext-link> (visited on 02/21/2024).</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="web"><string-name><given-names>I. I.</given-names> <surname>Low</surname></string-name>, <string-name><given-names>L. M.</given-names> <surname>Giocomo</surname></string-name>, and <string-name><given-names>A. H.</given-names> <surname>Williams</surname></string-name>, “<article-title>Remapping in a recurrent neural network model of navigation and context inference</article-title>,” <source>elife, preprint</source>, <month>Jun</month>. <year>2023</year>. doi: <pub-id pub-id-type="doi">10.7554/eLife.86943.2</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/reviewed-preprints/86943v2">https://elifesciences.org/reviewed-preprints/86943v2</ext-link> (visited on 02/29/2024).</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><string-name><given-names>V.</given-names> <surname>Schøyen</surname></string-name>, <string-name><given-names>M. B.</given-names> <surname>Pettersen</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Holzhausen</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Fyhn</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Malthe-Sørenssen</surname></string-name>, and <string-name><given-names>M. E.</given-names> <surname>Lepperød</surname></string-name>, “<article-title>Coherently remapping toroidal cells but not Grid cells are responsible for path integration in virtual agents</article-title>,” en, <source>iScience</source>, vol. <volume>26</volume>, no. <issue>11</issue>, p. <fpage>108</fpage> 102, <month>Nov</month>. <year>2023</year>, ISSN: <issn>25890042</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.isci.2023.108102</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S258900422302179X">https://linkinghub.elsevier.com/retrieve/pii/S258900422302179X</ext-link> (visited on 02/29/2024).</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="web"><string-name><given-names>B.</given-names> <surname>Uria</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Ibarz</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Banino</surname></string-name>, <etal>et al.</etal>, “<article-title>A model of egocentric to allocentric understanding in mammalian brains</article-title>,” en, <source>Neuroscience, preprint</source>, <month>Nov</month>. <year>2020</year>. doi: <pub-id pub-id-type="doi">10.1101/2020.11.11.378141</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://biorxiv.org/lookup/doi/10.1101/2020.11.11.378141">http://biorxiv.org/lookup/doi/10.1101/2020.11.11.378141</ext-link> (visited on 11/25/2022).</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="web"><string-name><given-names>J. Q.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>A. T.</given-names> <surname>Keinath</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Cianfarano</surname></string-name>, and <string-name><given-names>M. P.</given-names> <surname>Brandon</surname></string-name>, “<article-title>Identifying representational structure in CA1 to benchmark theoretical models of cognitive mapping</article-title>,” en, <source>Neuroscience, preprint</source>, <month>Oct</month>. <year>2023</year>. doi: <pub-id pub-id-type="doi">10.1101/2023.10.08.561112</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://biorxiv.org/lookup/doi/10.1101/2023.10.08.561112">http://biorxiv.org/lookup/doi/10.1101/2023.10.08.561112</ext-link> (visited on 03/20/2024).</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><given-names>Y.</given-names> <surname>Dordek</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Soudry</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Meir</surname></string-name>, and <string-name><given-names>D.</given-names> <surname>Derdikman</surname></string-name>, “<article-title>Extracting Grid Cell Characteristics from Place Cell Inputs Using Non-Negative Principal Component Analysis</article-title>,” <source>eLife</source>, vol. <volume>5</volume>, <fpage>e10094</fpage>, <month>Mar</month>. <year>2016</year>, ISSN: <issn>2050-084X</issn>. doi: <pub-id pub-id-type="doi">10.7554/eLife.10094</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/articles/10094">https://elifesciences.org/articles/10094</ext-link> (visited on 02/02/2022).</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="book"><string-name><given-names>M. P.</given-names> <surname>Witter</surname></string-name>, “<chapter-title>Connectivity of the Hippocampus</chapter-title>,” en, in <source>Hippocampal Microcircuits</source>, <person-group person-group-type="editor"><string-name><given-names>V.</given-names> <surname>Cutsuridis</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Graham</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Cobb</surname></string-name>, and <string-name><given-names>I.</given-names> <surname>Vida</surname></string-name></person-group>, Eds., <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer New York</publisher-name>, <year>2010</year>, pp. <fpage>5</fpage>–<lpage>26</lpage>, ISBN: <isbn>978-1-4419-0995-4978-1-4419-0996-1</isbn>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><given-names>B.</given-names> <surname>Harland</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Contreras</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Souder</surname></string-name>, and <string-name><given-names>J.-M.</given-names> <surname>Fellous</surname></string-name>, “<article-title>Dorsal CA1 hippocampal place cells form a multi-scale representation of megaspace</article-title>,” en, <source>Current Biology</source>, vol. <volume>31</volume>, no. <issue>10</issue>, <fpage>2178</fpage>–<lpage>2190.e6</lpage>, <month>May</month> <year>2021</year>, ISSN: <issn>09609822</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.cub.2021.03.003</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S0960982221003420">https://linkinghub.elsevier.com/retrieve/pii/S0960982221003420</ext-link> (visited on 03/08/2024).</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><string-name><given-names>Y.</given-names> <surname>Burak</surname></string-name> and <string-name><given-names>I. R.</given-names> <surname>Fiete</surname></string-name>, “<article-title>Accurate Path Integration in Continuous Attractor Network Models of Grid Cells</article-title>,” <source>PLoS Computational Biology</source>, vol. <volume>5</volume>, no. <issue>2</issue>, <person-group person-group-type="editor"><string-name><given-names>O.</given-names> <surname>Sporns</surname></string-name></person-group>, Ed., <fpage>e1000291</fpage>, <month>Feb</month>. <year>2009</year>, ISSN: <issn>1553-7358</issn>. doi: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1000291</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://dx.plos.org/10.1371/journal.pcbi.1000291">https://dx.plos.org/10.1371/journal.pcbi.1000291</ext-link> (visited on 02/02/2022).</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>Bush</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Manson</surname></string-name>, and <string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name>, “<article-title>Using Grid Cells for Navigation</article-title>,” <source>Neuron</source>, vol. <volume>87</volume>, no. <issue>3</issue>, pp. <fpage>507</fpage>–<lpage>520</lpage>, <month>Aug</month>. <year>2015</year>, ISSN: <issn>08966273</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.006</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S0896627315006285">https://linkinghub.elsevier.com/retrieve/pii/S0896627315006285</ext-link> (visited on 04/01/2022).</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="web"><string-name><given-names>V.</given-names> <surname>Schøyen</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Bechkov</surname></string-name>, <string-name><given-names>M. B.</given-names> <surname>Pettersen</surname></string-name>, <etal>et al.</etal>, “<article-title>Hexagons all the way down: Grid cells as a conformal isometric map of space</article-title>,” en, <source>Neuroscience, preprint</source>, <month>Feb</month>. <year>2024</year>. doi: <pub-id pub-id-type="doi">10.1101/2024.02.02.578585</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://biorxiv.org/lookup/doi/10.1101/2024.02.02.578585">http://biorxiv.org/lookup/doi/10.1101/2024.02.02.578585</ext-link> (visited on 02/29/2024).</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>L. L.</given-names> <surname>Ginzberg</surname></string-name>, <string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>, and <string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name>, “<article-title>Grid Cell Firing Patterns Signal Environmental Novelty by Expansion</article-title>,” <source>Proceedings of the National Academy of Sciences</source>, vol. <volume>109</volume>, no. <issue>43</issue>, pp. <fpage>17 687</fpage>–<lpage>17 692</lpage>, <month>Oct</month>. <year>2012</year>, ISSN: <issn>0027-8424</issn>, <issn>1091-6490</issn>. doi: <pub-id pub-id-type="doi">10.1073/pnas.1209918109</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://www.pnas.org/cgi/doi/10.1073/pnas.1209918109">http://www.pnas.org/cgi/doi/10.1073/pnas.1209918109</ext-link> (visited on 02/13/2022).</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Krupic</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Bauza</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Burton</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barry</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>, “<article-title>Grid Cell Symmetry Is Shaped by Environmental Geometry</article-title>,” <source>Nature</source>, vol. <volume>518</volume>, no. <issue>7538</issue>, pp. <fpage>232</fpage>–<lpage>235</lpage>, <month>Feb</month>. <year>2015</year>, Publisher: <publisher-name>Nature Publishing Group</publisher-name>, ISSN: <issn>1476-4687</issn>. doi: <pub-id pub-id-type="doi">10.1038/nature14153</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/nature14153">https://www.nature.com/articles/nature14153</ext-link> (visited on 01/31/2022).</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Hardcastle</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Ganguli</surname></string-name>, and <string-name><given-names>L. M.</given-names> <surname>Giocomo</surname></string-name>, “<article-title>Environmental Boundaries as an Error Correction Mechanism for Grid Cells</article-title>,” en, <source>Neuron</source>, vol. <volume>86</volume>, no. <issue>3</issue>, pp. <fpage>827</fpage>–<lpage>839</lpage>, <month>May</month> <year>2015</year>, ISSN: <issn>08966273</issn>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.039</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S0896627315002639">https://linkinghub.elsevier.com/retrieve/pii/S0896627315002639</ext-link> (visited on 02/21/2024).</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="web"><string-name><given-names>Q. V.</given-names> <surname>Le</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Jaitly</surname></string-name>, and <string-name><given-names>G. E.</given-names> <surname>Hinton</surname></string-name>, “<source>A Simple Way to Initialize Recurrent Networks of Rectified Linear Units</source>,” 1504.00941 [cs] Issue: <pub-id pub-id-type="arxiv">1504.00941</pub-id> Publisher: arXiv, <month>Apr</month>. <year>2015</year>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1504.00941">http://arxiv.org/abs/1504.00941</ext-link> (visited on 05/25/2022).</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="web"><string-name><given-names>A.</given-names> <surname>Paszke</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Gross</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Massa</surname></string-name>, <etal>et al.</etal>, “<source>PyTorch: An Imperative Style, High-Performance Deep Learning Library</source>,” <year>2019</year>, Publisher: arXiv Version Number: 1. doi: <pub-id pub-id-type="doi">10.48550/ARXIV.1912.01703</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1912.01703">https://arxiv.org/abs/1912.01703</ext-link> (visited on 02/21/2024).</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="web"><string-name><given-names>D. P.</given-names> <surname>Kingma</surname></string-name> and <string-name><given-names>J.</given-names> <surname>Ba</surname></string-name>, “<source>Adam: A Method for Stochastic Optimization</source>,” <pub-id pub-id-type="arxiv">1412.6980</pub-id> [cs], <month>Jan</month>. <year>2017</year>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1412.6980">http://arxiv.org/abs/1412.6980</ext-link> (visited on 05/04/2022).</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="other"><string-name><given-names>L.</given-names> <surname>McInnes</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Healy</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Melville</surname></string-name>, <source>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</source>, eprint: 1802.03426, <year>2020</year>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="web"><string-name><given-names>The Astropy</given-names> <surname>Collaboration</surname></string-name>, <string-name><given-names>A. M.</given-names> <surname>Price-Whelan</surname></string-name>, <string-name><given-names>P. L.</given-names> <surname>Lim</surname></string-name>, <etal>et al.</etal>, <source>The Astropy Project: Sustaining and Growing a Community-oriented Open-source Project and the Latest Major Release (v5.0) of the Core Package</source>, <pub-id pub-id-type="arxiv">2206.14220</pub-id> [astro-ph], <month>Jun</month>. <year>2022</year>. doi: <pub-id pub-id-type="doi">10.3847/1538-4357/ac7c74</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2206.14220">http://arxiv.org/abs/2206.14220</ext-link> (visited on 03/08/2024).</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><string-name><given-names>W.</given-names> <surname>Skaggs</surname></string-name>, <string-name><given-names>B.</given-names> <surname>McNaughton</surname></string-name>, and <string-name><given-names>K.</given-names> <surname>Gothard</surname></string-name>, “<article-title>An information-theoretic approach to deciphering the hippocampal code</article-title>,” <source>in Advances in neural information processing systems</source>, <person-group person-group-type="editor"><string-name><given-names>S.</given-names> <surname>Hanson</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Cowan</surname></string-name>, and <string-name><given-names>C.</given-names> <surname>Giles</surname></string-name></person-group>, Eds., vol. <volume>5</volume>, Morgan-Kaufmann, <year>1992</year>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper_files/paper/1992/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/1992/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf</ext-link>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Lagache</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Lang</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Sauvonnet</surname></string-name>, and <string-name><given-names>J.-C.</given-names> <surname>Olivo-Marin</surname></string-name>, “<article-title>Analysis of the Spatial Organization of Molecules with Robust Statistics</article-title>,” en, <source>PLoS ONE</source>, vol. <volume>8</volume>, no. <issue>12</issue>, <person-group person-group-type="editor"><string-name><given-names>J. Z.</given-names> <surname>Rappoport</surname></string-name></person-group>, Ed., <fpage>e80914</fpage>, <month>Dec</month>. <year>2013</year>, ISSN: <issn>1932-6203</issn>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0080914</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://dx.plos.org/10.1371/journal.pone.0080914">https://dx.plos.org/10.1371/journal.pone.0080914</ext-link> (visited on 03/20/2024).</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="web"><string-name><given-names>S.</given-names> <surname>Gillies</surname></string-name>, <string-name><given-names>C.</given-names> <surname>van der Wel</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Van den Bossche</surname></string-name>, <string-name><given-names>M. W.</given-names> <surname>Taves</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Arnott</surname></string-name>, <string-name><given-names>B. C.</given-names> <surname>Ward</surname></string-name>, <etal>et al.</etal>, <source>Shapely</source>, <month>Feb</month>. <year>2024</year>. doi: <pub-id pub-id-type="doi">10.5281/ZENODO.5597138</pub-id>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/doi/10.5281/zenodo.5597138">https://zenodo.org/doi/10.5281/zenodo.5597138</ext-link> (visited on 03/20/2024).</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><string-name><given-names>N.</given-names> <surname>Srivastava</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Hinton</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Krizhevsky</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Sutskever</surname></string-name>, and <string-name><given-names>R.</given-names> <surname>Salakhutdinov</surname></string-name>, “<article-title>Dropout: A simple way to prevent neural networks from overfitting</article-title>,” <source>The Journal of Machine Learning Research</source>, vol. <volume>15</volume>, no. <issue>1</issue>, pp. <fpage>1929</fpage>–<lpage>1958</lpage>, <month>Jan</month>. <year>2014</year>, Number of pages: 30 Publisher: <ext-link ext-link-type="uri" xlink:href="http://JMLR.org">JMLR.org</ext-link> tex.issue date: January 2014, ISSN: <issn>1532-4435</issn>.</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="book"><string-name><given-names>A.</given-names> <surname>Nayebi</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Attinger</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Campbell</surname></string-name>, <collab>et al.</collab>, “<chapter-title>Explaining heterogeneity in medial entorhinal cortex with task-driven neural networks</chapter-title>,” in <source>Advances in Neural Information Processing Systems</source>, <person-group person-group-type="editor"><string-name><given-names>M.</given-names> <surname>Ranzato</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Beygelzimer</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Dauphin</surname></string-name>, <string-name><given-names>P. S.</given-names> <surname>Liang</surname></string-name>, and <string-name><given-names>J. W.</given-names> <surname>Vaughan</surname></string-name></person-group>, Eds., vol. <volume>34</volume>, <publisher-name>Curran Associates, Inc</publisher-name>., <year>2021</year>, pp. <fpage>12 167</fpage>–<lpage>12 179</lpage>. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper_files/paper/2021/file/656f0dbf9392657eed7feefc486781fb-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2021/file/656f0dbf9392657eed7feefc486781fb-Paper.pdf</ext-link>.</mixed-citation></ref>
</ref-list>
<app-group>
<app id="app1">
<label>A</label>
<title>Appendix</title>
<sec id="s6">
<label>A.</label>
<title>Long Sequence Evaluation</title>
<p>To verify that the model performs accurate path integration, even for very long sequences, we computed Gaussian kernel density estimates of the Euclidean decoding error at every step along 100, 10000 timestep trajectories in each environment. The bandwidth parameter was set to approximately 0.4 according to Scott’s Rule, and the resulting error distributions are shown in <xref ref-type="fig" rid="figA1">Fig. A1</xref>.</p>
<fig id="figA1" position="float" fig-type="figure">
<label>Figure A1:</label>
<caption><title>Error distribution for long sequence evaluation.</title>
<p>Each pane shows the distribution and median of Euclidean distances (error) between true and decoded trajectories for the trained RNN evaluated on 100 long (10000 timestep) test trajectories in a particular environment (inset). The color indicates the kernel density estimate value at a particular timestep.</p></caption>
<graphic xlink:href="585049v2_figA1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figA2" position="float" fig-type="figure">
<label>Figure A2:</label>
<caption><title>Ratemaps of all 100 output units in each environment.</title>
<p>The geometry is indicated atop every ensemble. Unit identity is given by its location on the grid (e.g. unit 1 is top left in each environment).</p></caption>
<graphic xlink:href="585049v2_figA2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7">
<label>B</label>
<title>Extended Model Ratemaps</title>
<p><xref ref-type="fig" rid="figA2">Figures A2</xref> and <xref ref-type="fig" rid="figA3">A3</xref> show ratemaps for all 100 output units and 100 recurrent units, respectively. Responses in every environment are included. Notably, both output and recurrent units are sparse, with most recurrent units silent in a given environment. Output units display field shifts between environments, indicative of remapping.</p>
</sec>
<sec id="s8">
<label>C</label>
<title>Experimental Phase Distributions</title>
<p><xref rid="figA4" ref-type="fig">Figure A4</xref> shows estimated distributions of center locations, for centers decoded from ratemaps of high spatial-information place cells in mice (data provided by [<xref ref-type="bibr" rid="c38">38</xref>]). While some distributions display no clear patterns in their center arrangements (e.g., for animal QLAK-CA1-74), some distributions do display signs of clustering and even patterns with regularity (e.g., QLAK-CA1-50, which has a hexagonal resemblance).</p>
<fig id="figA3" position="float" fig-type="figure">
<label>Figure A3:</label>
<caption><title>Ratemaps of 100 recurrent units in each environment.</title>
<p>The geometry is indicated atop every ensemble. Unit identity is given by its location on the grid (e.g. unit 1 is top left in each environment).</p></caption>
<graphic xlink:href="585049v2_figA3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figA4" position="float" fig-type="figure">
<label>Figure A4:</label>
<caption><title>Place cell center distributions in mice.</title>
<p>Kernel Density estimates of center distributions, for centers decoded from 15<italic>×</italic>15 ratemaps of place cell activity for seven mice (indicated by title). Additionally, we show trajectories for all involved recording days, and the number of included cells is inset (N).</p></caption>
<graphic xlink:href="585049v2_figA4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s9">
<label>D</label>
<title>A Taxonomy of Cognitive Maps</title>
<p>With the definition of a cognitive map in <xref ref-type="disp-formula" rid="eqn1">Eq. (1)</xref>, we can categorise and compare recent normative neural navigation models. A range of models have recently been put forward that solve tasks similar to ours. In this section, we provide a brief recap of these models, and show that they may be viewed as instances of the cognitive map in <xref ref-type="disp-formula" rid="eqn1">Eq. (1)</xref> with different constraints and target representations.</p>
<p>Common to these models is that they all make use of random sampling of space in the form of simulated spatial trajectories in bounded 2D spaces, motivated by the foraging behaviour of rats. In addition, most works employ gradient-based optimization schemes, and optimize over independent minibatches. We will, however, omit indexing by minibatches for brevity.</p>
<p>For example, Dordek <italic>et al</italic>. used a target representation <bold>u</bold>(<bold>r</bold>) = <bold>p</bold>(<bold>r</bold>) of place cells modelled as either zero-mean Gaussians or difference of Gaussians, with <bold>r</bold> being a Cartesian coordinate which is encoded into a target place code. The target unit centre was sampled from a random, uniform distribution.</p>
<p>The task, in this case, was to perform non-negative PCA on the label place cells in a square domain Ω, i.e. finding a constrained low-dimensional representation of the label activity. Concretely, we can formulate PCA as the minimization problem
<disp-formula id="eqnA8">
<graphic xlink:href="585049v2_eqnA8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
with <italic>W∈</italic> ℝ<sup><italic>M×N</italic></sup>, <italic>M≤ N</italic> and where <inline-formula><inline-graphic xlink:href="585049v2_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="585049v2_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula> . The authors found that grid-like responses <bold>ĝ</bold> appear as an optimal low-dimensional representation of the target place code <bold>p</bold>. This formulation [<xref ref-type="bibr" rid="c39">39</xref>] is suitable for studying optimal cognitive maps in an idealized spatial setting. In the ideal setting, the candidate map is learned directly from true spatial coordinates, in contrast to the case where this information is latent, and agents have to build estimates of their location by integrating several sources of spatial information, such as landmark locations and path integration.</p>
<p>Cueva <italic>et al</italic>., Banino <italic>et al</italic>., Sorscher <italic>et al</italic>. learns latent spatial representations through path integration in a recurrent neural network model. The state of the recurrent network at time <italic>t</italic> is given by a recurrence relation
<disp-formula id="eqnA9">
<graphic xlink:href="585049v2_eqnA9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where Θ denotes a set of model parameters, and <bold>v</bold>(<italic>t</italic>) the input velocities at some time <italic>t</italic>, while Δ<italic>t</italic> is an increment of time. For the RNNs described in the coming sections, we suppress the dependency on parameters Θ for the sake of readability.</p>
<p>Cueva <italic>et al</italic>. considered a version of the cognitive map <xref ref-type="disp-formula" rid="eqn1">Eq. (1)</xref> in which a recurrent neural network was trained to minimize the reconstruction error and soft constraints
<disp-formula id="eqnA10">
<graphic xlink:href="585049v2_eqnA10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where<inline-formula><inline-graphic xlink:href="585049v2_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, is implemented using a continuous time RNN, with initial state <bold>ĝ</bold><sub>0</sub> = 0, and subsequent states given by the recurrence relation in <xref ref-type="disp-formula" rid="eqnA9">Eq. (A9)</xref> and stationary noise <italic>ξ</italic><sub><italic>t</italic></sub><italic>∼</italic>𝒩 (<italic>µ, σ</italic><sup>2</sup>). Moreover, <inline-formula><inline-graphic xlink:href="585049v2_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and <italic>W</italic><sub><italic>in</italic></sub> is a weight matrix for the velocity input <bold>v</bold><sub><italic>t</italic></sub> to the RNN. The domain Ω is a 2D square arena visited along simulated trajectories, and the network only received velocity inputs along trajectories, necessitating path integration. In this case, the target representation is Cartesian coordinates <bold>u</bold>(<bold>r</bold><sub><italic>t</italic></sub>) = <bold>r</bold><sub><italic>t</italic></sub><italic>∈</italic> Ω. The authors report that the learned recurrent representations <bold>ĝ</bold> appear square grid, band and border cell-like.</p>
<p>Banino <italic>et al</italic>. considered the case of a recurrent long short-term memory (LSTM) network trained to do supervised position prediction. Unlike [<xref ref-type="bibr" rid="c29">29</xref>], the training objective featured two target representations, <bold>u</bold><sub><italic>t</italic></sub> = <bold>p</bold><sub><italic>t</italic></sub> <italic>∪</italic> <bold>z</bold><sub><italic>t</italic></sub>. The first target representation, <bold>p</bold><sub><italic>t</italic></sub> = <bold>p</bold>(<bold>r</bold><sub><italic>t</italic></sub>), was given by an ensemble of normalized, Gaussian place-like units, with <bold>r</bold><sub><italic>t</italic></sub><italic>∈</italic> Ω being Cartesian coordinates along discretized spatial trajectories in a square domain Ω. The second target representation consisted of an ensemble of units encoding heading direction, <bold>z</bold><sub><italic>t</italic></sub> = <bold>z</bold>(<italic>ϕ</italic><sub><italic>t</italic></sub>), where <italic>ϕ</italic><sub><italic>t</italic></sub> is the head direction at time <italic>t</italic>. The representations of the head direction ensemble were given by a normalized mixture of von Mises distributions. At each step of path integration, the network received linear and angular velocity information along simulated trajectories. In summary, the loss and corresponding soft constraints can be written as
<disp-formula id="eqnA11">
<graphic xlink:href="585049v2_eqnA11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where CE is the cross entropy and Dropout [<xref ref-type="bibr" rid="c56">56</xref>] is a method that ablates random units with a specified rate during training to promote redundancy.</p>
<p>The cognitive map, in this case, is given by <inline-formula><inline-graphic xlink:href="585049v2_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula> with <bold>ĥ</bold><sub><italic>t</italic></sub> defined by a recurrent neural network with a tanh activation function, while <bold>ĝ</bold><sub><italic>t</italic></sub> = <italic>W</italic><sub><italic>g</italic></sub><bold>ĥ</bold><sub><italic>t</italic></sub> is an intermediate linear layer. Finally, <inline-formula><inline-graphic xlink:href="585049v2_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and<inline-formula><inline-graphic xlink:href="585049v2_inline14.gif" mimetype="image" mime-subtype="gif"/></inline-formula> . The intermediate representations, a subset of the cognitive map, <bold>ĝ</bold><sub><italic>t</italic></sub> were found to display heterogeneous, grid-like responses.</p>
<p>Sorscher <italic>et al</italic>. reproduced [<xref ref-type="bibr" rid="c29">29</xref>], [<xref ref-type="bibr" rid="c30">30</xref>], [<xref ref-type="bibr" rid="c39">39</xref>] and refined the grid cell model in [<xref ref-type="bibr" rid="c30">30</xref>] by considering a simpler RNN structure (a vanilla RNN - although other variations have also been tested and shown to provide similar results [<xref ref-type="bibr" rid="c57">57</xref>]), removing head-direction inputs and outputs, the intermediate linear layer, dropout, refining the place cell target representation, and selecting the ReLU as the recurrent activation function [<xref ref-type="bibr" rid="c31">31</xref>].
<disp-formula id="eqnA12">
<graphic xlink:href="585049v2_eqnA12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where CE is again the cross entropy, <bold>p</bold><sub><italic>t</italic></sub> = <bold>p</bold>(<bold>r</bold><sub><italic>t</italic></sub>) is a difference of softmax place cell encoding of the current position of the virtual agent. In this case, the cognitive map is given by<inline-formula><inline-graphic xlink:href="585049v2_inline15.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where <bold>ĝ</bold><sub><italic>t</italic></sub> and<inline-formula><inline-graphic xlink:href="585049v2_inline16.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where <italic>W</italic> is a weight matrix. Notably, <bold>ĝ</bold><sub><italic>t</italic></sub> is computed using a vanilla RNN that learns implicit path integration using Cartesian velocity inputs. The authors report that the recurrent responses <bold>ĝ</bold><sub><italic>t</italic></sub> learn to exhibit striking hexagonal firing fields, similar to [<xref ref-type="bibr" rid="c39">39</xref>].</p>
<p>This brief taxonomy of normative navigation models hopefully shows how our definition of a cognitive map can be used describe a range of different models that learn biologically inspired representations through the lens of machine learning. Furthermore, our definition, and the notion of a target representation, could hopefully inspire new models. For example, one could consider decoding into a target representation of simulated grid cells.</p>
</sec>
</app>
</app-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99302.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Bhalla</surname>
<given-names>Upinder S</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Centre for Biological Sciences</institution>
</institution-wrap>
<city>Bangalore</city>
<country>India</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>useful</bold> study shows the representations that emerge in a recurrent neural network trained on a navigation task by requiring path integration and decodability. The network modeling was <bold>solid</bold>, but interpretation of neural data and mechanisms was <bold>incomplete</bold>.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99302.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work studies representations in a network with one recurrent layer and one output layer that needs to path-integrate so that its position can be accurately decoded from its output. To formalise this problem, the authors define a cost function consisting of the decoding error and a regularisation term. They specify a decoding procedure that at a given time averages the output unit center locations, weighted by the activity of the unit at that time. The network is initialised without position information, and only receives a velocity signal (and a context signal to index the environment) at each timestep, so to achieve low decoding error it needs to infer its position and keep it updated with respect to its velocity by path integration.</p>
<p>The authors take the trained network and let it explore a series of environments with different geometries while collecting unit activities to probe learned representations. They find localised responses in the output units (resembling place fields) and border responses in the recurrent units. Across environments, the output units show global remapping and the recurrent units show rate remapping. Stretching the environment generally produces stretched responses in output and recurrent units. Ratemaps remain stable within environments and stabilise after noise injection. Low-dimensional projections of the recurrent population activity forms environment-specific clusters that reflect the environment's geometry, which suggests independent rather than generalised representations. Finally, the authors discover that the centers of the output unit ratemaps cluster together on a triangular lattice (like the receptive fields of a single grid cell), and find significant clustering of place cell centers in empirical data as well.</p>
<p>The model setup and simulations are clearly described, and are an interesting exploration of the consequences of a particular set of training requirements - here: path integration and decodability. But it is not obvious to what extent the modelling choices are a realistic reflection of how the brain solves navigation. Therefore it is not clear whether the results generalize beyond the specifics of the setup here.</p>
<p>Strengths:</p>
<p>The authors introduce a very minimal set of model requirements, assumptions, and constraints. In that sense, the model can function as a useful 'baseline', that shows how spatial representations and remapping properties can emerge from the requirement of path integration and decodability alone. Moreover, the authors use the same formalism to relate their setup to existing spatial navigation models, which is informative.</p>
<p>The global remapping that the authors show is convincing and well-supported by their analyses. The geometric manipulations and the resulting stretching of place responses, without additional training, are interesting. They seem to suggest that the recurrent network may scale the velocity input by the environment dimensions so that the exact same path integrator-output mappings remain valid (but maybe there are other mechanisms too that achieve the same).</p>
<p>The clustering of place cell peaks on a triangular lattice is intriguing, given there is no grid cell input. It could have something to do with the fact that a triangular lattice provides optimal coverage of 2d space? The included comparison with empirical data is valuable, although the authors only show significant clustering - there is no analysis of its grid-like regularity.</p>
<p>Weaknesses:</p>
<p>The navigation problem that needs to be solved by the model is a bit of an odd one. Without any initial position information, the network needs to figure out where it is, and then path-integrate with respect to a velocity signal. As the authors remark in Methods 4.2, without additional input, the only way to infer location is from border interactions. It is like navigating in absolute darkness. Therefore, it seems likely that the salient wall representations found in the recurrent units are just a consequence of the specific navigation task here; it is unclear if the same would apply in natural navigation. In natural navigation, there are many more sensory cues that help inferring location, most importantly vision, but also smell and whiskers/touch (which provides a more direct wall interaction; here, wall interactions are indirect by constraining velocity vectors). There is a similar but weaker concern about whether the (place cell like) localised firing fields of the output units are a direct consequence of the decoding procedure that only considers activity center locations.</p>
<p>The conclusion that 'contexts are attractive' (heading of section 2) is not well-supported. The authors show 'attractor-like behaviour' within a single context, but there could be alternative explanations for the recovery of stable ratemaps after noise injection. For example, the noise injection could scramble the network's currently inferred position, so that it would need to re-infer its position from boundary interactions along the trajectory. In that case the stabilisation would be driven by the input, not just internal attractor dynamics. Moreover, the authors show that different contexts occupy different regions in the space of low-dimensional projections of recurrent activity, but not that these regions are attractive.</p>
<p>The authors report empirical data that shows clustering of place cell centers like they find for their output units. They report that 'there appears to be a tendency for the clusters to arrange in hexagonal fashion, similar to our computational findings'. They only quantify the clustering, but not the arrangement. Moreover, in Figure 7e they only plot data from a single animal, then plot all other animals in the supplementary. Does the analysis of Fig 7f include all animals, or just the one for which the data is plotted in 7e? If so, why that animal? As Appendix C mentions that the ratemap for the plotted animal 'has a hexagonal resemblance' whereas other have 'no clear pattern in their center arrangements', it feels like cherrypicking to only analyse one animal without further justification.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99302.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
The authors proposed a neural network model to explore the spatial representations of the hippocampal CA1 and entorhinal cortex (EC) and the remapping of these representations when multiple environments are learned. The model consists of a recurrent network and output units (a decoder) mimicking the EC and CA1, respectively. The major results of this study are: the EC network generates cells with their receptive fields tuned to a border of the arena; decoder develops neuron clusters arranged in a hexagonal lattice. Thus, the model accounts for entrohinal border cells and CA1 place cells. The authors also suggested the remapping of place cells occurs between different environments through state transitions corresponding to unstable dynamical modes in the recurrent network.</p>
<p>Strengths:</p>
<p>
The authors found a spatial arrangement of receptive fields similar to their model's prediction in experimental data recorded from CA1. Thus, the model proposes a plausible mechanisms to generate hippocampal spatial representations without relying on grid cells. This result is consistent with the observation that grid cells are unnecessary to generate CA1 place cells.</p>
<p>The suggestion about the remapping mechanism shows an interesting theoretical possibility.</p>
<p>Weaknesses:</p>
<p>
The explicit mechanisms of generating border cells and place cells and those underlying remapping were not clarified at a satisfactory level.</p>
<p>The model cannot generate entorhinal grid cells. Therefore, how the proposed model is integrated into the entire picture of the hippocampal mechanism of meｍory processing remains elusive.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99302.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors used recurrent neural network modelling of spatial navigation tasks to investigate border and place cell behaviour during remapping phenomena.</p>
<p>Strengths:</p>
<p>The neural network training seemed for the most part (see comments later) well-performed, and the analyses used to make the points were thorough.</p>
<p>The paper and ideas were well explained.</p>
<p>Figure 4 contained some interesting and strong evidence for map-like generalisation as environmental geometry was warped.</p>
<p>Figure 7 was striking, and potentially very interesting.</p>
<p>It was impressive that the RNN path-integration error stayed low for so long (Fig A1), given that normally networks that only work with dead-reckoning have errors that compound. I would have loved to know how the network was doing this, given that borders did not provide sensory input to the network. I could not think of many other plausible explanations... It would be even more impressive if it was preserved when the network was slightly noisy.</p>
<p>Weaknesses:</p>
<p>I felt that the stated neuroscience interpretations were not well supported by the presented evidence, for a few reasons I'll now detail.</p>
<p>First, I was unconvinced by the interpretation of the reported recurrent cells as border cells. An equally likely hypothesis seemed to be that they were positions cells that are linearly encoding the x and y position, which when your environment only contains external linear boundaries, look the same. As in figure 4, in environments with internal boundaries the cells do not encode them, they encode (x,y) position. Further, if I'm not misunderstanding, there is, throughout, a confusing case of broken symmetry. The cells appear to code not for any random linear direction, but for either the x or y axis (i.e. there are x cells and y cells). These look like border cells in environments in which the boundaries are external only, and align with the axes (like square and rectangular ones), but the same also appears to be true in the rotationally symmetric circular environment, which strikes me as very odd. I can't think of a good reason why the cells in circular environments should care about the particular choice of (x,y) axes... unless the choice of position encoding scheme is leaking influence throughout. A good test of these would be differently oriented (45 degree rotated square) or more geometrically complicated (two diamonds connected) environments in which the difference between a pure (x,y) code and a border code are more obvious.</p>
<p>Next, the decoding mechanism used seems to have forced the representation to learn place cells (no other cell type is going to be usefully decodable?). That is, in itself, not a problem. It just changes the interpretation of the results. To be a normative interpretation for place cells you need to show some evidence that this decoding mechanism is relevant for the brain, since this seems to be where they are coming from in this model. Instead, this is a model with place cells built into it, which can then be used for studying things like remapping, which is a reasonable stance.</p>
<p>However, the remapping results were also puzzling. The authors present convincing evidence that the recurrent units effectively form 6 different maps of the 6 different environments (e.g. the sparsity of the cod, or fig 6a), with the place cells remapping between environments. Yet, as the authors point out, in neural data the finding is that some cells generalise their co-firing patterns across environments (e.g. grid cells, border cells), while place cells remap, making it unclear what correspondence to make between the authors network and the brain. There are existing normative models that capture both entorhinal's consistent and hippocampus' less consistent neural remapping behaviour (Whittington et al. and probably others), what have we then learnt from this exercise?</p>
<p>One striking result was figure 7, the hexagonal arrangement of place cell centres. I had one question that I couldn't find the answer to in the paper, which would change my interpretation. Are place cell centres within a single clusters of points in figure 7a, for example, from one cell across the 100 trajectories, or from many? If each cluster belongs to a different place cell then the interpretation seems like some kind of optimal packing/coding of 2D space by a set of place cells, an interesting prediction. If multiple place cells fall within a single cluster then that's a very puzzling suggestion about the grouping of place cells into these discrete clusters. From figure 7c I guess that the former is the likely interpretation, from the fact that clusters appear to maintain the same colour, and are unlikely to be co-remapping place cells, but I would like to know for sure!</p>
<p>I felt that the neural data analysis was unconvincing. Most notably, the statistical effect was found in only one of seven animals. Random noise is likely to pass statistical tests 1 in 20 times (at 0.05 p value), this seems like it could have been something similar? Further, the data was compared to a null model in which place cell fields were randomly distributed. The authors claim place cell fields have two properties that the random model doesn't (1) clustering to edges (as experimentally reported) and (2) much more provocatively, a hexagonal lattice arrangement. The test seems to collude the two; I think that nearby ball radii could be overrepresented, as in figure 7f, due to either effect. I would have liked to see a computation of the statistic for a null model in which place cells were random but with a bias towards to boundaries of the environment that matches the observed changing density, to distinguish these two hypotheses.</p>
<p>Some smaller weaknesses:</p>
<p>
- Had the models trained to convergence? From the loss plot it seemed like not, and when including regularisors recent work (grokking phenomena, e.g. Nanda et al. 2023) has shown the importance of letting the regularisor minimise completely to see the resulting effect. Else you are interpreting representations that are likely still being learnt, a dangerous business.</p>
<p>
- Since RNNs are nonlinear it seems that eigenvalues larger than 1 doesn't necessarily mean unstable?</p>
<p>
- Why do you not include a bias in the networks? ReLU networks without bias are not universal function approximators, so it is a real change in architecture that doesn't seem to have any positives?</p>
<p>
- The claim that this work provided a mathematical formalism of the intuitive idea of a cognitive map seems strange, given that upwards of 10 of the works this paper cite also mathematically formalise a cognitive map into a similar integration loss for a neural network.</p>
<p>Aim Achieved? Impact/Utility/Context of Work</p>
<p>Given the listed weaknesses, I think this was a thorough exploration of how this network with these losses is able to path-integrate its position and remap. This is useful, it is good to know how another neural network with slightly different constraints learns to perform these behaviours. That said, I do not think the link to neuroscience was convincing, and as such, it has not achieved its stated aim of explaining these phenomena in biology. The mechanism for remapping in the entorhinal module seemed fundamentally different to the brain's, instead using completely disjoint maps; the recurrent cell types described seemed to match no described cell type (no bad thing in itself, but it does limit the permissible neuroscience claims) either in tuning or remapping properties, with a potentially worrying link between an arbitrary encoding choice and the responses; and the striking place cell prediction was unconvincingly matched by neural data. Further, this is a busy field in which many remapping results have been shown before by similar models, limiting the impact of this work. For example, George et al. and Whittington et al. show remapping of place cells across environments; Whittington et al. study remapping of entorhinal codes; and Rajkumar Vasudeva et al. 2022 show similar place cell stretching results under environmental shifts. As such, this papers contribution is muddied significantly.</p>
</body>
</sub-article>
</article>