<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">93981</article-id>
<article-id pub-id-type="doi">10.7554/eLife.93981</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.93981.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Intrinsic dynamics of randomly clustered networks generate place fields and preplay of novel environments</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5793-4427</contrib-id>
<name>
<surname>Breffle</surname>
<given-names>Jordan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7624-2431</contrib-id>
<name>
<surname>Germaine</surname>
<given-names>Hannah</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7959-7772</contrib-id>
<name>
<surname>Shin</surname>
<given-names>Justin D.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5821-0551</contrib-id>
<name>
<surname>Jadhav</surname>
<given-names>Shantanu P.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9280-000X</contrib-id>
<name>
<surname>Miller</surname>
<given-names>Paul</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Neuroscience Program, Brandeis University</institution>, 415 South St., Waltham, MA 02454</aff>
<aff id="a2"><label>2</label><institution>Volen National Center for Complex Systems, Brandeis University</institution>, 415 South St., Waltham, MA 02454</aff>
<aff id="a3"><label>3</label><institution>Department of Psychology, Brandeis University</institution>, 415 South St., Waltham, MA 02454</aff>
<aff id="a4"><label>4</label><institution>Department of Biology, Brandeis University</institution>, 415 South St., Waltham, MA 02454</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Peyrache</surname>
<given-names>Adrien</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>McGill University</institution>
</institution-wrap>
<city>Montreal</city>
<country>Canada</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding Authors: <email>shantanu@brandeis.edu</email> (S.P.J.) <email>pmiller@brandeis.edu</email> (P.M.)</corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-03-04">
<day>04</day>
<month>03</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP93981</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-11-23">
<day>23</day>
<month>11</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-10-31">
<day>31</day>
<month>10</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.10.26.564173"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Breffle et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Breffle et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-93981-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>During both sleep and awake immobility, hippocampal place cells reactivate time-compressed versions of sequences representing recently experienced trajectories in a phenomenon known as replay. Intriguingly, spontaneous sequences can also correspond to forthcoming trajectories in novel environments experienced later, in a phenomenon known as preplay. Here, we present a model showing that sequences of spikes correlated with the place fields underlying spatial trajectories in both previously experienced and future novel environments can arise spontaneously in neural circuits with random, clustered connectivity rather than pre-configured spatial maps. Moreover, the realistic place fields themselves arise in the circuit from minimal, landmark-based inputs. We find that preplay quality depends on the network’s balance of cluster isolation and overlap, with optimal preplay occurring in small-world regimes of high clustering yet short path lengths. We validate the results of our model by applying the same place field and preplay analyses to previously published rat hippocampal place cell data. Our results show that clustered recurrent connectivity can generate spontaneous preplay and immediate replay of novel environments. These findings support a framework whereby novel sensory experiences become associated with preexisting “pluripotent” internal neural activity patterns.</p></abstract>
<abstract abstract-type="teaser">
<title>Impact Statement</title>
<p>Neural circuits with small-world connectivity spontaneously emit sequences of spikes that are correlated with any of the distinct sequences of realistic place fields produced by location-modulated, monotonically varying input.</p></abstract>
<abstract>
<title>Contributions</title>
<p>Jordan Breffle: Conceptualization, Formal Analysis, Investigation, Methodology, Software, Visualization, Writing – original draft, Writing – review &amp; editing</p>
<p>Hannah Germaine: Conceptualization, Methodology, Software, Writing – review &amp; editing Justin D. Shin: Data curation, Investigation, Writing – review &amp; editing</p>
<p>Shantanu P. Jadhav: Conceptualization, Funding acquisition, Resources, Supervision, Writing – review &amp; editing</p>
<p>Paul Miller: Conceptualization, Funding acquisition, Methodology, Project administration, Resources, Supervision, Writing – review &amp; editing</p></abstract>
<abstract>
<title>Funding</title>
<p>NIH/NINDS R01NS104818, NIH/NIMH R01MH112661, NIH/NIMH R01MH120228, and Brandeis University Neuroscience Graduate Program</p></abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The hippocampus plays a critical role in spatial and episodic memory in mammals (<xref ref-type="bibr" rid="c35">Morris et al., 1982</xref>; <xref ref-type="bibr" rid="c56">Squire et al., 2004</xref>). Place cells in the hippocampus exhibit spatial tuning, firing selectively in specific locations of a spatial environment (<xref ref-type="bibr" rid="c36">Moser et al., 2008</xref>; O’Keefe and Dostrovsky, 1971). During sleep and quiet wakefulness, place cells show a time-compressed reactivation of spike sequences corresponding to recent experiences (<xref ref-type="bibr" rid="c63">Wilson and McNaughton, 1994</xref>; <xref ref-type="bibr" rid="c15">Foster and Wilson, 2006</xref>), known as replay. These replay events are thought to be important for memory consolidation, often referred to as memory replay (<xref ref-type="bibr" rid="c8">Carr et al., 2011</xref>).</p>
<p>The CA3 region of the hippocampus is a highly recurrently connected region that is the primary site of replay generation in the hippocampus. Input from CA3 supports replay in CA1 (Csicsvari et al., 2002; <xref ref-type="bibr" rid="c64">Yamamoto and Tonegawa, 2017</xref>; <xref ref-type="bibr" rid="c38">Nakashiba et al., 2008</xref>; <xref ref-type="bibr" rid="c39">Nakashiba et al., 2009</xref>), and peri-ripple spiking in CA3 precedes that of CA1 (<xref ref-type="bibr" rid="c43">Nitzan et al., 2022</xref>). The recurrent connections support intrinsically generated bursts of activity that propagate through the network.</p>
<p>Most replay models rely on a recurrent network structure in which a map of the environment is encoded in the recurrent connections of CA3 cells, such that cells with nearby place fields are more strongly connected. Some models assume this structure is pre-existing (<xref ref-type="bibr" rid="c19">Haga and Fukai, 2018</xref>; <xref ref-type="bibr" rid="c46">Pang and Fairhall, 2019</xref>), and some show how it could develop over time through synaptic plasticity (<xref ref-type="bibr" rid="c58">Theodoni et al., 2018</xref>; <xref ref-type="bibr" rid="c24">Jahnke et al., 2015</xref>). However, in novel environments place cells remap immediately in a seemingly random fashion (<xref ref-type="bibr" rid="c28">Leutgeb et al., 2005</xref>; <xref rid="c37" ref-type="bibr">Muller and Kubie, 1987</xref>). The CA3 region, in particular, undergoes pronounced remapping (<xref ref-type="bibr" rid="c27">Leutgeb et al., 2004</xref>; <xref ref-type="bibr" rid="c28">Leutgeb et al., 2005</xref>; <xref ref-type="bibr" rid="c1">Alme et al., 2014</xref>). A random remapping of place fields in such models that rely on environment-specific recurrent connectivity between place cells would lead to recurrent connections that are random with respect to the novel environment, and thus would not support replay of the novel environment.</p>
<p>Rather, these models require a pre-existing structure of recurrent connections to be created for each environment. A proposed solution to account for remapping in hippocampal models is to assume the existence of multiple independent and uncorrelated spatial maps stored within the connections between cells. In this framework, the maximum number of maps is reached when the noise induced via connections needed for alternative maps becomes too great for a faithful rendering of the current map (<xref ref-type="bibr" rid="c48">Samsonovich and McNaughton, 1997</xref>; <xref ref-type="bibr" rid="c4">Battaglia and Treves, 1998</xref>; <xref ref-type="bibr" rid="c3">Azizi et al., 2013</xref>). However, experiments have found that hippocampal representations remain uncorrelated, with no signs of representation re-use, after testing as many as 11 different environments in rats (<xref ref-type="bibr" rid="c1">Alme et al., 2014</xref>).</p>
<p>Rather than re-using a previously stored map, another possibility is that a novel map for a novel environment is generated <italic>de novo</italic> through experience-dependent plasticity while in the environment. Given the timescales of synaptic and structural plasticity, one might expect that significant experience within each environment is needed to produce each new map. However, replay can occur after just 1-2 laps on novel tracks (<xref ref-type="bibr" rid="c15">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="c5">Berners-Lee et al., 2022</xref>), which means that the synaptic connections that allow the generation of the replayed sequences must already be present. Consistent with this expectation, it has been found that decoded sequences during sleep show significant correlations when decoded by place fields from future, novel environments. This phenomenon is known as preplay and has been observed in both rodents (<xref ref-type="bibr" rid="c11">Dragoi and Tonegawa, 2011</xref>; <xref ref-type="bibr" rid="c12">Dragoi and Tonegawa, 2013</xref>; <xref ref-type="bibr" rid="c18">Grosmark and Buzsaki, 2016</xref>; Liu et al., 2018) and humans (<xref ref-type="bibr" rid="c59">Vaz et al., 2023</xref>).</p>
<p>The existence of both preplay and immediate replay in novel environments suggests that the preexisting recurrent connections in the hippocampus that generate replay are somehow correlated with the pattern of future place fields that arise in novel environments. To reconcile these experimental results, we propose a model of intrinsic sequence generation based on randomly clustered recurrent connectivity, without reliance on pre-existing environment maps. Such clustering, also observed in cortex (<xref ref-type="bibr" rid="c55">Song et al., 2005</xref>), naturally arises from a combination of Hebbian and homeostatic plasticity in recurrent networks (<xref ref-type="bibr" rid="c6">Bourjaily and Miller, 2011</xref>; <xref ref-type="bibr" rid="c30">Litwin-Kumar and Doiron, 2014</xref>; <xref ref-type="bibr" rid="c33">Lynn et al., 2022</xref>), and spontaneously develops in networks of cultured hippocampal neurons (<xref ref-type="bibr" rid="c2">Antonello et al., 2022</xref>).</p>
<p>As an animal gains experience in an environment, the pattern of recurrent connections of CA3 would be shaped by Hebbian plasticity (<xref ref-type="bibr" rid="c10">Debanne et al., 1998</xref>; <xref ref-type="bibr" rid="c34">Mishra et al., 2016</xref>). Relative to CA1, which has little recurrent connectivity, CA3 has been found to have both more stable spatial tuning and a stronger functional assembly organization, consistent with the hypothesis that spatial coding in CA3 is influenced by its recurrent connections (<xref ref-type="bibr" rid="c51">Sheintuch et al., 2023</xref>). Gaining experience in different environments would then be expected to lead to individual place cells participating in multiple formed clusters. Such overlapping clustered connectivity may be a general feature of any hippocampal and cortical region that has typical Hebbian plasticity rules. <xref rid="c47" ref-type="bibr">Sadovsky et al., 2014</xref> found such structure in the spontaneous activity of excitatory neurons in primary visual cortex, where cells formed overlapping but distinct functional clusters. Further, such preexisting clusters may help explain the correlations that have been found in otherwise seemingly random remapping (<xref ref-type="bibr" rid="c26">Kinsky et al., 2018</xref>; <xref ref-type="bibr" rid="c62">Whittington et al., 2020</xref>).</p>
<p>Since our model relies on its random recurrent connections for propagation of activity through the network during spontaneous activity, we also sought to assess the extent to which the internal activity within the network can generate place cells with firing rate peaks at a location where they do not receive a peak in their external input. Our reasoning is that landmarks in the environment, such as boundaries or corners, provide location-specific visual input to an animal, but locations between such features are primarily indicated by their distance from them, which in our model is represented by reduction in the landmark-specific input. One can therefore equate our model’s inputs as corresponding to boundary cells (<xref ref-type="bibr" rid="c49">Savelli et al., 2008</xref>; <xref ref-type="bibr" rid="c54">Solstad et al., 2008</xref>; <xref ref-type="bibr" rid="c7">Bush et al., 2014</xref>), and the place fields between boundaries are generated by random internal structure within the network.</p>
<p>In our implementation of this model, we find that spontaneous sequences of spikes generated by a randomly clustered network can be decoded as spatial trajectories without relying on pre-configured, environment-specific maps. Because the network contains neither a preexisting map of the environment nor experience-dependent plasticity, we refer to the spike-sequences it generates as preplay. However, the model can also be thought of as a preexisting network in which immediate replay in a novel environment can be expressed and then reinforced through experience-dependent plasticity. We find that preplay in this model occurs most strongly when the network parameters are tuned to generate networks that have a small-world structure (<xref ref-type="bibr" rid="c61">Watts and Strogatz, 1998</xref>; <xref ref-type="bibr" rid="c20">Humphries et al., 2006</xref>; <xref rid="c22" ref-type="bibr">Humphries et al., 2008</xref>). Our results support the idea that preplay and immediate replay could be a natural consequence of the preexisting recurrent structure of the hippocampus.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>The model</title>
<p>We propose a model of preplay and immediate replay based on randomly clustered recurrent connections (<xref rid="fig1" ref-type="fig">Figure 1</xref>). In prior models of preplay and replay, a preexisting map of the environment is typically assumed to be contained within the recurrent connections of CA3 cells, such that cells with nearby place fields are more strongly connected (<xref rid="fig1" ref-type="fig">Figure 1a</xref>). While this type of model successfully produces replay (<xref ref-type="bibr" rid="c19">Haga and Fukai, 2018</xref>; <xref ref-type="bibr" rid="c46">Pang and Fairhall, 2019</xref>), such a map would only be expected to exist in a familiar environment, after experience-dependent synaptic plasticity has had time to shape the network (<xref ref-type="bibr" rid="c58">Theodoni et al., 2018</xref>). It remains unclear how, in the absence of such a preexisting map of the environment, the hippocampus can generate both preplay and immediate replay of a novel environment.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Illustration of the randomly clustered model</title>
<p><bold>(a)</bold> Schematic diagram of prior replay models that rely on preexisting environment-specific structure, wherein each cell receives uniquely tuned Gaussian-shaped feed-forward inputs to define the place fields, and cells with nearby place fields are recurrently connected. Pairs of cells with closest place fields are connected most strongly (thicker arrows). <bold>(b)</bold> Schematic diagram of our model, where neurons are randomly placed into clusters and all neurons receive the same spatial and contextual information but with random, cluster-dependent input strengths. <bold>(c)</bold> Example representation of the network (8 clusters, mean cluster participation per cell of 1.5). Excitatory cells (each symbol) are recurrently connected with each other and with inhibitory cells (“Feedback inhibition”, individual inhibitory cells not shown) and receive feed forward input (“Sensory input”). Symbol color indicates neurons’ membership in clusters 1 and 2, with ∼ meaning not in the cluster. Symbol size scales with the number of clusters a neuron is in. Lines show connections between neurons that are in cluster 2. Symbol positions are plotted based on a t-distributed stochastic neighbor embedding (t-SNE) of the connection matrix, which reveals the randomly overlapping clusters. <bold>(d-f)</bold> Histograms based on the network in (c) of: <bold>(d)</bold> the distribution of input strengths; <bold>(e)</bold> the number of clusters that each neuron is a member of; and <bold>(f)</bold> the fraction of the excitatory cells to which each excitatory cell connects. <bold>(g)</bold> The Small-World Index (SWI) of the excitatory connections varies with the number of clusters and the mean number of clusters of which each neuron is a member (“cluster participation”). The median value of the SWI from 10 networks at each parameter point is plotted. The red dashed line shows a contour line where SWI = 0.4. Regions in white are not possible due to either cluster participation exceeding the number of clusters (lower right) or cells not being able to connect to enough other cells to reach the target global connectivity <italic>p</italic><sub><italic>c</italic></sub> (upper left).</p></caption>
<graphic xlink:href="564173v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Our proposed alternative model is based on a randomly clustered recurrent network with random feed-forward inputs (<xref rid="fig1" ref-type="fig">Figure 1b</xref>). In our model, all excitatory neurons are randomly assigned to overlapping clusters that constrain the recurrent connectivity, and they all receive the same linear spatial and contextual input cues which are scaled by randomly drawn, cluster-dependent connection weights (see Methods).</p>
<p>An example network with 8 clusters and cluster participation of 1.5 (the mean number of clusters to which an excitatory neuron belongs) is depicted in <xref rid="fig1" ref-type="fig">Figure 1c</xref>. Excitatory neurons are recurrently connected to each other and to inhibitory neurons. Inhibitory cells have cluster-independent connectivity, such that all E-to-I and I-to-E connections exist with a probability of 0.25. Feed-forward inputs are independent Poisson spikes with random connection strength for each neuron (<xref rid="fig1" ref-type="fig">Figure 1d</xref>). Excitatory cells are randomly, independently assigned membership to each of the clusters in the network. All neurons are first assigned to one cluster, and then randomly assigned additional clusters to reach the target cluster participation (<xref rid="fig1" ref-type="fig">Figure 1e</xref>). Given the number of clusters and the cluster participation, the within-cluster connection probability is calculated such that the global connection probability matches the parameter <italic>p</italic><sub><italic>c</italic></sub> = 0.08 (<xref rid="fig1" ref-type="fig">Figure 1f</xref>). The left peak in the distribution shown in <xref rid="fig1" ref-type="fig">Figure 1f</xref> is from cells in a single cluster and the right peak is from cells in two clusters, with the long tail corresponding to cells in more than two clusters.</p>
<p>For a given <italic>p</italic><sub><italic>c</italic></sub>, excitatory connectivity is parameterized by the number of clusters in the network and the mean cluster participation. The small-world index (SWI; <xref ref-type="bibr" rid="c41">Neal, 2015</xref>; <xref ref-type="bibr" rid="c42">Neal, 2017</xref>) systematically varies across this 2-D parameterization (<xref rid="fig1" ref-type="fig">Figure 1g</xref>). A high SWI indicates a network with both clustered connectivity and short path lengths (<xref ref-type="bibr" rid="c61">Watts and Strogatz, 1998</xref>). For a fixed connection probability, SWI increases with more clusters and lower cluster participation, so long as cluster participation is greater than one to ensure sparse overlap of (and hence connections between) clusters. Networks in the top left corner of <xref rid="fig1" ref-type="fig">Figure 1g</xref> are not possible, since in that region all within-cluster connections are not sufficient to match the target global connectivity probability, <italic>p</italic><sub><italic>c</italic></sub>. Networks in the bottom right are not possible because otherwise mean cluster participation would exceed the number of clusters. The dashed red line shows an example contour line where <italic>SWI</italic> = 0.4.</p>
</sec>
<sec id="s2b">
<title>Example activity</title>
<p>Our randomly clustered model produces both place fields and preplay with no environment-specific plasticity or preexisting map of the environment (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Example place cell activity shows spatial specificity during linear track traversal (<xref rid="fig2" ref-type="fig">Figure 2a-c</xref>). Although the spatial tuning is noisy, this is consistent with the experimental finding that the place fields that are immediately expressed in a novel environment require experience in the environment to stabilize and improve decoding accuracy (<xref ref-type="bibr" rid="c57">Tang and Jadhav, 2022</xref>; <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>; <xref ref-type="bibr" rid="c23">Hwaun and Colgin, 2019</xref>). Raster plots of network spiking activity (<xref rid="fig2" ref-type="fig">Figure 2a</xref>) and example cell membrane potential traces (<xref rid="fig2" ref-type="fig">Figure 2b</xref>) demonstrate selective firing in specific track locations. Place fields from multiple networks generated from the same parameters, but with different input and recurrent connections, show spatial tuning across the track (<xref rid="fig2" ref-type="fig">Figure 2c</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Spatially correlated reactivations in networks without environment-specific connectivity or plasticity</title>
<p><bold>(a-f)</bold> Example activity from the fiducial parameter set (15 clusters, mean cluster participation of 1.25). <bold>(a)</bold> Example raster plot from one place-field trial. Cells sorted by trial peak. <bold>(b)</bold> Example membrane traces from two of the cells in (a). <bold>(c)</bold> Place fields from 10 different networks generated from the same parameter set, sorted by peak location and normalized by peak rate. <bold>(d)</bold> Example raster plot (top) and population firing rate (bottom; blue line) showing preplay in a simulation of sleep. Horizontal dashed black line is the mean population rate across the simulation. Horizontal dashed red line is the threshold for detecting a population-burst event (PBE). PBEs that exceeded the threshold for at least 50 ms and had at least 5 participating cells were included in the preplay decoding analysis. Grey bars highlight detected events. <bold>(e)</bold> Example replay event (Top, raster plot. Bottom, Bayesian decoding of position). Event corresponds to the center event in (d). Raster includes only participating cells. The blue line shows the weighted correlation of decoded position across time. <bold>(f)</bold> Nine example decoded events from the same networks in (c). The width of each time bin is 10 ms. The height spans the track length. Same color scale as in (e). r is each event’s absolute weighted correlation. jd is the maximum normalized jump in peak position probability between adjacent time bins. The same event in (e) is shown with its corresponding statistics in the center of the top row. Preplay statistics calculated as in <xref ref-type="bibr" rid="c13">Farooq et al., 2019</xref>.</p></caption>
<graphic xlink:href="564173v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To test the ability of the model to produce preplay, we simulated sleep sessions in the same networks. Sleep sessions were simulated in a similar manner to the running sessions but with no location cue inputs active and a different, unique set of context cue inputs active to represent the sleep context. The strength of the context cue inputs to the excitatory and inhibitory cells were scaled in order to generate an appropriate level of network activity, to account for the absence of excitatory drive from the location inputs (see Methods). During simulated sleep, the network produces structured spontaneous activations resembling preplay (<xref rid="fig2" ref-type="fig">Figure 2d-f</xref>). Example raster and population rate plots demonstrate spontaneous transient increases in spiking that exceed 1 standard deviation above the mean population rate denoting population burst events (PBEs; <xref rid="fig2" ref-type="fig">Figure 2d</xref>). We considered PBEs that lasted at least 50 ms and contained at least 5 participating cells candidates for Bayesian decoding (<xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>). Bayesian decoding of an example PBE using the simulated place fields reveals a spatial trajectory (<xref rid="fig2" ref-type="fig">Figure 2e</xref>). We use the same two statistics as <xref ref-type="bibr" rid="c13">Farooq et al. (2019)</xref> to quantify the quality of the decoded trajectory: the absolute weighted correlation (r) and the maximum jump distance (jd; <xref rid="fig2" ref-type="fig">Figure 2f</xref>). The absolute weighted correlation of a decoded event is the absolute value of the linear Pearson’s correlation of space-time weighted by the event’s derived posteriors. Since sequences can correspond to either direction along the track, the sign of the correlation simply indicates direction while the absolute value indicates the quality of preplay. The maximum jump distance of a decoded event is the maximum jump in the location of peak probability of decoded position across any two adjacent 10-ms time bins of the event’s derived posteriors. A high-quality event will have a high absolute weighted correlation and a low maximum jump distance.</p>
<p>Together, these results demonstrate that the model can reproduce key dynamics of hippocampal place cells, including spatial tuning and preplay, without relying on environment-specific recurrent connections.</p>
</sec>
<sec id="s2c">
<title>Place Fields</title>
<p>To compare the place fields generated by the model to those from hippocampal place cells of rats, we calculated several place-field statistics for both simulated and experimentally recorded place fields (<xref rid="fig3" ref-type="fig">Figure 3</xref>). Because our model assumes no previous environment-specific plasticity, we analyzed data from place cells in rats on their first exposure to a W-track (<xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>). Equivalent statistics of place-field peak rate, sparsity, and spatial information are shown for experimental data (<xref rid="fig3" ref-type="fig">Figure 3a</xref>) and simulations (<xref rid="fig3" ref-type="fig">Figure 3b</xref>). We found that the model produces qualitatively similar (but not quantitatively identical) distributions for the fiducial parameter set.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>The model produces place fields with similar properties to hippocampal place fields</title>
<p><bold>(a)</bold> Place field statistics for hippocampal place fields recorded in rats upon their first exposure to a W-track (<xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>). Left, place-field peak rate (Hz). Center, place-field specificity (fraction of track). Right, place-field spatial information (bits/spike). <bold>(b)</bold> Same as (a) but for place fields from a set of 10 simulated networks at one parameter point (15 clusters and mean cluster participation of 1.25). <bold>(c)</bold> Network parameter dependence of place-field statistics. For each parameter point, the color indicates the mean over all place fields from 10 networks. Top row: mean statistics corresponding to the same measures of place fields used in panels (a, b). Bottom left: mean firing rate of the inhibitory cells. Bottom center: the KL-divergence of the distribution of place-field peaks relative to a uniform spatial distribution. Bottom right: fraction of place-field peaks peaked in the central third of the track.</p></caption>
<graphic xlink:href="564173v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>These place-field properties depend on the network parameters (<xref rid="fig3" ref-type="fig">Figure 3c</xref>). With fewer clusters and lower cluster overlap (lower cluster participation), place fields have higher peak rates, sparsity, and spatial information (<xref rid="fig3" ref-type="fig">Figure 3c</xref>, top row and bottom left). However, lower overlap reduces the uniformity of place-field locations, measured by KL-divergence (<xref rid="fig3" ref-type="fig">Figure 3c</xref> bottom middle) and the fraction of place fields in the central third of the track (<xref rid="fig3" ref-type="fig">Figure 3c</xref> bottom right).</p>
</sec>
<sec id="s2d">
<title>Preplay</title>
<p>Having found that the model produces realistic place-field representations with neither place-field like inputs nor environment-specific spatial representation in the internal network connectivity (<xref rid="fig3" ref-type="fig">Figure 3</xref>), we next examined whether the same networks could generate spontaneous preplay of novel environments. To test this, for the same set of networks characterized by place-field properties in <xref rid="fig3" ref-type="fig">Figure 3</xref>, we simulated sleep activity by removing any location-dependent input cues and analyzed the resulting spike patterns for significant sequential structure resembling preplay trajectories (<xref rid="fig4" ref-type="fig">Figure 4</xref>). We find significant preplay in both our reference experimental data set (<xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>; <xref rid="fig4" ref-type="fig">Figure 4a, b</xref>; see <xref rid="figS4_1" ref-type="fig">Figure 4—figure supplement 1</xref> for example events) and our model (<xref rid="fig4" ref-type="fig">Figure 4c, d</xref>) when analyzed by the same methods as <xref ref-type="bibr" rid="c13">Farooq et al., 2019</xref>. For each detected event we calculated its absolute weighted correlation. We then generated 100 time-bin shuffles of each event, and for each shuffle recalculated the absolute weighted correlation to generate a null distribution of absolute weighted correlations. The distribution of absolute weighted correlations of actual events was significantly greater than the distribution of absolute weighted correlations of shuffled events for both the experimental data (<xref rid="fig4" ref-type="fig">Figure 4a</xref>, KS-test, p=2x10<sup>-12</sup>, KS-statistic=0.078) and the simulated data (<xref rid="fig4" ref-type="fig">Figure 4c</xref>, KS-test, p=3x10<sup>-16</sup>, KS-statistic=0.29). Additionally, we found that this result is robust to random subsampling of cells in our simulated data (<xref rid="figS4_2" ref-type="fig">Figure 4—figure supplement 2</xref>). Our analyses of the hippocampal data produce similar results when analyzing each trajectory independently (<xref rid="figS4_3" ref-type="fig">Figure 4—figure supplement 3</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Preplay depends on modest cluster overlap</title>
<p><bold>(a</bold>,<bold>c)</bold> The cumulative distribution function (CDF) of the absolute weighted correlations for actual events (blue line) versus shuffled events (red dashed line) of experimental data from Shin at al., 2019 (a; KS-test, p=2×10<sup>-12</sup>, KS-statistic=0.078) and simulated data (c; KS-test, p=3×10<sup>-16</sup>, KS-statistic=0.29) reveal results similar to those in Figure 1h of <xref ref-type="bibr" rid="c13">Farooq et al., 2019</xref>. *** p&lt;0.001. <bold>(b</bold>,<bold>d)</bold> P-value grids (p-value indicated logarithmically by color) showing that the actual decoded events are higher quality sequences than shuffles across a wide range of quality thresholds for both experimental data from <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref> (b) and simulated data (d). For each point on the grid the fraction of events that exceed the absolute weighted correlation threshold (y-axis) and don’t exceed the maximum jump distance (x-axis) is calculated, and the significance of this fraction is determined by comparison against a distribution of corresponding fractions from shuffled events. Black squares indicate criteria that were not met by any events (either shuffled or actual). The panel is equivalent to Figure 1e of <xref ref-type="bibr" rid="c13">Farooq et al., 2019</xref>. <bold>(e)</bold> Network parameter dependence of several statistics quantifying the population-burst events. Top left, fraction of excitatory cells firing per event. Top right, mean excitatory cell firing rate (Hz). Bottom left, mean event duration (s). Bottom right, mean event frequency (Hz). Each point is the mean of data combined across all population-burst events of 10 simulated networks at each parameter point. Data from the same simulations as Figure 3. <bold>(f)</bold> Network parameter dependence of several statistics quantifying the Bayesian decoding. Top left, p-value of the absolute weighted correlations (from a KS-test as calculated in (c)). Top right, the shift in the median absolute weighted correlation of actual events relative to shuffle events. Bottom left, the fraction of events with significant absolute weighted correlations relative to the distribution of absolute weighted correlations from time bin shuffles of the event. Bottom right, the mean entropy of the position probability of all time bins in decoded trajectories.</p></caption>
<graphic xlink:href="564173v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>For each event, we also calculated the maximum spatial jump of the peak probability of decoded position between any two adjacent time bins as a measure of the continuity of the decoded trajectory. The absolute weighted correlation (high is better) and maximum jump (low is better) were then two different measures of the quality of a decoded trajectory. We performed a bootstrap test that took both of these measures into account by setting thresholds for a minimum absolute weighted correlation and a maximum jump distance and then calculating the fraction of events meeting both criteria of quality. The significance of the fraction of events meeting both criteria was then determined by comparing it against a distribution of such fractions generated by sets of the time-bin shuffled events. We systematically varied both thresholds and found that the actual events are of significantly higher quality than chance for a wide range of thresholds in both the hippocampal (<xref rid="fig4" ref-type="fig">Figure 4b</xref>) and simulated (<xref rid="fig4" ref-type="fig">Figure 4d</xref>) data. The upper right corner of these grids cannot be significant since 100% of all possible events would be included in any shuffle or actual set. Points in the left-most column are not all significant because the strictness of the maximum jump distance means that very few events in either the actual or shuffled data sets meet the criterion, and therefore the analysis is underpowered. This pattern is similar to that seen in <xref ref-type="bibr" rid="c13">Farooq et al., 2019</xref> (as shown in their <xref rid="fig1" ref-type="fig">Figure 1e</xref>).</p>
<p>Both PBEs and preplay are significantly affected by the two network parameters (<xref rid="fig4" ref-type="fig">Figure 4c, d</xref>). The number of clusters and the extent of cluster overlap (indicated via mean cluster participation) affects PBE participation (<xref rid="fig4" ref-type="fig">Figure 4c</xref>, top left), firing rates (<xref rid="fig4" ref-type="fig">Figure 4c</xref>, top right), event durations (<xref rid="fig4" ref-type="fig">Figure 4c</xref>, bottom left), and event frequency (<xref rid="fig4" ref-type="fig">Figure 4c</xref>, bottom right). We find that significant preplay occurs only at moderate cluster overlap (<xref rid="fig4" ref-type="fig">Figure 4d</xref>, top left), where we also find the greatest increase from chance in the linearity of decoded trajectories (<xref rid="fig4" ref-type="fig">Figure 4d</xref>, top right). The fraction of events that are individually significant (determined by comparing the absolute weighted correlation of each decoded event against the set of absolute weighted correlations of its own shuffles) is similarly highest for modest cluster overlap (<xref rid="fig4" ref-type="fig">Figure 4d</xref>, bottom left). The mean entropy of position probability of each time bin of decoded trajectories is also highest for modest cluster overlap (<xref rid="fig4" ref-type="fig">Figure 4d</xref>, bottom right), meaning that high cluster overlap leads to more diffuse, less precise spatial decoding.</p>
</sec>
<sec id="s2e">
<title>Preplay is due to successive activations of individual clusters</title>
<p><xref rid="fig4" ref-type="fig">Figure 4f</xref> indicates that PBEs are best decoded as preplay when cluster participation is only slightly above one, indicating a small, but non-zero, degree of cluster overlap. We hypothesized that this can be explained as balancing two counteracting requirements: 1) Sufficient cluster overlap is necessary for a transient increase in activity in one cluster to induce activity in another cluster, so as to extend any initiated trajectory; and 2) Sufficient cluster isolation is necessary so that, early in a transient, spikes from an excited cluster preferentially add excitement to the same cluster. A network with too much cluster overlap will fail to coherently excite individual clusters—rendering decoded positions to be spread randomly throughout the track—while a network with too little cluster overlap will fail to excite secondary clusters—rendering decoded positions to remain relatively localized.</p>
<p>We find that the dependence of preplay on cluster overlap can indeed be explained by the manner in which clusters participate in PBEs (<xref rid="fig5" ref-type="fig">Figure 5</xref>). An example PBE (<xref rid="fig5" ref-type="fig">Figure 5a</xref>) shows transient recruitment of distinct clusters, with only one cluster prominently active at a time. We define a cluster as ‘active’ if its firing rate exceeds twice the rate of any other cluster. We calculated the number of active clusters per event (<xref rid="fig5" ref-type="fig">Figure 5b</xref>) and the duration of each active cluster period (<xref rid="fig5" ref-type="fig">Figure 5d</xref>). We find that these statistics vary systematically with the network parameters (<xref rid="fig5" ref-type="fig">Figure 5c, e</xref>), in a manner consistent with the dependence of preplay on cluster overlap (<xref rid="fig4" ref-type="fig">Figure 4f</xref>). When there is modest overlap of an intermediate number of clusters, events involve sequential activation of multiple clusters that are each active sufficiently long to correspond to at least one of the time bins used for decoding (10 ms). <xref rid="fig4" ref-type="fig">Figures 4</xref> and <xref rid="fig5" ref-type="fig">5</xref> together indicate that high-quality preplay arises via a succession of individually active clusters. Such succession requires a moderate degree of cluster overlap, but this must be combined with sufficient cluster isolation to promote independent activation of just one cell assembly for the duration of each time-bin used for decoding.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Coherent spiking within clusters supports preplay</title>
<p><bold>(a)</bold> Example event. Top, spike rates averaged across neurons of individual clusters: Each firing rate curve is the smoothed mean firing rate across the population of cells belonging to each cluster. We defined clusters as “active” if at any point their rates exceed twice that of any other cluster. Three clusters meet the criterion of being active (green, then red, then blue). Bottom, raster plots: Cells belonging to each of the active clusters are plotted separately in the respective colors. Cells in multiple clusters contribute to multiple population curves, and cells in multiple active clusters appear in multiple rows of the raster plot. Cells that participate but are not in any active clusters are labeled “Other cells” and plotted in black. Only active cells are plotted. <bold>(b)</bold> For the fiducial parameter set (15 clusters, mean cluster participation of 1.25), the distribution over events of the number of active clusters per event. <bold>(c)</bold> The mean number of active clusters per event as a function of the network parameters. Same data as that used for the parameter grids in earlier figures. <bold>(d)</bold> For the fiducial parameter set (15 clusters, mean cluster participation of 1.25), the distribution of durations of active clusters for all active cluster periods across all events. The active duration was defined as the duration for which an active cluster remained the most-active cluster. <bold>(e)</bold> The mean active cluster duration as a function of the network parameters.</p></caption>
<graphic xlink:href="564173v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2f">
<title>Small-world index correlates with preplay</title>
<p>We noticed that that the highest quality of decoded trajectories (<xref rid="fig4" ref-type="fig">Figure 4f</xref>) seemed to arise in networks with the highest small-world index (SWI; <xref rid="fig1" ref-type="fig">Figure 1g</xref>). In order to test this, we simulated different sets of networks with both increased and decreased global E-to-E connection probability, <italic>p</italic><sub><italic>c</italic></sub>. Changing <italic>p</italic><sub><italic>c</italic></sub>, in addition to varying the number of clusters and the mean cluster participation, impacted the SWI of the networks (<xref rid="fig6" ref-type="fig">Figure 6</xref>, left column).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>The Small-World Index of networks correlates with preplay quality</title>
<p><bold>(a-c)</bold> Left column, the Small-World Index (SWI; plotted as color) is affected by the global E-to-E connection probability, <italic>p</italic><sub><italic>c</italic></sub>. Red dotted line indicates a contour line of SWI = 0.4. This boundary shifts downward as <italic>p</italic><sub><italic>c</italic></sub> increases. Center column, across parameter points in the network parameter grid, SWI correlates with an increase in the median absolute weighted correlation of decoded trajectories relative to shuffles (e.g. this corresponds in <xref rid="fig4" ref-type="fig">Figure 4c</xref> to the rightward shift of the CDF of measured absolute weighted correlations relative to the shuffle events). Each point is produced by analysis of all events across 10 networks from one parameter point in the grid on the left. Right column, same as the center column but each point is data from each of the 10 individual networks per parameter set. P-value and correlation, <italic>ρ</italic>, are calculated from Spearman’s rank-order correlation test. Dashed line is the least-squares fit. <bold>(a)</bold> Data from a parameter grid where the E-to-E connection probability was decreased by 50% and the E-to-E connection strength was doubled from their fiducial values used in prior figures. <bold>(b)</bold> Data from the same parameter grid as Figures 3-5. <bold>(c)</bold> Data from a parameter grid where the E-to-E connection probability was increased by 50% and the E-to-E connection strength scaled by two-thirds from their fiducial values.</p></caption>
<graphic xlink:href="564173v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We hypothesized that independent of <italic>p</italic><sub><italic>c</italic></sub>, a higher SWI would correlate with improved preplay quality. To test this, we simulated networks across a range of parameters for three <italic>p</italic><sub><italic>c</italic></sub> values: a decrease of <italic>p</italic><sub><italic>c</italic></sub> by 50% to 0.04, the fiducial value of 0.08, and an increase by 50% to 0.12 (<xref rid="fig6" ref-type="fig">Figure 6a-c</xref>, respectively). For the decreased and increased <italic>p</italic><sub><italic>c</italic></sub> cases, the E-to-E connection strength was respectively doubled or reduced to 2/3 of the fiducial strength to keep total E-to-E input constant. For each parameter combination, we quantified preplay quality as the rightward shift in median absolute weighted correlation of decoded preplay events versus shuffled events (as in <xref rid="fig4" ref-type="fig">Figure 4f</xref>, top right). We then asked if there was a correlation between that quantification of preplay quality and SWI.</p>
<p>Across all three <italic>p</italic><sub><italic>c</italic></sub> values, SWI significantly correlated with improved preplay both across parameter sets (<xref rid="fig6" ref-type="fig">Figure 6</xref>, center column) and across individual networks (<xref rid="fig6" ref-type="fig">Figure 6</xref>, right column). These results support our prediction that higher small-world characteristics correspond to higher-quality preplay dynamics regardless of average connectivity.</p>
</sec>
<sec id="s2g">
<title>Preplay significantly decodes to linear trajectories in arbitrary environments</title>
<p>Information about each environment enters the network via the feed-forward input connection strengths, which contain cluster-dependent biases. A new environment is simulated by re-ordering those input biases. We first wished to test that a new environment simulated in such a manner produced a distinct set of place fields. We therefore simulated place maps for leftward and rightward trajectories on linear tracks in two distinct environments (<xref rid="fig7" ref-type="fig">Figure 7a</xref>). The two maps with different directions of motion showed very high correlations when in the same environment (<xref rid="fig7" ref-type="fig">Figure 7b</xref>, blue) while the comparisons of trajectories across environments show very low correlations (<xref rid="fig7" ref-type="fig">Figure 7b</xref>, red). We also performed simulations with extra laps of running and calculated the correlations between paired sets of place fields produced by random, independent splits of trials of the same trajectory. The distribution of these correlations was similar to the distribution of within-environment correlations (comparing opposite trajectories with the same spatial input), showing no significant <italic>de novo</italic> place-field directionality. This is consistent with hippocampal data in which place-field directionality is initially low in novel environments and increases with experience (<xref ref-type="bibr" rid="c16">Frank et al., 2004</xref>; <xref ref-type="bibr" rid="c40">Navratilova et al., 2012</xref>; <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>).</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7:</label>
<caption><title>Trajectories decoded from population-burst events are significantly correlated with linear trajectories in arbitrary environments</title>
<p><bold>(a)</bold> Place fields from a single network with simulated runs in both directions of travel on a linear track in two different environments. Each column of panels is the set of place fields for the trajectory labeled on the diagonal. Each row of panels has cells sorted by the order of place-field peaks for the trajectory labeled on the diagonal. The r values are the correlations between the corresponding remapped trajectory with its comparison on the diagonal. Note that correlations mirrored across the diagonal are equal because they correspond only to a change in the labels of the dimensions of the population rate vectors, which does not affect the vector correlation. <bold>(b)</bold> Distribution of the place-field map correlations across trajectories from both directions of travel on a linear track in two environments for 10 networks. Blue is the distribution of correlations for all left vs right place-field maps from the same environment. Red is the correlations from all pair-wise comparisons of trajectories from different environments. <bold>(c)</bold> An example event that shows a significant trajectory when it is decoded with place fields from one environment (top row), but not when it is decoded with place fields from another environment (bottom row). <bold>(d)</bold> An entire set of PBEs shows similar levels of absolute weighted correlations when decoded with different sets of place fields. In color are CDFs of absolute weighted correlations of decoded trajectories with leftward and rightward linear trajectories in each of the two environments (R1 and L1 are the rightward and leftward trajectories of environment one. R2 and L2 are the rightward and leftward trajectories of environment two). In black (all overlapping) are the corresponding absolute weighted correlations with each of the 4 trajectories arising from decoding of shuffled events. <bold>(e)</bold> The significance of linearity of decoded trajectories indicated by p-value in color (as in Figure 4b) from decoding the same PBEs with the four different environment place fields. Black squares indicate criteria that were not met by any events (either shuffled or actual). Env. 1 left is the same as that shown in Figure 4d.</p></caption>
<graphic xlink:href="564173v1_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Because we simulated preplay without any location-specific inputs, we expected that the set of spiking events that significantly decode to linear trajectories in one environment (<xref rid="fig4" ref-type="fig">Figure 4</xref>) should decode with a similar fidelity in another environment. Therefore, we decoded each PBE four times, once with the place fields of each trajectory (<xref rid="fig7" ref-type="fig">Figure 7c-e</xref>). As expected from the place map correlations (<xref rid="fig7" ref-type="fig">Figure 7a, b</xref>), an example event shows similar absolute weighted correlation with the place fields of trajectories from the same environment, but not with the place fields of trajectories from different environments (<xref rid="fig7" ref-type="fig">Figure 7c</xref>). The distributions of absolute weighted correlations arising from decoding of PBEs according to each of the four sets of place fields was consistent across environments (<xref rid="fig7" ref-type="fig">Figure 7d</xref>, colored lines) and all were significantly rightward shifted (indicating greater absolute weighted correlation) when compared to those absolute weighted correlations arising from the corresponding shuffled events (<xref rid="fig7" ref-type="fig">Figure 7d</xref>, overlapping black lines). If we consider both absolute weighted correlation and jump-distance thresholds as in <xref rid="fig4" ref-type="fig">Figure 4d</xref>, we find that the matrices of p-values are consistent across environments (<xref rid="fig7" ref-type="fig">Figure 7e</xref>). In summary, without environment-specific or place-field dependent pre-assigned internal wiring, the model produces population-burst events, which, as an ensemble, show significant preplay with respect to any selected environment.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Our work shows that spontaneous population bursts of spikes that can be decoded as spatial trajectories can arise in networks with clustered random connectivity without pre-configured maps representing the environment. In our proposed model, excitatory neurons were randomly clustered with varied overlap and received feed-forward inputs with random strengths that decayed monotonically from the boundaries of a track (<xref rid="fig1" ref-type="fig">Figure 1</xref>). Even though the model neural circuit lacked place-field like input and lacked environment-specific internal wiring, the network exhibited both realistic place fields (<xref rid="fig2" ref-type="fig">Figures 2</xref>,<xref rid="fig3" ref-type="fig">3</xref>) and spontaneous preplay of novel, future environments (<xref rid="fig2" ref-type="fig">Figures 2</xref>,<xref rid="fig4" ref-type="fig">4</xref>).</p>
<p>We validated our modeling results by applying the same analyses to a previously collected experimental data set (<xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>). Indeed, we replicated the general finding of hippocampal preplay found previously in <xref ref-type="bibr" rid="c13">Farooq et al., 2019</xref>, although the p-value matrix for our experimental data (<xref rid="fig4" ref-type="fig">Figure 4b</xref>) is significant across a smaller range of threshold values than found in their prior work. This is likely due to differences in statistical power. The pre-experience sleep sessions of <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref> were not longer than half an hour for each animal, while the pre-experience sleep sessions of <xref ref-type="bibr" rid="c13">Farooq et al., 2019</xref> lasted 2-4 hours. However, finding statistically significant hippocampal preplay in an experiment not designed for studying preplay shows that the general result is robust to a number of methodological choices, including shorter recording sessions, use of a W-track rather than linear track, and variations in candidate event detection criterion.</p>
<p>Although our model is a model of the recurrently connected CA3 region and the data set we analyze (<xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>) comes from CA1 cells, the qualitative comparisons we make here are nevertheless useful. Despite some statistically significant quantitative differences, the general properties of place fields that we consider are qualitatively similar across CA1 and CA3 (<xref ref-type="bibr" rid="c51">Sheintuch et al., 2023</xref>; <xref ref-type="bibr" rid="c21">Harvey et al., 2020</xref>), and CA3 and CA1 generally reactivate in a coordinated manner (O’Neil et al., 2008; <xref ref-type="bibr" rid="c25">Karlsson and Frank, 2009</xref>).</p>
<p>The model parameters that controlled the clustering of the recurrent connections strongly influenced preplay and place-field quality. Moderate overlap of clusters balanced the competing needs for both a) sufficiently isolated clusters to enable cluster-wise activation and b) sufficiently overlapping clusters to enable propagation of activity across clusters (<xref rid="fig5" ref-type="fig">Figure 5</xref>). Such a balance in cluster overlap produces networks with small-world characteristics (<xref ref-type="bibr" rid="c61">Watts and Strogatz, 1998</xref>) as quantified by a small-world index (SWI; <xref ref-type="bibr" rid="c41">Neal, 2015</xref>; <xref ref-type="bibr" rid="c42">Neal, 2017</xref>). Networks with a high SWI, indicating high clustering (if two neurons are connected to the same third neuron, they are more likely than chance to be connected to each other) yet short paths (the mean number of connections needed to traverse from one neuron to any other), showed optimal preplay dynamics (<xref rid="fig6" ref-type="fig">Figure 6</xref>). The same networks could flexibly represent distinct remapped environments (<xref ref-type="bibr" rid="c27">Leutgeb et al., 2004</xref>; <xref ref-type="bibr" rid="c28">Leutgeb et al., 2005</xref>; <xref ref-type="bibr" rid="c1">Alme et al., 2014</xref>) solely through differences in scaling of feed-forward spatially linear input (<xref rid="fig7" ref-type="fig">Figure 7</xref>).</p>
<p>Across many species, small-world properties can be found at both the local neuronal network scale and the gross scale of the network of brain regions. At the neuronal connection scale, small-world properties have been reported in a number of networks, such as the C. elegans connectome (<xref ref-type="bibr" rid="c61">Watts and Strogatz, 1998</xref>; <xref ref-type="bibr" rid="c22">Humphries et al., 2008</xref>), the brainstem reticular formation (<xref ref-type="bibr" rid="c20">Humphries et al., 2006</xref>), mouse visual cortex (<xref rid="c47" ref-type="bibr">Sadovsky et al., 2014</xref>), cultured rat hippocampal neurons (<xref ref-type="bibr" rid="c2">Antonello et al., 2022</xref>), mouse prefrontal cortex (<xref ref-type="bibr" rid="c32">Luongo et al., 2016</xref>), and connectivity within the entorhinal-hippocampal region in rats (<xref ref-type="bibr" rid="c50">She et al., 2016</xref>). At the level of connected brain regions, small-world properties have been reported across the network of brain regions activated by fear memories in mice (Vetere et al., 2016), in the hippocampal-amygdala network in humans (<xref ref-type="bibr" rid="c65">Zhang et al., 2022</xref>), and across the entire human brain (Liao et al., 2010).</p>
<p>Our results suggest that the preexisting hippocampal dynamics supporting preplay may reflect general properties arising from randomly clustered connectivity. The model predicts that preplay quality will depend on the network’s balance of cluster isolation and overlap, as quantified by small-world properties. Synaptic plasticity in the recurrent connections of CA3 may primarily serve to reinforce and stabilize intrinsic dynamics, rather than creating spatial maps <italic>de novo</italic>. The particular neural activity associated with a given experience would then selectively reinforce the relevant intrinsic dynamics, while leaving the rest of the network dynamics unchanged.</p>
<p>Our model provides a general framework for understanding the origin of pre-configured hippocampal dynamics. Hebbian plasticity on independent, previously experienced place maps would produce effectively random clustered connectivity. The spontaneous dynamics of such networks would influence expression of place fields in future, novel environments. Together with intrinsic sequence generation, this could enable preplay and immediate replay generated by the preexisting recurrent connections.</p>
<p>Future modeling work should explore how experience-dependent plasticity may leverage and reinforce the dynamics initially expressed through preexisting clustered recurrent connections to produce higher-quality place fields and decoded trajectories during replay (<xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>; <xref ref-type="bibr" rid="c13">Farooq et al., 2019</xref>). Plasticity may strengthen connectivity along frequently reactivated spatiotemporal patterns. Clarifying interactions between intrinsic dynamics and experience-dependent plasticity will provide key insights into hippocampal neural activity.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<p>To investigate what network properties could support preplay, we simulated recurrently connected networks of spiking neurons and analyzed their dynamics using standard hippocampal place cell analyses.</p>
<sec id="s4a">
<title>Neuron model</title>
<p>We simulate networks of Leaky Integrate-and-Fire (LIF) neurons, which have leak conductance, <italic>g</italic><sub><italic>L</italic></sub>, excitatory synaptic conductance, <italic>g</italic><sub><italic>E</italic></sub>, inhibitory synaptic conductance, <italic>g</italic><sub><italic>I</italic></sub>, spike-rate adaptation (SRA) conductance, <italic>g</italic><sub><italic>SRA</italic></sub>, and external feed-forward input synaptic conductance, <italic>g</italic><sub><italic>ext</italic></sub>. The membrane potential, <italic>V</italic>, follows the dynamics
<disp-formula id="ueqn1">
<graphic xlink:href="564173v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where τ<sub><italic>m</italic></sub> is the membrane time constant, <italic>E</italic><sub><italic>L</italic></sub> is the leak reversal potential, <italic>E</italic><sub><italic>E</italic></sub> is the excitatory synapse reversal potential, <italic>E</italic><sub><italic>I</italic></sub> is the inhibitory synapse reversal potential, <italic>E</italic><sub><italic>SRA</italic></sub> is the SRA reversal potential, and <italic>E</italic><sub><italic>ext</italic></sub> is the external input reversal potential. When the membrane potential reaches the threshold <italic>V</italic><sub><italic>th</italic></sub>, a spike is emitted and the membrane potential is reset to <italic>V</italic><sub><italic>reset</italic></sub>.</p>
<p>The changes in SRA conductance and all synaptic conductances follow
<disp-formula id="ueqn2">
<graphic xlink:href="564173v1_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
to produce exponential decay between spikes for any conductance <italic>i</italic>. A step increase in conductance occurs at the time of each spike by an amount corresponding to the connection strength for synapses or by <italic>δ</italic><sub><italic>SRA</italic></sub> for <italic>g</italic><sub><italic>SRA</italic></sub>.</p>
<table-wrap id="utbl1" orientation="portrait" position="float">
<graphic xlink:href="564173v1_utbl1.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="564173v1_utbl1a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s4b">
<title>Network structure</title>
<p>We simulated networks of <italic>n</italic> = 500 neurons, of which 75% were excitatory. Excitatory neurons were randomly, independently assigned membership to each of <italic>n</italic><sub><italic>c</italic></sub> clusters in the network. First, each neuron was randomly assigned membership to one of the clusters. Then, each cluster was assigned a number—<italic>n</italic><sub><italic>E</italic></sub> (<italic>μ</italic><sub><italic>c</italic></sub> − 1)/<italic>n</italic><sub><italic>c</italic></sub> rounded to the nearest integer—of additional randomly selected neurons such that each cluster had identical numbers of neurons, <italic>n</italic><sub><italic>E,clust</italic>.</sub> = <italic>n</italic><sub><italic>E</italic></sub> (<italic>μ</italic><sub><italic>c</italic></sub>/<italic>n</italic><sub><italic>c</italic></sub>), and mean cluster participation, <italic>μ</italic><sub><italic>c</italic></sub>, reached its goal value.</p>
<p>E-to-E recurrent connections were randomly assigned on a cluster-wise basis, where only neurons that shared membership in a cluster could be connected. The within-cluster connection probability was configured such that the network exhibited a desired global E-to-E connection probability <italic>p</italic><sub><italic>c</italic></sub>. Given the total number of possible connections between excitatory neurons is <italic>C</italic><sub><italic>tot</italic></sub>= <italic>n</italic><sub><italic>E</italic></sub> (<italic>n</italic><sub><italic>E</italic></sub> − 1) and the total number of possible connections between excitatory neurons within all clusters is <italic>C</italic><sub><italic>clust</italic></sub> = <italic>n</italic><sub><italic>E,clust</italic></sub> (<italic>n</italic><sub><italic>E,clust</italic></sub> − 1) <italic>n</italic><sub><italic>c</italic></sub>, we calculated the within-cluster connection probability as <italic>p</italic><sub><italic>c</italic></sub> (<italic>C</italic><sub><italic>tot</italic></sub>/<italic>C</italic><sub><italic>clust</italic></sub>). That is, given the absence of connections between clusters (clusters were coupled by the overlap of cells) the within-cluster connection probability was greater than <italic>p</italic><sub><italic>c</italic></sub> so as to generate the desired total number of connections equal to <italic>p</italic><sub><italic>c</italic></sub><italic>C</italic><sub><italic>tot</italic></sub>.</p>
<p>All E-to-I and I-to-E connections were independent of cluster membership and existed with a probability <inline-formula><inline-graphic xlink:href="564173v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. There were no I-to-I connections. <italic>p</italic><sub><italic>c</italic></sub>, <italic>n</italic><sub><italic>c</italic></sub>, and <italic>μ</italic><sub><italic>c</italic></sub> were varied for some simulations. Except where specified otherwise, all parameters took the fiducial value shown in the table below.</p>
<p>The network visualization in <xref rid="fig1" ref-type="fig">Figure 1c</xref> was plotted based on the first 2 dimensions of a t-distributed stochastic neighbor embedding of the connectivity between excitatory cells using the MATLAB function <italic>tsne</italic>. The feature vector for each excitatory cell was the binary vector indicating the presence of both input and output connections.</p>
<table-wrap id="utbl2" orientation="portrait" position="float">
<graphic xlink:href="564173v1_utbl2.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="564173v1_utbl2a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s4c">
<title>Network inputs</title>
<p>All excitatory neurons in the network received three different feed-forward inputs (<xref rid="fig1" ref-type="fig">Figure 1b</xref>). Two inputs were spatially modulated, with rates that peaked at either end of the track and linearly varied across the track to reach zero at the opposite end. One input was a context cue that was position independent. All excitatory cells received unique Poisson spike trains from each of the three inputs at their position-dependent rates. Inhibitory cells received only the context input.</p>
<p>The connection strength of each feed-forward input to each neuron was determined by an independent and a cluster-specific factor.</p>
<p>First, strengths were randomly drawn from a log-normal distribution e<sup>μ+σ 𝒩</sup>, where 𝒩 is a zero-mean, unit variance Normal distribution, <inline-formula><inline-graphic xlink:href="564173v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and σ <inline-formula><inline-graphic xlink:href="564173v1_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> mean strength <italic>W</italic><sub><italic>in</italic></sub> and standard deviation σ<sub><italic>in</italic></sub> for the location cues, with σ<sub><italic>in</italic></sub> replaced by σ<sub><italic>context</italic></sub> for the context cue. Each environment and the sleep session had unique context cue input weights. For model simplicity, the mean input strength <italic>W</italic><sub><italic>in</italic></sub> for all inputs was kept the same for both E and I cells in both the awake and sleep conditions, but the strength of the resulting context input was then scaled by some factor <italic>f</italic><sub>x</sub> for each of the 4 cases to accommodate for the presence, or lack thereof, of the additional current input from the location cues. These scaling factors were set at a level that generated appropriate levels of population activity. During simulation of linear track traversal, the context cue to excitatory cells was scaled down by <italic>f</italic><sub>E-awake</sub> to compensate for the added excitatory drive of the location cue inputs, and the context cue input to I cells was not changed (<italic>f</italic><sub>I-awake</sub> = 1). During sleep simulation, the context cue input to E cells was not scaled (<italic>f</italic><sub>E-awake</sub> = 1) but the context cue input to I cells was scaled down by <italic>f</italic><sub>I-sleep</sub>.</p>
<p>Second, to incorporate cluster-dependent spatial information, a small (≤ 4%) location cue bias was added to the randomly drawn feed-forward weights based on each neuron’s cluster membership. For each environment, the clusters were randomly shuffled and assigned a normalized rank bias value, such that the first cluster had a bias of -1 (corresponding to a rightward cue preference) and the last cluster had a bias of +1 (leftward cue preference). A neuron’s individual bias was calculated as the mean bias of all clusters it belonged to, multiplied by the scaling factor σ<sub><italic>bias</italic></sub>. The left cue weight for each neuron was then scaled by 1 plus its bias, and the right cue weight was scaled by 1 minus its bias. In this way, the feed-forward input tuning was biased based on the mean rank of a neuron’s cluster affiliations for each environment. The addition of this bias produced correlations in cells’ spatial tunings based on cluster membership, but, importantly, this did not affect any aspect of the sleep simulations of preplay, nor did it lead to high correlations of place-field maps between environments (<xref rid="fig7" ref-type="fig">Figure 7b</xref>).</p>
<table-wrap id="utbl3" orientation="portrait" position="float">
<graphic xlink:href="564173v1_utbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s4d">
<title>Simulation</title>
<p>For a given parameter set, we generated 10 random networks. We simulated each network for one sleep session of 120 s and for five 2-s long traversals of each of the two linear trajectories on each track. For analysis comparing place-field reliability, we simulated 10 traversals of each trajectory.</p>
</sec>
<sec id="s4e">
<title>Place field analysis</title>
<sec id="s4e1">
<title>Place-field rate maps</title>
<p>We followed the methods of <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref> to generate place fields from the spike trains. We calculated for each excitatory cell its trial-averaged occupancy-discounted firing rate in each 2 cm spatial bin of the 1 m long linear track. Note that the occupancy-discounting term is uniform across bins, so it has no impact in our model, because we simulated uniform movement speed. We then smoothed this with a Gaussian kernel with a 4 cm standard deviation. For statistics quantifying place-field properties and for Bayesian decoding, we considered only excitatory cells with place-field peaks exceeding 3 Hz as in <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>.</p>
</sec>
<sec id="s4e2">
<title>Place-field specificity</title>
<p>Place-field specificity was defined as 1 minus the fraction of the spatial bins in which the place field’s rate exceeded 25% of its maximum rate (<xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>).</p>
</sec>
<sec id="s4e3">
<title>Place-field spatial information</title>
<p>The spatial information of each cells’ place field was calculated as
<disp-formula id="ueqn3">
<graphic xlink:href="564173v1_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>p</italic><sub><italic>i</italic></sub> is the probability of being in spatial bin <italic>i, r</italic><sub><italic>i</italic></sub> is the place field’s rate in spatial bin <italic>i</italic>, and <inline-formula><inline-graphic xlink:href="564173v1_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the mean rate of the place field (<xref ref-type="bibr" rid="c51">Sheintuch et al., 2023</xref>). Given the division of the track into 50 spatial bins, spatial information could vary between 0 for equal firing in all bins and <italic>log</italic><sub><italic>2</italic></sub>(50) ≅ 5.6 for firing in only a single bin. Spatial information of 1 is equivalent, for example, to equal firing in exactly one half of the bins and no firing elsewhere.</p>
</sec>
<sec id="s4e4">
<title>Distribution of peaks</title>
<p>We used two measures to quantify the extent to which place-field peaks were uniformly distributed across the track. In our first measure, we calculated the Kullback-Leibler divergence of the distribution of peaks from a uniform distribution, as
<disp-formula id="ueqn4">
<graphic xlink:href="564173v1_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="564173v1_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the fraction of cells with peak firing rates in the <italic>i</italic><sup><italic>th</italic>,</sup> spatial bin and <inline-formula><inline-graphic xlink:href="564173v1_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is 1/50, <italic>i. e</italic>., the fraction expected from a uniform distribution (<xref ref-type="bibr" rid="c51">Sheintuch et al., 2023</xref>). Similarly, the range for spatial information, <italic>D</italic><sub><italic>KL</italic></sub> is bounded between zero for a perfectly uniform distribution of peaks and <italic>log</italic><sub><italic>2</italic></sub>(50) ≅ 5.6 if all peaks were in a single bin. <italic>D</italic><sub><italic>KL</italic></sub> of 1 is equivalent, for example, to all peaks being uniformly spread over one half of the bins in the track.</p>
<p>For our second measure, we calculated the fraction of place cells whose peak firing rate was in the central third of the track. Since inputs providing spatial information only peaked at the boundaries of the track, the central third was ubiquitously the most depleted of high firing rates.</p>
</sec>
<sec id="s4e5">
<title>Place-field map correlations</title>
<p>To compare the similarity of place fields across different trajectories, we calculated the correlation between the place-field rate maps of each pair of trajectories. For each spatial bin, we calculated the Pearson correlation coefficient between the vector of the population place-field rates of the two trajectories. We then averaged the correlation coefficients across all spatial bins to get the correlation between the two trajectories.</p>
</sec>
</sec>
<sec id="s4f">
<title>PBE detection</title>
<p>We detected candidate preplay events in the simulated data by identifying population-burst events (PBEs). During the simulated sleep period, we calculated the mean rate of the population of excitatory cells, which defines the population rate, smoothed with a Gaussian kernel (15 ms standard deviation). We then detected PBEs as periods of time when the population rate exceeded 1 standard deviation above the mean population rate for at least 30 ms. We also required the peak population rate to exceed 0.5 Hz (corresponding to 5-6 spikes per 30ms among excitatory cells) in order for the rate fluctuation to qualify as a PBE. We then combined PBEs into a single event if their start and end times were separated by less than 10 ms.</p>
</sec>
<sec id="s4g">
<title>Sharp-wave ripple detection</title>
<p>Because of the reduced number of recorded cells relative to the simulated data, we detected candidate events in the <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref> data with a method that incorporated the ripple band oscillation power in the local field potential (LFP) in addition to the population spiking activity. We first calculated the smoothed firing rate for each excitatory neuron by convolving its spikes with a Gaussian kernel (100 ms standard deviation) and capping at 1 to prevent bursting dominance. We then computed the z-scored population firing rate from the capped, smoothed single-neuron rates. Additionally, we calculated the z-scored, ripple-filtered envelope of the tetrode-averaged LFP. We then summed these two z-scores and detected peaks that exceeded 6 for at least 10 ms and exceeded the neighboring regions by at least 6 (<italic>MinPeakHeight, MinPeakWidth</italic>, and <italic>MinPeakProminence</italic> of the MATLAB function <italic>findpeaks</italic>, respectively). Candidate events were defined as periods around detected peaks, spanning from when the z-score sum first dipped below 0 for at least 5 ms before the peak to after the peak when it again dipped below 0 for at least 5 ms. We additionally required that the animal be immobile during the event.</p>
</sec>
<sec id="s4h">
<title>Bayesian decoding</title>
<p>We performed Bayesian decoding of candidate preplay events following the methods of <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>. We performed decoding on all candidate events that had at least 5 active cells and exceeded at least 50 ms in duration. Spikes in the event were binned into 10 ms time bins. We decoded using the place fields for each trajectory independently. The description provided below is for the decoding using the place fields of one particular trajectory.</p>
<p>For each time bin of each event, we calculated the location on the track represented by the neural spikes based on the place fields of the active cells using a memoryless Bayesian decoder
<disp-formula id="ueqn5">
<graphic xlink:href="564173v1_ueqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>P</italic>(<italic>x\s</italic>) is the probability of the animal being in spatial bin <italic>x</italic> given the set of spikes <italic>s</italic> that occurred in the time bin, <italic>P</italic>(<italic>s\x</italic>) is the probability of the spikes <italic>s</italic> given the animal is in spatial bin <italic>x</italic> (as given by the place fields), <italic>P</italic>(<italic>x</italic>) is the prior probability of the animal being in spatial bin <italic>x</italic>, and <italic>P</italic>(<italic>s</italic>) is the probability of the spikes <italic>s</italic>.</p>
<p>We assumed a uniform prior probability of position, <italic>P</italic>(<italic>x</italic>). We assumed that the <italic>N</italic> cells firing during the event acted as independent Poisson processes in order to calculate
<disp-formula id="ueqn6">
<graphic xlink:href="564173v1_ueqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where τ is the time bin window duration (10 ms), <italic>r</italic><sub><italic>i</italic></sub>(<italic>x</italic>) is the place-field rate of cell <italic>i</italic> in spatial bin <italic>x</italic> and <italic>s</italic><sub><italic>i</italic></sub> is the number of spikes from cell <italic>i</italic> in the time bin.</p>
<p>This allows us to calculate the posterior probability of position for each time bin as
<disp-formula id="ueqn7">
<graphic xlink:href="564173v1_ueqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>C</italic> is a normalization constant, which accounts for the position-independent term, <italic>P</italic>(<italic>s</italic>).</p>
</sec>
<sec id="s4i">
<title>Bayesian decoding statistical analyses</title>
<p>We analyzed the significance of preplay using the methods of <xref ref-type="bibr" rid="c13">Farooq et al., 2019</xref> (see also <xref ref-type="bibr" rid="c53">Silva et al., 2015</xref>). We computed two measures of the sequence quality of each decoded event: the event’s absolute weighted correlation and its jump distance. The absolute weighted correlation is the absolute weighted Pearson’s correlation of decoded position across the event’s time bins. For each decoded event, we calculate the weighted correlation between space and time with MATLAB’s <italic>fitlm</italic> function using the decoded probability in each space-time bin (10 ms by 2 cm) as the weight for the corresponding location in the correlation. The absolute value of the weighted correlation is used in order to account for both forward and reverse preplay. The jump distance is the maximum of the distance between the positions of peak probability for any two adjacent 10-ms time bins in the event, quantified as fraction of the track length.</p>
<p>For each event, we generated 100 shuffled events by randomly permuting the order of the 10-ms time bins. We then calculated the weighted correlation and jump distance for each shuffled event in the same manner as for the actual events. For each simulated parameter set, we combined all events from the 10 simulated networks.</p>
<p>Following the methods of <xref ref-type="bibr" rid="c13">Farooq et al., 2019</xref>, we calculated the statistical significance of the population of preplay events using two different methods. First, we used the Kolmogorov-Smirnov (KS) test to compare the distributions of absolute weighted correlations obtained from the actual events and the shuffled events (<xref rid="fig4" ref-type="fig">Figure 4a</xref>, c).</p>
<p>Second, we used a bootstrap test to compare the fraction of high-quality events—defined as having both high absolute weighted correlations and low maximum jump distance— relative to shuffles (<xref rid="fig4" ref-type="fig">Figure 4b,d</xref>). To perform the bootstrap test, we created a grid of thresholds for minimum absolute weighted correlation and maximum jump distance, and for each combination of thresholds we calculated the fraction of actual events that exceeded the minimum absolute weighted correlation threshold and did not exceed the maximum jump distance threshold. Then, we generated 100 data sets of shuffled events by randomly permuting the order of the 10-ms time bins for each actual event and calculated the fraction of events meeting the same pairs of thresholds for each shuffled data set. The p-value of the fraction of high-quality events was then calculated as the fraction of shuffled data sets with a higher fraction of high-quality events.</p>
<p>To test the significance of each event’s absolute weighted correlation individually, we calculated the event’s p-value as the fraction of the event’s own shuffles that had a higher absolute weighted correlation than the un-shuffled event (<xref rid="fig4" ref-type="fig">Figure 4f</xref>, bottom left).</p>
<p>The spatial entropy <italic>H</italic> of a decoded event was calculated as the mean over its time bins of the entropy of the decoded position probability in each time bin, using the equation
<disp-formula id="ueqn8">
<graphic xlink:href="564173v1_ueqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
for each time bin, where <italic>p</italic><sub><italic>i</italic></sub> is the decoded position probability for spatial bin <italic>i</italic>.</p>
</sec>
<sec id="s4j">
<title>Small-world index</title>
<p>The small-world index (SWI) was calculated following the method of <xref ref-type="bibr" rid="c41">Neal, 2015</xref> (see also <xref ref-type="bibr" rid="c42">Neal, 2017</xref>). It was defined as
<disp-formula id="ueqn9">
<graphic xlink:href="564173v1_ueqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>L</italic> is the mean path distance and <italic>C</italic> is the clustering coefficient of the network. We calculate <italic>L</italic> as the mean over all ordered pairs of excitatory cells of the shortest directed path length from the first to the second cell. We calculate <italic>C</italic> as the ratio of the number of all triplets of excitatory cells that are connected in either direction over the number of all triplets that could form, following the methods of <xref ref-type="bibr" rid="c14">Fagiolo, 2007</xref> for directed graphs. <italic>L</italic><sub><italic>l</italic></sub> and <italic>C</italic><sub><italic>l</italic></sub> are the expected values for a one-dimensional ring lattice network with the same size and connection probability (in which connections are local such that there are no connections between cells with a greater separation on the ring than that of any pairs without a connection). And <italic>L</italic><sub><italic>r</italic></sub> and <italic>C</italic><sub><italic>r</italic></sub> are the expected values for a random network of the same size and connection probability. A network with a high SWI index is therefore a network with both a high clustering coefficient, similar to a ring lattice network, and small mean path length, similar to a random network.</p>
<p>For directed graphs of size <italic>n</italic>, average degree <italic>k</italic>, and global connection probability <italic>p</italic></p>
<p><italic>C</italic><sub><italic>r</italic></sub> = <italic>p</italic> (<xref ref-type="bibr" rid="c14">Fagiolo, 2007</xref>),</p>
<p><inline-formula><inline-graphic xlink:href="564173v1_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (<xref ref-type="bibr" rid="c17">Fronczak et al., 2004</xref>),</p>
<p><inline-formula><inline-graphic xlink:href="564173v1_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (Neal et al., 2015)</p>
<p><inline-formula><inline-graphic xlink:href="564173v1_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (Neal et al., 2015; <xref ref-type="bibr" rid="c17">Fronczak et al., 2004</xref>)</p>
<p>where <italic>γ</italic> is the Euler-Mascheroni constant.</p>
</sec>
<sec id="s4k">
<title>Experimental data</title>
<p>Electrophysiological data was reanalyzed from the hippocampal CA1 recordings first published in <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>. All place-field data (<xref rid="fig3" ref-type="fig">Figure 3a</xref>) came from the six rats’ first experience on the W-track spatial alternation task. All preplay data (<xref rid="fig4" ref-type="fig">Figure 4a,b</xref>) came from the six rats’ first sleep-box session, which lasted 20-30 minutes and occurred immediately before their first experience on the W-track.</p>
</sec>
<sec id="s4l">
<title>Code</title>
<p>Simulations and analysis were performed in MATLAB with custom code. Code available at <ext-link ext-link-type="uri" xlink:href="https://github.com/primon23/Preplay_paper">https://github.com/primon23/Preplay_paper</ext-link>.</p>
</sec>
</sec>
</body>
<back>
<sec id="s5">
<title>Supplemental figures</title>
<fig id="figS4_1" position="float" fig-type="figure">
<label>Figure 4 —figure supplement 1:</label>
<caption><title>Example preplay events from the <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref> data</title>
<p>Example preplay events. Same as <xref rid="fig2" ref-type="fig">Figure 2f</xref> but for events from the hipopcampal data from <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref>. The height of each plot spans the length of the trajectory used for decoding, divided into 2 cm spatial bins. The width of each plot spans the duration of the detected event, divided into 10 ms time bins. Probability is show in color.</p></caption>
<graphic xlink:href="564173v1_figS4_1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS4_2" position="float" fig-type="figure">
<label>Figure 4 —figure supplement 2:</label>
<caption><title>Significant preplay can typically be identified with as few as 50 cells</title>
<p><bold>(a-c)</bold> Results from performing the same Bayesian decoding on the same simulated population burst events (PBEs) in <xref rid="fig4" ref-type="fig">Figure 4c</xref> but using only random subsets of the excitatory cells for performing the decoding analysis. Each circle is the result of an analysis performed on one random subset of the cells. 25 random subsets were analyzed for each analyzed cell count. The subset sizes are logarithmically spaced. Black lines show the median value. The variability at N=375 is due to the variation in the randomness of the time-bin shuffles. <bold>(a)</bold> Number of events meeting the inclusion criterion for decoding analysis. <bold>b)</bold> P-value of the KS-test comparing actual vs shuffled event absolute weighted correlations. A majority of the random subsets of 50 cells (17 out of 25) produce preplay p-values below 0.05. <bold>(c)</bold> Shift in the median absolute weighted correlation of actual events relative to shuffled events.</p></caption>
<graphic xlink:href="564173v1_figS4_2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS4_3" position="float" fig-type="figure">
<label>Figure 4 —figure supplement 3:</label>
<caption><title>Preplay statistics by trajectory for <xref ref-type="bibr" rid="c52">Shin et al., 2019</xref> data.</title>
<p><bold>(a)</bold> Same as <xref rid="fig4" ref-type="fig">Figure 4a</xref> but separated by results from decoding by each of the 4 trajectories of the W-track individually (trajectory 1, center arm to right arm; trajectory 2, right arm to center arm; trajectory 3, center arm to left arm; trajectory 4, left arm to center arm). KS-test for each trajectory: trajectory 1, p=0.0030; trajectory 2, p=0.0028; trajectory 3, p=0.0027; trajectory 4, p=5.461×10<sup>-5</sup>. ** p&lt;0.01, *** p&lt;0.001. <bold>b)</bold> Same as <xref rid="fig4" ref-type="fig">Figure 4b</xref> but separated by results from decoding by each of the 4 trajectories individually.</p></caption>
<graphic xlink:href="564173v1_figS4_3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Alme</surname> <given-names>CB</given-names></string-name>, <string-name><surname>Miao</surname> <given-names>C</given-names></string-name>, <string-name><surname>Jezek</surname> <given-names>K</given-names></string-name>, <string-name><surname>Treves</surname> <given-names>A</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>EI</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>M-B.</given-names></string-name> <year>2014</year>. <article-title>Place cells in the hippocampus: Eleven maps for eleven rooms</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <volume>111</volume>(<issue>52</issue>):<fpage>18428</fpage>–<lpage>18435</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1421056111</pub-id>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Antonello</surname> <given-names>PC</given-names></string-name>, <string-name><surname>Varley</surname> <given-names>TF</given-names></string-name>, <string-name><surname>Beggs</surname> <given-names>J</given-names></string-name>, <string-name><surname>Porcionatto</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O</given-names></string-name>, <string-name><surname>Faber</surname> <given-names>J.</given-names></string-name> <year>2022</year>. <article-title>Self-organization of in vitro neuronal assemblies drives to complex network topology</article-title>. <source>eLife</source>. <volume>11</volume>:<fpage>e74921</fpage>. doi:<pub-id pub-id-type="doi">10.7554/eLife.74921</pub-id>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Azizi</surname> <given-names>AH</given-names></string-name>, <string-name><surname>Wiskott</surname> <given-names>L</given-names></string-name>, <string-name><surname>Cheng</surname> <given-names>S.</given-names></string-name> <year>2013</year>. <article-title>A computational model for preplay in the hippocampus</article-title>. <source>Front Comput Neurosci</source>. <volume>7</volume>. doi:<pub-id pub-id-type="doi">10.3389/fncom.2013.00161</pub-id>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Battaglia</surname> <given-names>FP</given-names></string-name>, <string-name><surname>Treves</surname> <given-names>A.</given-names></string-name> <year>1998</year>. <article-title>Attractor neural networks storing multiple space representations: A model for hippocampal place fields</article-title>. <source>Phys Rev E</source>. <volume>58</volume>(<issue>6</issue>):<fpage>7738</fpage>–<lpage>7753</lpage>. doi:<pub-id pub-id-type="doi">10.1103/PhysRevE.58.7738</pub-id>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="other"><string-name><surname>Berners-Lee</surname> <given-names>A</given-names></string-name>, <string-name><surname>Feng</surname> <given-names>T</given-names></string-name>, <string-name><surname>Silva</surname> <given-names>D</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>X</given-names></string-name>, <string-name><surname>Ambrose</surname> <given-names>ER</given-names></string-name>, <string-name><surname>Pfeiffer</surname> <given-names>BE</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>DJ</given-names></string-name>. <year>2022</year> <month>Apr</month>. <article-title>Hippocampal replays appear after a single experience and incorporate greater detail with more experience</article-title>. <source>Neuron.:S089662732200246X</source>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2022.03.010</pub-id>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Bourjaily</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>P.</given-names></string-name> <year>2011</year>. <article-title>Excitatory, Inhibitory, and Structural Plasticity Produce Correlated Connectivity in Random Networks Trained to Solve Paired-Stimulus Tasks</article-title>. <source>Front Comput Neurosci</source>. <volume>5</volume>. doi:<pub-id pub-id-type="doi">10.3389/fncom.2011.00037</pub-id>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Bush</surname> <given-names>D</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name>, <string-name><surname>Burgess</surname> <given-names>N.</given-names></string-name> <year>2014</year>. <article-title>What do grid cells contribute to place cell firing?</article-title> <source>Trends in Neurosciences</source>. <volume>37</volume>(<issue>3</issue>):<fpage>136</fpage>–<lpage>145</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tins.2013.12.003</pub-id>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Carr</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Jadhav</surname> <given-names>SP</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>LM</given-names></string-name>. <year>2011</year>. <article-title>Hippocampal replay in the awake state: a potential substrate for memory consolidation and retrieval</article-title>. <source>Nature Neuroscience</source>. <volume>14</volume>(<issue>2</issue>):<fpage>147</fpage>–<lpage>153</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2732</pub-id>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Csicsvari</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hirase</surname> <given-names>H</given-names></string-name>, <string-name><surname>Mamiya</surname> <given-names>A</given-names></string-name>, <string-name><surname>Buzsáki</surname> <given-names>G.</given-names></string-name> <year>2000</year>. <article-title>Ensemble Patterns of Hippocampal CA3-CA1 Neurons during Sharp Wave–Associated Population Events</article-title>. <source>Neuron</source>. <volume>28</volume>(<issue>2</issue>):<fpage>585</fpage>–<lpage>594</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0896-6273(00)00135-5</pub-id>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Debanne</surname> <given-names>D</given-names></string-name>, <string-name><surname>Gähwiler</surname> <given-names>BH</given-names></string-name>, <string-name><surname>Thompson</surname> <given-names>SM</given-names></string-name>. <year>1998</year>. <article-title>Long-term synaptic plasticity between pairs of individual CA3 pyramidal cells in rat hippocampal slice cultures</article-title>. <source>The Journal of Physiology</source>. <volume>507</volume>(<issue>1</issue>):<fpage>237</fpage>–<lpage>247</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1469-7793.1998.237bu.x</pub-id>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Dragoi</surname> <given-names>G</given-names></string-name>, <string-name><surname>Tonegawa</surname> <given-names>S.</given-names></string-name> <year>2011</year>. <article-title>Preplay of future place cell sequences by hippocampal cellular assemblies</article-title>. <source>Nature</source>. <volume>469</volume>(<issue>7330</issue>):<fpage>397</fpage>–<lpage>401</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature09633</pub-id>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Dragoi</surname> <given-names>G</given-names></string-name>, <string-name><surname>Tonegawa</surname> <given-names>S.</given-names></string-name> <year>2013</year>. <article-title>Distinct preplay of multiple novel spatial experiences in the rat</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <volume>110</volume>(<issue>22</issue>):<fpage>9100</fpage>–<lpage>9105</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1306031110</pub-id>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Farooq</surname>, <given-names>Usman</given-names></string-name>, <string-name><given-names>Jeremie</given-names> <surname>Sibille</surname></string-name>, <string-name><given-names>Kefei</given-names> <surname>Liu</surname></string-name>, and <string-name><given-names>George</given-names> <surname>Dragoi</surname></string-name>. <year>2019</year>. <article-title>Strengthened Temporal Coordination within Pre-Existing Sequential Cell Assemblies Supports Trajectory Replay</article-title>. <source>Neuron 103, no</source>. <volume>4</volume>: <fpage>719</fpage>–<lpage>733</lpage>.e7. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2019.05.040</pub-id>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Fagiolo</surname> <given-names>G.</given-names></string-name> <year>2007</year>. <article-title>Clustering in complex directed networks</article-title>. <source>Phys Rev E</source>. <volume>76</volume>(<issue>2</issue>):<fpage>026107</fpage>. doi:<pub-id pub-id-type="doi">10.1103/PhysRevE.76.026107</pub-id>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Foster</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name>. <year>2006</year>. <article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title>. <source>Nature</source>. <volume>440</volume>(<issue>7084</issue>):<fpage>680</fpage>–<lpage>683</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature04587</pub-id>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Frank</surname> <given-names>LM</given-names></string-name>, <string-name><surname>Stanley</surname> <given-names>GB</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>EN</given-names></string-name>. <year>2004</year>. <article-title>Hippocampal Plasticity across Multiple Days of Exposure to Novel Environments</article-title>. <source>J Neurosci</source>. <volume>24</volume>(<issue>35</issue>):<fpage>7681</fpage>–<lpage>7689</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1958-04.2004</pub-id>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Fronczak</surname> <given-names>A</given-names></string-name>, <string-name><surname>Fronczak</surname> <given-names>P</given-names></string-name>, <string-name><surname>Holyst</surname> <given-names>JA</given-names></string-name>. <year>2004</year>. <article-title>Average path length in uncorrelated random networks with hidden variables</article-title>. <source>Phys Rev E</source>. <volume>70</volume>(<issue>5</issue>):<fpage>056110</fpage>. doi:<pub-id pub-id-type="doi">10.1103/PhysRevE.70.056110</pub-id>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Grosmark</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Buzsaki</surname> <given-names>G.</given-names></string-name> <year>2016</year>. <article-title>Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences</article-title>. <source>Science</source>. <volume>351</volume>(<issue>6280</issue>):<fpage>1440</fpage>–<lpage>1443</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.aad1935</pub-id>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Haga</surname> <given-names>T</given-names></string-name>, <string-name><surname>Fukai</surname> <given-names>T.</given-names></string-name> <year>2018</year>. <article-title>Recurrent network model for learning goal-directed sequences through reverse replay</article-title>. <source>eLife</source>. <volume>7</volume>:<fpage>e34171</fpage>. doi:<pub-id pub-id-type="doi">10.7554/eLife.34171</pub-id>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Humphries</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Gurney</surname> <given-names>K</given-names></string-name>, <string-name><surname>Prescott</surname> <given-names>TJ</given-names></string-name>. <year>2006</year>. <article-title>The brainstem reticular formation is a small-world, not scale-free, network</article-title>. <source>Proc R Soc B</source>. <volume>273</volume>(<issue>1585</issue>):<fpage>503</fpage>–<lpage>511</lpage>. doi:<pub-id pub-id-type="doi">10.1098/rspb.2005.3354</pub-id>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Harvey</surname> <given-names>RE</given-names></string-name>, <string-name><surname>Berkowitz</surname> <given-names>LE</given-names></string-name>, <string-name><surname>Savage</surname> <given-names>DD</given-names></string-name>, <string-name><surname>Hamilton</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Clark</surname> <given-names>BJ</given-names></string-name>. <year>2020</year>. <article-title>Altered Hippocampal Place Cell Representation and Theta Rhythmicity following Moderate Prenatal Alcohol Exposure</article-title>. <source>Current Biology</source>. <volume>30</volume>(<issue>18</issue>):<fpage>3556</fpage>–<lpage>3569</lpage>.e5. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2020.06.077</pub-id>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Humphries</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Gurney</surname> <given-names>K.</given-names></string-name> <year>2008</year>. <article-title>Network ‘Small-World-Ness’: A Quantitative Method for Determining Canonical Network Equivalence</article-title>. <person-group person-group-type="editor"><string-name><surname>Sporns</surname> <given-names>O</given-names></string-name></person-group>, editor. <source>PLoS ONE</source>. <volume>3</volume>(<issue>4</issue>):<fpage>e0002051</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0002051</pub-id>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Hwaun</surname> <given-names>E</given-names></string-name>, <string-name><surname>Colgin</surname> <given-names>LL</given-names></string-name>. <year>2019</year>. <article-title>CA3 place cells that represent a novel waking experience are preferentially reactivated during sharp wave-ripples in subsequent sleep</article-title>. <source>Hippocampus</source>. <volume>29</volume>(<issue>10</issue>):<fpage>921</fpage>–<lpage>938</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hipo.23090</pub-id>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Jahnke</surname> <given-names>S</given-names></string-name>, <string-name><surname>Timme</surname> <given-names>M</given-names></string-name>, <string-name><surname>Memmesheimer</surname> <given-names>R-M.</given-names></string-name> <year>2015</year>. <article-title>A Unified Dynamic Model for Learning, Replay, and Sharp-Wave/Ripples</article-title>. <source>Journal of Neuroscience</source>. <volume>35</volume>(<issue>49</issue>):<fpage>16236</fpage>–<lpage>16258</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3977-14.2015</pub-id>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Karlsson</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>LM</given-names></string-name>. <year>2009</year>. <article-title>Awake replay of remote experiences in the hippocampus</article-title>. <source>Nature Neuroscience</source>. <volume>12</volume>(<issue>7</issue>):<fpage>913</fpage>–<lpage>918</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2344</pub-id>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Kinsky</surname> <given-names>NR</given-names></string-name>, <string-name><surname>Sullivan</surname> <given-names>DW</given-names></string-name>, <string-name><surname>Mau</surname> <given-names>W</given-names></string-name>, <string-name><surname>Hasselmo</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Eichenbaum</surname> <given-names>HB</given-names></string-name>. <year>2018</year>. <article-title>Hippocampal Place Fields Maintain a Coherent and Flexible Map across Long Timescales</article-title>. <source>Current Biology</source>. <volume>28</volume>(<issue>22</issue>):<fpage>3578</fpage>–<lpage>3588</lpage>.e6. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2018.09.037</pub-id>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Leutgeb</surname> <given-names>S</given-names></string-name>, <string-name><surname>Leutgeb</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Treves</surname> <given-names>A</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>M-B</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>EI</given-names></string-name>. <year>2004</year>. <article-title>Distinct Ensemble Codes in Hippocampal Areas CA3 and CA1</article-title>. <source>Science</source>. <volume>305</volume>(<issue>5688</issue>):<fpage>1295</fpage>–<lpage>1298</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1100265</pub-id>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Leutgeb</surname> <given-names>S</given-names></string-name>, <string-name><surname>Leutgeb</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Barnes</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>EI</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>M-B.</given-names></string-name> <year>2005</year>. <article-title>Independent Codes for Spatial and Episodic Memory in Hippocampal Neuronal Ensembles</article-title>. <source>Science</source>. <volume>309</volume>(<issue>5734</issue>):<fpage>619</fpage>–<lpage>623</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1114037</pub-id>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Liao</surname> <given-names>W</given-names></string-name>, <string-name><surname>Ding</surname> <given-names>J</given-names></string-name>, <string-name><surname>Marinazzo</surname> <given-names>D</given-names></string-name>, <string-name><surname>Xu</surname> <given-names>Q</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Yuan</surname> <given-names>C</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Lu</surname> <given-names>G</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>H.</given-names></string-name> <year>2011</year>. <article-title>Small-world directed networks in the human brain: Multivariate Granger causality analysis of resting-state fMRI</article-title>. <source>NeuroImage</source>. <volume>54</volume>(<issue>4</issue>):<fpage>2683</fpage>–<lpage>2694</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.11.007</pub-id>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Litwin-Kumar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Doiron</surname> <given-names>B.</given-names></string-name> <year>2014</year>. <article-title>Formation and maintenance of neuronal assemblies through synaptic plasticity</article-title>. <source>Nat Commun</source>. <volume>5</volume>(<issue>1</issue>):<fpage>5319</fpage>. doi:<pub-id pub-id-type="doi">10.1038/ncomms6319</pub-id>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Liu</surname> <given-names>K</given-names></string-name>, <string-name><surname>Sibille</surname> <given-names>J</given-names></string-name>, <string-name><surname>Dragoi</surname> <given-names>G.</given-names></string-name> <year>2019</year>. <article-title>Preconfigured patterns are the primary driver of offline multi-neuronal sequence replay</article-title>. <source>Hippocampus</source>. <volume>29</volume>(<issue>3</issue>):<fpage>275</fpage>–<lpage>283</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hipo.23034</pub-id>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Luongo</surname> <given-names>FJ</given-names></string-name>, <string-name><surname>Zimmerman</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Horn</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Sohal</surname> <given-names>VS</given-names></string-name>. <year>2016</year>. <article-title>Correlations between prefrontal neurons form a small-world network that optimizes the generation of multineuron sequences of activity</article-title>. <source>Journal of Neurophysiology</source>. <volume>115</volume>(<issue>5</issue>):<fpage>2359</fpage>–<lpage>2375</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.01043.2015</pub-id>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="web"><string-name><surname>Lynn</surname> <given-names>CW</given-names></string-name>, <string-name><surname>Holmes</surname> <given-names>CM</given-names></string-name>, <string-name><surname>Palmer</surname> <given-names>SE</given-names></string-name>. <year>2022</year>. <article-title>Heavy–tailed neuronal connectivity arises from Hebbian self–organization</article-title>. <source>Neuroscience. [</source>accessed <date-in-citation content-type="access-date">2022 Oct 27</date-in-citation>]. <ext-link ext-link-type="uri" xlink:href="http://biorxiv.org/lookup/doi/10.1101/2022.05.30.494086">http://biorxiv.org/lookup/doi/10.1101/2022.05.30.494086</ext-link>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Mishra</surname> <given-names>RK</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>S</given-names></string-name>, <string-name><surname>Guzman</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Jonas</surname> <given-names>P.</given-names></string-name> <year>2016</year>. <article-title>Symmetric spike timing-dependent plasticity at CA3–CA3 synapses optimizes storage and recall in autoassociative networks</article-title>. <source>Nat Commun</source>. <volume>7</volume>(<issue>1</issue>):<fpage>11552</fpage>. doi:<pub-id pub-id-type="doi">10.1038/ncomms11552</pub-id>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Morris</surname> <given-names>RGM</given-names></string-name>, <string-name><surname>Garrud</surname> <given-names>P</given-names></string-name>, <string-name><surname>Rawlins</surname> <given-names>JNP</given-names></string-name>, <string-name><surname>O’Keefe</surname> <given-names>J.</given-names></string-name> <year>1982</year>. <article-title>Place navigation impaired in rats with hippocampal lesions</article-title>. <source>Nature</source>. <volume>297</volume>(<issue>5868</issue>):<fpage>681</fpage>–<lpage>683</lpage>. doi:<pub-id pub-id-type="doi">10.1038/297681a0</pub-id>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Moser</surname> <given-names>EI</given-names></string-name>, <string-name><surname>Kropff</surname> <given-names>E</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>M-B.</given-names></string-name> <year>2008</year>. <article-title>Place Cells, Grid Cells, and the Brain’s Spatial Representation System</article-title>. <source>Annu Rev Neurosci</source>. <volume>31</volume>(<issue>1</issue>):<fpage>69</fpage>–<lpage>89</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev.neuro.31.061307.090723</pub-id>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Muller</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kubie</surname> <given-names>J</given-names></string-name>, <string-name><surname>Ranck</surname> <given-names>J.</given-names></string-name> <year>1987</year>. <article-title>Spatial firing patterns of hippocampal complex-spike cells in a fixed environment</article-title>. <source>J Neurosci</source>. <volume>7</volume>(<issue>7</issue>):<fpage>1935</fpage>–<lpage>1950</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.07-07-01935.1987</pub-id>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Nakashiba</surname> <given-names>T</given-names></string-name>, <string-name><surname>Young</surname> <given-names>JZ</given-names></string-name>, <string-name><surname>McHugh</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Buhl</surname> <given-names>DL</given-names></string-name>, <string-name><surname>Tonegawa</surname> <given-names>S.</given-names></string-name> <year>2008</year>. <article-title>Transgenic Inhibition of Synaptic Transmission Reveals Role of CA3 Output in Hippocampal Learning</article-title>. <source>Science</source>. <volume>319</volume>(<issue>5867</issue>):<fpage>1260</fpage>–<lpage>1264</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1151120</pub-id>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Nakashiba</surname> <given-names>T</given-names></string-name>, <string-name><surname>Buhl</surname> <given-names>DL</given-names></string-name>, <string-name><surname>McHugh</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Tonegawa</surname> <given-names>S.</given-names></string-name> <year>2009</year>. <article-title>Hippocampal CA3 Output Is Crucial for Ripple-Associated Reactivation and Consolidation of Memory</article-title>. <source>Neuron</source>. <volume>62</volume>(<issue>6</issue>):<fpage>781</fpage>–<lpage>787</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2009.05.013</pub-id>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Navratilova</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Hoang</surname> <given-names>LT</given-names></string-name>, <string-name><surname>Schwindel</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Tatsuno</surname> <given-names>M</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>. <year>2012</year>. <article-title>Experience-dependent firing rate remapping generates directional selectivity in hippocampal place cells</article-title>. <source>Front Neural Circuits</source>. <volume>6</volume>. doi:<pub-id pub-id-type="doi">10.3389/fncir.2012.00006</pub-id>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Neal</surname> <given-names>Z.</given-names></string-name> <year>2015</year>. <article-title>Making Big Communities Small: Using Network Science to Understand the Ecological and Behavioral Requirements for Community Social Capital</article-title>. <source>American Journal of Community Psychology</source>. <volume>55</volume>(<issue>3–4</issue>):<fpage>369</fpage>–<lpage>380</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s10464-015-9720-4</pub-id>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Neal</surname> <given-names>ZP</given-names></string-name>. <year>2017</year>. <article-title>How small is it? Comparing indices of small worldliness</article-title>. <source>Net Sci</source>. <volume>5</volume>(<issue>1</issue>):<fpage>30</fpage>–<lpage>44</lpage>. doi:<pub-id pub-id-type="doi">10.1017/nws.2017.5</pub-id>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Nitzan</surname> <given-names>N</given-names></string-name>, <string-name><surname>Swanson</surname> <given-names>R</given-names></string-name>, <string-name><surname>Schmitz</surname> <given-names>D</given-names></string-name>, <string-name><surname>Buzsáki</surname> <given-names>G.</given-names></string-name> <year>2022</year>. <article-title>Brain-wide interactions during hippocampal sharp wave ripples</article-title>. <source>Proc Natl Acad Sci USA</source>. <volume>119</volume>(<issue>20</issue>):<fpage>e2200931119</fpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.2200931119</pub-id>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="book"><string-name><surname>O’Keefe</surname> <given-names>J</given-names></string-name>, <string-name><surname>Nadel</surname> <given-names>L.</given-names></string-name> <year>1978</year>. <source>The hippocampus as a cognitive map</source>. Oxford : <publisher-loc>New York</publisher-loc>: <publisher-name>Clarendon Press ; Oxford University Press</publisher-name>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>O’Neill</surname> <given-names>J</given-names></string-name>, <string-name><surname>Senior</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Allen</surname> <given-names>K</given-names></string-name>, <string-name><surname>Huxter</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Csicsvari</surname> <given-names>J.</given-names></string-name> <year>2008</year>. <article-title>Reactivation of experience-dependent cell assembly patterns in the hippocampus</article-title>. <source>Nature Neuroscience</source>. <volume>11</volume>(<issue>2</issue>):<fpage>209</fpage>–<lpage>215</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn2037</pub-id>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Pang</surname> <given-names>R</given-names></string-name>, <string-name><surname>Fairhall</surname> <given-names>AL</given-names></string-name>. <year>2019</year>. <article-title>Fast and flexible sequence induction in spiking neural networks via rapid excitability changes</article-title>. <source>eLife</source>. <volume>8</volume>:<fpage>e44324</fpage>. doi:<pub-id pub-id-type="doi">10.7554/eLife.44324</pub-id>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Sadovsky</surname> <given-names>A</given-names></string-name>, <string-name><surname>MacLean</surname> <given-names>J.</given-names></string-name> <year>2014</year>. <article-title>Mouse Visual Neocortex Supports Multiple Stereotyped Patterns of Microcircuit Activity</article-title>. <source>Journal of Neuroscience</source>. <volume>34</volume>(<issue>23</issue>):<fpage>7769</fpage>–<lpage>7777</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0169-14.2014</pub-id>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Samsonovich</surname> <given-names>A</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>. <year>1997</year>. <article-title>Path Integration and Cognitive Mapping in a Continuous Attractor Neural Network Model</article-title>. <source>J Neurosci</source>. <volume>17</volume>(<issue>15</issue>):<fpage>5900</fpage>–<lpage>5920</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-15-05900.1997</pub-id>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Savelli</surname> <given-names>F</given-names></string-name>, <string-name><surname>Yoganarasimha</surname> <given-names>D</given-names></string-name>, <string-name><surname>Knierim</surname> <given-names>JJ</given-names></string-name>. <year>2008</year>. <article-title>Influence of boundary removal on the spatial representations of the medial entorhinal cortex</article-title>. <source>Hippocampus</source>. <volume>18</volume>(<issue>12</issue>):<fpage>1270</fpage>–<lpage>1282</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hipo.20511</pub-id>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>She</surname> <given-names>Q</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>G</given-names></string-name>, <string-name><surname>Chan</surname> <given-names>RHM</given-names></string-name>. <year>2016</year>. <article-title>Evaluating the Small-World-Ness of a Sampled Network: Functional Connectivity of Entorhinal-Hippocampal Circuitry</article-title>. <source>Sci Rep</source>. <volume>6</volume>(<issue>1</issue>):<fpage>21468</fpage>. doi:<pub-id pub-id-type="doi">10.1038/srep21468</pub-id>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Sheintuch</surname> <given-names>L</given-names></string-name>, <string-name><surname>Geva</surname> <given-names>N</given-names></string-name>, <string-name><surname>Deitch</surname> <given-names>D</given-names></string-name>, <string-name><surname>Rubin</surname> <given-names>A</given-names></string-name>, <string-name><surname>Ziv</surname> <given-names>Y.</given-names></string-name> <year>2023</year>. <article-title>Organization of hippocampal CA3 into correlated cell assemblies supports a stable spatial code</article-title>. <source>Cell Reports</source>. <volume>42</volume>(<issue>2</issue>):<fpage>112119</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.celrep.2023.112119</pub-id>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Shin</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Tang</surname> <given-names>W</given-names></string-name>, <string-name><surname>Jadhav</surname> <given-names>SP</given-names></string-name>. <year>2019</year>. <article-title>Dynamics of Awake Hippocampal-Prefrontal Replay for Spatial Learning and Memory-Guided Decision Making</article-title>. <source>Neuron</source>. <volume>104</volume>(<issue>6</issue>):<fpage>1110</fpage>–<lpage>1125</lpage>.e7. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.012</pub-id>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Silva</surname> <given-names>D</given-names></string-name>, <string-name><surname>Feng</surname> <given-names>T</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>DJ</given-names></string-name>. <year>2015</year>. <article-title>Trajectory events across hippocampal place cells require previous experience</article-title>. <source>Nat Neurosci</source>. <volume>18</volume>(<issue>12</issue>):<fpage>1772</fpage>–<lpage>1779</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.4151</pub-id>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Solstad</surname> <given-names>T</given-names></string-name>, <string-name><surname>Boccara</surname> <given-names>CN</given-names></string-name>, <string-name><surname>Kropff</surname> <given-names>E</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>M-B</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>EI</given-names></string-name>. <year>2008</year>. <article-title>Representation of Geometric Borders in the Entorhinal Cortex</article-title>. <source>Science</source>. <volume>322</volume>(<issue>5909</issue>):<fpage>1865</fpage>–<lpage>1868</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1166466</pub-id>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Song</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sjöström</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Reigl</surname> <given-names>M</given-names></string-name>, <string-name><surname>Nelson</surname> <given-names>S</given-names></string-name>, <string-name><surname>Chklovskii</surname> <given-names>DB</given-names></string-name>. <year>2005</year>. <article-title>Highly Nonrandom Features of Synaptic Connectivity in Local Cortical Circuits</article-title>. <person-group person-group-type="editor"><string-name><surname>Friston</surname> <given-names>KJ</given-names></string-name></person-group>, editor. <source>PLoS Biology</source>. <volume>3</volume>(<issue>3</issue>):<fpage>e68</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.0030068</pub-id>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Squire</surname> <given-names>LR</given-names></string-name>, <string-name><surname>Stark</surname> <given-names>CEL</given-names></string-name>, <string-name><surname>Clark</surname> <given-names>RE</given-names></string-name>. <year>2004</year>. <article-title>The medial temporal lobe</article-title>. <source>Annual Review of Neuroscience</source>. <volume>27</volume>(<issue>1</issue>):<fpage>279</fpage>–<lpage>306</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev.neuro.27.070203.144130</pub-id>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Tang</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Jadhav</surname>, <given-names>S. P.</given-names></string-name> (<year>2022</year>). <article-title>Multiple-Timescale Representations of Space: Linking Memory to Navigation</article-title>. <source>Annual Review of Neuroscience</source>, <volume>45</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>21</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-neuro-111020-084824</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Theodoni</surname> <given-names>P</given-names></string-name>, <string-name><surname>Rovira</surname> <given-names>B</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Roxin</surname> <given-names>A.</given-names></string-name> <year>2018</year>. <article-title>Theta-modulation drives the emergence of connectivity patterns underlying replay in a network model of place cells</article-title>. <source>eLife</source>. <volume>7</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.37388</pub-id>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Vaz</surname> <given-names>AP</given-names></string-name>, <string-name><surname>Wittig</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Inati</surname> <given-names>SK</given-names></string-name>, <string-name><surname>Zaghloul</surname> <given-names>KA</given-names></string-name>. <year>2023</year>. <article-title>Backbone spiking sequence as a basis for preplay, replay, and default states in human cortex</article-title>. <source>Nat Commun</source>. <volume>14</volume>(<issue>1</issue>):<fpage>4723</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-023-40440-5</pub-id>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Vetere</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kenney</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Tran</surname> <given-names>LM</given-names></string-name>, <string-name><surname>Xia</surname> <given-names>F</given-names></string-name>, <string-name><surname>Steadman</surname> <given-names>PE</given-names></string-name>, <string-name><surname>Parkinson</surname> <given-names>J</given-names></string-name>, <string-name><surname>Josselyn</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Frankland</surname> <given-names>PW</given-names></string-name>. <year>2017</year>. <article-title>Chemogenetic Interrogation of a Brain-wide Fear Memory Network in Mice</article-title>. <source>Neuron</source>. <volume>94</volume>(<issue>2</issue>):<fpage>363</fpage>–<lpage>374</lpage>.e4. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.037</pub-id>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Watts</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Strogatz</surname> <given-names>SH</given-names></string-name>. <year>1998</year>. <article-title>Collective dynamics of ‘small-world’ networks</article-title>. <source>Nature</source>. <volume>393</volume>(<issue>6684</issue>):<fpage>440</fpage>–<lpage>442</lpage>. doi:<pub-id pub-id-type="doi">10.1038/30918</pub-id>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>Whittington</surname> <given-names>JCR</given-names></string-name>, <string-name><surname>Muller</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Mark</surname> <given-names>S</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>G</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name>, <string-name><surname>Burgess</surname> <given-names>N</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>. <year>2020</year>. <article-title>The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation</article-title>. <source>Cell</source>. <volume>183</volume>(<issue>5</issue>):<fpage>1249</fpage>–<lpage>1263</lpage>.e23. doi:<pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>. <year>1994</year>. <article-title>Reactivation of Hippocampal Ensemble Memories During Sleep</article-title>. <source>Science</source>. <volume>265</volume>(<issue>5172</issue>):<fpage>676</fpage>–<lpage>679</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.8036517</pub-id>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Yamamoto</surname> <given-names>J</given-names></string-name>, <string-name><surname>Tonegawa</surname> <given-names>S.</given-names></string-name> <year>2017</year>. <article-title>Direct Medial Entorhinal Cortex Input to Hippocampal CA1 Is Crucial for Extended Quiet Awake Replay</article-title>. <source>Neuron</source>. <volume>96</volume>(<issue>1</issue>):<fpage>217</fpage>–<lpage>227</lpage>.e4. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.017</pub-id>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname> <given-names>L</given-names></string-name>, <string-name><surname>Hu</surname> <given-names>X</given-names></string-name>, <string-name><surname>Hu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Tang</surname> <given-names>M</given-names></string-name>, <string-name><surname>Qiu</surname> <given-names>H</given-names></string-name>, <string-name><surname>Zhu</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Gao</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Li</surname> <given-names>H</given-names></string-name>, <string-name><surname>Kuang</surname> <given-names>W</given-names></string-name>, <string-name><surname>Ji</surname> <given-names>W.</given-names></string-name> <year>2022</year>. <article-title>Structural covariance network of the hippocampus–amygdala complex in medication-naïve patients with first-episode major depressive disorder</article-title>. <source>Psychoradiology</source>. <volume>2</volume>(<issue>4</issue>):<fpage>190</fpage>–<lpage>198</lpage>. doi:<pub-id pub-id-type="doi">10.1093/psyrad/kkac023</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93981.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Peyrache</surname>
<given-names>Adrien</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>McGill University</institution>
</institution-wrap>
<city>Montreal</city>
<country>Canada</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents a <bold>valuable</bold> finding on the spontaneous emergence of structured activity in artificial neural networks endowed with specific connectivity profiles. The evidence supporting the claims of the authors is potentially <bold>solid</bold> but still <bold>incomplete</bold> at this stage, as the authors would ideally demonstrate that similar properties are observed with more diverse inputs and in more complex environments. The work will be of interest to systems and computational neuroscientists.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93981.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this manuscript, the authors investigated the dynamics of a neural network model characterized by sparsely connected clusters of neuronal ensembles. They found that such a network could intrinsically generate sequence preplay and place maps, with properties like those observed in the real-world data. Strengths of the study include the computational model and data analysis supporting the hippocampal network mechanisms underlying sequence preplay of future experiences and place maps.</p>
<p>Previous models of replay or theta sequences focused on circuit plasticity and usually required a pre-existing place map input from the external environment via upstream structures. However, those models failed to explain how networks support rapid sequential coding of novel environments or simply transferred the question to the upstream structure. On the contrary, the current proposed model required minimal spatial inputs and was aimed at elucidating how a preconfigured structure gave rise to preplay, thereby facilitating the sequential encoding of future novel environments.</p>
<p>In this model, the fundamental units for spatial representation were clusters within the network. Sequential representation was achieved through the balance of cluster isolation and their partial overlap. Isolation resulted in a self-reinforced assembly representation, ensuring stable spatial coding. On the other hand, overlap-induced activation transitions across clusters, enabling sequential coding.</p>
<p>This study is important when considering that previous models mainly focused on plasticity and experience-related learning, while this model provided us with insights into how network architecture could support rapid sequential coding with large capacity, upon which learning could occur efficiently with modest modification via plasticity.</p>
<p>I found this research very inspiring and, below, I provide some comments aimed at improving the manuscript. Some of these comments may extend beyond the scope of the current study, but I believe they raise important questions that should be addressed in this line of research.</p>
<p>(1) The expression 'randomly clustered networks' needs to be explained in more detail given that in its current form risks to indicate that the network might be randomly organized (i.e., not organized). In particular, a clustered network with future functionality based on its current clustering is not random but rather pre-configured into those clusters. What the authors likely meant to say, while using the said expression in the title and text, is that clustering is not induced by an experience in the environment, which will only be later mapped using those clusters. While this organization might indeed appear as randomly clustered when referenced to a future novel experience, it might be non-random when referenced to the prior (unaccounted) activity of the network. Related to this, network organization based on similar yet distinct experiences (e.g., on parallel linear tracks as in Liu, Sibille, Dragoi, Neuron 2021) could explain/configure, in part, the hippocampal CA1 network organization that would appear otherwise 'randomly clustered' when referenced to a future novel experience.</p>
<p>(2) The authors should elaborate more on how the said 'randomly clustered networks' generate beyond chance-level preplay. Specifically, why was there preplay stronger than the time-bin shuffle? There are at least two potential explanations:</p>
<p>(1) - When the activation of clusters lasts for several decoding time bins, temporal shuffle breaks the continuity of one cluster's activation, thus leading to less sequential decoding results. In that case, the preplay might mainly outperform the shuffle when there are fewer clusters activating in a PBE. For example, activation of two clusters must be sequential (either A to B or B to A), while time bin shuffle could lead to non-sequential activations such as a-b-a-b-a-b where a and b are components of A and B;</p>
<p>(2) - There is a preferred connection between clusters based on the size of overlap across clusters. For example, if pair A-B and B-C have stronger overlap than A-C, then cluster sequences A-B-C and C-B-A are more likely to occur than others (such as A-C-B) across brain states. In that case, authors should present the distribution of overlap across clusters, and whether the sequences during run and sleep match the magnitude of overlap. During run simulation in the model, as clusters randomly receive a weak location cue bias, the activation sequence might not exactly match the overlap of clusters due to the external drive. In that case, the strength of location cue bias (4% in the current setup) could change the balance between the internal drive and external drive of the representation. How does that parameter influence the preplay incidence or quality?</p>
<p>(3). The manuscript is focused on presenting that a randomly clustered network can generate preplay and place maps with properties similar to experimental observations. An equally interesting question is how preplay supports spatial coding. If preplay is an intrinsic dynamic feature of this network, then it would be good to study whether this network outperforms other networks (randomly connected or ring lattice) in terms of spatial coding (encoding speed, encoding capacity, tuning stability, tuning quality, etc.)</p>
<p>(4) The manuscript mentions the small-world connectivity several times, but the concept still appears too abstract and how the small-world index (SWI) contributes to place fields or preplay is not sufficiently discussed.</p>
<p>For a more general audience in the field of neuroscience, it would be helpful to include example graphs with high and low SWI. For example, you can show a ring lattice graph and indicate that there are long paths between points at opposite sides of the ring; show randomly connected graphs indicating there are no local clustered structures, and show clustered graphs with several hubs establishing long-range connections to reduce pair-wise distance.</p>
<p>How this SWI contributes to preplay is also not clear. Figure 6 showed preplay is correlated with SWI, but maybe the correlation is caused by both of them being correlated with cluster participation. The balance between cluster overlap and cluster isolation is well discussed. In the Discussion, the authors mention &quot;...Such a balance in cluster overlap produces networks with small-world characteristics (Watts and Strogatz, 1998) as quantified by a small-world index...&quot; (Lines 560-561). I believe the statement is not entirely appropriate, a network similar to ring lattice can still have the balance of cluster isolation and cluster overlap, while it will have small SWI due to a long path across some node pairs. Both cluster structure and long-range connection could contribute to SWI. The authors only discuss the necessity of cluster structure, but why is the long-range connection important should also be discussed. I guess long-range connection could make the network more flexible (clusters are closer to each other) and thus increase the potential repertoire.</p>
<p>(5) What drives PBE during sleep? Seems like the main difference between sleep and run states is the magnitude of excitatory and inhibitory inputs controlled by scaling factors. If there are bursts (PBE) in sleep, do you also observe those during run? Does the network automatically generate PBE in a regime of strong excitation and weak inhibition (neural bifurcation)?</p>
<p>(6) Is the concept of 'cluster' similar to 'assemblies', as in Peyrache et al, 2010; Farooq et al, 2019? Does a classic assembly analysis during run reveal cluster structures?</p>
<p>(7) Can the capacity of the clustered network to express preplay for multiple distinct future experiences be estimated in relation to current network activity, as in Dragoi and Tonegawa, PNAS 2013?</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93981.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors show that a spiking network model with clustered neurons produces intrinsic spike sequences when driven with a ramping input, which are recapitulated in the absence of input. This behavior is only seen for some network parameters (neuron cluster participation and number of clusters in the network), which correspond to those that produce a small world network. By changing the strength of ramping input to each network cluster, the network can show different sequences.</p>
<p>Strengths:</p>
<p>A strength of the paper is the direct comparison between the properties of the model and neural data.</p>
<p>Weaknesses:</p>
<p>My main critiques of the paper relate to the form of the input to the network.</p>
<p>First, because the input is the same across trials (i.e. all traversals are the same duration/velocity), there is no ability to distinguish a representation of space from a representation of time elapsed since the beginning of the trial. The authors should test what happens e.g. with traversals in which the animal travels at different speeds, and in which the animal's speed is not constant across the entire track, and then confirm that the resulting tuning curves are a better representation of position or duration.</p>
<p>Second, it's unclear how much the results depend on the choice of a one-dimensional environment with ramping input. While this is an elegant idealization that allows the authors to explore the representation and replay properties of their model, it is a strong and highly non-physiological constraint. The authors should verify that their results do not depend on this idealization. Specifically, I would suggest the authors also test the spatial coding properties of their network in 2-dimensional environments, and with different kinds of input that have a range of degrees of spatial tuning and physiological plausibility. A method for systematically producing input with varying degrees of spatial tuning in both 1D and 2D environments has been previously used in (Fang et al 2023, eLife, see Figures 4 and 5), which could be readily adapted for the current study; and behaviorally plausible trajectories in 2D can be produced using the RatInABox package (George et al 2022, bioRxiv), which can also generate e.g. grid cell-like activity that could be used as physiologically plausible input to the network.</p>
<p>Finally, I was left wondering how the cells' spatial tuning relates to their cluster membership, and how the capacity of the network (number of different environments/locations that can be represented) relates to the number of clusters. It seems that if clusters of cells tend to code for nearby locations in the environment (as predicted by the results of Figure 5), then the number of encodable locations would be limited (by the number of clusters). Further, there should be a strong tendency for cells in the same cluster to encode overlapping locations in different environments, which is not seen in experimental data.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93981.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work offers a novel perspective on the question of how hippocampal networks can adaptively generate different spatial maps and replays/preplays of the corresponding place cells, without any such maps pre-existing in the network architecture or its inputs. Unlike previous modeling attempts, the authors do not pre-tune their model neurons to any particular place fields. Instead, they build a random, moderately-clustered network of excitatory (and some inhibitory) cells, similar to CA3 architecture. By simulating spatial exploration through border-cell-like synaptic inputs, the model generates place cells for different &quot;environments&quot; without the need to reconfigure its synaptic connectivity or introduce plasticity. By simulating sleep-like random synaptic inputs, the model generates sequential activations of cells, mimicking preplays. These &quot;preplays&quot; require small-world connectivity, so that weakly connected cell clusters are activated in sequence. Using a set of electrophysiological recordings from CA1, the authors confirm that the modeled place cells and replays share many features with real ones. In summary, the model demonstrates that spontaneous activity within a small-world structured network can generate place cells and replays without the need for pre-configured maps.</p>
<p>Strengths:</p>
<p>This work addresses an important question in hippocampal dynamics. Namely, how can hippocampal networks quickly generate new place cells when a novel environment is introduced? And how can these place cells preplay their sequences even before the environment is experienced? Previous models required pre-existing spatial representations to be artificially introduced, limiting their adaptability to new environments. Other models depended on synaptic plasticity rules which made remapping slower than what is seen in recordings. This modeling work proposes that quickly-adaptive intrinsic spiking sequences (preplays) and spatially tuned spiking (place cells) can be generated in a network through randomly clustered recurrent connectivity and border-cell inputs, avoiding the need for pre-set spatial maps or plasticity rules. The proposal that small-world architecture is key for place cells and preplays to adapt to new spatial environments is novel and of potential interest to the computational and experimental community.</p>
<p>The authors do a good job of thoroughly examining some of the features of their model, with a strong focus on excitatory cell connectivity. Perhaps the most valuable conclusion is that replays require the successive activation of different cell clusters. Small-world architecture is the optimal regime for such a controlled succession of activated clusters.</p>
<p>The use of pre-existing electrophysiological data adds particular value to the model. The authors convincingly show that the simulated place cells and preplay events share many important features with those recorded in CA1 (though CA3 ones are similar).</p>
<p>Weaknesses:</p>
<p>To generate place cell-like activity during a simulated traversal of a linear environment, the authors drive the network with a combination of linearly increasing/decreasing synaptic inputs, mimicking border cell-like inputs. These inputs presumably stem from the entorhinal cortex (though this is not discussed). The authors do not explore how the model would behave when these inputs are replaced by or combined with grid cell inputs which would be more physiologically realistic.</p>
<p>Even though the authors claim that no spatially-tuned information is needed for the model to generate place cells, there is a small location-cue bias added to the cells, depending on the cluster(s) they belong to. Even though this input is relatively weak, it could potentially be driving the sequential activation of clusters and therefore the preplays and place cells. In that case, the claim for non-spatially tuned inputs seems weak. This detail is hidden in the Methods section and not discussed further. How does the model behave without this added bias input?</p>
<p>Unlike excitation, inhibition is modeled in a very uniform way (uniform connection probability with all E cells, no I-I connections, no border-cell inputs). This goes against a long literature on the precise coordination of multiple inhibitory subnetworks, with different interneuron subtypes playing different roles (e.g. output-suppressing perisomatic inhibition vs input-gating dendritic inhibition). Even though no model is meant to capture every detail of a real neuronal circuit, expanding on the role of inhibition in this clustered architecture would greatly strengthen this work.</p>
<p>For the modeling insights to be physiologically plausible, it is important to show that CA3 connectivity (which the model mimics) shares the proposed small-world architecture. The authors discuss the existence of this architecture in various brain regions but not in CA3, which is traditionally thought of and modeled as a random or fully connected recurrent excitatory network. A thorough discussion of CA3 connectivity would strengthen this work.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93981.1.sa4</article-id>
<title-group>
<article-title>Author Response</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Breffle</surname>
<given-names>Jordan</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5793-4427</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Germaine</surname>
<given-names>Hannah</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7624-2431</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Shin</surname>
<given-names>Justin D.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7959-7772</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Jadhav</surname>
<given-names>Shantanu P.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5821-0551</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Miller</surname>
<given-names>Paul</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9280-000X</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We thank the reviewers for their positive comments and constructive feedback following their thorough reading of the manuscript. In this provisional reply we will briefly address the reviewer’s comments and suggestions point by point. In the forthcoming revised manuscript, we will more thoroughly address the reviewer’s comments and provide additional supporting data.</p>
<disp-quote content-type="editor-comment">
<p>(1) The expression 'randomly clustered networks' needs to be explained in more detail given that in its current form risks to indicate that the network might be randomly organized (i.e., not organized). In particular, a clustered network with future functionality based on its current clustering is not random but rather pre-configured into those clusters. What the authors likely meant to say, while using the said expression in the title and text, is that clustering is not induced by an experience in the environment, which will only be later mapped using those clusters. While this organization might indeed appear as randomly clustered when referenced to a future novel experience, it might be non-random when referenced to the prior (unaccounted) activity of the network. Related to this, network organization based on similar yet distinct experiences (e.g., on parallel linear tracks as in Liu, Sibille, Dragoi, Neuron 2021) could explain/configure, in part, the hippocampal CA1 network organization that would appear otherwise 'randomly clustered' when referenced to a future novel experience.</p>
</disp-quote>
<p>As suggested by the reviewer, we will revise the text to clarify that the random clustering is random with respect to any future, novel environment. The cause of clustering could be prior experiences (e.g. Bourjaily M &amp; Miller P, Front. Comput. Neurosci. 5:37, 2011) or developmental programming (e.g. Perin R, Berger TK, &amp; Markram H, Proc. Natl. Acad. Sci. USA 108:5419, 2011).</p>
<disp-quote content-type="editor-comment">
<p>(2) The authors should elaborate more on how the said 'randomly clustered networks' generate beyond chance-level preplay. Specifically, why was there preplay stronger than the time-bin shuffle? There are at least two potential explanations:</p>
<p>(2.1) When the activation of clusters lasts for several decoding time bins, temporal shuffle breaks the continuity of one cluster's activation, thus leading to less sequential decoding results. In that case, the preplay might mainly outperform the shuffle when there are fewer clusters activating in a PBE. For example, activation of two clusters must be sequential (either A to B or B to A), while time bin shuffle could lead to non-sequential activations such as a-b-a-b-a-b where a and b are components of A and B;</p>
<p>(2.2) There is a preferred connection between clusters based on the size of overlap across clusters. For example, if pair A-B and B-C have stronger overlap than A-C, then cluster sequences A-B-C and C-B-A are more likely to occur than others (such as A-C-B) across brain states. In that case, authors should present the distribution of overlap across clusters, and whether the sequences during run and sleep match the magnitude of overlap. During run simulation in the model, as clusters randomly receive a weak location cue bias, the activation sequence might not exactly match the overlap of clusters due to the external drive. In that case, the strength of location cue bias (4% in the current setup) could change the balance between the internal drive and external drive of the representation. How does that parameter influence the preplay incidence or quality?</p>
</disp-quote>
<p>Based on our finding that preplay occurs only in networks that sustain cluster activity over multiple decoding time bins (Figure 5d-e), our understanding of the model’s function is consistent with the reviewers first explanation. We will provide additional analysis in the forthcoming revised manuscript in order to directly test the first explanation and will also test the intriguing possibility that the reviewer’s second suggestion contributes to above-chance preplay.</p>
<disp-quote content-type="editor-comment">
<p>(3) The manuscript is focused on presenting that a randomly clustered network can generate preplay and place maps with properties similar to experimental observations. An equally interesting question is how preplay supports spatial coding. If preplay is an intrinsic dynamic feature of this network, then it would be good to study whether this network outperforms other networks (randomly connected or ring lattice) in terms of spatial coding (encoding speed, encoding capacity, tuning stability, tuning quality, etc.)</p>
</disp-quote>
<p>We agree that this is an interesting future direction, but we see it as outside the scope of the current work. There are two interesting avenues of future work: 1) Our current model does not include any plasticity mechanisms, but a future model could study the effects of synaptic plasticity during preplay on long-term network dynamics, and 2) Our current model does not include alternative approaches to constructing the recurrent network, but future studies could systematically compare the spatial coding properties of alternative types of recurrent networks.</p>
<disp-quote content-type="editor-comment">
<p>(4) The manuscript mentions the small-world connectivity several times, but the concept still appears too abstract and how the small-world index (SWI) contributes to place fields or preplay is not sufficiently discussed.</p>
<p>For a more general audience in the field of neuroscience, it would be helpful to include example graphs with high and low SWI. For example, you can show a ring lattice graph and indicate that there are long paths between points at opposite sides of the ring; show randomly connected graphs indicating there are no local clustered structures, and show clustered graphs with several hubs establishing long-range connections to reduce pair-wise distance.</p>
<p>How this SWI contributes to preplay is also not clear. Figure 6 showed preplay is correlated with SWI, but maybe the correlation is caused by both of them being correlated with cluster participation. The balance between cluster overlap and cluster isolation is well discussed. In the Discussion, the authors mention &quot;...Such a balance in cluster overlap produces networks with small-world characteristics (Watts and Strogatz, 1998) as quantified by a small-world index...&quot; (Lines 560-561). I believe the statement is not entirely appropriate, a network similar to ring lattice can still have the balance of cluster isolation and cluster overlap, while it will have small SWI due to a long path across some node pairs. Both cluster structure and long-range connection could contribute to SWI. The authors only discuss the necessity of cluster structure, but why is the long-range connection important should also be discussed. I guess long-range connection could make the network more flexible (clusters are closer to each other) and thus increase the potential repertoire.</p>
</disp-quote>
<p>We agree that the manuscript would benefit from a more concrete explanation of the small-world index. We will revise the text and add illustrative figures.</p>
<p>We note that while our most successful clustered networks are indeed those with small-world characteristics, there are other ways of producing small-world networks which may not show good place fields or preplay. We will test another type of small-world network if time permits.</p>
<p>Our discussion of “cluster overlap” is specific to our type of small-world network in which there is no pre-determined spatial dimension (unlike the ring network of Watts and Strogatz). Therefore, because clusters map randomly to location once a particular spatial context is imposed, the random overlap between clusters produces long-range connections in that context (and any other context) so one can think of the amount of overlap between clusters as representing the number of long-range connections in a Watts-Strogatz model, except, we wish to iterate, such models involve a spatial topology within the network, which we do not include.</p>
<disp-quote content-type="editor-comment">
<p>(5) What drives PBE during sleep? Seems like the main difference between sleep and run states is the magnitude of excitatory and inhibitory inputs controlled by scaling factors. If there are bursts (PBE) in sleep, do you also observe those during run? Does the network automatically generate PBE in a regime of strong excitation and weak inhibition (neural bifurcation)?</p>
</disp-quote>
<p>During sleep simulations, the PBEs are spontaneously generated by the recurrent connections in the network. The constant-rate Poisson inputs drive low-rate stochastic spiking in the recurrent network, which then randomly generates population events when there is sufficient internal activity to transiently drive additional spiking within the network.</p>
<p>During run simulations, the spatially-tuned inputs drive greater activity in a subset of the cells at a given point on the track, which in turn suppress the other excitatory cells through the feedback inhibition.</p>
<disp-quote content-type="editor-comment">
<p>(6) Is the concept of 'cluster' similar to 'assemblies', as in Peyrache et al, 2010; Farooq et al, 2019? Does a classic assembly analysis during run reveal cluster structures?</p>
</disp-quote>
<p>Yes, we are highly confident that the clusters in our network would correspond to the functional assemblies that have been studied through assembly analysis and will present the relevant data in a revision.</p>
<disp-quote content-type="editor-comment">
<p>(7) Can the capacity of the clustered network to express preplay for multiple distinct future experiences be estimated in relation to current network activity, as in Dragoi and Tonegawa, PNAS 2013?</p>
</disp-quote>
<p>We agree this is an interesting opportunity to compare the results of our model to what has been previously found experimentally and will test this if time permits.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer # 2</bold></p>
<p>Weaknesses:</p>
<p>My main critiques of the paper relate to the form of the input to the network.</p>
<p>First, because the input is the same across trials (i.e. all traversals are the same duration/velocity), there is no ability to distinguish a representation of space from a representation of time elapsed since the beginning of the trial. The authors should test what happens e.g. with traversals in which the animal travels at different speeds, and in which the animal's speed is not constant across the entire track, and then confirm that the resulting tuning curves are a better representation of position or duration.</p>
</disp-quote>
<p>We agree that this is an important question, and we plan to run further simulations where we test the effects of varying the simulated speed. We will present results in the resubmission.</p>
<disp-quote content-type="editor-comment">
<p>Second, it's unclear how much the results depend on the choice of a one-dimensional environment with ramping input. While this is an elegant idealization that allows the authors to explore the representation and replay properties of their model, it is a strong and highly non-physiological constraint. The authors should verify that their results do not depend on this idealization. Specifically, I would suggest the authors also test the spatial coding properties of their network in 2-dimensional environments, and with different kinds of input that have a range of degrees of spatial tuning and physiological plausibility. A method for systematically producing input with varying degrees of spatial tuning in both 1D and 2D environments has been previously used in (Fang et al 2023, eLife, see Figures 4 and 5), which could be readily adapted for the current study; and behaviorally plausible trajectories in 2D can be produced using the RatInABox package (George et al 2022, bioRxiv), which can also generate e.g. grid cell-like activity that could be used as physiologically plausible input to the network.</p>
</disp-quote>
<p>We agree that testing the robustness of our results to different models of feedforward input is important and we plan to do this in our revised manuscript for the linear track and W-track.</p>
<p>Testing the model in a 2D environment is an interesting future direction, but we see it as outside the scope of the current work. To our knowledge there are no experimental findings of preplay in 2D environments, but this presents an interesting opportunity for future modeling studies.</p>
<disp-quote content-type="editor-comment">
<p>Finally, I was left wondering how the cells' spatial tuning relates to their cluster membership, and how the capacity of the network (number of different environments/locations that can be represented) relates to the number of clusters. It seems that if clusters of cells tend to code for nearby locations in the environment (as predicted by the results of Figure 5), then the number of encodable locations would be limited (by the number of clusters). Further, there should be a strong tendency for cells in the same cluster to encode overlapping locations in different environments, which is not seen in experimental data.</p>
</disp-quote>
<p>Thank you for making this important point and giving us the opportunity to clarify. We do find that subsets of cells with identical cluster membership have correlated place fields, but as we show in Figure 7b the network place map as a whole shows low remapping correlations across environments, which is consistent with experimental data (Hampson RE et al, Hippocampus 6:281, 1996; Pavlides C, et al, Neurobiol Learn Mem 161:122, 2019). Our model includes a relatively small number of cells and clusters compared to CA3, and with a more realistic number of clusters, the level of correlation across network place maps should reduce even further in our model network. The reason for a low level of correlation is because cluster membership is combinatorial, whereby cells that share membership in one cluster can also belong to separate/distinct other clusters, rendering their activity less correlated than might be anticipated. In our revised manuscript we will address this point more carefully and cite the relevant experimental support.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer # 3</bold></p>
<p>Weaknesses:</p>
<p>To generate place cell-like activity during a simulated traversal of a linear environment, the authors drive the network with a combination of linearly increasing/decreasing synaptic inputs, mimicking border cell-like inputs. These inputs presumably stem from the entorhinal cortex (though this is not discussed). The authors do not explore how the model would behave when these inputs are replaced by or combined with grid cell inputs which would be more physiologically realistic.</p>
</disp-quote>
<p>We chose the linearly varying spatial inputs as the minimal model of providing spatial input to the network so that we could focus on the dynamics of the recurrent connections. We agree our results will be strengthened by testing alternative types of border-like input so will present such additional results in our revised version. However, given that a sub-goal of our model was to show that place fields could arise in locations at which no neurons receive a peak in external input, whereas combining input from multiple grid cells produces peaked place-field like input, adding grid cell input (and the many other types of potential hippocampal input) is beyond the scope of the paper.</p>
<disp-quote content-type="editor-comment">
<p>Even though the authors claim that no spatially-tuned information is needed for the model to generate place cells, there is a small location-cue bias added to the cells, depending on the cluster(s) they belong to. Even though this input is relatively weak, it could potentially be driving the sequential activation of clusters and therefore the preplays and place cells. In that case, the claim for non-spatially tuned inputs seems weak. This detail is hidden in the Methods section and not discussed further. How does the model behave without this added bias input?</p>
</disp-quote>
<p>First, we apologize for a lack of clarity if we have caused confusion about the type of inputs (linear and cluster-dependent as we had attempted to portray prominently in Figure 1, where it is described in the caption, l. 156-157, and Results, l. 189-190 &amp; l. 497-499, as well as in the Methods, l. 671-683) and if we implied an absence of spatially-tuned information in the network. In the revision we will clarify that for reliable place fields to appear, the network must receive spatial information and that one point of our paper is that the information need not arrive as peaks of external input already resembling place cells or grid cells. We chose linearly ramping boundary inputs as the minimally place-field like stimulus (that still contains spatial information) but in our revision we will include alternatives. We should note that during sleep, when “preplay” occurs, there is no such spatial bias (which is why preplay can equally correlate with place field sequences in any context). In the revision, we will update Figure 1 to show more clearly the cluster-dependent linearly ramping input received by some specific cells with both similar and different place fields.</p>
<disp-quote content-type="editor-comment">
<p>Unlike excitation, inhibition is modeled in a very uniform way (uniform connection probability with all E cells, no I-I connections, no border-cell inputs). This goes against a long literature on the precise coordination of multiple inhibitory subnetworks, with different interneuron subtypes playing different roles (e.g. output-suppressing perisomatic inhibition vs input-gating dendritic inhibition). Even though no model is meant to capture every detail of a real neuronal circuit, expanding on the role of inhibition in this clustered architecture would greatly strengthen this work.</p>
</disp-quote>
<p>This is an interesting future direction, but we see it as outside the scope of our current work. While inhibitory microcircuits are certainly important physiologically, we focus here on a minimal model that produces the desired place cell activity and preplay, as measured in excitatory cells.</p>
<disp-quote content-type="editor-comment">
<p>For the modeling insights to be physiologically plausible, it is important to show that CA3 connectivity (which the model mimics) shares the proposed small-world architecture. The authors discuss the existence of this architecture in various brain regions but not in CA3, which is traditionally thought of and modeled as a random or fully connected recurrent excitatory network. A thorough discussion of CA3 connectivity would strengthen this work.</p>
</disp-quote>
<p>We agree this is an important point that is missing, and we will revise the text to specifically address CA3 connectivity (Guzman et al., Science 353 (6304), 1117-1123 2016) and the small-world structure therein due to the presence of “assemblies”.</p>
</body>
</sub-article>
</article>