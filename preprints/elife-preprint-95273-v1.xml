<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">95273</article-id>
<article-id pub-id-type="doi">10.7554/eLife.95273</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.95273.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Cell Biology</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Unbiased identification of cell identity in dense mixed neural cultures</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8964-4480</contrib-id>
<name>
<surname>Beuckeleer</surname>
<given-names>Sarah De</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>De Looverbosch</surname>
<given-names>Tim Van</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Den Daele</surname>
<given-names>Johanna Van</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ponsaerts</surname>
<given-names>Peter</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0960-6781</contrib-id>
<name>
<surname>De Vos</surname>
<given-names>Winnok H.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Laboratory of Cell Biology and Histology, University of Antwerp</institution></aff>
<aff id="a2"><label>2</label><institution>Laboratory of Experimental Hematology, Vaccine and Infectious Disease Institute (Vaxinfectio), University of Antwerp</institution></aff>
<aff id="a3"><label>3</label><institution>Antwerp Centre for Advanced Microscopy, University of Antwerp</institution></aff>
<aff id="a4"><label>4</label><institution>µNeuro Research Centre of Excellence, University of Antwerp</institution></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Zaritsky</surname>
<given-names>Assaf</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Ben-Gurion University of the Negev</institution>
</institution-wrap>
<city>Beer Sheva</city>
<country>Israel</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Campelo</surname>
<given-names>Felix</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Institute of Photonic Sciences</institution>
</institution-wrap>
<city>Barcelona</city>
<country>Spain</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="others"><p><bold>e-mail</bold>:</p><p><email>sarah.debeuckeleer@uantwerpen.be</email></p><p><email>tim.vandelooverbosch@uantwerpen.be</email></p><p><email>johanna.vandendaele@uantwerpen.be</email></p><p><email>peter.ponsaerts@uantwerpen.be</email></p><p><email>winnok.devos@uantwerpen.be</email></p></fn>
<corresp id="cor1"><label>*</label>Contact information Corresponding author: University of Antwerp, Laboratory of Cell Biology and Histology Universiteitsplein 1, 2610 Antwerp, Belgium, E-mail: <email>winnok.devos@uantwerpen.be</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-03-13">
<day>13</day>
<month>03</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP95273</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-01-06">
<day>06</day>
<month>01</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-01-08">
<day>08</day>
<month>01</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.01.06.574474"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Beuckeleer et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Beuckeleer et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-95273-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Induced pluripotent stem cell (iPSC) technology is revolutionizing cell biology. However, the variability between individual iPSC lines and the lack of efficient technology to comprehensively characterize iPSC-derived cell types hinder its adoption in routine screening settings. To facilitate the validation of iPSC-derived cell culture composition, we have implemented an imaging assay based on cell painting and convolutional neural networks to recognize neural cell types in dense and mixed cultures with high fidelity. We have benchmarked our approach using pure and mixed cultures of neuroblastoma and astrocytoma cell lines and attained a classification accuracy above 96%. Through iterative data erosion we found that inputs containing the nuclear region of interest and its close environment, allow achieving equally high classification accuracy as inputs containing the whole cell for semi-confluent cultures and preserved its accuracy even in very dense cultures. We then applied the nucleocentric cell profiling approach to evaluate the differentiation status of iPSC-derived neural cultures, by determining the ratio of postmitotic neurons and neural progenitors. We found that the cell-based prediction significantly outperformed an approach in which the culture time point was used as classification criterion (96% <italic>vs.</italic> 86%, resp.). Thus, nucleocentric morphological single cell profiling provides a means to quantify cell composition in complex mixed neural cultures and holds promise for use in quality control of iPSC-derived neural cell culture models.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>morphological phenotyping</kwd>
<kwd>multiplexed imaging</kwd>
<kwd>iPSC culture validation</kwd>
<kwd>neural differentiation</kwd>
<kwd>computational biology</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Modelling the complexity of the human brain and its (dys)function has proven to be notoriously challenging. This is due to its intricate wiring, the cellular heterogeneity and species-specific differences<sup><xref ref-type="bibr" rid="c1">1</xref></sup>. To increase the translational value of neuroscientific research, there is a need for physiologically relevant human models. With the advent of human induced pluripotent stem cell (iPSC) technology, it has become possible to generate a wealth of brain-resident cell types including neurons<sup><xref ref-type="bibr" rid="c2">2</xref></sup>, astrocytes<sup><xref ref-type="bibr" rid="c3">3</xref></sup>, microglia<sup><xref ref-type="bibr" rid="c4">4</xref></sup>, oligodendrocytes<sup><xref ref-type="bibr" rid="c5">5</xref></sup> and endothelial cells<sup><xref ref-type="bibr" rid="c6">6</xref></sup>, allowing the study of complex polygenic pathologies that cannot be modelled in animals, opening avenues to precision pharmacology<sup><xref ref-type="bibr" rid="c7">7</xref>,<xref ref-type="bibr" rid="c8">8</xref></sup>. Furthermore, the ability of iPSC to develop into organoids renders them attractive for studying multi-cellular interactions in a 3D context that is closer to the <italic>in vivo</italic> situation<sup><xref ref-type="bibr" rid="c9">9</xref></sup>. However, genetic drift and batch-to-batch heterogeneity cause variability in reprogramming and differentiation efficiency<sup><xref ref-type="bibr" rid="c10">10</xref></sup>. This hinders the use of iPSC-derived cell systems in systematic drug screening or cell therapy pipelines. Quality control in such settings demands a robust and cost-effective approach. Current culture validation methods include sequencing, flow cytometry and immunocytochemistry <sup><xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c11">11</xref></sup>. These methods are often low in throughput, costly and/or destructive. Thence, we set out to develop a method for evaluating the composition of such cultures based on high-content imaging, which is fast and affordable. The primary criteria were to facilitate cell type identification with cellular resolution while preserving spatial information and ensuring compatibility with subsequent immunocytochemistry or molecular assays for further biological inquiries. To this end, we employed the Cell Painting (CP)<sup><xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c13">13</xref></sup> method, which is based on labelling cells with simple organic dyes and analysing the resulting phenotypes. CP has proven to be a powerful and generic method for predicting the mode-of-action of pharmacological or genetic perturbations, and this sheerly using a cell morphology readout<sup><xref ref-type="bibr" rid="c14">14</xref>–<xref ref-type="bibr" rid="c16">16</xref></sup>. Thus far, CP has primarily been utilized to predict conditions associated with pharmacological treatments or genetic modifications using images as input. An exemplary achievement in this context has been realized by the JUMP consortium, which has published an open-source CP image dataset comprising over 13,000 distinct conditions<sup><xref ref-type="bibr" rid="c17">17</xref></sup>. Recognizing the predictive potential of morphological information, we explored its utility at the single-cell level, shifting focus from the image level to predict individual cell types. By implementing deep learning for cell classification and tuning the input space, we established an approach that allows recognizing cell types with high accuracy, even in very dense cultures. We illustrate its potential by using it to distinguish iPSC-derived cell types in co-culture and to assess the maturity of differentiating neurons.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Neural cell lines have a unique morphotextural fingerprint</title>
<p>Several groups have demonstrated that morphological cell profiling can be used to discriminate pharmacogenomic perturbations based on phenotypic similarity<sup><xref ref-type="bibr" rid="c14">14</xref>–<xref ref-type="bibr" rid="c16">16</xref></sup>. We asked whether a similar approach could be leveraged to unequivocally distinguish individual cell types as well. To this end, we implemented a version of CP based on 4-channel confocal imaging (<bold><xref rid="fig1" ref-type="fig">Fig. 1A</xref></bold>) and applied it to monocultures of two neural cell lines from a different lineage, namely astrocyte-derived 1321N1 astrocytoma cells and neural crest-derived SH-SY5Y neuroblastoma cells. First, we explored whether traditional morphotextural feature extraction from cells and their nuclei provided sufficient distinctive power. Representation of the resulting standardized feature set in UMAP space revealed a clear separation of both cell types without replicate bias (<bold><xref rid="fig1" ref-type="fig">Fig. 1B</xref></bold>). Clustering of instances was less pronounced after principal component analysis (<bold>Suppl. Fig. 4 A</bold>), but UMAP better preserves local and global data structure <sup><xref ref-type="bibr" rid="c18">18</xref></sup>. When mapping the individual features to the UMAP space, we found that both texture (<italic>e.g.,</italic> energy, homogeneity) and shape (<italic>e.g.,</italic> nuclear area, cellular area) metrics contributed to the separation (<bold><xref rid="fig1" ref-type="fig">Fig. 1C</xref></bold>). The contribution of intensity-related features (<italic>e.g.,</italic> mean, max, min, std intensity) to cell type separation was less pronounced as they were more correlated with the biological replicate. Thus, we concluded that cell types can be separated across replicates based on a morphotextural fingerprint.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1</label>
<caption><title>| Shallow classification using manually defined features.</title>
<p>(A) Image overview of 1321N1 cells after CP staining acquired at higher magnification (Plan Apo VC 60×A WI DIC N2, NA = 1,20). Scale bar is 30µm. (B) UMAP dimensionality reduction, color coded for either cell type condition (left) or replicate (right). (C) Feature importance deducted from the UMAP (feature maps) and RF (Gini importance). Three exemplary feature maps are highlighted alongside the quantification per cell type. (D) Random Forest classification performance with confusion matrix and Gini importance. All features used in the UMAP are used for RF building.</p></caption>
<graphic xlink:href="574474v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2b">
<title>CNN outperforms random forest in cell type classification</title>
<p>To evaluate whether the morphotextural fingerprint could be used to predict cell type, we performed Random Forest (RF) classification, using different seeds for splitting up training and validation sets. This resulted in a rather poor prediction accuracy of 71,0±1,0%, mainly caused by the significant (46%) misclassification of 1321N1 cells (<bold><xref rid="fig1" ref-type="fig">Fig. 1D</xref></bold>). The imbalance in recall and precision was surprising given the clear separation of cell populations in UMAP space using the same feature matrix. When inspecting the main contributions to the RF classifier, we found very similar features as highlighted in UMAP space to add to the discrimination (<bold><xref rid="fig1" ref-type="fig">Fig. 1C</xref></bold>). Where the top 2 features (nuclear Cy3 energy and cellular area) showed the expected gradient along the UMAP1 direction, the third parameter (cellular DAPI contrast) had no contribution to UMAP separation. Reducing noise by manually removing redundant and correlating features could not ameliorate RF performance, which may be due to the documented bias in feature selection for node splitting in high-dimensional data<sup><xref ref-type="bibr" rid="c19">19</xref></sup>. This result drove us to improve the classification accuracy by means of a ResNet<sup><xref ref-type="bibr" rid="c20">20</xref></sup> convolutional neuronal network (CNN). Here, we no longer relied on the extraction of features from segmented cell objects, but instead used image crops centred around individual cells (bounding box around cell centroid) and blanked for their surroundings as input (<bold><xref rid="fig2" ref-type="fig">Fig. 2A</xref></bold>). Using this approach, we found a significantly higher prediction accuracy of 96,0±1,8%, with a much more balanced recall and precision (<bold><xref rid="fig2" ref-type="fig">Fig. 2B</xref></bold>). Even with only 100 training instances per class, CNN outperformed RF, but optimal performance was attained with 5000 training instances (<bold><xref rid="fig2" ref-type="fig">Fig. 2C</xref></bold>). As expected, a model trained on all three biological replicates performed slightly worse (lower accuracy and higher variability) at predicting a test set of a given replicate than a model trained on that same replicate (<bold><xref rid="fig2" ref-type="fig">Fig. 2D</xref></bold>). However, models trained on two different replicates outperformed those that were only trained on one when used for predicting instances of a third (unseen) replicate. This emphasizes the need for including sufficient variation in the training set (<bold><xref rid="fig2" ref-type="fig">Fig. 2E</xref></bold>). Although more performant, CNN classification does not allow direct retrieval of discriminative features, which complicates model interpretation. To gain a visual understanding of image information contributing most to the classification we therefore resorted to Gradient-weighted Class Activation Mapping (Grad-CAM)<sup><xref ref-type="bibr" rid="c21">21</xref></sup>. This revealed that the cell borders (edge information), nuclear and nucleolar signals were the most distinctive features (<bold><xref rid="fig2" ref-type="fig">Fig. 2F</xref></bold>). When scrutinizing CNN misclassifications, we found that these are mainly caused by faulty cell detection (<italic>e.g.,</italic> oversegmentation of cell ramifications), unhealthy/dead cells, debris or visibly aberrant cell shapes (<bold>Suppl. Fig. 4B</bold>) – mistakes not necessarily attributed to the CNN. To shed light on the contribution of individual markers to the classification, we eroded the input to single channel images. For all cases, the prediction performance was below or equal to 85,0% suggesting that no single channel contains all relevant information (<bold><xref rid="fig2" ref-type="fig">Fig. 2</xref> G</bold>). Combinations of two or three channels could not match the prediction accuracy of the full four-channel image either. Thus, we concluded that all channels contribute at least in part to a successful classification.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2</label>
<caption><title>| Convolutional neural network classification of monoculture conditions.</title>
<p>(A) Schematic of image pre-processing for CNN classification. (B) CNN accuracy and confusion matrix on cell type classification in monocultures. (C) Shallow vs. deep learning accuracy for varying training set sizes. Dots represent different training iterations (cross-validation). Train-validation-test dataset selection was performed with the same random seed at 60-10-30 ratios. (D) The impact of variability in the training dataset on model accuracy for shallow vs. deep learning. Mann-Whitney-U-test, p-values resp. 7,47e-6 and 1,96e-4. (E) The performance of deep learning classifiers trained on single replicates (low variability) and mixed replicates (high variability) on unseen images (independent replicates). Kruskal-Wallis test on single training condition, p-value of 0,026 with post-hoc Tukey test. Mann-Whitney-U-test on mixed training, p-value of 7,47e-6. (F) GradCAM map highlighting the regions on which the CNN relies for making its prediction. (G) Performance accuracy of the CNN when only a selection of image channels is given as training input.</p></caption>
<graphic xlink:href="574474v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2c">
<title>Nucleocentric predictions remain accurate regardless of culture density</title>
<p>Morphological profiling relies on cell identification for adequate class prediction. This may become difficult in dense cultures such as iPSC-cultures, clustered cells and tissue (mimics). Having established a method to distinguish cell types with high accuracy, we next asked how robust the classification was to increasing cell density. To this end, we acquired images of 1321N1 and SH-SY5Y monocultures, grown at densities ranging from 0 to 100% confluency (<bold><xref rid="fig3" ref-type="fig">Fig. 3A</xref></bold>). Based on the nuclear count, we binned individual fields into 6 density classes (0-20%, 20-40%, 40-60%, 60-80%, 80-95%, 95-100%) and trained a CNN with equal sampling of cell numbers per density class to avoid bias. No decrease in accuracy was observed until culture density reached 80% confluency. Only for very high densities (95-100%), we found a significant decrease in the prediction accuracy (92,0±1,7%) (<bold><xref rid="fig3" ref-type="fig">Fig. 3B</xref></bold>). We reasoned that under these conditions cell shape would be predominantly determined by neighbouring cells and cell segmentation performance would decrease (<bold>Suppl. Fig. 1</bold>). Nuclei are less malleable and even in dense cultures remain largely separated, allowing their robust segmentation and avoiding CNN misclassifications resulting from segmentation errors. Hence, we asked whether using the nuclear ROI as input would improve classification performance at high densities despite containing less cellular information. However, regardless of a relatively high average prediction accuracy of about 92,4±1,0% (<bold><xref rid="fig3" ref-type="fig">Fig. 3C</xref></bold>), the performance was lower than cell ROI across the density range. Thence, we tested an intermediate condition in which nuclear ROI with their direct surroundings (a square bounding box of 60×60 microns surrounding the nuclear centroid coordinates) were considered as input (<bold>Suppl. Fig. 4C</bold>). This resulted in a classification accuracy of 95,0±0,4% (<bold><xref rid="fig3" ref-type="fig">Fig. 3C</xref></bold>) comparable to that of models trained on whole-cell inputs for low to moderate cell densities, but also maintained prediction performance at high cell densities (<bold><xref rid="fig3" ref-type="fig">Fig. 3B</xref></bold>). To understand why this was not the case for nuclear crops, we inspected Grad-CAM output for these predictions, and found that the latter diverted the attention of the CNN to the background (<bold><xref rid="fig3" ref-type="fig">Fig. 3D</xref></bold>). We interpret this result as the CNN using the background as a proxy for nuclear size. As nuclear area dropped with culture density, the dynamic range decreased, which could explain the increased error rate of the CNN for high densities unrelated to segmentation errors (<bold>Suppl. Fig. 4B</bold>). Thus, we conclude that using the nucleocentric region as input for the CNN is a valuable strategy for accurate cell phenotype identification in dense cultures.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3</label>
<caption><title>| The impact of regional information on CNN performance in relation to culture density.</title>
<p>(A) Definition of different culture density categories with corresponding images. (B) The effect of culture density (number of cells within the FOV) on prediction accuracy, for each of the different input regions. Kruskal-Wallis test for each of the regions, statistically significant decrease (p-value 2,07e-5) between the most dense condition with all other density categories for the cell region. (C) CNN accuracy for different input regions. Kruskal-Wallis test, p-value of 4,29e-4 with post-hoc Tukey test. (D) GradCAM intensity plots highlighting the regions on which the CNN relies for making its prediction in nucleocentric (top) and nuclear (bottom) crops.</p></caption>
<graphic xlink:href="574474v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2d">
<title>Cell prediction remains accurate in mixed cell culture conditions</title>
<p>Although a very high classification accuracy was obtained with nucleocentric CNN predictions, both training and testing were performed with input images drawn from monocultures. As our goal was to allow cell type prediction in complex, heterogeneous cultures, we next switched to a more faithful situation in which we co-cultured both cell types. Ground-truth for these predictions was generated by either performing post-hoc immunofluorescence (IF) with cell-type specific antibodies (CD44 for 1321N1 and TUBB3 for SH-SY5Y cells), or by differential replication labelling (EdU or BrdU for either of the cell types) after dye quenching<sup><xref ref-type="bibr" rid="c22">22</xref></sup> (<bold><xref rid="fig4" ref-type="fig">Fig. 4A</xref></bold>). The latter proved significantly more successful for binary ground truth classification (through intensity thresholding) than the former (<bold><xref rid="fig4" ref-type="fig">Fig. 4B</xref></bold>). When training a CNN to recognize the cell types using these post-hoc markers as ground truth, we found that the prediction accuracy on the left-out dataset of the co-culture (Co2Co) was almost as high as when a model was trained and tested on monocultures (Mono2Mono) (<bold><xref rid="fig4" ref-type="fig">Fig. 4C</xref></bold>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4</label>
<caption><title>| Cell type prediction in mixed cultures by post-hoc ground truth identification.</title>
<p>(A) Schematic overview of virtual vs. physically mixed cultures and the subsequent CNN models. For virtual mixing, individual cell types arise from distinct cultures, the cell type label was assigned based on the culture condition. For physical mixing, the true phenotype of each crop was determined by intensity thresholding after post-hoc staining. Three model types are defined: Mono2Mono (culture-based label), Co2Co (cell-based label) and Mono2Co (trained with culture-based label and tested on cell-based label). (B) Determining ground-truth phenotype by intensity thresholding on IF (top) or pre-label (bottom). The threshold was determined on the intensity of monocultures. Only the pre-labelled ground-truth resulted in good cell type separation by thresholding for 1321N1 vs. SH-SY5Y cells. (C) Mono2Mono (culture-based ground truth) vs. Co2Co (cell-based ground truth) models for cell type classification. Mann-Whitney-U-test p-value 0,0027. (D) Monoculture-trained models were tested on mixed cultures. Pretrained models were trained on independent biological replicates. These could be finetuned by additional training on monoculture images from the same replicate as the coculture. This was shown to reduce the variation between model iterations (Median performance: Mann-Whitney-U-test, p-value 0,0015; Coefficient of variation: Mann-Whitney-U-test, p-value 3,48e-4)</p></caption>
<graphic xlink:href="574474v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We then tested whether it was possible to use a classifier trained on monocultures for cell type prediction in co-culture (Mono2Co). This resulted in a prediction accuracy of 85,0±4,6%. We contributed this drop in accuracy to the effect on cell phenotype exerted by the presence of other cell types in mixed cultures which is not captured in monocultures. As the images from monocultures and co-cultures were obtained from different plates, we suspected inter-replicate variability in culture and staining procedures to contribute in part to this lesser performance. Therefore, we tested whether we could improve the performance of the CNN by including monocultures from the same plate as the co-cultures. This finetuning indeed improved the average performance to 89,0±0,7%, and more importantly, it significantly reduced the variability (coefficient of variation) of the predictions (<bold><xref rid="fig4" ref-type="fig">Fig. 4D</xref></bold>). Thus, while not yet reaching the same accuracy, it proves that it is possible to establish a model that recognizes cell types in co-cultures that is solely trained on monocultures.</p>
</sec>
<sec id="s2e">
<title>Nucleocentric phenotyping can be applied to stage iPSC-derived neuronal cultures</title>
<p>iPSC-derived neuronal cell cultures suffer from significant inter– and intra-batch variability and could benefit from an efficient quality control<sup><xref ref-type="bibr" rid="c23">23</xref>,<xref ref-type="bibr" rid="c24">24</xref></sup>. Thence, we applied our nucleocentric phenotyping pipeline to stage the maturity of a neuronal cell culture based on its cell type composition. Using a guided protocol<sup><xref ref-type="bibr" rid="c2">2</xref></sup>, two differentiation stages were simulated: a primed stage, where most cells are cycling neural progenitors (NPCs), and a differentiated stage where most cells are post-mitotic neurons (<bold><xref rid="fig5" ref-type="fig">Fig. 5A</xref></bold>). The two cell types were discriminated by post-hoc IF labelling for the cell cycle marker Ki67 (NPC) and the microtubule marker ß-III-tubulin (TUBB3, neurons). Not all cells in the CP image could be assigned with a ground truth label due to cell detachment upon re-staining or sheer absence of the tested marker. Since no single monoculture consists of 100% of either cell type, we applied gates to retain only those cells that show unequivocal staining for either one of both markers. Based on these gates, ROIs were either classified as neuron (Ki67-/TUBB3+), NPC (Ki67+/TUBB3-) or undefined (outside of gating boundaries). We assume the latter category to represent transitioning cells in intermediate stages of neural development, un-or dedifferentiated iPSCs. (<bold><xref rid="fig5" ref-type="fig">Fig. 5B</xref></bold>). This gating strategy resulted in a fractional abundance of neurons vs. NPC of 36,4 % in the primed condition and 80,0% in the differentiated condition (<bold><xref rid="fig5" ref-type="fig">Fig. 5C</xref></bold>). UMAP dimensionality reduction revealed a clear clustering of both phenotypes suggesting that the morphotextural profile captured their distinct phenotypic fingerprint and should enable their separation (<bold><xref rid="fig5" ref-type="fig">Fig. 5D</xref></bold>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5</label>
<caption><title>| iPSC-derived differentiation staging using morphology profiling.</title>
<p>(A) Schematic overview of guided vs. spontaneous neural differentiation. (B) Representative images of morphological staining and post-hoc IF of primed and differentiated iPSC-derived cultures (guided differentiation). Ground-truth determination is performed using TUBB3 (for mature neurons) and Ki67 (mitotic progenitors). Scale bar is 200µm. (C) Fraction of neurons vs. NPC cells in the primed vs. differentiated condition as determined by IF staining. Upon guided differentiation, the fraction of neurons increased. (D) Following feature extraction (handcrafted features), supervised UMAP dimension reduction shows separation between the primed vs. differentiated cultures. (E) CNN performance when classifying neurons (Ki67-/TUBB3+) vs. NPC (Ki67+/TUBB3-) cells using either a condition-based or cell-type based ground truth. Mann-Whitney-U-test, p-value 4,04e-4. (F) Fractional abundance of predicted cell phenotypes (NPC vs. neurons) in primed vs. differentiated culture conditions using the cell-based CNN. (G) Representative images of spontaneously differentiating neural cultures. Scale bar is 200µm. (H) Handcrafted features were extracted from the morphological images. These morphological profiles were plotted onto the UMAP feature space created using the guided differentiation (panel D). Plotting the points of spontaneously differentiating cultures onto this space, revealed gradual displacement of the morphological profile from the NPC towards the neuronal cluster with increasing differentiation time. (I) Quantification of the number of points in each cluster of panel H. (J) Prediction of differentiation status using the cell-based CNN model trained on guided differentiated culture.</p></caption>
<graphic xlink:href="574474v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In a first attempt to classify cells within the guided culture, we trained a CNN on individual cell inputs using the culture condition as a weak label. This resulted in a prediction accuracy of 87,0±0,9%, which is not unexpected given the cellular heterogeneity within each condition. When we used the IF ground truth labels instead, we obtained a classification performance of 96,0±0,5 % (<bold><xref rid="fig5" ref-type="fig">Fig. 5E</xref></bold>). Applying this cell-based (as opposed to condition-based) CNN to the two culture conditions resulted in predicted fractional abundance of neurons to NPC of 40,5% in images of the primed condition and 74,2% in images of the differentiated condition – aligning well with the manually defined ratios (<bold><xref rid="fig5" ref-type="fig">Fig. 5F</xref></bold>).</p>
<p>We then went on to evaluate the established cell-based classifier to a primed neuronal cell culture undergoing gradual spontaneous differentiation after dual-SMAD inhibition<sup><xref ref-type="bibr" rid="c25">25</xref></sup>. We examined cell cultures at 13, 30, 60 and 90 days <italic>in vitro</italic> (DIV) after the start of the differentiation process and visually confirmed a gradual change in neural maturity, as evidenced by the increasing dendritic outgrowth (<bold><xref rid="fig5" ref-type="fig">Fig. 5G</xref></bold>). In absence of post-hoc ground truth labelling, we plotted the cells of the different DIVs onto the UMAP space of the guided differentiation and quantified their relative abundance in regions encompassing either NPCs or neurons (<bold><xref rid="fig5" ref-type="fig">Fig. 5H-I</xref></bold>). This confirmed a shift in the neuron-to-NPC fractional abundance with an especially strong accumulation of neurons at DIV90. The cell-based CNN model trained on the guided differentiation dataset recapitulated this shift in its predictions (<bold><xref rid="fig5" ref-type="fig">Fig. 5J</xref></bold>).</p>
</sec>
<sec id="s2f">
<title>Nucleocentric phenotyping can be applied to characterize mixed iPSC-derived neuronal cultures</title>
<p>Next to NPCs and neurons, iPSC-derived neuronal cultures are often studied in conjunction with other relevant cell types that influence neuronal connectivity and homeostasis such as astrocytes and microglia<sup><xref ref-type="bibr" rid="c26">26</xref></sup>. Therefore, we tested whether the cell-based approach could be extended to these cell types as well. We generated iPSC-derived astrocytes, neurons, and microglia from the same parental iPSC line (<bold><xref rid="fig6" ref-type="fig">Fig. 6A</xref></bold>) and trained a CNN to identify each cell type. In monocultures, this led to a prediction accuracy of 96,8±1,0% (<bold><xref rid="fig6" ref-type="fig">Fig. 6B</xref></bold>) and in mixed cultures of neurons and microglia (using NeuN, resp. Iba1 as ground-truth IF markers) (<bold><xref rid="fig6" ref-type="fig">Fig. 6C</xref></bold>) an accuracy of 96,9±0,5% (<bold><xref rid="fig6" ref-type="fig">Fig. 6D</xref></bold>). Based on these results, we conclude that nucleocentric phenotyping can be used to gauge the composition of iPSC-derived cultures.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6</label>
<caption><title>| iPSC cell type identification using morphology profiling.</title>
<p>(A) Representative images of iPSC-derived neurons, astrocytes and microglia with morphological staining. Scale bar is 200µm. (B) Prediction accuracy of a CNN trained to classify monocultures of iPSC-derived astrocytes, microglia and neurons (panel A) with confusion matrix (average of all models). (C) Representative images of a mixed culture of iPSC-derived neurons and microglia. Ground-truth identification was performed using IF. (D) CNN accuracy of a model trained to identify both cell types in mixed culture mounted up to 98%.</p></caption>
<graphic xlink:href="574474v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>iPSC-derived cell cultures can improve translatability of biomedical research but represent a challenge due to their higher variability and multicellular composition. In this research, we have presented a method to efficiently identify neural cell types in mixed cultures to aid in their validation and application in routine screening settings. We first benchmarked our approach using neural cell lines and found that a CNN-based approach outperforms shallow learning (RF) based on handcrafted feature extraction, even with a limited number of input images. This aligns well with recent data showing CNN-based feature representations outperformed shallow techniques for condition-based drug response prediction<sup><xref ref-type="bibr" rid="c27">27</xref></sup>.</p>
<p>We found that all channels contribute to the overall prediction accuracy but that the whole cell is not required to obtain the highest prediction accuracy, especially in dense cultures. In line with earlier studies that highlight the biomarker potential of the nucleus for patient stratification<sup><xref ref-type="bibr" rid="c28">28</xref></sup>, cell state identification<sup><xref ref-type="bibr" rid="c29">29</xref></sup> or drug response<sup><xref ref-type="bibr" rid="c14">14</xref></sup>, we found that the nuclear ROI as such already carries highly distinctive information for cell type prediction. However, extension to its direct surroundings proved to be the best and most robust input across a range of cell densities. Since errors made by the CNN largely arose from segmentation errors, we hypothesize that such errors will be most pronounced in dense cultures. The nucleocentric approach, which is based on more robust nuclear segmentation, minimizes such mistakes. Furthermore, it opens possibilities for applying cell profiling to even more complex 3D cell systems such as tissue slices or organoids, where cell segmentation becomes extremely challenging.</p>
<p>One important conclusion from this work is that cell types can be identified in mixed cultures solely using the input from monocultures. This implies that cells retain their salient characteristics even in complex heterogeneous environments. While for now, predictions are still superior when based on training on mixed cultures, we found that the prediction accuracy of monoculture trained models can be increased by employing replicate controls. This suggests that it may become possible to apply or adapt existing models without the need for a cell-level ground truth (as provided by post-hoc labelling). This technique could potentially be of use for cultures or tissues where no antibody-or pre-labelling is possible (<italic>e.g.,</italic> no unique IF marker is available, non-replicating cells). To increase the accuracy one could resort to intelligent data augmentation<sup><xref ref-type="bibr" rid="c30">30</xref></sup> or transfer learning<sup><xref ref-type="bibr" rid="c31">31</xref></sup> strategies. While a ground-truth independent method holds promise for bulk predictions (<italic>e.g.,</italic> for quality control purposes), the use of post-hoc labelling allows building more refined models that can distinguish multiple cell types and/or cell states at once. Especially using the cyclic staining that we have used<sup><xref ref-type="bibr" rid="c22">22</xref></sup>, much richer information content can be gained. With the method presented here, we combine the rich multidimensional information from cyclic IF with morphological information and show that it is possible to predict these IF outcomes. Multiplexed imaging has previously shown its utility in gaining in depth information on culture composition and differentiation status in iPSC-derived neural cultures (progenitor, radial glia, astrocytes (immature and mature) and neurons (inhibitory and excitatory)<sup><xref ref-type="bibr" rid="c32">32</xref></sup>. Similarly, this could be expanded to cell states (apoptosis, DNA damage)<sup><xref ref-type="bibr" rid="c15">15</xref></sup>. Initial model training requires both CP and multiplexed IF images. After the initial training phase, the IF step can be omitted, and the CNN will predict the phenotype outcomes of the IF with high accuracy on the CP images alone. This significantly reduces experimental costs and time requirements.</p>
<p>Applying the method to iPSC-neuronal cultures revealed its potential to score their differentiation state. Although guided protocols manage to speed up the differentiation process and lead to enhanced culture purity, the neural differentiation process proves to be less than binary, as evidenced by the mixed presence of Ki67+/TUBB3– and Ki67-/TUBB3+ cells. The spontaneous differentiation protocol illustrated the unpredictable nature and late stage of the differentiation process. Reports in literature highlight the difficulty of reproducible neural differentiation and attribute this to culture conditions, cultivation time and variation in developmental signalling pathways in the source iPSC material<sup><xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c34">34</xref></sup>. Spontaneous neural differentiation has previously been shown to require approximately 80 days before mature neurons arise that can fire action potentials and show neural circuit formation. Although these differentiation processes display a stereotypical temporal sequence<sup><xref ref-type="bibr" rid="c25">25</xref></sup>, the exact timing and duration might vary. Yet, we could reliably predict the gradual transition to a more differentiated state using our CNN model. Complementary, the same transition from NPC to neuronal phenotype could be observed in UMAP space. Although UMAP dimensionality reduction merely visualizes data structures and is less sensitive as compared to CNN classification, it aids in visualization and comprehension of the dataset. We realize that differentiating iPSC cultures are highly heterogenous and are composed of a landscape of transitioning progenitors in various stages of maturity that our binary models currently fail to capture. To predict more continuously the maturation of iPSC-derived neural progenitors to differentiated neurons, it could be of interest to consider deep learning-based regression approaches <sup><xref ref-type="bibr" rid="c35">35</xref></sup>.</p>
<p>For now, we have tailored models to the individual datasets, but it is conceivable that a more generalist CNN could be established for multiple culture types. This would obviously demand a much larger dataset to encompass the variability encountered in such models (<italic>e.g.,</italic> various starting iPSC lines, various differentiation protocols). Publicly available datasets (<italic>e.g.,</italic> JUMP-Cell Painting Consortium) can aid in creating an input database containing a large variability (different iPSC lines, different neural differentiation protocols, …), which would ultimately lead to a more robust and generalist predictor. Our results showing the prediction accuracy of a guided differentiation model on spontaneously differentiating cultures indicate that the approach can be transferred to other differentiation protocols. Inclusion of more input images and variability should thus enable developing a generalist model for other differentiation protocols without the need for ground truth validation and further CNN training.</p>
<p>In conclusion, we present a novel application for unbiased morphological profiling by extending its use to complex mixed neural cultures using sequential multispectral imaging and convolutional network-informed cell phenotype classification. We show that the resulting predictors are robust with respect to biological variation and cell culture density. This method holds promise for use in quality control of iPSC cultures to allow their routine use in high-throughput and high-content screening applications.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Cell culture</title>
<p>Cells were cultured at 37 °C and 5% CO2. 1321N1 and SH-SY5Y cell lines were maintained in DMEM-F12 + Glutamax (Gibco, 10565018) supplemented with 10% Fetal Bovine Serum (Gibco, 10500064). Cell seeding prior to imaging was done in 96-well black multiwell plates with #1.5 glass-like polymer coverslip bottom (Cellvis, P96-1.5P). Only the inner 60 wells were used, while the outer wells were filled with PBS−/− to avoid plate effects. Plates were coated with Matrigel (Corning, 734-1440) After seeding, the imaging plate was centrifuged at 100g for 3min.</p>
<p>iPSCs (Sigma Aldrich, iPSC0028 Epithelial-1) were cultured on Matrigel (Corning, 734-1440) in Essential 8 medium (Gibco, A1517001). Upon cell thawing, Rock inhibitor (Y-27632 dichloride, MedChem, HY-10583) was added in 10µM concentration. Subculturing of iPSCs was performed with ReLeSR (Stemcell Technologies, 05872).</p>
<p>Unguided differentiation<sup><xref ref-type="bibr" rid="c25">25</xref></sup> of iPS cells to neural progenitor cells (NPCs) was started by subculturing the iPSCs single cell using Tryple Express Enzyme (Life technologies, 12605010) at a density of 10e4 cells/cm² in mTesR1 medium (Stemcell Technologies, 85850) and Rock inhibitor. The following day, differentiation to NPCs was started by dual SMAD inhibition in neural maintenance medium (1:1 Neurobasal (Life technologies, 21103049):DMEM-F12+Glutamax (Gibco, 10565018), 0.5× Glutamax (Gibco, 35-050-061), 0.5% Mem Non Essential Amino Acids Solution (Gibco, 11140050), 0.5% Sodium Pyruvate (Gibco, 11360070), 50 μM 2-Mercaptoethanol (Gibco, 31350010), 0.025% Human Insulin Solution (Sigma Aldrich, I9278), 0.5X N2 (Gibco, 17502048), B27 (Gibco, 17504044), 50 U/ml Penicillin-Streptomycin (Gibco, 15140122)) supplemented with 1 μM LDN-193189 (Miltenyi, 130-106-540), SB431542 (Tocris, 1614). Daily medium changes were performed for 11 consecutive days. Following neural induction, neural rosettes were selected by STEMdiff Neural Rosette Selection Reagent (Stemcell technologies, 05832). Maintenance of neural progenitor cells was performed in neural maintenance medium with 10 µM bFGF (Peprotech, 100-18C) added after subculturing. Single cell detachment of NPCs during maintenance was performed using Tryple Express Enzyme. Cell seeding prior to imaging is done in 96-well black multiwell plates µCLEAR (Greiner, 655090) coated with Poly-L-ornithine (Sigma-Aldrich, P4957) and laminin (Sigma-Aldrich, L2020). Only the inner 60 wells were used, while the outer wells were filled with PBS−/− to avoid plate effects. After seeding, the imaging plate was centrifuged at 100g for 3min.</p>
<p>Guided iPSC differentiation to neurons was performed according to Bell et al. (2019)<sup><xref ref-type="bibr" rid="c2">2</xref></sup>. The initial phase of neural induction consisted of 12 days neural induction medium (DMEM-F12+Glutamax (Gibco, 10565018), 1× N2 (Gibco, 17502048), 1× B27 (Gibco, 17504044),1mg/ml BSA (Sigma-Aldrich, A7979), 0.5% Mem Non-Essential Amino Acids Solution (Gibco, 11140050)). Of these 12 days, the first 7 were supplemented with cytokines for dual-SMAD inhibition (1 μM LDN-193189 (Miltenyi, 130-106-540), SB431542 (Tocris, 1614)). Following neural induction, the NPCs were floated in uncoated MW6 culture plates in NPC medium (DMEM-F12+Glutamax (Gibco, 10565018), 1× N2 (Gibco, 17502048), 1× B27 (Gibco, 17504044), 10 µM bFGF (Peprotech, 100-18C), 10 µM EGF (Peprotech, 100-47)). After 4 days, NPC clusters of appropriate size were filtered using a cell strainer ((37 µm cell strainer, Stemcell technologies, 27250) and plated on Matrigel-coated (Corning, 734-1440) MW6 culture plates. NPCs can now be expanded in NPC medium. Guided differentiation into forebrain neurons can be induced by switching to neuronal medium (BrainPhys (STEMCELL Technologies, 05792), 1× N2 (Gibco, 17502048), 1× B27 (Gibco, 17504044), 10 µM BDNF (PeproTech, AF-450-02), 10 µM GDNF (PeproTech, AF-450-02) for 15 days before fixation. Differentiation of iPSC to microglia<sup><xref ref-type="bibr" rid="c4">4</xref></sup> was performed by the formation of embroid bodies (EBs) with 10e3 iPSCs/well in a 96-well U-bottom plate (Corning, 351177) coated with Anti-Adherence Rinsing Solution (Stemcell technologies, 07010) in mTeSR medium supplemented with Rock inhibitor, 50 ng/mL BMP4 (Peprotech, 120-05), 50 ng/mL VEGF (Peprotech, 100-20), 20 ng/mL SCF (Peprotech, 250-03). 75% medium is changed for 4 consecutive days. After mesoderm induction, EBs are transferred to a 6-well plate with 20 EBs/well and placed in macrophage precursor medium (X-vivo15 (Lonza, BE02-060Q), 100 ng/mL M-CSF (Peprotech, 300-25), 25 ng/mL IL-3 (Peprotech, 213-13), 1× Glutamax, 50 U/ml Penicillin-Streptomycin, 50 μM 2-Mercaptoethanol). 14 days after macrophage differentiation, macrophage precursors were harvested using a cell strainer (Stemcell technologies, 27250). Macrophage precursors were added to the NPC culture in 1:1 neural maintenance medium:microglia medium ((DMEM-F12+Glutamax, 100 ng/mL M-CSF (Peprotech, 300-25), 100 ng/mL IL-34 (Peprotech, 200-34), 1× Glutamax, 50 U/ml Penicillin-Streptomycin, 50 μM 2-Mercaptoethanol).</p>
</sec>
<sec id="s4b">
<title>Replication labelling</title>
<p>Prior to co-seeding of 1321N1 and SH-SY5Y mixed cultures, individual cultures were incubated with either 10 µM EdU (Click-iT® EdU Imaging Kit, Life Technologies, C10340) or 10 µM BrdU (Sigma-Aldrich, B5002) for 24h. This incubation time exceeded the doubling time, allowing incorporation of the nucleotide analog in all cells. This labelling period was followed by a 24h washout period in regular cell culture medium. After washout, the cells were subcultured and plated in coculture. In half of the replicate, SH-SY5Y cells received BrdU while 1321N1 cells received EdU. For the remainder of wells, the pre-label switched cell types.</p>
</sec>
<sec id="s4c">
<title>Morphological staining</title>
<p>Morphological staining (Cell Painting) was adapted from Bray et al. 2016<sup><xref ref-type="bibr" rid="c13">13</xref></sup>. After careful titration, all dye concentrations were adjusted and evaluated for compatibility with 4-channel laser and filter combinations available on the confocal microscope (see further). Staining was performed on cell cultures fixed in 4% PFA (roti-histofix 4% paraformaldehyde, Roth, 3105.2) for 15min. Cells were rinsed once with PBS−/− (Life Technologies, 10010015) prior to fixation and 3× 5min post fixation. Staining solutions were prepared fresh before staining in PBS−/− with 0.3% Triton-X-100 (Sigma Aldrich, X100) (<bold><xref rid="tbl1" ref-type="table">Table 1</xref></bold>). Each staining solution was incubated for 30min on a shaker at RT in the dark. After staining, the cells were washed 1× with PBS −/− and sealed for imaging.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1</label>
<caption><title>|</title><p>Specifications of morphological staining composition.</p></caption>
<graphic xlink:href="574474v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s4d">
<title>Cyclic staining and immunocytochemistry</title>
<p>Cyclic staining is executed by fluorescence quenching after each sequential imaging round. 1mg/ml in ddH<sub>2</sub>O LiBH<sub>4</sub> solution<sup><xref ref-type="bibr" rid="c22">22</xref></sup> (Acros Organics, 206810050) was prepared fresh before use. 1.5h incubation of quenching solution was performed before each successive staining series. After incubation, the quenching solution was removed by washing 3× 5min in PBS-/-. Successful fluorescence quenching was microscopically verified before proceeding with immunofluorescence staining (IF) (<bold><xref rid="tbl2" ref-type="table">Table 2</xref></bold>). Cells are treated with PAV blocking buffer (Thimerosal 0.5% (Fluka, 71230), NaN3 0.1% (Merck, k 6688), Bovine serum albumin (Sigma-Aldrich, A7284), Normal horse serum, PBS-/-) for 8min. The desired primary antibodies (pAB) are diluted in PAV blocking buffer. pAB incubation was performed 12h (overnight) at 4°C after which the cells were washed 1× 5min in PBS−/− followed by incubation in secondary antibody solution (sAB) in PAV + DAPI for nuclear counterstain. sAB staining was performed for 3h at RT while shaking. Prior to imaging, the cells were washed 2× with PBS−/− and stored in PBS−/− + 0,1% NaN<sub>3</sub>.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2</label>
<caption><title>|</title><p>Used antibodies.</p></caption>
<graphic xlink:href="574474v1_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>BrdU staining was performed using IF, requiring DNA denaturation before pAB incubation. This was performed by 10 min incubation with 2N HCl at 37°C. HCl was neutralized with 0.1 M sodium borate buffer pH 8.5 for 30min at RT. Cells were washed 3× 5min in PBS−/− before continuing with the general IF protocol. EdU click-it labelling was performed according to the manufacturer’s instructions (Click-iT® EdU Imaging Kit, Life Technologies, C10340).</p>
</sec>
<sec id="s4e">
<title>Image acquisition</title>
<p>Images were acquired using a spinning disk confocal microscope (Nikon CSU-W1 SoRa) with a 20× 0.75 NA objective (Plan APO VC 20× DIC N2) and Kinetix sCMOS camera (pinhole 50µm; disk speed 4000 rpm; pinhole aperture 10; bit depth 12-bit, pixel size 0.325µm²). We opted for confocal microscopy instead of widefield to overcome image quality limitations resulting from highly dense cell clusters. 96-well plates were scanned, capturing a minimum of 16 images per well spread in a regular pattern (0,8 mm spacing in x and y) across the surface of the well. If multiple z-slices were acquired (to correct for surface inclinations in the field of view), a maximum projection was performed before further analysis. Morphological images were acquired in all 4 channels. (<bold><xref rid="tbl3" ref-type="table">Table 3</xref></bold>).</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3</label>
<caption><title>|</title><p>Specifications of the used laser lines, excitation and emission filters.</p></caption>
<graphic xlink:href="574474v1_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="574474v1_tbl3a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s4f">
<title>Software</title>
<p>Images were captured by the Nikon CSU-W1 confocal system in combination with the NIS elements software (RRID:SCR_014329). Image visualization was later performed using Fiji freeware<sup><xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c37">37</xref></sup>. In-depth image analysis, pre-processing and machine learning for cell classification were performed using Python programming language<sup><xref ref-type="bibr" rid="c38">38</xref></sup> in combination with Anaconda<sup><xref ref-type="bibr" rid="c39">39</xref></sup> (distribution and package managing software) and Visual Studio Code (code editor). The packages and versions used for data analysis are shown in <bold><xref rid="tbl4" ref-type="table">Table 4</xref></bold>.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4</label>
<caption><title>|</title><p>Python packages used for image and data analysis alongside the software version.</p></caption>
<graphic xlink:href="574474v1_tbl4.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="574474v1_tbl4a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s4g">
<title>Image pre-processing</title>
<sec id="s4g1">
<title>Cell/nuclear segmentation</title>
<p>Using a tailor-made script implementing the Cellpose<sup><xref ref-type="bibr" rid="c40">40</xref></sup> (cell segmentation) or StarDist<sup><xref ref-type="bibr" rid="c41">41</xref></sup> (nuclear segmentation) package, images were pre-processed by normalizing the intensity values of each channel between the 1st and 99th quantile. Individual channels or channel combinations for segmentation can be selected depending on the desired outcome mask. Resulting outputs included the segmentation mask alongside the quality control images. For Stardist implementation, hyperparameter probability was set at 0,6 and overlap at 0,3. For Cellpose segmentation, 4 models (cyto2) were averaged to obtain the final mask. Segmentation was performed on the composite of all CP channels. An estimation of the cell’s diameter could be included to optimize cell detection.</p>
</sec>
<sec id="s4g2">
<title>Ground truth alignment</title>
<p>Following sequential staining and imaging rounds, multiple images were captured representing the same cell with different markers. All images were aligned using Fourier-based image cross correlation on the intensity-normalized multichannel images. The alignment shift between image1 and image2 was determined using scikit-image phase cross correlation. Image2 was then moved according to the predetermined shift to align morphological with ground truth images.</p>
</sec>
<sec id="s4g3">
<title>Ground truth phenotyping</title>
<p>The true cell phenotype was determined by the fluorescence intensity of the post-hoc immunostaining with class-specific markers. Each ground truth image was imported alongside the corresponding cell mask for that image. For each cell label, the fluorescence intensity was determined and tabulated. The threshold was set manually based on the fluorescence intensity of the monoculture controls. Ground truth labels were assigned to each region of interest (ROI).</p>
</sec>
<sec id="s4g4">
<title>Data filtering</title>
<p>Over the entire pipeline, ROIs could be discarded based on 3 conditions: (1) Cell detachment. Due to the harsh sample preparation and repeated washing steps, cells could detach from the imaging substrate thus resulting in lack of ground truth information for those cells. As a result, all ROIs for which there was no DAPI signal detected in the ground truth image, were removed from the dataset as incomplete. (2) Cells for which the ground truth fluorescence intensity was ambiguous. Ground truth labels were determined based on the presence of specific IF staining in either of the phenotype classes. If no class-specific IF staining was detected by thresholding, no true label could be assigned. These ROIs were therefore discarded due to uncertainty. (3) Likelihood of faulty ROI detection. The DAPI signal was used to discard ROIs that do not represent (complete) cells by thresholding on minimal DAPI intensity and minimal nuclear size.</p>
</sec>
</sec>
<sec id="s4h">
<title>ROI classification</title>
<sec id="s4h1">
<title>Train-validation-test split</title>
<p>Model training requires splitting the available data in 3 subsets: training (60%), validation (10%), and testing (30%). The training dataset was used to train the machine learning models (either RF or CNN). The validation dataset, composing of 10% of the total data, was used to determine the hyperparameters and intermediate testing. The remaining 30% of the dataset was kept apart and used to test the final model when training is completed. For both RF and CNN, the testing dataset was never shown to the model during the training phase, but only used after training to determine the accuracy of predictions to the ground truth. The number of instances for each class was equalized by sampling equal number of instances from each predicted class. To account for variation between technical replicates, the train-validation-test split was stratified per well. As a result, no datapoints arising from the same well could appear simultaneously in the training, validation and testing subset. This data stratification was repeated 3 times with different random seeds (see Methods – Reproducibility).</p>
</sec>
<sec id="s4h2">
<title>Random Forest</title>
<p>For each ROI, a set of manually defined parameters was extracted corresponding to cell shape (area, convex area, filled area, length minor axis, length major axis, centroid, eccentricity, equivalent diameter area, ferret diameter max, orientation, perimeter), texture (GLCM: contrast, dissimilarity, homogeneity, energy, correlation, ASM), intensity (maximal intensity, minimal intensity, mean intensity, standard deviation intensity) and distribution (solidity). This was done for 3 regions (nucleus, cytoplasm and complete cell), and for all channel dimensions. Redundant parameters were removed. All parameters were standardized per ROI, grouped per replicate. The number of trees within the forest was varied between 10 and 150, reaching maximum accuracy at around 30 trees.</p>
</sec>
<sec id="s4h3">
<title>Uniform Manifold Approximation and Projection</title>
<p>Dimensionality reduction using UMAP was performed on the same feature matrix as used for RF prediction. Hyperparameters were set at the default settings.</p>
</sec>
<sec id="s4h4">
<title>Convolutional neural network</title>
<p>A ResNet50 model was trained for image classification. In contrast to classical machine learning techniques, no handcrafted features were extracted. Cell crops (60µm whole cell – 15µm nucleocentric/nuclear area) were defined based on the segmentation mask for each ROI. Each ROI was cropped out of the original morphological image and associated with metadata corresponding to its ground truth label. Images alongside their labels were fed to the network. Tensors were normalized per channel. Models are trained on a minimum of 5000 training inputs of each class for 50 epochs (training iterations). Each batch consisted of 100 samples. The training input was augmented by linear transformations (horizontal and vertical flip, random rotation). Each epoch, the current model was tested against a validation dataset. The performance of the model on this validation subset determined whether the model was stored as new best (if the new accuracy exceeded the accuracy of the previous best model) or discarded. The learning rate at the start was set at 0,0001 and automatically reduced with a factor of 0,1 during training when no improvement was seen after 10 epochs. After 50 epochs, the best resulting model was tested on a separate test dataset to determine the accuracy on previously unseen data.</p>
</sec>
</sec>
<sec id="s4i">
<title>Reproducibility</title>
<p>Each model training was performed 3 independent times. This was repeated for 3 different random seeds. Each model received input data arising from a minimum of 16 images per well, at least 15 technical replicates (wells). The optimization experiments (<xref rid="fig1" ref-type="fig">figures 1</xref>-<xref rid="fig4" ref-type="fig">4</xref>) were performed with cell lines with limited variability. These models were trained on 3 independent experiments where ground truth pre-labelling (Edu/BrdU) was performed at least once on either of the cell lines in coculture. For iPSC-derived cultures, as variability is inherent to these differentiations, 3 biological replicates (independent differentiations) were pooled for model training.</p>
</sec>
<sec id="s4j">
<title>Statistics</title>
<p>All statistical comparisons were made nonparametric using Mann-Whitney U (for two independent sample comparison) or Kruskal-Wallis (for multiple sample comparison) with pairwise tests using Tukey’s honestly significant difference test. We opted for nonparametric testing because the number of models in each group to be compared was &lt; 15. Significance levels are indicated on the figures using ns. (no statistical significance, p-value above 0,05), * (p-value between 0,05 and 5e-4), ** (p-value between 5e-4 and 5e-6) and *** (p-value smaller than 5e-6).</p>
</sec>
<sec id="s4k">
<title>Funding</title>
<p>This work was funded by Fonds Wetenschappelijk Onderzoek Vlaanderen (1SB7423N; 1274822N), BOF (FFB210009) and IOF Uantwerpen (FFI210239; FFI230099) and VLAIO (HBC.2023.0155).</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We thank Marlies Verschuuren and Hugo Steenberghen for their assistance and knowledge regarding the cell lines. By extension, we would like to thank all current and former members of the De Vos lab.</p>
</ack>
<sec id="s5">
<title>Data availability statement</title>
<p>The authors report that the results of this study are available within the manuscript and supplementary materials. All image analysis scripts are open-source available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/DeVosLab">https://github.com/DeVosLab</ext-link>)</p>
</sec>
<sec id="s6">
<title>Conflict of interest</title>
<p>The authors declare no conflict of interest.</p>
</sec>
<sec id="s7">
<title>Abbreviations</title>
<p>BrdU: Bromodeoxyuridine; CNN: convolutional neural network; CP: cell painting; DAPI: 4’,6-diamidino-2-fenylindool; DIV: days in vitro; EdU: 5-ethynyl-2’-deoxyuridine; ER: endoplasmic reticulum; Grad-CAM: Gradient-weighted Class Activation Mapping; IF: immunofluorescence; iPSC: induced pluripotent stem cell; NPC: neural progenitor cell; RF: random forest; ROI: region of interest; TUBB3: beta-III-tubulin; UMAP: Uniform Manifold Approximation and Projection</p>
</sec>
<sec id="s8">
<title>Author contributions</title>
<p>The experiments were conceptualized by SDB, TVDL, JVDD, PP and WDV. Experiments were executed by SDB and JVDD. TVDL and SDB optimized the data analysis scripts. SDB analysed the imaging data and performed the data analysis. SDB and WDV prepared the original draft. PP and WDV supervised the work. All authors took part in reviewing and editing the manuscript.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>De Strooper</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Karran</surname>, <given-names>E</given-names></string-name>. <article-title>The Cellular Phase of Alzheimer’s Disease</article-title>. <source>Cell</source> <volume>164</volume>, <fpage>603</fpage>–<lpage>615</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Bell</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <article-title>Differentiation of Human Induced Pluripotent Stem Cells (iPSCs) into an Effective Model of Forebrain Neural Progenitor Cells and Mature Neurons</article-title>. <source>BIO-PROTOCOL</source> <volume>9</volume>, (<year>2019</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Neyrinck</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal> <article-title>SOX9-induced Generation of Functional Astrocytes Supporting Neuronal Maturation in an All-human System</article-title>. <source>Stem Cell Rev and Rep</source> <volume>17</volume>, <fpage>1855</fpage>–<lpage>1873</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Haenseler</surname>, <given-names>W.</given-names></string-name> <etal>et al.</etal> <article-title>A Highly Efficient Human Pluripotent Stem Cell Microglia Model Displays a Neuronal-Co-culture-Specific Expression Profile and Inflammatory Response</article-title>. <source>Stem Cell Reports</source> <volume>8</volume>, <fpage>1727</fpage>–<lpage>1742</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Nevin</surname>, <given-names>Z. S.</given-names></string-name> <etal>et al.</etal> <article-title>Modeling the Mutational and Phenotypic Landscapes of Pelizaeus-Merzbacher Disease with Human iPSC-Derived Oligodendrocytes</article-title>. <source>The American Journal of Human Genetics</source> <volume>100</volume>, <fpage>617</fpage>–<lpage>634</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Abutaleb</surname>, <given-names>N. O.</given-names></string-name> &amp; <string-name><surname>Truskey</surname>, <given-names>G. A</given-names></string-name>. <article-title>Differentiation and characterization of human iPSC-derived vascular endothelial cells under physiological shear stress</article-title>. <source>STAR Protocols</source> <volume>2</volume>, <issue>100394</issue> (<year>2021</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Paik</surname>, <given-names>D. T.</given-names></string-name>, <string-name><surname>Chandy</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Wu</surname>, <given-names>J. C</given-names></string-name>. <article-title>Patient and Disease–Specific Induced Pluripotent Stem Cells for Discovery of Personalized Cardiovascular Drugs and Therapeutics</article-title>. <source>Pharmacol Rev</source> <volume>72</volume>, <fpage>320</fpage>–<lpage>342</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Lopez-Gonzalez</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal> <article-title>Poly(GR) in C9ORF72 –Related ALS/FTD Compromises Mitochondrial Function and Increases Oxidative Stress and DNA Damage in iPSC-Derived Motor Neurons</article-title>. <source>Neuron</source> <volume>92</volume>, <fpage>383</fpage>– <lpage>391</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Amin</surname>, <given-names>N. D.</given-names></string-name> &amp; <string-name><surname>Paşca</surname>, <given-names>S. P</given-names></string-name>. <article-title>Building Models of Brain Disorders with Three-Dimensional Organoids</article-title>. <source>Neuron</source> <volume>100</volume>, <fpage>389</fpage>–<lpage>405</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>D’Antonio</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>High-Throughput and Cost-Effective Characterization of Induced Pluripotent Stem Cells</article-title>. <source>Stem Cell Reports</source> <volume>8</volume>, <fpage>1101</fpage>–<lpage>1111</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="preprint"><string-name><surname>Chen</surname>, <given-names>C. X.-Q.</given-names></string-name>, <etal>et al.</etal> <article-title>Standardized quality control workflow to evaluate the reproducibility and differentiation potential of human iPSCs into neurons</article-title> <source>bioRxiv</source>. 10.1101/2021.01.13.426620 (<year>2021</year>) doi:<pub-id pub-id-type="doi">10.1101/2021.01.13.426620</pub-id>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Gustafsdottir</surname>, <given-names>S. M.</given-names></string-name> <etal>et al.</etal> <article-title>Multiplex Cytological Profiling Assay to Measure Diverse Cellular States</article-title>. <source>PLoS ONE</source> <volume>8</volume>, <fpage>e80999</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Bray</surname>, <given-names>M.-A.</given-names></string-name> <etal>et al.</etal> <article-title>Cell Painting, a high-content image-based assay for morphological profiling using multiplexed fluorescent dyes</article-title>. <source>Nat Protoc</source> <volume>11</volume>, <fpage>1757</fpage>–<lpage>1774</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Cimini</surname>, <given-names>B. A.</given-names></string-name> <etal>et al.</etal> <article-title>Optimizing the Cell Painting assay for image-based profiling</article-title>. <source>Nat Protoc</source> <volume>18</volume>, <fpage>1981</fpage>– <lpage>2013</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Way</surname>, <given-names>G. P.</given-names></string-name> <etal>et al.</etal> <article-title>Predicting cell health phenotypes using image-based morphology profiling</article-title>. <source>MBoC</source> <volume>32</volume>, <fpage>995</fpage>–<lpage>1005</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Schiff</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal> <article-title>Integrating deep learning and unbiased automated high-content screening to identify complex disease signatures in human fibroblasts</article-title>. <source>Nat Commun</source> <volume>13</volume>, <fpage>1590</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="preprint"><string-name><surname>Chandrasekaran</surname>, <given-names>S. N.</given-names></string-name> <etal>et al.</etal> <article-title>JUMP Cell Painting dataset: morphological impact of 136,000 chemical and genetic perturbations</article-title> <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2023.03.23.534023</pub-id> (<year>2023</year>) doi: 10.1101/2023.03.23.534023.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="preprint"><string-name><surname>McInnes</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Healy</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Melville</surname>, <given-names>J.</given-names></string-name> <article-title>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</article-title> <source>arXiv</source>. (<year>2018</year>) doi:<pub-id pub-id-type="doi">10.48550/ARXIV.1802.03426</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Nguyen</surname>, <given-names>T.-T.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>J. Z.</given-names></string-name> &amp; <string-name><surname>Nguyen</surname>, <given-names>T. T</given-names></string-name>. <article-title>Unbiased Feature Selection in Learning Random Forests for High-Dimensional Data</article-title>. <source>The Scientific World Journal</source> <volume>2015</volume>, <fpage>1</fpage>–<lpage>18</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>He</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Ren</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Sun</surname>, <given-names>J</given-names></string-name>. <article-title>Deep Residual Learning for Image Recognition</article-title>. <source>Preprint at</source> <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1512.03385">http://arxiv.org/abs/1512.03385</ext-link> (<year>2015</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Selvaraju</surname>, <given-names>R. R.</given-names></string-name> <etal>et al.</etal> <article-title>Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization</article-title>. <source>Int J Comput Vis</source> <volume>128</volume>, <fpage>336</fpage>–<lpage>359</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Radtke</surname>, <given-names>A. J.</given-names></string-name> <etal>et al.</etal> <article-title>IBEX: an iterative immunolabeling and chemical bleaching method for high-content imaging of diverse tissues</article-title>. <source>Nat Protoc</source> <volume>17</volume>, <fpage>378</fpage>–<lpage>401</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Hernández</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal> <article-title>Culture Variabilities of Human iPSC-Derived Cerebral Organoids Are a Major Issue for the Modelling of Phenotypes Observed in Alzheimer’s Disease</article-title>. <source>Stem Cell Rev and Rep</source> <volume>18</volume>, <fpage>718</fpage>–<lpage>731</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Volpato</surname>, <given-names>V.</given-names></string-name> &amp; <string-name><surname>Webber</surname>, <given-names>C</given-names></string-name>. <article-title>Addressing variability in iPSC-derived models of human disease: guidelines to promote reproducibility</article-title>. <source>Disease Models &amp; Mechanisms</source> <volume>13</volume>, <fpage>dmm042317</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Shi</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Kirwan</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Livesey</surname>, <given-names>F. J</given-names></string-name>. <article-title>Directed differentiation of human pluripotent stem cells to cerebral cortex neurons and neural networks</article-title>. <source>Nat Protoc</source> <volume>7</volume>, <fpage>1836</fpage>–<lpage>1846</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Kuijlaars</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal> <article-title>Sustained synchronized neuronal network activity in a human astrocyte co-culture system</article-title>. <source>Sci Rep</source> <volume>6</volume>, <fpage>36529</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="preprint"><string-name><surname>Dincer</surname>, <given-names>A. B.</given-names></string-name>, <string-name><surname>Celik</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hiranuma</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Lee</surname>, <given-names>S.-I</given-names></string-name>. <article-title>DeepProfile: Deep learning of cancer molecular profiles for precision medicine</article-title> <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/278739</pub-id> (<year>2018</year>) doi:10.1101/278739.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>De Vos</surname>, <given-names>W. H.</given-names></string-name> <etal>et al.</etal> <article-title>Increased plasticity of the nuclear envelope and hypermobility of telomeres due to the loss of A–type lamins</article-title>. <source>Biochimica et Biophysica Acta (BBA) – General Subjects</source> <volume>1800</volume>, <fpage>448</fpage>–<lpage>458</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Heckenbach</surname>, <given-names>I.</given-names></string-name> <etal>et al.</etal> <article-title>Nuclear morphology is a deep learning biomarker of cellular senescence</article-title>. <source>Nat Aging</source> <volume>2</volume>, <fpage>742</fpage>–<lpage>755</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Mikolajczyk</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Grochowski</surname>, <given-names>M.</given-names></string-name> <article-title>Data augmentation for improving deep learning in image classification problem</article-title><source>. in 2018 International Interdisciplinary PhD Workshop (IIPhDW)</source> <fpage>117</fpage>–<lpage>122</lpage> (IEEE, <year>2018</year>). doi:<pub-id pub-id-type="doi">10.1109/IIPHDW.2018.8388338</pub-id>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Nguyen</surname>, <given-names>L. D.</given-names></string-name>, <string-name><surname>Lin</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Lin</surname>, <given-names>Z.</given-names></string-name> &amp; <string-name><surname>Cao</surname>, <given-names>J.</given-names></string-name> <article-title>Deep CNNs for microscopic image classification by exploiting transfer learning and feature concatenation</article-title><source>. in 2018 IEEE International Symposium on Circuits and Systems (ISCAS)</source> <fpage>1</fpage>–<lpage>5</lpage> (IEEE, <year>2018</year>). doi:<pub-id pub-id-type="doi">10.1109/ISCAS.2018.8351550</pub-id>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Tomov</surname>, <given-names>M. L.</given-names></string-name> <etal>et al.</etal> <article-title>Resolving cell state in iPSC-derived human neural samples with multiplexed fluorescence imaging</article-title>. <source>Commun Biol</source> <volume>4</volume>, <fpage>786</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Strano</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Tuck</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Stubbs</surname>, <given-names>V. E.</given-names></string-name> &amp; <string-name><surname>Livesey</surname>, <given-names>F. J</given-names></string-name>. <article-title>Variable Outcomes in Neural Differentiation of Human PSCs Arise from Intrinsic Differences in Developmental Signaling Pathways</article-title>. <source>Cell Reports</source> <volume>31</volume>, <fpage>107732</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Galiakberova</surname>, <given-names>A. A.</given-names></string-name> <etal>et al.</etal> <article-title>Different iPSC-derived neural stem cells shows various spectrums of spontaneous differentiation during long term cultivation</article-title>. <source>Front. Mol. Neurosci</source>. <volume>16</volume>, <fpage>1037902</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Du</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Xu</surname>, <given-names>Y</given-names></string-name>. <article-title>Hierarchical deep neural network for multivariate regression</article-title>. <source>Pattern Recognition</source> <volume>63</volume>, <fpage>149</fpage>–<lpage>157</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Rueden</surname>, <given-names>C. T.</given-names></string-name> <etal>et al.</etal> <article-title>ImageJ2: ImageJ for the next generation of scientific image data</article-title>. <source>BMC Bioinformatics</source> <volume>18</volume>, <fpage>529</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Schindelin</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Rueden</surname>, <given-names>C. T.</given-names></string-name>, <string-name><surname>Hiner</surname>, <given-names>M. C.</given-names></string-name> &amp; <string-name><surname>Eliceiri</surname>, <given-names>K. W</given-names></string-name>. <article-title>The ImageJ ecosystem: An open platform for biomedical image analysis</article-title>. <source>Molecular Reproduction Devel</source> <volume>82</volume>, <fpage>518</fpage>–<lpage>529</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c38"><label>37.</label><mixed-citation publication-type="other"><string-name><surname>Van Rossum</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Drake</surname>, <given-names>F. L.</given-names></string-name> <source>Python 3 Reference Manual</source>. (<year>2009</year>).</mixed-citation></ref>
<ref id="c39"><label>38.</label><mixed-citation publication-type="other"><collab>Anaconda Software Distribution</collab>. <source>Anaconda Documentation</source>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Stringer</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Michaelos</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Pachitariu</surname>, <given-names>M</given-names></string-name>. <article-title>Cellpose: a generalist algorithm for cellular segmentation</article-title>. <source>Nat Methods</source> <volume>18</volume>, <fpage>100</fpage>–<lpage>106</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Weigert</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Schmidt</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Haase</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Sugawara</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Myers</surname>, <given-names>G.</given-names></string-name> <article-title>Star-convex Polyhedra for 3D Object Detection and Segmentation in Microscopy</article-title>. in <source>2020 IEEE Winter Conference on Applications of Computer Vision (WACV)</source> <fpage>3655</fpage>–<lpage>3662</lpage> (IEEE, <year>2020</year>). doi:<pub-id pub-id-type="doi">10.1109/WACV45572.2020.9093435</pub-id>.</mixed-citation></ref>
</ref-list>
<sec id="s9">
<p>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary figure 1</label>
<caption><title>| The influence of cell density on segmentation quantity and quality.</title>
<p>(A) Representative images of 1321N1 cells with increasing density alongside their cell and nuclear mask produced using resp. Cellpose and Stardist. (B) the number of ROIs detected in comparison to the ground truth (manual segmentation) (determined as intersection over union (IoU) &lt; 0,15). (C) ROI detection quality (IoU) for increasing cell density for cell and nuclear masks.</p></caption>
<graphic xlink:href="574474v1_figs1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary figure 2</label>
<caption><title>| Fluorescence quenching over time using LiBH4.</title>
<p>(A) Images before and after quenching for all 4 fluorescence channels. (B) Time curve of normalized image-level fluorescence intensity during incubation with 1mg/ml LiBH4.</p></caption>
<graphic xlink:href="574474v1_figs2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary figure 3</label>
<caption><title>| Methods.</title>
<p>(A) Pipeline used for morphological profiling in mixed cultures. (B) Overview of the steps within the image analysis pipeline. (C) Evaluation of accuracy, true negative and true positive rate during CNN training (1321N1 vs. SH-SY5Y in monocultures) across all 50 epochs.</p></caption>
<graphic xlink:href="574474v1_figs3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary figure 4</label>
<caption><title>| Additional figures.</title>
<p>(A) PCA dimension reduction on handcrafted features extracted from monocultures of 1321N1 and SH-SY5Y cells. In contrast to UMAP dimension reduction, this linear approach does not result in clear cell type clustering. (B) Examples of misclassified ROIs. (C) Definition of cell regions given as training input for nuclear and nucleocentric model training. (D) Decreasing nuclear area in function of culture density. (E) Evaluation of cell phenotype prediction on an image of differentiating neurons (guided differentiation). The predicted phenotype is shown by the color of the square around each ROI. The distinctive phenotype is shown in the insets. (F) Additional GradCAM images for both cell type classes. (G) Predicted neuron-to-NPC ratio in spontaneously differentiating cultures as predicted by the condition-based classifier (<xref rid="fig5" ref-type="fig">Fig. 5E</xref>) in contrast to the cell-based classifier performance on the same dataset (<xref rid="fig5" ref-type="fig">Fig. 5H</xref>).</p></caption>
<graphic xlink:href="574474v1_figs4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</p>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95273.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Zaritsky</surname>
<given-names>Assaf</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Ben-Gurion University of the Negev</institution>
</institution-wrap>
<city>Beer Sheva</city>
<country>Israel</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents an <bold>important</bold> application of high-content image-based morphological profiling to quantitatively and systematically characterize induced pluripotent stem cell-derived mixed neural cultures cell type compositions. <bold>Convincing</bold> evidence through rigorous experimental and computational validations supports new potential applications of this cheap and simple assay.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95273.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors present a new application of the high-content image-based morphological profiling Cell Painting (CP) to single cell type classification in mixed heterogeneous induced pluripotent stem cell-derived mixed neural cultures. Machine learning models were trained to classify single cell types according to either &quot;engineered&quot; features derived from the image or from the raw CP multiplexed image. The authors systematically evaluated experimental (e.g., cell density, cell types, fluorescent channels) and computational (e.g., different models, different cell regions) parameters and convincingly demonstrated that focusing on the nucleus and its surroundings contains sufficient information for robust and accurate cell type classification. Models that were trained on mono-cultures (i.e., containing a single cell type) could generalize for cell type prediction in mixed co-cultures, and describe intermediate states of the maturation process of iPSC-derived neural progenitors to differentiation neurons.</p>
<p>Strengths:</p>
<p>Automatically identifying single-cell types in heterogeneous mixed-cell populations holds great promise to characterize mixed-cell populations and to discover new rules of spatial organization and cell-cell communication. Although the current manuscript focuses on the application of quality control of iPSC cultures, the same approach can be extended to a wealth of other applications including an in-depth study of the spatial context. The simple and high-content assay democratizes use and enables adoption by other labs.</p>
<p>The manuscript is supported by comprehensive experimental and computational validations that raise the bar beyond the current state of the art in the field of high-content phenotyping and make this manuscript especially compelling. These include (i) Explicitly assessing replication biases (batch effects); (ii) Direct comparison of feature-based (a la cell profiling) versus deep-learning-based classification (which is not trivial/obvious for the application of cell profiling); (iii) Systematic assessment of the contribution of each fluorescent channel; (iv) Evaluation of cell-density dependency; (v) Explicit examination of mistakes in classification; (vi) Evaluating the performance of different spatial contexts around the cell/nucleus; (vii) Generalization of models trained on cultures containing a single cell type (mono-cultures) to mixed co-cultures; (viii) Application to multiple classification tasks.</p>
<p>I especially liked the generalization of classification from mono- to co-cultures (Figure 4C), and quantitatively following the gradual transition from NPC to Neurons (Figure 5H).</p>
<p>The manuscript is well-written and easy to follow.</p>
<p>Weaknesses:</p>
<p>I am not certain how useful/important the specific application demonstrated in this study is (quality control of iPSC cultures), this could be better explained in the manuscript. Another issue that I feel should be discussed more explicitly is how far can this application go - how sensitively can the combination of cell painting and machine learning discriminate between cell types that are more subtly morphologically different from one another?</p>
<p>Regarding evaluations, the use of accuracy, which is a measure that can be biased by class imbalance, is not the most appropriate measurement in my opinion. The confusion matrices are a great help, but I would recommend using a measurement that is less sensitive for class imbalance for cell-type classification performance evaluations. Another issue is that the performance evaluation is calculated on a subset of the full cell population - after exclusion/filtering. Could there be a bias toward specific cell types in the exclusion criteria? How would it affect our ability to measure the cell type composition of the population?</p>
<p>I am not entirely convinced by the arguments regarding the superiority of the nucleocentric vs. the nuclear representations. Could it be that this improvement is due to not being sensitive/ influenced by nucleus segmentation errors?</p>
<p>GRADCAM shows cherry-picked examples and is not very convincing.</p>
<p>There are many missing details in the figure panels, figure legend, and text that would help the reader to better appreciate some of the technical details, see details in the section on recommendations for the authors.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95273.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This study uses an AI-based image analysis approach to classify different cell types in cultures of different densities. The authors could demonstrate the superiority of the CNN strategy used with nucleocentric cell profiling approach for a variety of cell types classification.</p>
<p>The paper is very clear and well-written. I just have a couple of minor suggestions and clarifications needed for the reader.</p>
<p>The entire prediction model is based on image analysis. Could the authors discuss the minimal spatial resolution of images required to allow a good prediction? Along the same line, it would be interesting to the reader to know which metrics related to image quality (e.g. signal to noise ratio) allow a good accuracy of the prediction.</p>
<p>The authors show that nucleocentric-based cell feature extraction is superior to feeding the CNN-based model for cell type prediction. Could they discuss what is the optimal size and shape of this ROI to ensure a good prediction? What if, for example, you increase or decrease the size of the ROI by a certain number of pixels?</p>
<p>It would be interesting for the reader to know the number of ROI used to feed each model and know the minimal amount of data necessary to reach a high level of accuracy in the predictions.</p>
<p>From Figure 1 to Figure 4 the author shows that CNN based approach is efficient in distinguishing 1321N1 vs SH-SY5Y cell lines. The last two figures are dedicated to showing 2 different applications of the techniques: identification of different stages of neuronal differentiation (Figure 5) and different cell types (neurons, microglia, and astrocytes) in Figure 6.</p>
<p>It would be interesting, for these 2 two cases as well, to assess the superiority of the CNN-based approach compared to the more classical Random Forest classification. This would reinforce the universal value of the method proposed.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95273.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Induced pluripotent stem cells, or iPSCs, are cells that scientists can push to become new, more mature cell types like neurons. iPSCs have a high potential to transform how scientists study disease by combining precision medicine gene editing with processes known as high-content imaging and drug screening. However, there are many challenges that must be overcome to realize this overall goal. The authors of this paper solve one of these challenges: predicting cell types that might result from potentially inefficient and unpredictable differentiation protocols. These predictions can then help optimize protocols.</p>
<p>The authors train advanced computational algorithms to predict single-cell types directly from microscopy images. The authors also test their approach in a variety of scenarios that one may encounter in the lab, including when cells divide quickly and crowd each other in a plate. Importantly, the authors suggest that providing their algorithms with just the right amount of information beyond the cells' nuclei is the best approach to overcome issues with cell crowding.</p>
<p>The work provides many well-controlled experiments to support the authors' conclusions. However, there are two primary concerns: (1) The model may be relying too heavily on the background and thus technical artifacts (instead of the cells) for making CNN-based predictions, and (2) the conclusion that their nucleocentric approach (including a small area beyond the nucleus) is not well supported, and may just be better by random chance. If the authors were to address these two concerns (through additional experimentation), then the work may influence how the field performs cell profiling in the future.</p>
<p>Additionally, the impact of this work will be limited, given the authors do not provide a specific link to the public source code that they used to process and analyze their data.</p>
</body>
</sub-article>
</article>