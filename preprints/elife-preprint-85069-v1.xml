<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">85069</article-id>
<article-id pub-id-type="doi">10.7554/eLife.85069</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.85069.1</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Mega-scale movie-fields in the mouse visuo-hippocampal network</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Purandare</surname>
<given-names>Chinmay S.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
<xref ref-type="author-notes" rid="n2">✉</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2005-2468</contrib-id>
<name>
<surname>Mehta</surname>
<given-names>Mayank R.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="author-notes" rid="n2">✉</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Bioengineering, UCLA</institution>, Los Angeles, CA, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>W.M. Keck Center for Neurophysics, Department of Physics and Astronomy, UCLA</institution>, Los Angeles, CA, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>Department of Neurology, UCLA</institution>, Los Angeles, CA, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution>Department of Electrical and Computer Engineering, UCLA</institution>, Los Angeles, CA, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label> Corresponding author; email: <email>mayankmehta@ucla.edu</email></corresp>
<fn id="n1" fn-type="present-address"><label>†</label><p>Department of Physiology, UCSF, San Francisco, CA, USA</p></fn>
<fn id="n2" fn-type="others"><label>✉</label><p>e-mail: <email>chinmay.purandare@gmail.com</email>, <email>MayankMehta@ucla.edu</email></p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-02-14">
<day>14</day>
<month>02</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP85069</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2022-12-07">
<day>07</day>
<month>12</month>
<year>2022</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2022-12-07">
<day>07</day>
<month>12</month>
<year>2022</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.12.07.519455"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Purandare &amp; Mehta</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Purandare &amp; Mehta</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-85069-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Natural behavior often involves a continuous series of related images, often while the subject is immobile. How is this information processed across the cortico-hippocampal circuit? The hippocampus is crucial for episodic memory<sup><xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c3">3</xref></sup>, but most rodent single unit studies require spatial exploration<sup><xref ref-type="bibr" rid="c4">4</xref>–<xref ref-type="bibr" rid="c6">6</xref></sup> or active engagement<sup><xref ref-type="bibr" rid="c7">7</xref></sup>. Hence, we investigated neural responses to a silent, iso-luminant, black and white movie in head-fixed mice without any task or locomotion demands, or rewards. The activity of most neurons (97%, 6554/6785) in the thalamo-cortical visual areas was significantly modulated by the 30s long movie clip. Surprisingly, a third (33%, 3379/10263) of hippocampal –dentate gyrus, CA1 and subiculum– neurons showed movie-selectivity, with elevated firing in specific movie sub-segments, termed movie-fields. On average, a cell had more than 5 movie-fields in visual areas, but only 2 in hippocampal areas. The movie-field durations in all brain regions spanned an unprecedented 1000-fold range: from 0.02s to 20s, termed mega-scale coding. Yet, the total duration of all the movie-fields of a cell was comparable across neurons and brain regions, partly due to broader movie-fields in hippocampal areas, indicating greater sequence coding. Consistently presentation of the movie images in a scrambled sequence virtually abolished hippocampal but not visual-cortical selectivity. The enhancement of sequential movie tuning compared to the scrambled sequence was eight-fold greater in hippocampal than visual areas, further supporting visual sequence encoding. Thus, a movie was encoded in all mouse-brain areas investigated. Similar results are likely to hold in primates and humans. Hence, movies could provide a unified way to probe neural mechanisms of non-spatial information processing and memory across brain regions and species.</p>
</abstract>
<counts>
<page-count count="33"/>
</counts>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>In addition to the position and orientation of simple visual cues, like Gabor patches and drifting gratings<sup><xref ref-type="bibr" rid="c8">8</xref></sup>, primary visual cortical responses are also direction selective<sup><xref ref-type="bibr" rid="c9">9</xref></sup>, and show predictive coding<sup><xref ref-type="bibr" rid="c10">10</xref></sup>, suggesting that the temporal sequence of visual cues influences neural firing. Accordingly, these and higher visual cortical neurons also encode a sequence of visual images, i.e., a movie<sup><xref ref-type="bibr" rid="c11">11</xref>–<xref ref-type="bibr" rid="c13">13</xref></sup>. The hippocampus is farthest downstream from the retina in the visual circuit. The rodent hippocampal place cells encode spatial or temporal sequences<sup><xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c14">14</xref>–<xref ref-type="bibr" rid="c21">21</xref></sup> and episode-like responses<sup><xref ref-type="bibr" rid="c22">22</xref>–<xref ref-type="bibr" rid="c24">24</xref></sup>. However, these responses typically require active locomotion<sup><xref ref-type="bibr" rid="c25">25</xref></sup>, and they are thought to be non-sensory responses<sup><xref ref-type="bibr" rid="c26">26</xref></sup>. Primate and human hippocampal responses are selective to specific sets of visual cues, e.g., the object-place association<sup><xref ref-type="bibr" rid="c27">27</xref></sup>, their short-term<sup><xref ref-type="bibr" rid="c1">1</xref></sup> and long-term<sup><xref ref-type="bibr" rid="c28">28</xref></sup> memories, cognitive boundaries between episodic movies<sup><xref ref-type="bibr" rid="c29">29</xref></sup>, and event integration for narrative association<sup><xref ref-type="bibr" rid="c30">30</xref></sup>. However, despite strong evidence for hippocampal role in episodic memory, the hippocampal encoding of a continuous sequence of images, i.e., a visual episode, is unknown.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>We used a publicly available dataset (Allen Brain Observatory – Neuropixels Visual Coding, © 2019 Allen Institute). Mice were monocularly shown a 30s clip of a continuous segment from the movie <italic>Touch of Evil</italic> (Welles, 1958)<sup><xref ref-type="bibr" rid="c31">31</xref></sup> (<xref rid="figED1" ref-type="fig">Extended Data Fig. 1</xref>). Mice were head-fixed but were free to run on a circular disk. A total of 17048 broad spiking, active, putatively excitatory neurons were analyzed, recorded using 4-6 Neuropixel probes in 24 sessions from 24 mice (See <italic>Methods</italic>).</p>
<p>The majority of neurons in the visual areas (Lateral geniculate nucleus LGN, primary visual cortex V1, higher visual areas: antero-medial and medio-lateral AM-PM) were modulated by the movie, consistent with previous reports (<xref rid="figED2" ref-type="fig">Extended Data Fig. 2</xref>)<sup><xref ref-type="bibr" rid="c11">11</xref>–<xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c32">32</xref></sup>. Surprisingly, neurons from all parts of the hippocampus (dentate gyrus DG, CA3, CA1, subiculum SUB) were also clearly modulated (<xref rid="fig1" ref-type="fig">Fig. 1</xref>), with reliable, elevated spiking across many trials in small movie segments. To quantify selectivity in an identical, firing rate- and threshold-independent fashion across brain regions, we computed the z-scored sparsity<sup><xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c34">34</xref></sup> of neural selectivity (See <italic>Methods</italic>). Cells with z-scored sparsity &gt;2 were considered significantly (<italic>p</italic>&lt;0.03) modulated. The areas V1 (97.3%) and AM-PM (97.1%) had the largest percentage of movie tuned cells, much higher than reported earlier<sup><xref ref-type="bibr" rid="c11">11</xref></sup> (∼40%), perhaps because we analyzed extracellular spikes, while the previous study used calcium imaging. The majority of neurons in LGN (89.2%) too showed significant modulation by the movie. Thus, the vast majority of thalamo-cortical neurons were significantly modulated by the movie.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Fig. 1</label>
<caption><title>Movie frame selectivity in hippocampal neurons</title>
<p><bold>(a)</bold> Raster plots of two different dentate gyrus (DG) neurons as a function of the movie frame (top). The corresponding mean firing rate response over 60 trials is also shown (bottom). These two cells had significantly increased firing activity in specific parts of the movie. 33.1% of dentate neurons were significantly modulated by the movie (right, green bar), far greater than chance (gray bar). Total active, broad spiking neurons for each brain region indicated at top (N<sub>tuned</sub> /N<sub>cells</sub>=506/1531). <bold>(b)</bold> Same as (a), for CA3 (168/969, 17.3%), <bold>(c)</bold> CA1 (2326/6914, 33.6%) and <bold>(d)</bold> subiculum (379/849, 44.6%) neurons.</p></caption>
<graphic xlink:href="519455v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Movie selectivity was prevalent in the hippocampal regions too, despite head fixation, dissociation between self-movements and visual cues as well as the absence of rewards, task, or memory demands (<xref rid="fig1" ref-type="fig">Fig. 1a-d</xref>). Subiculum, the output region of the hippocampus, farthest removed from the retina, had the largest fraction (44.6% <xref rid="fig1" ref-type="fig">Fig. 1d</xref>) of movie-tuned neurons, followed by the upstream CA1 (33.6%, <xref rid="fig1" ref-type="fig">Fig. 1c</xref>) and dentate gyrus (33.1%, <xref rid="fig1" ref-type="fig">Fig. 1a</xref>). However, CA3 movie selectivity was nearly half as much (17.3%, <xref rid="fig1" ref-type="fig">Fig. 1b</xref>). This is unlike place cells, where CA3 and CA1 selectivity are comparable<sup><xref ref-type="bibr" rid="c35">35</xref>,<xref ref-type="bibr" rid="c36">36</xref></sup> and subiculum selectivity is weaker<sup><xref ref-type="bibr" rid="c37">37</xref></sup>.</p>
<p>To confirm these findings, we did several controls. Running alters neural activity in visual areas<sup><xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c39">39</xref></sup> and hippocampus<sup><xref ref-type="bibr" rid="c40">40</xref>,<xref ref-type="bibr" rid="c41">41</xref></sup>. Hence, we used the data from only the stationary epochs (see <italic>Methods</italic>) and only from sessions with at least 300 seconds of stationary data (17 sessions, 24906 cells). Movie tuning was unchanged in this data (<xref rid="figED3" ref-type="fig">Extended Data Fig. 3</xref>). This is unlike place cells where spatial selectivity is greatly reduced during immobility<sup><xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c6">6</xref></sup>. Neurons recorded simultaneously from the same brain region also showed different selectivity patterns (<xref rid="figED4" ref-type="fig">Extended Data Fig. 4</xref>). Thus, nonspecific effects such as running cannot explain the brain wide movie selectivity.</p>
<p>Hippocampal neurons have one or two place fields in typical mazes which take a few seconds to traverse<sup><xref ref-type="bibr" rid="c42">42</xref></sup>. In larger arenas that take tens of seconds to traverse, the number of peaks per cell and the peak duration increases<sup><xref ref-type="bibr" rid="c43">43</xref>–<xref ref-type="bibr" rid="c46">46</xref></sup>. Peak detection for movie tuning is nontrivial because neurons have nonzero background firing rate, and the elevated rates cover a wide range (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). We developed a novel algorithm to address this (see <italic>Methods</italic>). On average, V1 neurons had the largest number of movie-fields (<xref rid="fig2" ref-type="fig">Fig. 2a</xref>, mean±s.e.m.=10.4±0.1), followed by LGN (8.6±0.3) and AM-PM (6.3±0.07). Hippocampal areas had significantly fewer movie-fields per cell: dentate gyrus (2.1±0.1), CA3 (2.8±0.3), CA1(2.0±0.02) and subiculum (2.1±0.05). Thus, the number of movie-fields per cell was smaller than the number of place-fields per cell in comparably long spatial tracks<sup><xref ref-type="bibr" rid="c43">43</xref>–<xref ref-type="bibr" rid="c48">48</xref></sup>, but a handful of hippocampal cells had more than 5 movie-fields (<xref rid="figED5" ref-type="fig">Extended Data Fig. 5</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Fig. 2</label>
<caption><title>Multi-peaked, mega-scale movie-fields across all brain areas</title>
<p><bold>(a)</bold> Distribution of the number of movie-fields per tuned cell (See <italic>Methods)</italic> in different brain regions (shown by different colors, top line inset, arranged in their hierarchical order). Hippocampal regions (blue-green shades) were significantly different from each other (KS-test <italic>p</italic>&lt;0.04), except DG-CA3. All visual regions were significantly different from each other (KS-test p&lt;7.0×10<sup>−11</sup>). All visual-hippocampal region pair-wise comparisons were also significantly different (KS-test <italic>p</italic>&lt;1.8×10<sup>−44</sup>). CA1 had the lowest number of movie-fields per cell (2.0±0.02, mean±s.e.m.) while V1 had the highest (10.4±0.1). <bold>(b)</bold> Distribution of the durations of movie-fields identified in (a), across all tuned neurons from a given brain region. These were significantly different for all brain region pairs (KS-test <italic>p</italic>&lt;7.3×10<sup>−3</sup>). The longest movie-fields were in subiculum (3169.9±169.8 ms), and the shortest in V1 (156.6±9.2ms). <bold>(c)</bold> Snippets of movie-fields from an example cell from V1, with 2 of the fields zoomed in, showing 60x difference in duration. Black bar at top indicates 50ms, and gray bar indicates 1s. Each frame corresponds to 33.3ms. Average response (solid trace, y-axis on the right) is superimposed on the trial wise spiking response (dots, y-axis on the left). Color of dots corresponds to frame numbers as in Fig. 1. <bold>(d)</bold> Same as (c), for a CA1 neuron with 54x difference in duration. <bold>(e)</bold> The ratio of longest to shortest field duration within a single cell, i.e., mega-scale index, was largest in V1 (56.7±2.2) and least in subiculum (8.0±9.7). All visual-visual and visual-hippocampal brain region pairs were significantly different on this metric (KS-test <italic>p</italic>&lt;0.02). Among the hippocampal-hippocampal pairs, only CA3-SUB were significantly different (<italic>p</italic>=0.03). <bold>(f)</bold> For each cell, the total duration of all movie-fields, i.e., cumulative duration of significantly elevated activity, was comparable across brain regions. The largest cumulative duration (10.2±0.46s, CA3) was only 1.66x of the smallest (6.2±0.09 sec, V1). Visual-hippocampal and visual-visual brain region pairs’ cumulative duration distributions were significantly different (KS-test <italic>p</italic>&lt;0.001), but not hippocampal pairs (<italic>p</italic>&gt;0.07). Distribution of the firing within fields, normalized by that in the shuffle response. All fields from all tuned neurons in a brain region were used. Firing in movie-fields was significantly different across all brain region pairs (KS-test, <italic>p</italic>&lt;1.0×10<sup>−7</sup>), except DG-CA3. Movie-field firing was largest in V1 (2.9±0.03) and smallest in subiculum (1.14±0.03). <bold>(h)</bold> Snippets of movie-fields from representative tuned cells, from LGN showing a long movie-field (233 frames, or 7.8s, panel 1), and from AM-PM and from hippocampus showing short fields (2 frames or 66.6ms wide or less).</p></caption>
<graphic xlink:href="519455v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Typical receptive field size increases as one moves away from the retina in the visual hierarchy<sup><xref ref-type="bibr" rid="c31">31</xref></sup>. A similar effect was seen for movie-field durations. On average, hippocampal movie-fields were longer than visual regions (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>). But there were many exceptions –movie-fields of LGN (median±s.e.m., here and subsequently, unless stated otherwise, 308.5±33.9 ms) were twice as long as in V1 (156.6±9.2ms). Movie-fields of subiculum (3169.9±169.8 ms) were significantly longer than CA1 (2786.1±77.5 ms) and nearly three-fold longer than the upstream CA3 (979.1±241.1 ms). However, the dentate movie-fields (2113.2±172.4 ms) were two-fold longer than the downstream CA3. This is similar to the patterns reported for CA3, CA1 and dentate gyrus place cells<sup><xref ref-type="bibr" rid="c48">48</xref></sup>. But others have claimed that CA3 place fields are slightly bigger than CA1<sup><xref ref-type="bibr" rid="c49">49</xref></sup>, whereas movie-fields showed the opposite pattern.</p>
<p>The movie-field durations spanned a 500-1000-fold range in every brain region investigated (<xref rid="fig2" ref-type="fig">Fig. 2e</xref>). This mega-scale scale is unprecedentedly large, nearly 2 orders of magnitude greater than previous reports in place cells<sup><xref ref-type="bibr" rid="c43">43</xref>,<xref ref-type="bibr" rid="c45">45</xref></sup>. Even individual neurons showed 100-fold mega-scale responses (<xref rid="fig2" ref-type="fig">Fig. 2c</xref> &amp; <xref ref-type="fig" rid="fig2">d</xref>) compared to less than 10-fold scale within single place cells<sup><xref ref-type="bibr" rid="c43">43</xref>,<xref ref-type="bibr" rid="c45">45</xref></sup>. The mega-scale tuning within a neuron was largest in V1 and smallest in subiculum (<xref rid="fig2" ref-type="fig">Fig. 2e</xref>). This is partly because the short duration movie-fields in hippocampal regions were typically neither as narrow and nor as prominent as in the visual areas (<xref rid="figED6" ref-type="fig">Extended Data Fig. 6</xref>).</p>
<p>Despite these differences in mega-scale tuning across different brain areas, the total duration of elevated activity, i.e., the sum of movie-field durations within a single cell, was remarkably conserved across neurons within and across brain regions (<xref rid="fig2" ref-type="fig">Fig. 2f</xref>). Unlike movie-field durations, which differed by more than ten-fold between hippocampal and visual regions, cumulative durations were quite comparable, ranging from 6.2s (V1) to 10.2s (CA3) (<xref rid="fig2" ref-type="fig">Fig. 2f</xref>, LGN=8.8±0.21sec, V1=6.2±0.09, AM-PM=7.8±0.09, DG=9.4±0.26, CA3=10.2±0.46, CA1=9.1±0.12, SUB=9.5±0.27). Thus, hippocampal movie-fields are longer and less multi-peaked than visual areas, such that the total duration of elevated activity was similar across all areas, spanning about a fourth of the movie, comparable to the fraction of large environments in which place cells are active<sup><xref ref-type="bibr" rid="c45">45</xref>,<xref ref-type="bibr" rid="c47">47</xref>,<xref ref-type="bibr" rid="c48">48</xref></sup>. To quantify the net activity in the movie-fields, we computed the total firing in the movie-fields (i.e., the area under the curve for the duration of the movie-fields), normalized by the expected discharge from the shuffled response. Net movie-field discharge was also comparable across brain areas, but maximal in V1 and least in subiculum (<xref rid="fig2" ref-type="fig">Fig. 2g</xref>).</p>
<p>Many movie-fields showed elevated activity spanning up to several seconds, suggesting rate-code like encoding (<xref rid="fig2" ref-type="fig">Fig. 2h</xref>). However, some cells showed movie-fields with elevated spiking restricted to less than 50ms, similar to responses to briefly flashed stimuli in anesthetized cats<sup><xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c50">50</xref></sup>. This is suggestive of a temporal code, characterized by low spike timing jitter<sup><xref ref-type="bibr" rid="c51">51</xref></sup>. Such short-duration movie-fields were not only common in the thalamus, but also AM-PM, three synapses away from the retina. A small fraction of cells in the hippocampal areas, more than five synapses away from the retina, too showed such temporally coded fields (<xref rid="fig2" ref-type="fig">Fig. 2h</xref>).</p>
<p>To determine the stability and temporal-continuity of movie tuning across the neural ensembles we computed the population vector overlap between even and odd trials<sup><xref ref-type="bibr" rid="c52">52</xref></sup> (see <italic>Methods</italic>). Population response stability was significantly greater for tuned than for untuned neurons (<xref rid="figED7" ref-type="fig">Extended Data Fig. 7</xref>). The population vector overlap around the diagonal was broader in hippocampal regions than visual cortical and LGN, indicating longer temporal-continuity, reflective of their longer movie-fields. Further, the population vector overlap away from the diagonal was longer around frames 400-800 in all brain areas due to the longer movie-fields in that movie segment (see below).</p>
<p>Are all movie frames represented equally by all brain areas? The duration and density of movie-fields varied as a function of the movie frame and brain region (<xref rid="figED8" ref-type="fig">Extended Data Fig. 8</xref>). We hypothesized that this variation could correspond to the change in visual content from one frame to the next. Hence for comparison, we quantified the similarity between adjacent movie frames as the correlation coefficient between corresponding pixels and termed it as frame-to-frame (F2F) correlation. The majority of brain regions had substantially reduced density of movie-fields between the movie frames 400 to 800, but the movie-fields were longer in this region. This effect was greater in the visual areas than hippocampal. Using significantly tuned neurons, we computed the average neural activity in each brain region at each point in the movie (see <italic>Methods</italic>). Although movie-fields (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>), or just the tallest movie-field per cell (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>), covered the entire movie, the peak normalized, ensemble activity level of all brain regions showed significant overrepresentation, i.e., deviation from the norm, in certain parts of the movie (<xref rid="fig3" ref-type="fig">Fig. 3c</xref>, see <italic>Methods</italic>). This was most pronounced in V1 and higher visual areas AM-PM. The number of movie frames with elevated ensemble activity was higher in visual areas than hippocampal regions (<xref rid="fig3" ref-type="fig">Fig. 3d</xref>), and also this modulation (see <italic>Methods</italic>) was smaller in hippocampus and LGN, compared to visual cortical regions (<xref rid="fig3" ref-type="fig">Fig. 3e</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Fig. 3</label>
<caption><title>Population averaged movie-tuning varies across brain areas.</title>
<p><bold>(a)</bold> Stack plot of all the movie-fields detected from all tuned neurons of a brain region. Color indicates relative firing rate, normalized by the maximum firing rate in that movie-field. The movie-fields are sorted according to the frame with the maximal response. Note accumulation of fields in certain parts of the movie, especially in subiculum and AM-PM. <bold>(b)</bold> Similar to (a), but using only a single, tallest movie-field peak from each neuron showing a similar pattern, with pronounced overrepresentation of some portions of the movie in most brain areas. Each neuron’s response is normalized by its maximum firing rate. <bold>(c)</bold> Multiple single unit activity (MSUA) in a given brain region, obtained as the average response across all tuned cells, by using maxima-normalized response for each cell from (b). Gray lines indicate mean±4*std response from the shuffle data corresponding to <italic>p</italic>=0.025 after Bonferroni correction for multiple comparisons (see <italic>Methods</italic>). AM-PM had the largest MSUA modulation (sparsity=0.01) and CA1 had the smallest (sparsity=1.8×10<sup>−4</sup>). The MSUA modulation across several brain region pairs –AM&amp;PM-DG, V1-CA3, DG-CA3, CA3-CA1 and CA1-SUB were not significantly correlated (Pearson correlation coefficient <italic>p</italic>&gt;0.05). Some brain region pairs, DG-LGN, DG-V1, AM&amp;PM-CA3, LGN-CA1, V1-CA1, DG-SUB and CA3-SUB, were significantly negatively correlated (<italic>r</italic>&lt;-0.18, <italic>p</italic>&lt;4.0×10<sup>−7</sup>). All other brain region pairs were significantly positively correlated (<italic>r</italic>&gt;0.07, <italic>p</italic>&lt;0.03). <bold>(d)</bold> Number of frames for which the observed MSUA deviates from the z=±4 range from (c), termed significant deviation. V1 and AM-PM had the largest positive deviant frames (289), and CA3 had the least (zero). <bold>(e)</bold> Firing in deviant frames above (or below) chance level, as a percentage of the average response. Above chance level deviation was greater or equal to that below, for all brain regions, with the largest positive deviation in AM-PM (9.3%), largest negative deviation in V1 (6.0%), and least in CA3 (zero each). <bold>(f)</bold> Total firing rate response of visual regions across tuned neurons. All regions had significant negative correlation (<italic>r</italic>&lt;-0.39, <italic>p</italic>&lt;3.4×10<sup>−34</sup>) between the ensemble response and the frame-to-frame (F2F) correlation (gray line, y-axis on the left) across movie frames. <bold>(g)</bold> Similar to (f), for hippocampal regions. CA3 response were not significantly correlated with the frame-to-frame correlation, dentate gyrus (<italic>r</italic>=0.26, <italic>p</italic>=4.0×10<sup>−15</sup>) and CA1 (<italic>r</italic>=0.21, <italic>p</italic>=1.5×10<sup>−10</sup>) responses were positively correlated, and subiculum response was negatively correlated (<italic>r</italic>=-0.44, <italic>p</italic>=2.2×10<sup>−43</sup>). Note the substantially higher mean firing rates of LGN in (f) and subiculum neurons in (g) (colored lines closer to the top) compared to other brain areas.</p></caption>
<graphic xlink:href="519455v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Using the significantly tuned neurons, we also computed the average neural activity in each brain region corresponding to each frame in the movie, without peak rate normalization (see <italic>Methods</italic>). The degree of continuity between the movie frames, quantified as above (F2F correlation), was inversely correlated with the ensemble rate modulation in all areas except DG, CA3 and CA1 (<xref rid="fig3" ref-type="fig">Fig. 3f</xref> and g). As expected for a continuous movie, this F2F correlation was close to unity for most frames, but highest in the latter part of the movie where the images changed more slowly. The population wide elevated firing rates, as well as the smallest movie-fields, occurred during the earlier parts (<xref rid="figED8" ref-type="fig">Extended Data Fig. 8</xref>). Thus, the movie-code was stronger in the segments with greatest change across movie frames. These results show differential ensemble-wide representation of the movie across brain regions.</p>
<p>If these responses were purely visual, a movie made of scrambled sequence of images would generate equally strong or even stronger selectivity due to the even larger change across movie frame, despite the absence of similarity between adjacent frames. To explore this possibility, we investigated neural selectivity when the same movie frames were presented in a fixed but scrambled sequence (scrambled movie). The within frame and the total visual content was identical between the continuous and scrambled movies, and the same sequence of images was repeated many times in both experiments (see <italic>Methods</italic>). But there was no correlation between adjacent frames, i.e., visual continuity, in the latter (<xref ref-type="fig" rid="fig4">Fig.4a</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Fig. 4</label>
<caption><title>Larger reduction of selectivity in hippocampal than visual regions due to scrambled presentation.</title>
<p><bold>(a)</bold> Similarity between the visual content of one frame with the subsequent one, quantified as the <italic>Pearson</italic> correlation coefficient between pixel-pixel across adjacent frames for the continuous movie (pink) and the scrambled sequence (lavender), termed F2F correlation. Similar to <xref ref-type="fig" rid="fig3">Fig. 3g</xref>. For the scrambled movie, the frame number here corresponds to the chronological frame sequence, as presented. <bold>(b)</bold> Fraction of broad spiking neurons significantly modulated by either the continuous movie or the scrambled sequence using z-scored sparsity measures (similar to <xref ref-type="fig" rid="fig1">Fig. 1</xref>, see <italic>Methods</italic>). For all brain regions, continuous movie generated greater selectivity than scrambled sequence (KS-test <italic>p</italic>&lt;7.4×10<sup>−4</sup>). <bold>(c)</bold> Percentage change in the magnitude of tuning between the continuous and scrambled movies for cells significantly modulated by either continuous or scrambled movie, termed visual continuity index. Largest drop in selectivity due to scrambled movie occurred in CA1 (90.3±2.0%), and least in V1 (−1.5±0.6%). Continuous to scrambled tuning change was significantly different between all brain region pairs (KS-test <italic>p</italic>&lt;0.03) and significantly greater for hippocampal areas than visual (8.2-fold, p&lt;10<sup>−100</sup>). <bold>(d)</bold> Raster plots (top) and mean rate responses (color, bottom) showing increased spiking responses to only one or two scrambled movie frames, lasting about 50ms. Tuned responses to scrambled movie were found in all brain regions, but these were the least frequent in DG and CA1. <bold>(e)</bold> One representative cell each from V1 (left) and CA1 (right), where the frame rearrangement of scrambled responses resulted in a response with high correlation to the continuous movie response for V1, but not CA1. <italic>Pearson</italic> correlation coefficient values of continuous movie and rearranged scrambled responses are indicated on top. <bold>(f)</bold> Average decoding error for observed data (see <italic>Methods</italic>), over 60 trials for continuous movie (maroon), was significantly lower than shuffled data (gray) (KS-test <italic>p</italic>&lt;8.2×10<sup>− 22</sup>). Solid line – mean error across 60 trials, shaded box – s.e.m. <bold>(g)</bold> Similar to (f), decoding of scrambled trials was significantly worse than that for the continuous movie (KS-test <italic>p</italic>&lt;3.6×10<sup>−8</sup>), except V1 (<italic>p</italic>=0.13), where the errors were not significantly different (2.6 vs. 2.7 frames). Scrambled responses, in their “as is”, chronological order were used herein. LGN decoding error for scrambled presentation was 6.5x greater than that for continuous movie, whereas the difference in errors was least for V1 (1.04x). Scrambled movie decoding error for all visual areas and for CA1 and subiculum was significantly smaller than chance level (KS-test <italic>p</italic>&lt;2.6×10<sup>−3</sup>), but not DG and CA3 (<italic>p</italic>&gt;0.13). Only the middle 20 trials of the continuous movie were used for comparison with the scrambled movie since the scrambled movie was only presented 20 times. Middle trials of the continuous movie were chosen as the appropriate subset since they were chronologically closest to the scrambled movie presentation.</p></caption>
<graphic xlink:href="519455v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>For all brain regions investigated, the continuous movie generated significantly greater modulation of neural activity than the scrambled sequence (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). Middle 20 trials of the continuous movie were chosen as the appropriate subset for comparison since they were chronologically closest to the scrambled movie presentation. This preference for sequential over scrambled movie was the greatest in hippocampal regions where the percentage of significantly tuned neurons (4.4%, near chance level of 2.3%) reduced more than 4-fold compared to the continuous movie (17.8%, after accounting for the lesser number of trials, see <italic>Methods</italic>). This was unlike visual areas where the scrambled (80.4%) and the continuous movie (92.4%) generated similar prevalence levels of selectivity (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). The few hippocampal cells which had significant selectivity to the scrambled sequence, did not have long-duration responses, but only very short, ∼50ms long responses (<xref rid="fig4" ref-type="fig">Fig. 4d</xref>), reminiscent of, but even sharper than human hippocampal responses to flashed images<sup><xref ref-type="bibr" rid="c28">28</xref></sup>. To estimate the effect of continuous movie compared to the scrambled sequence on individual cells, we computed the normalized difference between the continuous and scrambled movie selectivity for cells which were selective in either condition (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>, see <italic>Methods</italic>). This visual continuity index was more than eight-fold higher in hippocampal areas (87.8%) compared to the visual areas (10.6%).</p>
<p>The pattern of increasing visual continuity index as we moved up the visual hierarchy, largely paralleled the anatomic organization<sup><xref ref-type="bibr" rid="c53">53</xref></sup>, with the greatest sensitivity to visual continuity in the hippocampal output regions, CA1 and subiculum, but there were notable exceptions. The primary visual cortical neurons showed the least reduction in selectivity due to the loss of temporally contiguous content, whereas LGN neurons, the primary source of input to the visual cortex and closer to the periphery, showed far greater sensitivity (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>).</p>
<p>Many visual cortical neurons were significantly modulated by the scrambled sequence, but their number of movie-fields per cell was greater and their duration was shorter than during the continuous movie (<xref rid="figED9" ref-type="fig">Extended Data Fig. 9</xref> and <xref rid="figED10" ref-type="fig">10</xref>). This could occur due to the loss of frame-to- frame correlation in the scrambled sequence. The average activity of the neural population in V1 and AM-PM showed significant deviation even with the scrambled movie, comparable to the continuous movie, but this multi-unit ensemble response was uncorrelated with the frame-to- frame correlation in the scrambled sequence (<xref rid="figED11" ref-type="fig">Extended Data Fig. 11</xref>). A substantial fraction of visual cortical and LGN responses to the scrambled sequence could be rearranged to resemble continuous movie responses (<xref rid="figED12" ref-type="fig">Extended Data Fig. 12</xref>, see <italic>Methods</italic>). The latency needed to shift the responses was least in LGN and largest in AM-PM, as expected from the feed-forward anatomy and the model of visual information processing (<xref rid="figED12" ref-type="fig">Extended Data Fig. 12</xref>). This rearrangement did not recreate the continuous movie responses above chance levels in the hippocampal regions (example cells in <xref rid="fig4" ref-type="fig">Fig. 4e</xref>, also see <xref rid="figED12" ref-type="fig">Extended Data Fig. 12</xref> for statistics and details).</p>
<p>Population vector decoding of the ensemble of a few hundred place cells is sufficient to decode the rat’s position using place cells<sup><xref ref-type="bibr" rid="c54">54</xref></sup>, and the position of a passively moving object<sup><xref ref-type="bibr" rid="c55">55</xref></sup>. Using similar methods, we decoded the movie frame number (see <italic>Methods</italic>). Continuous movie decoding was better than chance in all brain regions analyzed (<xref rid="fig4" ref-type="fig">Fig. 4f</xref>). Scrambled movie decoding was significantly weaker yet above chance level (as expected from shuffles, see <italic>Methods</italic>) in visual areas, but not in CA3 and dentate gyrus. But CA1 and subiculum neuronal ensembles could be used to decode scrambled movie frame number slightly above chance levels (<xref rid="fig4" ref-type="fig">Fig. 4g</xref>). Similarly, the population overlap between even and odd trials for scrambled sequence was strong for visual areas, and weaker in hippocampal regions, but significantly greater than untuned neurons in hippocampal regions (<xref rid="figED13" ref-type="fig">Extended Data Fig. 13</xref>).</p>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>To understand how neurons encode a continuously unfolding visual episode, we investigated the neural responses in the rodent brain to an isoluminant human movie. As expected, neural activity in all thalamo-cortical visual areas was significantly modulated, with elevated activity in response to specific visual content. Most (96.6%, 6554/6785) of thalamo-cortical neurons showed significant movie tuning, nearly double that reported for the classic stimuli such as Gabor patches in the same dataset<sup><xref ref-type="bibr" rid="c31">31</xref></sup>. Remarkably, a third of hippocampal neurons (32.9%, 3379/10263) were also movie-tuned, comparable to the fraction of neurons with significant spatial selectivity in mice<sup><xref ref-type="bibr" rid="c56">56</xref></sup> and bats<sup><xref ref-type="bibr" rid="c57">57</xref></sup>. While the hippocampus is implicated in episodic memory, rodent hippocampal responses are largely studied in the context of spatial maps or place cells, and more recently in other tasks which requires active locomotion or active engagement<sup><xref ref-type="bibr" rid="c7">7</xref>,<xref ref-type="bibr" rid="c58">58</xref></sup>.</p>
<p>However, unlike place cells<sup><xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c6">6</xref></sup>, movie-tuning remained intact during immobility in all brain areas studied. This dissociation of the effect of mobility on spatial and movie selectivity agrees with the recent reports of dissociated mechanisms of episodic encoding and spatial navigation in human amnesia<sup><xref ref-type="bibr" rid="c59">59</xref></sup>.</p>
<p>Across all brain regions, neurons showed a mega-scale encoding by movie-fields varying in duration by up to 1000-fold, similar to, but far greater than recent reports of 10-fold multi-scale responses in the hippocampus<sup><xref ref-type="bibr" rid="c43">43</xref>–<xref ref-type="bibr" rid="c48">48</xref>,<xref ref-type="bibr" rid="c60">60</xref></sup>. Importantly, mega-scale responses were found within single neurons as well, which can enable encoding of both finer and broader details of an episode in the same neuron. This could provide greatly enhanced episodic memory and recall.</p>
<p>The response latency was highest in AM-PM, then V1 and least in LGN, thus following the visual hierarchy. Among the visual areas, continuous movie tuning was greater in V1, more than the upstream LGN. This is surprising but can explain the recent findings that silencing V1 reduces movie tuning in the thalamus<sup><xref ref-type="bibr" rid="c61">61</xref></sup>. Similarly, the preference for the continuous movie over scrambled sequence was greater in LGN and AM-PM than V1, which does not follow the expected hierarchy of visual processing. This effect was even greater in the hippocampal areas than any visual regions. Temporal integration window<sup><xref ref-type="bibr" rid="c62">62</xref>–<xref ref-type="bibr" rid="c64">64</xref></sup> as well as intrinsic timescale of firing<sup><xref ref-type="bibr" rid="c31">31</xref></sup> increases along the anatomical hierarchy in the cortex, with the hippocampus being farthest removed from the retina<sup><xref ref-type="bibr" rid="c53">53</xref></sup>. This hierarchical organization could explain the longer movie-fields and several fold greater preference for the continuous movie over scrambled sequence in the hippocampus. But, unlike reports of image-association memory in the inferior temporal cortex for unrelated images<sup><xref ref-type="bibr" rid="c65">65</xref></sup>, only a handful hippocampal neurons showed selective responses to the scrambled sequence. These results, along with the longer duration of hippocampal movie-fields could mediate visual-chunking or binding of a sequence of events.</p>
<p>Could the brain-wide mega-scale tuning be an artifact of poor unit isolation, e.g., due to an erroneous mixing of two neurons, one with very short and another with very long movie-fields? This is unlikely since the LGN and visual cortical neural selectivity to classic stimuli (Gabor patches, drifting gratings etc.) in the same dataset was similar to that reported in most studies<sup><xref ref-type="bibr" rid="c31">31</xref></sup> whereas poor unit isolation should reduce these selective responses. However, to directly test this possibility, we calculated the correlation between the unit isolation index (or fraction of refractory violations) and the mega-scale index of the cell, while factoring out the contribution of mean firing rate (<xref rid="figED14" ref-type="fig">Extended Data Fig. 14</xref>). This correlation was not significant (<italic>p</italic>&gt;0.05) for any brain areas.</p>
<p>Do the movie fields arise from the same mechanism as place fields? Studies have shown that when rodents are passively moved along a linear track that they had explored<sup><xref ref-type="bibr" rid="c6">6</xref></sup>, or when the images of the environment around a linear track was played back to them<sup><xref ref-type="bibr" rid="c5">5</xref></sup>, some hippocampal neurons generated spatially selective activity. Since the movie clip involved change of spatial view, one could hypothesize that the movie fields are just place fields generated by passive viewing. This is unlikely for several reasons. Mega-scale movie fields were found in all brain regions investigated, including the lateral geniculate nucleus and the primary visual cortex. There is no evidence of place cells in these brain regions. Further, in prior passive viewing experiments, the rodents were shown the same narrow linear track, like a tunnel, that they had previously explored actively to get food rewards at specific places. In contrast, in current experiments, these mice had never actively explored the space shown in the movie, nor obtained any rewards. Active exploration of a maze, combined with spatially localized rewards engages multisensory mechanisms resulting in increased place cell activation<sup><xref ref-type="bibr" rid="c17">17</xref>,<xref ref-type="bibr" rid="c23">23</xref>,<xref ref-type="bibr" rid="c66">66</xref></sup> which are entirely missing in these experiments during passive viewing of a movie, presented monocularly, without any other multisensory stimuli and without any rewards. Compared to the exploration of a real-world maze, exploration of a visually identical virtual world causes 60% reduction in CA1 place cell activation<sup><xref ref-type="bibr" rid="c67">67</xref></sup>. In contrast, there was no evidence of significant CA1 neural shutdown during movie viewing, compared to the blank screen presentation (<xref rid="figED14" ref-type="fig">Extended Data Fig. 14</xref>).</p>
<p>A recent study showed that CA1 neurons encode the distance, angle, and movement direction of motion of a vertical bar of light<sup><xref ref-type="bibr" rid="c55">55</xref></sup>, consistent with the position of hippocampus in the visual circuitry<sup><xref ref-type="bibr" rid="c53">53</xref></sup>. Do those findings predict the movie tuning herein? There are indeed some similarities between the two experimental protocols –purely passive optical motion without any self-motion or rewards. However, there are significant differences too; similar to place cells in the real and virtual worlds<sup><xref ref-type="bibr" rid="c34">34</xref></sup>, all the cells tuned to the moving bar of light had single receptive fields with elevated responses lasting a few seconds; there were neither punctate responses nor even 10-fold variation in neural field durations, let alone the 1000-fold change reported here. Finally, those results were reported only in area CA1, while the results presented here cover nearly all the major stations of the visual hierarchy.</p>
<p>Notably, hippocampal neurons did not encode Gabor patches or drifting gratings in the same dataset, indicating the importance of temporally continuous sequences of images for hippocampal activation<sup><xref ref-type="bibr" rid="c31">31</xref></sup>. This is consistent with the hypothesis that the hippocampus is involved in coding spatial sequences<sup><xref ref-type="bibr" rid="c16">16</xref>,<xref ref-type="bibr" rid="c24">24</xref>,<xref ref-type="bibr" rid="c68">68</xref></sup>. However, unlike place cells that degrade in immobile rats, hippocampal movie tuning was unchanged in the immobile mouse. Further, the scrambled sequence too was presented in the same sequence many times, yet movie tuning dropped to chance level in the hippocampal areas. Unlike visual areas, scrambled sequence response of hippocampal neurons could not be rearranged to obtain the continuous movie response. This shows the importance of continuous, episodic content instead of mere sequential recurrence of unrelated content for rodent hippocampal activation.</p>
<p>These results complement recent findings of spatial modulation of visual cortical neurons and coordinated activity of visual and hippocampal neurons during navigation<sup><xref ref-type="bibr" rid="c69">69</xref>,<xref ref-type="bibr" rid="c70">70</xref></sup>. Our findings open up the possibility of studying thalamic, cortical, and hippocampal brain regions in a simple, passive, and purely visual experimental paradigm and extend comparable convolutional neural networks<sup><xref ref-type="bibr" rid="c11">11</xref></sup> to have the hippocampus at the apex<sup><xref ref-type="bibr" rid="c53">53</xref></sup>. Further, our results here bridge the long-standing gap between the hippocampal rodent and human studies<sup><xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c71">71</xref>–<xref ref-type="bibr" rid="c73">73</xref></sup>, where natural movies can be decoded from fMRI signals in immobile humans<sup><xref ref-type="bibr" rid="c74">74</xref></sup>. This brain-wide mega-scale encoding of a human movie episode and enhanced preference for visual continuity in the hippocampus compared to visual areas supports the hypothesis that the rodent hippocampus could play a role in non-spatial episodic memories, consistent with classic findings in humans<sup><xref ref-type="bibr" rid="c1">1</xref></sup> and agrees with a more generalized, representational framework<sup><xref ref-type="bibr" rid="c75">75</xref>,<xref ref-type="bibr" rid="c76">76</xref></sup> of episodic memory where it encodes temporal patterns. Similar responses are likely across different species, including primates. Thus movie-coding can provide a unified platform to investigate the neural mechanisms of episodic coding, learning and memory.</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="other"><string-name><surname>Scoviille</surname>, <given-names>W. B.</given-names></string-name> &amp; <string-name><surname>Milner</surname>, <given-names>B.</given-names></string-name> <article-title>LOSS OF RECENT MEMORY AFTER BILATERAL HIPPOCAMPAL LESIONS</article-title>. <source>J. Neurol. Neurosurg. Psychiat</source> (<year>1957</year>) doi:<pub-id pub-id-type="doi">10.1136/jnnp.20.1.11</pub-id>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>MacDonald</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Lepage</surname>, <given-names>K. Q.</given-names></string-name>, <string-name><surname>Eden</surname>, <given-names>U. T.</given-names></string-name> &amp; <string-name><surname>Eichenbaum</surname>, <given-names>H.</given-names></string-name> <article-title>Hippocampal “Time Cells” Bridge the Gap in Memory for Discontiguous Events</article-title>. <source>Neuron</source> <volume>71</volume>, <fpage>737</fpage>–<lpage>749</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Vargha-Khadem</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal> <article-title>Differential effects of early hippocampal pathology on episodic and semantic memory</article-title>. <source>Science (1979)</source> <volume>277</volume>, <fpage>376</fpage>–<lpage>380</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="book"><string-name><surname>O’Keefe</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Nadel</surname>, <given-names>L.</given-names></string-name> <source>The hippocampus as a cognitive map</source>. (<publisher-name>Clarendon Press</publisher-name>, <year>1978</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Chen</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>King</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Burgess</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>O’Keefe</surname>, <given-names>J.</given-names></string-name> <article-title>How vision and movement combine in the hippocampal place code</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>110</volume>, <fpage>378</fpage>–<lpage>383</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Foster</surname>, <given-names>T. C.</given-names></string-name>, <string-name><surname>Castro</surname>, <given-names>C. A.</given-names></string-name> &amp; <string-name><surname>McNaughton</surname>, <given-names>B. L.</given-names></string-name> <article-title>Spatial Selectivity of Rat Hippocampal Neurons: Dependence on Preparedness for Movement</article-title>. <source>Science (1979)</source> <volume>244</volume>, <fpage>1580</fpage>–<lpage>1582</lpage> (<year>1989</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Aronov</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Nevers</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Tank</surname>, <given-names>D. W.</given-names></string-name> <article-title>Mapping of a non-spatial dimension by the hippocampal– entorhinal circuit</article-title>. <source>Nature</source> <volume>543</volume>, <fpage>719</fpage>–<lpage>722</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Hubel</surname>, <given-names>D. H.</given-names></string-name> &amp; <string-name><surname>Wiesel</surname>, <given-names>T. N.</given-names></string-name> <article-title>Receptive fields of single neurones in the cat’s striate cortex</article-title>. <source>J Physiol</source> <volume>148</volume>, <fpage>574</fpage>–<lpage>591</lpage> (<year>1959</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>De Valois</surname>, <given-names>R. L.</given-names></string-name>, <string-name><surname>William Yund</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Hepler</surname>, <given-names>N.</given-names></string-name> <article-title>The orientation and direction selectivity of cells in macaque visual cortex</article-title>. <source>Vision Res</source> <volume>22</volume>, <fpage>531</fpage>–<lpage>544</lpage> (<year>1982</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Xu</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Jiang</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Poo</surname>, <given-names>M. M.</given-names></string-name> &amp; <string-name><surname>Dan</surname>, <given-names>Y.</given-names></string-name> <article-title>Activity recall in a visual cortical ensemble</article-title>. <source>Nat Neurosci</source> <volume>15</volume>, <fpage>449</fpage>–<lpage>455</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>de Vries</surname>, <given-names>S. E. J.</given-names></string-name> <etal>et al.</etal> <article-title>A large-scale standardized physiological survey reveals functional organization of the mouse visual cortex</article-title>. <source>Nat Neurosci</source> <volume>23</volume>, <fpage>138</fpage>–<lpage>151</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Yen</surname>, <given-names>S.-C.</given-names></string-name>, <string-name><surname>Baker</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Gray</surname>, <given-names>C. M.</given-names></string-name> <article-title>Heterogeneity in the Responses of Adjacent Neurons to Natural Stimuli in Cat Striate Cortex</article-title>. <source>J Neurophysiol</source> <volume>97</volume>, <fpage>1326</fpage>–<lpage>1341</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Herikstad</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Baker</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Lachaux</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Gray</surname>, <given-names>C. M.</given-names></string-name> &amp; <string-name><surname>Yen</surname>, <given-names>S. C.</given-names></string-name> <article-title>Natural movies evoke spike trains with low spike time variability in cat primary visual cortex</article-title>. <source>Journal of Neuroscience</source> <volume>31</volume>, <fpage>15844</fpage>– <lpage>15860</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Mehta</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Quirk</surname>, <given-names>M. C.</given-names></string-name> &amp; <string-name><surname>Wilson</surname>, <given-names>M. A.</given-names></string-name> <article-title>Experience-Dependent Asymmetric Shape of Hippocampal Receptive Fields</article-title>. <source>Neuron</source> <volume>25</volume>, <fpage>707</fpage>–<lpage>715</lpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><collab>Mehta</collab> and <string-name><surname>Wilson</surname>, <given-names>M.A. M. R.</given-names></string-name> <article-title>From Hippocampus to V1: Effect of LTP on Spatio-Temporal Dynamics of Receptive Fields</article-title>. <source>Neurocomputing</source> <volume>32</volume>, <fpage>905</fpage>–<lpage>911</lpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Mehta</surname>, <given-names>M. R.</given-names></string-name> <article-title>From synaptic plasticity to spatial maps and sequence learning</article-title>. <source>Hippocampus</source> vol. <volume>25</volume> <fpage>756</fpage>–<lpage>762</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Mehta</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Barnes</surname>, <given-names>C. A.</given-names></string-name> &amp; <string-name><surname>Mcnaughton</surname>, <given-names>B. L.</given-names></string-name> <article-title>Experience-dependent, asymmetric expansion of hippocampal place fields</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>94</volume>, <fpage>8918</fpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="other"><string-name><surname>Buzsáki</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Moser</surname>, <given-names>E. I.</given-names></string-name> <source>Memory, navigation and theta rhythm in the hippocampal-entorhinal system</source>. (<year>2013</year>) doi:<pub-id pub-id-type="doi">10.1038/nn.3304</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Mau</surname>, <given-names>W.</given-names></string-name> <etal>et al.</etal> <article-title>The Same Hippocampal CA1 Population Simultaneously Codes Temporal Information over Multiple Timescales</article-title>. <source>Current Biology</source> <volume>28</volume>, <fpage>1499</fpage>-<lpage>1508.e4</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Kraus</surname>, <given-names>B. J.</given-names></string-name> <etal>et al.</etal> <article-title>During Running in Place, Grid Cells Integrate Elapsed Time and Distance Run</article-title>. <source>Neuron</source> <volume>88</volume>, <fpage>578</fpage>–<lpage>589</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Kraus</surname>, <given-names>B. J.</given-names></string-name>, <string-name><surname>Robinson</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>White</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Eichenbaum</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Hasselmo</surname>, <given-names>M. E.</given-names></string-name> <article-title>Hippocampal ‘time cells’: time versus path integration</article-title>. <source>Neuron</source> <volume>78</volume>, <fpage>1090</fpage>–<lpage>1101</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Pastalkova</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Itskov</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Amarasingham</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Buzsaki</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Buzsáki</surname>, <given-names>G.</given-names></string-name> <article-title>Internally generated cell assembly sequences in the rat hippocampus</article-title>. <source>Science (1979)</source> <volume>321</volume>, <fpage>1322</fpage>–<lpage>1327</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Moore</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Cushman</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Acharya</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Popeney</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Mehta</surname>, <given-names>M. R.</given-names></string-name> <article-title>Linking hippocampal multiplexed tuning, Hebbian plasticity and navigation</article-title>. <source>Nature</source> 2021 599:7885 <volume>599</volume>, <fpage>442</fpage>–<lpage>448</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="book"><string-name><surname>Buzsáki</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Tingley</surname>, <given-names>D.</given-names></string-name> <chapter-title>Space and Time: The Hippocampus as a Sequence Generator</chapter-title>. <source>Trends in Cognitive Sciences</source> vol. <volume>22</volume> <fpage>853</fpage>–<lpage>869</lpage> (<publisher-name>Elsevier Ltd</publisher-name>, <year>2018</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>McNaughton</surname>, <given-names>B. L.</given-names></string-name> <etal>et al.</etal> <article-title>Deciphering the hippocampal polyglot: the hippocampus as a path integration system</article-title>. <source>J Exp Biol</source> <volume>199</volume>, <fpage>173</fpage>–<lpage>85</lpage>. (<year>1996</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>O’Keefe</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Dostrovsky</surname>, <given-names>J.</given-names></string-name> <article-title>The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat</article-title>. <source>Brain Res</source> <volume>34</volume>, <fpage>171</fpage>–<lpage>5</lpage>. (<year>1971</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Parkinson</surname>, <given-names>J. K.</given-names></string-name>, <string-name><surname>Murray</surname>, <given-names>E. A.</given-names></string-name> &amp; <string-name><surname>Mishkin</surname>, <given-names>M.</given-names></string-name> <article-title>A selective mnemonic role for the hippocampus in monkeys: Memory for the location of objects</article-title>. <source>Journal of Neuroscience</source> <volume>8</volume>, <fpage>4159</fpage>–<lpage>4167</lpage> (<year>1988</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Quiroga</surname>, <given-names>R. Q.</given-names></string-name>, <string-name><surname>Reddy</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Kreiman</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Koch</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Fried</surname>, <given-names>I.</given-names></string-name> <source>Invariant visual representation by single neurons in the human brain</source>. <volume>435</volume>, <fpage>1102</fpage>–<lpage>1107</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Zheng</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal> <article-title>Neurons detect cognitive boundaries to structure episodic memories in humans</article-title>. <source>Nature Neuroscience</source> 2022 25:3 <volume>25</volume>, <fpage>358</fpage>–<lpage>368</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Cohn-Sheehy</surname>, <given-names>B. I.</given-names></string-name> <etal>et al.</etal> <article-title>The hippocampus constructs narrative memories across distant events</article-title>. <source>Current Biology</source> <volume>31</volume>, <fpage>4935</fpage>-<lpage>4945.e7</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Siegle</surname>, <given-names>J. H.</given-names></string-name> <etal>et al.</etal> <article-title>Survey of spiking in the mouse visual system reveals functional hierarchy</article-title>. <source>Nature</source> <volume>592</volume>, <fpage>86</fpage>–<lpage>92</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="other"><string-name><surname>Hoseini</surname>, <given-names>M. S.</given-names></string-name> <etal>et al.</etal> <article-title>Dynamics and sources of response variability and its coordination in visual cortex</article-title>. <source>Vis Neurosci</source> (<year>2019</year>) doi:<pub-id pub-id-type="doi">10.1017/S0952523819000117</pub-id>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Acharya</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Aghajan</surname>, <given-names>Z. M.</given-names></string-name>, <string-name><surname>Vuong</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Moore</surname>, <given-names>J. J.</given-names></string-name> &amp; <string-name><surname>Mehta</surname>, <given-names>M. R.</given-names></string-name> <article-title>Causal Influence of Visual Cues on Hippocampal Directional Selectivity</article-title>. <source>Cell</source> <volume>164</volume>, <fpage>197</fpage>–<lpage>207</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Aghajan</surname>, <given-names>Z. M.</given-names></string-name> <etal>et al.</etal> <article-title>Impaired spatial selectivity and intact phase precession in two-dimensional virtual reality</article-title>. <source>Nat Neurosci</source> <volume>18</volume>, <fpage>121</fpage>–<lpage>128</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Jung</surname>, <given-names>M. W.</given-names></string-name> &amp; <string-name><surname>Mcnaughton</surname>, <given-names>B. L.</given-names></string-name> <article-title>Spatial Selectivity of Unit Activity in the Hippocampal Granular Layer</article-title>. <source>HIPPOCAMPUS</source> vol. <volume>3</volume> (<year>1993</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Muller</surname>, <given-names>R.</given-names></string-name> <article-title>A Quarter of a Century of Place Cells</article-title>. <source>Neuron</source> <volume>17</volume>, <fpage>813</fpage>–<lpage>822</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Sharp</surname>, <given-names>P. E.</given-names></string-name> &amp; <string-name><surname>Green</surname>, <given-names>C.</given-names></string-name> <article-title>Spatial correlates of firing patterns of single cells in the subiculum of the freely moving rat</article-title>. <source>Journal of Neuroscience</source> <volume>14</volume>, <fpage>2339</fpage>–<lpage>2356</lpage> (<year>1994</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Niell</surname>, <given-names>C. M.</given-names></string-name> &amp; <string-name><surname>Stryker</surname>, <given-names>M. P.</given-names></string-name> <article-title>Modulation of Visual Responses by Behavioral State in Mouse Visual Cortex</article-title>. <source>Neuron</source> <volume>65</volume>, <fpage>472</fpage>–<lpage>479</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Erisken</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <article-title>Effects of Locomotion Extend throughout the Mouse Early Visual System</article-title>. <source>Current Biology</source> <volume>24</volume>, <fpage>2899</fpage>–<lpage>2907</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Góis</surname>, <given-names>Z. H. T. D.</given-names></string-name> &amp; <string-name><surname>Tort</surname>, <given-names>A. B. L.</given-names></string-name> <article-title>Characterizing Speed Cells in the Rat Hippocampus</article-title>. <source>Cell Rep</source> <volume>25</volume>, <fpage>1872</fpage>-<lpage>1884.e4</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="other"><string-name><surname>Wiener</surname>, <given-names>S. I.</given-names></string-name>, <string-name><surname>Paul</surname>, <given-names>C. A.</given-names></string-name> &amp; <string-name><surname>Eichenbaum</surname>, <given-names>H.</given-names></string-name> <source>Spatial and Behavioral Correlates of Hippocampal Neuronal Activity</source>. (<year>1989</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="other"><string-name><surname>O’keefe</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Burgess</surname>, <given-names>N.</given-names></string-name> <source>Geometric determinants of the place fields of hippocampal neurons</source>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Eliav</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal> <article-title>Multiscale representation of very large environments in the hippocampus of flying bats</article-title>. <source>Science (1979)</source> <volume>372</volume>, (<year>2021</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Kjelstrup</surname>, <given-names>K. B.</given-names></string-name> <etal>et al.</etal> <article-title>Finite Scale of Spatial Representation in the Hippocampus</article-title>. <source>Science (1979)</source> <volume>321</volume>, <fpage>140</fpage>–<lpage>143</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Harland</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Contreras</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Souder</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Fellous</surname>, <given-names>J. M.</given-names></string-name> <article-title>Dorsal CA1 hippocampal place cells form a multi-scale representation of megaspace</article-title>. <source>Current Biology</source> <volume>31</volume>, <fpage>2178</fpage>-<lpage>2190.e6</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Rich</surname>, <given-names>P. D.</given-names></string-name>, <string-name><surname>Liaw</surname>, <given-names>H. P.</given-names></string-name> &amp; <string-name><surname>Lee</surname>, <given-names>A. K.</given-names></string-name> <article-title>Large environments reveal the statistical structure governing hippocampal representations</article-title>. <source>Science (1979)</source> <volume>345</volume>, <fpage>814</fpage>–<lpage>817</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="other"><string-name><surname>Fenton</surname>, <given-names>A. A.</given-names></string-name> <etal>et al.</etal> <source>Behavioral/Systems/Cognitive Unmasking the CA1 Ensemble Place Code by Exposures to Small and Large Environments: More Place Cells and Multiple, Irregularly Arranged, and Expanded Place Fields in the Larger Space</source>. (<year>2008</year>) doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2862-08.2008</pub-id>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Park</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Dvorak</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Fenton</surname>, <given-names>A. A.</given-names></string-name> <article-title>Ensemble Place Codes in Hippocampus: CA1, CA3, and Dentate Gyrus Place Cells Have Multiple Place Fields in Large Environments</article-title>. <source>PLoS One</source> <volume>6</volume>, <fpage>22349</fpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Roth</surname>, <given-names>E. D.</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Rao</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Knierim</surname>, <given-names>J. J.</given-names></string-name> <article-title>Functional Differences in the Backward Shifts of CA1 and CA3 Place Fields in Novel and Familiar Environments</article-title>. <source>PLoS One</source> <volume>7</volume>, <fpage>e36035</fpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Xia</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Marks</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Goard</surname>, <given-names>M. J.</given-names></string-name> &amp; <string-name><surname>Wessel</surname>, <given-names>R.</given-names></string-name> <article-title>Stable representation of a naturalistic movie emerges from episodic activity with 2 gain variability</article-title>. <source>Nature Communications</source> 2021 12:1 <volume>12</volume>, <fpage>1</fpage>–<lpage>15</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><surname>Ikegaya</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal> <article-title>Synfire Chains and Cortical Songs: Temporal Modules of Cortical Activity</article-title>. <source>Science (1979)</source> <volume>304</volume>, <fpage>559</fpage>–<lpage>564</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Resnik</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>McFarland</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Sprengel</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Sakmann</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Mehta</surname>, <given-names>M. R.</given-names></string-name> <article-title>The Effects of GluA1 Deletion on the Hippocampal Population Code for Position</article-title>. <source>J Neurosci</source> <volume>32</volume>, <fpage>8952</fpage>–<lpage>68</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Felleman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Van</surname>, <given-names>D. C. E.</given-names></string-name> <article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title>. <source>Cereb Cortex</source> <volume>1</volume>, <fpage>1</fpage>–<lpage>47</lpage> (<year>1991</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname>, <given-names>M. A.</given-names></string-name> &amp; <string-name><surname>McNaughton</surname>, <given-names>B. L.</given-names></string-name> <article-title>Dynamics of the hippocampal ensemble code for space</article-title>. <source>Science (1979)</source> <volume>261</volume>, <fpage>1055</fpage>–<lpage>8</lpage>. (<year>1993</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="other"><string-name><surname>Purandare</surname>, <given-names>C. S.</given-names></string-name> <etal>et al.</etal> <article-title>Moving bar of light evokes vectorial spatial selectivity in the immobile rat hippocampus</article-title>. <source>Nature</source> 2022 <fpage>1</fpage>–<lpage>7</lpage> (<year>2022</year>) doi:<pub-id pub-id-type="doi">10.1038/s41586-022-04404-x</pub-id>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><surname>Jun</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal> <article-title>Disrupted Place Cell Remapping and Impaired Grid Cells in a Knockin Model of Alzheimer’s Disease</article-title>. <source>Neuron</source> <volume>107</volume>, <fpage>1095</fpage>-<lpage>1112.e6</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="other"><string-name><surname>Yartsev</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Witter</surname>, <given-names>M. P.</given-names></string-name> &amp; <string-name><surname>Ulanovsky</surname>, <given-names>N.</given-names></string-name> <article-title>Grid cells without theta oscillations in the entorhinal cortex of bats</article-title>. <source>Nature</source> (<year>2011</year>) doi:<pub-id pub-id-type="doi">10.1038/nature10583</pub-id>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><surname>Danjo</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Toyoizumi</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Fujisawa</surname>, <given-names>S.</given-names></string-name> <article-title>Spatial representations of self and other in the hippocampus</article-title>. <source>Science (1979)</source> <volume>359</volume>, <fpage>213</fpage>–<lpage>218</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><string-name><surname>McAvan</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Wank</surname>, <given-names>A. A.</given-names></string-name>, <string-name><surname>Rapcsak</surname>, <given-names>S. Z.</given-names></string-name>, <string-name><surname>Grilli</surname>, <given-names>M. D.</given-names></string-name> &amp; <string-name><surname>Ekstrom</surname>, <given-names>A. D.</given-names></string-name> <article-title>Largely intact memory for spatial locations during navigation in an individual with dense amnesia</article-title>. <source>Neuropsychologia</source> <volume>170</volume>, <fpage>108225</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="other"><string-name><surname>Harland</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Contreras</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Fellous</surname>, <given-names>J.-M.</given-names></string-name> <article-title>A Role for the Longitudinal Axis of the Hippocampus in Multiscale Representations of Large and Complex Spatial Environments and Mnemonic Hierarchies</article-title>. <source>The Hippocampus - Plasticity and Functions</source> (<year>2018</year>) doi:<pub-id pub-id-type="doi">10.5772/INTECHOPEN.71165</pub-id>.</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><string-name><surname>Spacek</surname>, <given-names>M. A.</given-names></string-name> <etal>et al.</etal> <article-title>Robust effects of corticothalamic feedback and behavioral state on movie responses in mouse dLGN</article-title>. <source>Elife</source> <volume>11</volume>, (<year>2022</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><string-name><surname>Norman-Haignere</surname>, <given-names>S. V.</given-names></string-name> <etal>et al.</etal> <article-title>Multiscale temporal integration organizes hierarchical computation in human auditory cortex</article-title>. <source>Nat Hum Behav</source> <volume>6</volume>, (<year>2022</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><string-name><surname>Gauthier</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Eger</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Hesselmann</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Giraud</surname>, <given-names>A. L.</given-names></string-name> &amp; <string-name><surname>Kleinschmidt</surname>, <given-names>A.</given-names></string-name> <article-title>Temporal tuning properties along the human ventral visual stream</article-title>. <source>Journal of Neuroscience</source> <volume>32</volume>, (<year>2012</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><string-name><surname>Hasson</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Vallines</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Rubin</surname>, <given-names>N.</given-names></string-name> <article-title>A Hierarchy of Temporal Receptive Windows in Human Cortex</article-title>. <source>Journal of Neuroscience</source> <volume>28</volume>, <fpage>2539</fpage>–<lpage>2550</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><string-name><surname>Sakai</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Miyashita</surname>, <given-names>Y.</given-names></string-name> <article-title>Neural organization for the long-term memory of</article-title>. <source>Nature</source> <volume>354</volume>, <fpage>152</fpage>–<lpage>155</lpage> (<year>1991</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="other"><string-name><surname>Mehta</surname>, <given-names>M. R.</given-names></string-name> &amp; <string-name><surname>McNaughton</surname>, <given-names>B. L.</given-names></string-name> <article-title>Expansion and Shift of Hippocampal Place Fields: Evidence for Synaptic Potentiation during Behavior</article-title>. <source>Computational Neuroscience</source> <fpage>741</fpage>–<lpage>745</lpage> (<year>1997</year>) doi:<pub-id pub-id-type="doi">10.1007/978-1-4757-9800-5_115</pub-id>.</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><string-name><surname>Ravassard</surname>, <given-names>P.</given-names></string-name> <etal>et al.</etal> <article-title>Multisensory control of hippocampal spatiotemporal selectivity</article-title>. <source>Science</source> <volume>340</volume>, <fpage>1342</fpage>–<lpage>6</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="web"><string-name><surname>Foster</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Knierim</surname>, <given-names>J. J.</given-names></string-name> <article-title>Sequence learning and the role of the hippocampus in rodent navigation</article-title>. <source>Current Opinion in Neurobiology</source> vol. <volume>22</volume> <fpage>294</fpage>–<lpage>300</lpage> Preprint at <pub-id pub-id-type="doi">10.1016/j.conb.2011.12.005</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><string-name><surname>Haggerty</surname>, <given-names>D. C.</given-names></string-name> &amp; <string-name><surname>Ji</surname>, <given-names>D.</given-names></string-name> <article-title>Activities of visual cortical and hippocampal neurons co-fluctuate in freely moving rats during spatial behavior</article-title>. <source>Elife</source> <volume>4</volume>, <fpage>e08902</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><string-name><surname>Saleem</surname>, <given-names>A. B.</given-names></string-name> <etal>et al.</etal> <article-title>Coherent encoding of subjective spatial position in visual cortex and hippocampus</article-title>. <source>Nature</source> <volume>562</volume>, <fpage>124</fpage>–<lpage>127</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><string-name><surname>Rutishauser</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Mamelak</surname>, <given-names>A. N.</given-names></string-name> &amp; <string-name><surname>Schuman</surname>, <given-names>E. M.</given-names></string-name> <article-title>Single-trial learning of novel stimuli by individual neurons of the human hippocampus-amygdala complex</article-title>. <source>Neuron</source> <volume>49</volume>, <fpage>805</fpage>–<lpage>813</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="other"><string-name><surname>Silson</surname>, <given-names>E. H.</given-names></string-name>, <string-name><surname>Zeidman</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Knapen</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Baker</surname>, <given-names>C. I.</given-names></string-name> <source>Representation of contralateral visual space in the human hippocampus 1 2</source>. (<year>2021</year>). doi:<pub-id pub-id-type="doi">10.1101/2020.07.30.228361</pub-id>.</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><string-name><surname>King</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Wyart</surname>, <given-names>V.</given-names></string-name> &amp; <string-name><surname>King</surname>, <given-names>J. R.</given-names></string-name> <article-title>The Human Brain Encodes a Chronicle of Visual Events at Each Instant of Time Through the Multiplexing of Traveling Waves</article-title>. <source>Journal of Neuroscience</source> <volume>41</volume>, <fpage>7224</fpage>–<lpage>7233</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><string-name><surname>Nishimoto</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <source>Reconstructing visual experiences from brain activity evoked by natural movies</source>. <volume>21</volume>, <fpage>1641</fpage>–<lpage>1646</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><string-name><surname>Nadel</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Peterson</surname>, <given-names>M. A.</given-names></string-name> <article-title>The hippocampus: part of an interactive posterior representational system spanning perceptual and memorial systems</article-title>. <source>J Exp Psychol Gen</source> <volume>142</volume>, <fpage>1242</fpage>–<lpage>1254</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="journal"><string-name><surname>Nadel</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Hardt</surname>, <given-names>O.</given-names></string-name> <article-title>Update on Memory Systems and Processes</article-title>. <source>Neuropsychopharmacology</source> 2011 36:1 <volume>36</volume>, <fpage>251</fpage>–<lpage>273</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="other"><string-name><surname>Stringer</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal> <source>Spontaneous behaviors drive multidimensional, brainwide activity</source>. (<year>2019</year>) doi:<pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id>.</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>Q.</given-names></string-name> <etal>et al.</etal> <article-title>The Allen Mouse Brain Common Coordinate Framework: A 3D Reference Atlas ll The Allen Mouse Brain Common Coordinate Framework: A 3D Reference Atlas</article-title>. <source>Cell</source> <volume>181</volume>, <fpage>936</fpage>–<lpage>953</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><string-name><surname>Hill</surname>, <given-names>D. N.</given-names></string-name>, <string-name><surname>Mehta</surname>, <given-names>S. B.</given-names></string-name> &amp; <string-name><surname>Kleinfeld</surname>, <given-names>D.</given-names></string-name> <article-title>Quality Metrics to Accompany Spike Sorting of Extracellular Signals</article-title>. <source>Journal of Neuroscience</source> <volume>31</volume>, <fpage>8699</fpage>–<lpage>8705</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="journal"><string-name><surname>Schmitzer-Torbert</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Jackson</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Henze</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Harris</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Redish</surname>, <given-names>A. D.</given-names></string-name> <article-title>Quantitative measures of cluster quality for use in extracellular recordings</article-title>. <source>Neuroscience</source> <volume>131</volume>, <fpage>1</fpage>–<lpage>11</lpage> (<year>2005</year>).</mixed-citation></ref>
</ref-list>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Experiments</title>
<p>We used the Allen Brain Observatory – Neuropixels Visual Coding dataset (© 2019 Allen Institute, <ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels">https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels</ext-link>). This website and related publication<sup><xref ref-type="bibr" rid="c31">31</xref></sup> contain detailed experimental protocol, neural recording techniques, spike sorting etc. Briefly, and of relevance here, prior to implantation with Neuropixel probes, mice passively viewed the entire range of images including drifting gratings, Gabor patches and the movies of interest here. Videos of the body and eye movements were obtained at 30Hz and synced to the neural data and stimulus presentation using a photodiode. Movies were presented monocularly on an LCD monitor with a refresh rate of 60Hz, positioned 15cm away from the mouse’s right eye and spanned 120°x95°. 30 trials of the continuous movie presentation were followed by 10 trials of the scrambled movie. Next was a presentation of drifting gratings, followed by a quiet period of 30 minutes where the screen was blank. Then the second block of drifting gratings, scrambled movie and continuous movie was presented.</p>
<p>Neural spiking data was sampled at 30 kHz with a 500Hz high pass filter. Spike sorting was automated using Kilosort2<sup><xref ref-type="bibr" rid="c77">77</xref></sup>. Output of Kilosort2 was post-processed to remove noise units, characterized by unphysiological waveforms. Neuropixel probes were registered to a common co-ordinate framework<sup><xref ref-type="bibr" rid="c78">78</xref></sup>. Each recorded unit was assigned to a recording channel corresponding to the maximum spike amplitude and then to the corresponding brain region. Broad spiking units identified as those with average spike waveform duration (peak to trough) between 0.45 to 1.5ms were analyzed herein.</p>
</sec>
<sec id="s4b">
<title>Movie tuning quantification</title>
<p>The movie consisted of 900 frames: 30s total, 30Hz refresh rate, 33.3ms per frame. At the first level of analysis, spike data were split into 900 bins, each 33.3ms wide (the bin size was later varied systematically to detect mega-scale tuning, see below). The resulting tuning curves were smoothed with a Gaussian window of σ=66.6 ms or 2 frames. The degree of modulation and its significance was estimated by the sparsity <italic>s</italic> as below, and as previously described methods<sup><xref ref-type="bibr" rid="c55">55</xref></sup>.
<disp-formula id="ueqn1">
<alternatives><graphic xlink:href="519455v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>r</italic><sub><italic>n</italic></sub> is the firing rate in the nth frame or bin and N=900 is the total number of bins. Statistical significance of sparsity was computed using a bootstrapping procedure, which does not assume a normal distribution. Briefly, for each cell, the spike train as a function of the frame number from each trial were circularly shifted by different amounts and the sparsity of the randomized data computed. This procedure was repeated 100 times with different amounts of random shifts. The mean value and standard deviation of the sparsity of randomized data were used to compute the z-scored sparsity of observed data using the function <italic>zscore</italic> in MATLAB. The observed sparsity was considered statistically significant if the z-scored sparsity of the observed spike train was greater 2, which corresponds to <italic>p</italic>&lt;0.023 in a one tailed t-test. Similar method was used to quantify significance of the scrambled movie tuning, as well as for the subset of data with only stationary epochs, or its equivalent subsample (see below). Middle 20 trials of the continuous movie were used in comparisons with the scrambled movie in <xref rid="fig4" ref-type="fig">Fig. 4</xref>, to ensure a fair comparison by using same number of trials, with similar time delays across measurements.</p>
</sec>
<sec id="s4c">
<title>Stationary epoch identification</title>
<p>To eliminate the confounding effects of changes in behavioral state associated with running, we repeated our analysis in stationary epochs, defined as epochs when the running speed remained less than 2cm/sec for this period, as well as at least 5 seconds before and after this period. Analysis was further restricted to sessions with at least 5 total minutes of these epochs during the 60 trials of continuous movie presentation. To account for using lesser data of the stationary epochs, we compared the tuning using a random subsample of data, regardless of running or stopping and compared the two results for difference in selectivity.</p>
</sec>
<sec id="s4d">
<title>Mega-scale movie-field detection in tuned neurons</title>
<p>For neurons with significant movie-sparsity, i.e., movie-tuned, the movie response was first recalculated at a higher resolution of 3.33ms (10 times the frame rate of 33.3ms). The <italic>findpeaks</italic> function in MATLAB was used to obtain peaks with <italic>prominence</italic> larger than 110% (1.1x) the range of firing variation obtained by chance, as determined from a sample shuffled response. This calculation was repeated at different smoothing values (logarithmically spaced in 10 Gaussian smoothing schemes with σ ranging from 6.7ms to 3430ms), to ensure that long as well as short movie-fields were reliably detected and treated equally. For frames where overlapping peaks were found at different smoothing levels, we employed a comparative algorithm to only select the peak(s) with higher prominence score. This score was obtained as the ratio of the peak’s prominence to the range of fluctuations in the correspondingly smoothed shuffle. This procedure was conducted iteratively, in increasing order of smoothing. If a broad peak overlapped with multiple narrow ones, the sum of scores of the narrow ones was compared with the broad one. To ensure that peaks at the beginning as well as the end of the movie frames were reliably detected, we circularly wrapped the movie response, for the observed as well as shuffle data.</p>
</sec>
<sec id="s4e">
<title>Identifying frames with significant deviations in multiple single-unit activity (MSUA)</title>
<p>First, the average response across tuned neurons for each brain region was computed for each movie frame, after normalizing the response of each cell by the peak firing response. This average response was used as the observed “Multiple single unit activity (MSUA)” in <xref rid="fig3" ref-type="fig">Fig. 3</xref>. To compute chance level, individual neuron responses were circularly shifted with respect to the movie frames to break the frame to firing rate association but maintain overall firing rate modulation. 100 such shuffles were used, and for each shuffle, the shuffled MSUA response was computed by averaging across neurons. Across these 100 shuffles, mean and standard deviation was obtained for all frames, and used to compute the z-score of the observed MSUA. To obtain significance at <italic>p</italic>=0.025 level, Bonferroni correction was applied, and the appropriate z-score (4.04) level was chosen. The number of frames in the observed MSUA above (and below) this level were further quantified in <xref rid="fig3" ref-type="fig">Fig. 3</xref>. The firing deviation for these frames was computed as the ratio between the mean observed MSUA and the mean shuffled MSUA, reported as a percentage, for frames corresponding to z-score greater than +4 or less than -4. To obtain a total firing rate report, where each spike gets equal vote, we computed the total firing response by computing the total rate across all tuned neurons (and averaging by the number of neurons) in <xref rid="fig3" ref-type="fig">Fig. 3</xref> and across all neurons in <xref rid="figED8" ref-type="fig">Extended Data Fig. 8</xref>.</p>
</sec>
<sec id="s4f">
<title>Population Vector Overlap</title>
<p>To evaluate the properties of a population of cells, movie presentations were divided into alternate trials, yielding even and odd blocks<sup><xref ref-type="bibr" rid="c52">52</xref></sup>. Population vector overlap was computed between the movie responses calculated separately for these 2 blocks of trials. Population vector overlap between frames <italic>x</italic> of the even trials &amp; frame <italic>y</italic> of the odd trials was defined as the Pearson correlation coefficient between the vectors <italic>(R</italic><sub><italic>1,x</italic></sub>, <italic>R</italic> <sub><italic>2,x</italic></sub>, <italic>… R</italic> <sub><italic>N,x</italic></sub> <italic>) &amp; (R</italic> <sub><italic>1,y</italic></sub>, <italic>R</italic> <sub><italic>2,y</italic></sub>, <italic>… R</italic> <sub><italic>N,y</italic></sub> <italic>)</italic>, where <italic>R</italic> <sub><italic>n,x</italic></sub> is the mean firing rate response of the <italic>n</italic><sup>th</sup> neuron to the <italic>x</italic><sup>th</sup> movie frame. N is the total number of neurons used, for each brain region. This calculation was done for <italic>x</italic> and <italic>y</italic> ranging from 1 to 900, corresponding to the 900 movie frames. The same method was used for tuned and untuned neurons in continuous movie responses in <xref rid="figED7" ref-type="fig">Extended Data Fig. 7</xref>, and for scrambled sequence responses in <xref rid="figED13" ref-type="fig">Extended Data Fig. 13</xref>.</p>
</sec>
<sec id="s4g">
<title>Decoding analysis</title>
<p>Methods similar to those previously described were used<sup><xref ref-type="bibr" rid="c54">54</xref>,<xref ref-type="bibr" rid="c55">55</xref></sup>. For tuned cells, the 60 trials of continuous movie were each decoded using all other trials. Mean firing rate responses in the 59 trials for 900 frames were used to compute a “look-up” matrix. Each neuron’s response was normalized between 0 and 1. At each frame in the “observed” trial, the correlation coefficient was computed between the population vector response in this trial and the look-up matrix. The frame corresponding to the maximal correlation was denoted as the decoded frame. Decoding error was computed as the average of the absolute difference between actual and decoded frames, across the 900 frames of the movie. For comparison, shuffle data was generated by randomly shuffling the cell-cell pairing of the look-up matrix and “observed response”. A similar procedure was used for the 20 trials of the scrambled sequence, and the corresponding middle 20 trials of the continuous movie were used.</p>
</sec>
<sec id="s4h">
<title>Rearranged scrambled movie analysis</title>
<p>To differentiate the effects of visual content versus visual continuity between consecutive frames, we compared the responses of the same neuron to the continuous movie and the scrambled sequence. In the scrambled movie, the same visual frames as the continuous movie were used, but they were shuffled in a pseudo random fashion. The same scrambled sequence was repeated for 20 trials. The neural response was computed at each frame of the scrambled sequence, keeping the frames in the chronological order of presentation. Then the scrambled sequence of frames was rearranged to recreate the continuous movie and the corresponding neural responses computed. To address the latency between movie frame presentation and its evoked neural response, which can differ across brain regions and neurons, this calculation was repeated for rearranged scrambled sequences with variable delays between τ= -500 to +500 ms (i.e., -150 to +150 frames of 3.33ms resolution, in steps of 5 frames or 16.6ms). The correlation coefficient was computed between the continuous movie response and this variable delayed response at each delay as r<sub>measured</sub> (τ) = corrcoef (R<sub>continuous</sub>, R<sub>scramble-rearranged</sub>(τ)). R<sub>continuous</sub> is the continuous movie response, obtained at 3.33ms resolution and similarly, R<sub>scramble-rearranged</sub> corresponds to the scrambled response after rearrangement, at the latency τ. The latency τ yielding the largest correlation between the continuous and rearranged scrambled movie was designated as the putative response latency for that neuron. This was used in Extended Data Fig.</p>
<p>12. The value of r<sub>measured</sub>(τ<sub>max</sub>) was bootstrapped using 100 randomly generated frame reassignments, and this was used to z-score r<sub>measured</sub>(τ<sub>max</sub>), with z-score &gt; 2 as criterion for significance. The resultant z-score is reported in <xref rid="figED12" ref-type="fig">Extended Data Fig. 12</xref>.</p>
</sec>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank the Allen Brain Institute for provision of the dataset, Dr. Josh Siegle for help with the dataset, Dr. Krishna Choudhary for proof-reading of the text and Dr. Massimo Scanziani for input and feedback. This work was supported by grants to M.R.M. by the National Institutes of Health NIH 1U01MH115746.</p>
</ack>
<sec id="s5">
<title>Author contributions</title>
<p>C.S.P. performed the analyses with input from M.R.M. C.S.P. and</p>
<p>M.R.M. wrote the manuscript.</p>
</sec>
<sec id="s6">
<title>Competing interests</title>
<p>Authors declare that they have no competing interests.</p>
</sec>
<sec id="s7">
<title>Data availability</title>
<p>All data is publicly available at the Allen Brain Observatory – Neuropixels Visual Coding dataset (© 2019 Allen Institute, <ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels">https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels</ext-link>).</p>
</sec>
<sec id="s8">
<title>Code availability</title>
<p>All analyses were performed using custom-written code in MATLAB version R2020a. Codes written for analysis and visualization are available from the corresponding authors at reasonable request.</p>
</sec>
<sec id="s9">
<title>Extended Data Figures</title>
<fig id="figED1" position="float" fig-type="figure">
<label>Extended Data Fig. 1</label>
<caption><title>The movie.</title>
<p>The 30 second long, isoluminant movie with frame numbers denoting key episodes in this continuous segment.</p></caption>
<graphic xlink:href="519455v1_figED1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED2" position="float" fig-type="figure">
<label>Extended Data Fig. 2</label>
<caption><title>Movie selectivity across brain areas.</title>
<p><bold>(a)</bold> Similar to <xref rid="fig1" ref-type="fig">Fig. 1</xref>, representative single cells from LGN showing selective movie responses. Fraction selective are shown by the bar chart on the right. <bold>(b)</bold> Same as (a), for V1. <bold>(c)</bold> Same as (a), for higher visual areas AM-PM. <bold>(d)</bold> Cumulative distribution of movie selectivity across all broad spiking cells, including tuned cells (z&gt;2 vertical black line, see <italic>Methods</italic>). Largest prevalence of selectivity in broad spiking neurons was seen in primary visual cortex (V1, 97.3%, 2606 out of 2679) and least in CA3 hippocampus (17.3%, 168 out of 969). <bold>(e)</bold> All brain regions analyzed showed far greater selectivity than the chance level (dashed gray line).</p></caption>
<graphic xlink:href="519455v1_figED2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED3" position="float" fig-type="figure">
<label>Extended Data Fig. 3</label>
<caption><title>Movie tuning is unaffected by locomotive state of the mouse</title>
<p><bold>(a)</bold> Similar to <xref rid="fig1" ref-type="fig">Fig. 1</xref>, a representative cell from each brain region showing significant modulation movie tuning using only the data when the mouse was immobile, while excluding the data when the mouse was running (stationary data, see <italic>Methods</italic>). All cells except for DG are from <xref rid="fig1" ref-type="fig">Fig. 1</xref> or <xref rid="figED2" ref-type="fig">Extended Data Fig. 2</xref>. <bold>(b)</bold> Fraction of selective neurons was significantly above chance in all brain regions, ranging from 94.7% in V1 up to 7.1% in CA3 in the stationary data. <bold>(c)</bold> To explicitly test the effect of running on movie selectivity, we compared the results in (b) with a random subsample of data that included running and stationary, to control for the loss of data (see <italic>Methods</italic>). Prevalence of movie selectivity was not significantly different (KS-test <italic>p</italic>&gt;0.18) in these 2 subsamples, except in CA1 (<italic>p</italic>=0.007, 13.1% in stationary data, 15.0% in the equivalent subsample). Only sessions with at least 300 seconds of stationary data were used in this analysis to ensure sufficient statistical power.</p></caption>
<graphic xlink:href="519455v1_figED3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED4" position="float" fig-type="figure">
<label>Extended Data Fig. 4</label>
<caption><title>Simultaneously recorded hippocampal cells have different movie tuning.</title>
<p>Four simultaneously recorded and significantly movie-tuned cells from each from <bold>(a)</bold> Dentate gyrus, <bold>(b)</bold> CA3, <bold>(c)</bold> CA1 and <bold>(d)</bold> Subiculum. Each cell shows different movie selectivity. Average responses are overlaid (on raster plots), and their color corresponds to the different brain regions, described in <xref rid="fig1" ref-type="fig">Fig. 1</xref> legend.</p></caption>
<graphic xlink:href="519455v1_figED4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED5" position="float" fig-type="figure">
<label>Extended Data Fig. 5</label>
<caption><title>Few hippocampal neurons had greater than 5 movie-fields.</title>
<p>Handful of movie-tuned neurons from dentate gyrus (row 1 and 2), CA3 (row 3 and 4), CA1 and subiculum (bottom-right), had multiple movie-fields. Average responses are overlaid (on raster plots), similar to <xref rid="fig1" ref-type="fig">Fig. 1</xref> and <xref rid="figED4" ref-type="fig">Extended Data Fig. 4</xref>.</p></caption>
<graphic xlink:href="519455v1_figED5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED6" position="float" fig-type="figure">
<label>Extended Data Fig. 6</label>
<caption><title>Movie-field duration ratios are shorter than expected by chance in visual, but not hippocampal areas.</title>
<p><bold>(a)</bold> Distribution of median duration of movie-fields, computed across all fields of a neuron. All visual-hippocampal region pairs were significantly different (KS-test <italic>p</italic>&lt;7.1×10<sup>−31</sup>). DG-CA3 and DG-CA1 were not significantly different, but other visual-visual and hippocampal-hippocampal region pairs were significantly different. (KS-test <italic>p</italic>&lt;0.04). CA3 had the largest median field duration (6.3±0.48s), and V1 had the smallest (0.27±0.03sec). Surprisingly, LGN movie-field durations (0.57±0.13s) were significantly longer than V1 (<italic>p</italic>=2.5×10<sup>−21</sup>), and comparable to those in the higher order brain areas (0.71±0.05s). <bold>(b)</bold> Median firing in movie-fields, normalized by that in the shuffle response, obtained as the median from all fields of a neuron. This metric is significantly different across all brain region pairs (KS-test <italic>p</italic>&lt;3.4×10<sup>−5</sup>), except DG-CA3, CA3-CA1 and DG-CA1 pairs. The largest median firing was seen for V1 (2.5±0.05), and the smallest in subiculum (1.13±0.03). <bold>(c)</bold> Cumulative firing in movie-fields, normalized by that in the shuffle response, obtained by adding the firing within all fields of a neuron was significantly different across all brain region pairs (KS-test <italic>p</italic>&lt;3.0×10<sup>−7</sup>), except DG-CA3, CA3-CA1 and DG-CA1. V1 response was largest (1.93±0.04), and subiculum was the smallest (1.11±0.02). <bold>(d)</bold> For each brain region, the movie-field duration ratio was recalculated by randomly reassigning the cell ids to all the movie peaks from that brain region. Using this new assignment of movie peaks to a cell, we obtain the chance level of mega-scale index (largest/smallest peak duration) within a cell. The observed mega-scale index was lesser than chance in all the visual areas (KS-test <italic>p</italic>&lt;3.2×10<sup>−3</sup>, median was 77.5%, 56.2% and 41.7% of chance for LGN, V1 and AM-PM respectively). This was not the case in hippocampal regions (<italic>p</italic>&gt;0.23). <bold>(e)</bold> Histogram of movie-fields, binned for their durations and their prominence, on a log-log scale. The most prominent fields tended to be wider in most brain areas, and this effect was stronger in hippocampal regions, than visual. Note that the histogram color is also logarithmically scaled.</p></caption>
<graphic xlink:href="519455v1_figED6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED7" position="float" fig-type="figure">
<label>Extended Data Fig. 7</label>
<caption><title>Population vector overlap is broader in hippocampus and more stable for tuned than untuned cells.</title>
<p><bold>(a)</bold> Population vector overlap between even and odd trials for the population of tuned neurons show highest overlap along the diagonal, i.e. the same movie frame, for all brain regions. Each neuron’s response was normalized by its mean rate and the average response in even as well as odd trials was smoothed by a Gaussian window of 2 frames (66.6ms, see <italic>Methods</italic>). Dashed black lines indicate the -300 and +300 frames away from the diagonal. Notice large correlations (close to unity, horizontal color bar) indicating stable responses. The correlations decay quickly to smaller values for the visual areas but slowly for hippocampal areas, due to their broader movie-fields. <bold>(b)</bold> Same as (a), but for untuned neurons, resulting in a salt and pepper overlap pattern and low values of correlation, indicating lesser stability than the tuned neurons. Since the majority of cells in the visual areas were tuned, the untuned population was smaller, leading to more variable population vector overlap. <bold>(c)</bold> The average overlap as a function of the number of movie frames away from the diagonal. It had a large value in visual regions for the 0<sup>th</sup> diagonal (colored lines) indicating stable responses, whereas the untuned neuron population (gray lines) were unstable, with values near zero, or chance level. The highest population vector overlap in hippocampal regions was smaller than visual areas but persisted for more frames, due to their broader movie-fields (Full width at half maximum of the peak – 17.3 frames for LGN, 22.7-V1, 39.0-AM&amp;PM, 49.8-DG, 57.4-CA3, 64.7-CA1 and 59.2-subiculum).</p></caption>
<graphic xlink:href="519455v1_figED7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED8" position="float" fig-type="figure">
<label>Extended Data Fig. 8</label>
<caption><title>Distribution of movie-fields reflects frame to frame correlation structure of the movie.</title>
<p><bold>(a)</bold> Histogram of movie-fields across all tuned neurons in a brain region, as a function of the movie frame, showing non-uniform distribution. Frame<sub>n</sub> to frame<sub>n+1</sub> correlation coefficient (F2F correlation), indicating the similarity of 2 consecutive frames, is shown for reference in gray. All distributions were deemed significantly different than a uniform distribution based on a Chi-square goodness-of-fit test (<italic>p</italic>&lt;3.8×10<sup>−6</sup>). All distributions were significantly negatively correlated with F2F correlation (r&lt;-0.18, <italic>p</italic>&lt;10<sup>−7</sup>). <bold>(b)</bold> Same as (a), but for the median duration of movie-fields. F2F correlation shown in gray, with large correlation between consecutive frames between frames 400-800 reflected in larger movie-field durations in visual areas. All distributions were significantly different than a uniform distribution based on a Chi-square goodness-of-fit test (<italic>p</italic>&lt;10<sup>−100</sup>) and all distributions were significantly positively correlated with F2F correlation (<italic>r</italic>&gt;0.24, <italic>p</italic>&lt;2×10<sup>−13</sup>). Note-y-axes for the histogram are log-scaled and show larger median durations for hippocampal regions than visual. <bold>(c)</bold> Total firing rate across all broad spiking neurons in different brain regions, showing similar non-uniformity as <xref rid="fig3" ref-type="fig">Fig. 3</xref>. All brain regions had significantly negative correlation with the F2F correlation (<italic>r</italic>&lt;-0.08, <italic>p</italic>&lt;0.03), except DG, which was significantly positively correlated (<italic>r</italic>=0.21, <italic>p</italic>=2.4×10<sup>−10</sup>). Largest number of above chance deviations were seen for AM-PM (340 frames), and least for CA3 (57 frames). Below chance level deviations were least common in LGN (25 frames), and most common in AM-PM (441 frames). Similar to <xref rid="fig3" ref-type="fig">Fig. 3c-e</xref>.</p></caption>
<graphic xlink:href="519455v1_figED8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED9" position="float" fig-type="figure">
<label>Extended Data Fig. 9</label>
<caption><title>Scrambled movie elicits narrower but more movie-fields per cell than the continuous movie in the visual regions.</title>
<p><bold>(a)</bold> Total number of fields per cell for the scrambled sequence were hierarchically arranged, with largest number of fields in LGN (mean±s.e.m., 31.8±2.0), followed by V1 (24.0±0.38) and last AM-PM (11.1±2.1). All three brain regions were significantly different from each other (KS-test <italic>p</italic>&lt;2.0×10<sup>−5</sup>). <bold>(b)</bold> Median scrambled movie-field duration was shortest in LGN (43.9±131.2ms), intermediate in V1 (46.2±24.8) and widest in AM-PM (77.6±40.1ms), and differences were significant (<italic>p</italic>&lt;7.0×10<sup>−4</sup>). This was much smaller than for the continuous movie (<xref rid="fig2" ref-type="fig">Fig. 2</xref>). <bold>(c)</bold> Durations of fields for scrambled sequence across all fields of all neurons from a brain region. These were narrowest in LGN (31.3±6.5ms), followed by V1 (38.6±0.2) and last AM-PM (64.3±6.7). All differences were significant (KS-test <italic>p</italic>&lt;7.2×10<sup>−136</sup>). <bold>(d)</bold> Despite these differences, the cumulative duration of movie-fields was comparable across the three brain regions (1.69±0.05sec for V1, 2.03±0.07 for AM-PM and 2.4±0.2 for LGN), but significantly different (<italic>p</italic>&lt;1.7×10<sup>−5</sup>). Note the linear scale on the x-axis in this panel compared to the log-scale in other panels. <bold>(e)</bold> Ratio of field durations, i.e., mega-scale index, was smallest in V1 (15.5±1.6), intermediate in LGN (16.3±5.4) and largest in AM-PM (23.4±2.1), and not significantly different between V1 and LGN (<italic>p</italic>=0.28). V1-AM&amp;PM and LGN-AM&amp;PM were significantly different (<italic>p</italic>&lt;5.7×10<sup>−5</sup>). <bold>(f)</bold> Cumulative firing activity, summed across all movie-fields of a given neuron was largest in V1 (3.8±0.1), intermediate in LGN (2.3±0.1) and smallest in AM-PM (2.0±0.07), and significantly different between all brain region pairs (<italic>p</italic>&lt;0.02).</p></caption>
<graphic xlink:href="519455v1_figED9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED10" position="float" fig-type="figure">
<label>Extended Data Fig. 10</label>
<caption><title>Scrambled sequence evoked movie-fields were narrower than the continuous movie-fields in all visual regions, cell by cell comparison.</title>
<p>Data for only those visual area neurons that were significantly modulated by both the continuous and scrambled movie were used. <bold>(a)</bold> The number of movie-fields per cell for the continuous movie was significantly smaller than that for scrambled sequence in all brain areas (LGN – continuous mean±s.e.m.=10.7±0.42, scrambled=31.8±2.0, KS-test <italic>p</italic>=2.0×10<sup>−23</sup>, V1-10.8±0.11 vs. 24.0±0.38, KS-test <italic>p=</italic>3.7×10<sup>−210</sup>, AM&amp;PM-6.9±0.07, vs. 11.1±0.21, KS-test <italic>p</italic>=1.3×10<sup>−57</sup>). Data are additionally scattered by a small random number for ease of visualization. <bold>(b)</bold> Median duration of movie-fields for a cell was significantly larger for continuous movie, compared to scrambled sequence in all visual regions. (LGN continuous=0.46±0.08sec, scrambled=0.04±0.13, KS-test <italic>p</italic>=7.1×10<sup>−65</sup>, V1-0.25±0.03 vs. 0.04±0.02, KS-test <italic>p&lt;</italic>10<sup>−150</sup>, AM&amp;PM-0.65±0.04, vs. 0.08±0.04, KS-test <italic>p</italic>&lt;10<sup>−150</sup>). <bold>(c)</bold> Cumulative duration of all movie-fields for a cell was significantly larger for continuous movie, compared to scrambled sequence in all visual regions. (continuous=8.9±0.23sec, scrambled=2.4±0.19, KS-test <italic>p</italic>=3.2×10<sup>−69</sup>, V1-6.1±0.09 vs. 1.69±0.05, KS-test <italic>p=</italic>3.3<italic>x</italic>10<sup>−296</sup>, AM&amp;PM-7.8±0.1, vs. 2.0±0.07, KS-test <italic>p</italic>=9.0×10<sup>−318</sup>). <bold>(d)</bold> Histogram of number of fields per cell, for continuous and scrambled movies. <bold>(e)</bold> Logarithmically spaced histogram of median field durations was significantly different between continuous and scrambled sequence. <bold>(f)</bold> Similar to (e), histogram of cumulative duration of movie-fields for each cell. <bold>(g)</bold> The ratio of number of fields per cell between continuous and scrambled movies was biased to smaller than unity values for all brain regions, with the largest bias for LGN (0.46±0.08), intermediate for V1 (0.5±0.04), and least for AM-PM (0.77±0.05). <bold>(h)</bold> The median field duration ratio was biased to values greater than unity, with the largest bias for LGN (7.4±1.4), least for V1 (4.5±0.68), and intermediate for AM-PM (5.5±0.82). <bold>(i)</bold> The cumulative field duration ratio was also biased to values greater than unity, with similar biases for LGN (3.37±0.36), V1 (3.1±0.3), and AM-PM (3.3±0.67).</p></caption>
<graphic xlink:href="519455v1_figED10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED11" position="float" fig-type="figure">
<label>Extended Data Fig. 11</label>
<caption><title>Multiple-single unit activity (MSUA) across all movie-tuned neurons in a brain region shows greater modulation than chance levels for scrambled sequence in all visual areas.</title>
<p><bold>(a)</bold> Stack plot of tuned responses to the scrambled movie presentation from each brain region, arranged in their increasing order of the frame corresponding to the peak firing response. Each response is normalized by the peak response. <bold>(b)</bold> Colored trace-average response, across all tuned responses from (b). gray trace - chance level, z=±4, corresponding to the <italic>p</italic>=0.025 level after Bonferroni correction. <bold>(c)</bold> Number of frames for which the observed response exceeds (or falls below) z=±4 cutoff from (b), called significantly deviant frames. V1 had the largest number of positive (279 frames) and negative (297) deviant frames, AM-PM had intermediate (225 &amp; 235), and LGN had the least (31 &amp; 29). <bold>(d)</bold> Firing rate deviation above chance levels, corresponding to the significant frames, as identified in (c), normalized by the mean rate of the MSUA. Largest deviation was observed in V1 (above-3.1 and below-2.7%), and least in LGN (1.1% and 0.45%) Compare with <xref rid="fig3" ref-type="fig">Fig. 3</xref>. <bold>(e)</bold> Frame to frame correlation, from <xref rid="fig4" ref-type="fig">Fig. 4a</xref> for comparison. This was not significantly correlated with the MSUA responses in (b), for any of the brain regions (<italic>Pearson</italic> correlation coefficient LGN <italic>p</italic>=0.06, V1 <italic>p</italic>=0.07, AM-PM <italic>p</italic>=0.26).</p></caption>
<graphic xlink:href="519455v1_figED11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED12" position="float" fig-type="figure">
<label>Extended Data Fig. 12</label>
<caption><title>Latency of responses to scrambled-sequence correspond to the anatomical hierarchy of visual areas.</title>
<p><bold>(a)</bold> Average response for one representative cell from each visual region, that had high similarity between continuous movie and rearranged scrambled sequence responses (see <italic>Methods</italic>). Gray response in background corresponds to the chronological scrambled sequence. <bold>(b)</bold> Cumulative histogram of z-scored correlation between continuous and scrambled-rearranged tuning responses (see <italic>Methods</italic>). Dotted black line indicates significance threshold of z&gt;2. <bold>(c)</bold> The latency at which continuous and scrambled-rearranged responses were maximally correlated showed high values (heuristically above 0.25) in a short range of positive latencies for LGN, V1 and AM-PM neurons. This analysis was restricted to neurons tuned in continuous as well as scrambled movies. Similar analysis for hippocampal regions resulted in almost no correlations above 0.25. <bold>(d)</bold> Cumulative histogram of latencies when the continuous and scrambled-rearranged responses were maximally correlated was smallest for LGN (59.5±4.6ms), and largest for higher visual areas, AM-PM (91.6±1.6ms). Hippocampal regions were excluded, owing to lack of data with correlation about 0.25.</p></caption>
<graphic xlink:href="519455v1_figED12.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED13" position="float" fig-type="figure">
<label>Extended Data Fig. 13</label>
<caption><title>Population vector overlap was narrow at the diagonal with scrambled movie</title>
<p><bold>(a)</bold> Population vector overlap between even and odd trials for tuned neurons showing higher overlap along the diagonal for all brain regions. Black lines indicate the -300 and +300 diagonal, whereas the main diagonal is the 0<sup>th</sup> diagonal. <bold>(b)</bold> Same as (a) but for untuned neurons, resulting in a salt and pepper overlap without higher correlation around the diagonal. <bold>(c)</bold> The average overlap along diagonals had a large value in visual regions for the 0<sup>th</sup> diagonal, which was not true for the untuned neuron population. Average correlation in hippocampal regions was broader and lesser in magnitude compared to visual regions. Similar to <xref rid="figED7" ref-type="fig">Extended Data Fig. 7</xref>. Full width at half maximum of the peak – 4.4 frames for LGN, 4.8-V1, 5.2-AM&amp;PM, 7.6-DG, 5.7-CA3, 10.8-CA1 and 15.1-subiculum.</p></caption>
<graphic xlink:href="519455v1_figED13.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figED14" position="float" fig-type="figure">
<label>Extended Data Fig. 14</label>
<caption><title>Movie presentation did not alter hippocampal firing rates and the mega-scale coding was unrelated to cluster quality.</title>
<p><bold>(a)</bold> More than 50% of hippocampal place cells shut down during maze exploration. In contrast, there was no consistent pattern of neural activation or shutdown during the movie presentation in all brain areas. To make a more conservative estimate, this comparison was restricted to units whose firing rates did not differ by more than 20% across the two movie blocks. Further only the data when the animals were immobile was used to avoid confounding effects of running. <bold>(b)</bold> The mega-scale index was only weakly correlated with the mean firing rate of a neuron in V1 (Pearson’s correlation coefficient <italic>r</italic>=0.08, <italic>p</italic>=7.3×10<sup>−5</sup>), CA1 (<italic>r</italic>=-0.14, <italic>p</italic>=3.5×10<sup>−8</sup>) and subiculum (<italic>r</italic>=-0.14, <italic>p</italic>=0.02), and was uncorrelated for other brain regions (<italic>p</italic>&gt;0.05) <bold>(c)</bold> The refractory violations index was uncorrelated with the mega-scale index (lower index means better cluster quality<sup><xref ref-type="bibr" rid="c31">31</xref>,<xref ref-type="bibr" rid="c79">79</xref></sup>) for all brain regions (<italic>p</italic>&gt;0.05). To remove potential confounding effect of mean firing rates, we computed the partial correlation coefficient, by factoring out the mean firing rate). <bold>(d)</bold> Similar to (c), the isolation index (greater isolation index means better cluster quality<sup><xref ref-type="bibr" rid="c31">31</xref>,<xref ref-type="bibr" rid="c80">80</xref></sup>) was uncorrelated with the mega-scale index for all brain regions (partial correlation coefficient, by factoring out the mean firing rate, <italic>p</italic>&gt;0.12). Factoring out mean firing rate was deemed necessary since the isolation index was typically positively correlated, and the refractory violations index was typically negatively correlated with mean rate. The mega-scale index comparisons were restricted to movie active, tuned neurons with at least two movie peaks. Note-log spaced axes for (a)-(d)</p></caption>
<graphic xlink:href="519455v1_figED14.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.85069.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>This manuscript analyzes large-scale Neuropixels recordings from visual areas and hippocampus of mice passively viewing repeated clips of a movie and reports that neurons respond with elevated firing activities to specific, continuous sequences of movie frames. The <bold>important</bold> results support a role of rodent hippocampal neurons in general episode encoding and advance understanding of visual information processing across different brain regions. The strength of evidence for the primary conclusion is <bold>solid</bold>, but some technical limitations of the study were identified that merit further analyses.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.85069.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Taking advantage of a publicly available dataset, neuronal responses in both the visual and hippocampal areas to passive presentation of a movie are analyzed in this manuscript. Since the visual responses have been described in a number of previous studies (e.g., see Refs. 11-13), the value of this manuscript lies mostly on the hippocampal responses, especially in the context of how hippocampal neurons encode episodic memories. Previous human studies show that hippocampal neurons display selective responses to short (5 s) video clips (e.g. see Gelbard-Sagiv et al, Science 322: 96-101, 2008). The hippocampal responses in head-fixed mice to a longer (30 s) movie as studied in this manuscript could potentially offer important evidence that the rodent hippocampus encodes visual episodes.</p>
<p>The analysis strategy is mostly well designed and executed. A number of factors and controls, including baseline firing, locomotion, frame-to-frame visual content variation, are carefully considered. The inclusion of neuronal responses to scrambled movie frames in the analysis is a powerful method to reveal the modulation of a key element in episodic events, temporal continuity, on the hippocampal activity. The properties of movie fields are comprehensively characterized in the manuscript.</p>
<p>Although the hippocampal movie fields appear to be weaker than the visual ones (Fig. 2g, Ext. Fig. 6b), the existence of consistent hippocampal responses to movie frames is supported by the data shown. Interestingly, in my opinion, a strong piece of evidence for this is a &quot;negative&quot; result presented in Ext. Fig. 13c, which shows higher than chance-level correlations in hippocampal responses to same scrambled frames between even and odd trials (and higher than correlations with neighboring scrambled frames). The conclusion that hippocampal movie fields depend on continuous movie frames, rather than a pure visual response to visual contents in individual frames, is supported to some degree by their changed properties after the frame scrambling (Fig. 4). However, there are two potential issues that could complicate this main conclusion.</p>
<p>One issue is related to the effect of behavioral variation or brain state. First, although the authors show that the movie fields are still present during low-speed stationary periods, there is a large drop in the movie tuning score (Z), especially in the hippocampal areas, as shown in Ext. Fig. 3b (compared to Ext. Fig. 2d). This result suggests a potentially significant enhancement by active behavior.</p>
<p>Second, a general, hard-to-tackle concern is that neuronal responses could be greatly affected by changes in arousal or brain state (including drowsy or occasional brief slow-wave sleep state) in head-fixed animals without a task. Without the analysis of pupil size or local field potentials (LFPs), the arousal states during the experiment are difficult to know. Many example movie fields in the presented raw data (e.g., Fig. 1c, Ext. Fig. 4) are broad with low-quality tuning, which could be due to broad changes in brain states. This concern is especially important for hippocampal responses, since the hippocampus can enter an offline mode indicated by the occurrence of LFP sharp-wave ripples (SWRs) while animals simply stay immobile. It is believed that the ripple-associated hippocampal activity is driven mainly by internal processing, not a direct response to external input (e.g., Foster and Wilson, Nature 440: 680, 2006). The &quot;actual&quot; hippocampal movie fields during a true active hippocampal network state, after the removal of SWR time periods, could have different quantifications that impact the main conclusion in the manuscript.</p>
<p>Another issue is related to the relative contribution of direct visual response versus the response to temporal continuity in movie fields. First, the data in Ext. Fig. 8 show that rapid frame-to-frame changes in visual contents contribute largely to hippocampal movie fields (similarly to visual movie fields). Interestingly, the data show that movie-field responses are correlated across all brain areas including the hippocampal ones. This could be due to heightened behavioral arousal caused by the changing frames as mentioned above, or due to enhanced neuronal responses to visual transients, which supports a component of direct visual response in hippocampal movie fields. Second, the data in Ext. Fig. 13c show a significant correlation in hippocampal responses to same scrambled frames between even and odd trials, which also suggests a significant component of direct visual response.</p>
<p>Is there a significant component purely due to the temporal continuity of movie frames in hippocampal movie fields? To support that this is indeed the case, the authors have presented data that hippocampal movie fields largely disappear after movie frames are scrambled. However, this could be caused by the movie-field detection method (it is unclear whether single-frame field could be detected). Another concern in the analysis is that movie-fields are not analyzed on re-arranged neural responses to scrambled movie frames. The raw data in Fig. 4e seem quite convincing. Unfortunately, the quantifications of movie fields in this case are not compared to those with the original movie.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.85069.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Purandare and Mehta investigated the neural activities modulated by continuous and sequential visual stimuli composed of natural images, termed &quot;movie-tuning,&quot; measured along the visuo-hippocampal network when the animals passively viewed a movie without any task demand. Neurons selectively responded to some specific parts of the movie, and their activity timescales ranged from tens of milliseconds to seconds and tiled the entire movie with their movie-fields. The movie-tuning was lost in the hippocampus but not in the visual cortices when the image frames were temporally scrambled, implying that the rodent hippocampus encoded the specific sequence of images.</p>
<p>The authors have concluded that the neurons in the thalamo-cortical visual areas and the hippocampus commonly encode continuous visual stimuli with their firing fields spanning the mega-scale, but they respond to different aspects of the visual stimuli (i.e., visual contents of the image versus a sequence of the images). The conclusion of the study is fairly supported by the data, but some remaining concerns should be addressed.</p>
<p>1. Care should be taken in interpreting the results since the animal's behavior was not controlled during the physiological recording. It has been reported that some hippocampal neuronal activities are modulated by locomotion, which may still contribute to some of the results in the current study. Although the authors claimed that the animal's locomotion did not influence the movie-tuning by showing the unaltered proportion of movie-tuned cells with stationary epochs only, the effects of locomotion should be tested in a more specific way (e.g., comparing changes in the strength of movie-tuning under certain locomotion conditions at the single-cell level).</p>
<p>2. The mega-scale spanning of movie-fields needs to be further examined with a more controlled stimulus for reasonable comparison with the traditional place fields. This is because the movie used in the current study consists of a fast-changing first half and a slow-changing second half, and such varying and ununified composition of the movie might have largely affected the formation of movie-fields. According to Fig. 3, the mega-scale spanning appears to be driven by the changes in frame-to-frame correlation within the movie. That is, visual stimuli changing quickly induced several short fields while persisting stimuli with fewer changes elongated the fields. The presentation of persisting visual input for a long time is thought to be similar to staying in one place for a long time, and the hippocampal activities have been reported to manifest in different ways between running and standing still (i.e., theta-modulated vs. sharp wave ripple-based). Therefore, it should be further examined whether the broad movie-fields are broadly tuned to the continuous visual inputs or caused by other brain states.</p>
<p>3. The population activities of the hippocampal movie-tuned cells in Fig. 3a-b look like those of time cells, tiling the movie playback period. It needs to be clarified whether the hippocampal cells are actively coding the visual inputs or just filling the duration. The scrambled condition in which the sequence of the images was randomly permutated made the hippocampal neurons totally lose their selective responses, failing to reconstruct the neural responses to the original sequence by rearrangement of the scrambled sequence. This result indirectly addressed that the substantial portion of the hippocampal cells did not just fill the duration but represented the contents and temporal order of the images. However, it should be directly confirmed whether the tiling pattern disappeared with the population activities in the scrambled condition (as shown in Extended Data Fig. 11, but data were not shown for the hippocampus).</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.85069.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In their study, Purandare &amp; Mehta analyze large-scale single unit recordings from the visual system (LGN, V1, extrastriate regions AM and PM) and hippocampal system (DG, CA3, CA1 and subiculum) while mice monocularly viewed repeats of a 30s movie clip. The data were part of a larger release of publicly available recordings from the Allen Brian Observatory. The authors found that cells in all regions exhibited tuning to specific segments of the movie (i.e. &quot;movie fields&quot;) ranging in duration from 20ms to 20s. The largest fractions of movie-responsive cells were in visual regions, though analyses of scrambled movie frames indicated that visual neurons were driven more strongly by visual features of the movie images themselves. Cells in the hippocampal system, on the other hand, tended to exhibit fewer &quot;movie fields&quot;, which on average were a few seconds in duration, but could range from &gt;50ms to as long as 20s. Unlike the visual system &quot;movie fields&quot; in the hippocampal system disappeared when the frames of the movie were scrambled, indicating that the cells encoded more complex (episodic) content, rather than merely passively reading out visual input.</p>
<p>The paper is conceptually novel since it specifically aims to remove any behavioral or task engagement whatsoever in the head-fixed mice, a setup typically used as an open-loop control condition in virtual reality-based navigational or decision making tasks (e.g. Harvey et al., 2012). Because the study specifically addresses this aspect of encoding (i.e. exploring effects of pure visual content rather than something task-related), and because of the widespread use of video-based virtual reality paradigms in different sub-fields, the paper should be of interest to those studying visual processing as well as those studying visual and spatial coding in the hippocampal system. However, the task-free approach of the experiments (including closely controlling for movement-related effects) presents a Catch-22, since there is no way that the animal subjects can report actually recognizing or remembering any of the visual content we are to believe they do. We must rely on above-chance-level decoding of movie segments, and the requirement that the movie is played in order rather than scrambled, to indicate that the hippocampal system encodes episodic content of the movie. So the study represents an interesting conceptual advance, and the analyses appear solid and support the conclusion, but there are methodological limitations.</p>
<p>Major concerns:</p>
<p>1. A lot hinges on hinges on the cells having a z-scored sparsity &gt;2, the cutoff for a cell to be counted as significantly modulated by the movie. What is the justification of this criterion? It should be stated in the Results. Relatedly, it appears the formula used for calculating sparseness in the present study is not the same as that used to calculate lifetime sparseness in de Vries et al. 2020 quoted in the results (see the formula in the Methods of the de Vries 2020 paper immediately under the sentence: &quot;Lifetime sparseness was computed using the definition in Vinje and Gallant&quot;).</p>
<p>To rule out systematic differences between studies beyond differences in neural sampling (single units vs. calcium imaging), it would be nice to see whether calculating lifetime sparseness per de Vries et al. changed the fraction &quot;movie&quot; cells in the visual and hippocampal systems.</p>
<p>1. In Figures 1, 2 and the supplementary figures-the sparseness scores should be reported along with the raw data for each cell, so the readers can be apprised of what types of firing selectivity are associated with which sparseness scores-as would be shown for metrics like gridness or Raleigh vector lengths for head direction cells. It would be helpful to include this wherever there are plots showing spike rasters arranged by frame number &amp; the trial-averaged mean rate.</p>
<p>2. The examples shown on the right in Figures 1b and c are not especially compelling examples of movie-specific tuning; it would be helpful in making the case for &quot;movie&quot; cells if cleaner / more robust cells are shown (like the examples on the left in 1b and c).</p>
<p>3. The scrambled movie condition is an essential control which, along with the stability checks in Supplementary Figure 7, provide the most persuasive evidence that the movie fields reflect more than a passive readout of visual images on a screen. However, in reference to Figure 4c, can the authors offer an explanation as to why V1 is substantially less affected by the movie scrambling than it's main input (LGN) and the cortical areas immediately downstream of it? This seems to defy the interpretation that &quot;movie coding&quot; follows the visual processing hierarchy. Relatedly, the hippocampal data do not quite fit with visual hierarchical ordering either, with CA3 being less sensitive to scrambling than DG. Since the data (especially in V1) seem to defy hierarchical visual processing, why not drop that interpretation? It is not particularly convincing as is.</p>
<p>4. In the Discussion, the authors argue that the mice encode episodic content from the movie clip as a human or monkey would. This is supported by the (crucial) data from the scrambled movie condition, but is nevertheless difficult to prove empirically since the animals cannot give a behavioral report of recognition and, without some kind of reinforcement, why should a segment from a movie mean anything to a head-fixed, passively viewing mouse? Would the authors also argue that hippocampal cells would exhibit &quot;song&quot; fields if segments of a radio song-equally arbitrary for a mouse-were presented repeatedly? (reminiscent of the study by Aronov et al. 2017, but if sound were presented outside the context of a task). How can one distinguish between mere sequence coding vs. encoding of episodically meaningful content? One or a few sentences on this should be added in the Discussion.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.85069.1.sa4</article-id>
<title-group>
<article-title>Author Response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Purandare</surname>
<given-names>Chinmay S.</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mehta</surname>
<given-names>Mayank R.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2005-2468</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>eLife assessment</bold></p>
<p>This manuscript analyzes large-scale Neuropixels recordings from visual areas and hippocampus of mice passively viewing repeated clips of a movie and reports that neurons respond with elevated firing activities to specific, continuous sequences of movie frames. The important results support a role of rodent hippocampal neurons in general episode encoding and advance understanding of visual information processing across different brain regions. The strength of evidence for the primary conclusion is solid, but some technical limitations of the study were identified that merit further analyses.</p>
</disp-quote>
<p>We thank the editors and reviews for the assessment and reviews. We have provided clarifications and updated the manuscripts to address the seeming technical limitations that are perhaps due to some misunderstanding, please see below. We provide additional results that isolate the contribution of pupil diameter, sharpwave ripple and theta power to show that movie tuning cannot be explained by these nonspecific effects. Nor are these mere time cells or some other internally generated patterns due to many differences highlighted below.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Taking advantage of a publicly available dataset, neuronal responses in both the visual and hippocampal areas to passive presentation of a movie are analyzed in this manuscript. Since the visual responses have been described in a number of previous studies (e.g., see Refs. 11-13), the value of this manuscript lies mostly on the hippocampal responses, especially in the context of how hippocampal neurons encode episodic memories. Previous human studies show that hippocampal neurons display selective responses to short (5 s) video clips (e.g. see Gelbard-Sagiv et al, Science 322: 96-101, 2008). The hippocampal responses in head-fixed mice to a longer (30 s) movie as studied in this manuscript could potentially offer important evidence that the rodent hippocampus encodes visual episodes.</p>
</disp-quote>
<p>We have now included citations to Gelbard-Sagiv et al. Science 2008 paper and many other references too, thank you for pointing that out. There are major differences between that study and ours.</p>
<list list-type="bullet">
<list-item><p>The movies used in previous study contained very familiar, famous people and famous events, and the experiment was about the patient’s ability to recall those famous movie episodes. In our case the mice had seen this movie clip only twice before.</p>
</list-item>
<list-item><p>They did not look at the fine structure of neural responses below half a second whereas we looked at the mega-scale representations from 30ms to 30s.</p>
</list-item>
<list-item><p>The movie clips in that study were in full color with audio, we used an isoluminant, black-and-white, silent movie clip.</p>
</list-item>
<list-item><p>Their movie clips contained humans and was observed by humans, whereas our study mice observed a movie clip with humans and no mice or other animals.</p>
</list-item>
</list>
<disp-quote content-type="editor-comment">
<p>The analysis strategy is mostly well designed and executed. A number of factors and controls, including baseline firing, locomotion, frame-to-frame visual content variation, are carefully considered. The inclusion of neuronal responses to scrambled movie frames in the analysis is a powerful method to reveal the modulation of a key element in episodic events, temporal continuity, on the hippocampal activity. The properties of movie fields are comprehensively characterized in the manuscript.</p>
</disp-quote>
<p>Thank you.</p>
<disp-quote content-type="editor-comment">
<p>Although the hippocampal movie fields appear to be weaker than the visual ones (Fig. 2g, Ext. Fig. 6b), the existence of consistent hippocampal responses to movie frames is supported by the data shown. Interestingly, in my opinion, a strong piece of evidence for this is a &quot;negative&quot; result presented in Ext. Fig. 13c, which shows higher than chance-level correlations in hippocampal responses to same scrambled frames between even and odd trials (and higher than correlations with neighboring scrambled frames). The conclusion that hippocampal movie fields depend on continuous movie frames, rather than a pure visual response to visual contents in individual frames, is supported to some degree by their changed properties after the frame scrambling (Fig. 4).</p>
</disp-quote>
<p>Yes, hippocampal selectivity is not entirely abolished with scrambled movie, as we show in several figures (Fig 4d,g and Extended Data Fig. 16), but it is greatly reduced, far more than in the afferent visual cortices. The fraction of tuned cells for scrambled movies dropped to 4.5% in hippocampus, which is close to the chance level of 3%. In contrast, in visual areas selectivity was still above 80%.</p>
<p>Significant overlap between even and odd trials is to be expected for the tuned cells. Without a significant overlap, i.e. a stable representation, they will not be tuned. Despite this, the correlation between even and odd trials for the (only 4.5% of) tuned cells in the hippocampus was more than 2-fold smaller than (more than 80% of) cells in visual cortices. This strongly supports our hypothesis that unlike visual cortices, hippocampal subfields depended very strongly on the continuity of visual information. We will clarify this in the main text.</p>
<disp-quote content-type="editor-comment">
<p>However, there are two potential issues that could complicate this main conclusion.</p>
<p>One issue is related to the effect of behavioral variation or brain state. First, although the authors show that the movie fields are still present during low-speed stationary periods, there is a large drop in the movie tuning score (Z), especially in the hippocampal areas, as shown in Ext. Fig. 3b (compared to Ext. Fig. 2d). This result suggests a potentially significant enhancement by active behavior.</p>
</disp-quote>
<p>There seems to be some misunderstanding here. There was no major reduction in movie tuning during immobility or active running. As we wrote in the manuscript, the drop in selectivity during purely immobile epochs is because of reduction in the amount of data, not reduction in selectivity per se. Specifically, as the amount data reduces, the statistical strength of tuning (z-scored sparsity) reduces. For example, if we split the total of 60 trials worth of data into two parts, the amount of data reduces to about half in each part, leading to a seeming reduction in selectivity in both halves. Extended figure 2B shows nearly identical tuning in all brain regions during immobility and equivalent subsamples chosen randomly from the entire data, including mobility and immobility. We will include additional data in the revised manuscript to demonstrate this more clearly. Please see below for more details.</p>
<disp-quote content-type="editor-comment">
<p>Second, a general, hard-to-tackle concern is that neuronal responses could be greatly affected by changes in arousal or brain state (including drowsy or occasional brief slow-wave sleep state) in head-fixed animals without a task. Without the analysis of pupil size or local field potentials (LFPs), the arousal states during the experiment are difficult to know.</p>
</disp-quote>
<p>In the revised manuscript we will that the behavioral state effects cannot explain movie tuning. Specifically:</p>
<list list-type="bullet">
<list-item><p>We compare sessions in which the mouse was mostly immobile versus sessions in which the mouse was mostly running. Movie tuned cells were found in both these cases (Extended Data Fig. 7).</p>
</list-item>
<list-item><p>b. We detect and remove all data around sharp-wave ripples (SWR). Movie tuning was unchanged in the remaining data.</p>
</list-item>
<list-item><p>c. As a further control, we quantified arousal by two standard metrics. First within a session, we split the data into two groups, segments with high theta power and segments with low theta power. Significant movie tuning persisted in both.</p>
</list-item>
<list-item><p>d. Finally, pupil dilation is another common method to estimate arousal, so data within a session were split into two parts: those with pupil dilation versus constriction. Movie tuning remained significant in both parts. See the new Extended Data Fig. 7.</p>
</list-item>
</list>
<disp-quote content-type="editor-comment">
<p>Many example movie fields in the presented raw data (e.g., Fig. 1c, Ext. Fig. 4) are broad with low-quality tuning, which could be due to broad changes in brain states. This concern is especially important for hippocampal responses, since the hippocampus can enter an offline mode indicated by the occurrence of LFP sharp-wave ripples (SWRs) while animals simply stay immobile. It is believed that the ripple-associated hippocampal activity is driven mainly by internal processing, not a direct response to external input (e.g., Foster and Wilson, Nature 440: 680, 2006). The &quot;actual&quot; hippocampal movie fields during a true active hippocampal network state, after the removal of SWR time periods, could have different quantifications that impact the main conclusion in the manuscript.</p>
</disp-quote>
<p>We included the broadly tuned hippocampal neurons to demonstrate the movie-field broadening compared to those in visual areas. We will include more examples with sharp movie fields in the hippocampal regions (Main figure 1a-d right column, 2d and h, Extended Data Fig 5 and 8). Further, as stated above, we detected sharp-wave ripples and removed one second of data around SWR. Move tuning was unchanged in the remaining data. Thus, movie tuning is not generated internally via SWR (Extended Data Fig. 6). See also Extended Data 7 and 8 and the response above.</p>
<disp-quote content-type="editor-comment">
<p>Another issue is related to the relative contribution of direct visual response versus the response to temporal continuity in movie fields. First, the data in Ext. Fig. 8 show that rapid frame-to-frame changes in visual contents contribute largely to hippocampal movie fields (similarly to visual movie fields).</p>
</disp-quote>
<p>There seems to be some misunderstanding here. That figure showed that the frame-toframe changes in the visual content had the highest effect on visual areas MSUA and much weaker in hippocampus (Extended Data Fig. 8, as per previous version). For example, the depth of modulation (max – min) / (max + min) for MSUA was 21% and 24% for V1 but below 6% for hippocampal regions. Similarly, the MSUA was more strongly (negatively) correlated with F2F correlation for visual areas (r=0.48 to 0.56) than hippocampal (0.07 to 0.3). Similarly, comparing the number of peaks or their median widths, visual regions showed stronger correlation with F2F, and largest depth of modulation than hippocampal regions, barring handful exceptions (like CA3 correlation between F2F and median peak duration). This strongly supports our claim that visual regions generated far greater response of the frame-to-frame changes in the movie than hippocampal regions.</p>
<disp-quote content-type="editor-comment">
<p>Interestingly, the data show that movie-field responses are correlated across all brain areas including the hippocampal ones.</p>
</disp-quote>
<p>The changes in multiunit activity are strongly correlated only between visual areas and some of the hippocampal region pairs. The correlation is much weaker for hippocampal areas, or hippocampal-visual area pairs. This will be quantified explicitly in the revised text Extended Data Fig. 11 with an additional correlation matrix. Further, in Fig 3c we compared the MSUA responses with normalization between brain regions. Amongst the 21 possible brain region pairs, 5 were uncorrelated, 7 were significantly negatively correlated and 9 were significantly correlated.</p>
<disp-quote content-type="editor-comment">
<p>This could be due to heightened behavioral arousal caused by the changing frames as mentioned above, or due to enhanced neuronal responses to visual transients, which supports a component of direct visual response in hippocampal movie fields.</p>
</disp-quote>
<p>As shown in Extended data 7 and 8 and described above, the effect of arousal as quantified by theta power of pupil diameter cannot explain the results in hippocampal areas and the correlations in multiunit responses are unrelated across many brain areas.</p>
<disp-quote content-type="editor-comment">
<p>Second, the data in Ext. Fig. 13c show a significant correlation in hippocampal responses to same scrambled frames between even and odd trials, which also suggests a significant component of direct visual response.</p>
</disp-quote>
<p>This is plausible. The fraction of hippocampal cells which were significantly tuned for the scrambled presentation (4.5%) was close to chance level (3%), and this small subset of cells was used to compute the population overlap between even and odd trials in Ext Fig. 13 (old numbering). As described above, this significant but small amount of tuning could generate significant population overlap, which is to be expected by construction.</p>
<disp-quote content-type="editor-comment">
<p>Is there a significant component purely due to the temporal continuity of movie frames in hippocampal movie fields? To support that this is indeed the case, the authors have presented data that hippocampal movie fields largely disappear after movie frames are scrambled. However, this could be caused by the movie-field detection method (it is unclear whether single-frame field could be detected).</p>
</disp-quote>
<p>As described in the methods section, the movie-field detection algorithm had a resolution of 3.3ms resolution, which ensured that we could detect single frame fields. As reported, we did find such short movie fields in several cells in the visual areas. The sparsity metric used is agnostic to the ordering of the responses, and hence single frame field, and the resultant significant movie-tuning, if present, can be detected by our methods.</p>
<disp-quote content-type="editor-comment">
<p>Another concern in the analysis is that movie-fields are not analyzed on re-arranged neural responses to scrambled movie frames. The raw data in Fig. 4e seem quite convincing. Unfortunately, the quantifications of movie fields in this case are not compared to those with the original movie.</p>
</disp-quote>
<p>We saw very few (3.6-4.9%) cells with significant movie tuning for scrambled presentation in the hippocampus. Hence, we did not quantify this earlier. This is now provided in new Extended Data Fig. 16. The amount of movie tuning for the scrambled presentation taken as-is, or after rearranging the frames is below 5% for all hippocampal brain regions.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>[…] The authors have concluded that the neurons in the thalamo-cortical visual areas and the hippocampus commonly encode continuous visual stimuli with their firing fields spanning the mega-scale, but they respond to different aspects of the visual stimuli (i.e., visual contents of the image versus a sequence of the images). The conclusion of the study is fairly supported by the data, but some remaining concerns should be addressed.</p>
<p>1. Care should be taken in interpreting the results since the animal's behavior was not controlled during the physiological recording.</p>
</disp-quote>
<p>This was done intentionally since plenty of research shows that task demand (e.g., Aronov and Tank, Nature 2017) can not only modulate hippocampal responses but also dramatically alter them. We have now provided additional figures (Extended Data Fig. 6 and 7) where we quantified the effects of the behavioral states (sharp wave ripples, theta power and pupil diameter), as well as the effect of locomotion (Extended Data Fig. 4). Movie tuning remained unaffected with these manipulations. Thus, movie tuning cannot be attributed to behavioral effects.</p>
<disp-quote content-type="editor-comment">
<p>It has been reported that some hippocampal neuronal activities are modulated by locomotion, which may still contribute to some of the results in the current study. Although the authors claimed that the animal's locomotion did not influence the movie-tuning by showing the unaltered proportion of movie-tuned cells with stationary epochs only, the effects of locomotion should be tested in a more specific way (e.g., comparing changes in the strength of movie-tuning under certain locomotion conditions at the single-cell level).</p>
</disp-quote>
<p>Single cell analysis of the effect of locomotion and visual stimulation is underway, and beyond the scope of the current work. As detailed in the (Extended Data Fig. 4), we have ensured that in spite of the removal of running or stationary epochs, as well as removal of sharp wave ripple events (Extended Data Fig. 6) movie tuning persists. Further, we will provide examples of strongly tuned cells from sessions with predominantly running or predominantly stationary behavior (Extended Data Fig. 7).</p>
<disp-quote content-type="editor-comment">
<p>1. The mega-scale spanning of movie-fields needs to be further examined with a more controlled stimulus for reasonable comparison with the traditional place fields. This is because the movie used in the current study consists of a fast-changing first half and a slow-changing second half, and such varying and ununified composition of the movie might have largely affected the formation of movie-fields. According to Fig. 3, the mega-scale spanning appears to be driven by the changes in frame-to-frame correlation within the movie. That is, visual stimuli changing quickly induced several short fields while persisting stimuli with fewer changes elongated the fields.</p>
</disp-quote>
<p>Please note that a strong correlation between the speed at which the movie scene changed across frames was correlated with movie-field width in the visual areas, but that correlation was much weaker in the hippocampal areas (see above). Please see Extended Data Fig. 11 and the quantification of correlation between frame-to-frame changes in the movie and the properties of movie fields.</p>
<disp-quote content-type="editor-comment">
<p>The presentation of persisting visual input for a long time is thought to be similar to staying in one place for a long time, and the hippocampal activities have been reported to manifest in different ways between running and standing still (i.e., theta-modulated vs. sharp wave ripple-based). Therefore, it should be further examined whether the broad movie-fields are broadly tuned to the continuous visual inputs or caused by other brain states.</p>
</disp-quote>
<p>As shown in Extended Data Fig. 6, movie field properties are largely unchanged when SWR are removed from the data, or when the effect of pupil diameter or theta power were factored for (Extended Data Fig.7).</p>
<disp-quote content-type="editor-comment">
<p>1. The population activities of the hippocampal movie-tuned cells in Fig. 3a-b look like those of time cells, tiling the movie playback period. It needs to be clarified whether the hippocampal cells are actively coding the visual inputs or just filling the duration.</p>
</disp-quote>
<p>Tiling patterns would be observed when the maximal are sorted in any data, even for random numbers. This alone does not make them time cells. The following observations suggest that movie fields cannot be explained as being time cells.</p>
<list list-type="bullet">
<list-item><p>a. Time cells mostly cluster at the beginning of a running epoch (Pastalkova et al. Science 2008, MacDonald et al. Neuron 2011) and they taper off towards the end. Such large clustering is not visible in these tiling plots for movie tuned cells.</p>
</list-item>
<list-item><p>b. Time fields become wider as the temporal duration progresses (Pastalkova et al. Science 2008, MacDonald et al. Neuron 2011) as the encoded temporal duration increases. This is not evident in any movie fields.</p>
</list-item>
<list-item><p>c. Widths of movie fields in visual areas, and to a smaller extent in the hippocampal areas, were clearly modulated by the visual content, like the change from one frame to the next (F2F correlation, Extended Data Fig. 11).</p>
</list-item>
<list-item><p>d. Tiling pattern of movie fields was found in visual areas too, with qualitatively similar pattern as hippocampus. Clearly, visual area responses are not time cells, as shown by the scrambled stimulus experiment. Here, neural selectivity could be recovered by rearranging them based on the visual content of the continuous movie, and not the passage of time.</p>
</list-item>
</list>
<disp-quote content-type="editor-comment">
<p>The scrambled condition in which the sequence of the images was randomly permutated made the hippocampal neurons totally lose their selective responses, failing to reconstruct the neural responses to the original sequence by rearrangement of the scrambled sequence. This result indirectly addressed that the substantial portion of the hippocampal cells did not just fill the duration but represented the contents and temporal order of the images. However, it should be directly confirmed whether the tiling pattern disappeared with the population activities in the scrambled condition (as shown in Extended Data Fig. 11, but data were not shown for the hippocampus).</p>
</disp-quote>
<p>As stated above for the continuous movie, tiling pattern alone does not mean those are time cells. Further, tuning, and tiling pattern remained intact with scrambled movie in the visual cortices but not in hippocampus.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public Review):</bold></p>
<p>[…] The paper is conceptually novel since it specifically aims to remove any behavioral or task engagement whatsoever in the head-fixed mice, a setup typically used as an open-loop control condition in virtual reality-based navigational or decision making tasks (e.g. Harvey et al., 2012). Because the study specifically addresses this aspect of encoding (i.e. exploring effects of pure visual content rather than something task-related), and because of the widespread use of video-based virtual reality paradigms in different sub-fields, the paper should be of interest to those studying visual processing as well as those studying visual and spatial coding in the hippocampal system. However, the task-free approach of the experiments (including closely controlling for movement-related effects) presents a Catch-22, since there is no way that the animal subjects can report actually recognizing or remembering any of the visual content we are to believe they do.</p>
</disp-quote>
<p>Our claim is that these are movie scene evoked responses. We make no claims about the animal’s ability to recognize or remember the movie content. That would require entirely different set of experiments. Meanwhile, we have shown that these results are not an artifact of brain states such as sharp wave ripples, theta power or pupil diameter (Extended Data Fig. 6 and 7) or running behavior (Extended Data Fig. 4). Please see above for a detailed response.</p>
<disp-quote content-type="editor-comment">
<p>We must rely on above-chance-level decoding of movie segments, and the requirement that the movie is played in order rather than scrambled, to indicate that the hippocampal system encodes episodic content of the movie. So the study represents an interesting conceptual advance, and the analyses appear solid and support the conclusion, but there are methodological limitations.</p>
</disp-quote>
<p>It is important to emphasize that these responses could constitute episodic responses but does not prove episodic memory, just as place cell responses constitute spatial responses but that does not prove spatial memory. The link between place cells and place memory is not entirely clear. For example, mice lacking NMDA receptors have intact place cells, but are impaired in spatial memory task (McHugh et al. Cell 1996), whereas spatial tuning was virtually destroyed in mice lacking GluR1 receptors, but they could still do various spatial memory tasks (Resnik et al. J. Neuro 2012). The experiments about episodic memory would require an entirely different set of experiments that involve task demand and behavioral response, which in turn would modify hippocampal responses substantially, as shown by many studies. Our hypothesis here, is that just like place cells, these episodic responses without task demand would play a role, to be determined, in episodic memory. We will emphasize this point in the main text (Ln 432-436 in the revised manuscript).</p>
<disp-quote content-type="editor-comment">
<p>Major concerns:</p>
<p>1. A lot hinges on hinges on the cells having a z-scored sparsity &gt;2, the cutoff for a cell to be counted as significantly modulated by the movie. What is the justification of this criterion?</p>
</disp-quote>
<p>The z-scored sparsity (z&gt;2) corresponds to p&lt;0.03. This would mean that 3% of the results could appear by chance. Hence, z&gt;2 is a standard method used in many publications. Another advantage of z-scored sparsity is that it is relatively insensitive to the number of spikes generated by a neuron (i.e. the mean firing rate of the neuron and the duration of the experiment). In contrast, sparsity is strongly dependent on the number of spikes which makes it difficult to compare across neurons, brain regions and conditions (See Supplement S5 Acharya et al. Cell 2016). To further address this point, we compared our z-scored sparsity measure with 2 other commonly used metrics to quantify neural selectivity, depth of modulation and mutual information (Extended Data Fig. 3). Comparable movie tuning was obtained from all 3 metrics, upon z-scoring in an identical fashion.</p>
<disp-quote content-type="editor-comment">
<p>It should be stated in the Results. Relatedly, it appears the formula used for calculating sparseness in the present study is not the same as that used to calculate lifetime sparseness in de Vries et al. 2020 quoted in the results (see the formula in the Methods of the de Vries 2020 paper immediately under the sentence: &quot;Lifetime sparseness was computed using the definition in Vinje and Gallant&quot;).</p>
</disp-quote>
<p>The definition of sparsity we used is used commonly by most hippocampal scientists (Treves and Rolls 1991, Skaggs et al. 1996, Ravassard et al. 2013). Lifetime sparseness equation used by de Vries et al. 2020, differs from us by just one constant factor (1-1/N) where N=900 is the number of frames in the movie. This constant factor equals (1- 1/900)=0.999. Hence, there is no difference between the sparsity obtained by these two methods. Further, z-scored sparsity is entirely unaffected by such constant factors. We will clarify this in the methods of the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>To rule out systematic differences between studies beyond differences in neural sampling (single units vs. calcium imaging), it would be nice to see whether calculating lifetime sparseness per de Vries et al. changed the fraction &quot;movie&quot; cells in the visual and hippocampal systems.</p>
<p>As stated above, the two definitions of sparsity are virtually identical and we obtained similar results using two other commonly used metrics, which are detailed in Extended Data Fig. 3.</p>
<p>1. In Figures 1, 2 and the supplementary figures-the sparseness scores should be reported along with the raw data for each cell, so the readers can be apprised of what types of firing selectivity are associated with which sparseness scores-as would be shown for metrics like gridness or Raleigh vector lengths for head direction cells. It would be helpful to include this wherever there are plots showing spike rasters arranged by frame number &amp; the trial-averaged mean rate.</p>
</disp-quote>
<p>As shown in several papers (Aghajan et al Nature Neuroscience 2015, Acharya et al., Cell 2016) raw sparsity (or information content) are strongly dependent on the number of spikes of a neuron. This makes the raw values of these numbers impossible to compare across cells, brain regions and conditions. (Please see Supplement S5 from Acharya et al., Cell 2016 for details). Including the data of sparsity would thus cause undue confusion. Hence, we provide z-scored sparsity. This metric is comparable across cells and brain regions, and now provided above each example cell in Figure 1 and Extended Data Fig. 2.</p>
<disp-quote content-type="editor-comment">
<p>1. The examples shown on the right in Figures 1b and c are not especially compelling examples of movie-specific tuning; it would be helpful in making the case for &quot;movie&quot; cells if cleaner / more robust cells are shown (like the examples on the left in 1b and c).</p>
</disp-quote>
<p>We did not put the most strongly tuned hippocampal neurons in the main figures so that these cells are representative of the ensemble and not the best possible ones, so as to include examples with broad tuning responses. We have clarified in the legend that these cells are some of the best tuned cells. Although not the cleanest looking, the z-scored sparsity mentioned above the panels now indicates how strongly they are modulated compared to chance levels. Additional examples, including those with sharply tuned responses are shown in Extended Data Fig. 5 and 8.</p>
<disp-quote content-type="editor-comment">
<p>1. The scrambled movie condition is an essential control which, along with the stability checks in Supplementary Figure 7, provide the most persuasive evidence that the movie fields reflect more than a passive readout of visual images on a screen. However, in reference to Figure 4c, can the authors offer an explanation as to why V1 is substantially less affected by the movie scrambling than it's main input (LGN) and the cortical areas immediately downstream of it? This seems to defy the interpretation that &quot;movie coding&quot; follows the visual processing hierarchy.</p>
</disp-quote>
<p>This is an important point, one that we find very surprising as well. Perhaps this is related to other surprising observations in our manuscript, such as more neurons appeared to be tuned to the movie than the classic stimuli. A direct comparison between movie responses versus fixed images is not possible at this point due to several additional differences such as the duration of image presentations and their temporal history. The latency required to rearrange the scrambled responses (60ms for LGN, 74ms for V1, 91ms for AM/PM) supports the anatomical hierarchy. The pattern of movie tuning properties was also broadly consistent between V1 and AM/PM (Fig 2). However, all metrics of movie selectivity (Fig 2) to the continuous movie showed a consistent pattern that was the exact opposite pattern of the simple anatomical hierarchy: V1 had stronger movie tuning, higher number of movie fields per cell, narrower movie-field widths, larger mega-scale structure, and better decoding than LGN. V1 was also more robust to the scrambled sequence than LGN. One possible explanation is that there are other sources of inputs to V1, beyond LGN, that contribute significantly to movie tuning. This is an important insight and we will modify the discussion to highlight this.</p>
<disp-quote content-type="editor-comment">
<p>Relatedly, the hippocampal data do not quite fit with visual hierarchical ordering either, with CA3 being less sensitive to scrambling than DG. Since the data (especially in V1) seem to defy hierarchical visual processing, why not drop that interpretation? It is not particularly convincing as is.</p>
</disp-quote>
<p>The anatomical organization is well established and an important factor. Even when observations do not fit the anatomical hierarchy, it provides important insights about the mechanisms. All properties of movie tuning (Fig 2) –the strength of tuning, number of movie peaks, their width and decoding accuracy firmly put visual areas upstream of hippocampal regions. But, just like visual cortex there are consistent patterns that do not support a simple feed-forward anatomical hierarchy. We have pointed out these patterns so that future work can build upon it.</p>
<disp-quote content-type="editor-comment">
<p>1. In the Discussion, the authors argue that the mice encode episodic content from the movie clip as a human or monkey would. This is supported by the (crucial) data from the scrambled movie condition, but is nevertheless difficult to prove empirically since the animals cannot give a behavioral report of recognition and, without some kind of reinforcement, why should a segment from a movie mean anything to a head-fixed, passively viewing mouse?</p>
</disp-quote>
<p>We emphasize once again that our claim is about the nature of encoding of the movie across these neurons. We make no claims about whether this forms a memory or whether the mouse is able to recognize the content or remember it. Despite decades of research, similar claims are difficult to prove for place cells, with plenty of counter examples (See the points above). The important point here is that despite any cognitive component, we see remarkably tuned responses in these brain areas. Their role in cognition would take a lot more effort and is beyond the scope of the current work.</p>
<disp-quote content-type="editor-comment">
<p>Would the authors also argue that hippocampal cells would exhibit &quot;song&quot; fields if segments of a radio song-equally arbitrary for a mouse-were presented repeatedly? (reminiscent of the study by Aronov et al. 2017, but if sound were presented outside the context of a task). How can one distinguish between mere sequence coding vs. encoding of episodically meaningful content? One or a few sentences on this should be added in the Discussion.</p>
</disp-quote>
<p>Aronov et al 2017, found the encoding of an audio sweep in hippocampus when the animals were doing a task (release the lever at a specific frequency to obtain a reward). However, without a task demand they found that hippocampal neurons did not encode the audio sequence beyond chance levels. This is at odds with our findings with the movie where we see strong tuning despite any task demand or reward. These results are consistent with but go far beyond our recent findings that hippocampal (CA1) neurons can encode the position and direction of motion of a revolving bar of light (Purandare et al. Nature 2022). Please see Ln 414-420 for related discussion.</p>
<p>These responses are unlikely to be mere sequence responses since the scrambled sequence was also fixed sequence that was presented many times and it elicited reliable responses in visual areas, but not in hippocampus. Hence, we hypothesize that hippocampal areas encode temporally related information, i.e. episodic content. We will modify the discussion to address these points.</p>
</body>
</sub-article>
</article>