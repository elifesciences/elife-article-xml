<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">101511</article-id>
<article-id pub-id-type="doi">10.7554/eLife.101511</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.101511.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Non-feature-specific elevated responses and feature-specific backward replay in human brain induced by visual sequence exposure</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>He</surname>
<given-names>Tao</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gong</surname>
<given-names>Xizi</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wang</surname>
<given-names>Qian</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zhu</surname>
<given-names>Xinyi</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Liu</surname>
<given-names>Yunzhe</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Fang</surname>
<given-names>Fang</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="aff" rid="a7">7</xref>
<email>ffang@pku.edu.cn</email>
</contrib>
<aff id="a1"><label>1</label><institution>Center for the Cognitive Science of Language, Beijing Language and Culture University</institution>, <city>Beijing</city>, <country>China</country></aff>
<aff id="a2"><label>2</label><institution>Key Laboratory of Language Cognitive Science (Ministry of Education), Beijing Language and Culture University</institution>, <city>Beijing</city>, <country>China</country></aff>
<aff id="a3"><label>3</label><institution>School of Psychological and Cognitive Sciences and Beijing Key Laboratory of Behavior and Mental Health, Peking University</institution>, <city>Beijing</city>, <country>China</country></aff>
<aff id="a4"><label>4</label><institution>IDG/McGovern Institute for Brain Research, Peking University</institution>, <city>Beijing</city>, <country>China</country></aff>
<aff id="a5"><label>5</label><institution>Chinese Institute for Brain Research</institution>, <city>Beijing</city>, <country>China</country></aff>
<aff id="a6"><label>6</label><institution>Peking-Tsinghua Center for Life Sciences, Peking University</institution>, <city>Beijing</city>, <country>China</country></aff>
<aff id="a7"><label>7</label><institution>Key Laboratory of Machine Perception (Ministry of Education), Peking University</institution>, <city>Beijing</city>, <country>China</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Kok</surname>
<given-names>Peter</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-10-11">
<day>11</day>
<month>10</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP101511</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-07-26">
<day>26</day>
<month>07</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-08-08">
<day>08</day>
<month>08</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.09.07.556631"/>
</event>
</pub-history>
<permissions>
<copyright-statement>Â© 2024, He et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>He et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-101511-v1.pdf"/>
<abstract>
<title>Abstract</title><p>The ability of cortical circuits to adapt in response to experience is a fundamental property of the brain. After exposure to a moving dot sequence, flashing a dot as cue at the starting point of the sequence can induce successive elevated responses even in the absence of the sequence. This cue-triggered elevated responses have been demonstrated to play a crucial role in predicting future events in dynamic environments. However, temporal sequences we are exposed usually contain rich feature information. It remains unknown whether the elevated responses are feature specific and, more crucially, how the brain organizes this sequence information after exposure. To address these questions, participants were exposed to a predefined sequence of four motion directions for about 30 min and subsequently presented with the start or end motion direction of the sequence as a cue. Surprisingly, we found that the cue-triggered elevated responses were not specific to a particular motion direction. Interestingly, the motion direction information was spontaneously reactivated and the motion sequence was backward replayed in a time-compressed manner. These effects were marginally significant even with brief exposure. Notably, no replay events were observed when the second or third motion direction of the sequence served as a cue. Further analyses revealed that activity in the medial temporal lobe (MTL) preceded the ripple power increase in visual cortex at replay onset, implying a coordinated relationship between the activities in the MTL and visual cortex. Together, we demonstrate that visual sequence exposure could induce two-fold brain plasticity that may simultaneously serve for different functional purposes. The non-feature-specific elevated responses may facilitate general processing of upcoming stimuli, whereas the feature-specific backward replay may underpin passive learning of visual sequence.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The first author affiliations have been updated.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The capacity of cortical circuits to undergo plasticity in response to experience is a fundamental feature of the brain (<xref ref-type="bibr" rid="c5">Buonomano and Merzenich, 1998</xref>; <xref ref-type="bibr" rid="c13">Costandi, 2016</xref>; <xref ref-type="bibr" rid="c44">Li, 2016</xref>). This plasticity can be induced not only by active, task-dependent training, such as visual perceptual learning (<xref ref-type="bibr" rid="c72">Watanabe and Sasaki, 2015</xref>; <xref ref-type="bibr" rid="c11">Chen et al., 2016</xref>; <xref ref-type="bibr" rid="c50">Lu and Dosher, 2022</xref>), but also by passive, repetitive exposure (<xref ref-type="bibr" rid="c29">Gutnisky et al., 2009</xref>; <xref ref-type="bibr" rid="c65">Sasaki et al., 2010</xref>; <xref ref-type="bibr" rid="c19">Ekman et al., 2017</xref>). For instance, after repeated exposure to a moving dot sequence, flashing a dot (i.e., cue) at the starting point of the sequence elicits successive elevated neural responses along the motion path in visual cortex, akin to those induced by the actual moving dot sequence in both humans (Ekman et al., 2017, <xref ref-type="bibr" rid="c20">2023</xref>; <xref ref-type="bibr" rid="c49">Lu et al., 2020</xref>) and animals (<xref ref-type="bibr" rid="c17">Eagleman and Dragoi, 2012</xref>; <xref ref-type="bibr" rid="c76">Xu et al., 2012</xref>). This cue-triggered reactivation is thought to be driven by expectation and is prediction-related (Ekman et al., 2017, <xref ref-type="bibr" rid="c20">2023</xref>) since it has been shown to facilitate the prediction of upcoming stimuli and affect the perception of sensory information (<xref ref-type="bibr" rid="c29">Gutnisky et al., 2009</xref>; <xref ref-type="bibr" rid="c3">Baker et al., 2014</xref>; <xref ref-type="bibr" rid="c59">Pojoga et al., 2020</xref>).</p>
<p>Rather than simple white dot sequences used in previous studies (<xref ref-type="bibr" rid="c76">Xu et al., 2012</xref>; Ekman et al., 2017, <xref ref-type="bibr" rid="c20">2023</xref>; <xref ref-type="bibr" rid="c49">Lu et al., 2020</xref>), temporal sequences to which we are exposed in daily life usually contain rich feature information. However, it remains unknown whether the cue-triggered elevated responses are feature-specific. On the one hand, if they are not feature-specific, these elevated responses may simply reflect general cortical preparedness for any upcoming stimuli. On the other hand, if they are indeed specific to a particular feature in the sequence, the elevated responses could only facilitate the processing of specific future events, according to the view that expectation leads to sharper neural tuning and therefore facilitates the processing of expected stimuli (<xref ref-type="bibr" rid="c38">Kok et al., 2012</xref>). For instance, expectation increased the prestimulus baseline of sensory neurons tuned to the expected stimulus (<xref ref-type="bibr" rid="c75">Wyart et al., 2012</xref>; <xref ref-type="bibr" rid="c37">Kok et al., 2014</xref>) and elicited preactivation of the stimulus template in both visual (<xref ref-type="bibr" rid="c39">Kok et al., 2017</xref>) and auditory (<xref ref-type="bibr" rid="c14">Demarchi et al., 2019</xref>) cortices. It should be noted that all these prediction-related feature-specific activities arose from static contexts. Whether prediction-related responses in dynamic temporal contexts (e.g., visual sequence) are feature-specific remains unclear.</p>
<p>After exposure to a feature-contained temporal sequence, another important question is how the feature information in the sequence is encoded and organized in neural activity following the cue. Previous studies have demonstrated that, after training with a temporal sequence, memory consolidation (<xref ref-type="bibr" rid="c28">Gridchyn et al., 2020</xref>; <xref ref-type="bibr" rid="c26">Gillespie et al., 2021</xref>) or learning process (<xref ref-type="bibr" rid="c34">Igata et al., 2021</xref>) has been linked to a neural pattern known as replay. Replay refers to the sequential reactivation of neural activity patterns associated with the trained sequence in both sleep (<xref ref-type="bibr" rid="c43">Lee and Wilson, 2002</xref>) and awake (<xref ref-type="bibr" rid="c23">Foster and Wilson, 2006</xref>) states and is believed to be crucial for memory consolidation and learning (<xref ref-type="bibr" rid="c10">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="c47">Liu et al., 2021b</xref>, <xref ref-type="bibr" rid="c48">2022</xref>). During replay, the neural representation of the trained sequence was temporally compressed and displayed in either forward or backward direction (<xref ref-type="bibr" rid="c10">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="c36">Joo and Frank, 2018</xref>; <xref ref-type="bibr" rid="c54">Nour et al., 2021</xref>; <xref ref-type="bibr" rid="c48">Liu et al., 2022</xref>; <xref ref-type="bibr" rid="c52">McFadyen et al., 2023</xref>). These replay events frequently coincide with sharp-wave ripples (SWRs), which are high-frequency (150â220 Hz) oscillations (<xref ref-type="bibr" rid="c55">OâKeefe and Nadel, 1978</xref>; <xref ref-type="bibr" rid="c6">Bush et al., 2022</xref>) detected in the local field potentials of the hippocampus (<xref ref-type="bibr" rid="c7">BuzsÃ¡ki, 1986</xref>, <xref ref-type="bibr" rid="c9">2015</xref>). To date, replay was exclusively found when participants performed a task with sequences, e.g., nonlocal reinforcement learning (<xref ref-type="bibr" rid="c47">Liu et al., 2021b</xref>) and episodic memory retrieval (<xref ref-type="bibr" rid="c74">Wimmer et al., 2020</xref>). It remains unclear whether simple visual exposure to temporal sequences could also trigger replay events in humans.</p>
<p>In the current study, we used magnetoencephalography (MEG) to investigate whether the cue-triggered elevated brain responses following visual sequence exposure are feature-specific and, more importantly, to understand how the feature information in the exposed sequence is encoded and organized in the brain after exposure. To address these questions, participants were initially exposed to a predetermined motion sequence. We subsequently decoded the motion direction information during the blank period after presenting only the first or last motion direction in the sequence as a cue. Surprisingly, we found that the cue-triggered elevated responses were not specific to a particular motion direction. Interestingly, the motion direction information was spontaneously reactivated during the blank period and the motion sequence was backward replayed in a time-compressed manner. This backward replay was identified even with brief exposure. However, neither forward nor backward replay was detected when an intermediate motion direction in the sequence was presented as a cue. Lastly, through MEG source reconstruction analysis, we found that medial temporal lobe (MTL) activation preceded visual cortical activation, implying that the replay events observed in visual cortex may be triggered by activities in the MTL.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>The visual stimuli used in the study were four random-dot kinematograms (RDKs). All dots in an RDK moved in a direction (i.e., 0Â°, 90Â°, 180Â°, or 270Â°) with 100% coherence. In Experiment 1, we included three trial conditions: full sequence trial, start-only trial, and end-only trial (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). In a full sequence trial, participants were exposed to a predefined sequence of the four RDKs in either clockwise (i.e., 0Â° â 90Â°â 180Â° â 270Â°) or counterclockwise in the center of the screen, with a 300 ms of inter-stimulus interval (ISI) between every two RDKs. In a start-or end-only trial, the first or last RDK of the sequence was presented at the beginning of the trial, followed by a 2.4 s of blank period. Participants were instructed to complete three successive phases: functional localizer phase, exposure phase, and main phase (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). The functional localizer data were used to train models to decode each motion direction in the sequence. During this phase, one of the four RDKs was randomly presented for 1 s in each trial. During the exposure phase, the participants were exposed to only full sequence trials for about 30 min. In the main phase, 50%, 25%, and 25% trials were full sequence, start-and end-only trials, respectively. The full sequence trials served as topping-up exposure to maintain the exposure effect.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Stimuli, experimental procedure and evoked responses in Experiment 1</title>
<p><bold>(A)</bold> Participants were presented with RDKs in three conditions. In the full sequence trial condition, four successive RDKs were presented. In the start-or end-only condition, only the first or last RDK in the sequence was presented at the beginning of the trial. <bold>(B)</bold> During MEG scanning, the participants were presented with two functional localizer runs (i.e., functional localizer phase) before providing any sequence information. Next, they were exposed with four full sequence runs (i.e., exposure phase). Finally, in the main phase, full sequence, start-and end-only trials were presented in a pseudo-randomized order. <bold>(C)</bold> Evoked brain responses as a function of time relative to trial onset in the full sequence, start-and end-only trial conditions, respectively. Bold black lines at the bottom indicate temporal clusters in which they reached significance when compared to the pre-stimulus baseline. Inset figures at the top-right corner show the peak amplitudes during the four corresponding RDK intervals after baseline correction.</p></caption>
<graphic xlink:href="556631v3_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<sec id="s2a">
<title>Cue-triggered elevated responses are not feature-specific</title>
<p>We first measured the event-related field (ERF) activity evoked by RDKs in the three trial conditions using all occipital gradiometer sensors (see Methods). <xref rid="fig1" ref-type="fig">Figure 1C</xref> showed the evoked response by full sequence trials (left panel, cluster-based permutation test with cluster forming threshold t &gt; 3.1 and 5000 permutations). Remarkably, start-and end-only trials elicited similar wave-like responses as the full sequence trials, despite the absence of stimuli following the first RDK (<xref rid="fig1" ref-type="fig">Figure 1C</xref>, middle and right panels, cluster-based permutation test with cluster forming threshold t &gt; 3.1 and 5000 permutations). To further quantify the ERF peak amplitudes in the three conditions while mitigating baseline confounds, we calculated each peak amplitude by using the 300 ms blank period just preceding the onset of the corresponding RDK as baseline (see Methods). We found that the four successive RDKs in the full sequence trials evoked four comparable peaks after stimulus onset (<xref rid="fig1" ref-type="fig">Figure 1C</xref>, inset figure in the left panel; two-tailed t-test; all ts<sub>(17)</sub> &gt; 6.8072, all <italic>p</italic>s &lt; 10<sup>-5</sup>). Interestingly, in start-and end-only trials, we could still observe significant peaks during the periods corresponding to the intervals of the second and third RDKs in the full sequence trials (<xref rid="fig1" ref-type="fig">Figure 1C</xref>, inset figures in the middle and right panels; start-only condition, two-tailed t-test; all ts<sub>(17)</sub> &gt; 4.5790, all <italic>p</italic>s &lt; 10<sup>-3</sup>; end-only condition, two-tailed t-test; all ts<sub>(17)</sub> &gt; 6.0140, all <italic>p</italic>s &lt; 10<sup>-4</sup>), although there was no significant peak during the period corresponding to the interval of the last RDK (start-only condition, two-tailed t-test; t<sub>(17)</sub> = 1.3221, <italic>p</italic> = 0.2036; end-only condition, two-tailed t-test; t<sub>(17)</sub> = 0.2473, <italic>p</italic> = 0.8076). These results demonstrate cue-triggered elevated brain responses following visual exposure to the RDK sequences, resembling previous studies using simple white dot sequences (Ekman et al., 2017; <xref ref-type="bibr" rid="c49">Lu et al., 2020</xref>).</p>
<p>Given that we observed the elevated responses even in the absence of stimuli following the cue, next we examined whether these responses were specific to a particular feature (i.e., motion direction). Specifically, we asked if we could successfully decode motion directions in start-and end-only trials, particularly during the blank periods that corresponding to the intervals of the second and third RDKs in full sequence trials. To this end, we applied a time-resolved decoding analysis. For each participant, we trained a one-versus-rest Lasso logistic regression model using the functional localizer data to classify the neural activity pattern elicited by each motion direction in the main phase. MEG signals from 72 occipital sensors were selected as features in the training model. To validate the reliability of our data, we first used a leave-one-out cross-validation scheme on the localizer data to independently estimate the decoding accuracy at each time point. At the group level, decoding accuracies peaked at 411 ms, 464 ms, 444 ms, and 434 ms after stimulus onset for motion directions 0Â° (55.37% Â± 1.21), 90Â° (58.10% Â± 1.14), 180Â° (54.07% Â± 1.47), and 270Â° (53.64% Â± 1.34), respectively. There were no significant differences among the four motion directions in terms of either latency (F(3, 51) = 0.375, p = 0.7716, <italic>Î·<sub>p</sub></italic><sup>2</sup> = 0.0159) or decoding accuracy (F(3, 51) = 2.757, p = 0.0517, <italic>Î·<sub>p</sub></italic><sup>2</sup> = 0.091) at the peak time point. Thereafter, the trained classifier was applied to the MEG signals in the three types of trials in the main phase. Finally, decoding probability (<xref ref-type="bibr" rid="c70">Turner et al., 2023</xref>) for each motion direction was calculated at each time point at the group level (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Here, we used decoding probability because it provides a time-resolved decoding preference for each motion direction, rather than only a decoded label (e.g., 0Â°, 90Â°, 180Â°, or 270Â°).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Time-resolved decoding probability for each motion direction</title>
<p><bold>(A)</bold> Visualization of the time-resolved decoding probability in the three trial conditions. Each row shows the decoding probabilities for the four motion directions at that time point and each column indicates one of the four motion directions. <bold>(B)</bold> The line plots of the time-resolved decoding probability for the three conditions. Each colored line shows the time course of the decoding probability for each motion direction. For the start-and end-only conditions, we calculated the permutation threshold estimated by randomly shuffling of the labels and re-decoding, only the decoding probability of the cue surpassed the threshold.</p></caption>
<graphic xlink:href="556631v3_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In full sequence trials, the motion direction information could be successfully decoded, as evidenced by the highest decoding probability during the interval corresponding to the presentation of the respective RDK (<xref rid="fig2" ref-type="fig">Figure 2A</xref><bold> and </bold><xref rid="fig2" ref-type="fig">2B</xref>, left panels). In start-and end-only trials, we could also reliably decode the motion direction of the first RDK (i.e., the cue) after stimulus onset (<xref rid="fig2" ref-type="fig">Figure 2A</xref><bold> and </bold><xref rid="fig2" ref-type="fig">2B</xref>, middle and right panels, only the decoding probability of the first RDK surpass the peak-level significance threshold obtained from a nonparametric permutation test, FWE corrected across time). Surprisingly, however, subsequent motion direction information was absent at the group level during the post-cue blank period, where the cue-triggered elevated responses were previously observed. Together, these results demonstrate that the cue-triggered elevated response induced by visual sequence exposure was not consistently specific to a particular feature across participants and trials.</p>
</sec>
<sec id="s2b">
<title>Time-compressed backward replay of exposed motion sequence</title>
<p>How is the motion direction information encoded and organized in the brain during the post-cue blank period? Clearly, the motion direction representation is not time-locked to the onset of the cue in either start-or end-only trials. However, it is possible that individual motion directions are encoded in the MEG signals in a spontaneous way but are sequentially organized (<xref ref-type="bibr" rid="c46">Liu et al., 2019</xref>).</p>
<p>To test this possibility, we trained four decoding models using the functional localizer data to capture the neural features of the four motion directions. Here, we employed four decoding models because our aim was to obtain four feature-specific classifiers. Each classifier was designed to be sensitive to only one motion direction, thereby being useful for quantifying the evidence of feature-specific sequence in subsequent steps. The models used a one-versus-rest Lasso logistic regression algorithm, with MEG signals from 72 occipital sensors as features. We then selected the time point with the highest decoding accuracy, which was estimated during the validation of the functional localizer data mentioned above, as the optimal time point for each participant and motion direction, since these time points are believed to carry the richest feature information (<xref ref-type="bibr" rid="c53">Mo et al., 2019</xref>). For subsequent analyses, we used classifiers trained at their respective optimal time point. Finally, we obtained four classifiers, each yielding significant decoding probabilities only when the stimulus matched the motion direction that the classifier was trained to detect (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). We did not find any spatial correlation between any two trained classifiers (highest correlation <italic>r</italic> &lt; 0.12, <xref rid="figs1" ref-type="fig">Figure S1A</xref>). Since each participant and motion direction had an optimal time point at different latencies, for visualization at the group level, we circularly shifted the decoding probability over time and aligned their optimal time points to an arbitrary time point (here, 200 ms after stimulus onset) for each participant and motion direction, respectively (<xref rid="fig3" ref-type="fig">Figure 3A</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Illustration of replay analysis pipeline: Temporally delayed linear modeling (TDLM)</title>
<p><bold>(A)</bold> The decoding probabilities were aligned at 200 ms post-stimulus onset according to their corresponding optimal time point per participant and motion direction. Each colored line indicates the decoding results of a classifier applied to a motion direction dataset. The dashed horizontal line indicates the permutation threshold estimated by random shuffling of the labels and re-decoding. <bold>(B)</bold> Regression models were trained for each participant and motion direction using MEG signals from the functional localizer data. <bold>(C)</bold> Classifiers were next applied to MEG signals during the post-cue blank period to derive a decoded [time x state] reactivation matrix. An example of backward sequential reactivation of stimuli is shown on the left. <bold>(D)</bold> Using TDLM, we quantified the evidence for sequential replay of motion directions during the post-cue blank period in start-and end-only conditions. We initially performed a time-lagged regression to create a regression coefficient matrix [states x states] for each time lag by regressing each lagged predictor matrix X(Î¹1t) onto the state reactivation matrix, Y (i.e., 1<sup>st</sup> level GLM analysis). The degree to which the reactivations systematically follow a transition matrix of interest was measured by âsequencenessâ (i.e., 2<sup>nd</sup> level GLM analysis). We tested the magnitude of this effect at each time lag independently for all transition lags up to 600 ms. The dashed line represents the corrected nonparametric statistical significance threshold (see Methods for details). The green area indicates the lags when the evidence of sequenceness in the backward direction exceeded the permutation threshold.</p></caption>
<graphic xlink:href="556631v3_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Having established the classifiers for each participant and motion direction, we then applied the classifiers to the MEG signals during the post-cue blank period in start-and end-only conditions to estimate the reactivation probability (i.e., decoding probability) for each motion direction at each time point (<xref ref-type="bibr" rid="c46">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="c74">Wimmer et al., 2020</xref>; <xref ref-type="bibr" rid="c54">Nour et al., 2021</xref>). Example trials in the start-and end-only conditions are shown in <xref rid="figs2" ref-type="fig">Figure S2A</xref>. The results revealed that motion direction reactivations occurred sparsely during the post-cue blank period, rather than crowded within the intervals corresponding to the RDK presentations in the full sequence condition, suggesting that the motion direction information might be reactivated in a spontaneous way. Next, we applied temporally delayed linear modeling (TDLM) to quantify the evidence whether and how the spontaneous reactivations follow the order of the exposed sequence (<xref rid="fig3" ref-type="fig">Figure 3D</xref>). This algorithm includes two-level regression analyses; a first-level regression that quantifies the evidence for each pairwise state-to-state transition, and a second-level regression that evaluates the extent to which the reactivation patterns align with a particular order of interest. Finally, we defined âsequencenessâ as a metric of forward (i.e., 1 â 2 â 3 â 4) or backward (i.e., 4 â 3 â 2 â 1) replay (<xref ref-type="bibr" rid="c42">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="c46">Liu et al., 2019</xref>, <xref ref-type="bibr" rid="c45">2021a</xref>; <xref ref-type="bibr" rid="c54">Nour et al., 2021</xref>).</p>
<p>As shown in <xref rid="fig4" ref-type="fig">Figure 4A</xref> and <xref rid="fig4" ref-type="fig">4B</xref>, in the start-only condition, we found evidence of backward replay of the exposed motion sequence (i.e., the replay sequence was 270Â°â 180Â° â 90Â° â 0Â° when the exposed motion sequence was 0Â° â 90Â° â 180Â° â270Â°) during the post-cue blank period, with a peak transition lag at 28â40 ms (maximal effect at 32 ms-lag: Î² = â0.0202 Â± 0.002, p &lt; 1/24 â 0.042, peak-level significance threshold derived from a nonparametric permutation test, FWE corrected across lags, <xref rid="fig4" ref-type="fig">Figure 4B</xref>). For visualization, an example of backward replay of the motion sequence was illustrated in <xref rid="fig4" ref-type="fig">Figure 4A</xref>. This effect was observed in most participants (<xref rid="figs3" ref-type="fig">Figure S3A</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Backward replay in both start-and end-only conditions</title>
<p><bold>(A</bold> and <bold>D)</bold> Examples of backward sequential reactivation in start-(A) and end-(D) only conditions from a representative participant. Each row represents the reactivation probabilities for the four motion directions at that time point and each column indicates one of the four motion directions. <bold>(B and E)</bold> Backward replay of the exposed motion sequence with peak transition lags at 28â40 ms in the start-only condition (B) and at 28 â 36 ms in the end-only condition (E). Horizontal dashed lines represent corrected significance levels from a nonparametric permutation test at the 2<sup>nd</sup>-level GLM analysis of TDLM. <bold>(C and F)</bold> Backward replay of the exposed motion sequence predominantly appeared at 1.2 â 1.8 s in the start-only condition (C) and 0.6 â 1.8 s in the end-only condition (F) after the onset of the blank period.</p></caption>
<graphic xlink:href="556631v3_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In the end-only condition, we also found evidence of backward replay during the post-cue blank period, with a peak transition lag at 28â36 ms (maximal effect at 32 ms-lag: Î²= â0.0145 Â± 0.0016, p &lt; 1/24 â 0.042, peak-level significance threshold obtained from a nonparametric permutation test, FWE corrected across lags; <xref rid="fig4" ref-type="fig">Figure 4E</xref>). <xref rid="fig4" ref-type="fig">Figure 4D</xref> shows an example of backward replay of the motion sequence in this condition, found in most participants (<xref rid="figs3" ref-type="fig">Figure S3A</xref>). Note that the time lag in the horizontal axis in <xref rid="fig4" ref-type="fig">Figure 4B</xref> and <xref rid="fig4" ref-type="fig">4E</xref> indicates the interval between the onsets of every two items in the replayed motion sequence. We found that the replayed sequence was approximately 10 times faster than the evoked activity sequence in the full sequence condition.</p>
<p>To further examine the period during which the backward replay occurred most frequently, we divided the blank period (2.4 s) into 4 stages, each lasting 600 ms. In start-only trials, we found that the backward replay predominantly appeared within the third stage of the blank period (1.2 â 1.8 s after the onset of the blank period, Wilcoxon signed-rank test, p = 0.0108), but there was no significant sequenceness in the other three stages (first stage, p = 0.7112; second stage, p = 0.5566; fourth stage, p = 0.6791; <xref rid="fig4" ref-type="fig">Figure 4C</xref>). In end-only trials, the backward replay was more likely to occur during the second and third stages of the blank period, although the results approached, but did not reach, significance (Wilcoxon signed-rank test, second stage, p = 0.0936; third stage, p = 0.0642; <xref rid="fig4" ref-type="fig">Figure 4F</xref>), In contrast, the replay was not frequently observed during the first and last stages (Wilcoxon signed-rank test, first stage, p = 0.9479; fourth stage, p = 0.4997). Finally, in a control analysis, we conducted a comprehensive examination of all 24 potential sequences. Only the backward replay was detected in both start-and end-only conditions (<xref rid="figs4" ref-type="fig">Figure S4</xref>).</p>
</sec>
<sec id="s2c">
<title>Backward replay is cue-dependent and depends on the amount of exposure</title>
<p>So far, we have demonstrated that the cue-triggered elevated responses induced by the motion sequence exposure were not motion direction specific. However, the motion information was spontaneously reactivated and the motion sequence was backward replayed in a time-compressed manner. It remains unknown whether the observed backward replay of the motion sequence was cue-dependent or not. In other words, does the replay of the motion sequence occur irrespective of which item of the sequence is presented as a cue? To address this question, we conducted Experiment 2, mirroring the design of Experiment 1 but with a different cue. Instead of flashing the first or last RDK, we presented the second or third RDK as a cue (2<sup>nd</sup>-only or 3<sup>rd</sup>-only condition, see <xref rid="figs5" ref-type="fig">Figure S5A</xref> and Methods) to examine whether these two non-terminal cues could induce replay during the post-cue blank period. We found no evidence of either forward or backward replay in either condition (<xref rid="fig5" ref-type="fig">Figure 5A</xref>; maximal nonsignificant effect at 32 ms-lag: 2<sup>nd</sup>-only condition, Î² = â0.0024 Â± 0.0014; 3<sup>rd</sup>-only condition, Î² =â0.0018 Â± 0.0015).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Backward replay is cue-dependent and depends on the amount of exposure</title>
<p><bold>(A)</bold> No evidence for replay was found in either the 2<sup>nd</sup>-only (left) or 3<sup>rd</sup>-only (right) condition in Experiment 2. Horizontal dashed lines have the same meaning as those in <xref rid="fig4" ref-type="fig">Figure 4B</xref> and <xref rid="fig4" ref-type="fig">4E</xref>. <bold>(B)</bold> In Experiment 3, immediately after the functional localizer phase, participants entered the main phase without the exposure phase. In the end-only condition, backward replay was observed; however, in the start-only condition, no such replay was observed.</p></caption>
<graphic xlink:href="556631v3_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Another interesting question is how changing the amount of exposure would affect the replay events during the blank period. To explore this issue, we conducted Experiment 3, also similar to Experiment 1 except for the removal of the exposure phase. Accordingly, only full sequence trials (50% trials) in the main phase served for exposure (see <xref rid="figs5" ref-type="fig">Figure S5B</xref> and Methods). In the start-only condition, we found a numerical trend of backward replay at transition lags at 20â40 ms, although it did not reach statistical significance (<xref rid="fig5" ref-type="fig">Figure 5B</xref>, left panel; maximum effect at 28 ms-lag: Î² =â0.0139 Â± 0.0021). In the end-only condition, the evidence for backward replay just reached the significance level at transition lags at 20 â 40 ms (<xref rid="fig5" ref-type="fig">Figure 5B</xref>, right panel; maximal effect at 24 ms-lag: Î² = â0.0147 Â± 0.0019, p &lt; 1/24 â 0.042, using the peak-level significance threshold from a nonparametric permutation test, FWE-corrected across lags).</p>
</sec>
<sec id="s2d">
<title>Power increase in replay-associated sharp-wave ripple frequencies</title>
<p>Previous studies on rodents and humans showed that replay events were associated with increased high-frequency ripple power (<xref ref-type="bibr" rid="c9">BuzsÃ¡ki, 2015</xref>; <xref ref-type="bibr" rid="c46">Liu et al., 2019</xref>). To investigate whether such replay-associated power increase could be observed in our study, we performed a time-frequency analysis using combined data from start-and end-only conditions in Experiment 1. We first identified putative replay onsets during the post-cue blank period in each trial, using probabilities decoded from MEG signals in the occipital region. Replay onsets were determined by choosing time points with a high (&gt;95<sup>th</sup> percentile) probability for backward replay with a 32 ms-lag transition (maximal replay effect at the group level for both start-and end-only conditions, <xref rid="fig4" ref-type="fig">Figure 4B</xref> and <xref rid="fig4" ref-type="fig">4E</xref>; see Methods for details). Using the MEG signals recorded from whole brain sensors, we found a transient ripple power increase at 120â180 Hz at the onset of replay events, compared to the baseline period of 50â100 ms prior to replay onset (<xref rid="fig6" ref-type="fig">Figure 6A</xref>; cluster-based permutation test with cluster forming threshold t &gt; 3.1 and 5000 permutations).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Replay events align with ripple power, with source activation in the MTL preceding activation in visual cortex</title>
<p><bold>(A)</bold> Top: In Experiment 1, a time-frequency decomposition of sensor-level data revealing a brief increase in high-frequency oscillatory power at replay onset. Bottom: a cluster-based permutation test (cluster forming threshold, t &gt; 3.1; number of permutations = 5000) could identify a significant cluster around 140 Hz. <bold>(B)</bold> Source localization of ripple-band power 30 ms before replay onset showing significant activation in the MTL (peak Montreal Neurological Institute [MNI] coordinates: X = 21, Y = 21, Z = 13. Neurological orientation.) <bold>(C)</bold> Source localization of ripple-band power at replay onset showing significant activation in visual cortex (peak MNI coordinates: X = 20, Y = 8, Z = 17). <bold>(D)</bold> The activation time course of the MTL at its peak MNI coordinate is shown in red, whereas that of visual cortex at its peak MNI coordinate is displayed in green. The MTL reached its peak activation before visual cortex.</p></caption>
<graphic xlink:href="556631v3_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2e">
<title>Visual cortical activation lags MTL activation</title>
<p>Since replay events were obtained using decoding probabilities from occipital sensors only, we next examined whether the observed replay onsets were related to power increase within visual cortex. Using a linearly constrained minimum variance (LCMV) beamforming algorithm (<xref ref-type="bibr" rid="c71">Van Veen et al., 1997</xref>), we first epoched the data using replay onsets combined from both start-and end-only conditions and then beamformed the broadband power into the source space (see Methods for details). We found that the power increase at replay onset was localized to sources in bilateral visual cortex (<xref rid="fig6" ref-type="fig">Figure 6C</xref>). Moreover, the right MTL, including the hippocampus and amygdala, was associated with power increase prior to the onset of replay events (<xref rid="fig6" ref-type="fig">Figure 6B</xref>). Specifically, activation (i.e., power increase) in the MTL occurred 30 ms earlier than that in visual cortex (p &lt; 0.05, corrected, whole brain nonparametric permutation test). For display purposes, we extracted activations from the 10 most activated voxels within the MTL and visual cortex, respectively, and plotted the time courses of their broadband power. Peak activation in visual cortex at replay onset was preceded by peak activation in the MTL (<xref rid="fig6" ref-type="fig">Figure 6D</xref>), implying an information flow from the MTL to visual cortex.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We found the co-existence of time-locked, non-feature-specific elevated responses and non-time-locked, feature-specific backward replay after visual sequence exposure in human brain. The feature-specific backward replay occurred in a time-compressed manner and could be triggered only by the first or last stimulus of the sequence. Interestingly, even brief exposure to the sequence could still induce a trend for the backward replay. Finally, we observed that MTL activity preceded the ripple power increase in visual cortex at replay onset.</p>
<p>Our study provides two new findings in the fields of vision and learning. First, different from many previous studies showing that expectation-based responses in static contexts are feature-specific (<xref ref-type="bibr" rid="c75">Wyart et al., 2012</xref>; <xref ref-type="bibr" rid="c37">Kok et al., 2014</xref>, 2017), we show here that prediction-related elevated responses in the dynamic temporal context are not. This non-feature-specific elevated responses potentially facilitate the general processing of any upcoming stimuli, rather than stimuli with a specific feature. Second, contrary to the prevailing notion that replay in learning and memory requires lengthy training with a task, our study shows that even brief exposure to a visual sequence is sufficient to induce replay. The replay we unveiled here may play a critical role in memorizing the visual sequence.</p>
<p>Regarding the two-fold neural consequences following the visual sequence exposure, an interesting question is whether the elevated responses and the backward replay share the same neural origin, for instance, originating from the hippocampus or other brain areas. For the elevated responses, the cue serves to provide temporal information for upcoming stimuli but without detailed feature information, thereby priming the cortices for activation and facilitating the general processing of future events. Previous animal studies (<xref ref-type="bibr" rid="c76">Xu et al., 2012</xref>; <xref ref-type="bibr" rid="c25">Gavornik and Bear, 2014</xref>) showed that this process can be implemented through a simple local synaptic mechanism in visual cortex (<xref ref-type="bibr" rid="c76">Xu et al., 2012</xref>) without top-down guidance. Moreover, <xref ref-type="bibr" rid="c20">Ekman et al. (2023)</xref> recently found no functional relationship between activities in V1 and the hippocampus when exposing human participants with a white dot sequence, further suggesting that the elevated responses may indeed originate in visual cortex.</p>
<p>Different from the elevated responses, the replay events are likely initiated by the hippocampus. This speculation is supported by two key findings. First, the replay of the motion direction information manifested in a backward direction and a time-compressed manner. Second, the replay is observed regardless of whether the cue is the first or last RDK in the sequence. Both of these two properties cannot be explained by a simple local synaptic mechanism (<xref ref-type="bibr" rid="c76">Xu et al., 2012</xref>) or a pattern completion-like mechanism (<xref ref-type="bibr" rid="c32">Hindy et al., 2016</xref>; Ekman et al., 2017; <xref ref-type="bibr" rid="c40">Kok and Turk-Browne, 2018</xref>) within visual cortex alone. Instead, the replay entails reorganizing the motion direction sequence in the brain. Therefore, we propose the involvement of active communication between the hippocampus and visual cortex in the occurrence of replay events, consistent with the view that the hippocampus encodes relationships among stimuli whereas visual cortex primarily acts as a platform for the manifestation of replay events (<xref ref-type="bibr" rid="c73">Whittington et al., 2020</xref>). Previous studies on memory consolidation considered the exchange of information between these two regions critical for facilitating replay events through hippocampal-neocortical circuits (<xref ref-type="bibr" rid="c8">BuzsÃ¡ki, 1996</xref>; <xref ref-type="bibr" rid="c35">Ji and Wilson, 2007</xref>; <xref ref-type="bibr" rid="c10">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="c57">ÃlafsdÃ³ttir et al., 2016</xref>; <xref ref-type="bibr" rid="c4">Buch et al., 2021</xref>). Functionally, replay events offer a mechanism for transferring recent experience from the hippocampus to the cortex, enabling the encoding of stimulus relationships in the cortex (<xref ref-type="bibr" rid="c51">Marr and Brindley, 1971</xref>; <xref ref-type="bibr" rid="c1">Alvarez and Squire, 1994</xref>; <xref ref-type="bibr" rid="c61">Redish and Touretzky, 1998</xref>; <xref ref-type="bibr" rid="c16">Dimakopoulos et al., 2022</xref>).</p>
<p>A natural behavioral consequence of visual sequence exposure is visual sequence learning (<xref ref-type="bibr" rid="c3">Baker et al., 2014</xref>; <xref ref-type="bibr" rid="c22">Finnie et al., 2021</xref>; <xref ref-type="bibr" rid="c20">Ekman et al., 2023</xref>). How is the learning implemented through hippocampus-dependent replay in visual cortex? Three key processes are considered here. First, the hippocampus is involved in encoding relationships among stimuli (<xref ref-type="bibr" rid="c67">Staresina and Davachi, 2009</xref>; <xref ref-type="bibr" rid="c69">Turk-Browne et al., 2009</xref>; <xref ref-type="bibr" rid="c33">Hsieh et al., 2014</xref>; <xref ref-type="bibr" rid="c24">Garvert et al., 2017</xref>); in fact, the ability to encode such relationships drastically decreases when the hippocampus is damaged (<xref ref-type="bibr" rid="c12">Chun and Phelps, 1999</xref>; <xref ref-type="bibr" rid="c30">Hannula et al., 2006</xref>; <xref ref-type="bibr" rid="c41">Konkel et al., 2008</xref>; <xref ref-type="bibr" rid="c66">Schapiro et al., 2014</xref>; <xref ref-type="bibr" rid="c22">Finnie et al., 2021</xref>). Second, visual cortical areas act as a âcognitive blackboardâ where task-relevant features are highlighted through feedback connections (<xref ref-type="bibr" rid="c63">Roelfsema and de Lange, 2016</xref>). Such a blackboard can be flexibly written or edited. Third, there are strong bidirectional connections between the hippocampus and sensory cortices (<xref ref-type="bibr" rid="c18">Eichenbaum et al., 2007</xref>; <xref ref-type="bibr" rid="c31">Henke, 2010</xref>). As proposed by the hippocampal-cortical backward projection model (<xref ref-type="bibr" rid="c64">Rolls, 2000</xref>), sequential reactivations of feature information initially generated in the hippocampus can be quickly and accurately sent back to the sensory cortices, consistent with the findings of <xref ref-type="bibr" rid="c35">Ji and Wilson, (2007)</xref>. A recent study also provided direct evidence that visual sequence plasticity is impaired when the hippocampus is damaged (<xref ref-type="bibr" rid="c22">Finnie et al., 2021</xref>), supporting the hypothesis of functional feedback information flow.</p>
<p>Why does the replay manifest in a reverse order? To date, there is no consensus on this issue. In rodents, a seminal study of replay during the awake state showed that when animals stopped at the end of a rewarded pathway, place cells were reactivated in the reverse order of the previously experienced direction (<xref ref-type="bibr" rid="c23">Foster and Wilson, 2006</xref>). However, a later study revealed that awake replay could occur in either a forward or backward direction relative to behavioral experience (<xref ref-type="bibr" rid="c15">Diba and BuzsÃ¡ki, 2007</xref>). Similarly, in humans, both directions have been observed in different nonspatial cognitive tasks (<xref ref-type="bibr" rid="c46">Liu et al., 2019</xref>, <xref ref-type="bibr" rid="c47">2021b</xref>; <xref ref-type="bibr" rid="c74">Wimmer et al., 2020</xref>). Forward replay may be associated with planning (<xref ref-type="bibr" rid="c56">ÃlafsdÃ³ttir et al., 2015</xref>; <xref ref-type="bibr" rid="c26">Gillespie et al., 2021</xref>), providing information pertaining to the assessment of future pathways (<xref ref-type="bibr" rid="c15">Diba and BuzsÃ¡ki, 2007</xref>). Backward replay may be more related to experience, as often observed at the end of runs when animals consume a reward (<xref ref-type="bibr" rid="c23">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="c2">Ambrose et al., 2016</xref>). Nevertheless, the exact function of the replay direction remains mysterious, as both forward and backward replays are modulated by task demands (<xref ref-type="bibr" rid="c58">ÃlafsdÃ³ttir et al., 2017</xref>). Thus, the underlying neural mechanisms of backward replay in visual cortex remain to be investigated.</p>
<p>Finally, we also found that replay occurrence is modulated by the cue. This result highlights the importance of the start and end points of the sequence in the replay. One fascinating proposal is that the replay event is sensitive to sequence boundaries, as indicated by the role of the start or end point of the sequence as salient boundaries that anchor place cell firing (<xref ref-type="bibr" rid="c62">Rivard et al., 2004</xref>). Accordingly, previous studies have shown that when rats are trained to run along a linear track starting at different points, place fields tend to be anchored to either the start or end of the journey (<xref ref-type="bibr" rid="c27">Gothard et al., 1996</xref>; <xref ref-type="bibr" rid="c60">Redish et al., 2000</xref>), suggesting that a boundary is essential to sequence integrity and may play a pivotal role in triggering replay onset. An alternative explanation to these findings posits that the onset of the second or third stimulus in the sequence reinstate the neural representations of a partial visual sequence (<xref ref-type="bibr" rid="c20">Ekman et al., 2023</xref>). For example, for a given sequence, A â B â C â D, flashing the third stimulus (i.e., C) only trigger a backward reactivation of the sequence giving C â B â A during the blank period.</p>
<p>Taken together, we found that simple visual sequence exposure could concurrently induce two-fold brain plasticity, that is, non-feature-specific elevated responses and feature-specific backward replay in the human visual cortex. We speculate that the non-feature-specific elevated responses may enhance general processing of upcoming visual stimuli, whereas the feature-specific backward replay may subserve visual sequence learning and memory. These findings significantly advance our understanding of the task-independence and the multifaceted nature of brain plasticity in response to visual experience.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Participants</title>
<p>A total of 59 healthy participants (29 females) were involved in the three experiments (Experiment 1: n = 21, 11 females, 22.1 Â± 2.61 years; Experiment 2: n = 18, 10 females, 23.56 Â± 3.29 years; Experiment 3: n = 20, 10 females, 20.65 Â± 2.62 years). In Experiment 1, data from three participants were excluded before analyses, as two showed large head motion (&gt;20 mm) and the behavioral performance of one was at chance level. In Experiment 3, data from two participants were excluded before analyses because of large head motion (&gt;20 mm). All participants were recruited in exchange for monetary compensation (100 RMB/h). They reported normal or corrected-to-normal vision and had no history of neurological disorders. They were naive to the purposes of the study. The experiments reported here were carried out in accordance with the guidelines expressed in the Declaration of Helsinki. All participants provided written informed consent in accordance with the procedures and protocols approved by the Human Subject Review Committee of Peking University.</p>
</sec>
<sec id="s4b">
<title>Task</title>
<sec id="s4b1">
<title>Experiment 1</title>
<p>Visual stimuli were RDKs with 100% coherence. All dots in an RDK moved in the same direction (luminance: 2.86 cd/ m<sup>2</sup>; diameter: 0.1Â°; speed: 8Â°/s) and were presented against a gray background (luminance: 16.7 cd/m<sup>2</sup>). At any one moment, 400 dots were visible within a 9Â° circular aperture and moved in one of the four directions: 0Â° (right), 90Â° (up), 180Â° (left), and 270Â° (down). Each participant completed three phases successively in the MEG scanner, namely, the functional localizer phase, the exposure phase, and the main phase (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). In the functional localizer phase, each trial started with the presentation of an RDK for 1 s followed by a 1â1.5 s intertrial interval (ITI). Participants did not need to perform any task in this phase. The motion direction of the RDK was randomly chosen from the four directions. Each participant performed two functional localizer runs and, each run comprised 100 trials, resulting in a total of 50 trials per motion direction. The localizer data were used to train motion direction classification models. This phase took approximately 10 min.</p>
<p>In the exposure phase, we showed participants the four RDKs in either clockwise or counterclockwise order (e.g., 0Â° â 90Â° â 180Â° â 270Â°, <xref rid="fig1" ref-type="fig">Figure 1A</xref> and <xref rid="fig1" ref-type="fig">1C</xref>); each was displayed for 400 ms, followed by 300 ms of a blank screen with fixation only. Therefore, the total sequence lasted for 2.8 s. The order was counterbalanced among participants, but once decided, it was fixed for each participant. Participants were instructed to detect an oddball RDK by pressing a button, i.e., in 20% trials, dots in one of the four RDKs traveled at a faster speed (9Â°/s). Each participant completed four runs of 50 trials.</p>
<p>In the main phase, participants were presented with trials in three different conditions: full sequence condition (50% trials), start-only condition (25% trials), and end-only condition (25% trials). Trials in the full sequence condition were identical to those in the exposure phase which served as âtopping-upâ exposure to maintain the exposure effect, similar to âtopping-upâ adaptation in visual adaptation studies (<xref ref-type="bibr" rid="c21">Fang et al., 2005</xref>). In the start-and end-only conditions; however, we only presented the first RDK (start-only condition) or the last RDK (end-only condition) of the full sequence. For a given run, the order of the three conditions was pseudorandomized with the restriction that the start-and end-only trials were always preceded or followed by a full sequence trial. Participants performed an identical oddball detection task as during the exposure phase. The oddball occurred in 10% of full sequence trials. Finally, each participant completed four runs of 48 trials, yielding a total of 96 full sequence trials, 48 start-only trials and 48 end-only trials.</p>
</sec>
<sec id="s4b2">
<title>Experiments 2 and 3</title>
<p>In Experiment 2, we only presented the second or the third RDK as a cue at the start of the trial, referred to as the 2<sup>nd</sup>-only and 3<sup>rd</sup>-only conditions, respectively. The procedure of Experiment 2 was similar to that of Experiment 1 except that the start-and end-only conditions were replaced with the 2<sup>nd</sup>-only and 3<sup>rd</sup>-only conditions. Experiment 3 followed the same procedure as Experiment 1 except that the exposure phase was removed.</p>
</sec>
</sec>
<sec id="s5">
<title>Quantification and statistical analysis</title>
<sec id="s5a">
<title>MEG acquisition and preprocessing</title>
<p>Neuromagnetic signals were recorded continuously at 1000 Hz with a 306-channel (204 planar gradiometers; 102 magnetometers), whole-head MEG system (Elekta Neuromag TRIUX) in a magnetically shielded room. Before scanning, four-headed position indicator coils attached to the scalp determined the head position with respect to the sensor array. Coil location was digitized with respect to three anatomical landmarks (nasion and preauricular points) with a 3D digitizer (Polhemus Isotrak system). Participants sat upright inside the scanner, while the stimuli were projected onto a screen suspended in front of them. Participants responded using a MEG-compatible button box held in their right hand.</p>
<p>To reduce noise from external environment, the temporal extension of signal-space separation (tSSS) method was applied at the preprocessing stage using the Elekta Neuromag MaxFilter software (<xref ref-type="bibr" rid="c68">Taulu and Simola, 2006</xref>). MEG signals were high-pass filtered at 0.5 Hz using a first-order IIR filter to remove slow-drifts. Data were then downsampled from 1000 Hz to 250 Hz for sequenceness analysis or 500 Hz for time-frequency analysis. Excessively noisy segments and sensors were automatically removed before independent component analysis (FastICA, <ext-link ext-link-type="uri" xlink:href="http://research.ics.aalto.fi/ica/fastica">http://research.ics.aalto.fi/ica/fastica</ext-link>) and performed to remove artifacts including cardiac signals, eye movements and blinks, and environmental noise. Artifact components were removed by visual inspection of spatial topography, time course, kurtosis of the time course, and frequency spectrum of all components. Only 72 sensors (including both gradiometers and magnetometers) covering the occipital lobe, labeled as âOccipitalâ in the MEG data acquisition system were used for MEG data analyses, except for source localization. The sensor selection was primarily motivated by the main objective of the study, examining replay events in visual cortex.</p>
</sec>
<sec id="s5b">
<title>Event-related fields</title>
<p>To calculate the event-related fields (ERFs), MEG epochs around trial onset were segmented for each trial and baseline-corrected using the mean activity in the time window of [â0.3 s, 0] before trial onset. Only 48 planar gradiometers of âOccipitalâ sensors were used to calculate the ERFs. We then averaged the planar-combined ERF activity for each condition. To avoid any potential baseline influence due to the short interval between every two RDKs, we further calculated the ERF peak amplitude by using the mean activity in the time window of [â0.3 s, 0] before the onset of the corresponding RDK as baseline. Subsequently, peak amplitudes during the four corresponding RDK intervals were calculated as the difference between the peak and its corresponding baseline.</p>
</sec>
<sec id="s5c">
<title>Decoding analysis</title>
<p>Decoding analysis was performed to classify the neural activity patterns elicited by the motion directions of the four RDKs in the main phase. A one-versus-rest Lasso-regularized logistic regression model was trained using the MEG signals from the 72 occipital sensors in the functional localizer phase. Specifically, we trained a five-class classifier, including four classes from trials in which the four RDKs were presented, and an additional class comprising an equivalent amount of null data extracted from the 1â1.5 s ITI. Null data were included to reduce the spatial correlation among the classes, thereby concurrently lowering the decoding probabilities for all classes (<xref ref-type="bibr" rid="c45">Liu et al., 2021a</xref>; <xref ref-type="bibr" rid="c54">Nour et al., 2021</xref>). Class weights were balanced by adjusting inversely proportional to class frequencies (i.e., trial numbers) in the training procedure. Additionally, every 5 trials were averaged within the same class to reduce noises. We then applied the trained classifier to the MEG signals at each time point in the main phase. Finally, decoding probabilities were averaged across each condition and motion direction to yield a time course of decoding probability.</p>
</sec>
<sec id="s5d">
<title>Optimal time point of motion direction representation</title>
<p>The optimal time point of motion direction representation was considered as the time point with the highest decoding accuracy. To index the optimal time point of each motion direction for each participant, we conducted time-resolved motion direction decoding analysis on the functional localizer data using Lasso-regularized logistic regression models. A leave-one-trial-out cross-validation procedure was used to train the classifier to determine one of the four motion directions, yielding a decoding accuracy at each time point for each participant. Finally, the time point with the highest decoding accuracy was independently extracted for each participant and each motion direction. These time points are referred to as optimal time points and were used for sequenceness analysis.</p>
</sec>
<sec id="s5e">
<title>Sequenceness measure</title>
<p>To identify sequenceness during the post-cue blank period in each trial, we trained models to detect transient spontaneous neural reactivation of each motion direction representation. Therefore, one-versus-rest Lasso-regularized logistic regression models were trained separately for each motion direction using the functional localizer data. MEG signals from the 72 occipital sensors obtained throughout all scanning sessions were used to train the decoding models. For each motion direction, we trained a binomial classifier, using positive instances from trials in which that feature (i.e., one motion direction) was presented and negative instances from trials in which all other features (i.e., the other three motion directions) were presented, together with an equivalent amount of null data from the 1â1.5 s ISI. The sensor distributions of beta estimates and the spatial correlation among the classifiers are shown in <xref rid="figs1" ref-type="fig">Figure S1</xref>.</p>
<p>The sequenceness analysis pipeline is illustrated in <xref rid="fig3" ref-type="fig">Figure 3</xref>. We first applied the trained classifiers with the functional localizer data at the optimal time point to MEG signals at each time point during the blank period, to generate a [time x state] reactivation probability matrix for each trial. The TDLM framework was then used to quantify evidence for sequential reactivations consistent with the inferred task transition structure (<xref ref-type="bibr" rid="c47">Liu et al., 2021b</xref>, <xref ref-type="bibr" rid="c45">2021a</xref>; <xref ref-type="bibr" rid="c54">Nour et al., 2021</xref>).</p>
<p>TDLM is a multiple linear regression approach to quantify the extent to which a lagged reactivation time course of state i, (X(Ît)<sub>i</sub>, Ît indicates lag time) can predict the reactivation time course of state j, (X<sub>j</sub>). Two steps were included in this pipeline. First, we performed multiple separate regressions using each stateâs reactivation time course as a dependent variable (j â [1: 4]) and the historical (i.e., time-lagged) reactivation time courses of all states (i â [1: 4]) as predictor variables.
<disp-formula id="eqn1">
<graphic xlink:href="556631v3_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>The regression coefficients from <xref rid="eqn1" ref-type="disp-formula">Equation 1</xref> quantify the evidence for each empirical state â state reactivation pattern at a given time lag, Ît. For example, Î²(Ît)<sub>ij</sub> is the coefficient capturing the unique variance in X<sub>j</sub> explained by X(Ît)<sub>i</sub>. All such first-level coefficients were placed in a lag-specific [4 x 4] empirical transition matrix <bold><italic>Î</italic></bold>, representing evidence for all possible state-to-state transitions at a specific lag.</p>
<p>In the second step, we quantified evidence supporting that the empirical (lag-specific) transition matrix, <bold><italic>Î</italic></bold>, can be predicted by the sequences of interest, i.e., the exposed motion sequence. All transitions of interest were specified in a model transition matrix (1 for transitions of interest and 0 otherwise), separately for forward (as in the visual experience) (<italic>T<sub>F</sub></italic>), and backward (opposite to the visual experience) direction (<italic>T<sub>B</sub></italic>). Then, the strength of all sequences of interest was measured by:
<disp-formula id="eqn2">
<graphic xlink:href="556631v3_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <bold><italic>Î</italic></bold> is the [state x state] empirical transition matrix, T<sub>r</sub> is the [state x state] predictor transition matrix (for regressor r), predicting the empirical transitions <bold><italic>B</italic></bold>. We included four predictor matrices: (1) <italic>T<sub>F</sub></italic>: transitions as in the motion sequence in the forward direction (transitions corresponding to [A â B â C â D]), (2) <italic>T<sub>B</sub></italic>: transitions opposite to the experience in the backward direction ([D â C â B â A], <italic>T<sub>B</sub></italic> is the transpose of <italic>T<sub>F</sub></italic>), (3) <italic>T<sub>auto</sub></italic>: self-transitions to control for autocorrelation ([4 x 4] identity matrix), and (4) <italic>T<sub>const</sub></italic>: a constant matrix to model away the average of all transitions, ensuring that any weight on <italic>T<sub>F</sub></italic> and <italic>T<sub>B</sub></italic> was not due to general background neural dynamics.</p>
<p>Z<sub>r</sub> is the scalar regression coefficient quantifying evidence for the hypothesized sequences in the empirical transitions, i.e., sequence strength. Note, this estimate of sequence strength is a relative quantity. An estimate of zero for state i to state j, for example, does not mean lack of replay from i â j but no stronger replay of i â j than that of other transitions. Repeating the regression in <xref rid="eqn2" ref-type="disp-formula">Equation 2</xref> at each time lag (Ît = 4, 8, 12,â¦,600 ms) results in both forward and backward sequence strength as a function of time lag. Shorter lags indicate greater time compression, corresponding to faster speed.</p>
<p>In the current study, sequenceness was defined from the contrast between the evidence for sequential replay of task structure in the forward ([A â B â C â D]) versus backward ([D â C â B â A]) direction (i.e., Z<sub>1</sub>âZ<sub>2</sub>); thus, removing between-participant variance in the sequential replay per se (which may arise secondary to task engagement and measurement sensitivity (<xref ref-type="bibr" rid="c45">Liu et al., 2021a</xref>; <xref ref-type="bibr" rid="c54">Nour et al., 2021</xref>)). Positive sequenceness values indicate replay in a predominantly forward direction, whereas negative sequenceness values indicate replay in a predominantly backward direction.</p>
<p>For statistical inference, we used nonparametric permutation tests involving all possible permutations of the stimulus labels at the second-level regression, equivalent to permuting the rows and columns together of the transition matrices used to calculate sequenceness. For each permutation, we calculated the peak absolute mean sequence strength over participants and across lags (controlling for multiple comparisons across lags). Sequence strength in unpermuted data was considered significant if its absolute magnitude was &gt;95% of the within-permutation peak.</p>
</sec>
<sec id="s5f">
<title>Identifying replay onsets and analyzing time-frequency</title>
<p>Given that the maximal evidence for replay transitions at the group level was a 32 ms-lag, we next identified replay onsets. Replay onsets were defined as the times when a strong reactivation of one stimulus (e.g., A) was followed by a strong reactivation of the next stimulus (e.g., B) in the sequence, with a 32 ms-lag (<xref ref-type="bibr" rid="c46">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="c54">Nour et al., 2021</xref>). Specifically, we shifted the reactivation matrix X up to the time lag Ît for the first time with maximal evidence for replay (i.e., 32 ms), obtained X(Ît).
<disp-formula id="eqn3">
<graphic xlink:href="556631v3_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>We then multiplied X by the transition matrix P; corresponding to the unscrambled sequences: X x P. The transition matrix P defines the mapping between the task state corresponding to column i in X, and column i in Orig. Specifically, column i in Orig is the reactivation time course of the state preceding state i in T.
<disp-formula id="eqn4">
<graphic xlink:href="556631v3_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Next, we multiplied Proj and Orig element-wise, summing over the columns of the resulting matrix; therefore, creating a [time x 1] vector, R, in which each element (i.e., row) indicates the strength of replay with a 32 ms-lag at a given moment in time.
<disp-formula id="eqn5">
<graphic xlink:href="556631v3_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Finally, we identified putative replay event onsets by threshold R at its 95<sup>th</sup> percentile preceded by a 100 ms pre-onset baseline exhibiting a low probability of replay at each time point.</p>
<p>We then epoched MEG data in the blank period surrounding each onset and computed a frequency decomposition (wavelet transformation) in the time window of â100â150 ms using all sensors. We aimed to find an evidence for the power increase in the high-frequency (120â160 Hz) region of interest at replay onset, compared with a pre-onset baseline (â100ââ50 ms from onset), as mentioned in our previous study (<xref ref-type="bibr" rid="c46">Liu et al., 2019</xref>). Finally, we generated two separate [time x frequency] matrices (i.e., using forward and backward task transition matrices separately) by averaging estimates over sensors and events, capturing the typical spectrally-resolved power change at replay onset.</p>
</sec>
<sec id="s5g">
<title>MEG source reconstruction</title>
<p>We identified the neural sources associated with increased ripple power at putative replay onsets. Forward models were generated based on a single shell using the superposition of basic functions that approximately correspond to the plane tangential to the MEG sensor array. Linearly constrained minimum variance beamforming (<xref ref-type="bibr" rid="c71">Van Veen et al., 1997</xref>) was used to reconstruct the epoched MEG data to a grid in MNI space (grid step, 5 mm). The sensor covariance matrix for beamforming was estimated using broadband power data across all frequencies. The baseline activity was the mean activity averaged over â100 â â50 ms relative to replay onset. All nonartifactual replay epochs were baseline-corrected at source level. We obtained whole-brain results for voxels predicted by participant-specific ripple power at replay onset. Nonparametric permutation tests were performed on the volume of interest to compute the multiple comparison P values of clusters &gt;10 voxels (whole-brain corrected, cluster-defining threshold; t = 3.1, n = 5000 permutations).</p>
</sec>
</sec>
</sec>
</body>
<back>
<sec id="s6">
<title>Data and Code availability</title>
<p>Data used to generate the findings of this study will be available upon request (subject to participant consent) to the Lead Contact. TDLM MATLAB Code available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/YunzheLiu/TDLM">https://github.com/YunzheLiu/TDLM</ext-link>. Custom computer code will be made available upon request to the Lead Contact.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>This study was supported by National Science and Technology Innovation 2030 Major Program (2022ZD0204802), the National Natural Science Foundation of China (31930053), Beijing Natural Science Foundation (5244044), and the Young Scientists Fund of the Humanities and Social Science Foundation of Ministry of Education of China (23YJCZH071).</p>
</ack>
<sec id="s7">
<title>Additional information</title>
<sec id="s7a">
<title>Author contributions</title>
<p>Conceptualization, T.H., Y.L., and F.F.; Investigation, T.H., Q.W., X.G., and X.Z.; Writing â Original Draft, T.H.; Writing â Review &amp; Editing, T.H., Q.W., X.Z., Y.L., and F.F.</p>
</sec>
<sec id="s8">
<title>Declaration of interests</title>
<p>The authors declare no competing interests.</p>
</sec>
</sec>
<sec id="s9">
<title>Supplementary information</title>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Figure S1.</label>
<caption><title>Sensor maps and spatial correlation of trained Lasso logistic regression models (related to <xref rid="fig3" ref-type="fig">Figure 3</xref>)</title>
<p><bold>(A)</bold> Left: Sensor map for each state decoding model in Experiment 1; MEG signals from 72 occipital sensors were selected as features while training the classifier. Right: Correlation matrix among classifiers. No spatial correlation was found among trained classifiers (highest correlation; <italic>r</italic> &lt; 0.12). <bold>(B and C)</bold> Same as (A), except the sensor maps and correlation matrix correspond to Experiments 2 (Panel B, highest correlation; <italic>r</italic> &lt; 0.1) and 3 (Panel C, highest correlation; <italic>r</italic> &lt; 0.1), respectively.</p></caption>
<graphic xlink:href="556631v3_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Figure S2.</label>
<caption><title>Decoded feature representations in start-and end-only conditions (related to <xref rid="fig3" ref-type="fig">Figures 3</xref>)</title>
<p>Time series of reactivation probability output from the four regression models on an example trial. Time zero corresponds to trial onset. Both participants S08 and S12 were exposed with a fixed motion sequence of 0Â° â 90Â° â 180Â° â 270Â°.</p></caption>
<graphic xlink:href="556631v3_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Figure S3.</label>
<caption><title>Sequenceness distribution across participants (related to <xref rid="fig4" ref-type="fig">Figures 4</xref> and <xref rid="fig5" ref-type="fig">5</xref>)</title>
<p><bold>(A)</bold> In Experiment 1, of the 18 participants, 14 showed backward replay at 32 ms-lag for the start-only condition (left), and 13 showed backward replay at 32 ms-lag for the end-only condition (right). Each dot represents an individual participant. Backward and forward sequenceness is denoted by blue and yellow dots, respectively. The inset histogram shows the distribution of deviations from the unity line. <bold>(B)</bold> Same as described in (A), but for the results of Experiment 2 in the 2<sup>nd</sup>-only (left) and 3<sup>rd</sup>-only (right) conditions, respectively. <bold>(C)</bold> Same as described in (A) but for the results of Experiment 3 in the start-(left) and end-only (right) conditions, respectively.</p></caption>
<graphic xlink:href="556631v3_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Figure S4.</label>
<caption><title>Sequenceness for each of the 24 possible orders (related to <xref rid="fig4" ref-type="fig">Figure 4</xref>)</title>
<p><bold>(A)</bold> In the start-only condition of Experiment 1, only the backward sequence [4 â 3 â 2â 1] with lags at 28â40 ms was significantly different (gray panels). The horizontal dashed lines represent significance thresholds derived from state label permutation at the 2<sup>nd</sup>-level GLM matrix of temporally delayed linear modeling. <bold>(B)</bold> Same as described in (A) but for the end-only condition in Experiment 1.</p></caption>
<graphic xlink:href="556631v3_figs4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>Figure S5.</label>
<caption><title>Stimuli and experimental procedures in Experiments 2 and 3 (related to <xref rid="fig5" ref-type="fig">Figure 5</xref>)</title>
<p><bold>(A)</bold> We presented the second (2<sup>nd</sup>-only condition) or third RDK (3<sup>rd</sup>-only condition) as a cue in Experiment 2. <bold>(B)</bold> The procedure of Experiment 3 was identical to that of Experiment 1 except for removing the exposure phase.</p></caption>
<graphic xlink:href="556631v3_figs5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alvarez</surname> <given-names>P</given-names></string-name>, <string-name><surname>Squire</surname> <given-names>LR</given-names></string-name></person-group> (<year>1994</year>) <article-title>Memory consolidation and the medial temporal lobe: a simple network model</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>91</volume>:<fpage>7041</fpage>â<lpage>7045</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ambrose</surname> <given-names>RE</given-names></string-name>, <string-name><surname>Pfeiffer</surname> <given-names>BE</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>DJ</given-names></string-name></person-group> (<year>2016</year>) <article-title>Reverse Replay of Hippocampal Place Cells Is Uniquely Modulated by Changing Reward</article-title>. <source>Neuron</source> <volume>91</volume>:<fpage>1124</fpage>â<lpage>1136</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baker</surname> <given-names>R</given-names></string-name>, <string-name><surname>Dexter</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hardwicke</surname> <given-names>TE</given-names></string-name>, <string-name><surname>Goldstone</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kourtzi</surname> <given-names>Z</given-names></string-name></person-group> (<year>2014</year>) <article-title>Learning to predict: Exposure to temporal sequences facilitates prediction of future events</article-title>. <source>Vision Res</source> <volume>99</volume>:<fpage>124</fpage>â<lpage>133</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buch</surname> <given-names>ER</given-names></string-name>, <string-name><surname>Claudino</surname> <given-names>L</given-names></string-name>, <string-name><surname>Quentin</surname> <given-names>R</given-names></string-name>, <string-name><surname>BÃ¶nstrup</surname> <given-names>M</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>LG</given-names></string-name></person-group> (<year>2021</year>) <article-title>Consolidation of human skill linked to waking hippocampo-neocortical replay</article-title>. <source>Cell Rep</source> <volume>35</volume>:<fpage>109193</fpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buonomano</surname> <given-names>DV</given-names></string-name>, <string-name><surname>Merzenich</surname> <given-names>MM</given-names></string-name></person-group> (<year>1998</year>) <article-title>CORTICAL PLASTICITY: From Synapses to Maps</article-title>. <source>Annual Review of Neuroscience</source> <volume>21</volume>:<fpage>149</fpage>â<lpage>186</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bush</surname> <given-names>D</given-names></string-name>, <string-name><surname>ÃlafsdÃ³ttir</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name>, <string-name><surname>Burgess</surname> <given-names>N</given-names></string-name></person-group> (<year>2022</year>) <article-title>Ripple band phase precession of place cell firing during replay</article-title>. <source>Current Biology</source> <volume>32</volume>:<fpage>64</fpage>â<lpage>73.</lpage> </mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>BuzsÃ¡ki</surname> <given-names>G</given-names></string-name></person-group> (<year>1986</year>) <article-title>Hippocampal sharp waves: Their origin and significance</article-title>. <source>Brain Research</source> <volume>398</volume>:<fpage>242</fpage>â<lpage>252</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>BuzsÃ¡ki</surname> <given-names>G</given-names></string-name></person-group> (<year>1996</year>) <article-title>The hippocampo-neocortical dialogue</article-title>. <source>Cereb Cortex</source> <volume>6</volume>:<fpage>81</fpage>â<lpage>92</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>BuzsÃ¡ki</surname> <given-names>G</given-names></string-name></person-group> (<year>2015</year>) <article-title>Hippocampal sharp wave-ripple: A cognitive biomarker for episodic memory and planning</article-title>. <source>Hippocampus</source> <volume>25</volume>:<fpage>1073</fpage>â<lpage>1188</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carr</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Jadhav</surname> <given-names>SP</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>LM</given-names></string-name></person-group> (<year>2011</year>) <article-title>Hippocampal replay in the awake state: a potential substrate for memory consolidation and retrieval</article-title>. <source>Nat Neurosci</source> <volume>14</volume>:<fpage>147</fpage>â <lpage>153</lpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname> <given-names>N</given-names></string-name>, <string-name><surname>Cai</surname> <given-names>P</given-names></string-name>, <string-name><surname>Zhou</surname> <given-names>T</given-names></string-name>, <string-name><surname>Thompson</surname> <given-names>B</given-names></string-name>, <string-name><surname>Fang</surname> <given-names>F</given-names></string-name></person-group> (<year>2016</year>) <article-title>Perceptual learning modifies the functional specializations of visual cortical areas</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>113</volume>:<fpage>5724</fpage>â<lpage>5729</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chun</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Phelps</surname> <given-names>EA</given-names></string-name></person-group> (<year>1999</year>) <article-title>Memory deficits for implicit contextual information in amnesic subjects with hippocampal damage</article-title>. <source>Nat Neurosci</source> <volume>2</volume>:<fpage>844</fpage>â<lpage>847</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Costandi</surname> <given-names>M</given-names></string-name></person-group> (<year>2016</year>) <source>Neuroplasticity</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Demarchi</surname> <given-names>G</given-names></string-name>, <string-name><surname>Sanchez</surname> <given-names>G</given-names></string-name>, <string-name><surname>Weisz</surname> <given-names>N</given-names></string-name></person-group> (<year>2019</year>) <article-title>Automatic and feature-specific prediction-related neural activity in the human auditory system</article-title>. <source>Nat Commun</source> <volume>10</volume>:<fpage>3440</fpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diba</surname> <given-names>K</given-names></string-name>, <string-name><surname>BuzsÃ¡ki</surname> <given-names>G</given-names></string-name></person-group> (<year>2007</year>) <article-title>Forward and reverse hippocampal place-cell sequences during ripples</article-title>. <source>Nat Neurosci</source> <volume>10</volume>:<fpage>1241</fpage>â<lpage>1242</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dimakopoulos</surname> <given-names>V</given-names></string-name>, <string-name><surname>MÃ©gevand</surname> <given-names>P</given-names></string-name>, <string-name><surname>Stieglitz</surname> <given-names>LH</given-names></string-name>, <string-name><surname>Imbach</surname> <given-names>L</given-names></string-name>, <string-name><surname>Sarnthein</surname> <given-names>J</given-names></string-name></person-group> (<year>2022</year>) <article-title>Information flows from hippocampus to auditory cortex during replay of verbal working memory items</article-title> <source>eLife</source> <volume>11</volume>:<fpage>e78677</fpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eagleman</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Dragoi</surname> <given-names>V</given-names></string-name></person-group> (<year>2012</year>) <article-title>Image sequence reactivation in awake V4 networks</article-title>. <source>PNAS</source> <volume>109</volume>:<fpage>19450</fpage>â<lpage>19455</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eichenbaum</surname> <given-names>H</given-names></string-name>, <string-name><surname>Yonelinas</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Ranganath</surname> <given-names>C</given-names></string-name></person-group> (<year>2007</year>) <article-title>The Medial Temporal Lobe and Recognition Memory</article-title>. <source>Annu Rev Neurosci</source> <volume>30</volume>:<fpage>123</fpage>â<lpage>152</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ekman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kok</surname> <given-names>P</given-names></string-name>, <string-name><surname>Lange</surname> <given-names>FP de</given-names></string-name></person-group> (<year>2017</year>) <article-title>Time-compressed preplay of anticipated events in human primary visual cortex</article-title>. <source>Nat Commun</source> <volume>8</volume>:<fpage>15276</fpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ekman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kusch</surname> <given-names>S</given-names></string-name>, <string-name><surname>de Lange</surname> <given-names>FP</given-names></string-name></person-group> (<year>2023</year>) <article-title>Successor-like representation guides the prediction of future events in human visual cortex and hippocampus</article-title> <source>eLife</source> <volume>12</volume>:<fpage>e78904</fpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fang</surname> <given-names>F</given-names></string-name>, <string-name><surname>Murray</surname> <given-names>SO</given-names></string-name>, <string-name><surname>Kersten</surname> <given-names>D</given-names></string-name>, <string-name><surname>He</surname> <given-names>S</given-names></string-name></person-group> (<year>2005</year>) <article-title>Orientation-Tuned fMRI Adaptation in Human Visual Cortex</article-title>. <source>Journal of Neurophysiology</source> <volume>94</volume>:<fpage>4188</fpage>â<lpage>4195</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Finnie</surname> <given-names>PSB</given-names></string-name>, <string-name><surname>Komorowski</surname> <given-names>RW</given-names></string-name>, <string-name><surname>Bear</surname> <given-names>MF</given-names></string-name></person-group> (<year>2021</year>) <article-title>The spatiotemporal organization of experience dictates hippocampal involvement in primary visual cortical plasticity</article-title>. <source>Current Biology</source> <volume>31</volume>:<fpage>3996</fpage>â<lpage>4008.</lpage> </mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Foster</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name></person-group> (<year>2006</year>) <article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title>. <source>Nature</source> <volume>440</volume>:<fpage>680</fpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garvert</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TE</given-names></string-name></person-group> (<year>2017</year>) <article-title>A map of abstract relational knowledge in the human hippocampalâentorhinal cortex</article-title> <source>eLife</source> <volume>6</volume>:<fpage>e17086</fpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gavornik</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Bear</surname> <given-names>MF</given-names></string-name></person-group> (<year>2014</year>) <article-title>Learned spatiotemporal sequence recognition and prediction in primary visual cortex</article-title>. <source>Nat Neurosci</source> <volume>17</volume>:<fpage>732</fpage>â<lpage>737</lpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gillespie</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Maya</surname> <given-names>DAA</given-names></string-name>, <string-name><surname>Denovellis</surname> <given-names>EL</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>DF</given-names></string-name>, <string-name><surname>Kastner</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Coulter</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Roumis</surname> <given-names>DK</given-names></string-name>, <string-name><surname>Eden</surname> <given-names>UT</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>LM</given-names></string-name></person-group> (<year>2021</year>) <article-title>Hippocampal replay reflects specific past experiences rather than a plan for subsequent choice</article-title>. <source>Neuron</source> <volume>109</volume>:<fpage>3149</fpage>â<lpage>3163.</lpage> </mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gothard</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Skaggs</surname> <given-names>WE</given-names></string-name>, <string-name><surname>Moore</surname> <given-names>KM</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name></person-group> (<year>1996</year>) <article-title>Binding of hippocampal CA1 neural activity to multiple reference frames in a landmark-based navigation task</article-title>. <source>J Neurosci</source> <volume>16</volume>:<fpage>823</fpage>â<lpage>835</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gridchyn</surname> <given-names>I</given-names></string-name>, <string-name><surname>Schoenenberger</surname> <given-names>P</given-names></string-name>, <string-name><surname>OâNeill</surname> <given-names>J</given-names></string-name>, <string-name><surname>Csicsvari</surname> <given-names>J</given-names></string-name></person-group> (<year>2020</year>) <article-title>Assembly-Specific Disruption of Hippocampal Replay Leads to Selective Memory Deficit</article-title>. <source>Neuron</source> <volume>106</volume>:<fpage>291</fpage>â<lpage>300.</lpage> </mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gutnisky</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Hansen</surname> <given-names>BJ</given-names></string-name>, <string-name><surname>Iliescu</surname> <given-names>BF</given-names></string-name>, <string-name><surname>Dragoi</surname> <given-names>V</given-names></string-name></person-group> (<year>2009</year>) <article-title>Attention Alters Visual Plasticity during Exposure-Based Learning</article-title>. <source>Current Biology</source> <volume>19</volume>:<fpage>555</fpage>â<lpage>560</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hannula</surname> <given-names>DE</given-names></string-name>, <string-name><surname>Tranel</surname> <given-names>D</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>NJ</given-names></string-name></person-group> (<year>2006</year>) <article-title>The Long and the Short of It: Relational Memory Impairments in Amnesia, Even at Short Lags</article-title>. <source>J Neurosci</source> <volume>26</volume>:<fpage>8352</fpage>â<lpage>8359</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Henke</surname> <given-names>K</given-names></string-name></person-group> (<year>2010</year>) <article-title>A model for memory systems based on processing modes rather than consciousness</article-title>. <source>Nat Rev Neurosci</source> <volume>11</volume>:<fpage>523</fpage>â<lpage>532</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hindy</surname> <given-names>NC</given-names></string-name>, <string-name><surname>Ng</surname> <given-names>FY</given-names></string-name>, <string-name><surname>Turk-Browne</surname> <given-names>NB</given-names></string-name></person-group> (<year>2016</year>) <article-title>Linking pattern completion in the hippocampus to predictive coding in visual cortex</article-title>. <source>Nat Neurosci</source> <volume>19</volume>:<fpage>665</fpage>â<lpage>667</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hsieh</surname> <given-names>L-T</given-names></string-name>, <string-name><surname>Gruber</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Jenkins</surname> <given-names>LJ</given-names></string-name>, <string-name><surname>Ranganath</surname> <given-names>C</given-names></string-name></person-group> (<year>2014</year>) <article-title>Hippocampal Activity Patterns Carry Information about Objects in Temporal Context</article-title>. <source>Neuron</source> <volume>81</volume>:<fpage>1165</fpage>â<lpage>1178</lpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Igata</surname> <given-names>H</given-names></string-name>, <string-name><surname>Ikegaya</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Sasaki</surname> <given-names>T</given-names></string-name></person-group> (<year>2021</year>) <article-title>Prioritized experience replays on a hippocampal predictive map for learning</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>118</volume>:<fpage>e2011266118</fpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ji</surname> <given-names>D</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name></person-group> (<year>2007</year>) <article-title>Coordinated memory replay in the visual cortex and hippocampus during sleep</article-title>. <source>Nature Neuroscience</source> <volume>10</volume>:<fpage>100</fpage>â<lpage>107</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Joo</surname> <given-names>HR</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>LM</given-names></string-name></person-group> (<year>2018</year>) <article-title>The hippocampal sharp waveâripple in memory retrieval for immediate use and consolidation</article-title>. <source>Nat Rev Neurosci</source> <volume>19</volume>:<fpage>744</fpage>â<lpage>757</lpage>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kok</surname> <given-names>P</given-names></string-name>, <string-name><surname>Failing</surname> <given-names>M</given-names></string-name>, <string-name><surname>de Lange</surname> <given-names>F</given-names></string-name></person-group> (<year>2014</year>) <article-title>Prior Expectations Evoke Stimulus Templates in the Primary Visual Cortex</article-title>. <source>Journal of cognitive neuroscience</source> <volume>26</volume>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kok</surname> <given-names>P</given-names></string-name>, <string-name><surname>Jehee</surname> <given-names>JFM</given-names></string-name>, <string-name><surname>de Lange</surname> <given-names>FP</given-names></string-name></person-group> (<year>2012</year>) <article-title>Less Is More: Expectation Sharpens Representations in the Primary Visual Cortex</article-title>. <source>Neuron</source> <volume>75</volume>:<fpage>265</fpage>â<lpage>270</lpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kok</surname> <given-names>P</given-names></string-name>, <string-name><surname>Mostert</surname> <given-names>P</given-names></string-name>, <string-name><surname>Lange</surname> <given-names>FP de</given-names></string-name></person-group> (<year>2017</year>) <article-title>Prior expectations induce prestimulus sensory templates</article-title>. <source>PNAS</source> <volume>114</volume>:<fpage>10473</fpage>â<lpage>10478</lpage>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kok</surname> <given-names>P</given-names></string-name>, <string-name><surname>Turk-Browne</surname> <given-names>NB</given-names></string-name></person-group> (<year>2018</year>) <article-title>Associative Prediction of Visual Shape in the Hippocampus</article-title>. <source>J Neurosci</source> <volume>38</volume>:<fpage>6888</fpage>â<lpage>6899</lpage>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Konkel</surname> <given-names>A</given-names></string-name>, <string-name><surname>Warren</surname> <given-names>D</given-names></string-name>, <string-name><surname>Duff</surname> <given-names>M</given-names></string-name>, <string-name><surname>Tranel</surname> <given-names>D</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>N</given-names></string-name></person-group> (<year>2008</year>) <article-title>Hippocampal amnesia impairs all manner of relational memory</article-title>. <source>Frontiers in Human Neuroscience</source> <volume>2</volume> Available at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/article/10.3389/neuro.09.015.2008">https://www.frontiersin.org/article/10.3389/neuro.09.015.2008</ext-link> [Accessed May 26, 2022].</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kurth-Nelson</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Economides</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P</given-names></string-name></person-group> (<year>2016</year>) <article-title>Fast Sequences of Non-spatial State Representations in Humans</article-title>. <source>Neuron</source> <volume>91</volume>:<fpage>194</fpage>â<lpage>204</lpage>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name></person-group> (<year>2002</year>) <article-title>Memory of Sequential Experience in the Hippocampus during Slow Wave Sleep</article-title>. <source>Neuron</source> <volume>36</volume>:<fpage>1183</fpage>â<lpage>1194</lpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname> <given-names>W</given-names></string-name></person-group> (<year>2016</year>) <article-title>Perceptual Learning: Use-Dependent Cortical Plasticity</article-title>. <source>Annual Review of Vision Science</source> <volume>2</volume>:<fpage>109</fpage>â<lpage>130</lpage>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Higgins</surname> <given-names>C</given-names></string-name>, <string-name><surname>Penagos</surname> <given-names>H</given-names></string-name>, <string-name><surname>Woolrich</surname> <given-names>MW</given-names></string-name>, <string-name><surname>ÃlafsdÃ³ttir</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TE</given-names></string-name></person-group> (<year>2021a</year>) <article-title>Temporally delayed linear modelling (TDLM) measures replay in both animals and humans</article-title> <source>eLife</source> <volume>10</volume>:<fpage>e66917</fpage>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name></person-group> (<year>2019</year>) <article-title>Human Replay Spontaneously Reorganizes Experience</article-title>. <source>Cell</source> <volume>178</volume>:<fpage>640</fpage>â<lpage>652.</lpage> </mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Liu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Mattar</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>, <string-name><surname>Daw</surname> <given-names>ND</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group> (<year>2021b</year>) <article-title>Experience replay is associated with efficient nonlocal learning</article-title>. <source>Science</source> <volume>372</volume> Available at: <ext-link ext-link-type="uri" xlink:href="https://science.sciencemag.org/content/372/6544/eabf1357">https://science.sciencemag.org/content/372/6544/eabf1357</ext-link> [Accessed May 21, 2021].</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Nour</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Schuck</surname> <given-names>NW</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group> (<year>2022</year>) <article-title>Decoding cognition from spontaneous neural activity</article-title>. <source>Nat Rev Neurosci</source>:<fpage>1</fpage>â<lpage>11</lpage>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname> <given-names>J</given-names></string-name>, <string-name><surname>Luo</surname> <given-names>L</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Q</given-names></string-name>, <string-name><surname>Fang</surname> <given-names>F</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>N</given-names></string-name></person-group> (<year>2020</year>) <article-title>Cue-triggered activity replay in human early visual cortex</article-title>. <source>Sci China Life Sci</source> <pub-id pub-id-type="doi">10.1007/s11427-020-1726-5</pub-id>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname> <given-names>Z-L</given-names></string-name>, <string-name><surname>Dosher</surname> <given-names>BA</given-names></string-name></person-group> (<year>2022</year>) <article-title>Current directions in visual perceptual learning</article-title>. <source>Nat Rev Psychol</source> <volume>1</volume>:<fpage>654</fpage>â<lpage>668</lpage>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marr</surname> <given-names>D</given-names></string-name>, <string-name><surname>Brindley</surname> <given-names>GS</given-names></string-name></person-group> (<year>1971</year>) <article-title>Simple memory: a theory for archicortex. Philosophical Transactions of the Royal Society of London B</article-title>, <source>Biological Sciences</source> <volume>262</volume>:<fpage>23</fpage>â<lpage>81</lpage>.</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McFadyen</surname> <given-names>J</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group> (<year>2023</year>) <article-title>Differential replay of reward and punishment paths predicts approach and avoidance</article-title>. <source>Nat Neurosci</source> <volume>26</volume>:<fpage>627</fpage>â<lpage>637</lpage>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mo</surname> <given-names>C</given-names></string-name>, <string-name><surname>Lu</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>B</given-names></string-name>, <string-name><surname>Jia</surname> <given-names>J</given-names></string-name>, <string-name><surname>Luo</surname> <given-names>H</given-names></string-name>, <string-name><surname>Fang</surname> <given-names>F</given-names></string-name></person-group> (<year>2019</year>) <article-title>Competing rhythmic neural representations of orientations during concurrent attention to multiple orientation features</article-title>. <source>Nat Commun</source> <volume>10</volume>:<fpage>1</fpage>â<lpage>10</lpage>.</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nour</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Arumuham</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group> (<year>2021</year>) <article-title>Impaired neural replay of inferred relationships in schizophrenia</article-title>. <source>Cell</source> <volume>184</volume>:<fpage>4315</fpage>â<lpage>4328.</lpage> </mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>OâKeefe</surname> <given-names>J</given-names></string-name>, <string-name><surname>Nadel</surname> <given-names>L</given-names></string-name></person-group> (<year>1978</year>) <source>The hippocampus as a cognitive map</source>. <publisher-loc>Oxford:New York</publisher-loc>: <publisher-name>Clarendon Press;Oxford University Press</publisher-name>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>ÃlafsdÃ³ttir</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name>, <string-name><surname>Saleem</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Hassabis</surname> <given-names>D</given-names></string-name>, <string-name><surname>Spiers</surname> <given-names>HJ</given-names></string-name></person-group> (<year>2015</year>) <article-title>Hippocampal place cells construct reward related sequences through unexplored space</article-title> <source>eLife</source> <volume>4</volume>:<fpage>e06063</fpage>.</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>ÃlafsdÃ³ttir</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Carpenter</surname> <given-names>F</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name></person-group> (<year>2016</year>) <article-title>Coordinated grid and place cell replay during rest</article-title>. <source>Nat Neurosci</source> <volume>19</volume>:<fpage>792</fpage>â<lpage>794</lpage>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>ÃlafsdÃ³ttir</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Carpenter</surname> <given-names>F</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name></person-group> (<year>2017</year>) <article-title>Task Demands Predict a Dynamic Switch in the Content of Awake Hippocampal Replay</article-title>. <source>Neuron</source> <volume>96</volume>:<fpage>925</fpage>â<lpage>935.</lpage> </mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pojoga</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Kharas</surname> <given-names>N</given-names></string-name>, <string-name><surname>Dragoi</surname> <given-names>V</given-names></string-name></person-group> (<year>2020</year>) <article-title>Perceptually unidentifiable stimuli influence cortical processing and behavioral performance</article-title>. <source>Nat Commun</source> <volume>11</volume>:<fpage>6109</fpage>.</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Redish</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Rosenzweig</surname> <given-names>ES</given-names></string-name>, <string-name><surname>Bohanick</surname> <given-names>JD</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Barnes</surname> <given-names>CA</given-names></string-name></person-group> (<year>2000</year>) <article-title>Dynamics of Hippocampal Ensemble Activity Realignment: Time versus Space</article-title>. <source>J Neurosci</source> <volume>20</volume>:<fpage>9298</fpage>â<lpage>9309</lpage>.</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Redish</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Touretzky</surname> <given-names>DS</given-names></string-name></person-group> (<year>1998</year>) <article-title>The role of the hippocampus in solving the Morris water maze</article-title>. <source>Neural Comput</source> <volume>10</volume>:<fpage>73</fpage>â<lpage>111</lpage>.</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rivard</surname> <given-names>B</given-names></string-name>, <string-name><surname>Li</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Lenck-Santini</surname> <given-names>P-P</given-names></string-name>, <string-name><surname>Poucet</surname> <given-names>B</given-names></string-name>, <string-name><surname>Muller</surname> <given-names>RU</given-names></string-name></person-group> (<year>2004</year>) <article-title>Representation of objects in space by two classes of hippocampal pyramidal cells</article-title>. <source>J Gen Physiol</source> <volume>124</volume>:<fpage>9</fpage>â<lpage>25</lpage>.</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roelfsema</surname> <given-names>PR</given-names></string-name>, <string-name><surname>de Lange</surname> <given-names>FP</given-names></string-name></person-group> (<year>2016</year>) <article-title>Early Visual Cortex as a Multiscale Cognitive Blackboard</article-title>. <source>Annual Review of Vision Science</source> <volume>2</volume>:<fpage>131</fpage>â<lpage>151</lpage>.</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rolls</surname> <given-names>ET</given-names></string-name></person-group> (<year>2000</year>) <article-title>Hippocampo-cortical and cortico-cortical backprojections</article-title>. <source>Hippocampus</source> <volume>10</volume>:<fpage>380</fpage>â<lpage>388</lpage>.</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sasaki</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Nanez</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Watanabe</surname> <given-names>T</given-names></string-name></person-group> (<year>2010</year>) <article-title>Advances in visual perceptual learning and plasticity</article-title>. <source>Nat Rev Neurosci</source> <volume>11</volume>:<fpage>53</fpage>â<lpage>60</lpage>.</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schapiro</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Gregory</surname> <given-names>E</given-names></string-name>, <string-name><surname>Landau</surname> <given-names>B</given-names></string-name>, <string-name><surname>McCloskey</surname> <given-names>M</given-names></string-name>, <string-name><surname>Turk-Browne</surname> <given-names>NB</given-names></string-name></person-group> (<year>2014</year>) <article-title>The necessity of the medial temporal lobe for statistical learning</article-title>. <source>J Cogn Neurosci</source> <volume>26</volume>:<fpage>1736</fpage>â<lpage>1747</lpage>.</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Staresina</surname> <given-names>BP</given-names></string-name>, <string-name><surname>Davachi</surname> <given-names>L</given-names></string-name></person-group> (<year>2009</year>) <article-title>Mind the Gap: Binding Experiences across Space and Time in the Human Hippocampus</article-title>. <source>Neuron</source> <volume>63</volume>:<fpage>267</fpage>â<lpage>276</lpage>.</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Taulu</surname> <given-names>S</given-names></string-name>, <string-name><surname>Simola</surname> <given-names>J</given-names></string-name></person-group> (<year>2006</year>) <article-title>Spatiotemporal signal space separation method for rejecting nearby interference in MEG measurements</article-title>. <source>Phys Med Biol</source> <volume>51</volume>:<fpage>1759</fpage>â<lpage>1768</lpage>.</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Turk-Browne</surname> <given-names>NB</given-names></string-name>, <string-name><surname>Scholl</surname> <given-names>BJ</given-names></string-name>, <string-name><surname>Chun</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>MK</given-names></string-name></person-group> (<year>2009</year>) <article-title>Neural evidence of statistical learning: efficient detection of visual regularities without awareness</article-title>. <source>J Cogn Neurosci</source> <volume>21</volume>:<fpage>1934</fpage>â<lpage>1945</lpage>.</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Turner</surname> <given-names>W</given-names></string-name>, <string-name><surname>Blom</surname> <given-names>T</given-names></string-name>, <string-name><surname>Hogendoorn</surname> <given-names>H</given-names></string-name></person-group> (<year>2023</year>) <article-title>Visual Information Is Predictively Encoded in Occipital Alpha/Low-Beta Oscillations</article-title>. <source>J Neurosci</source> <volume>43</volume>:<fpage>5537</fpage>â<lpage>5545</lpage>.</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van Veen</surname> <given-names>BD</given-names></string-name>, <string-name><surname>van Drongelen</surname> <given-names>W</given-names></string-name>, <string-name><surname>Yuchtman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Suzuki</surname> <given-names>A</given-names></string-name></person-group> (<year>1997</year>) <article-title>Localization of brain electrical activity via linearly constrained minimum variance spatial filtering</article-title>. <source>IEEE Trans Biomed Eng</source> <volume>44</volume>:<fpage>867</fpage>â<lpage>880</lpage>.</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Watanabe</surname> <given-names>T</given-names></string-name>, <string-name><surname>Sasaki</surname> <given-names>Y</given-names></string-name></person-group> (<year>2015</year>) <article-title>Perceptual learning: Toward a comprehensive theory</article-title>. <source>Annu Rev Psychol</source> <volume>66</volume>:<fpage>197</fpage>â<lpage>221</lpage>.</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Whittington</surname> <given-names>JCR</given-names></string-name>, <string-name><surname>Muller</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Mark</surname> <given-names>S</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>G</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name>, <string-name><surname>Burgess</surname> <given-names>N</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name></person-group> (<year>2020</year>) <article-title>The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation</article-title>. <source>Cell</source> <volume>183</volume>:<fpage>1249</fpage>â<lpage>1263.</lpage> </mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wimmer</surname> <given-names>GE</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Vehar</surname> <given-names>N</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group> (<year>2020</year>) <article-title>Episodic memory retrieval success is associated with rapid replay of episode content</article-title>. <source>Nature Neuroscience</source> <volume>23</volume>:<fpage>1025</fpage>â<lpage>1033</lpage>.</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wyart</surname> <given-names>V</given-names></string-name>, <string-name><surname>Nobre</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Summerfield</surname> <given-names>C</given-names></string-name></person-group> (<year>2012</year>) <article-title>Dissociable prior influences of signal probability and relevance on visual contrast sensitivity</article-title>. <source>PNAS</source> <volume>109</volume>:<fpage>3593</fpage>â<lpage>3598</lpage>.</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname> <given-names>S</given-names></string-name>, <string-name><surname>Jiang</surname> <given-names>W</given-names></string-name>, <string-name><surname>Poo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dan</surname> <given-names>Y</given-names></string-name></person-group> (<year>2012</year>) <article-title>Activity recall in a visual cortical ensemble</article-title>. <source>Nature Neuroscience</source> <volume>15</volume>:<fpage>449</fpage>â<lpage>455</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101511.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Kok</surname>
<given-names>Peter</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study investigates both online responses to, and offline replay of, visual motion sequences. Sophisticated EEG analyses provide <bold>solid</bold> evidence for both feature-specific and non-specific sequence representations, though the explanation of the statistical methods used is currently <bold>incomplete</bold>.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101511.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The study identifies two types of activation: one that is cue-triggered and non-specific to motion directions, and another that is specific to the exposed motion directions but occurs in a reversed manner. The finding that activity in the medial temporal lobe (MTL) preceded that in the visual cortex suggests that the visual cortex may serve as a platform for the manifestation of replay events, which potentially enhance visual sequence learning.</p>
<p>Strengths:</p>
<p>Identifying the two types of activation after exposure to a sequence of motion directions is very interesting. The experimental design, procedures, and analyses are solid. The findings are interesting and novel.</p>
<p>Weaknesses:</p>
<p>It was not immediately clear to me why the second type of activation was suggested to occur spontaneously. The procedural differences in the analyses that distinguished between the two types of activation need to be a little better clarified.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101511.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This paper shows and analyzes an interesting phenomenon. It shows that when people are exposed to sequences of moving dots (that is moving dots in one direction, followed by another direction, etc.), showing either the starting movement direction or ending movement direction causes a coarse-grained brain response that is similar to that elicited by the complete sequence of 4 directions. However, they show by decoding the sensor responses that this brain activity actually does not carry information about the actual sequence and the motion directions, at least not on the time scale of the initial sequence. They also show a reverse reply on a highly compressed time scale, which is elicited during the period of elevated activity, and activated by the first and last elements of the sequence, but not others. Additionally, these replays seem to occur during periods of cortical ripples, similar to what is found in animal studies.</p>
<p>These results are intriguing. They are based on MEG recordings in humans, and finding such replays in humans is novel. Also, this is based on what seems to be sophisticated statistical analysis. However, this is the main problem with this paper. The statistical analysis is not explained well at all, and therefore its validity is hard to evaluate. I am not at all saying it is incorrect; what I am saying is that given how it is explained, it cannot be evaluated.</p>
</body>
</sub-article>
</article>