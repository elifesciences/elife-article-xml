<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">94835</article-id>
<article-id pub-id-type="doi">10.7554/eLife.94835</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.94835.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Neural encoding of multiple motion speeds in visual cortical area MT</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Huang</surname>
<given-names>Xin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ghimire</surname>
<given-names>Bikalpa</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chakrala</surname>
<given-names>Anjani Sreeprada</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wiesner</surname>
<given-names>Steven</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Neuroscience, University of Wisconsin-Madison</institution>, Wisconsin 53705, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Groh</surname>
<given-names>Jennifer M</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Duke University</institution>
</institution-wrap>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence should be addressed to: Xin Huang, Department of Neuroscience, University of Wisconsin, Madison, WI 53705, USA, Email: <email>Xin.Huang@wisc.edu</email></corresp>
<fn fn-type="supported-by"><p><bold>Grant support</bold> This research was supported by National Eye Institute Grant R01 EY022443.</p></fn>
<fn fn-type="conflict"><p><bold>Conflict of Interest</bold> None.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-03-28">
<day>28</day>
<month>03</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP94835</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-01-03">
<day>03</day>
<month>01</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-11-22">
<day>22</day>
<month>11</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.04.08.532456"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Huang et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Huang et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-94835-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Segmenting objects from each other and their background is critical for vision. The speed at which objects move provides a salient cue for segmentation. However, how the visual system represents and differentiates multiple speeds is largely unknown. Here we investigated the neural encoding of multiple speeds of overlapping stimuli in the primate visual cortex. We first characterized the perceptual capacity of human and monkey subjects to segment spatially overlapping stimuli moving at different speeds. We then determined how neurons in the motion-sensitive, middle-temporal (MT) cortex of macaque monkeys encode multiple speeds. We made a novel finding that the responses of MT neurons to two speeds of overlapping stimuli showed a robust bias toward the faster speed component when both speeds were slow (≤ 20°/s). The faster-speed bias occurred even when a neuron had a slow preferred speed and responded more strongly to the slower component than the faster component when presented alone. The faster-speed bias emerged very early in neuronal response and was robust over time and to manipulations of motion direction and attention. As the stimulus speed increased, the faster-speed bias changed to response averaging. Our finding can be explained by a modified divisive normalization model, in which the weights for the speed components are proportional to the responses of a population of neurons elicited by the individual speeds. Our results suggest that the neuron population, referred to as the weighting pool, includes neurons that have a broad range of speed preferences. As a result, the response weights for the speed components are determined by the stimulus speeds and invariant to the speed preferences of individual neurons. Our findings help to define the neural encoding rule of multiple stimuli and provide new insight into the underlying neural mechanisms. The faster-speed bias would benefit behavioral tasks such as figure-ground segregation if figural objects tend to move faster than the background in the natural environment.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>neural encoding</kwd>
<kwd>segmentation</kwd>
<kwd>discrimination</kwd>
<kwd>speed tuning</kwd>
<kwd>velocity</kwd>
<kwd>transparent motion</kwd>
<kwd>divisive normalization</kwd>
<kwd>figure-ground segregation</kwd>
<kwd>natural scenes</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Changed the title from &quot;Neural coding of multiple motion speeds in visual cortical area MT&quot; to &quot;Neural encoding of multiple motion speeds in visual cortical area MT&quot;.
The new version (V2) is focused on neural encoding of multiple motion speeds and does not include the extensive decoding analyses of extracting motion speeds from population neural responses in the previous version (V1).
Revised Abstract, Introduction, Results, Discussion, and Methods accordingly. Separated human psychophysics and animal psychophysics figure (previous Figure 1) into two figures (current Figures 1 and 2) and some minor edits of the figure formats and figure legends throughout.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Neuroscientists have been investigating how neurons in the brain represent sensory information for decades. Previous studies were often concerned with the neural coding of a single visual stimulus. However, natural environments are abundant with multiple entities that often co-occupy visual neurons’ receptive fields (RFs). Segmenting visual objects from each other and their background is a fundamental function of vision (<xref ref-type="bibr" rid="c9">Braddick, 1993</xref>). However, how the visual system represents multiple visual stimuli to achieve segmentation is not well understood. As the field progresses to unravel visual processing in natural vision, it becomes increasingly important to understand the principles of neural coding of multiple visual stimuli.</p>
<p>Visual motion provides a salient cue for scene segmentation. Common motion helps to group elements into the same object, whereas entities moving at different velocities can often be segregated from each other. An object moving at a speed different from its background, for example, is easier to segment. Here we investigated how the primate visual system represents multiple motion speeds. The extrastriate middle-temporal cortex (area MT) is important for motion processing and motion-based segmentation (<xref ref-type="bibr" rid="c1">Allman et al., 1985</xref>; <xref ref-type="bibr" rid="c13">Britten 2003</xref>; <xref ref-type="bibr" rid="c7">Born and Bradley 2005</xref>; <xref ref-type="bibr" rid="c39">Pasternak et al., 2020</xref>; <xref ref-type="bibr" rid="c8">Born et al., 2000</xref>; <xref ref-type="bibr" rid="c18">Huang et al., 2007</xref>, <xref ref-type="bibr" rid="c19">2008</xref>). To investigate the neural representation of multiple moving stimuli, it is advantageous to start with overlapping stimuli so the effects of motion cues can be isolated from spatial cues. Segmentation of overlapping stimuli moving at different directions and speeds gives rise to the perception of transparent motion (<xref ref-type="bibr" rid="c10">Braddick, 1997</xref>; <xref ref-type="bibr" rid="c11">Braddick et al, 2002</xref>; <xref ref-type="bibr" rid="c31">Mestre et al., 2001</xref>; <xref ref-type="bibr" rid="c28">Masson et al., 1999</xref>). Previous studies have investigated how neurons in area MT represent two motion directions of transparently moving stimuli (<xref ref-type="bibr" rid="c50">Snowden et al., 1991</xref>; <xref ref-type="bibr" rid="c43">Qian and Andersen, 1994</xref>; <xref ref-type="bibr" rid="c30">McDonald et al., 2014</xref>; <xref ref-type="bibr" rid="c57">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="c56">Xiao and Huang, 2015</xref>; <xref ref-type="bibr" rid="c55">Wiesner et al., 2020</xref>; <xref ref-type="bibr" rid="c52">Stoner and Albright, 1992</xref>; <xref ref-type="bibr" rid="c23">Krekelberg and van Wezel, 2013</xref>). Although how cortical neurons represent the speed of a single stimulus has been well-studied (<xref ref-type="bibr" rid="c29">Maunsell and van Essen, 1983</xref>; <xref ref-type="bibr" rid="c25">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="c35">Nover et al., 2005</xref>; <xref ref-type="bibr" rid="c38">Pack et al., 2005</xref>; <xref ref-type="bibr" rid="c24">Krekelberg et al., 2006a</xref>; <xref ref-type="bibr" rid="c40">Perrone and Thiele, 2001</xref>; <xref ref-type="bibr" rid="c41">Priebe et al., 2003</xref>, <xref ref-type="bibr" rid="c42">2006</xref>; <xref ref-type="bibr" rid="c26">Liu and Newsome 2003</xref>), how neurons represent multiple speeds is largely unknown.</p>
<p>In characterizing how MT neurons represent multiple directions of transparently moving stimuli, we have previously shown that many neurons do not pool two directions equally, but weigh one direction more than the other (<xref ref-type="bibr" rid="c56">Xiao and Huang, 2015</xref>). We have also found that some MT neurons show response nonlinearity in pooling two motion directions in a way that better represents the individual direction components. The heterogeneous response weights and response nonlinearity in representing multiple directions can benefit the neural coding of multiple stimuli (<xref ref-type="bibr" rid="c37">Orhan and Ma, 2015</xref>; <xref ref-type="bibr" rid="c56">Xiao and Huang, 2015</xref>), and may constitute an optimal population representation of visual motion with multiple directions (<xref ref-type="bibr" rid="c21">Huang et al., 2017</xref>). Unlike two motion directions for which the individual component directions appear to be balanced and symmetrical in perceptual quality and salience, visual stimuli moving at two speeds appear to be asymmetrical – one slower and one faster. The goal of this study is to determine the neural coding principle for multiple speeds of overlapping stimuli. It is conceivable that the responses of MT neurons elicited by two motion speeds may follow one of the following rules: 1) averaging the responses elicited by the individual speed components; 2) bias toward the speed component that elicits a stronger response, i.e. “soft-max operation” (<underline>Riesenhuber</underline> and <underline>Poggio</underline>, 1999); 3) bias toward the slower speed component, which may better represent the more probable slower speeds in nature scenes (<xref ref-type="bibr" rid="c54">Weiss et al., 2002</xref>); 4) bias toward the faster speed component, which may benefit the segmentation of a faster-moving stimulus from a slower background. We also asked whether the encoding rule was dependent on the stimulus speeds and the speed preference of the individual neurons.</p>
<p>We first characterized the perception of overlapping stimuli that moved simultaneously at two speeds. Our results showed that human and monkey subjects can segment overlapping stimuli based only on speed cues. The performance was better when the separation between two stimulus speeds was larger and the ability of speed segmentation was reduced when stimulus speeds were fast. We next recorded neuronal responses from area MT of male macaque monkeys. We made a novel finding that MT neurons showed a strong faster-speed bias when stimulus speeds were slow and as stimulus speeds increased, the faster-speed bias gradually shifted to response averaging. We also showed that a classifier could differentiate a two-speed stimulus from a single-speed stimulus based on MT responses, in a way generally consistent with perception. We proposed a model in which each speed component was weighted by the responses of a population of neurons with a broad range of speed preferences elicited by that speed component. The model extends the standard divisive normalization and can well explain our results. This study helps to fill a gap in understanding the neural coding principle of multiple visual stimuli and provides new insight into the mechanism underlying the neural representation of multiple stimuli and scene segmentation.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Perception of overlapping stimuli moving at different speeds</title>
<sec id="s2a1">
<title>Human psychophysics</title>
<p>To establish the perceptual basis for our study, we first characterized how human subjects perceived overlapping stimuli moving at different speeds. We used similar visual stimuli in our psychophysics experiments as in our neurophysiology experiments. We asked how perceptual segmentation was impacted by the separation between two stimulus speeds, and as the mean stimulus speed changed from slow to fast.</p>
<p>The visual stimuli were two overlapping random-dot patches presented within a stationary square aperture 10° wide and centered at 11° eccentricity. The random dots translated within the aperture in the same direction at two different speeds. It has been suggested that the neural representation of speed in the visual cortex is encoded on a logarithmic scale (<xref ref-type="bibr" rid="c29">Maunsell and van Essen, 1983</xref>; <xref ref-type="bibr" rid="c25">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="c35">Nover et al., 2005</xref>), so we used a fixed ratio between two speeds, which gave rise to a fixed speed difference in the logarithmic scale. One set of stimuli had a “large speed separation”, and the speed of the faster component was four times (x4) that of the slower component. The five speed pairs used were 1.25 and 5°/s, 2.5 and 10°/s, 5 and 20°/s, 10 and 40°/s, and 20 and 80°/s (<xref rid="fig1" ref-type="fig">Fig. 1B1</xref>). Another set of stimuli had a “small speed separation”, and the speed ratio was two (x2). The five speed pairs were 1.25 and 2.5°/s, 2.5 and 5°/s, 5 and 10°/s, 10 and 20°/s, and 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1B2</xref>). Experimental trials of bi-speed stimuli that had large and small speed separations were randomly interleaved.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Psychophysical tasks and performance of human subjects.</title>
<p><bold>A</bold>. Illustration of the 2AFC and 3AFC tasks. <bold>B</bold>. Motion speeds of visual stimuli. The speeds of two stimulus components were plotted versus the log mean speed of each bi-speed stimulus. <bold>C</bold>. Discriminability of four human subjects performing a standard 2AFC task. <bold>D</bold>. In the 3AFC task, the percentage of trials that human subjects reported “no two-speeds”. <bold>E</bold>. Discriminability of the same subjects performing the 3AFC task. <bold>B1-E1</bold>. X4 speed separation. <bold>B2-E2</bold>. X2 speed separation. Each color represents data from one subject. The solid line shows the subject-averaged result. Error bars and error bands represent ±STE.</p></caption>
<graphic xlink:href="532456v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Human subjects first performed a standard two-alternative-forced-choice (2AFC) task to discriminate a bi-speed stimulus from the corresponding single-speed stimulus that moved at the log mean speed of the two component speeds. In each trial, the bi-speed and single-speed stimuli were presented in two consecutive time intervals in a random and balanced order (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). At large (x4) speed separation, all four subjects could perform the task well when the component speeds were less than 20 and 80°/s (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). At 20 and 80°/s, the discrimination performance was poor (mean <italic>d’</italic> = 0.74, standard error STE = 0.5), indicating that subjects could not segment the speed components. At the small (x2) speed separation, the discriminability was worse than at the x4 separation. When the component speeds were less than 20 and 40°/s, subjects on average could differentiate the bi-speed stimulus from the single-speed stimulus (<italic>d’</italic> &gt; 1.5), but not when speeds were at 20 and 40°/s (mean <italic>d’</italic> = 0.17, STE = 0.1) (<xref rid="fig1" ref-type="fig">Fig. 1C2</xref>).</p>
<p>In the standard 2AFC task, it is possible that subjects could not segment the bi-speed stimulus into two separate speeds, but were still able to differentiate the bi-speed from single-speed stimuli based on their appearances (e.g., the distribution of the random dots of the bi-speed stimulus may appear less uniform). Because our goal was to measure discriminability based on perceptual segmentation, we designed a novel 3AFC task to address this concern. In the modified task, subjects still discriminated the bi-speed stimulus from the corresponding single-speed stimulus but had the option to make a third choice on trials when they thought neither stimulus interval appeared to contain two speeds (“no two-speeds” choice) (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Panels D1 and D2 of <xref rid="fig1" ref-type="fig">Figure 1</xref> show the percentage of trials in which subjects made the no two-speeds choice (NTC). At x4 speed separation, the percentage of NTC was low at most of the speed pairs, except at the highest speeds of 20 and 80°/s, subjects reported they could not see two speeds in most of the trials (<xref rid="fig1" ref-type="fig">Fig. 1D1</xref>). At x2 speed separation, the percentage of NTC showed a U-shape as a function of the stimulus speed, and was near 100% at 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1D2</xref>). These results confirmed that human subjects had difficulty segmenting two speeds when stimulus speeds were high. In addition, at low stimulus speeds with a small (x2) speed separation, subjects tended to perceive only one speed (<xref rid="fig1" ref-type="fig">Fig. 1D2</xref>). We incorporated the NTC into the <italic>d’</italic> calculation by evenly splitting the NTC trials into “hit” trials and “false alarm” trials (see Methods). In this way, the NTC trials were accounted for by <italic>d’</italic>, in the sense that they did not contribute to successful discrimination.</p>
<p>The <italic>d’</italic> from the 3AFC task were similar to those of the 2AFC task, with a slight reduction of <italic>d’</italic> across conditions as the NTC trials reduced discrimination performance (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref> vs. 1C1, 1E2 vs. 1C2). The small performance difference between the 2AFC and 3AFC tasks suggests that human subjects generally relied on speed segmentation to perform the 2AFC task. Based on the results from the 3AFC task, we performed a two-way ANOVA, in which the two factors were the mean speed of the stimulus components and the speed separation (x4 or x2). We found that both factors had significant effects. <italic>d’</italic> changed significantly with the mean stimulus speed (F(4,30) = 26.8, p = 1.60x10<sup>-9</sup>) and the <italic>d’</italic> at x4 separation differed significantly from that at x2 separation (F(1,30) = 84.1, p = 3.29x10<sup>-10</sup>). <italic>d’</italic> was higher at x4 (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref>) than at x2 speed separation except at the fastest speeds of 20 and 80°/s vs. 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1E2</xref>). Our results also showed that segmentation was significantly worse at fast speeds – <italic>d’</italic> dropped significantly as the stimulus speeds increased from 10 and 40°/s to 20 and 80°/s for x4 separation (one-way ANOVA, F(1,6) = 38.6, p = 8.1x10<sup>-4</sup>) (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref>), and from 10 and 20°/s to 20 and 40°/s for x2 separation (one-way ANOVA, F(1,6) = 32.7, p = 1.24x10<sup>-3</sup>) (<xref rid="fig1" ref-type="fig">Fig. 1E2</xref>).</p>
</sec>
<sec id="s2a2">
<title>Monkey psychophysics</title>
<p>We next measured the monkey’s ability to segment overlapping stimuli moving at two speeds. We trained one monkey to perform a 2AFC task to report whether a stimulus contained one or two speeds (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>, see Methods). The monkey’s performance at x2 speed separation (<xref rid="fig2" ref-type="fig">Fig. 2B2</xref>) was very similar in shape to that of humans (<xref rid="fig1" ref-type="fig">Fig. 1C2</xref> of the 2AFC task). In addition, the monkey’s performance was generally better at x4 separation than at x2 separation (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref> vs <xref ref-type="fig" rid="fig2">2B2</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Monkey psychophysics.</title>
<p><bold>A</bold>. Behavioral task and visual stimuli. <bold>B</bold>. Discriminability of a monkey subject performing a 2AFC task. <bold>B1</bold>. X4 speed separation. <bold>B2</bold>. X2 speed separation. Error bars and error bands represent ±STE.</p></caption>
<graphic xlink:href="532456v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>At x4 separation, the performance improved as the stimulus speeds increased from 1.25 and 5°/s to 5 and 20°/s. As the stimulus speeds increased from 5 and 20°/s to 20 and 80°/s, the performance declined (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref>), similar to the human results (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). However, the monkey was still able to differentiate the bi-speed and single-speed stimuli at the fastest speeds of 20 and 80°/s (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref>), whereas the average human performance was poor (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). Note that one human subject (NP) performed better than other subjects at 20 and 80°/s (mean <italic>d’</italic> = 2.12, STE = 0.12) (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). The difference between the monkey and human results may be due to species differences or individual variability. It was also possible when it was difficult to segment two speeds at fast stimulus speeds, the monkey subject may resort to using the appearance (e.g. the apparent coherence) of the stimulus rather than speed segmentation to perform the task. Whereas human subjects were more likely to perform the task based on speed segmentation, as indicated by the similar results obtained using the 2AFC and 3AFC tasks.</p>
<p>Another notable difference between the monkey and human results was that, at low stimulus speeds of 1.25 and 5°/s, human subjects could differentiate the bi-speed stimulus from the corresponding single-speed (2.5°/s) stimulus nearly perfectly. In comparison, the ability of the monkey subject to segment 1.25 and 5 °/s was lower (<italic>d’</italic> = 2.8, STE = 0.51), although still good (<xref rid="fig2" ref-type="fig">Fig 2B1</xref> vs 1C1). This may be explained by how the monkey performed the task. For human subjects, while the motion of the faster component (5°/s) of the bi-speed stimulus appeared to be salient, it required effort to notice the very slow component (1.25°/s) to be moving rather than stationary. In some trials, the monkey may be able to segment the 5°/s component from the bi-speed stimulus but consider the slower component of 1.25°/s as stationary and, therefore, reported that the stimulus contained only one speed. Despite some differences between the human and monkey results, the two general trends – better segmentation performance at larger than smaller speed separation and reduced segmentation ability at very fast speeds were consistent across species.</p>
</sec>
</sec>
<sec id="s2b">
<title>Neuronal responses in MT elicited by bi-speed stimuli and single-speed components</title>
<p>To characterize how neurons in the visual cortex encode two overlapping stimuli moving at different speeds, we recorded extracellularly from 100 isolated neurons in the extrastriate area MT of two male monkeys (60 neurons from IM and 40 neurons from MO) while the monkeys performed a fixation task. <xref rid="fig3" ref-type="fig">Figure 3</xref> shows the responses from four example neurons. To visualize the relationship between the responses to the bi-speed stimulus (red) and the constituent speed components, the plots of the response tuning curves to the slower (green) and faster (blue) components are shifted horizontally so that the responses elicited by the bi-speed stimulus and its constituent single-speed components are aligned along a vertical line as illustrated in <xref rid="fig3" ref-type="fig">Figure 3A1</xref>.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Speed tuning curves of four example neurons to bi-speed stimuli and constituent single-speed components.</title>
<p><bold>A</bold>. Illustration of the visual stimuli and the response tuning curves of an example neuron. Green and blue dots in the diagram indicate two overlapping achromatic random-dot patterns moving in the same direction at different speeds. Colors are used for illustration purposes only. The abscissas in green and blue show the speeds of the slower and faster components, respectively. The abscissa in black shows the log mean speed of the two speed components. <bold>A-D</bold>. Four example neurons are sorted by their preferred speeds (PS) from slow to fast. Error bars represent ±STE. For some data points, error bars were comparable to the symbol size. <bold>A1-D1</bold>. X4 speed separation. <bold>A2-D2</bold>. X2 speed separation.</p></caption>
<graphic xlink:href="532456v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We found that the relationship between the responses elicited by the bi-speed stimulus and the constituent components depended on the stimulus speeds. <xref rid="fig3" ref-type="fig">Figure 3A1-D1</xref> shows the results of four example MT neurons obtained when the separation between the two component speeds was large (×4). The component speeds were the same as the bi-speed stimuli used in the psychophysics experiments (<xref rid="fig1" ref-type="fig">Fig. 1B1, B2</xref>). When the two component speeds were slow (1.25 and 5°/s), the response to the bi-speed stimulus nearly followed the response elicited by the faster-speed component (the leftmost data points in <xref rid="fig3" ref-type="fig">Fig. 3A1-D1</xref>). Importantly, the response elicited by the bi-speed stimuli did not simply follow the stronger component response. When the preferred speed of a neuron was sufficiently low such that the response elicited by the faster component was weaker than that elicited by the slower component, the response to the bi-speed stimulus still followed the weaker response elicited by the faster component (<xref rid="fig3" ref-type="fig">Fig. 3A1</xref>). When the speeds of the two stimulus components were at 2.5 and 10°/s, the response elicited by the bi-speed stimulus was also biased toward the faster component, albeit to a lesser degree. As the mean speed of the two stimulus components increased, the bi-speed response became closer to the average of the two component responses (<xref rid="fig3" ref-type="fig">Fig. 3A1-D1</xref>). We found similar results when the speed separation between the two stimulus components was small (×2) (<xref rid="fig3" ref-type="fig">Fig. 3A2-D2</xref>).</p>
<p>We found the same trend in the neural responses averaged across 100 neurons (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>). At ×4 speed separation, the population-averaged response showed a strong bias toward the faster component when the stimulus speeds were low and shifted toward the average of the component responses as the speeds increased (<xref rid="fig4" ref-type="fig">Fig. 4A1</xref>). To determine whether this trend held for neurons with different preferred speeds, we divided the neuron population into three groups with “low” (&lt;2.5°/s), “intermediate” (between 2.5 and 25°/s), and “high” (&gt;25°/s) preferred speeds. For 10 neurons that preferred low speeds, the response to the faster component was weaker than that to the slower component. However, the response to the bi-speed stimuli was strongly biased toward the faster component when the stimulus speeds were low (<xref rid="fig4" ref-type="fig">Fig. 4B1</xref>). This finding suggests that the bi-speed response is not biased toward the stimulus component that the neuron prefers when presented alone but biased toward the faster speed component.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Population-averaged speed tuning curves to bi-speed stimuli and constituent single-speed components.</title>
<p>Speed tuning curves averaged across <bold>A</bold>. 100 neurons in our dataset. <bold>B</bold>. 10 neurons that had PS lower than 2.5°/s. <bold>C</bold>. 61 neurons that had PS between 2.5 and 25°/s. <bold>D</bold>. 29 neurons that had PS greater than 25°/s. Error bars represent ±STE. For some data points, error bars were comparable to the symbol size. <bold>A1-D1</bold>. X4 speed separation. <bold>A2-D2</bold>. X2 speed separation.</p></caption>
<graphic xlink:href="532456v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>For 61 neurons that preferred intermediate speeds (<xref rid="fig4" ref-type="fig">Fig. 4C1</xref>) and 29 neurons that preferred high speeds (<xref rid="fig4" ref-type="fig">Fig. 4D1</xref>), we also found a strong bias toward the faster speed component when the stimulus speeds were low, and a gradual change toward the average of the component responses as the stimulus speeds increased. At the lowest stimulus speeds of 1.25 and 5°/s, the bi-speed response was nearly identical to that elicited by the faster component, showing “faster-component-take-all”. For neurons that preferred high speeds, faster-component-take-all was also found for the stimulus speeds of 2.5 and 10°/s (<xref rid="fig4" ref-type="fig">Fig. 4D1</xref>). We found similar results at x2 speed separation (<xref rid="fig4" ref-type="fig">Fig. 4A2-D2</xref>), although the effect is not as pronounced as x4 speed separation.</p>
</sec>
<sec id="s2c">
<title>Relationship between the responses to bi-speed stimuli and constituent stimulus components</title>
<p>To quantify the relationship between the response elicited by the bi-speed stimuli and the corresponding component responses, we expressed the response <italic>R</italic> of a neuron elicited by two component speeds <italic>v</italic><sub><italic>s</italic></sub> and <italic>v</italic><sub><italic>f</italic></sub> as a weighted sum of the component responses <italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub> elicited by the slower (<italic>v</italic><sub><italic>s</italic></sub>) and faster (<italic>v</italic><sub><italic>f</italic></sub>) component speed, respectively:
<disp-formula id="eqn5">
<graphic xlink:href="532456v2_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in which, <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub> are the response weights for the slower and faster component, respectively, and <italic>f</italic> is the speed-tuning function of the neuron in response to a single speed.</p>
<p>For three data points of <italic>R, R</italic><sub><italic>s</italic></sub>, and <italic>R</italic><sub><italic>f</italic></sub>, as long as <italic>R</italic><sub><italic>f</italic></sub> ≠ <italic>R</italic><sub><italic>s</italic></sub>, <italic>R</italic> can always be expressed as:
<disp-formula id="eqn6">
<graphic xlink:href="532456v2_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The response weights can be expressed as <inline-formula><inline-graphic xlink:href="532456v2_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub> <italic>s</italic>um to 1.</p>
<p>By this definition, if <italic>R</italic> were closer to one component response, that stimulus component would have a higher weight. Note that <xref ref-type="disp-formula" rid="eqn6">Equation 6</xref> is not intended for fitting the response <italic>R</italic> using <italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub>, but rather to use the relationship among <italic>R, R</italic><sub><italic>s</italic></sub>, and <italic>R</italic><sub><italic>f</italic></sub> to define the weights for the faster and slower components. We aim to determine whether, and if so how, the response weights change with the stimulus speeds.</p>
<p>Using this approach to estimate the response weights for individual neurons can be inaccurate because, at each speed pair, the weights are determined only by three data points. Also, <italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub> can sometimes be similar so the denominator in <xref ref-type="disp-formula" rid="eqn6">Equation 6</xref> could be close to zero. We therefore used the neuronal responses across the population to determine the response weights (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). For each pair of stimulus speeds, we plotted (<italic>R - R</italic><sub><italic>s</italic></sub>) in the ordinate versus (<italic>R</italic><sub><italic>f</italic></sub> - <italic>R</italic><sub><italic>s</italic></sub>) in the abscissa. <xref rid="fig5" ref-type="fig">Figure 5A1-E1</xref> shows the results obtained at ×4 speed separation. Across the neuronal population, the relationship between (<italic>R - R</italic><sub><italic>s</italic></sub>) and (<italic>R</italic><sub><italic>f</italic></sub> - <italic>R</italic><sub><italic>s</italic></sub>) is remarkably linear (Type II regression, <italic>R</italic><sup><italic>2</italic></sup> ranged from 0.94 to 0.76, see <xref rid="tbl1" ref-type="table">Table 1</xref>), and can be well described as:</p>
<p>
<disp-formula id="eqn7">
<graphic xlink:href="532456v2_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Because all the regression lines in <xref rid="fig5" ref-type="fig">Figure 5</xref> nearly go through the origin (i.e. intercept <italic>b</italic> ≈ 0, <xref rid="tbl1" ref-type="table">Table 1</xref>), the slope <italic>k</italic> obtained from the linear regression approximates <inline-formula><inline-graphic xlink:href="532456v2_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, which is the response weight <italic>w</italic><sub><italic>f</italic></sub> for the faster component (<xref ref-type="disp-formula" rid="eqn6">Eq. 6</xref>). Therefore, for each pair of stimulus speeds, we can estimate the response weight for the faster component using the slope of the linear regression of the responses from the neuronal population. Our results showed that the bi-speed response changed progressively from a scheme of “faster-component-take-all” to “response-averaging” as the speeds of the two stimulus components increased (<xref rid="fig5" ref-type="fig">Fig. 5F1</xref>). We found similar results when the speed separation between the stimulus components was small (×2), although the bias toward the faster component at low stimulus speeds was not as strong as x4 speed separation (<xref rid="fig5" ref-type="fig">Fig. 5A2-F2</xref> and <xref rid="tbl1" ref-type="table">Table 1</xref>).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Response weight for faster component based on linear regression (N = 100)</title></caption>
<graphic xlink:href="532456v2_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Relationship between the responses to the bi-speed stimuli and the constituent stimulus components.</title>
<p><bold>A-E</bold>. Each panel shows the responses from 100 neurons. Each dot represents the response from one neuron. The ordinate shows the difference between the responses to a bi-speed stimulus and the slower component (<italic>R - R</italic><sub><italic>s</italic></sub>). The abscissa shows the difference between the responses to the faster and slower components (<italic>R</italic><sub><italic>f</italic></sub> <italic>- R</italic><sub><italic>s</italic></sub>). Type II regression line is shown in red. <bold>F</bold>. Response weights for the faster stimulus component obtained from the slope of the linear regression based on the responses of 100 neurons. <bold>A1-F1</bold>. X4 speed separation. <bold>A2-F2</bold>. X2 speed separation.</p></caption>
<graphic xlink:href="532456v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>So far we have shown that human and monkey subjects can segment two overlapping speeds, but the segmentation becomes harder when the mean stimulus speed is fast. We have also established that the neural representation of two speeds in area MT can be well described by weighted summation of the responses elicited by the individual speed components, and the weights change from faster-take-all to response-averaging as the mean stimulus speed increases. In the following sections, we will show that this neural encoding rule is robust over time and across different motion directions, and is not due to attention modulation. We will further show the result from a decoding analysis using a linear classifier that suggests a connection between the neural representation of multiple speeds in MT and perception. Finally, we will describe a normative model that captures the encoding rule.</p>
</sec>
<sec id="s2d">
<title>Timecourse of MT responses to bi-speed stimuli</title>
<p>We asked whether the bias toward the faster speed component was robust over time. We also asked whether the faster-speed bias occurred early in the neuronal response or developed gradually over time. <xref rid="fig6" ref-type="fig">Figure 6</xref> shows the timecourse of the response averaged across 100 neurons in the population. The bias toward the faster speed component occurred at the very beginning of the neuronal response when the stimulus speeds were less than 20º/s (<xref rid="fig6" ref-type="fig">Fig. 6A-C</xref>). The first 20-30 ms of the neuronal response elicited by the bi-speed stimulus was nearly identical to the response elicited by the faster component alone, as if the slower component were not present. The early dominance of the faster component on the bi-speed response cannot be explained by the difference in the response latencies of the faster and slower components. Faster stimuli elicit a shorter response latency (<xref ref-type="bibr" rid="c25">Lisberger and Movshon, 1999</xref>), which can be seen in <xref rid="fig6" ref-type="fig">Figure 6A-C</xref>. However, the bi-speed response still closely followed the faster component for a period of time after the response to the slower component started to rise. The effect of the slower component on the bi-speed response was delayed for about 25 ms, as indicated by the arrows in <xref rid="fig6" ref-type="fig">Figure 6A-C</xref>. During the rest of the response period, the bias toward the faster component was persistent. As the stimulus speeds increased, the bi-speed response gradually changed to follow the average of the component responses (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>). We found similar results when the speed separation between the two stimulus components was x4 (<xref rid="fig6" ref-type="fig">Fig. 6A1-E1</xref>) and x2 (<xref rid="fig6" ref-type="fig">Fig. 6A2-E2</xref>).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Timecourse of MT responses averaged across neurons to bi-speed stimuli.</title>
<p>Peristimulus time histograms (PSTHs) were averaged across 100 neurons. The bin width of PSTH was 10 ms. <bold>A1-E1</bold>. X4 speed separation. <bold>A2-E2</bold>. X2 speed separation. In A-C, the left dash line indicates the latency of the response to a bi-speed stimulus, and the right dash line and the arrow indicate when the response to a bi-speed stimulus started to diverge from the response to the faster component.</p></caption>
<graphic xlink:href="532456v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s2d1">
<title>Faster speed bias also occurs when stimulus components move in different directions</title>
<p>We showed that at low and intermediate speeds, MT response to the bi-speed stimulus was biased toward the faster stimulus component when two overlapping components moved in the same direction (at the preferred direction of the neuron). We asked whether this faster-speed bias also occurred when visual stimuli moved in different directions. We presented overlapping random-dot stimuli moving in two directions separated by 90° in the RF. The two stimulus components moved at different speeds. The speed of the stimulus component moving on the clockwise side of the two directions was 10°/s, whereas the speed of the other component was 2.5°/s. We varied the vector-average (VA) direction of the two component directions across 360° to characterize the direction tuning curves. <xref rid="fig7" ref-type="fig">Figure 7A</xref> shows the direction tuning curves averaged across 21 neurons (13 neurons from monkey RG, 8 neurons from monkey GE). The direction tuning curve of each neuron was first fitted with a spline and rotated such that the VA direction 0° was aligned with the neuron’s preferred direction before averaging across neurons. The peak response to the faster component (<xref rid="fig7" ref-type="fig">Fig. 7A</xref>, blue curve) was stronger than that to the slower component (green curve). MT responses elicited by the bi-directional stimuli (red curve) showed a strong bias toward the faster component, more than expected by the average of the two component responses (black curve).</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>MT responses to bi-speed stimuli moving in different directions.</title>
<p><bold>A</bold>. Population-averaged direction tuning curves of 21 neurons in response to stimuli moving at two speeds and in two directions separated by 90° (red). The component direction Dir. 1 (blue) moved at 10°/s and the component direction Dir. 2 (green) moved at 2.5°/s. Dir. 1 was on the clockwise side of Dir. 2. The abscissas in blue and green show the directions of stimulus components Dir. 1 and Dir. 2, respectively. The blue and green axes are shifted by 90° relative to each other. The abscissa in black shows the corresponding VA direction of the two direction components. <bold>B</bold>. Response weights for the stimulus components obtained using a linear weighted summation fit. Each dot represents the response from one neuron.</p></caption>
<graphic xlink:href="532456v2_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We fitted the MT raw direction tuning curve to the bi-directional stimuli as a weighted sum of the direction tuning curves to the individual stimulus components moving at different speeds:
<disp-formula id="eqn8">
<graphic xlink:href="532456v2_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in which, <italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub> are the direction tuning curves to the slower and faster stimulus components, respectively; <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub> are the motion directions of the two components; <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub> are fitted response weights for the slower and faster components, respectively and they are not required to sum to 1. An implicit assumption of the model is that, at a given pair of stimulus speeds, the response weights for the slower and faster components are fixed across motion directions. The model fitted MT responses very well, accounting for an average of 90.3% of the response variance (std = 8.4%, N = 21). The median response weights for the slower and faster components were 0.26 and 0.74, respectively, and were significantly different (Wilcoxon signed-rank test, p = 8.0 x10<sup>-5</sup>). For most neurons (20 out of 21), the response weight for the faster component was larger than that for the slower component (<xref rid="fig7" ref-type="fig">Fig. 7B</xref>). This result suggests that at low to intermediate speeds the faster-speed bias is a general phenomenon that applies to overlapping stimuli moving either in the same direction or different directions.</p>
</sec>
<sec id="s2d2">
<title>Faster-speed bias is not due to attention</title>
<p>We asked whether the faster-speed bias was due to bottom-up attention being drawn toward the faster stimulus component. To test this hypothesis, we recorded neural responses from one monkey (RG) as the animal directed attention away from the single- and bi-speed stimuli presented in the RFs. We trained the monkey to perform a demanding fine direction-discrimination task in the visual field opposite to that of the RFs. The perifoveal/peripheral viewing of the attended stimulus and the use of a fine direction-discrimination task made the task attention-demanding (see Methods). The monkey performed the task reliably with an average correct rate of 86.7 ± 7.3% (mean ± std) across 23 sessions and a total of 5184 trials. The correct rates for 10°, 15°, and 20° direction offsets of the fine direction-discrimination task were 78.8 ± 9.7%, 87.5 ± 8.3%, and 93.9 ± 5.8%, respectively (see Methods).</p>
<p>We recorded the responses from 48 MT neurons in 23 experimental sessions while the monkey performed the task. Among the 48 neurons, 32 neurons were recorded using both the attention-away paradigm and a fixation paradigm. We found a similar faster-speed bias at low and intermediate speeds. The results obtained using the attention-away paradigm and the fixation paradigm were similar (<xref rid="figS1" ref-type="fig">Supplementary Fig. 1</xref>). The faster-speed bias was more evident at x4 speed separation than at x2 speed separation. Based on the neuronal responses across the population, we calculated the weight for the faster stimulus component at each of the five speed pairs using linear regression (<xref ref-type="disp-formula" rid="eqn6">Eqs. 6</xref>, <xref ref-type="disp-formula" rid="eqn7">7</xref>) as we did for <xref rid="fig5" ref-type="fig">Figure 5</xref>. When attention was directed away from the RF, the response weight for the faster component decreased from a strong faster-speed bias to response averaging as the stimulus speeds increased (red curves in <xref rid="fig8" ref-type="fig">Fig. 8</xref>), similar to the results from the fixation paradigm (blue and black curves in <xref rid="fig8" ref-type="fig">Fig. 8</xref>). Together, these results suggest that the faster-speed bias at low to intermediate speeds was not due to attention being drawn to the faster-speed component.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Comparison of response weights between attention-away and fixation paradigms.</title>
<p>The red and blue curves indicate the response weights for the faster speed component in an attention-away paradigm and a fixation paradigm, respectively, obtained from the same population of 32 neurons. The black curves are the replot of the data in <xref rid="fig5" ref-type="fig">Figure 5F</xref>, obtained from 100 neurons in a fixation paradigm. <bold>A</bold>. X4 speed separation. <bold>B</bold>. X2 speed separation.</p></caption>
<graphic xlink:href="532456v2_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><title>Population-averaged speed tuning curves to bi-speed stimuli and constituent single-speed components recorded in an attention-away and a fixation paradigm.</title>
<p>Speed tuning curves from one monkey (RG) averaged across <bold>A1-D1</bold>. 5 neurons that had PS ≤ 2.5°/s, <bold>A2-D2</bold>. 6 neurons that had PS between 2.5 and 25°/s, <bold>A3-D3</bold>. 21 neurons that had PS &gt; 25°/s. Error bars represent ±STE. <bold>A1-A3</bold> and <bold>B1-B3</bold>. X4 speed separation; <bold>C1-C3</bold> and <bold>D1-D3</bold>. X2 speed separation. <bold>A1-A3</bold> and <bold>C1-C3</bold>. Attention directed away from the RF; <bold>B1-B3</bold> and <bold>D1-D3</bold>. Fixation paradigm.</p></caption>
<graphic xlink:href="532456v2_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2d3">
<title>Discriminate bi-speed and single-speed stimuli based on neuronal responses in area MT</title>
<p>We asked whether the responses of MT neurons contain information about bi-speed and single-speed stimuli suitable to support the perceptual discrimination of these stimuli. To address this question, we first examined the responses elicited by the bi-speed and single-speed stimuli from a population of MT neurons that have different preferred speeds (PS). We next used a classifier to discriminate the bi-speed stimuli from the single, log-mean speed stimuli based on MT responses.</p>
<p>In different experimental sessions, we centered visual stimuli on neurons’ RFs. Except for the spatial location, the visual stimuli were identical across experimental sessions. This allowed us to pool the trial-averaged responses recorded from different neurons to form a pseudo-population (see Methods). One can interpret the responses as from a population of neurons with spatially aligned center locations of the RFs elicited by the same visual stimulus. <xref rid="fig9" ref-type="fig">Figure 9</xref> shows the pseudo-population neural response (referred to as the population response) plotted as a function of neurons’ preferred speed (PS), constructed from 100 neurons that we recorded using a fixation paradigm (see Methods). To capture the population response evenly across a full range of PS, we spline-fitted the recorded response elicited by the bi-speed stimulus (the red curves) and by the single, log-mean speed (the black curves) (<xref rid="fig9" ref-type="fig">Fig. 9A-E</xref>). At x4 and x2 speed separations, the population responses elicited by two speeds did not show two separate peaks but rather had a main hump that shifted from low PS to high PS as the stimulus speeds increased. At x4 speed separation and across all five speed pairs, the population response elicited by two speeds was broader and flatter than that elicited by the single log-mean speed (<xref rid="fig9" ref-type="fig">Fig. 9A1-E1</xref>).</p>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9.</label>
<caption><title>Population neural responses elicited by the bi-speed and single-speed stimuli and the performance of a linear classifier.</title>
<p>A population of 100 neurons was constructed by pooling across recordings in different experimental sessions. Each neuron’s response was averaged across experimental trials and normalized by the maximum response of the spline-fitted speed tuning curve to single speeds. Each dot represents the response from one neuron plotted as the neuron’s PS in the natural logarithm scale. The curves represent the spline-fitted population neural responses. Red: response to the bi-speed stimulus; Black: the response to the corresponding single, log-mean speed. <bold>A1-F1</bold>. X4 speed separation. The speeds of the bi-speed stimuli are 1.25 and 5°/s (A1), 2.5 and 10°/s (B1), 5 and 20°/s (C1), 10 and 40°/s (D1), 20 and 80°/s (E1). <bold>A2-F2</bold>. X2 speed separation. The speeds of the bi-speed stimuli are 1.25 and 2.5°/s (A2), 2.5 and 5°/s (B2), 5 and 10°/s (C2), 10 and 20°/s (D2), 20 and 40°/s (E2). Two red dots on the X-axis indicate two component speeds; the black dot indicates the log-mean speed. <bold>F1, F2</bold>. Performance of a linear classifier to discriminate the population neural responses to the bi-speed stimulus and the corresponding single log-mean speed. Error bars represent STE.</p></caption>
<graphic xlink:href="532456v2_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In our experiments, we directly measured the neuronal responses elicited by the log-mean speed of x4, but not x2 speed separation. Because we had characterized each neuron’s tuning curve to single speeds, we were able to infer the responses elicited by the log-mean speed of x2 separation by interpolating the speed tuning curve using a spline fit. At x2 speed separation, the population response elicited by two speeds was similar to that elicited by the single log-mean speed, with the two-speed population response being slightly broader (<xref rid="fig9" ref-type="fig">Fig. 9A2-E2</xref>).</p>
<p>To evaluate the discriminability between MT population responses elicited by the bi-speed stimulus and the corresponding log-mean speed, we used a linear classifier to perform a discrimination task. Trial-by-trial population responses were generated randomly according to a Poisson process and with the mean response of each neuron set to the trial-averaged neuronal response. The classifier was trained and tested using k-fold cross-validation. The classifier determined whether a population response of the 100 neurons was elicited by two speeds or a single speed (see Methods). Discriminability of the classifier was measured in <italic>d’</italic> as in our psychophysics study. At x2 speed separation, the classifier’s performance (<xref rid="fig9" ref-type="fig">Fig. 9F2</xref>) had a similar shape as that of the human (<xref rid="fig1" ref-type="fig">Fig. 1C2, E2</xref>) and monkey (<xref rid="fig2" ref-type="fig">Fig. 2B2</xref>) subjects, but the classifier’s performance was worse than perceptual performance. Consistent with perceptual discrimination, the classifier’s performance at x4 speed separation (<xref rid="fig9" ref-type="fig">Fig. 9F1</xref>) was better than that at x2 speed separation (<xref rid="fig9" ref-type="fig">Fig. 9F2</xref>). At x4 speed separation, the discriminability was high and slightly decreased as the stimulus speed increased (<xref rid="fig9" ref-type="fig">Fig. 9F1</xref>), which was generally consistent with the psychophysics results (<xref rid="fig1" ref-type="fig">Fig. 1C1, E1</xref>). One difference was that at 20 and 80°/s, the classifier’s performance did not drop to a low level as human performance (compare <xref rid="fig9" ref-type="fig">Fig. 9F1</xref> with <xref rid="fig1" ref-type="fig">Fig. 1C1, E1</xref>), but was more comparable to that of the monkey subject (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref>). At the highest stimulus speeds, although the difference between the population responses to the bi-speed and single-speed stimuli is sufficiently large for the classifier to pick up (<xref rid="fig9" ref-type="fig">Fig. 9E1</xref>), it is difficult to decode two speeds from the population response elicited by 20 and 80°/s (data not shown, but see Figs. 12-14 of <xref ref-type="bibr" rid="c20">Huang et al., 2023</xref>). Therefore, if the subject performed the discrimination task based on whether a stimulus contains one or two speeds (as for human subjects), the performance should be low at these high speeds. Whereas, if the subject performed the task based on other cues such as the apparent coherence of the stimulus at these fast speeds, the performance could be reasonably good. Overall, the discrimination performance of the classifier based on the population responses in MT is largely consistent with the perceptual discrimination of human and monkey subjects, with an exception when stimulus speeds were 20 and 80°/s.</p>
</sec>
</sec>
<sec id="s2e">
<title>A model that accounts for the neuronal responses to bi-speed stimuli</title>
<p>We showed that the neuronal response in MT to a bi-speed stimulus can be described by a weighted sum of the neuron’s responses to the individual speed components. We also showed that the weights were dependent on the stimulus speeds, rather than the preferred speed of the neuron (<xref rid="fig5" ref-type="fig">Fig. 5A-E</xref>). We will next show that a modified normalization model could explain these results.</p>
<p>The divisive normalization model (<xref ref-type="bibr" rid="c15">Carandini and Heeger, 2012</xref>) has been used to explain a wide array of phenomena, including neuronal responses elicited by multiple visual stimuli (e.g. <xref ref-type="bibr" rid="c12">Britten and Heuer 1999</xref>; <xref ref-type="bibr" rid="c17">Heuer and Britten 2002</xref>; <xref ref-type="bibr" rid="c14">Busse et al. 2009</xref>; <xref ref-type="bibr" rid="c57">Xiao et al. 2014</xref>; <xref ref-type="bibr" rid="c56">Xiao and Huang 2015</xref>; <xref ref-type="bibr" rid="c5">Bao and Tsao 2018</xref>). In the normalization model, while the division by the activity of a population of neurons in the denominator (the normalization pool) is well accepted, what constitutes the numerator is unclear. The signal strength such as luminance contrast or motion coherence of each stimulus component was typically used in the numerator. However, it is not always clear how to define the signal strength of a sensory stimulus. In this study, multiple speed components had the same contrast and coherence. Stimulus speed itself is not a good measure of signal strength. We have previously proposed that the weight of a stimulus component is proportional to the activity of a population of neurons elicited by the stimulus component (<xref ref-type="bibr" rid="c57">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="c55">Wiesner et al., 2020</xref>), which reflects the signal strength in the “eye” of the neuronal population. We name this neuronal population the “weighting pool”. The nature and scope of the weighting pool are currently unclear. Here we assumed that, in response to multiple overlapping speeds, the weighting pool is composed of neurons with a broad range of speed preferences. We used the following equation (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>) to fit each neuron’s responses to the bi-speed stimuli across 5 pairs of speeds (i.e. the speed tuning curve to the bi-speed stimuli), at either x4 or x2 speed separation:
<disp-formula id="eqn9">
<graphic xlink:href="532456v2_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<italic>R</italic><sub><italic>b</italic></sub> is the model-fitted response of a neuron to a bi-speed stimulus. <italic>f</italic> is the response tuning of the neuron to single speeds. <italic>v</italic><sub><italic>s</italic></sub> and <italic>v</italic><sub><italic>f</italic></sub> are the slower and faster component speeds, respectively. <italic>S</italic><sub><italic>s</italic></sub> and <italic>S</italic><sub><italic>f</italic></sub> are the population neural responses in MT to the slower and faster component speeds, respectively, and were estimated based on the population-averaged speed-tuning curve to single speeds of our recorded MT neurons (<xref rid="fig10" ref-type="fig">Fig. 10A</xref>). <italic>n, σ</italic>, α, and <italic>c</italic> are model parameters and have the following constraints: 0 ≤ n ≤ 100, 0 ≤ σ ≤ 500, 0.01 ≤ α ≤ 100, 0 ≤ c ≤ 100. α is a parameter that controls for the tuned normalization (<xref ref-type="bibr" rid="c34">Ni et al., 2012</xref>; <xref ref-type="bibr" rid="c47">Rust et al 2006</xref>; <xref ref-type="bibr" rid="c16">Carandini et al., 1997</xref>).</p>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure 10.</label>
<caption><title>Model fit of MT responses to bi-speed stimuli.</title>
<p><bold>A</bold>. Speed tuning curve to single-speed stimulus averaged across 100 recorded MT neurons in our data set. <bold>B</bold>. Population-averaged responses to slower (open circle) and faster (solid circle) speed components. The convention for the speed components is the same as in <xref rid="fig1" ref-type="fig">Figure 1B1, B2</xref>. <bold>C, D</bold>. The response weights for the faster component calculated based on the data (black) and the models of <xref ref-type="disp-formula" rid="eqn9">Equation 9</xref> (green in <bold>C</bold>) and <xref ref-type="disp-formula" rid="eqn10">Equation 10</xref> (red in <bold>D</bold>). <bold>B1-D1</bold>. X4 speed separation. <bold>B2-D2</bold>. X2 speed separation.</p></caption>
<graphic xlink:href="532456v2_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>When the stimulus components move at low or intermediate speeds ≤ 20°/s, population-averaged MT response to the faster-speed component <italic>S</italic><sub><italic>f</italic></sub> is stronger than that to the slower-speed component <italic>S</italic><sub><italic>s</italic></sub> at the x4 (<xref rid="fig10" ref-type="fig">Fig. 10B1</xref>) and x2 speed separation (<xref rid="fig10" ref-type="fig">Fig. 10B2</xref>). This difference between <italic>S</italic><sub><italic>f</italic></sub> and <italic>S</italic><sub><italic>s</italic></sub> would weigh the faster stimulus component more strongly than the slower component (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>). When one or more stimulus components move at speeds greater than 20°/s, <italic>S</italic><sub><italic>f</italic></sub> is smaller than <italic>S</italic><sub><italic>s</italic></sub> (<xref rid="fig10" ref-type="fig">Fig. 10B1, B2</xref>) and would weigh the faster component less than the slower component. The model accounted for on average 78.3% of the response variance across 100 neurons at x4 speed separation, and 95.9% of the variance at x2 speed separation. Based on the model-fitted bi-speed responses across the population of 100 neurons, we calculated the weight for the faster stimulus component at each of the five speed pairs using linear regression, as we did for the recorded neuronal responses (<xref ref-type="disp-formula" rid="eqn6">Eqs. 6</xref>, <xref ref-type="disp-formula" rid="eqn7">7</xref>). The weights obtained using the model-fitted responses <italic>R</italic><sub><italic>bi</italic></sub> matched the weights derived from the data well (R<sup>2</sup> = 0.90 for x4 and 0.87 for x2 speed separation) (<xref rid="fig10" ref-type="fig">Fig. 10C1, C2</xref>). Although the model is reasonably successful, it has two small deficiencies: 1) At the fastest speeds of 20 and 80°/s and 20 and 40°/s, the model predicted the weight for the faster component to be slightly less than 0.5, whereas the data showed response averaging (<xref rid="fig10" ref-type="fig">Fig. 10C1, C2</xref>); 2) At the slowest speeds of 1.25 and 5°/s, the faster-speed bias predicted by the model was not as strong as the data (<xref rid="fig10" ref-type="fig">Fig. 10C1</xref>).</p>
<p>In <xref ref-type="disp-formula" rid="eqn9">Equation 9</xref>, the parameter α only controls the relative contribution of <italic>S</italic><sub><italic>s</italic></sub> and <italic>S</italic><sub><italic>f</italic></sub> to the response of the normalization pool. Although the mechanism underlying the tuned normalization is unknown, we assumed that a similar mechanism may also apply to the response of the weighting pool, and may reflect how faster and slower components are mixed in the feedforward input. In <xref ref-type="disp-formula" rid="eqn10">Equation 10</xref>, α appears in both the numerator and denominator in determining the weight for the faster speed component.
<disp-formula id="eqn10">
<graphic xlink:href="532456v2_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The model based on <xref ref-type="disp-formula" rid="eqn10">Equation 10</xref> improved the fit of the speed tuning to the bi-speed stimuli and accounted for on average 84.7% and 97.7% of the response variance at x4 and x2 separation, respectively, significantly better than <xref ref-type="disp-formula" rid="eqn9">Equation 9</xref> (one-tailed paired t-test, p &lt; 0.002). The weights obtained using <xref ref-type="disp-formula" rid="eqn10">Equation 10</xref> also matched the weight of the faster component derived from data better (R<sup>2</sup> = 0.925 for x4 and 0.93 for x2 separation) (<xref rid="fig10" ref-type="fig">Fig. 10D1, D2</xref>). For both x4 and x2 separations, the median α of <xref ref-type="disp-formula" rid="eqn10">Equation 10</xref> is 1.2, which is significantly different from 1 (Wilcoxon signed-rank test, p &lt; 0.0002). This result indicates that, in addition to the stimulus-dependent weighting prescribed by <italic>S</italic><sub><italic>f</italic></sub> and <italic>S</italic><sub><italic>s</italic></sub>, the parameter α provides a stronger weighting for the faster component across speeds. Together, the overall response weight for the faster component is greater than the slower component at the low and intermediate speed range, and the two weights are similar at fast stimulus speeds, consistent with the neural data (<xref rid="fig10" ref-type="fig">Fig. 10D1, D2</xref>).</p>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<sec id="s4a">
<title>Perception of multiple motion speeds and possible neural basis</title>
<p>Our human psychophysical study employed a novel 3AFC task. The task combined an identification task (to report whether a stimulus had one or two speeds) with a discrimination task (to compare a two-speed stimulus with a single-speed stimulus) (<xref rid="fig1" ref-type="fig">Fig. 1A, E1, E2</xref>). This approach allowed us to characterize discriminability based on perceptual segmentation, rather than other perceptual appearances of the stimuli. We made two findings. First and intuitively, the performance of speed segmentation was better when the separation between two stimulus speeds was larger. Second, at a fixed speed separation, speed segmentation became harder at fast speeds. Our results are consistent with previous studies. <xref ref-type="bibr" rid="c28">Masson et al. (1999)</xref> showed that the speed segmentation threshold increased sharply when the mean stimulus speed increased from 8°/s to 16°/s. By varying the width of a speed notch, <xref ref-type="bibr" rid="c45">Rocchi et al. (2018)</xref> showed that transparent motion perception was stronger when the notch width was wider, and that transparent motion was well perceived at slow speeds (mean speed = 4.6°/s), but not at faster speeds (mean speed = 20.6°/s) at a range of notch width from 1 to 6°/s. Our study showed that the segmentation performance dropped sharply at speeds of 20 and 80°/s (x4), and 20 and 40°/s (x2), faster than those shown in the previous studies. This discrepancy is likely due to the larger speed separations used in our study and the difference in stimuli. The visual stimuli used in our study had either one or two speeds, whereas those used by <xref ref-type="bibr" rid="c45">Rocchi et al. (2018)</xref> were sampled from a distribution of motion speeds and had multiple elements.</p>
<p>Our MT data from macaque monkeys provide explanations for the perceptual performance of speed segmentation. By comparing the constructed population MT responses elicited by two speeds and a single, log-mean speed, we found that the response difference was larger at x4 speed separation than at x2 separation (<xref rid="fig9" ref-type="fig">Fig. 9</xref>). This provides a neural correlate with better perceptual speed segmentation at larger speed separation. The explanation for the poor speed segmentation at fast stimulus speeds is more complicated. One factor may be related to the rule of neural encoding. At slow stimulus speeds, we found that neuronal response in MT showed a faster-speed bias. This would make detecting and extracting the faster speed component easier and therefore benefit speed segmentation. At fast stimulus speeds, we found that the encoding of multiple speeds changed to response averaging. As we have shown previously using visual stimuli moving transparently in different directions, a classifier’s performance of discriminating a bi-directional stimulus from a single-direction stimulus is worse when the encoding rule is response-averaging than biased toward one of the stimulus components (Fig. 12, <xref ref-type="bibr" rid="c56">Xiao and Huang, 2015</xref>). The same may apply to multiple motion speeds. Indeed, when the stimulus speeds were 20 and 40°/s (x2 separation), the constructed population responses elicited by the bi-speed stimulus and the log-mean speed were very similar (<xref rid="fig9" ref-type="fig">Fig. 9E2</xref>), which explained the poor performance of the classifier (<xref rid="fig9" ref-type="fig">Fig. 9F2</xref>) and the monkey subject (<xref rid="fig2" ref-type="fig">Fig. 2B2</xref>) at these speeds. However, when the stimulus speeds were 20 and 80°/s (x4 separation), the population responses elicited by the bi-speed stimulus and the log-mean speed were noticeably different, likely due to the large speed separation (<xref rid="fig9" ref-type="fig">Fig. 9E1</xref>). As a result, the classifier performed well at these fast speeds (<xref rid="fig9" ref-type="fig">Fig. 9F1</xref>), which was inconsistent with the performance of the monkey and human subjects. These observations suggest that, even when the population neural response elicited by a bi-speed stimulus is different from that elicited by a single-speed stimulus, there is no guarantee that information of two motion speeds is carried in the population neural response elicited by the bi-speed stimulus. The difference in population neural responses may contribute to perceptual differences in quality other than motion speeds. We therefore conducted a decoding study to evaluate what speed(s) can be extracted from MT population neural responses. We will report the main findings of the decoding study in a different paper as the current paper focuses on neural encoding. Briefly, we found that at x4 speed separation, it was possible to extract the speeds of motion components from the MT population neural response when the component speeds were slower than 20 and 80°/s. At 20 and 80°/s, the decoder was uncertain about how many speeds were in the visual stimuli and therefore had difficulty segmenting the visual stimuli at these fast speeds. The discrimination performance based on the decoded speeds was comparable to the perceptual performance of the monkey subject (Figs. 12-14 of <xref ref-type="bibr" rid="c20">Huang et al., 2023</xref>).</p>
</sec>
<sec id="s4b">
<title>Neural mechanisms underlying the encoding of multiple speeds of overlapping stimuli</title>
<p>We made a novel finding that the responses of MT neurons to overlapping stimuli were biased toward the faster speed component when the stimulus speeds were slow. The faster-speed bias was not due to an attentional modulation because we found similar results when attention was directed away from the RF. The faster-speed bias cannot be explained by the apparent contrast of the stimulus component either – the random dots of the faster speed component had shorter dwell time on the video display and appeared to be dimmer than the slower component. We showed that the neural encoding results can be explained by a modified normalization model.</p>
<p>Previous studies that characterize the neural representation of multiple stimuli have used stimulus strength to weigh the component responses in the divisive normalization model (<xref ref-type="bibr" rid="c14">Busse et al., 2009</xref>; <xref ref-type="bibr" rid="c34">Ni et al, 2012</xref>; <xref ref-type="bibr" rid="c57">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="c17">Heuer and Britten, 2002</xref>). In comparison to the standard normalization model, our model assumes that the response of a population of neurons (i.e. the weighting pool) defines the numerator of the normalization equation. The weighting pool may or may not be the same as the normalization pool that defines the response in the denominator. We have shown that weighting by the population neural response elicited by the stimulus component provides a parsimonious explanation of the response to multiple speeds even if the stimulus strength is not well defined. In a study investigating how neurons in the inferotemporal cortex represent multiple objects, <xref ref-type="bibr" rid="c5">Bao and Tsao (2018)</xref> suggest that the responses of neurons in category-selective regions to multiple objects are weighted by the responses from neighboring neurons that have the same category selectivity. Our study provides new insight into the extent of the weighting pool – in response to multiple speeds of overlapping stimuli, the weighting pool may include neurons with a broad range of preferred speeds. In this way, the summed (or averaged) population response depends only on the stimulus speed and is invariant to the individual neuron’s speed preference. In our data, MT population-averaged speed tuning curve peaks around 20°/s (<xref rid="fig10" ref-type="fig">Fig. 10A</xref>), which is consistent with previous studies (<xref ref-type="bibr" rid="c29">Maunsell and Van Essen 1983</xref>; <xref ref-type="bibr" rid="c25">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="c35">Nover et al., 2005</xref>; <xref ref-type="bibr" rid="c22">Huang and Lisberger, 2009</xref>). At speeds less than 20°/s, the population speed tuning has a positive slope, and a faster component would elicit a stronger population response than a slower component. This insight explains the faster-speed bias at low stimulus speeds and why a fixed weight for the faster component fits the responses of individual neurons elicited by a pair of stimulus speeds remarkably well, regardless of the speed preferences of the individual neurons (<xref rid="fig5" ref-type="fig">Fig. 5A-E</xref>). Neurons with similar speed preferences are spatially clustered in MT (<xref ref-type="bibr" rid="c26">Liu and Newsome, 2003</xref>). Should the weighting pool be composed of locally clustered neurons with similar preferred speeds, the response weight of a neuron would be higher for a speed component that elicits a stronger response. This would be contrary to our finding that neurons preferring very low speeds also showed a faster-speed bias, rather than a bias toward the slower component that elicited a stronger response (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>).</p>
<p>Although in our model we used the responses of a population of MT neurons to estimate the response of the weighting pool, it is also possible that the weighting pool may be composed of neurons that feed signals into MT and have similar population-averaged speed tuning as MT neurons. A recent study from our lab using multiple stimuli competing in more than one feature domain suggests that it is important to consider hierarchical processing in representing multiple stimuli, in particular how multiple stimuli are represented in the feedforward input to a visual area (<xref ref-type="bibr" rid="c55">Wiesner et al., 2020</xref>). Our result that the initial MT response to the bi-speed stimuli was nearly identical to the response to the faster component alone (<xref rid="fig6" ref-type="fig">Fig. 6A-C</xref>) suggests that the faster-speed bias may be already present in the feedforward input. The suppressive effect due to the presence of the slower component did not appear until 20-30 ms after the MT response onset (arrows in <xref rid="fig6" ref-type="fig">Fig. 6A-C</xref>), suggesting possible involvement of neural circuits within MT for additional processing and divisive normalization. MT neurons receive feedforward motion-selective input mainly from V1, and also from V2 and V3 (<xref ref-type="bibr" rid="c53">Ungerleider and Desimone, 1986</xref>; Movshson and Newsome, 1996; <xref ref-type="bibr" rid="c2">Anderson et al., 1998</xref>; <xref ref-type="bibr" rid="c3">Anderson and Martin 2002</xref>; <xref ref-type="bibr" rid="c46">Rockland 2002</xref>). Speed-selective complex cells in V1 have preferred speeds in a range similar to that of MT neurons, but the mean preferred speed is slower than MT (<xref ref-type="bibr" rid="c32">Mikami et al. 1986</xref>; <xref ref-type="bibr" rid="c36">Orban et al., 1986</xref>; <xref ref-type="bibr" rid="c42">Priebe et al., 2006</xref>). Normalization in V1 may contribute to the faster-speed bias at low speeds. The roles of neural processing in early visual areas on the faster-speed bias remain to be determined in future studies.</p>
</sec>
<sec id="s4c">
<title>Efficient coding and functional implication of faster-speed bias</title>
<p>We have shown that the faster-speed bias in MT response is a robust phenomenon regardless of whether the stimulus components move in the same or different directions. An efficient way to represent sensory information is to devote limited resources to better represent signals that occur more frequently in the natural environment (<xref ref-type="bibr" rid="c4">Attneave 1954</xref>; <xref ref-type="bibr" rid="c6">Barlow 1961</xref>; <xref ref-type="bibr" rid="c49">Simoncelli and Olshausen 2001</xref>). Previous studies have suggested that slow speeds are more likely to occur than fast speeds in natural scenes (<xref ref-type="bibr" rid="c54">Weiss et al., 2002</xref>; <xref ref-type="bibr" rid="c51">Stocker and Simoncelli, 2006</xref>; <xref ref-type="bibr" rid="c58">Zhang and Stocker, 2022</xref>). If neurons in the primate visual cortex are optimized to efficiently represent speeds that are more likely to occur in natural scenes, one may expect to find neurons showing a slower-speed bias rather than a faster-speed bias. However, besides maximizing information about the environment, neural representation in the sensory cortices may be optimized for other goals such as maximizing the performance of certain behavioral tasks (<xref ref-type="bibr" rid="c49">Simoncelli and Olshausen 2001</xref>; <xref ref-type="bibr" rid="c27">Manning et al., 2023</xref>). In the natural environment, it is common to encounter multiple motions occurring concurrently in a spatial region, due to object motions in the world coordinate and retinal image slip caused by the self-motion of the observer. If a figural object (e.g. a lion) tends to move faster than its background in natural scenes, a neural representation of multiple motions with a faster-speed bias would help to identify the figure, and therefore benefit the performance of an essential behavioral task – figure/ground segregation. To test this hypothesis, future study is needed to characterize natural scene statistics of speeds for figural objects and their background.</p>
</sec>
</sec>
<sec id="s5">
<title>Materials and methods</title>
<p>We conducted psychophysical experiments using human subjects, and psychophysical and neurophysiological experiments using macaque monkeys.</p>
<sec id="s5a">
<title>Human psychophysics</title>
<sec id="s5a1">
<title>Subjects</title>
<p>Four adult human subjects (<italic>CN, CO, IN, NP</italic>), two men and two women, with normal or corrected-to-normal visual acuity participated in the psychophysics experiments. Subject <italic>CN</italic> was naive about the purposes of the experiments. Subjects CO and IN had a general idea about this study but did not know the specific design of the experiments. Informed consent was obtained from the subjects. All aspects of the study were in accordance with the principles of the Declaration of Helsinki and were approved by the Institutional Review Board at the University of Wisconsin-Madison.</p>
</sec>
<sec id="s5a2">
<title>Apparatus</title>
<p>Visual stimuli were generated by a Linux workstation using an OpenGL application and displayed on a 19-inch CRT monitor. The monitor had a resolution of 1,024 × 768 pixels and a refresh rate of 100 Hz. The output of the video monitor was measured with a photometer (LS-110, Minolta) and was gamma-corrected. Stimulus presentation was controlled by a real-time data acquisition and stimulus control program “Maestro” (<ext-link ext-link-type="uri" xlink:href="https://sites.google.com/a/srscicomp.com/maestro/">https://sites.google.com/a/srscicomp.com/maestro/</ext-link>) as in the animal behavior and neurophysiology experiments. Subjects viewed the visual stimuli in a dark room with dim background illumination. The viewing distance was 58 cm. A chin rest and forehead support were used to restrict the head movements of the observers. During experimental trials, human subjects maintained fixation on a small spot within a 2 × 2° window. Eye positions were monitored using a video-based eye tracker (EyeLink, SR Research) at a rate of 1kHz.</p>
</sec>
<sec id="s5a3">
<title>Visual stimuli</title>
<p>Visual stimuli were two spatially overlapping random-dot patches presented within a square aperture 10° wide. Each square stimulus was centered 11° to the right of the fixation spot, therefore covering 6° to 16° eccentricity. This range roughly matched the RF eccentricity of the recorded MT neurons in our neurophysiological experiments. The random dots were achromatic. Each random dot was 3 pixels and had a luminance of 15.0 cd/m<sup>2</sup>. The background luminance was 0.03 cd/m<sup>2</sup>. The dot density of each random dot patch was 2 dots/degree<sup>2</sup>. The two random-dot patches translated horizontally in the same direction. To reduce adaptation, the motion direction was either leftward or rightward in half of the trials, and stimulus trials were randomly interleaved. In one set of trials, two overlapping random-dot patches had a “large speed separation” and the speed of the faster component was always four times (x4) that of the slower component. In another set of trials, visual stimuli had a “small speed separation” and the speed of the faster component was always twice (x2) that of the slower component (see <xref rid="fig1" ref-type="fig">Fig. 1B1, B2</xref>). For each bi-speed stimulus, there was a corresponding single-speed stimulus composed of two overlapping random-dot patches moving in the same direction at the same speed. The single speed was the natural logarithmic (log) mean speed of the bi-speed stimulus:<inline-formula><inline-graphic xlink:href="532456v2_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, in which <italic>Spd</italic><sub><italic>1</italic></sub> and <italic>Spd</italic><sub><italic>2</italic></sub> were the two component speeds. The motion coherence of each random-dot patch was always 100%.</p>
</sec>
<sec id="s5a4">
<title>Procedure</title>
<p>In a standard two-alternative-forced-choice (2AFC) task, subjects discriminated a bi-speed stimulus from the corresponding single log-mean speed stimulus. The bi-speed and single-speed stimuli were presented in two consecutive time intervals with a 500 ms gap in between, in random, balanced order. In each time interval, the visual stimulus appeared, remained stationary for 250 ms, and then moved for 500 ms. At the end of each trial, subjects reported which time interval contained a bi-speed stimulus by pressing one of two buttons (left or right) within a 1500-ms window. After the button press, the inter-trial interval was 1300 ms. Each block of trials contained 40 trials, i.e. 5 speed pairs × 2 speed separations × 2 temporal orders (the bi-speed stimulus appeared in the first or second time-interval) × 2 motion directions (visual stimuli moved either to the left or right). Each experimental session typically contained 5 blocks, i.e. 200 trials.</p>
<p>Subjects also performed a 3AFC task. As in the 2AFC task, subjects discriminated a bi-speed stimuli from the corresponding single log-mean speed stimulus but had the option to make a third choice by pressing the middle button on trials when they thought neither stimulus interval appeared to contain two speeds (“no two-speeds” choice). When subjects thought one of the two stimulus intervals contained two speeds, subjects then pressed either the left or the right button to indicate which interval had two speeds.</p>
</sec>
<sec id="s5a5">
<title>Data analysis</title>
<p>The hit rate was calculated as the percentage of trials in which a subject correctly picked the bi-speed stimulus as having two speeds. The false alarm rate was calculated as the percentage of trials that a subject incorrectly picked the singe-speed stimulus as having two speeds. As a measure of discriminability between the bi-speed and the corresponding single-speed stimuli, we calculated the discriminability index <italic>d′</italic> = <italic>norminv</italic>(hit rate) – <italic>norminv(</italic>false alarm rate). <italic>norminv</italic> is a MATLAB function that calculates the inverse of the normal cumulative distribution function, with the mean and standard deviation set to 0 and 1, respectively. When the hit or false alarm rate was occasionally close to 1, to avoid infinite d’ values, d’ was calculated using a modified formula: <italic>d’</italic> = norminv{[(100 x hit rate)+1]/102} - norminv{[(100 x false alarm rate) +1]/102}. In analyzing the results of the 3AFC task, we incorporated the NTC trials into the <italic>d’</italic> calculation by evenly splitting the NTC trials into “hit” trials and “false alarm” trials. In this way, the NTC trials were still accounted for by the hit rate and false alarm rate, in the sense that they did not contribute to the discrimination. We also examined the percentage of trials in which subjects made the NTC choice at different stimulus speeds.</p>
</sec>
</sec>
<sec id="s5b">
<title>Neurophysiological and psychophysical experiments</title>
<sec id="s5b1">
<title>Subjects</title>
<p>Five male adult rhesus monkeys (<italic>Macaca mulatta</italic>) were used in the experiments. Four monkeys were used in the neurophysiological experiments, and one was used in the psychophysical experiment. Experimental protocols were approved by the local Institutional Animal Care and Use Committee and were in strict compliance with U.S. Department of Agriculture regulations and the National Institutes of Health <italic>Guide for the Care and Use of Laboratory Animals</italic>.</p>
</sec>
<sec id="s5b2">
<title>Apparatus and electrophysiological recording</title>
<p>Procedures for surgical preparation and electrophysiological recording were routine and similar to those described previously (<xref ref-type="bibr" rid="c22">Huang and Lisberger 2009</xref>; <xref ref-type="bibr" rid="c57">Xiao et al., 2014</xref>). For subjects IM and MO, horizontal and vertical eye positions were monitored using the search coil method at a sampling rate of 1kHz on each channel. For subjects RG, GE, and BJ, eye positions were monitored using a video-based eye tracker (EyeLink, SR Research) at a rate of 1kHz. For electrophysiological recordings, we lowered single-contact tungsten microelectrodes (Thomas Recording or FHC) either using the MiniMatrix microdrive (Thomas Recording) or the NAN drive (NAN Instruments) into the posterior bank of the superior temporal sulcus. The impedances of the electrodes were 1∼3 MΩ. We identified area MT by its characteristically large proportion of directionally selective neurons, small classical RFs relative to those in the neighboring medial superior temporal area, and location on the posterior bank of the superior temporal sulcus. Electrical signals were filtered, amplified, and digitized conventionally. Single units were identified with a real-time template-matching system (Plexon). Spikes were carefully sorted using Plexon offline sorter.</p>
<p>Stimulus presentation and the behavioral paradigm were controlled by a real-time data acquisition program Maestro as described in the human psychophysics experiment. For neurophysiological recordings from IM and MO, visual stimuli were presented on a 20-inch CRT monitor at a viewing distance of 38 cm. Monitor resolution was 1,280 × 1,024 pixels and the refresh rate was 85 Hz. For RG, GE, and BJ, visual stimuli were presented on a 25-inch CRT monitor at a viewing distance of 63 cm. Monitor resolution was 1,024 × 768 pixels and the refresh rate was 100 Hz. Visual stimuli were generated by a Linux workstation using an OpenGL application that communicated with the main experimental-control computer over a dedicated Ethernet link. The output of the video monitor was gamma-corrected.</p>
</sec>
<sec id="s5b3">
<title>Visual stimuli and experimental procedure of the main experiment</title>
<p>All visual stimuli were presented in individual trials while monkeys maintained fixation. Monkeys were required to maintain fixation within a 1.5 × 1.5° window centered around a fixation spot during each trial to receive juice rewards, although actual fixation was typically more accurate. In a trial, visual stimuli were illuminated after the animal had acquired fixation for 200 ms. To assist the isolation of directional-selective neurons in area MT, we used circular translation of a large random-dot patch (30 × 30°) as a search stimulus (<xref ref-type="bibr" rid="c48">Schoppmann and Hoffmann, 1976</xref>). After an MT neuron was isolated, we characterized the direction tuning by randomly interleaved trials of 30 × 30° random-dot patches moving at 10°/s in eight different directions from 0 to 315° at 45° steps. Next, we mapped the RF by recording responses to a series of 5 × 5° patches of random dots that moved in the preferred direction of the neuron at 10°/s. The location of the patch was varied randomly to tile the screen in 5° steps without overlap and to cover an area of either 40 × 30° or 35 × 25°. The raw map of the RF was interpolated using the Matlab function <italic>interp2</italic> at an interval of 0.5° and the location giving rise to the highest firing rate was taken as the center of the RF. In the following experiments, testing stimuli were centered on the RF.</p>
<p>Monkeys IM and MO were tested with the main visual stimuli used in our experiments, which were two spatially overlapping random-dot patches presented within a square aperture 10° wide. The random dots were achromatic. The dot density of each random-dot patch was 2 dots/deg<sup>2</sup>. Each random dot was 3 pixels at a side and had a luminance of 15.0 cd/m<sup>2</sup>. The background luminance was &lt; 0.2 cd/m<sup>2</sup>. In each trial, the random dots moved within the aperture. The two random-dot patches translated at two different speeds at 100% motion coherence and in the same direction (the preferred direction of the recorded neuron). The ratio between the two component speeds was fixed either at 4 (i.e. the large speed separation) or 2 (i.e. the small speed separation) (see Methods for human psychophysics above). At x4 speed separation, the five speed pairs used were 1.25 and 5°/s, 2.5 and 10°/s, 5 and 20°/s, 10 and 40°/s, and 20 and 80°/s (<xref rid="fig1" ref-type="fig">Fig. 1B1</xref>). At x2 speed separation, the speed pairs used were 1.25 and 2.5°/s, 2.5 and 5°/s, 5 and 10°/s, 10 and 20°/s, and 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1B2</xref>). Experimental trials of bi-speed stimuli that had x4 or x2 speed separations were randomly interleaved. Also randomly interleaved were trials that showed only a single random-dot patch moving at a speed of 1.25, 2.5, 5, 10, 20, 40, or 80°/s, which were the individual stimulus components of the bi-speed stimuli.</p>
<p>Monkeys RG and GE were tested with a variation of the main visual stimuli, in which two overlapping random-dot stimulus components moved at two fixed speeds of 2.5 and 10°/s, respectively, and in two different directions separated by 90°. The diameter of the stimulus aperture was 3°. The faster component moved at the clockwise side of the two component directions (illustrated in <xref rid="fig7" ref-type="fig">Figure 7</xref>). We varied the vector average direction of the two stimulus components across 360° in a step of 15° to characterize the direction-tuning curves of MT neurons. We also measured the direction-tuning curves to a single stimulus moving at the individual component speeds.</p>
</sec>
<sec id="s5b4">
<title>Behavioral paradigm and visual stimuli of attention control</title>
<p>Monkey RG was also tested in a control experiment in which the attention of the animal was directed away from the RFs of MT neurons. The attended stimulus was a random-dot patch moving in a single direction at 100% motion coherence within a stationary circular aperture that had a diameter of 5°. The stimulus patch was centered 10° to the left of the fixation spot, in the visual hemifield contralateral to the hemifield of the recorded MT neurons’ RFs. The monkey performed a fine direction-discrimination task to report whether the motion direction of the attended stimulus moved at the clockwise or counter-clockwise side of the vertical direction. While the animal fixated on a point at the center of the monitor, both the attended stimulus and the RF stimulus were turned on and remained stationary for 250 ms before they moved for 500 ms. The attended stimulus translated at a speed of 10°/s and in a direction either clockwise or counter-clockwise from an invisible vertical (upward) direction by an offset of 10°, 15°, or 20°. The RF stimuli were the same as our main visual stimuli, with either a single-speed or bi-speed stimulus moving in the same direction. All trials were randomly interleaved. After the motion period, all the visual stimuli were turned off, and two reporting targets appeared 10° eccentric on the left and right sides of the fixation point. To receive a juice reward, the animal was required to make a saccadic eye movement within 400 ms after the fixation spot was turned off, either to the left or right target when the motion direction of the attended stimulus was counter-clockwise or clockwise to the vertical direction, respectively.</p>
</sec>
<sec id="s5b5">
<title>Monkey psychophysics</title>
<p>Monkey BJ was trained to perform a 2AFC discrimination task. The visual stimuli were the same as our main visual stimuli in the neurophysiological experiments except that the stimulus moving at a single speed was also composed of two overlapping random-dot patches moving in the same direction at the same speed, the same as in the human psychophysics experiments. In this way, the single-speed stimulus and the bi-speed stimuli had the same dot density. Visual stimuli were random-dot patches moving within a square aperture of 10°x10°, centered 10° to the right of the fixation spot. The motion direction of the visual stimuli was always rightward. Experimental trials of bi-speed stimuli that had x4 or x2 speed separations, as well as the single-speed stimulus that moved at the log mean speed of the bi-speed stimuli were randomly interleaved. Visual stimuli were turned on and remained stationary for 250 ms before they moved for 500 ms. Following the stimulus offset, two reporting targets (dots) were presented 5.7° away from the fixation spot, at upper right (4°, 4°) and lower left (-4°, -4°) positions relative to the fixation spot. To receive a juice reward, the animal was required to make a saccadic eye movement to one of the two targets within 300 ms after the fixation spot was turned off. In a majority of the experiment trials, the animal received juice rewards if selecting the upper-right target when visual stimuli moved at two different speeds and selecting the lower-left target when visual stimuli moved at a single speed. Guided by our human psychophysics results, we made an exception to always reward the animal when the bi-speed stimuli moved at 20 and 80°/s or at 20 and 40°/s, regardless of which target was selected to avoid biasing the monkey’s choice by veridically rewarding the animal. This was because, at these fast speeds, human subjects could not segment the bi-speed stimuli. During training, the animal was never presented with the bi-speed stimuli of 20 and 80°/s, and 20 and 40°/s. During testing, the trials of 20 and 80°/s, and 20 and 40°/s were randomly interleaved with bi-speed and single-speed trials that were rewarded veridically to anchor the task rule. Among all testing trials, only 10% of the trials were rewarded with a 100% rate. We collected 50 trials of data for x4 speed separation across 5 experimental sessions, and 90 trials for x2 speed separation across 9 sessions during the testing phase. The hit rate, false alarm rate, and the <italic>d’</italic> were calculated in the same way as in the human psychophysics experiments.</p>
</sec>
<sec id="s5b6">
<title>Model fit of the tuning curves to bi-speed stimuli</title>
<p>We fitted the response tuning curves to the bi-speed stimuli using a few variants of a divisive normalization model (<xref rid="fig10" ref-type="fig">Fig. 10</xref>). We also used a weighted summation model to fit the direction tuning curves to overlapping stimuli moving in different directions and at different speeds (<xref rid="fig7" ref-type="fig">Fig. 7</xref>). These model fits were obtained using the constrained minimization tool “fmincon” (MATLAB) to minimize the sum of squared error. To evaluate the goodness of fit of models for the response tuning curves, we calculated the percentage of variance (PV) accounted for by the model as follows: <inline-formula><inline-graphic xlink:href="532456v2_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where SSE is the sum of squared errors between the model fit and the neuronal data, and SST is the sum of squared differences between the data and the mean of the data (Morgan et al., 2008).</p>
</sec>
<sec id="s5b7">
<title>Construction of population neural response</title>
<p>For each recorded MT neuron, we plotted the trial-averaged speed tuning curve in response to the single speed and spline-fitted the tuning curve using the Matlab function <italic>csaps</italic> with the smoothing parameter <italic>p</italic> set to 0.93. We found <italic>p</italic> = 0.93 best captured the trend of the speed tuning, without obvious overfitting. We then found the preferred speed (PS) of the neuron, which is the speed when the maximum firing rate was reached in the spline-fitted tuning curve. The neuron’s responses to all single-speed and bi-speed stimuli were normalized by the maximum firing rate at the PS. To construct the population neural response to a given stimulus, we took the normalized firing rate of each neuron elicited by that stimulus and plotted it against the PS of the neuron. Because the PSs of the neurons in our data sample did not cover the full speed range evenly, we spline-fitted (with a smoothing parameter of 0.93) the population neural response to capture the population neural response evenly across the full range of PS.</p>
</sec>
<sec id="s5b8">
<title>Discrimination of population neural responses using a classifier</title>
<p>We trained a linear classifier to discriminate constructed population neural response to a bi-speed stimuli and the corresponding single-speed stimulus moving at the log mean speed. Constructed trial-by-trial population responses were generated randomly according to a Poisson process with the mean set to the recorded neuronal response averaged across experimental trials. For each speed combination, we generated 200 trials of responses to the bi-speed stimuli and the corresponding single-speed stimulus, respectively. Constructed population responses were partitioned into training and testing sets using k-fold cross-validation (k = 40). The 200 generated trials were randomly divided into 40 folds. The classifier was trained on 39 data folds and tested on the remaining fold, and the process was repeated 40 times to ensure that each fold was used for testing exactly once. The Matlab <italic>fitclinear</italic> function was used to fit a linear classifier to the training data. The logistic learner and lasso regularization techniques were specified during the model training. The Stochastic Gradient Descent solver was used to optimize the objective function during the training of the classifier. The performance of the classifier was evaluated by <italic>d′</italic>, calculated using the hit rate and false alarm rate as described in human psychophysics.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgment</title>
<p>We thank Dr. Steven Lisberger for his support in the early phase of this project, Emily Ausloos and Jianbo Xiao for data collection in early human psychophysics experiments, Bryce Arseneau for animal training, Drs. Jennifer Coonen and Kevin Brunner at the Wisconsin National Primate Research Center for excellent veterinary care and surgical assistance, and Drs. Emily Cooper and Greg DeAngelis for valuable comments on the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Allman</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Miezin</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>McGuinness</surname>, <given-names>E.</given-names></string-name> (<year>1985</year>). <article-title>Direction- and velocity-specific responses from beyond the classical receptive field in the middle temporal visual area (MT)</article-title>. <source>Perception</source>, <volume>14</volume>(<issue>2</issue>), <fpage>105</fpage>–<lpage>126</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Anderson</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Binzegger</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>K. A.</given-names></string-name>, &amp; <string-name><surname>Rockland</surname>, <given-names>K. S.</given-names></string-name> (<year>1998</year>). <article-title>The connection from cortical area V1 to V5: a light and electron microscopic study</article-title>. <source>J Neurosci</source>, <volume>18</volume>(<issue>24</issue>), <fpage>10525</fpage>–<lpage>10540</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Anderson</surname>, <given-names>J. C.</given-names></string-name>, &amp; <string-name><surname>Martin</surname>, <given-names>K. A.</given-names></string-name> (<year>2002</year>). <article-title>Connection from cortical area V2 to MT in macaque monkey</article-title>. <source>J Comp Neurol</source>, <volume>443</volume>(<issue>1</issue>), <fpage>56</fpage>–<lpage>70</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Attneave</surname>, <given-names>F.</given-names></string-name> (<year>1954</year>). <article-title>Some informational aspects of visual perception</article-title>. <source>Psychol Rev</source>, <volume>61</volume>(<issue>3</issue>), <fpage>183</fpage>–<lpage>193</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Bao</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Tsao</surname>, <given-names>D. Y.</given-names></string-name> (<year>2018</year>). <article-title>Representation of multiple objects in macaque category-selective areas</article-title>. <source>Nat Commun</source>, <volume>9</volume>(<issue>1</issue>), <fpage>1774</fpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="book"><string-name><surname>Barlow</surname> <given-names>H. B.</given-names></string-name> (<year>1961</year>). <article-title>Possible principles underlying the transformations of sensory messages. Chapter 13</article-title>. In: <person-group person-group-type="editor"><string-name><given-names>W.</given-names> <surname>Rosenblith</surname></string-name></person-group> (Ed.), <source>Sensory communication</source> (pp. <fpage>217</fpage>–<lpage>234</lpage>). <publisher-name>M.I.T. Press</publisher-name>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Born</surname>, <given-names>R. T.</given-names></string-name>, &amp; <string-name><surname>Bradley</surname>, <given-names>D. C.</given-names></string-name> (<year>2005</year>). <article-title>Structure and function of visual area MT</article-title>. <source>Annu Rev Neurosci</source>, <volume>28</volume>, <fpage>157</fpage>–<lpage>189</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Born</surname>, <given-names>R. T.</given-names></string-name>, <string-name><surname>Groh</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Lukasewycz</surname>, <given-names>S. J.</given-names></string-name> (<year>2000</year>). <article-title>Segregation of object and background motion in visual area MT: effects of microstimulation on eye movements</article-title>. <source>Neuron</source>, <volume>26</volume>(<issue>3</issue>), <fpage>725</fpage>–<lpage>734</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Braddick</surname>, <given-names>O.</given-names></string-name> (<year>1993</year>). <article-title>Segmentation versus integration in visual motion processing</article-title>. <source>Trends Neurosci</source>, <volume>16</volume>(<issue>7</issue>), <fpage>263</fpage>–<lpage>268</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Braddick</surname>, <given-names>O.</given-names></string-name> (<year>1997</year>). <article-title>Local and global representations of velocity: transparency, opponency, and global direction perception</article-title>. <source>Perception</source>, <volume>26</volume>(<issue>8</issue>), <fpage>995</fpage>–<lpage>1010</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Braddick</surname>, <given-names>O. J.</given-names></string-name>, <string-name><surname>Wishart</surname>, <given-names>K. A.</given-names></string-name>, &amp; <string-name><surname>Curran</surname>, <given-names>W.</given-names></string-name> (<year>2002</year>). <article-title>Directional performance in motion transparency</article-title>. <source>Vision Res</source>, <volume>42</volume>(<issue>10</issue>), <fpage>1237</fpage>–<lpage>1248</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Britten</surname>, <given-names>K. H.</given-names></string-name>, &amp; <string-name><surname>Heuer</surname>, <given-names>H. W.</given-names></string-name> (<year>1999</year>). <article-title>Spatial summation in the receptive fields of MT neurons</article-title>. <source>J Neurosci</source>. <volume>19</volume>, <fpage>5074</fpage>–<lpage>5084</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="book"><string-name><surname>Britten</surname>, <given-names>K. H.</given-names></string-name> (<year>2003</year>). <article-title>The middle temporal area: motion processing and the link to perception</article-title>. In <person-group person-group-type="editor"><string-name><given-names>J. W.</given-names> <surname>LM Chalupa</surname></string-name></person-group> (Ed.), <source>The visual neurosciences</source> (pp. <fpage>1203</fpage>-<lpage>1216</lpage>). <publisher-name>The MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Busse</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Wade</surname>, <given-names>A. R.</given-names></string-name>, &amp; <string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name> (<year>2009</year>). <article-title>Representation of concurrent stimuli by population activity in visual cortex</article-title>. <source>Neuron</source>, <volume>64</volume>(<issue>6</issue>), <fpage>931</fpage>–<lpage>942</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name> (<year>2012</year>). <article-title>Normalization as a canonical neural computation</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>13</volume>(<issue>1</issue>), <fpage>51</fpage>–<lpage>62</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Carandini</surname>. <given-names>M.</given-names></string-name>, <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name> (<year>1997</year>). <article-title>Linearity and normalization in simple cells of the macaque primary visual cortex</article-title>. <source>J Neurosci</source>. <volume>17</volume>, <fpage>8621</fpage>–<lpage>8644</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Heuer</surname>, <given-names>H. W.</given-names></string-name>, &amp; <string-name><surname>Britten</surname>, <given-names>K. H.</given-names></string-name> (<year>2002</year>). <article-title>Contrast dependence of response normalization in area MT of the rhesus macaque</article-title>. <source>J Neurophysiol</source>, <volume>88</volume>(<issue>6</issue>), <fpage>3398</fpage>–<lpage>3408</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name>, &amp; <string-name><surname>Stoner</surname>, <given-names>G. R.</given-names></string-name> (<year>2007</year>). <article-title>Adaptive surround modulation in cortical area MT</article-title>. <source>Neuron</source>, <volume>53</volume>(<issue>5</issue>), <fpage>761</fpage>–<lpage>770</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name>, &amp; <string-name><surname>Stoner</surname>, <given-names>G. R.</given-names></string-name> (<year>2008</year>). <article-title>Stimulus dependency and mechanisms of surround modulation in cortical area MT</article-title>. <source>J Neurosci</source>, <volume>28</volume>(<issue>51</issue>), <fpage>13889</fpage>–<lpage>13906</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="preprint"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Ghimire</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Chakrala</surname>, <given-names>A. S.</given-names></string-name>, &amp; <string-name><surname>Wiesner</surname>, <given-names>S.</given-names></string-name> (<year>2023</year>). <article-title>Neural coding of multiple motion speeds in visual cortical area MT</article-title>. <source>BioRxiv</source>. doi: <pub-id pub-id-type="doi">10.1101/2023.04.08.532456</pub-id>. 10.10.1101/2023.04.08.532456v1.full</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Huang</surname> <given-names>W.</given-names></string-name>, <string-name><surname>Huang</surname> <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Zhang</surname> <given-names>K.</given-names></string-name> (<year>2017</year>). <article-title>Information-theoretic interpretation of tuning curves for multiple motion directions</article-title>. <source>51st Annual Conference on Information Sciences and Systems (CISS), Baltimore, MD, USA</source>, pp. <fpage>1</fpage>–<lpage>4</lpage>, doi: <pub-id pub-id-type="doi">10.1109/CISS.2017.7926142</pub-id>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name> (<year>2009</year>). <article-title>Noise correlations in cortical area MT and their potential impact on trial-by-trial variation in the direction and speed of smooth-pursuit eye movements</article-title>. <source>J Neurophysiol</source>, <volume>101</volume>(<issue>6</issue>), <fpage>3012</fpage>–<lpage>3030</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Krekelberg</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>van Wezel</surname>, <given-names>R. J.</given-names></string-name> (<year>2013</year>). <article-title>Neural mechanisms of speed perception: transparent motion</article-title>. <source>J Neurophysiol</source>, <volume>110</volume>(<issue>9</issue>), <fpage>2007</fpage>–<lpage>2018</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Krekelberg</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>van Wezel</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name> (<year>2006a</year>). <article-title>Adaptation in macaque MT reduces perceived speed and improves speed discrimination</article-title>. <source>J Neurophysiol</source>, <volume>95</volume>(<issue>1</issue>), <fpage>255</fpage>–<lpage>270</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name> (<year>1999</year>). <article-title>Visual motion analysis for pursuit eye movements in area MT of macaque monkeys</article-title>. <source>J Neurosci</source>, <volume>19</volume>(<issue>6</issue>), <fpage>2224</fpage>–<lpage>2246</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Liu</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name> (<year>2003</year>). <article-title>Functional organization of speed tuned neurons in visual area MT</article-title>. <source>J Neurophysiol</source>, <volume>89</volume>(<issue>1</issue>), <fpage>246</fpage>–<lpage>256</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="preprint"><string-name><surname>Manning</surname>, <given-names>T.S.</given-names></string-name>, <string-name><surname>Alexander</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Cumming</surname>, <given-names>B. G.</given-names></string-name>, <string-name><surname>DeAngelis</surname>, <given-names>G. C.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Cooper</surname>, <given-names>E. A.</given-names></string-name> (<year>2023</year>). <article-title>Transformations of sensory information in the brain reflect a changing definition of optimality</article-title>. <source>BioRxiv</source>. doi: <pub-id pub-id-type="doi">10.1101/2023.03.24.534044</pub-id>. 10.10.1101/2023.03.24.534044v1.full</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Masson</surname>, <given-names>G. S.</given-names></string-name>, <string-name><surname>Mestre</surname>, <given-names>D. R.</given-names></string-name>, &amp; <string-name><surname>Stone</surname>, <given-names>L. S.</given-names></string-name> (<year>1999</year>). <article-title>Speed tuning of motion segmentation and discrimination</article-title>. <source>Vision Res</source>, <volume>39</volume>(<issue>26</issue>), <fpage>4297</fpage>–<lpage>4308</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name>, &amp; <string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name> (<year>1983</year>). <article-title>Functional properties of neurons in middle temporal visual area of the macaque monkey. I. Selectivity for stimulus direction, speed, and orientation</article-title>. <source>J Neurophysiol</source>, <volume>49</volume>(<issue>5</issue>), <fpage>1127</fpage>–<lpage>1147</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>McDonald</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Clifford</surname>, <given-names>C. W.</given-names></string-name>, <string-name><surname>Solomon</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>S. C.</given-names></string-name>, &amp; <string-name><surname>Solomon</surname>, <given-names>S. G.</given-names></string-name> (<year>2014</year>). <article-title>Integration and segregation of multiple motion signals by neurons in area MT of primate</article-title>. <source>J Neurophysiol</source>, <volume>111</volume>(<issue>2</issue>), <fpage>369</fpage>–<lpage>378</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Mestre</surname>, <given-names>D. R.</given-names></string-name>, <string-name><surname>Masson</surname>, <given-names>G. S.</given-names></string-name>, &amp; <string-name><surname>Stone</surname>, <given-names>L. S.</given-names></string-name> (<year>2001</year>). <article-title>Spatial scale of motion segmentation from speed cues</article-title>. <source>Vision Res</source>, <volume>41</volume>(<issue>21</issue>), <fpage>2697</fpage>–<lpage>2713</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Mikami</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name>, &amp; <string-name><surname>Wurtz</surname>, <given-names>R. H.</given-names></string-name> (<year>1986</year>). <article-title>Motion selectivity in macaque visual cortex. I. Mechanisms of direction and speed selectivity in extrastriate area MT</article-title>. <source>J Neurophysiol</source>, <volume>55</volume>(<issue>6</issue>), <fpage>1308</fpage>–<lpage>1327</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name> (<year>1996</year>). <article-title>Visual response properties of striate cortical neurons projecting to area MT in macaque monkeys</article-title>. <source>J Neurosci</source>, <volume>16</volume>(<issue>23</issue>), <fpage>7733</fpage>–<lpage>7741</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Ni</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Ray</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name> (<year>2012</year>). <article-title>Tuned normalization explains the size of attention modulations</article-title>. <source>Neuron</source>, <volume>73</volume>(<issue>4</issue>), <fpage>803</fpage>–<lpage>813</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Nover</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Anderson</surname>, <given-names>C. H.</given-names></string-name>, &amp; <string-name><surname>DeAngelis</surname>, <given-names>G. C.</given-names></string-name> (<year>2005</year>). <article-title>A logarithmic, scale-invariant representation of speed in macaque middle temporal area accounts for speed discrimination performance</article-title>. <source>J Neurosci</source>, <volume>25</volume>(<issue>43</issue>), <fpage>10049</fpage>–<lpage>10060</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Orban</surname>, <given-names>G. A.</given-names></string-name>, <string-name><surname>Kennedy</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Bullier</surname>, <given-names>J.</given-names></string-name> (<year>1986</year>). <article-title>Velocity sensitivity and direction selectivity of neurons in areas V1 and V2 of the monkey: influence of eccentricity</article-title>. <source>J Neurophysiol</source>, <volume>56</volume>(<issue>2</issue>), <fpage>462</fpage>–<lpage>480</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Orhan</surname>, <given-names>A. E.</given-names></string-name>, &amp; <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name> (<year>2015</year>). <article-title>Neural population coding of multiple stimuli</article-title>. <source>J Neurosci</source>. <volume>35</volume>, <fpage>3825</fpage>–<lpage>3841</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Pack</surname>, <given-names>C. C.</given-names></string-name>, <string-name><surname>Hunter</surname>, <given-names>J. N.</given-names></string-name>, &amp; <string-name><surname>Born</surname>, <given-names>R. T.</given-names></string-name> (<year>2005</year>). <article-title>Contrast dependence of suppressive influences in cortical area MT of alert macaque</article-title>. <source>J Neurophysiol</source>, <volume>93</volume>(<issue>3</issue>), <fpage>1809</fpage>–<lpage>1815</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Pasternak</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Tadin</surname>, <given-names>D.</given-names></string-name> (<year>2020</year>). <article-title>Linking Neuronal Direction Selectivity to Perceptual Decisions About Visual Motion</article-title>. <source>Annu Rev Vis Sci</source>, <volume>6</volume>, <fpage>335</fpage>–<lpage>362</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Perrone</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Thiele</surname>, <given-names>A.</given-names></string-name> (<year>2001</year>). <article-title>Speed skills: measuring the visual speed analyzing properties of primate MT neurons</article-title>. <source>Nat Neurosci</source>, <volume>4</volume>(<issue>5</issue>), <fpage>526</fpage>–<lpage>532</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Priebe</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Cassanello</surname>, <given-names>C. R.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name> (<year>2003</year>). <article-title>The neural representation of speed in macaque area MT/V5</article-title>. <source>J Neurosci</source>, <volume>23</volume>(<issue>13</issue>), <fpage>5650</fpage>–<lpage>5661</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Priebe</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name> (<year>2006</year>). <article-title>Tuning for spatiotemporal frequency and speed in directionally selective neurons of macaque striate cortex</article-title>. <source>J Neurosci</source>, <volume>26</volume>(<issue>11</issue>), <fpage>2941</fpage>–<lpage>2950</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Qian</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Andersen</surname>, <given-names>R. A.</given-names></string-name> (<year>1994</year>). <article-title>Transparent motion perception as detection of unbalanced motion signals. II. Physiology</article-title>. <source>J Neurosci</source>, <volume>14</volume>(<issue>12</issue>), <fpage>7367</fpage>–<lpage>7380</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Riesenhuber</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Poggio</surname>, <given-names>T.</given-names></string-name> (<year>1999</year>). <article-title>Hierarchical models of object recognition in cortex</article-title>. <source>Nat Neurosci</source>, <volume>2</volume>(<issue>11</issue>), <fpage>1019</fpage>–<lpage>1025</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Rocchi</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Ledgeway</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Webb</surname>, <given-names>B.</given-names></string-name> (<year>2018</year>). <article-title>Criterion-free measurement of motion transparency perception at different speeds</article-title>. <source>Journal of Vision</source> <volume>18</volume>(<issue>4</issue>).</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Rockland</surname>, <given-names>K. S.</given-names></string-name> (<year>2002</year>). <article-title>Visual cortical organization at the single axon level: a beginning</article-title>. <source>Neurosci Res</source>, <volume>42</volume>(<issue>3</issue>), <fpage>155</fpage>–<lpage>166</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Rust</surname>, <given-names>N. C.</given-names></string-name>, <string-name><surname>Mante</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name> (<year>2006</year>). <article-title>How MT cells analyze the motion of visual patterns</article-title>. <source>Nature Neuroscience</source>, <volume>9</volume>(<issue>11</issue>), <fpage>1421</fpage>–<lpage>1431</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Schoppmann</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Hoffmann</surname>, <given-names>K. P.</given-names></string-name> (<year>1976</year>). <article-title>Continuous mapping of direction selectivity in the cat’s visual cortex</article-title>. <source>Neurosci Lett</source>, <volume>2</volume>(<issue>4</issue>), <fpage>177</fpage>–<lpage>181</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, &amp; <string-name><surname>Olshausen</surname>, <given-names>B. A.</given-names></string-name> (<year>2001</year>). <article-title>Natural image statistics and neural representation</article-title>. <source>Annu Rev Neurosci</source>, <volume>24</volume>, <fpage>1193</fpage>–<lpage>1216</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Snowden</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Erickson</surname>, <given-names>R. G.</given-names></string-name>, &amp; <string-name><surname>Andersen</surname>, <given-names>R. A.</given-names></string-name> (<year>1991</year>). <article-title>The response of area MT and V1 neurons to transparent motion</article-title>. <source>J Neurosci</source>, <volume>11</volume>(<issue>9</issue>), <fpage>2768</fpage>–<lpage>2785</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Stocker</surname>, <given-names>A. A.</given-names></string-name>, &amp; <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name> (<year>2006</year>). <article-title>Noise characteristics and prior expectations in human visual speed perception</article-title>. <source>Nat Neurosci</source>, <volume>9</volume>(<issue>4</issue>), <fpage>578</fpage>–<lpage>585</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Stoner</surname>, <given-names>G. R.</given-names></string-name>, &amp; <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name> (<year>1992</year>). <article-title>Neural correlates of perceptual motion coherence</article-title>. <source>Nature</source>, <volume>358</volume>(<issue>6385</issue>), <fpage>412</fpage>–<lpage>414</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Ungerleider</surname>, <given-names>L. G.</given-names></string-name>, &amp; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> (<year>1986</year>). <article-title>Cortical connections of visual area MT in the macaque</article-title>. <source>J Comp Neurol</source>, <volume>248</volume>(<issue>2</issue>), <fpage>190</fpage>–<lpage>222</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Weiss</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, &amp; <string-name><surname>Adelson</surname>, <given-names>E. H.</given-names></string-name> (<year>2002</year>). <article-title>Motion illusions as optimal percepts</article-title>. <source>Nat Neurosci</source>, <volume>5</volume>(<issue>6</issue>), <fpage>598</fpage>–<lpage>604</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Wiesner</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Baumgart</surname>, <given-names>I. W.</given-names></string-name>, &amp; <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name> (<year>2020</year>). <article-title>Spatial Arrangement Drastically Changes the Neural Representation of Multiple Visual Stimuli That Compete in More Than One Feature Domain</article-title>. <source>J Neurosci</source>, <volume>40</volume>(<issue>9</issue>), <fpage>1834</fpage>–<lpage>1848</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Xiao</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name> (<year>2015</year>). <article-title>Distributed and Dynamic Neural Encoding of Multiple Motion Directions of Transparently Moving Stimuli in Cortical Area MT</article-title>. <source>J Neurosci</source>, <volume>35</volume>(<issue>49</issue>), <fpage>16180</fpage>–<lpage>16198</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Xiao</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Niu</surname>, <given-names>Y. Q.</given-names></string-name>, <string-name><surname>Wiesner</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name> (<year>2014</year>). <article-title>Normalization of neuronal responses in cortical area MT across signal strengths and motion directions</article-title>. <source>J Neurophysiol</source>, <volume>112</volume>(<issue>6</issue>), <fpage>1291</fpage>–<lpage>1306</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname>, <given-names>L. Q.</given-names></string-name>, &amp; <string-name><surname>Stocker</surname>, <given-names>A. A.</given-names></string-name> (<year>2022</year>). <article-title>Prior Expectations in Visual Speed Perception Predict Encoding Characteristics of Neurons in Area MT</article-title>. <source>J Neurosci</source>, <volume>42</volume>(<issue>14</issue>), <fpage>2951</fpage>–<lpage>2962</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Groh</surname>
<given-names>Jennifer M</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Duke University</institution>
</institution-wrap>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study concerns how macaque visual cortical area MT represents stimuli composed of more than one speed of motion. The study is <bold>valuable</bold> because little is known about how the visual pathway segments and preserves information about multiple stimuli, and the study involves perceptual reports from both humans and one monkey regarding whether there are one or two speeds in the stimulus. The study presents <bold>compelling</bold> evidence that (on average) MT neurons represent the average of the two speeds, with a bias that accentuates the faster of the two speeds. Ultimately, this study raises intriguing questions about how exactly the response patterns in visual cortical area MT might preserve information about each speed, since such information could potentially be lost in an average response as described here, depending on assumptions about how MT activity is evaluated by other visual areas.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Most studies in sensory neuroscience investigate how individual sensory stimuli are represented in the brain (e.g., the motion or color of a single object). This study starts tackling the more difficult question of how the brain represents multiple stimuli simultaneously and how these representations help to segregate objects from cluttered scenes with overlapping objects.</p>
<p>Strengths</p>
<p>The authors first document the ability of humans to segregate two motion patterns based on differences in speed. Then they show that a monkey's performance is largely similar; thus establishing the monkey as a good model to study the underlying neural representations.</p>
<p>Careful quantification of the neural responses in the middle temporal area during the simultaneous presentation of fast and slow speeds leads to the surprising finding that, at low average speeds, many neurons respond as if the slowest speed is not present, while they show averaged responses at high speeds. This unexpected complexity of the integration of multiple stimuli is key to the model developed in this paper.</p>
<p>One experiment in which attention is drawn away from the receptive field supports the claim that this is not due to the involuntary capture of attention by fast speeds.</p>
<p>A classifier using the neuronal response and trained to distinguish single-speed from bi-speed stimuli shows a similar overall performance and dependence on the mean speed as the monkey. This supports the claim that these neurons may indeed underlie the animal's decision process.</p>
<p>The authors expand the well-established divisive normalization model to capture the responses to bi-speed stimuli. The incremental modeling (eq 9 and 10) clarifies which aspects of the tuning curves are captured by the parameters.</p>
<p>Weaknesses</p>
<p>While the comparison of the overall pattern of behavioral performance between monkeys and humans is important, some of the detailed comparisons are not well supported by the data. For instance, whether the monkey used the apparent coherence simply wasn't tested and a difference between 4 human subjects and a single monkey subject cannot be tested statistically in a meaningful manner. I recommend removing these observations from the manuscript and leaving it at &quot;The difference between the monkey and human results may be due to species differences or individual variability&quot; (and potentially add that there are differences in the task as well; the monkey received feedback on the correctness of their choice, while the humans did not.)</p>
<p>A control experiment aims to show that the &quot;fastest speed takes all&quot; behavior is general by presenting two stimuli that move at fast/slow speeds in orthogonal directions. The claim that these responses also show the &quot;fastest speed takes all&quot; is not well supported by the data. In fact, for directions in which the slow speed leads to the largest response on its own, the population response to the bi-speed stimulus is the average of the response to the components. Only for the directions where the fast speed stimulus is the preferred direction is there a bias towards the faster speed (Figure 7A). The quantification of this effect in Figure 7B seems to suggest otherwise, but I suspect that this is driven by the larger amplitude of Rf in Figure 8, and the constraint that ws and wf are constant across directions. The interpretation of this experiment needs to be reconsidered.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This is a paper about the segmentation of visual stimuli based on speed cues. The experimental stimuli are random dot fields in which each dot moves at one of two velocities. By varying the difference between the two speeds, as well as the mean of the two speeds, the authors estimate the capacity of observers (human and non-human primates) to segment overlapping motion stimuli. Consistent with previous work, perceptual segmentation ability depends on the mean of the two speeds. Recordings from area MT in monkeys show that the neuronal population to compound stimuli often shows a bias towards the faster-speed stimuli. This bias can be accounted for with a computational model that modulates single-neuron firing rates by the speed preferences of the population. The authors also test the capacity of a linear classifier to produce the psychophysical results from the MT data.</p>
<p>Strengths:</p>
<p>Overall, this is a thorough treatment of the question of visual segmentation with speed cues. Previous work has mostly focused on other kinds of cues (direction, disparity, color), so the neurophysiological results are novel. The connection between MT activity and perceptual segmentation is potentially interesting, particularly as it relates to existing hypotheses about population coding.</p>
<p>Weaknesses:</p>
<p>Page 10: The relationship between (R-Rs) and (Rf-Rs) is described as &quot;remarkably linear&quot;. I don't actually find this surprising, as the same term (Rs) appears on both the x- and y-axes. The R^2 values are a bit misleading for this reason.</p>
<p>Figure 9: I'm confused about the linear classifier section of the paper. The idea makes sense - the goal is to relate the neuronal recordings to the psychophysical data. However the results generally provide a poor quantitative match to the psychophysical data. There is mention of a &quot;different paper&quot; (page 26) involving a separate decoding study, as well as a preprint by Huang et al. (2023) that has better decoding results. But the Huang et al. preprint appears to be identical to the current manuscript, in that neither has a Figure 12, 13, or 14. The text also says (page 26) that the current paper is not really a decoding study, but the linear classifier (Figure 9F) is a decoder, as noted on page 10. It sounds like something got mixed up in the production of two or more papers from the same dataset. In any case, I think that some kind of decoding analysis would really strengthen the current paper by linking the physiology to the psychophysics, but given the limitations of the linear classifier, a more sophisticated approach might be necessary -- see for example Zemel, Dayan, and Pouget, 1998. The authors might also want to check out closely related work by Treue et al. (Nature Neuroscience 2000) and Watamaniuk and Duchon (1992).</p>
<p>What do we learn from the normalization model? Its formulation is mostly a restatement of the results - that the faster and slower speeds differentially affect the combined response. This hypothesis is stated quantitatively in equation 8, which seems to provide a perfectly adequate account of the data. The normalization model in equation 10 is effectively the same hypothesis, with the mean population response interposed - it's not clear how much the actual tuning curve in Figure 10A even matters, since the main effect of the model is to flatten it out by averaging the functions in Figure 10B. Although the fit to the data is reasonable, the model uses 4 parameters to fit 5 data points and is likely underconstrained; the parameters other than alpha should at least be reported, as it would seem that sigma is actually the most important one. And I think it would help to examine how robust the statistical results are to different assumptions about the normalization pool.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This study concerns how macaque visual cortical area MT represents stimuli composed of more than one speed of motion.</p>
<p>Strengths:</p>
<p>The study is valuable because little is known about how the visual pathway segments and preserves information about multiple stimuli. The study presents compelling evidence that (on average) MT neurons represent the average of the two speeds, with a bias that accentuates the faster of the two speeds. An additional strength of the study is the inclusion of perceptual reports from both humans and one monkey participant performing a task in which they judged whether the stimuli involved one vs two different speeds. Ultimately, this study raises intriguing questions about how exactly the response patterns in visual cortical area MT might preserve information about each speed, since such information could potentially be lost in an average response as described here, depending on assumptions about how MT activity is evaluated by other visual areas.</p>
<p>Weaknesses:</p>
<p>My main concern is that the authors are missing an opportunity to make clear that the divisive normalization, while commonly used to describe neural response patterns in visual areas (and which fits the data here), fails on the theoretical front as an explanation for how information about multiple stimuli can be preserved. Thus, there is a bit of a disconnect between the goal of the paper - how does MT represent multiple stimuli? - and the results: mostly averaging responses which, while consistent with divisive normalization, would seem to correspond to the perception of a single intermediate speed. This is in contrast to the psychophysical results which show that subjects can at least distinguish one from two speeds. The paper would be strengthened by grappling with this conundrum in a head-on manner.</p>
</body>
</sub-article>
</article>