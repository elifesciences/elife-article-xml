<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">103001</article-id>
<article-id pub-id-type="doi">10.7554/eLife.103001</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.103001.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Change point estimation by the mouse medial frontal cortex during probabilistic reward learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Murphy</surname>
<given-names>Cayla E</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wang</surname>
<given-names>Hongli</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ortega</surname>
<given-names>Heather K</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2169-1667</contrib-id>
<name>
<surname>Kwan</surname>
<given-names>Alex C</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8582-4815</contrib-id>
<name>
<surname>Atilgan</surname>
<given-names>Huriye</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a6">6</xref>
<email>huriye.atilgan@dpag.ox.ac.uk</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Psychiatry, Yale University School of Medicine</institution></institution-wrap>, <city>New Haven</city>, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Interdepartmental Neuroscience Program, Yale University School of Medicine</institution></institution-wrap>, <city>New Haven</city>, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Neuroscience, Yale University School of Medicine</institution></institution-wrap>, <city>New Haven</city>, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05bnh6r87</institution-id><institution>Meinig School of Biomedical Engineering, Cornell University</institution></institution-wrap>, <city>Ithaca</city>, <country>USA</country></aff>
<aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02r109517</institution-id><institution>Department of Psychiatry, Weill Cornell Medicine</institution></institution-wrap>, <city>New York</city>, <country>USA</country></aff>
<aff id="a6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>Department of Physiology, Anatomy and Genetics, University of Oxford</institution></institution-wrap>, <city>Oxford</city>, <country>UK</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Erlich</surname>
<given-names>Jeffrey</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Sainsbury Wellcome Centre</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-12-17">
<day>17</day>
<month>12</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP103001</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-09-06">
<day>06</day>
<month>09</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-12-13">
<day>13</day>
<month>12</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.05.26.493245"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Murphy et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Murphy et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-103001-v1.pdf"/>
<abstract>
<title>Summary</title>
<p>There are often sudden changes in the state of environment. For a decision maker, accurate prediction and detection of change points are crucial for optimizing performance. Still unclear, however, is whether rodents are simply reactive to reinforcements, or if they can be proactive to estimate future change points during value-based decision making. In this study, we characterize head-fixed mice performing a two-armed bandit task with probabilistic reward reversals. Choice behavior deviates from classic reinforcement learning, but instead suggests a strategy involving belief updating, consistent with the anticipation of change points to exploit the task structure. Excitotoxic lesion and optogenetic inactivation implicate the anterior cingulate and premotor regions of medial frontal cortex. Specifically, over-estimation of hazard rate arises from imbalance across frontal hemispheres during the time window before the choice is made. Collectively, the results demonstrate that mice can capitalize on their knowledge of task regularities, and this estimation of future changes in the environment may be a main computational function of the rodent dorsal medial frontal cortex.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The author list and acknowledgment are updated</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>In life, we experience twists and turns – discrete events that abruptly alter the state of environment. In some cases, the change is a one-time occurrence that is impossible to predict. We must then adjust by assessing the new situation following the change. However, in other cases, the changes may occur repeatedly with certain tendencies. For example, a favorite chef in a restaurant may have a recurring schedule where she cooks throughout the year, except in the summer for 3 – 5 weeks when she would take a vacation and lets a substitute take over. As a patron, it would be advantageous to learn this pattern, anticipate the impending switches, and maximize the chance of receiving a delicious outcome. While it is evident that humans can estimate change points and leverage the information in decision-making, whether animals such as mice have this ability and the neural substrates supporting the computations remain unclear.</p>
<p>A classic paradigm to study decision-making in response to repeated changes is the two-armed bandit task. Each trial, the animal has two options, and each option is associated probabilistically with a reward. After a certain number of trials, the reward probabilities are switched among the options. The two-armed bandit task is widely used because it can be tested in different species including humans (<xref ref-type="bibr" rid="c11">Evers et al., 2005</xref>; <xref ref-type="bibr" rid="c27">O’Doherty et al., 2001</xref>; <xref ref-type="bibr" rid="c41">Tsuchida et al., 2010</xref>), monkeys (<xref ref-type="bibr" rid="c8">Clarke et al., 2008</xref>; <xref ref-type="bibr" rid="c9">Costa et al., 2015</xref>; <xref ref-type="bibr" rid="c10">Donahue and Lee, 2015</xref>; <xref ref-type="bibr" rid="c31">Samejima et al., 2005</xref>), rats (<xref ref-type="bibr" rid="c13">Groman et al., 2019</xref>; <xref ref-type="bibr" rid="c17">Hamid et al., 2016</xref>; <xref ref-type="bibr" rid="c19">Ito and Doya, 2009</xref>; <xref ref-type="bibr" rid="c37">Sul et al., 2011</xref>; <xref ref-type="bibr" rid="c38">Sul et al., 2010</xref>), and mice (<xref ref-type="bibr" rid="c2">Bari et al., 2019</xref>; <xref ref-type="bibr" rid="c15">Grossman et al., 2022</xref>; <xref ref-type="bibr" rid="c18">Hattori et al., 2019</xref>; <xref ref-type="bibr" rid="c40">Tai et al., 2012</xref>). Moreover, the paradigm has translational significance because it can reveal defects from pharmacological interventions (<xref ref-type="bibr" rid="c9">Costa et al., 2015</xref>) or in animal models for psychiatric disorders (<xref ref-type="bibr" rid="c14">Groman et al., 2018</xref>; <xref ref-type="bibr" rid="c25">Liao and Kwan, 2021</xref>; <xref ref-type="bibr" rid="c44">Villiamma et al., 2022</xref>).</p>
<p>Most analyses of rodents performing two-armed bandit and related decision-making tasks have relied on simple reinforcement learning schemes such as Q-learning algorithms (<xref ref-type="bibr" rid="c2">Bari et al., 2019</xref>; <xref ref-type="bibr" rid="c13">Groman et al., 2019</xref>; <xref ref-type="bibr" rid="c18">Hattori et al., 2019</xref>; <xref ref-type="bibr" rid="c19">Ito and Doya, 2009</xref>; <xref ref-type="bibr" rid="c38">Sul et al., 2010</xref>; <xref ref-type="bibr" rid="c45">Wang et al., 2022</xref>), with some exceptions (<xref ref-type="bibr" rid="c7">Beron et al., 2022</xref>; <xref ref-type="bibr" rid="c20">Ito and Doya, 2015</xref>). Q-learning algorithms assume that animals learn from experience, and therefore choice behavior adapts only after a change point has occurred. By contrast, recent studies in monkeys and humans have challenged this assumption.</p>
<p>Namely, primates can exploit predictable structure in a task and adjust for an impending change point (<xref ref-type="bibr" rid="c4">Bartolo and Averbeck, 2020</xref>; <xref ref-type="bibr" rid="c9">Costa et al., 2015</xref>; <xref ref-type="bibr" rid="c21">Jang et al., 2019</xref>; <xref ref-type="bibr" rid="c48">Woo et al., 2023</xref>). Indeed, under some situations, rodents also seem to make inferences about hidden states (<xref ref-type="bibr" rid="c26">Liu et al., 2021</xref>; <xref ref-type="bibr" rid="c35">Starkweather et al., 2017</xref>; <xref ref-type="bibr" rid="c36">Starkweather et al., 2018</xref>; <xref ref-type="bibr" rid="c43">Vertechi et al., 2020</xref>; <xref ref-type="bibr" rid="c48">Woo et al., 2023</xref>). These recent results hint at the possibility that mice may leverage their knowledge of task structure for probabilistic reward learning.</p>
<p>To test the possibility that rodents may estimate change points during probabilistic reward learning, we trained head-fixed mice on a two-armed bandit task. By analyzing a sizable data set totaling 1,007 sessions involving 15,352 reversals, we demonstrate that mice are sensitive to impending switches in reward probabilities, because they alter their choices prior to the actual change points. We show that the animals’ choice behavior can be modelled effectively with a Bayesian framework involving belief updating and choice kernels. Furthermore, we performed unilateral and bilateral excitotoxic lesions and optogenetic inactivation to demonstrate mechanistically how the anterior cingulate and premotor regions of medial frontal cortex may be involved in the computation. Together, the results indicate that mice can take advantage of the task structure to solve a classic probabilistic reward learning task and implicate the dorsal medial frontal cortex as a locus in the accurate estimation of future changes in the state of environment.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Mice use their knowledge of the task structure during a two-armed bandit task</title>
<p>We trained head-fixed C57BL/6J mice on a two-armed bandit task involving probabilistic reward reversals. On each trial, the mouse could choose left or right by a directional tongue lick. The two options were associated with different reward probabilities, e.g., “70:10” for 70% and 10% chance to receive water from the left and right spouts respectively (<xref rid="fig1" ref-type="fig">Figure 1A – B</xref>). The reward probabilities would flip when the animal reaches the switching condition, which is a performance-dependent number of trials to fulfill a criterion (L<sub>Criterion</sub>, 10 trials choosing the better option) followed by a performance-independent random number of trials (L<sub>Random</sub>, drawn from a geometric distribution with <italic>p</italic> = 0.0909 and truncated at 30). In an example session shown in <xref rid="fig1" ref-type="fig">Figure 1C</xref>, the animal performed more than 500 trials, including 15 reversals of 70:10 and 10:70 blocks. To visualize how animals adjust to the sudden changes in reward probabilities, we aligned the trials by the time of block switches. As expected, mice primarily chose the better option pre-switch, and then quickly adapted their preferred action post-switch (<xref rid="fig1" ref-type="fig">Figure 1D</xref>, n = 31 mice, 617 sessions, 9,163 blocks).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Mice were sensitive to block length and leverage this information during the two-armed bandit task</title>
<p><bold>(A)</bold> The mouse makes a left or right choice via tongue lick after the go cue. Depending on the reward probabilities, the choice might lead to water. <bold>(B)</bold> Trials were organized into blocks, each with distinct reward probabilities: “70:10” (70% chance to receive water for left choice; 10% for right) or “10:70” (10% for left; 70% for right). The block switches after the animal choose the high-reward-probability side ten times (L<sub>Criterion</sub>) plus an additional random number of trials (L<sub>Random</sub>, drawn from exponential distribution, up to 30 trials). <bold>(C)</bold> Performance of a mouse in one example session. The top row shows reward probabilities for left and right options. The bottom row shows the animal’s choices and the outcomes. <bold>(D)</bold> Choice behavior around block switches. Thin line, mean values for individual animal. Thick line, mean values and SEM for all animals. <bold>(E)</bold> Histogram of L<sub>Random.</sub> For all blocks with L<sub>Criterion</sub> ≤ 20. Colors indicate the 4 ranges of L<sub>Random</sub> for subsequent analyses. <bold>(F)</bold> Choice behavior around block switches, plotted separately for the 4 ranges of L<sub>Random</sub>. Mean values and SEM for all animals. <bold>(G)</bold> The probability of choosing the better option on the trial immediately preceding the switch, as a function of L<sub>Random</sub> for the block preceding the switch. Mean values and SEM for all animals. (H) The number of trials to reach midpoint (when animal is equally likely to choose either option) as a function of L<sub>Random</sub> for the block preceding the switch. Mean values and SEM for all animals. n = 31 mice, 617 sessions.</p></caption>
<graphic xlink:href="493245v3_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>An important parameter in our task is L<sub>Random</sub>, which dictates the frequency of reversals. Although the animals cannot know the exact value of L<sub>Random</sub> before each switch because it is drawn randomly, it is possible for the mice to learn the statistical distribution of L<sub>Random</sub>. This knowledge may then be used to infer that the more trials that an animal stays at the better option, the more likely that a block switch might have already occurred. To determine if mice were making use of such knowledge of the task structure, we analyzed the subset of 7,396 blocks (81% of the total of 9,163 blocks) in which animals were adapting quickly after block switches (achieving L<sub>Criterion</sub> in 20 or fewer trials), therefore focusing on expert-level performance and avoiding periods when animals may be unmotivated. <xref rid="fig1" ref-type="fig">Figure 1E</xref> shows the histogram of L<sub>Random</sub> values for these trial blocks, exhibiting the geometric distribution as the task was designed. We found that if L<sub>Random</sub> was large in the preceding block, the animals tended to choose the better option less frequently prior to the block switch, and subsequently adapted faster after the block switch (<xref rid="fig1" ref-type="fig">Figure 1F</xref>). The results were qualitatively similar if we included more or all blocks (<xref ref-type="fig" rid="figs1-1">Supplementary Figure 1.1</xref>). Moreover, in a smaller number of animals (n = 10 mice, 48 sessions, 312 blocks), we trained them on a variant of the task in which the switching condition is only determined by L<sub>Random</sub> (i.e., L<sub>Criteiron</sub> = 0), and the animals exhibited comparable tendency (<xref ref-type="fig" rid="figs1-2">Supplementary Figure 1.2</xref>). These results suggest that the mice may anticipate an impending change point and adjust their behavior prior to the block switch.</p>
<p>To quantify the observations, we computed <italic>P (better option) <sub>pre-switch</sub></italic>, the probability of selecting the better option in the trial immediately before the block switch, and <italic>trials to reach midpoint</italic>, the number of trials from switch for <italic>P (better option)</italic> to reach 0.5. These analyses confirmed the influence of L<sub>Random</sub> on choice patterns around a block switch (main effect of L<sub>Random</sub>: F (30, 5544) = 6.0743, <italic>P</italic> &lt; 0.001, one-way ANOVA; or if data were binned by 2: main effect of L<sub>Random</sub>: F (15, 5521) = 10.4589, <italic>P</italic> &lt; 0.001; one-way ANOVA; <xref rid="fig1" ref-type="fig">Figure 1G</xref>) and their speed to adjust after a block switch (main effect of L<sub>Random</sub>: F (30, 711) = 2.1316, <italic>P</italic> &lt; 0.001; or if data were binned by 2: main effect of L<sub>Random</sub>: F (15, 707) = 1.7407, <italic>P</italic> = 0.038; one-way ANOVA; <xref rid="fig1" ref-type="fig">Figure 1H</xref>). We reiterate that the animal could not predict the exact value of L<sub>Random</sub> for each block, which was drawn randomly. However, the tendencies around a block switch are consistent with animals learning the task structure, namely the distribution of possible values of L<sub>Random</sub>, presumably through repeated training over dozens of sessions on the two-armed bandit task. As the animal dwells in a block selecting the same better option for many trials, it becomes more probable that a change point in reward probabilities has occurred and therefore the animals should explore the alternate option more. Overall, these results demonstrate that mice were sensitive to the block length – a key feature of the task structure – and could leverage this information during the two-armed bandit task.</p>
</sec>
<sec id="s2b">
<title>Effects of unilateral lesion of ACAd/MOs on choice behavior around switches</title>
<p>Prior studies implicated the anterior cingulate cortex in behavioral flexibility in the face of variability in the environment (<xref ref-type="bibr" rid="c5">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c34">Soltani and Izquierdo, 2019</xref>). The related region in the mouse is the dorsal aspect of the medial frontal cortex, encompassing the anterior cingulate (ACAd) and medial secondary motor (MOs) areas (<xref ref-type="bibr" rid="c3">Barthas and Kwan, 2017</xref>; <xref ref-type="bibr" rid="c23">Laubach et al., 2018</xref>; <xref ref-type="bibr" rid="c49">Yang and Kwan, 2021</xref>). To determine the role of ACAd/MOs, we trained mice until they reached expert performance, and then performed unilateral excitotoxic lesion by injecting ibotenic acid into the ACAd/MOs region in the left or right hemisphere (n = 5 and 4 mice respectively, 200 pre-lesion and 142 post-lesion sessions in total; <xref rid="fig2" ref-type="fig">Figure 2A</xref>). For clarity, we will collapse the two groups and refer to trial blocks as ‘lesion’, if the lesioned side was the better option, or ‘contra’ if the side contralateral to the lesion was the better option (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). Post hoc histology with cresyl violet staining confirmed the loss of cell bodies at the targeted ACAd/MOs location (<xref rid="fig2" ref-type="fig">Figure 2C – D</xref>). After the lesion, animals performed a similar number of trials and block switches (<xref ref-type="fig" rid="figs2-1">Supplementary Figure 2.1</xref>) and had no motor deficit in licking (<xref ref-type="fig" rid="figs2-2">Supplementary Figure 2.2</xref>). Post-lesion mice exhibited block length-dependent choice patterns (<xref rid="fig2" ref-type="fig">Figure 2E</xref>). However, with the unilateral loss of ACAd/MOs, for the switch from lesion block to contra block, this tendency to choose the worse option pre-switch exacerbated with increasing L<sub>Random</sub> (left panel, <xref rid="fig2" ref-type="fig">Figure 2E</xref>). Summary of the data reaffirmed that animals with unilateral ACAd/MOs lesion were selecting the worse option at the expense of exploiting the better option pre-switch, specifically when L<sub>Random</sub> was large in the preceding block (main effect of lesion: <italic>P</italic> &lt; 0.001, main effect of L<sub>Random</sub>: <italic>P</italic> &lt; 0.001, lesion * L<sub>Random</sub> interaction: <italic>P</italic> = 0.044, three-way ANOVA; <xref rid="fig2" ref-type="fig">Figure 2F</xref>, <xref ref-type="table" rid="tbls2-1">Supplementary Table 2.1</xref>). Although they appeared to adapt faster after the switch relative to control animals (main effect of lesion: <italic>P</italic> &lt; 0.001, main effect of side: <italic>P</italic> = 0.003, lesion * side interaction: <italic>P</italic> = 0.038, L<sub>Random</sub> * side interaction: <italic>P</italic> = 0.004, three-way ANOVA; <xref rid="fig2" ref-type="fig">Figure 2G</xref>), overall the performance suffered after the lesion (main effect of lesion: <italic>P</italic> = 0.027, main effect of side: <italic>P</italic> = 0.045, main effect of L<sub>Random</sub>: <italic>P</italic> &lt; 0.001, lesion * L<sub>Random</sub> interaction: <italic>P</italic> = 0.027, three-way ANOVA; <xref rid="fig2" ref-type="fig">Figure 2H</xref>). The data therefore show that unilateral lesion of the ACAd/MOs impairs the proper estimate and use of task structure knowledge during probabilistic reward learning.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Unilateral lesion of ACAd/MOs altered block-length-dependent choice behavior and impaired overall performance</title>
<p><bold>(A)</bold> Schematic representation of the unilateral excitotoxic lesion via injection of ibotenic acid. <bold>(B)</bold> Lesion blocks refers to blocks in which the lesioned side is the better option. Contra blocks refer to blocks in which the lesioned side is contralateral to the better option. <bold>(C, D)</bold> Post hoc histology with cresyl violet staining to confirm the loss of neurons in ACAd/MOs. <bold>(E)</bold> Choice behavior around block switches, plotted separately for the 4 ranges of L<sub>Random</sub>. Black, pre-lesion. Green, post-lesion. Left, switches from lesion block to contra block. Right, switches from contra block to lesion block. Mean values and SEM for all animals. <bold>(F)</bold> The probability of choosing the better option on the trial immediately preceding the switch, as a function of L<sub>Random</sub> for the block preceding the switch. Black, pre-lesion. Green, post-lesion. Mean values and SEM for all animals. <bold>(G)</bold> Similar to (F) for number of trials to reach midpoint (when animal is equally likely to choose either option). <bold>(H)</bold> Similar to (F) for hit rate (probability for animal to choose the better option). For (F) – (H), significant main effects and interactions from three-way ANOVA were indicated (<italic>P</italic> &lt; 0.05). n = 9 mice, 200 pre-lesion sessions and 142 post-lesion sessions.</p></caption>
<graphic xlink:href="493245v3_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2c">
<title>A hybrid model of belief and choice kernels to explain the animals’ behavior</title>
<p>To gain insight into the empirical findings, we fitted different computational models to the data. We were specifically drawn to two emerging ideas in the field of decision-making. First, the concept of belief enables an agent to apply their knowledge of the task structure (<xref ref-type="bibr" rid="c21">Jang et al., 2019</xref>). Namely, the two-armed bandit task in this study can be conceptualized as a task with two ‘states’ (‘70:10’ and ‘10:70’). For each state, there is an optimal action to take - either choosing left or right, for 70:10 and 10:70 respectively. In this scheme, during each trial, the animal (or agent) holds a belief.</p>
<p>This belief is the probabilities that the task is currently in one of the two states. Then, the agent acts based on this belief. Once the result of the action is revealed, the animal’s belief is updated. This update is influenced by the outcome and the animal’s knowledge of the task structure, which can be approximated as its estimation of the likelihood of a reversal in reward probabilities, which is a change point with hazard rate H. From a Bayesian perspective, the ‘prior’ is the initial belief held by the agent about which state they are in before taking an action. This could be based on their previous experiences or could be a neutral assumption if they have no prior experience. For example, the animal might initially believe it is equally likely to be in either the ‘70:10’ or ‘10:70’ state, or it might have a stronger belief in one state over the other based on past rewards. Second, choice kernels can be used to capture an agent’s tendency to repeat the previous actions (<xref ref-type="bibr" rid="c46">Wilson and Collins, 2019</xref>). The choice kernels are updated based on the prior action, scaled by a learning rate. Our belief-CK model contains components for belief and choice kernels, and integrates their outputs for action selection based on a softmax function with separate inverse temperature parameters for belief, and choice kernel, (<xref rid="fig3" ref-type="fig">Figure 3A</xref>, <xref ref-type="fig" rid="figs3-1">Supplementary Figure 3.1</xref> - <xref ref-type="fig" rid="figs3-4">3.4</xref>). Fit to an example session of animal data suggests that this 4-parameter belief-CK model can recapitulate the choice behavior of the mouse in the two-armed bandit task (<xref rid="fig3" ref-type="fig">Figure 3B – E</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>A hybrid model of beliefs and choice kernels to explain the behavior</title>
<p><bold>(A)</bold> The schematic representation of the belief with choice kernel model (belief-CK). The model has four parameters: H (hazard rate), <italic>β</italic> (inverse temperature for belief), <italic>α<sub>K</sub></italic> (learning rate for choice kernel) and <italic>β<sub>K</sub></italic> (inverse temperature for choice kernel). <bold>(B – E)</bold> An example session along with the fits from the belief-CK model, including reward probabilities for left and right options (B) the running-average of probability of choosing right for the animal (black) and model (purple) (C), the belief that the left option is associated with reward probability of 10% (pL10, blue) or 70% (pL70, red) (D), and the choice kernels for left (blue) and right options (red) (E). <bold>(F)</bold> Model comparison between the belief-CK model and 7 other models. Lower log BIC values indicate a better fit. <bold>(G)</bold> The tally of the best-fitting model for each animal. <bold>(H)</bold> The probability of choosing the better option on the trial immediately preceding the switch, as a function of L<sub>Random</sub> for the block preceding the switch. Black, mice. Purple, simulated performance using the belief-CK model with best-fitting parameters. Mean values and SEM for all animals. <bold>(I)</bold> Similar to (H) for number of trials to reach midpoint (when animal is equally likely to choose either option). <bold>(J)</bold> Similar to (H) for the tendency to win-stay on the 5 trials preceding the switch. <bold>(K)</bold> Similar to (H) for the tendency to lose-switch on the 5 trials preceding the switch. n = 31 mice, 617 sessions.</p></caption>
<graphic xlink:href="493245v3_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We compared the belief-CK model against 7 other computational models (see Methods). We started with the win-stay, lose-switch (WSLS) and 3 classic reinforcement learning algorithms including Q-learning (Q-RPE), Q-learning with forgetting (F-Q-RPE), and Q-learning with differential forgetting (DF-Q-RPE) (<xref ref-type="bibr" rid="c20">Ito and Doya, 2015</xref>). We then examined effects of adding choice kernels, by testing DF-Q-RPE with choice kernels (DF-Q-RPE-CK), because DF-Q-RPE was the best fit in the initial set of 4 algorithms, and F-Q-RPE with choice kernels (F-Q-RPE-CK), because this model has the same number of free parameters as the belief-CK model. Finally, we also tested the belief model alone without choice kernels. Model comparison based on Bayesian information criterion (BIC) revealed that inclusion of choice kernels improved the fits significantly. Moreover, the belief-CK model had the lowest BIC values (<xref rid="fig3" ref-type="fig">Figure 3F</xref>; belief-CK versus F-Q-RPE-CK: t<sub>60</sub>= 2.562, <italic>P</italic> = 0.013, paired t-test; belief-CK versus DF-Q-RPE-CK: t<sub>60</sub>= 2.313, <italic>P</italic> = 0.024), and was the best fit for 30 out of 31 animals in this study (<xref rid="fig3" ref-type="fig">Figure 3G</xref>). For each session, we can simulate the belief-CK model using the best-fitting parameters and compare the tendencies of the simulated and experimental data. This exercise shows that the belief-CK model can capture the L<sub>Random</sub>-dependent choice behavior in the experimental data (<xref rid="fig3" ref-type="fig">Figure 3H – K</xref>), which is not possible with the classic reinforcement learning algorithm DF-Q-RPE (<xref ref-type="fig" rid="figs3-5">Supplementary Figure 3.5</xref>). These analyses demonstrate that simple models of reward-based learning such as Q-learning algorithms cannot fully account for the observed choice behavior. Instead, the results support our intuition that mice were estimating change points, which is formalized as the hazard rate <italic>H</italic> in the belief-CK model.</p>
</sec>
<sec id="s2d">
<title>Unilateral ACAd/MOs lesion led to side-specific increase in hazard rate for change points</title>
<p>Next, we applied the computational model to quantify the effect of unilateral ACAd/MOs lesion. To account for the possibility of side-specific alterations, we modified the 4-parameter belief-CK model to include 6 parameters to include differential learning for the sides ipsilateral and contralateral to lesion (see Methods; <italic>H</italic><sub><italic>lesion</italic></sub>, <italic>H</italic><sub><italic>Contra</italic></sub>, α<sub><italic>K lesion</italic></sub>, α<sub><italic>K Contra</italic></sub>, <italic>β</italic>, and <italic>β<sub>K</sub></italic>). After fitting the expanded model to animal data, we compared pre-versus post-lesion performance in two ways. First, on a per-animal basis, sessions before or after the lesion were concatenated for fitting to yield one set of pre-lesion parameters and one set of post-lesion parameters for each animal. Second, on a per-session basis, each session was analyzed separately and the fitted parameters were summarized.</p>
<p>These analyses revealed a side-specific increase in hazard rate after unilateral ACAd/MOs lesion. The exaggerated hazard rate for the side contralateral to lesion <italic>H</italic><sub><italic>Contra</italic></sub> was detected on a per-animal basis (<xref rid="fig4" ref-type="fig">Figure 4A</xref>; pre- vs. post-lesion, <italic>H</italic><sub>Contra</sub>: <italic>P</italic> = 0.004; post-lesion, <italic>H</italic><sub>Contra</sub> vs. <italic>H</italic><sub><italic>lesion</italic></sub>: <italic>P</italic> = 0.810, Wilcoxon signed-rank test), and on a per-session basis (<xref rid="fig4" ref-type="fig">Figure 4B</xref>; pre- vs. post-lesion, <italic>H<sub>Contra</sub></italic>: <italic>P</italic> = 0.001; post-lesion, <italic>H<sub>Contra</sub></italic> vs. <italic>H<sub>lesion</sub></italic>: <italic>P</italic> &lt; 0.001, Wilcoxon rank sum test). Unilateral ACAd/MOs lesion also led to an increase in choice perseveration for both sides, reflected as higher choice-kernel learning rates (<xref rid="fig4" ref-type="fig">Figure 4C – D</xref>; per-animal, pre- vs. post-lesion, α<sub><italic>K lesion</italic></sub>: <italic>P</italic> = 0.012; α<sub><italic>K Contra</italic></sub>: <italic>P</italic> = 0.004; per-session, pre- vs. post-lesion, α<sub><italic>K lesion</italic></sub>: <italic>P</italic> &lt; 0.001; α<sub><italic>K Contra</italic></sub>: <italic>P</italic> &lt; 0.001, Wilcoxon ranked sum test). Action selection depends on the inverse temperature sum, β+ β<sub>K</sub>, reflecting the exploration-exploitation balance, and inverse temperature ratio, <inline-formula><inline-graphic xlink:href="493245v3_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> reflecting the relative reliance on belief over choice kernels. There was no detected difference in inverse temperature sum between pre- and post-lesion animals (<xref rid="fig4" ref-type="fig">Figure 4E – F</xref>, per animal, <italic>P</italic> = 0.567; per session <italic>P</italic> = 0.858, Wilcoxon signed-rank test). By contrast, the inverse temperature ratio was heightened after the lesion (<xref rid="fig4" ref-type="fig">Figure 4G – H</xref>, per animal <italic>P</italic> = 0.038; per session <italic>P</italic> = 0.001, Wilcoxon signed-rank test). Collectively, these analyses show that the consequences of unilateral ACAd/MOs lesion are a contralateral side-specific increase in hazard rate, and broad increases in choice perseveration and reliance on belief for action selection.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Effects of unilateral lesion of ACAd/MOs is consistent with a side-specific increase in hazard rate</title>
<p><bold>(A)</bold> The hazard rates, before and after lesion, extracted by fitting the belief-with-choice-kernel model on a per-animal basis. Square, hazard rate for side ipsilateral to lesion. Cross, hazard rate for side contralateral to lesion. Inset, violin plot of the same data. <bold>(B)</bold> The hazard rates, before and after lesion, on a per-session basis. Mean and SEM. <bold>(C – D)</bold> Similar to (A – B) for learning rate for choice kernel. <bold>(E)</bold> The inverse temperature sum, before and after lesion, on a per-animal basis. <bold>(F)</bold> The inverse temperature sum, before and after lesion, on a per-session basis. <bold>(G - H)</bold> Similar to (E – F) for inverse temperature ratio. *, <italic>P</italic> &lt; 0.05. n.s., not significant. n = 9 mice, 190 pre-lesion sessions and 140 post-lesion sessions.</p></caption>
<graphic xlink:href="493245v3_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2e">
<title>Accurate change point estimation depends on the balance between the left and right hemispheres</title>
<p>The results so far from unilateral lesions suggest two potential mechanisms for change point estimation. The first possibility is that the computation of change point estimation is lateralized, such that the left hemisphere is involved in estimation for the right side, and vice versa. If this is the case, for a bilateral lesion, we would expect aberrant increases of hazard rates for both sides. The second possibility is that the estimation of change points involves inter-hemispheric coordination, which was perturbed by disruption of one hemisphere. If true, the lack of medial frontal cortex on both sides could nullify their respective maladaptive influences on behavior, and we may observe no or milder deficit after a bilateral lesion of ACAd/MOs. To distinguish between these two possibilities, we injected ibotenic acid bilaterally to the left and right ACAd/MOs regions in expert mice. Animals with bilateral lesions performed fewer trials per session, and accordingly fewer block switches (<xref rid="fig5" ref-type="fig">Figure 5A – B</xref>, <xref ref-type="fig" rid="figs5-1">Supplementary Figure 5.1</xref>; <italic>P</italic> &lt; 0.001, Wilcoxon signed-rank test), but had no motor deficit (<xref ref-type="fig" rid="figs5-2">Supplementary Figure 5.2</xref>). Surprisingly, and in line with inter-hemispheric coordination, there was no detectable change in the L<sub>Random</sub>-dependent choice behavior (<xref rid="fig5" ref-type="fig">Figure 5C – D</xref>, <xref ref-type="table" rid="tbls5-1">Supplementary table 5.1</xref>), and no significant changes in the latent decision parameters including hazard rates (<xref rid="fig5" ref-type="fig">Figure 5E – H</xref>). Comparison to sham animals in which saline was injected unilaterally (<xref rid="fig5" ref-type="fig">Figure 5I-P</xref>, <xref ref-type="table" rid="tbls5-2">Supplementary table 5.2</xref>) highlights again that the only effect of bilateral lesion was diminished motivation to perform the task, which was also seen in a prior work from the lab (<xref ref-type="bibr" rid="c32">Siniscalchi et al., 2016</xref>). More importantly, these results argue against change point estimation as a lateralized computation in ACAd/MOs, but rather point to unbalance between the hemispheres as the reason for behavioral deficits.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Effects of bilateral and sham lesions of ACAd/Mos</title>
<p><bold>(A)</bold> The number of trials performed in each session, before and after bilateral lesion, on a per-session basis. Mean and SEM. <bold>(B)</bold> Similar to (A) for the number of block switches in each session. <bold>(C)</bold> The probability of choosing the better option on the trial immediately preceding the switch, as a function of L<sub>Random</sub> for the block preceding the switch, before and after bilateral lesion, on a per-session basis. Mean and SEM. Significant main effects and interactions from three-way ANOVA were indicated (<italic>P</italic> &lt; 0.05). <bold>(D)</bold> Similar to (C) for number of trials to reach midpoint (when animal is equally likely to choose either option). <bold>(E)</bold> The hazard rates, before and after bilateral lesion, extracted by fitting the belief-CK model on a per-session basis. Mean and SEM. <bold>(F)</bold> Similar to (E) for learning rate for choice kernel. <bold>(G)</bold> Similar to (E) for inverse temperature sum. <bold>(H)</bold> Similar to (E) for inverse temperature ratio. <bold>(I – P)</bold> Similar to (A – H) for sham controls with unilateral saline injection. n.s., not significant. For bilateral lesion, n = 4 mice, 105 pre-lesion sessions and 61 post-lesion sessions. For saline control, n = 4 mice, 117 pre-lesion sessions and 53 post-lesion sessions.</p></caption>
<graphic xlink:href="493245v3_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2f">
<title>Medial frontal cortex impacts the decisions during action selection</title>
<p>The lesion-induced effects may be a direct consequence of ACAd/MOs disruption, but some of the behavioral changes can also be due to compensatory adjustments. Therefore, we additionally performed transient inactivation experiments using optogenetics. Mice were implanted with a clear-skull cap that has ∼50% optical transmission (<xref ref-type="fig" rid="figs6-1">Supplementary Figure 6.1A</xref>). For photostimulation, we used a laser-steering system (<xref ref-type="bibr" rid="c29">Pinto et al., 2019</xref>), in which the excitation beam from a 473 nm laser was steered by a set of mirror galvanometers to specific locations with high spatial and temporal resolutions (<xref rid="fig6" ref-type="fig">Figure 6A</xref>). We calibrated the linearity of the steered coordinates as a function of galvanometer voltages and the spatial profile of the laser beam (<xref ref-type="fig" rid="figs6-1">Supplementary Figure 6.1B – C</xref>). We demonstrated that the system can effectively manipulate neural activity by showing elevated c-fos immunohistostaining after unilateral photostimulation of ACAd/MOs in <italic>CaMKIIa<sup>Cre</sup>;Ai32</italic> animals (<xref ref-type="fig" rid="figs6-1">Supplementary Figure 6.1D – F</xref>). Additionally, to determine that our system can effectively bias animal’s behavior, we inactivated the primary visual cortex (V1) and anterolateral motor cortex (ALM) by photostimulating parvalbumin-expressing interneurons in <italic>Pvalb<sup>Cre</sup>;Ai32</italic> animals. No effect was observed when silencing V1, whereas biased tongue licks were induced by inhibiting ALM in mice during the two-armed bandit task, consistent with previous findings (<xref ref-type="bibr" rid="c16">Guo et al., 2014</xref>) (<xref ref-type="fig" rid="figs6-2">Supplementary Figure 6.2</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Optogenetic inactivation in pre-choice, but not post-choice, period reproduced the deficit in change-point estimation</title>
<p><bold>(A)</bold> The schematic representation of experimental setup. <bold>(B)</bold> CCD image of a mouse with a cleared skull cap. The tw blue crosses indicate the locations of the photostimulation, i.e. left and right ACAd/MOs. <bold>(C - D)</bold> The trial and block structures, and the timing of the photostimulation. <bold>(E)</bold> The probability of choosing the better option on the trial immediately preceding the switch, as a function of L<sub>Random</sub> for the block preceding the switch for pre-choice inactivation. Black, control blocks. Light blue, Stimulated blocks. Blue, contralateral to stimulated blocks. Mean values and SEM for all animals. <bold>(F)</bold> The hazard rates extracted by fitting a modified belief-CK model, for pre-choice inactivation, on a per-animal basis. <bold>(G)</bold> Similar to (F) for learning rate for choice kernel. <bold>(H)</bold> Similar to (F) for inverse temperature sum. <bold>(I)</bold> Similar to (F) for inverse temperature ratio (<bold>J-N</bold>) Similar to E-I for post-choice inactivation. n = 6 animals.</p></caption>
<graphic xlink:href="493245v3_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To suppress excitatory activity in ACAd/MOs during block switches, we used <italic>Pvalb<sup>Cre</sup>;Ai32</italic> animals in which the channelrhodopsin ChR2 was selectively expressed in parvalbumin-expressing (PV) GABAergic interneurons (n = 6). Targeted photostimulation would activate PV interneurons in the left or right ACAd/MOs (<xref rid="fig6" ref-type="fig">Figure 6B</xref>), which would in turn silence local excitatory spiking activity (<xref ref-type="bibr" rid="c16">Guo et al. 2014</xref>; Li et al. 2019). These transient inactivations were applied either at the time of action selection (“pre-choice”, from cue onset to lick response) or after the outcome (“post-choice”, from lick response for 2 s; <xref rid="fig6" ref-type="fig">Figure 6C</xref>), and on every trials across two consecutive blocks such that activity was suppressed before and after certain block switches (<xref rid="fig6" ref-type="fig">Figure 6D</xref>).</p>
<p>Pre-choice inactivation impaired the ability of the mice to select the better option in the trials immediately preceding the block switch, when the stimulated side was contralateral to the side with the better option (<xref rid="fig6" ref-type="fig">Figure 6E</xref>), suggesting a lateralized influence of ACAd/MOs on decision-making under conditions of uncertainty as observed in lesion data. In contrast, post-choice inactivation did not produce significant changes in the selection of the better option immediately before block switches (<xref rid="fig6" ref-type="fig">Figure 6J</xref>, indicating that the effects of ACAd/MOs inactivation are primarily restricted to the pre-choice period (three-way ANOVA: main effect of block length: F(3, 1999) = 49.778, <italic>P</italic> &lt; 0.001; main effect of stimulation period: F (1, 1999) = 7.974, <italic>P</italic> = 0.004; interaction between block length and stimulation: F(3, 1999) = 2.674, <italic>P</italic> = 0.046; interaction between block length, stimulation and stimulation period: F(3, 1999) = 2.625, <italic>P</italic> = 0.049).</p>
<p>Fitting to the belief-CK model, expanded to account for the optogenetic stimulation (see Methods; <italic>H<sub>Control</sub>, H<sub>ipsi stim</sub>, H<sub>Contra stim</sub>, α<sub>K Control</sub>, α<sub>K ipsi stim</sub>, α<sub>K Contra stim</sub>, β<sub>Control</sub>, β<sub>stim</sub>, β<sub>K Control</sub></italic> and <italic>β<sub>K stim</sub></italic>), highlights the strongest effect is an acute change to hazard rate contralateral to the transient inactivation for pre-choice inactivation (<xref rid="fig6" ref-type="fig">Figure 6F</xref>; pre-choice inactivation, <italic>H<sub>Contra stim</sub></italic> vs. <italic>H<sub>ipsi stim</sub></italic>: <italic>P</italic> = 0.156; <italic>H<sub>Contra stim</sub></italic> vs. <italic>H<sub>Control</sub></italic>: <italic>P</italic> = 0.094; <xref rid="fig6" ref-type="fig">Figure 6K</xref>; post-choice inactivation, <italic>H<sub>Contra stim</sub></italic> vs. <italic>H<sub>ipsi stim</sub></italic>: <italic>P</italic> = 0.687; <italic>H<sub>Contra stim</sub></italic> vs. <italic>H<sub>Control</sub></italic>: <italic>P</italic> = 0.562, Wilcoxon signed-rank test), although there were variations across individual animals and effect was not statistically significant There were no detectable effects of transient inactivation on <inline-formula><inline-graphic xlink:href="493245v3_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and <italic>β + β<sub>k</sub></italic> for pre-choice inactivation (<xref rid="fig6" ref-type="fig">Figure 6G-I</xref>) or post-choice inactivation (<xref rid="fig6" ref-type="fig">Figure 6K-N</xref>). Together with the results from unilateral lesions, we interpret these findings from acute inactivation to indicate that ACAd/MOs is involved specifically in the change point estimation process, which occurs during the pre-choice period.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>This study provides evidence that mice anticipate impending change points by altering their choices prior to switches in a classic probabilistic reward learning task. Computational analyses indicate that the animals’ choice behavior is consistent with a model of belief updating and choice perseveration. Causal perturbation experiments emphasize the role of the ACAd/MOs region of the medial frontal cortex. Crucially, as discussed below, the collective results from the range of manipulations employed – unilateral and bilateral lesions, as well as pre- and post-choice optogenetic inactivation – provide important insights that can constrain the potential neural mechanisms underlying change-point estimation during decision-making.</p>
<p>Although many studies of decision-making in rodents relied on analyses involving Q-learning algorithms, there are other reports suggesting deviations from simple reinforcement learning. For instance, a pioneering study demonstrated that rats are exceedingly sensitive to changes in reward rates, approximating an ideal observer (<xref ref-type="bibr" rid="c12">Gallistel et al., 2001</xref>). Moreover, several studies using a variety of timing, operant conditioning, decision, and sensory categorization tasks have found neural and behavioral data consistent with the use of belief in rodents (<xref ref-type="bibr" rid="c22">Karlsson et al., 2012</xref>; <xref ref-type="bibr" rid="c24">Li and Dudman, 2013</xref>; <xref ref-type="bibr" rid="c26">Liu et al., 2021</xref>; <xref ref-type="bibr" rid="c35">Starkweather et al., 2017</xref>; <xref ref-type="bibr" rid="c43">Vertechi et al., 2020</xref>). However, these prior studies are different because in some cases, the use of belief did not necessarily confer better performance over other strategies for the task (<xref ref-type="bibr" rid="c35">Starkweather et al., 2017</xref>). In other cases, the task employs a series of deterministic outcomes (<xref ref-type="bibr" rid="c43">Vertechi et al., 2020</xref>), which strongly favors switching behaviors. Our study therefore extends these past results by showing decisions consistent with belief updating in one of the most popular value-based decision-making tasks used for human and animal studies (<xref ref-type="bibr" rid="c39">Sutton and Barto, 2018</xref>).</p>
<p>To quantify the animals’ behavior, we proposed a model involving belief updating with a fixed hazard rate, which was motivated by a prior study (<xref ref-type="bibr" rid="c21">Jang et al., 2019</xref>) and adapted to fit our task design. In this model, the agent understands that each action is associated with one of two reward probabilities. Given information from its choice and reward history as well as knowledge of the probability of a switch in reward probabilities, the agent infers the likelihood of the current states associated with the actions. This is in sharp contrast to the Q-learning algorithms, where the agent is implicitly ignorant of the task structure, and simply updates action values based on the last trial’s action and outcome. For belief updating, one limitation for our model is that the hazard rate is a constant value within a session. This assumption seems reasonable because mice were trained on the task extensively and probably accrue knowledge of the hazard rate based on experience of multiple switches across many sessions. That said, in principle, it is possible for an agent to infer and adjust the hazard rate as the task proceeds (<xref ref-type="bibr" rid="c47">Wilson et al., 2010</xref>). Moreover, there are other models, such as ones based on a flexible learning rate, that can account for variable choice behavior as a function of outcome history (<xref ref-type="bibr" rid="c15">Grossman et al., 2022</xref>). Future studies may employ tasks that can more specifically disambiguate between the different ways in which mice may adapt learning parameters within a session.</p>
<p>To determine the role of the medial frontal cortex, we used both permanent lesions and transient inactivation, methods that each have its advantages and limitations (<xref ref-type="bibr" rid="c28">Otchy et al., 2015</xref>; <xref ref-type="bibr" rid="c42">Vaidya et al., 2019</xref>) and they provide complementary insights into the functioning of this brain region. Specifically for lesions, we employed unilateral manipulations, such that we can compare effects between sides ipsilateral and contralateral to the lesion in the same animal, serving as a rigorous internal control. Results from these experiments demonstrated lateralized deficits from lesions of the medial frontal cortex. This finding may be surprising, because although sensory and motor functions are typically expected to be lateralized, it is less obvious that cognitive function may also be side-dependent. However, we note that a few prior studies have also found side-specific decision-making deficits from unilateral manipulations, such as effects of dorsal striatum on action values (<xref ref-type="bibr" rid="c40">Tai et al., 2012</xref>) and effects of frontal cortex on lapses in a multisensory task (<xref ref-type="bibr" rid="c30">Pisupati et al., 2021</xref>) and short-term memory (<xref ref-type="bibr" rid="c50">Yin et al., 2022</xref>). There were also instances of hemi-neglect in humans (Stone et al., 1991; Kerkhoff, 2001; Crowne et al., 1986; Reep and Corwin, 2009). The exact reason for side-specific effects is unclear, although one possibility is that when decisions are intimately tied to responses associated with lateralized motor actions, then there is embodiment and motor and premotor cortical regions become involved in the neural computation (<xref ref-type="bibr" rid="c6">Bennur and Gold, 2011</xref>).</p>
<p>The various deficits arising from lesion and optogenetic manipulations are useful for thinking about the potential mechanisms for how the medial frontal cortex contributes to belief updating and more specifically change-point estimation. An inaccurate estimate, which would reflect as altered hazard rate in our computational model, can occur for several reasons: (1) error in estimating the value of hazard rate, (2) error when using the hazard rate to update belief, and (3) error when using the prior choice and reward to update belief. Reason (3) was not explicitly tested in our model fits but could manifest as an apparent change in hazard rate. Among these possibilities, the first option seems unlikely. In our task, an accurate value for hazard rate cannot be determined quickly but must be calibrated by experiencing many switches across multiple sessions. This is difficult to reconcile with the immediate deficit observed with pre-choice optogenetic inactivation. The third option is also unlikely. Previous studies have shown that choice- and outcome-related signals arise in the medial frontal cortex shortly after the outcome (<xref ref-type="bibr" rid="c33">Siniscalchi et al., 2019</xref>; <xref ref-type="bibr" rid="c37">Sul et al., 2011</xref>), whereas optogenetic inactivation during this post-choice period was ineffective. Therefore, it may be the case that the medial frontal cortex is involved in incorporating the likelihood of an impending change point for estimating the current task state.</p>
<p>Furthermore, rather than computing using a probability such as the hazard rate, the animal may instead approximate the process by employing simpler heuristics to predict the impending occurrence of a change point. One intuitive heuristic, consistent with the reason for lateralized deficits, is that the animals may rely on the recent choice history of the number of better options chosen, which would indicate a higher likelihood of an impending switch. Here, the lack of effect from bilateral lesions can shed light on the form of the heuristic. For example, one heuristic that can work is a ratio of the number of recent left choices divided by the number of recent right choices, and if the unilateral lesion effectively adds a multiplier to the side’s choice history, then a bilateral perturbation would lead to a null effect. Heuristics based on choice history are plausible because the medial frontal cortex has long-lasting, persistent representation of past choices (<xref ref-type="bibr" rid="c2">Bari et al., 2019</xref>; <xref ref-type="bibr" rid="c18">Hattori et al., 2019</xref>; <xref ref-type="bibr" rid="c32">Siniscalchi et al., 2016</xref>; <xref ref-type="bibr" rid="c37">Sul et al., 2011</xref>). One caveat for this line of logic is that it is based on a specific belief updating model. However, we discuss the implications to illustrate how the results can inform the underlying neural basis.</p>
<p>To sum, the two-armed bandit task has gained widespread use in neuroscience and artificial intelligence research because of its simplicity, translational significance, and amenability to computational modeling. Our results show that mice may perform the task by not only updating based on choices and outcomes, but also leverage knowledge of the environment to estimate change points. The diminished or exaggerated use of this prior knowledge represents suboptimal decision-making, which may underlie pathological behaviors in neuropsychiatric disorders that involve dysfunctions of the medial frontal cortex.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Lead Contact</title>
<p>Further information and requests for resources and reagents should be directed to and will be fulfilled by the Lead Contact, Huriye Atilgan (<email>huriye.atilgan@dpag.ox.ac.uk</email>)</p>
</sec>
<sec id="s4b">
<title>Materials Availability</title>
<p>All published reagents and mouse lines will be shared upon request within the limits of the respective material transfer agreements. Detailed plans including parts list for constructing the behavioral training apparatus is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Kwan-Lab/behavioral-rigs">https://github.com/Kwan-Lab/behavioral-rigs</ext-link>.</p>
</sec>
<sec id="s4c">
<title>Data and Code Availability</title>
<p>Data and analysis software for this paper will be available at Github (<ext-link ext-link-type="uri" xlink:href="https://github.com/Kwan-Lab">https://github.com/Kwan-Lab</ext-link>).</p>
</sec>
<sec id="s5">
<title>Experimental model and subject details</title>
<sec id="s5a">
<title>Mouse lines</title>
<p>In this study, we used a total of 30 adult male mice (<bold>Table 1</bold>; 2 - 8 months old), including 24 C57BL/6J wild-type mice (#000664, Jackson Laboratory) for the lesion experiments, and 6 <italic>Pvalb<sup>Cre</sup></italic>;<italic>ROSA<sup>CAG-ChR2-EYFP</sup>(Ai32)</italic> mice for the photostimulation experiments. The <italic>Pvalb<sup>Cre</sup></italic>;<italic>ROSA<sup>CAG-</sup> <sup>ChR2-EYFP</sup>(Ai32)</italic> mice were generated by crossing the <italic>Pvalb<sup>Cre</sup></italic>(B6.129P2-<italic>Pvalb</italic><sup>tm1(cre)Arbr</sup>/J; #017320, Jackson laboratory) and <italic>ROSA<sup>CAG-ChR2-EYFP</sup>(Ai32)</italic> (B6.Cg-<italic>Gt(ROSA)26Sor<sup>tm32</sup> <sup>(CAG-</sup> <sup>COP4*H134R/EYFP)Hze</sup></italic>/J; #024109, Jackson laboratory) strains. Mice were housed in groups of 2 – 5 per cage in a 12h:12h light:dark cycle with ad libitum access to food. All of the experiments were completed during the light cycle. Experimental procedures were approved by the Yale University Institutional Animal Care and Use Committee.</p>
</sec>
</sec>
<sec id="s6">
<title>Method details</title>
<sec id="s6a">
<title>Surgery for lesion experiments</title>
<p>All of the mice in the lesion study underwent two surgeries. In the first surgery, a stainless steel headplate was attached to the skull to facilitate behavioral training. After collecting baseline behavioral data, a second surgery consisting of either an excitotoxic or sham lesion was performed. Before each surgery, the animal was treated pre-operatively with carprofen (5 mg/kg, i.p.; 024751, Butler Animal Health) and dexamethasone (3 mg/kg, i.p.; Dexaject SP, #002459, Henry Schein Animal Health). At the start of each surgery, anesthesia was induced with 2% isoflurane in oxygen, and the animal was placed on a water-circulating heating pad (TP-700, Gaymar Stryker). The head was secured in a stereotaxic frame with ear bars (David Kopf Instruments). Following induction, isoflurane concentration was lowered to 1 – 1.5% based on the animal’s weight and breathing pattern.</p>
<p>For the first surgery, the scalp was shaved using scissors and cleaned with povidone-iodine (Betadine, Perdue Products L.P.). A narrow portion of the scalp was removed along the midline from the interaural line to a line visualized just posterior to the eyes. The scalp was retracted to expose the dorsal aspect of the skull and washed thoroughly with artificial cerebrospinal fluid (ACSF; in mM: 5 KCl, 5 HEPES, 135 NaCl, 1 MgCl2, and 1.8 CaCl2; pH 7.3). A scalpel and a ballpoint pen were used to scratch and paint marks onto the skull at the secondary motor and anterior cingulate cortices (MOs/ACAd; +1.5 mm AP, +0.3 mm ML from bregma), to be used as a landmark for the second surgery. A custom-made stainless-steel head plate (eMachineShop) was then bonded to the skull with cyanoacrylate glue (Loctite 454, Henkel) and transparent dental acrylic (C&amp;B Metabond, Parkell Inc.), with care taken to cover any remaining exposed skull. The post-operative care was provided immediately, and for three consecutive days following surgery, consisting of carprofen (5 mg/kg, i.p.) for analgesia and preservative-free 0.9% NaCl (0.5 mL, i.p.) for fluid support. The animal had at least one week for post-operative recovery prior to the onset of behavioral training.</p>
<p>For the second surgery, a 1-mm-diameter circular craniotomy was made over the marked spot using a high-speed rotary drill (K.1070, Foredom). A total of ∼300 nL of ibotenic acid (5 mg/mL in saline; 505024, Abcam) was injected into two locations (+1.5 mm and +1.7mm AP, +0.3 mm ML from bregma; 0.4 mm DV) through a glass micropipette attached to a microinjection unit (Nanoject II, Drummond). More specifically, each location would receive 15 pulses of 9.6 nL of the prepared solution. To minimize backflow of the injected solution, there was a 1 min gap between each pulse, and the micropipette was left in place for 20 min after the last pulse. Sham animals underwent the same surgical procedure, but saline was delivered instead of ibotenic acid. The exposed skull was covered with dental cement. The animal had two weeks of post-operative recovery prior to resuming behavioral testing.</p>
</sec>
<sec id="s6b">
<title>Surgery for photostimulation experiments</title>
<p>All of the mice in the photostimulation study underwent one surgery. The animal was anesthetized in the same way as described above. Procedures to prepare the skull were nearly identical to those described in (<xref ref-type="bibr" rid="c29">Pinto et al., 2019</xref>). Briefly, the scalp covering the dorsal skull surface was excised and the periosteum over the skull was removed using a micro-curette (VWR Buck Micro Curette, 10806-346). The skull was washed thoroughly with ACSF. A custom stainless-steel head-plate (eMachineShop) was affixed at points above the cerebellum and olfactory bulbs with cyanoacrylate glue (Loctite 454, Henkel) and transparent dental acrylic (C&amp;B Metabond, Parkell Inc.). The exposed skull was covered with a thin layer of cyanoacrylate glue (Apollo 2000, Cyberbond) and transparent dental acrylic, then polished with an acrylic polishing kit (0321, PearsonDental), and finally covered with transparent nail polish (72180, Electron Microscopy Services). The animal had at least one week of post-operative recovery prior to the onset of behavioral training.</p>
</sec>
<sec id="s6c">
<title>Behavioral training apparatus</title>
<p>The apparatus for training head-fixed mice was adapted from (<xref ref-type="bibr" rid="c32">Siniscalchi et al., 2016</xref>). Detailed plans including parts list for constructing the behavioral training apparatus is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Kwan-Lab/behavioral-rigs">https://github.com/Kwan-Lab/behavioral-rigs</ext-link>. Briefly, the behavioral box was constructed using a closed compartment of an audio-visual cart (4731T74, McMaster-Carr) that was soundproofed with acoustic foam (5692T49, McMaster-Carr). The mouse was placed in an acrylic tube (8486K433, McMaster-Carr), which allowed for postural adjustments but restricted large body movements. Two metal screws were used to attach the head plate of the mouse onto a custom stainless-steel mount (eMachineShop). The lickometer was based on a 3D-printed part that held two lick ports constructed from 20-gauge needles, and was placed in front of the mouse such that the lick ports are on the left and right of the animal’s mouth. The position of the lick ports relative to the mouse could induce considerable side bias and influence response time. To mitigate variations across sessions, the lickometer was attached to an XYZ translation stage (MT3, Thorlabs) for precise positioning, and the same set of coordinates were used for the same mouse between sessions.</p>
<p>Water was supplied to the lick ports via Tygon tubing (EW-95666-01, Cole-Parmer). A touch detector circuit was used for detecting tongue licks onto each lick port. Water was delivered at the lick ports by gravity feed and controlled by solenoid valves (EV-2-24; Clippard or MB202-V-A-3-0-L-204, Gems Sensor Solenoid). The water amount is controlled by the duration of a TTL pulse, and we calibrated the solenoid to deliver ∼2 <italic>β</italic>L per pulse. All of the electrical circuits for water delivery and lick detection were connected to a desktop computer via a data acquisition board (USB-201, Measurement Computing). A pair of speakers (S120, Logitech) were positioned in front of the animal for auditory stimuli (calibrated to 80 dB). The tasks were programmed in scripts using the Presentation software (Neurobehavioral Systems), which controlled the entire behavioral apparatus including stimulus presentation. A table lamp (LT-T6, Aukey) was placed in each box, behind the mouse, to provide dim ambient light in the box. A camera (SV-USBFHD01M-BFV, Svpro) was used to optimize the lick port position at the beginning of each session and monitor the animal’s behavior throughout the session.</p>
</sec>
<sec id="s6d">
<title>Two-armed bandit task</title>
<p>Mice were fluid-restricted. On training days, animals received all of their water intake from behavioral training that occurred 1 session per day, 5 days per week. On non-training days and days when weight measurements fell below 85% of their pre-restriction weight, water was provided ad libitum in the home cage for 5 minutes.</p>
<p>Prior to any behavioral training, the animal was handled and habituated to head fixation for increasing durations over three days. Water was manually provided via the lick ports to familiarize mice with receiving fluid from the lickometer. After 1 – 2 days of habituation, the animal underwent two phases of shaping.</p>
<p>In the first phase, the animal was trained to alternate between the two lick ports to receive water rewards. More specifically, on each trial, there would be an auditory cue (duration = 0.2 s, tone with 5 kHz carrier frequency). The onset of the auditory cue is the start of a 5-s long response window, during which the first lick detected is the animal’s response. The playback of the auditory cue was terminated early if the response was recorded before the entire stimulus was played. The animal was required to alternate between left and right responses to earn water rewards: if the last rewarded response was left, then the mouse must make a right response to receive water, and vice versa. The inter-trial interval had a fixed duration, such that the auditory cue for the next trial would occur 3.1 s after the animal’s response. A session would end when the animal did not lick during the response window (‘miss’) for 20 consecutive trials. When the animal could attain at least ∼60 rewards in a session, the shaping would proceed to the second phase.</p>
<p>In the second phase, the animal still had to alternate, but was trained to the trial structure including withholding licks between trials. The second phase was similar to the first phase, with two exceptions. First, the onset of the auditory cue is the start of a 2-s long response window, during which the first lick detected is the animal’s response. Second, the addition of a no-lick period between trials. The no-lick period began 3 s after the animal’s response. Initially, the duration of the no-lick period was drawn from a truncated exponential distribution (λ = 0.33333, minimum = 1, maximum = 5). If any lick was detected during the no-lick period, then another duration drawn from the same truncated exponential distribution would be added onto the end of the first no-lick period. The addition could repeat for up to 5 times if the animal could not withhold licking. Therefore, the possible duration for the entire no-lick period ranged between 1 and 25 s, and was dependent on whether the animal could withhold licking. Subsequently, the auditory cue for the next trial would occur 0.1 s after the end of the no-lick period. When the animal could receive rewards in at least ∼40% of all trials, it would be advanced to the two-armed bandit task. Typically, the animal would proceed through each shaping phase in 3 or fewer sessions.</p>
<p>In the two-armed bandit task, the auditory stimulus, response timing, and inter-trial interval including no-lick period were exactly the same as the second shaping phase. However, the outcome of each trial was probabilistically determined. In a 10:70 block of trials, the left lick port had a 10% chance of delivering water if chosen and the right lick port had a 70% chance of delivering water if chosen. By contrast, in a 70:10 block of trials, the reward probabilities associated with the left and right ports were reversed. Hence, the better option is right in a 10:70 block, but left in a 70:10 block. At the start of each session, the block type (10:70 or 70:10) was randomly chosen.</p>
<p>The block type would switch when the mouse fulfilled the switching condition: perform trials (L<sub>Criterion</sub>) until the animal accumulated 10 choices selecting the side with high reward probability, and then perform additional trials (L<sub>Random</sub>) that were drawn from a truncated geometric distribution (<italic>p</italic> = 0.0909, no minimum = 0, maximum = 30). Notably, L<sub>Criterion</sub> depended on the animal’s performance, whereas L<sub>Random</sub> was random and independent of performance. The block type would continue to switch, as long as the animal was fulfilling the switching condition of each block. In the lesion experiments, they would be tested on the two-armed bandit task in daily sessions until at least 150 switches were collected for each of the pre- and post-lesion conditions.</p>
</sec>
<sec id="s6e">
<title>Photostimulation</title>
<p>The photostimulation rig allowed for rapid adjustment of the position of the laser. The rig was constructed based on the design in (<xref ref-type="bibr" rid="c29">Pinto et al., 2019</xref>). Briefly, a 473 nm laser beam (Obis LX 473 nm, 75 mW; 1193830, Coherent) was steered by a set of XY galvo mirrors (6210H, Cambridge Technologies) mounted in a ThorLabs 60 mm cage system. The laser was sent through a F-theta scan lens (f = 160 mm; FTH160-1064-M39, ThorLabs) and directed onto the animal’s head. A monochromatic camera (Grasshopper3; GS3-U3-23S6M-C, Point Grey) equipped with a telecentric lens (TEC-55, Computar) was used to visualize the cortical surface and to calibrate the position of the laser beam relative to bregma. The laser, mirrors, and camera were controlled via a data acquisition board (PCIe-6343, National Instruments) by custom software written in MATLAB on a desktop computer. The laser was calibrated to yield a time-averaged power of 1.5 mW at the sample. Light transmission through the clear-skull cap (dental cement and skull) was measured by placing the cap at the sample plane, and positioning a laser power meter underneath the cap.</p>
<p>Animals underwent the same shaping phases and task training. For the photostimulation experiments, the animal was tested on the two-armed bandit task in a behavioral setup within the photostimulation rig. Temporally, the photostimulation could occur either before or after the animal’s response. For pre-choice photostimulation, the laser was turned on at the onset of the auditory cue and turned off immediately when a response was detected. For post-choice photostimulation, the laser was turned on immediately when a response was detected and turned off 2 s later. Spatially, the photostimulation was targeted to one of two possible locations: left MOs/ACAd (+1.5 mm AP, - 0.3 mm ML from bregma) or right MOs/ACAd (+1.5 mm AP, +0.3 mm ML from bregma).</p>
<p>At the start of each session, the timing of the photostimulation (pre-choice or post-choice) was randomly chosen and stayed the same for the entire session. The initial 3 – 5 blocks were always control blocks, i.e., no photostimulation. The rationale was to make sure the animal was performing the task well that day before any perturbation. Subsequently, the next 2 blocks would be photostimulation blocks targeting the same spatial location, followed by 2 control blocks, followed by 2 photostimulation blocks targeting the same spatial location, and so on. For the photostimulation blocks, the spatial location was randomly selected to be left or right MOs/ACAd each time. In other words, in the same session, the animal may receive perturbation of both left and right MOs/ACAd, albeit in different trial blocks.</p>
<p>To prevent the animal from using stray laser light to distinguish photostimulation from control blocks, we implemented a masking stimulus by shining a blue LED at the eyes. The masking stimulus had the same onset timing and duration as the photostimulation used for the session, and was applied for every trial in both control and photostimulation blocks.</p>
</sec>
<sec id="s6f">
<title>Histology</title>
<p>To determine the extent of the lesions, following behavioral experiments, the mouse was deeply anaesthetized with an overdose of isoflurane and transcardially perfused with chilled formaldehyde solution (4%, in phosphate-buffered saline (PBS)) at a rate of 5 mL/min. The brain was quickly removed, stored overnight in the formaldehyde solution at 4 °C, and then switched to PBS for long-term storage. Coronal sections with a thickness of 100 μm were cut using a vibratome (VT1000 S, Leica).</p>
<p>For cresyl violet staining, cresyl violet (1 g/L; 10510-54-0, Sigma Aldrich) was added to filtered <italic>H</italic><sub>2</sub>O and stirred overnight. The next day, glacial acetic acid (2.5 mL/L; 64-19-7, Sigma Aldrich) was added to the solution. The tissue sections were washed with filtered <italic>H</italic><sub>2</sub>O before mounting on glass slides and stained with a pre-warmed (50°C) cresyl violet solution. The sections were dehydrated with ascending grades of alcohol (95% for 10 minutes, 100% twice for 10 minutes each), cleared with xylene (twice for 5 minutes each), and mounted with DPX mounting medium (06522, MilliporeSigma).</p>
<p>For NeuN staining, tissue sections were washed three times with PBS and then incubated with a blocking solution (5% normal goat serum, 0.3% Triton X-100, in PBS) for 1 hour at room temperature. Subsequently, sections were incubated with rabbit monoclonal primary antibody against NeuN (1:500 dilution; ab177487, Abcam Inc,) overnight at 4°C on the shaker. After washing three times with PBS, tissue sections were incubated with goat anti-rabbit secondary antibody with conjugated Alexa 488 (1:500 dilution; ab150077, Abcam Inc,) for 2.5 hours at room temperature. After washing with PBS, nuclear staining was performed by incubating with a 4′,6-diamidino-2-phenylindole (DAPI) staining solution (ab228549, Abcam Inc.) for 10 minutes. Finally, sections were washed three times with PBS and then with filtered <italic>H</italic><sub>2</sub>O, before mounting on slides with DPX mounting medium (06522, MilliporeSigma). A motorized upright fluorescence microscope (Olympus BX61, Olympus) was used to image the sections.</p>
</sec>
</sec>
<sec id="s7">
<title>Quantification and statistical analysis</title>
<sec id="s7a">
<title>Analysis of behavioral data</title>
<p>Timestamps of the behavioral events, including cue onsets, outcome onsets, licks, and reward probabilities were logged to a text file by the NBS Presentation software. The text files were parsed and analyzed using scripts written in MATLAB (MathWorks, Inc.). For all of the analyses, we excluded the session if the animal had fewer than 4 block switches. We analyzed all of the trials up to the last switch, and ignored the trials in the last incomplete block where by definition had many miss trials.</p>
<p>When analyzing the consequences of unilateral lesions, for simplicity, we used the term <italic><underline>lesion</underline> <underline>blocks</underline></italic> and <italic><underline>contra blocks</underline></italic>. This is because unilateral lesions were randomly assigned to the left or right hemisphere for each animal. Lesion blocks refer to those blocks where the lesioned side is the same as the better option. In other words, if the animal had a unilateral lesion on the right hemisphere, then the lesion blocks correspond to 10:70 blocks. If the animal had a unilateral lesion on the left hemisphere, then the lesion blocks correspond to the 70:10 blocks. The remainder was referred to as the contra blocks.</p>
</sec>
<sec id="s7b">
<title>Analysis of behavioral data – effects of block length</title>
<p>For analyses involving block lengths, we used the subset of data in which L<sub>Criterion</sub>≤ 20 trials for the pre-switch block, in order to restrict the analyses to situations where the performance was similar.</p>
<p>The probability of choosing the better option pre-switch, <underline><italic>P</italic> (<italic>better option</italic>) <sub>pre-switch</sub></underline>, was determined for each animal by examining the last trial before each block switch, dividing the number of times in which the animal chose the initial better option (i.e., the side with 70% reward probability before switch) by the number of switches. <underline>Hit rate</underline> was the proportion of trials in which the animal selected the better option. The win-stay probability, <underline>P (stay | win)</underline>, was the fraction of trials in which animals repeated a choice after a rewarded trial. The lose-switch probability, <underline>P (switch | lose)</underline>, was the fraction of trials in which an animal switched its choice after an unrewarded trial. For all of these performance metrics, we computed the metric on a session-by-session basis, then averaged across sessions to obtain per-animal value. In the lesion data, <underline>P (better option) <sub>pre-switch</sub></underline>, <underline>P (stay | win)</underline> and <underline>P (switch | lose)</underline> was calculated in the last five trials before each block switch</p>
<p><underline>Trials to reach midpoint</underline> was determined by first calculating the fraction of trials for choosing the initial better option around the block switch for the animal, and then identifying the trial from the switch where the fraction of trials choosing the initial better option was closest to 0.5 To compute the trials to reach the midpoint metric, we would first concatenate data across sessions including inserting 20 NaN in the gaps, then compute the metric to obtain the per-animal value. This allowed us to calculate the fraction of trials, resulting in a smoother switching curve for each different L<sub>Random</sub> block. After establishing this more reliable switching curve, we were able to determine the trial from the switch for each animal.</p>
</sec>
<sec id="s7c">
<title>Analysis of behavioral data – reinforcement learning models</title>
<p>The response-by-response behavior of the animal was fitted with eight models: (1) win-stay lose-switch (WSLS); (2) Q-learning (Q-RPE); (3) Q-learning with forgetting (F-Q-RPE); (4) Q-learning with differential forgetting (DF-Q-RPE); (5) F-Q-RPE with choice kernel (F-Q-RPE-CK), which captured the tendency to repeat the same option; (6) DF-Q-RPE with choice kernel (DF-Q-RPE-CK); (7) belief model that uses the prior knowledge of a change point in reward probabilities to make a decision (7) belief model with choice kernel (belief-CK). We will describe these models in detail in the following paragraphs.</p>
<p>For <italic><underline>win-stay lose-switch (WSLS)</underline></italic>, if the last trial was rewarded, the agent would repeat to choose the same option with probability <italic>p</italic>. Else, if the last trial was unrewarded, the agent would switch to choose the other option with probability <italic>p</italic>. This model has 1 free parameter: <italic>p</italic>.</p>
<p>For the three <italic><underline>simple Q-learning models (Q-RPE, F-Q-RPE, DF-Q-RPE)</underline></italic>, the updating rules are as follows. On trial <italic>n</italic>, for a choice <italic>c<sub>n</sub></italic> that leads to an outcome <italic>r<sub>n</sub></italic>, the reward prediction error <italic>δ<sub>n</sub></italic> is:
<disp-formula id="eqn1">
<graphic xlink:href="493245v3_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="493245v3_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the action value associated with the chosen action <italic>i</italic>. In our task, there are two options, so <italic>i</italic> ɛ {<italic>L</italic>, <italic>R</italic>}. For the outcome, <italic>r<sub>n</sub></italic> = 1 for reward, 0 for no reward. The action value for each action is then updated accordingly:
<disp-formula id="eqn2">
<graphic xlink:href="493245v3_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>α</italic> is the learning rate, <italic>λ</italic> are the forgetting terms for the unchosen action. Then on the next trial, the probability of choosing each action was determined by a softmax rule:
<disp-formula id="eqn3">
<graphic xlink:href="493245v3_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>β</italic> is the inverse temperature parameter.</p>
<p>The model as stated with 3 free parameters — α, λ, and β — is referred to as Q-learning with differential forgetting (DF-Q-RPE). A special case of this model is when, <italic>λ</italic> = <italic>α</italic>, which is referred to as Q-learning with forgetting (F-Q-RPE). Another special case is when, <italic>λ</italic> = 0, which is referred to as Q-learning (Q-RPE).</p>
<p>For two <underline>Q-learning models with choice kernel (<italic>F-Q-RPE-CK, DF-Q-RPE-CK)</italic></underline>, choice kernel was implemented to capture the tendency of choosing the previous choice. We adapted the formulation from (<xref ref-type="bibr" rid="c46">Wilson and Collins, 2019</xref>). The choice kernel <inline-formula><inline-graphic xlink:href="493245v3_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula> on trial <italic>t</italic> associated with action <italic>i</italic> is updated in a manner analogous to the action values:
<disp-formula id="eqn4">
<graphic xlink:href="493245v3_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where α<sub><italic>K</italic></sub> is the choice-kernel learning rate. For action selection with both action values and choice kernels, the probability of choosing each action was determined by a softmax rule:
<disp-formula id="eqn5">
<graphic xlink:href="493245v3_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where β and β<sub><italic>K</italic></sub> are the inverse temperature parameters for the action values and choice kernels respectively. Note that the term within the numerator on the right-hand side can be re-arranged:
<disp-formula id="eqn6">
<graphic xlink:href="493245v3_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Where (β + β<sub><italic>K</italic></sub>) is the effective inverse temperature parameter reflecting the exploration-exploitation balance, and <inline-formula><inline-graphic xlink:href="493245v3_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a ratio indicating the relative reliance on expected reward rather than perseveration in action selection.</p>
</sec>
<sec id="s7d">
<title>Analysis of behavioral data – belief models</title>
<p>In the <underline>belief model</underline>, the agent knows two aspects about the task structure. First, the left option can have reward probabilities of either 10% or 70%. It follows that the right option would have the other reward probability. These are the two possible hidden states of the environment. Second, the reward probabilities will reverse with a certain frequency characterized by a hazard rate, <italic>H</italic>. In each trial, the animal has a belief, which consists of the likelihood that the left option has a reward probability of 10%, <italic>ρ<sub>L10</sub></italic>, and the likelihood that the left option has a reward probability of 70%, <italic>ρ<sub>L70</sub></italic>. The constraints are that <italic>ρ<sub>L10</sub></italic> + <italic>ρ<sub>L70</sub></italic> = 1, <italic>ρ<sub>R10</sub></italic> =1 - <italic>ρ<sub>L70</sub></italic> and <italic>ρ<sub>R70</sub></italic> =1 - <italic>ρ<sub>L70</sub></italic>. At the start of a session, we set the prior as a uniform distribution, so the <italic>ρ<sub>R10</sub></italic> = <italic>ρ<sub>L70</sub></italic> = <italic>ρ<sub>prior</sub></italic> = 0.5. At the end of each trial, the belief is updated. The possibility of a reward probability switch is considered:
<disp-formula id="eqn7">
<graphic xlink:href="493245v3_eqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Similarly, <italic>ρ<sub>L70</sub></italic> is updated and then <italic>ρ<sub>L10</sub></italic> and <italic>ρ<sub>L70</sub></italic> are normalized to sum to 1. Next, inference is made based on the outcome following Bayes’ rule, which states that P (belief | observation) = P(belief) * P (observation | belief):
<disp-formula id="eqn8">
<graphic xlink:href="493245v3_eqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
or if the animal chooses right, then <italic>ρ<sub>R10</sub></italic> and <italic>ρ<sub>R70</sub></italic> would be updated instead. Again, the probabilities for the belief are normalized to sum to 1. With the updated belief, the expected rewards for the left and right options can be calculated directly, for example:
<disp-formula id="eqn9">
<graphic xlink:href="493245v3_eqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Action selection then proceeds using the same softmax equation as <xref ref-type="disp-formula" rid="eqn3">Equations 3</xref> or <xref ref-type="disp-formula" rid="eqn5">5</xref>, with the expected rewards replacing the action value terms, for the belief and belief with choice kernels models respectively. The belief model has two free parameters, <italic>H</italic> and <italic>β</italic>. The belief model with choice kernel model has four free parameters <italic>H</italic>, <italic>β</italic>, <italic>α<sub>K</sub></italic>, and β<italic><sub>K</sub></italic>.</p>
</sec>
<sec id="s7e">
<title>Parameter fitting and model evaluation</title>
<p>For each animal, trials across sessions were concatenated. The values for the free parameters were determined by fitting each model to the concatenated data using the Bayesian adaptive direct search (BADS) algorithm with default settings (<xref ref-type="bibr" rid="c1">Acerbi and Ma, 2017</xref>). The initial values for <italic>α, λ, H</italic>, <italic>α<sub>K</sub></italic>, β and <italic>β<sub>K</sub></italic> were set to 0.3, 0.3, 0.1, 0.2, 5 and 5 respectively. The lower bound of parameters were set to 0 and the upper bound was set to 100 for inverse temperatures and 1 for the rest of the parameters. To evaluate the models, we calculated the Bayes information criterion (BIC).
<disp-formula id="eqn10">
<graphic xlink:href="493245v3_eqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where N<sub>m</sub> is the number of parameters in model m. T is the number of trials used to estimate the parameters and LL is the negative log-likelihood value at the best fitting parameter settings. The model that best fits the data should have the smallest BIC score as the positive effect of the number of parameters, N<sub>m</sub>, has an explicit penalty for free parameters.</p>
<p>The parameters used for the simulated data for the belief model with choice kernel was the best-fitting parameters of one animal (H = 0.320, <italic>β</italic> = 1.387, <italic>α<sub>k</sub></italic>=0.468, <italic>β<sub>K</sub></italic> = 2.543 with 300,000 trials, approximately 9000 switches as in the experiment data). The belief model with choice kernel was used to analyze the latent variables for lesion and photostimulation data.</p>
<p>To fit the lesion data, we modified the belief-CK model. Different parameters for hazard rate and choice kernel learning rate were used depending on if the animal’s choice in the current trial is ipsilateral or contralateral to the lesion side. This yields an expanded model with 6 parameters: <italic>H<sub>lesion</sub>, H<sub>Contra</sub>, α<sub>K lesion</sub>, α<sub>K Control</sub>, β</italic>, and <italic>β<sub>K</sub></italic>. To fit the data on a per-animal basis, trials across sessions before lesion were concatenated, and trials across sessions after lesion were concatenated. To fit the data on a per-session basis, we estimated the parameters for each session.</p>
<p>To fit the optogenetics data, we modified the belief-CK model. Different parameters for hazard rate and choice kernel learning rate were used depending on if the animal’s choice in the current trial is ipsilateral or contralateral to the photostimulated side, or if the animal’s choice occurred in a control trial with no photostimulation. Different parameters for inverse temperatures were used depending on if the current trial was photostimulation or control. This yields an expanded model with 10 parameters: <italic>H<sub>ipsi stim</sub>, H<sub>Contra stim</sub>, H<sub>Control</sub>, α<sub>K ipsi stim</sub>, α<sub>K Contra stim</sub>, α<sub>K Control</sub>, β<sub>Control</sub>, β<sub>stim</sub>, β<sub>K Control</sub></italic>, and <italic>β<sub>K stim</sub></italic>. Per each animal fittings, trials across sessions for pre-choice stimulation and post-choice stimulation were concatenated. Per session fittings was not used for this dataset as total number of trials within a session did not give a reliable estimate for the ten parameters fittings.</p>
</sec>
<sec id="s7f">
<title>Statistical Analyses</title>
<p>All statistical analyses were completed using MATLAB (version 2019b, MathWorks). Three-way ANOVA was used to examine the effect of the lesion on behavioral performance. For datasets with a matched number of data points, Wilcoxon signed-rank test was used; otherwise, Wilcoxon ranked sum test was used. Unless otherwise specified, we used an alpha level of 0.05 for all statistical tests.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>We thank Neil Savalia and John-Anthony Fraga for assistance with behavioral training, Michael Siniscalchi for use of help with the behavioral apparatus, Farhan Ali for advice on histology, Lucas Pinto, Stephan Thiberge and David Tank for sharing design of photostimulation rig, and Alireza Soltani for comments on an earlier version of the analysis. This work was supported by NIH/NIMH grants R01MH112750 (A.C.K.), R21MH118596 (A.C.K.), F32NS101871 (L.P.), K99MH120047 (L.P.), China Scholarship Council-Yale World Scholars Fellowship (H.W.), Gruber Science Fellowship (H.K.O.), NIH training grant T32NS007224 (H.K.O.), and Kavli Institute for Neuroscience Postdoctoral Fellowship (H.A.).</p>
</ack>
<sec id="s8">
<title>Additional information</title>
<sec id="s8a">
<title>Author Contributions</title>
<p>H.A. and A.C.K. conceived the project. H.A. performed all surgeries. H.A. and C.E.M performed behavioral training including lesion and optogenetic inactivation experiments, and histology. H.K.O. performed the ALM inactivation experiment. H.W., H.A., and A.C.K. put together the optogenetic activation rig, based on L.P.’s plans. H.A. and A.C.K. analyzed the data and wrote the paper with input from all other authors.</p>
</sec>
<sec id="s9">
<title>Declaration of Interests</title>
<p>The authors declare no competing financial interests.</p>
</sec>
</sec>
<ref-list>
<title>Reference</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Acerbi</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Ma</surname>, <given-names>W.J</given-names></string-name>. (). .   <collab>(Nips 2017)</collab></person-group><year>2017</year>). <article-title>Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search</article-title>. <source>Advances in Neural Information Processing Systems</source> <volume>30</volume>  <fpage>30</fpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bari</surname>, <given-names>B.A.</given-names></string-name>, <string-name><surname>Grossman</surname>, <given-names>C.D.</given-names></string-name>, <string-name><surname>Lubin</surname>, <given-names>E.E.</given-names></string-name>, <string-name><surname>Rajagopalan</surname>, <given-names>A.E.</given-names></string-name>, <string-name><surname>Cressy</surname>, <given-names>J.I.</given-names></string-name>, and <string-name><surname>Cohen</surname>, <given-names>J.Y</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Stable Representations of Decision Variables for Flexible Behavior</article-title>. <source>Neuron</source> <volume>103</volume>, <fpage>922</fpage>–<lpage>933 e927</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barthas</surname>, <given-names>F.</given-names></string-name>, and <string-name><surname>Kwan</surname>, <given-names>A.C</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Secondary Motor Cortex: Where ‘Sensory’ Meets ‘Motor’ in the Rodent Frontal Cortex</article-title>. <source>Trends Neurosci</source> <volume>40</volume>, <fpage>181</fpage>–<lpage>193</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bartolo</surname>, <given-names>R.</given-names></string-name>, and <string-name><surname>Averbeck</surname>, <given-names>B.B</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Prefrontal Cortex Predicts State Switches during Reversal Learning</article-title>. <source>Neuron</source> <volume>106</volume>, <fpage>1044</fpage>–<lpage>1054 e1044</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname>, <given-names>T.E.</given-names></string-name>, <string-name><surname>Woolrich</surname>, <given-names>M.W.</given-names></string-name>, <string-name><surname>Walton</surname>, <given-names>M.E.</given-names></string-name>, and <string-name><surname>Rushworth</surname>, <given-names>M.F</given-names></string-name></person-group>. (<year>2007</year>). <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source> <volume>10</volume>, <fpage>1214</fpage>–<lpage>1221</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bennur</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Gold</surname>, <given-names>J.I</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Distinct representations of a perceptual decision and the associated oculomotor plan in the monkey lateral intraparietal area</article-title>. <source>J Neurosci</source> <volume>31</volume>, <fpage>913</fpage>–<lpage>921</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Beron</surname>, <given-names>C.C.</given-names></string-name>, <string-name><surname>Neufeld</surname>, <given-names>S.Q.</given-names></string-name>, <string-name><surname>Linderman</surname>, <given-names>S.W.</given-names></string-name>, and <string-name><surname>Sabatini</surname>, <given-names>B.L</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Mice exhibit stochastic and efficient action switching during probabilistic decision making</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>119</volume>, <fpage>e2113961119</fpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clarke</surname>, <given-names>H.F.</given-names></string-name>, <string-name><surname>Robbins</surname>, <given-names>T.W.</given-names></string-name>, and <string-name><surname>Roberts</surname>, <given-names>A.C</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Lesions of the medial striatum in monkeys produce perseverative impairments during reversal learning similar to those produced by lesions of the orbitofrontal cortex</article-title>. <source>J Neurosci</source> <volume>28</volume>, <fpage>10972</fpage>–<lpage>10982</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Costa</surname>, <given-names>V.D.</given-names></string-name>, <string-name><surname>Tran</surname>, <given-names>V.L.</given-names></string-name>, <string-name><surname>Turchi</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Averbeck</surname>, <given-names>B.B</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Reversal learning and dopamine: a bayesian perspective</article-title>. <source>J Neurosci</source> <volume>35</volume>, <fpage>2407</fpage>–<lpage>2416</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Donahue</surname>, <given-names>C.H.</given-names></string-name>, and <string-name><surname>Lee</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Dynamic routing of task-relevant signals for decision making in dorsolateral prefrontal cortex</article-title>. <source>Nat Neurosci</source> <volume>18</volume>, <fpage>295</fpage>–<lpage>301</lpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Evers</surname>, <given-names>E.A.</given-names></string-name>, <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>van der Veen</surname>, <given-names>F.M.</given-names></string-name>, <string-name><surname>Jolles</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Sahakian</surname>, <given-names>B.J.</given-names></string-name>, and <string-name><surname>Robbins</surname>, <given-names>T.W.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Serotonergic modulation of prefrontal cortex during negative feedback in probabilistic reversal learning</article-title>. <source>Neuropsychopharmacology</source> <volume>30</volume>, <fpage>1138</fpage>–<lpage>1147</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gallistel</surname>, <given-names>C.R.</given-names></string-name>, <string-name><surname>Mark</surname>, <given-names>T.A.</given-names></string-name>, <string-name><surname>King</surname>, <given-names>A.P.</given-names></string-name>, and <string-name><surname>Latham</surname>, <given-names>P.E</given-names></string-name></person-group>. (<year>2001</year>). <article-title>The rat approximates an ideal detector of changes in rates of reward: Implications for the law of effect</article-title>. <source>Journal of Experimental Psychology-Animal Behavior Processes</source> <volume>27</volume>, <fpage>354</fpage>–<lpage>372</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Groman</surname>, <given-names>S.M.</given-names></string-name>, <string-name><surname>Keistler</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Keip</surname>, <given-names>A.J.</given-names></string-name>, <string-name><surname>Hammarlund</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>DiLeone</surname>, <given-names>R.J.</given-names></string-name>, <string-name><surname>Pittenger</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>D.</given-names></string-name>, and <string-name><surname>Taylor</surname>, <given-names>J.R</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Orbitofrontal Circuits Control Multiple Reinforcement-Learning Processes</article-title>. <source>Neuron</source>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Groman</surname>, <given-names>S.M.</given-names></string-name>, <string-name><surname>Rich</surname>, <given-names>K.M.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>N.J.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>D.</given-names></string-name>, and <string-name><surname>Taylor</surname>, <given-names>J.R</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Chronic Exposure to Methamphetamine Disrupts Reinforcement-Based Decision Making in Rats</article-title>. <source>Neuropsychopharmacology</source> <volume>43</volume>, <fpage>770</fpage>–<lpage>780</lpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Grossman</surname>, <given-names>C.D.</given-names></string-name>, <string-name><surname>Bari</surname>, <given-names>B.A.</given-names></string-name>, and <string-name><surname>Cohen</surname>, <given-names>J.Y</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Serotonin neurons modulate learning rate through uncertainty</article-title>. <source>Curr Biol</source> <volume>32</volume>, <fpage>586</fpage>–<lpage>599 e587</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname>, <given-names>Z.V.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Huber</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Ophir</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Gutnisky</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Ting</surname>, <given-names>J.T.</given-names></string-name>, <string-name><surname>Feng</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>Svoboda</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Flow of cortical activity underlying a tactile decision in mice</article-title>. <source>Neuron</source> <volume>81</volume>, <fpage>179</fpage>–<lpage>194</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hamid</surname>, <given-names>A.A.</given-names></string-name>, <string-name><surname>Pettibone</surname>, <given-names>J.R.</given-names></string-name>, <string-name><surname>Mabrouk</surname>, <given-names>O.S.</given-names></string-name>, <string-name><surname>Hetrick</surname>, <given-names>V.L.</given-names></string-name>, <string-name><surname>Schmidt</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Vander Weele</surname>, <given-names>C.M.</given-names></string-name>, <string-name><surname>Kennedy</surname>, <given-names>R.T.</given-names></string-name>, <string-name><surname>Aragona</surname>, <given-names>B.J.</given-names></string-name>, and <string-name><surname>Berke</surname>, <given-names>J.D</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Mesolimbic dopamine signals the value of work</article-title>. <source>Nat Neurosci</source> <volume>19</volume>, <fpage>117</fpage>–<lpage>126</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hattori</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Danskin</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Babic</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Mlynaryk</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Komiyama</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Area-Specificity and Plasticity of History-Dependent Value Coding During Learning</article-title>. <source>Cell</source> <volume>177</volume>, <fpage>1858</fpage>–<lpage>1872 e1815</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ito</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Doya</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Validation of decision-making models and analysis of decision variables in the rat basal ganglia</article-title>. <source>J Neurosci</source> <volume>29</volume>, <fpage>9861</fpage>–<lpage>9874</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ito</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Doya</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Parallel Representation of Value-Based and Finite State-Based Strategies in the Ventral and Dorsal Striatum</article-title>. <source>PLoS Comput Biol</source> <volume>11</volume>, <fpage>e1004540</fpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jang</surname>, <given-names>A.I.</given-names></string-name>, <string-name><surname>Nassar</surname>, <given-names>M.R.</given-names></string-name>, <string-name><surname>Dillon</surname>, <given-names>D.G.</given-names></string-name>, and <string-name><surname>Frank</surname>, <given-names>M.J</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Positive reward prediction errors during decision-making strengthen memory encoding</article-title>. <source>Nat Hum Behav</source> <volume>3</volume>, <fpage>719</fpage>–<lpage>732</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Karlsson</surname>, <given-names>M.P.</given-names></string-name>, <string-name><surname>Tervo</surname>, <given-names>D.G.</given-names></string-name>, and <string-name><surname>Karpova</surname>, <given-names>A.Y</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Network resets in medial prefrontal cortex mark the onset of behavioral uncertainty</article-title>. <source>Science</source> <volume>338</volume>, <fpage>135</fpage>–<lpage>139</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Laubach</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Amarante</surname>, <given-names>L.M.</given-names></string-name>, <string-name><surname>Swanson</surname>, <given-names>K.</given-names></string-name>, and <string-name><surname>White</surname>, <given-names>S.R</given-names></string-name>. ().   , <collab>ENEURO.0315-0318.2018</collab></person-group><year>2018</year>). <article-title>What, If Anything, Is Rodent Prefrontal Cortex?</article-title> <source>eNeuro</source> <volume>5</volume>, .</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>Y.</given-names></string-name>, and <string-name><surname>Dudman</surname>, <given-names>J.T</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Mice infer probabilistic models for timing</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>110</volume>, <fpage>17154</fpage>–<lpage>17159</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liao</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Kwan</surname>, <given-names>A.C.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Applying Reinforcement Learning to Rodent Stress Research</article-title>. <source>Chronic Stress (Thousand Oaks)</source> <volume>5</volume>, <fpage>2470547020984732</fpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Xin</surname>, <given-names>Y.</given-names></string-name>, and <string-name><surname>Xu</surname>, <given-names>N.-l.</given-names></string-name></person-group> (<year>2021</year>). <article-title>A cortical circuit mechanism for structural knowledge-based flexible sensorimotor decision-making</article-title>. <source>Neuron</source> <volume>109</volume>, <fpage>2009</fpage>–<lpage>2024.e2006</lpage>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Doherty</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Kringelbach</surname>, <given-names>M.L.</given-names></string-name>, <string-name><surname>Rolls</surname>, <given-names>E.T.</given-names></string-name>, <string-name><surname>Hornak</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Andrews</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Abstract reward and punishment representations in the human orbitofrontal cortex</article-title>. <source>Nat Neurosci</source> <volume>4</volume>, <fpage>95</fpage>–<lpage>102</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Otchy</surname>, <given-names>T.M.</given-names></string-name>, <string-name><surname>Wolff</surname>, <given-names>S.B.</given-names></string-name>, <string-name><surname>Rhee</surname>, <given-names>J.Y.</given-names></string-name>, <string-name><surname>Pehlevan</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Kawai</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kempf</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gobes</surname>, <given-names>S.M.</given-names></string-name>, and <string-name><surname>Olveczky</surname>, <given-names>B.P</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Acute off-target effects of neural circuit manipulations</article-title>. <source>Nature</source> <volume>528</volume>, <fpage>358</fpage>–<lpage>363</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pinto</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Rajan</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>DePasquale</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Thiberge</surname>, <given-names>S.Y.</given-names></string-name>, <string-name><surname>Tank</surname>, <given-names>D.W.</given-names></string-name>, and <string-name><surname>Brody</surname>, <given-names>C.D</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Task-Dependent Changes in the Large-Scale Dynamics and Necessity of Cortical Regions</article-title>. <source>Neuron</source> <volume>104</volume>, <fpage>810</fpage>–<lpage>824 e819</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pisupati</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Chartarifsky-Lynn</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Khanal</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Churchland</surname>, <given-names>A.K</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Lapses in perceptual decisions reflect exploration</article-title>. <source>Elife</source> <volume>10</volume>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Samejima</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Ueda</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Doya</surname>, <given-names>K.</given-names></string-name>, and <string-name><surname>Kimura</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2005</year>). <article-title>Representation of action-specific reward values in the striatum</article-title>. <source>Science</source> <volume>310</volume>, <fpage>1337</fpage>–<lpage>1340</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Siniscalchi</surname>, <given-names>M.J.</given-names></string-name>, <string-name><surname>Phoumthipphavong</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Ali</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Lozano</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Kwan</surname>, <given-names>A.C</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Fast and slow transitions in frontal ensemble activity during flexible sensorimotor behavior</article-title>. <source>Nat Neurosci</source> <volume>19</volume>, <fpage>1234</fpage>–<lpage>1242</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Siniscalchi</surname>, <given-names>M.J.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>H.</given-names></string-name>, and <string-name><surname>Kwan</surname>, <given-names>A.C</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Enhanced Population Coding for Rewarded Choices in the Medial Frontal Cortex of the Mouse</article-title>. <source>Cereb Cortex</source> <volume>29</volume>, <fpage>4090</fpage>–<lpage>4106</lpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Soltani</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Izquierdo</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Adaptive learning under expected and unexpected uncertainty</article-title>. <source>Nat Rev Neurosci</source> <volume>20</volume>, <fpage>635</fpage>–<lpage>644</lpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Starkweather</surname>, <given-names>C.K.</given-names></string-name>, <string-name><surname>Babayan</surname>, <given-names>B.M.</given-names></string-name>, <string-name><surname>Uchida</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Gershman</surname>, <given-names>S.J</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Dopamine reward prediction errors reflect hidden-state inference across time</article-title>. <source>Nature Neuroscience</source> <volume>20</volume>, <fpage>581</fpage>–<lpage>589</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Starkweather</surname>, <given-names>C.K.</given-names></string-name>, <string-name><surname>Gershman</surname>, <given-names>S.J.</given-names></string-name>, and <string-name><surname>Uchida</surname>, <given-names>N.</given-names></string-name></person-group> (<year>2018</year>). <article-title>The Medial Prefrontal Cortex Shapes Dopamine Reward Prediction Errors under State Uncertainty</article-title>. <source>Neuron</source> <volume>98</volume>, <fpage>616</fpage>-<lpage>629 e616</lpage>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sul</surname>, <given-names>J.H.</given-names></string-name>, <string-name><surname>Jo</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>D.</given-names></string-name>, and <string-name><surname>Jung</surname>, <given-names>M.W</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Role of rodent secondary motor cortex in value-based action selection</article-title>. <source>Nat Neurosci</source> <volume>14</volume>, <fpage>1202</fpage>–<lpage>1208</lpage>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sul</surname>, <given-names>J.H.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Huh</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>D.</given-names></string-name>, and <string-name><surname>Jung</surname>, <given-names>M.W</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Distinct roles of rodent orbitofrontal and medial prefrontal cortex in decision making</article-title>. <source>Neuron</source> <volume>66</volume>, <fpage>449</fpage>–<lpage>460</lpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Sutton</surname>, <given-names>R.S.</given-names></string-name>, and <string-name><surname>Barto</surname>, <given-names>A.G.</given-names></string-name></person-group> (<year>2018</year>). <source>Reinforcement Learning: An Introduction</source> (<edition>2nd Edition</edition>) (<publisher-name>MIT Press</publisher-name>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tai</surname>, <given-names>L.H.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>A.M.</given-names></string-name>, <string-name><surname>Benavidez</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Bonci</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Wilbrecht</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Transient stimulation of distinct subpopulations of striatal neurons mimics changes in action value</article-title>. <source>Nat Neurosci</source> <volume>15</volume>, <fpage>1281</fpage>–<lpage>1289</lpage>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tsuchida</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Doll</surname>, <given-names>B.B.</given-names></string-name>, and <string-name><surname>Fellows</surname>, <given-names>L.K</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Beyond reversal: a critical role for human orbitofrontal cortex in flexible learning from probabilistic feedback</article-title>. <source>J Neurosci</source> <volume>30</volume>, <fpage>16868</fpage>–<lpage>16875</lpage>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vaidya</surname>, <given-names>A.R.</given-names></string-name>, <string-name><surname>Pujara</surname>, <given-names>M.S.</given-names></string-name>, <string-name><surname>Petrides</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Murray</surname>, <given-names>E.A.</given-names></string-name>, and <string-name><surname>Fellows</surname>, <given-names>L.K</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Lesion Studies in Contemporary Neuroscience</article-title>. <source>Trends Cogn Sci</source> <volume>23</volume>, <fpage>653</fpage>–<lpage>671</lpage>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vertechi</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Lottem</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Sarra</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Godinho</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Treves</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Quendera</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Oude Lohuis</surname>, <given-names>M.N.</given-names></string-name>, and <string-name><surname>Mainen</surname>, <given-names>Z.F</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Inference-Based Decisions in a Hidden State Foraging Task: Differential Contributions of Prefrontal Cortical Areas</article-title>. <source>Neuron</source> <volume>106</volume>, <fpage>166</fpage>–<lpage>176.e166</lpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Villiamma</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Casby</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Groman</surname>, <given-names>S.M</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Adolescent reinforcement-learning trajectories predict cocaine-taking behaviors in adult male and female rats</article-title>. <source>Psychopharmacology (Berl)</source> <volume>239</volume>, <fpage>2885</fpage>–<lpage>2901</lpage>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Ortega</surname>, <given-names>H.K.</given-names></string-name>, <string-name><surname>Atilgan</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Murphy</surname>, <given-names>C.E.</given-names></string-name>, and <string-name><surname>Kwan</surname>, <given-names>A.C</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Pupil Correlates of Decision Variables in Mice Playing a Competitive Mixed-Strategy Game</article-title>. <source>eNeuro</source> <volume>9</volume>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname>, <given-names>R.C.</given-names></string-name>, and <string-name><surname>Collins</surname>, <given-names>A.G</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Ten simple rules for the computational modeling of behavioral data</article-title>. <source>Elife</source> <volume>8</volume>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname>, <given-names>R.C.</given-names></string-name>, <string-name><surname>Nassar</surname>, <given-names>M.R.</given-names></string-name>, and <string-name><surname>Gold</surname>, <given-names>J.I</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Bayesian online learning of the hazard rate in change-point problems</article-title>. <source>Neural Comput</source> <volume>22</volume>, <fpage>2452</fpage>–<lpage>2476</lpage>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Woo</surname>, <given-names>J.H.</given-names></string-name>, <string-name><surname>Aguirre</surname>, <given-names>C.G.</given-names></string-name>, <string-name><surname>Bari</surname>, <given-names>B.A.</given-names></string-name>, <string-name><surname>Tsutsui</surname>, <given-names>K.I.</given-names></string-name>, <string-name><surname>Grabenhorst</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>J.Y.</given-names></string-name>, <string-name><surname>Schultz</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Izquierdo</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Soltani</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Mechanisms of adjustments to different types of uncertainty in the reward environment across mice and monkeys</article-title>. <source>Cogn Affect Behav Neurosci</source>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname>, <given-names>J.H.</given-names></string-name>, and <string-name><surname>Kwan</surname>, <given-names>A.C</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Secondary motor cortex: Broadcasting and biasing animal’s decisions through long-range circuits</article-title>. <source>Int Rev Neurobiol</source> <volume>158</volume>, <fpage>443</fpage>–<lpage>470</lpage>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yin</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Guo</surname>, <given-names>Z.V</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Lateralization of short-term memory in the frontal cortex</article-title>. <source>Cell Rep</source> <volume>40</volume>, <fpage>111190</fpage>.</mixed-citation></ref>
</ref-list>
<sec id="s10">
<title>Supplementary Information</title>
<fig id="figs1-1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 1.1:</label>
<caption><title>Animal’s choice behavior around block switches with different performance criteria</title>
<p>(A) The equation for the switching condition, or block length (BL), which is the sum of L<sub>criterion</sub> and L<sub>Random</sub>. (B) Choice behavior around block switches, plotted separately for 4 ranges of BL. Mean values and SEM for all animals. All data were included. (C) Similar to (B), including data in which L<sub>criterion</sub> ≤ 20 trials. (D) Choice behavior around block switches, plotted separately for 4 ranges of L<sub>Random</sub>. Mean values and SEM for all animals. All data were included. (E) Similar to (C), including data in which L<sub>criterion</sub> ≤ 50 trials.</p></caption>
<graphic xlink:href="493245v3_figs1-1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs1-2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 1.2:</label>
<caption><title>Animal’s choice behavior in a task variant without L<sub>criterion</sub></title>
<p>(A) Choice behavior around block switches in a task variant without L<sub>criterion</sub>. All the trial timing and reward probabilities are identical, except the switching condition consists of only L<sub>Random</sub>. Thin line, mean values for individual animal. Thick line, mean values and SEM for all animals.</p><p>(B) Histogram of L<sub>Random.</sub> for all blocks. Colors indicate the 4 ranges of L<sub>Random</sub> for subsequent analyses. (C) Choice behavior around block switches, plotted separately for the 4 ranges of L<sub>Random</sub>. Mean values and SEM for all animals. (D) The probability of choosing the better option on the trial immediately preceding the switch, as a function of L<sub>Random</sub> for the block preceding the switch (in 2 datapoints bin; main effect of L<sub>Random</sub>: F (14, 204) = 1.8068, <italic>P</italic> = 0.0394 one-way ANOVA) Mean values and SEM for all animals. (E) The number of trials to reach midpoint (when animal is equally likely to choose either option) as a function of L<sub>Random</sub> for the block preceding the switch (in 2 datapoints bin; main effect of L<sub>Random</sub>: F (14, 120) = 1.0734, <italic>P</italic> = 0.3883 one-way ANOVA). Mean values and SEM for all animals. n = 10 mice, 48 sessions, 312 blocks.</p></caption>
<graphic xlink:href="493245v3_figs1-2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2-1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 2.1:</label>
<caption><title>No decrease in overall performance after unilateral lesion of ACAd/Mos</title>
<p>The total number of trials and block switches per session before (pre) and after (post) the unilateral lesion.</p></caption>
<graphic xlink:href="493245v3_figs2-1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2-2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 2.2:</label>
<caption><title>No motor deficits after unilateral lesion of ACAd/Mos</title>
<p>Mean left and right lick density for each possible combination for choice (left or right) and outco e (reward or no reward). No significant difference was detected between pre- and post-unilateral lesion.</p></caption>
<graphic xlink:href="493245v3_figs2-2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3-1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 3.1:</label>
<caption><title>Belief-CK model: effect of varying the hazard rate</title>
<p>The belief-CK model was used to simulate an agent’s choice behavior in the two-armed bandit task with probabilistic reward reversal. Parameters were selected based on the best fitting values from an animal. Each column shows the results using a different hazard rate (= 0.01, 0.25, 0.5, 0.75, 1) while all other parameters were kept constant (n = 300,000 trials, = 1.387, =0.468, = 2.543). Top row shows the mean fraction of trials choosing the better and worse options for 4 different L<sub>Random</sub> ranges for 10 trials before and after the block switch. Middle row shows the P (better option) <sub>pre-switch</sub> as a function of L<sub>Random</sub>. Mean and SEM. Bottom row shows the mean number of trials to reach midpoint as a function of L<sub>Random</sub>.</p></caption>
<graphic xlink:href="493245v3_figs3-1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3-2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 3.2:</label>
<caption><title>Belief-CK model: effect of varying choice kernel learning rate.</title>
<p>Similar to <xref ref-type="fig" rid="figs3-1">Supplementary Figure 3.1</xref>, with different choice kernel learning rates (= 0.01, 0.25, 0.5, 0.75, 1) while all other parameters were kept constant (n = 300,000 trials, = 0.320, = 1.387, = 2.543).</p></caption>
<graphic xlink:href="493245v3_figs3-2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3-3" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 3.3:</label>
<caption><title>Belief-CK model: effect of varying beta sum.</title>
<p>Similar to <xref ref-type="fig" rid="figs3-1">Supplementary Figure 3.1</xref>, with different beta sum (= 0, 1, 3, 5, 10) while all other parameters were kept constant (n = 300,000 trials, = 0.320, = 0.468). was set to equal to.</p></caption>
<graphic xlink:href="493245v3_figs3-3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3-4" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 3.4:</label>
<caption><title>Belief-CK model: effect of varying beta ratio.</title>
<p>Similar to <xref ref-type="fig" rid="figs3-1">Supplementary Figure 3.1</xref>, with different beta ratios (0.01, 0.25, 0.5, 0.75, 1) while all other parameters were kept constant (n = 300,000 trials, = 0.320, =0.468, = 2.543). was fixed and was calculated based on the beta ratio values.</p></caption>
<graphic xlink:href="493245v3_figs3-4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3-5" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 3.5:</label>
<caption><title>DF-Q-RPE algorithm cannot reproduce the L<sub>Random</sub>-dependent trends in the experimental data.</title>
<p><bold>(A)</bold> The probability of choosing the better option on the trial immediately preceding the switch, as a function of L<sub>Random</sub> for the block preceding the switch. Black, mice. Purple, simulated performance using the DF-Q-RPE model with best-fitting parameters. Mean values and SEM for all animals. <bold>(B)</bold> Similar to (A) for number of trials to reach midpoint (when animal is equally likely to choose either option). <bold>(C)</bold> Similar to (A) for the tendency to win-stay on the 5 trials preceding the switch. <bold>(D)</bold> Similar to (A) for the tendency to lose-switch on the 5 trials preceding the switch. Mean and SEM. n = 31 mice, 617 sessions.</p></caption>
<graphic xlink:href="493245v3_figs3-5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs5-1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 5.1:</label>
<caption><title>Fewer trials but similar performance after bilateral lesion of ACAd/Mos</title>
<p>The total number of left- and right-responding trials, reward rates, and hit rates before (pre) and after (post) the lesion.</p></caption>
<graphic xlink:href="493245v3_figs5-1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs5-2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 5.2:</label>
<caption><title>No motor deficits after bilateral lesion of ACAd/Mos</title>
<p>Mean left and right lick density for each possible combination for choice (left or right) and outco e (reward or no reward). No significant difference was detected between pre- and post-bilateral lesion.</p></caption>
<graphic xlink:href="493245v3_figs5-2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs6-1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 6.1:</label>
<caption><title>Validation of the laser steering system for optogenetic manipulation: characterization and c-Fos staining</title>
<p>(A) Optical transmission of the clear skull cap preparation was measured by illuminating with a laser and recording intensity using a power meter. Mean and SEM. n = 5. (B) Linearity of the galvanometers in the x and y directions. (C) Beam profile was measured at the sample plane by inserting and moving a razor blade across the plane using a micromanipulator. (D - F) In <italic>CaMKIIa<sup>Cre</sup>;Ai32</italic> animals, cortical excitatory neurons express ChR2. After unilateral photostimulation of the left ACAd/MOs region (40 Hz, 1.5 mW, 1 min on then 1 min off repeatedly for 20 min), immunohistostaining with a c-Fos antibody showed elevated signals.</p></caption>
<graphic xlink:href="493245v3_figs6-1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs6-2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 6.2:</label>
<caption><title>Inactivating left and right ALM during two-armed bandit task</title>
<p><bold>(A)</bold> In <italic>Pvalb<sup>Cre</sup>;Ai32</italic> animals, parvalbumin-expressing neurons including fast-spiking interneurons in the neocortex express ChR2. Photostimulation of a brain region drives spiking in the interneurons, which in turn suppresses excitatory activity. Lick raster recorded in an example session, in which trials were sorted based on the photostimulation (None: no stimulation; ALM-L: left anterior lateral motor cortex, AP=2.5 mm, ML=-1.5 mm; ALM-R: right anterior lateral motor cortex, AP=2.5 mm, ML=1.5 mm; V1-L: left primary visual cortex, AP=-2.7 mm, ML=-2.5 mm; V1-R: right primary visual cortex, AP=-2.7 mm, ML=2.5 mm). <bold>(B)</bold> The number of trials of each type per session. <bold>(C)</bold> Percent of trials resulted in a miss, as a function of trial type. <bold>(D)</bold> Percent of trials resulted in a left response, as a function of trial type. <bold>(E)</bold> Percent of trials resulted in a right response, as a function of trial type. These results show that transient inactivation of ALM increased ipsilateral responses at the expense of contralateral responses. 9 sessions from 3 animals.</p></caption>
<graphic xlink:href="493245v3_figs6-2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<table-wrap id="tbls2-1" orientation="portrait" position="float">
<label>Supplementary Table 2.1:</label>
<caption><p>The results of three-way between-subjects ANOVA with factors of lesion (pre- and post-lesion), side (lesion blocks and Contra blocks), and L<sub>Random</sub> (4 L<sub>Random</sub> ranges) for P(better option)<sub>pre-switch</sub>, trials to reach midpoint and hit rates. p &lt; 0.05 in bold. All dependent variables calculated for each block across sessions. (Error = 3285; 2399; 3285; 3285; 2816;3187 for P (better option) <sub>pre-switch</sub>, trials to reach midpoint and hit rates respectively</p></caption>
<graphic xlink:href="493245v3_tbls2-1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbls5-1" orientation="portrait" position="float">
<label>Supplementary Table 5.1:</label>
<caption><p>The results of two-way between-subjects ANOVA for bilaterally injected animals with factors of lesion (pre- and post-lesion and L<sub>Random</sub> (4 L<sub>Random</sub> ranges) for P(better option) <sub>pre-switch</sub>, trials to reach midpoint and hit rates. p &lt; 0.05 in bold. All dependent variables calculated for each block across sessions. (Error = 1356;911;1356; for P (better option) <sub>pre-switch</sub>, trials to reach midpoint and hit rates respectively</p></caption>
<graphic xlink:href="493245v3_tbls5-1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbls5-2" orientation="portrait" position="float">
<label>Supplementary Table 5.2:</label>
<caption><p>The results of two-way between-subjects ANOVA for saline injected animals with factors of lesion (pre- and post-lesion and L<sub>Random</sub> (4 L<sub>Random</sub> ranges) for P (better option) <sub>pre-switch</sub>, trials to reach midpoint, hit rates, P(lose | switch), P(win | stay). p &lt; 0.05 in bold. All dependent variables calculated for each block across sessions. (Error = 1871;1217; 1871 for P (better option) <sub>pre-switch</sub>, trials to reach midpoint and hit rates respectively.</p></caption>
<graphic xlink:href="493245v3_tbls5-2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103001.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Erlich</surname>
<given-names>Jeffrey</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Sainsbury Wellcome Centre</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Inadequate</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study examined the role of the dorsal medial prefrontal cortex of mice in anticipating reward-value switch points in a two-armed bandit task. They demonstrate the dorsal medial prefrontal cortex is involved in task performance and use model-based methods to uncover the algorithmic processes affected by prefrontal cortex perturbations. If the claims were supported, this would be a <bold>valuable</bold> finding. Unfortunately, the reviewers recognised significant issues with the task design and analyses, making the evidence to support the role of the prefrontal cortex in anticipation of switches <bold>inadequate</bold>.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103001.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this manuscript, the authors train mice on a two-armed bandit task, in which the reward value associated with the arms suddenly switches in a pseudorandom fashion. Their first finding is that the mice are able to anticipate the reward value switch points after long blocks, evident both prior to the switch point with higher rates of switching to the less-rewarded arm, and after the switch point with faster transition to the more-rewarded arm. They next find that unilateral ACAd/MO lesion / optogenetic silencing (surprisingly) causes greater anticipation of reward switch points, both prior to and after the switch point. They use behavioral modeling to argue that the unilateral ACAd/MO lesion effects are due to an increase in the contralateral hazard rate. Finally, they found that bilateral lesions did not have any effect on the hazard rate, suggesting that the unilateral lesion effect is due to balancing between hemispheres. This manuscript employed a clever behavioral design and analysis approach, though the effects were somewhat difficult to interpret and the author's interpretation relies heavily on the accuracy of their underlying behavioral model.</p>
<p>Strengths:</p>
<p>This paper employs a well-designed task that allows the researchers to detect whether mice have noticed a change in reward value both before and after the change takes place. The use of unilateral and bilateral inactivation experiments allowed the authors to test the role of the ACAd/MO region in the change point estimation. They found that unilateral inactivation, but not bilateral inactivation, had a significant effect on behavior. They performed sophisticated behavioral analysis to determine how ACAd/MO perturbations affect decision-making variables. This topic is of interest to the field, and the results are presented clearly and generally convincing.</p>
<p>Weaknesses:</p>
<p>The observed effects of the lesions are somewhat counterintuitive, with lesions appearing to affect persistence within a block more than change point detection itself-the mice actually adjusted more quickly to changes in reward values. Moreover, they had no issue detecting change points after bilateral inactivation. As a result, I'm not sure if the main framing of the article (including the title) is supported by their findings. Finally, I was unsure how the differences between unilateral and bilateral inactivation could be explained by their behavioral model.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103001.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The manuscript by Murphy et al. titled &quot;Change point estimation by the mouse medial prefrontal cortex during probabilistic reward learning&quot; investigated the role of the mPFC in the exploitation of task structure. Previous work had shown that monkeys and humans exploit predictable task structures (e.g., switching rapidly when heavily trained a reversal learning task), but whether this was also the case for mice was not known. To test this, Murphy et al. trained head-fixed mice on a two-armed bandit task in which the contingencies reversed when mice met a performance criterion (10 trials choosing the better option) plus an additional random number of trials (referred to as Lrandom). They found that as the length of Lrandom increased, mice began to exhibit pre-emptive switching in their choices as if they were expecting and/or anticipating the reversal to occur. They report that unilateral lesions of the mPFC (ACC + MO) led to earlier pre-emptive switching (although I found this part of the manuscript the most challenging to understand) and faster post-reversal switching that they argue reflects an impairment in the proper estimation of the reversal. They also report that this requires inter-hemispheric coordination because bilateral lesions did not further impair this estimation. Optogenetic inhibition just prior to the mouse making a choice recapitulated some of the behavioral metrics observed in the mPFC lesioned animals. Finally, the authors developed a novel hybrid belief-choice kernel model to provide a computational approach to quantifying these behavioral differences.</p>
<p>Strengths:</p>
<p>The paper is extremely well written and was an absolute pleasure to read. The results are novel and provide exciting (although not surprising) evidence that mice exploit task structures to earn rewards. Moreover, the experiments were well-designed and included appropriate controls and/or control conditions that support their findings.</p>
<p>Weaknesses:</p>
<p>Some of the results need to be clarified and/or language changed to ensure that readers will understand. Restricting analyses to expert mice that show the predicted effect is problematic.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103001.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors examine the role of the medial frontal cortex of mice in exploiting statistical structure in tasks. They claim that mice are &quot;proactive&quot;: they predict upcoming changes, rather than responding in a &quot;model-free&quot; way to environmental changes. Further, they speculate that the estimation of future change (i.e., prediction of upcoming events, based on learning temporal regularities) might be &quot;a main ... function of dorsal medial frontal cortex (dmFC).&quot; Unfortunately, the current manuscript contains flaws such that the evidence supporting these claims is inadequate.</p>
<p>Strengths:</p>
<p>Understanding the neural mechanisms by which we learn about statistical structure in the world is an important goal. The authors developed an interesting task and used model-based techniques to try to understand the mechanisms by which perturbation of dmFC influenced behavior. They demonstrate that lesions and optogenetic silencing of dmFC influence behavior, showing that this region has a causal influence on the task.</p>
<p>Weaknesses:</p>
<p>I was concerned that the main behavioral effects shown in Figure 1F were a statistical artifact. By requiring the Geometric block length to be preceded by a performance-based block, the authors introduce a dependence that can generate the phenomena they describe as anticipation.</p>
<p>To demonstrate this, I simulated their task with an agent that does not have any anticipation of the change point (Reviewer image 1). The agent repeats the previous action with probability `p(repeat)` (similar to the choice kernel in the author's models). If the agent doesn't repeat then the next choice depends on the previous outcome. If the previous choice was rewarded, it stays with `P(WS)` and chooses randomly with `1-P(WS)`. If the previous choice was unrewarded, it switches with `P(LS)` and chooses randomly with `1-P(LS)`.</p>
<fig id="sa3fig1">
<label>Review image 1.</label>
<graphic mime-subtype="jpg" xlink:href="elife-103001-sa3-fig1.jpg" mimetype="image"/>
</fig>
<p>An agent with `P(WS)=P(LS)=P(repeat)=0.85` shows the same phenomena as the mice: a difference in performance before the block switch and &quot;earlier&quot; crossing of the midpoint after the switch. <ext-link ext-link-type="uri" xlink:href="https://imgdrop.io/image/aHn6y">https://imgdrop.io/image/aHn6y</ext-link>. The phenomena go away in the simulations when a fixed block length of 20 trials is followed by a Geometric block length.</p>
<p>The authors did not completely rely on the phenomena of Figure 1F for their conclusions. They did a model comparison to provide evidence that animals are anticipating the switch. Unfortunately, the authors did not use state-of-the-art methods in this section of the paper. In particular, they failed to show that under a range of generative parameters for each model class, the model selection process chooses the correct model class (i.e. a confusion matrix). A more minor point, they used BIC instead of a more robust cross-validated metric for model selection. Finally, instead of comparing their &quot;best&quot; anticipating model to their 2nd best model (without anticipation), they compared their best to their 4th best (Supp Fig 3.5). This seems misleading.</p>
<p>Given all of the the above issues, it is hard to critically evaluate the model-based analysis of the effects of lesions/optogenetics.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103001.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Murphy</surname>
<given-names>Cayla E</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wang</surname>
<given-names>Hongli</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ortega</surname>
<given-names>Heather K</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kwan</surname>
<given-names>Alex C</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2169-1667</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Atilgan</surname>
<given-names>Huriye</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8582-4815</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We appreciate the reviewers' thoughtful and constructive comments. In this provisional response, we aim to address what we see as the key critiques, with a detailed, point-by-point reply to be provided alongside the revised manuscript. Below, we outline how we intend to address these critiques in the revised manuscript.</p>
<p>(1) We will revise sections of the manuscript to ensure that all results, particularly those concerning the effects of lesions, are described more clearly and with sufficient context. This includes providing additional visualizations and rewording any ambiguous statements.</p>
<p>(2) In this study, we examined a subset of 7,396 blocks where animals quickly adapted after block switches (achieving LCriterion in 20 or fewer trials), thereby focusing on expert-level performance and avoiding periods that might be affected by low motivation. It is valid to question whether the same observations would hold if the full dataset were analyzed. To address this, we expanded our analysis to include a supplementary figure Supplementary Figure 1.1 that illustrate the same relationships based on block length (BL) instead of LRandom, both with and without the restriction on LCriterion (n = 9,156 blocks in which the block length is under 100 trials, without any LCriterion restrictions), and based on LRandom without any LCriterion restrictions and with a less stringent LCriterion restriction (with ≤ 50 Trials for the criterion). This method allowed us to include all trials in our dataset. We observed similar effects of block length on choice behavior around switches (Figure 3), confirming the consistency of our findings across different analytical conditions.</p>
<p>(3) We agree that robust validation of model selection is crucial. To address this, we will generate a confusion matrix to assess whether our model selection process accurately identifies the correct model class across a range of generative parameters. Include additional model selection metrics, such as cross-validation, to complement the BIC analysis and provide a more robust comparison of models.</p>
<p>(4) We acknowledge the concern regarding our comparison of the &quot;best&quot; and the &quot;4th best&quot; models. The &quot;4th best&quot; model was chosen because it is the most widely recognized in the literature. Our intention was to demonstrate the performance of the most commonly used model, but we understand how this may have been misleading. To address this, we will revise our comparison to focus on the &quot;best&quot; and the &quot;2nd best&quot; models, ensuring greater clarity in the manuscript. Additionally, we will include supplementary simulation results and figures to provide a more comprehensive analysis on models.</p>
</body>
</sub-article>
</article>