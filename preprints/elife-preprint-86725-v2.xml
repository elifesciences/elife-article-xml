<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">86725</article-id>
<article-id pub-id-type="doi">10.7554/eLife.86725</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.86725.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>From recency to central tendency biases in working memory: a unifying network model</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2476-8714</contrib-id>
<name>
<surname>Boboeva</surname>
<given-names>Vezha</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8998-7942</contrib-id>
<name>
<surname>Pezzotta</surname>
<given-names>Alberto</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4507-8648</contrib-id>
<name>
<surname>Clopath</surname>
<given-names>Claudia</given-names>
</name>
<email>c.clopath@imperial.ac.uk</email>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5711-0903</contrib-id>
<name>
<surname>Akrami</surname>
<given-names>Athena</given-names>
</name>
<email>athena.akrami@ucl.ac.uk</email>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Sainsbury Wellcome Centre, University College London</institution></aff>
<aff id="a2"><label>2</label><institution>Department of Bioengineering, Imperial College London</institution></aff>
<aff id="a3"><label>3</label><institution>Gatsby Computational Neuroscience Unit, University College London</institution></aff>
<aff id="a4"><label>4</label><institution>The Francis Crick Institute</institution></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Sharpee</surname>
<given-names>Tatyana O</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Salk Institute for Biological Studies</institution>
</institution-wrap>
<city>La Jolla</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="others"><label>*</label><p>These authors jointly supervised this work</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-08-02">
<day>02</day>
<month>08</month>
<year>2023</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2024-01-05">
<day>05</day>
<month>01</month>
<year>2024</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP86725</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-03-09">
<day>09</day>
<month>03</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-01-27">
<day>27</day>
<month>01</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.05.16.491352"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2023-08-02">
<day>02</day>
<month>08</month>
<year>2023</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.86725.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.86725.1.sa2">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.86725.1.sa1">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.86725.1.sa0">Reviewer #2 (Public Review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Boboeva et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Boboeva et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-86725-v2.pdf"/>
<abstract>
<title>Abstract</title>
<p>The central tendency bias, or contraction bias, is a phenomenon where the judgment of the magnitude of items held in working memory appears to be biased towards the average of past observations. It is assumed to be an optimal strategy by the brain, and commonly thought of as an expression of the brain’s ability to learn the statistical structure of sensory input. On the other hand, recency biases such as serial dependence are also commonly observed, and are thought to reflect the content of working memory. Recent results from an auditory delayed comparison task in rats, suggest that both biases may be more related than previously thought: when the posterior parietal cortex (PPC) was silenced, both short-term and contraction biases were reduced. By proposing a model of the circuit that may be involved in generating the behavior, we show that a volatile working memory content susceptible to shifting to the past sensory experience – producing short-term sensory history biases – naturally leads to contraction bias. The errors, occurring at the level of individual trials, are sampled from the full distribution of the stimuli, and are not due to a gradual shift of the memory towards the sensory distribution’s mean. Our results are consistent with a broad set of behavioral findings and provide predictions of performance across different stimulus distributions and timings, delay intervals, as well as neuronal dynamics in putative working memory areas. Finally, we validate our model by performing a set of human psychophysics experiments of an auditory parametric working memory task.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>We have added a new Section 1.5 together with Fig.5.
We revised Fig. 3F &amp; 7E since we found a minor mistake in one of our analysis codes that computed the n-trial back biases for different delay intervals; correcting the error made the effects clearer.
We revised Fig. 8 to include human data
We revised Fig. S2 to include phase diagram
In the previous version, the colorbar reported the incorrect fraction classified in Figs 1B, 2C, 7B (new 8B), S2C, S3A, S5B. We have corrected this in this version of the manuscript.</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/vboboeva/ParametricWorkingMemory_Data">https://github.com/vboboeva/ParametricWorkingMemory_Data</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>A fundamental question in neuroscience relates to how brains efficiently process the statistical regularities of the environment to guide behavior. Exploiting such regularities may be of great value to survival in the natural environment, but may lead to biases in laboratory tasks. Repeatedly observed across species and sensory modalities is the central tendency (“contraction”) bias, where performance in perceptual tasks seemingly reflects a shift of the working memory representation towards the mean of the sensory history [<xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c6">6</xref>]. Equally common are sequential biases, either attractive or repulsive, towards the immediate sensory history [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c8">8</xref>–<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c15">15</xref>].</p>
<p>It is commonly thought that these biases occur due to disparate mechanisms - contraction bias is widely thought to be a result of learning the statistical structure of the environment, whereas serial biases are thought to reflect the contents of working memory [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>]. Recent evidence, however, challenges this picture: our recent study of a parametric working memory task discovered that the rat posterior parietal cortex (PPC) plays a key role in modulating contraction bias [<xref ref-type="bibr" rid="c7">7</xref>]. When the region is optogenetically inactivated, contraction bias is attenuated. Intriguingly, however, this is also accompanied by the suppression of bias effects induced by the recent history of the stimuli, suggesting that the two phenomena may be interrelated. Interestingly, other behavioral components, including working memory of immediate sensory stimuli (in the current trial), remain intact. In another recent study with humans, a double dissociation was reported between three cohorts of subjects: subjects on the autistic spectrum (ASD) expressed reduced biases due to recent statistics, whereas dyslexic subjects (DYS) expressed reduced biases towards long-term statistics, relative to neurotypical subjects (NT) [<xref ref-type="bibr" rid="c16">16</xref>]. Finally, further complicating the picture is the observation of not only attractive serial dependency, but also repulsive biases [<xref ref-type="bibr" rid="c18">18</xref>]. It is as of yet unclear how such biases occur and what mechanisms underlie such history dependencies.</p>
<p>These findings stimulate the question of whether contraction bias and the different types of serial biases are actually related, and if so, how. Although normative models have been proposed to explain these effects [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c16">16</xref>], the neural mechanisms and circuits underlying them remain poorly understood. We address this question through a model of the putative circuit involved in giving rise to the behavior observed in [<xref ref-type="bibr" rid="c7">7</xref>]. Our model consists of two continuous (bump) attractor sub-networks, representing a working memory (WM) module and the PPC. Given the finding that PPC neurons carry more information about stimuli presented during previous trials, the PPC module integrates inputs over a longer timescale relative to the WM network, and incorporates firing rate adaptation.</p>
<p>We find that both contraction bias and short-term sensory history effects emerge in the WM network as a result of inputs from the PPC network. Importantly, we see that these effects do not necessarily occur due to separate mechanisms. Rather, in our model, contraction bias emerges as a statistical effect of errors in working memory, occurring due to the persisting memory of stimuli shown in the preceding trials. The integration of this persisting memory in the WM module competes with that of the stimulus in the current trial, giving rise to short-term history effects. We conclude that contraction biases in such paradigms may not necessarily reflect explicit learning of regularities or an “attraction towards the mean”, on individual trials. Rather, it may be an effect emerging at the level of average performance, when in each trial, errors are made according to the recent sensory experiences whose distribution follow that of the input stimuli. Furthermore, using the same model, we also show that the biases towards long-term (short-term) statistics inferred from the performance of ASD (DYS) subjects [<xref ref-type="bibr" rid="c16">16</xref>] may actually reflect short-term biases extending more or less into the past with respect to NT subjects, challenging the hypothesis of a double-dissociation mechanism. Last, we show that as a result of neuronal integration of inputs and adaptation, in addition to attraction effects occurring on a short timescale, repulsion effects are observed on a longer timescale [<xref ref-type="bibr" rid="c18">18</xref>].</p>
<p>We make specific predictions on neuronal dynamics in the PPC and downstream working memory areas, as well as how contraction bias may be altered, upon manipulations of the sensory stimulus distribution, inter-trial and inter-stimulus delay intervals. We show agreements between the model and our previous results in humans and rats. Finally, we test our model predictions by performing new human auditory parametric working memory tasks. The data is in agreement with our model and not with an aternative Bayesian model.</p>
</sec>
<sec id="s2">
<label>1</label>
<title>Results</title>
<sec id="s2a">
<label>1.1</label>
<title>The PPC as a slower integrator network</title>
<p>Parametric working memory (PWM) tasks involve the sequential comparison of two graded stimuli that differ along a physical dimension and are separated by a delay interval of a few seconds (<xref rid="fig1" ref-type="fig">Fig. 1 A</xref> and <xref ref-type="fig" rid="fig1">B</xref>) [<xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c19">19</xref>]. A key feature emerging from these studies is contraction bias, where the averaged performance is as if the memory of the first stimulus progressively shifts towards the center of a prior distribution built from past sensory history (<xref rid="fig1" ref-type="fig">Fig. 1 C</xref>). Additionally, biases towards the most recent sensory stimuli (immediately preceding trials) have also been documented [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c5">5</xref>].</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>The PPC as a slower integrator network.</title>
<p><bold>(A)</bold> In any given trial, a pair of stimuli (here, sounds) separated by a variable delay interval is presented to a subject. After the second stimulus, and after a go cue, the subject must decide which of the two sounds is louder by pressing a key (humans) or nose-poking in an appropriate port (rats). <bold>(B)</bold> The stimulus set. The stimuli are linearly separable, and stimulus pairs are equally distant from the <italic>s</italic><sub>1</sub> = <italic>s</italic><sub>2</sub> diagonal. Error-free performance corresponds to network dynamics from which it is possible to classify all the stimuli below the diagonal as <italic>s</italic><sub>1</sub> <italic>&gt; s</italic><sub>2</sub> (shown in blue) and all stimuli above the diagonal as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub> (shown in red). An example of a correct trial can be seen in (E). In order to assay the psychometric threshold, several additional pairs of stimuli are included (purple box), where the distance to the diagonal <italic>s</italic><sub>1</sub> = <italic>s</italic><sub>2</sub> is systematically changed. The colorbar expresses the fraction classified as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. <bold>(C)</bold> Schematics of contraction bias in delayed comparison tasks. Performance is a function of the difference between the two stimuli, and is impacted by contraction bias, where the base stimulus <italic>s</italic><sub>1</sub> is perceived as closer to the mean stimulus. This leads to a better/worse (green/red area) performance, depending on whether this “attraction” increases (Bias+) or decreases (Bias-) the discrimination between the base stimulus <italic>s</italic><sub>1</sub> and the comparison stimulus <italic>s</italic><sub>2</sub>. <bold>(D)</bold> Our model is composed of two modules, representing working memory (WM), and sensory history (PPC). Each module is a continuous one-dimensional attractor network. Both networks are identical except for the timescales over which they integrate external inputs; PPC has a significantly longer integration timescale and its neurons are additionally equipped with neuronal adaptation. The neurons in the WM network receive input from those in the PPC, through connections (red lines) between neurons coding for the same stimulus. Neurons (gray dots) are arranged according to their preferential firing locations. The excitatory recurrent connections between neurons in each network are a symmetric, decreasing function of their preferential firing locations, whereas the inhibitory connections are uniform (black lines). For simplicity, connections are shown for a single pre-synaptic neuron (where there is a bump in green). When a sufficient amount of input is given to a network, a bump of activity is formed, and sustained in the network when the external input is subsequently removed. This activity in the WM network is read out at two time points: slightly before and after the onset of the second stimulus, and is used to assess performance. <bold>(E)</bold> The task involves the comparison of two sequentially presented stimuli, separated by a delay interval (top panel, black lines). The WM network integrates and responds to inputs quickly (middle panel), while the PPC network integrates inputs more slowly (bottom panel). As a result, external inputs (corresponding to stimulus 1 and 2) are enough to displace the bump of activity in the WM network, but not in the PPC. Instead, inputs coming from the PPC into the WM network are not sufficient to displace the activity bump, and the trial is consequently classified as correct. In the PPC, instead, the activity bump corresponds to a stimulus shown in previous trials.</p></caption>
<graphic xlink:href="491352v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In order to investigate the circuit mechanisms by which such biases may occur, we use two identical one-dimensional continuous attractor networks to model WM and PPC modules. Neurons are arranged according to their preferential firing locations in a continuous stimulus space, representing the amplitude of auditory stimuli. Excitatory recurrent connections between neurons are symmetric and a monotonically decreasing function of the distance between the preferential firing fields of neurons, allowing neurons to mutually excite one another; inhibition, instead, is uniform. Together, both allow a localized bump of activity to form and be sustained (<xref rid="fig1" ref-type="fig">Fig. 1 D</xref> and <xref ref-type="fig" rid="fig1">E</xref>) [<xref ref-type="bibr" rid="c21">21</xref>–<xref ref-type="bibr" rid="c29">29</xref>]. Both networks have free boundary conditions. Neurons in the WM network receive inputs from neurons in the PPC coding for the same stimulus amplitude (<xref rid="fig1" ref-type="fig">Fig. 1 D</xref>). Building on experimental findings [<xref ref-type="bibr" rid="c30">30</xref>–<xref ref-type="bibr" rid="c35">35</xref>], we designed the PPC network such that it integrates activity over a longer timescale compared to the WM network (<xref ref-type="sec" rid="s4a">Sect. 3.1</xref>). Moreover, neurons in the PPC are equipped with neural adaptation, that can be thought of as a threshold that dynamically follows the activation of a neuron over a longer timescale.</p>
<p>To simulate the parametric WM task, at the beginning of each trial, the network is provided with a stimulus <italic>s</italic><sub>1</sub> for a short time via an external current <italic>I</italic><sub>ext</sub> as input to a set of neurons (see <xref ref-type="table" rid="tbl1">Tab. 1</xref>). Following <italic>s</italic><sub>1</sub>, after a delay interval, a second stimulus <italic>s</italic><sub>2</sub> is presented (<xref rid="fig1" ref-type="fig">Fig. 1 E</xref>). The pair (<italic>s</italic><sub>1</sub>, <italic>s</italic><sub>2</sub>) is drawn from the stimulus set shown in <xref rid="fig1" ref-type="fig">Fig. 1 B</xref>, where they are all equally distant from the diagonal <italic>s</italic><sub>1</sub> = <italic>s</italic><sub>2</sub>, and are therefore of equal nominal discrimination, or difficulty. The stimuli (<italic>s</italic><sub>1</sub>, <italic>s</italic><sub>2</sub>) are co-varied in each trial so that the task cannot be solved by relying on only one of the stimuli [<xref ref-type="bibr" rid="c36">36</xref>]. As in the study in Ref. [<xref ref-type="bibr" rid="c7">7</xref>] using an interleaved design, across consecutive trials, the inter-stimulus delay intervals are randomized and sampled uniformly between 2, 6 and 10 seconds. The inter-trial interval, instead, is fixed at 5 seconds.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p>Simulation parameters, when not explicitly mentioned. Used to produce <xref rid="fig1" ref-type="fig">Figs. 1</xref>, <xref rid="fig2" ref-type="fig">2</xref>, <xref rid="fig3" ref-type="fig">3</xref>, <xref rid="fig4" ref-type="fig">4</xref>, <xref rid="fig5" ref-type="fig">5</xref>, <xref rid="fig8" ref-type="fig">8</xref>, <xref ref-type="fig" rid="figS2">S2</xref>, <xref ref-type="fig" rid="figS3">S3</xref>, <xref ref-type="fig" rid="figS5">S5</xref>.</p></caption>
<graphic xlink:href="491352v3_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>We additionally include psychometric pairs (indicated in the box in <xref rid="fig1" ref-type="fig">Fig. 1 B</xref>) where the distance to the diagonal, hence the discrimination difficulty, is varied. The task is a binary comparison task that aims at classifying whether <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub> or vice-versa. In order to solve the task, we record the activity of the WM network at two time points: slightly before and after the onset of <italic>s</italic><sub>2</sub> (<xref rid="fig1" ref-type="fig">Fig. 1 E</xref>). We repeat this procedure across many different trials, and use the recorded activity to assess performance (see (<xref ref-type="sec" rid="s4b">Sect. 3.2</xref>) for details). Importantly, at the end of each trial, the activity of both networks is not re-initialized, and the state of the network at the end of the trial serves as the initial network configuration for the next trial.</p>
</sec>
<sec id="s2b">
<label>1.2</label>
<title>Contraction bias and short-term stimulus history effects as a result of PPC network activity</title>
<p>Probing the WM network performance on psychometric stimuli (<xref rid="fig1" ref-type="fig">Fig. 1 B</xref>, purple box, 10% of all trials) shows that the comparison behavior is not error-free, and that the psychometric curves (different colors) differ from the optimal step function (<xref rid="fig2" ref-type="fig">Fig. 2 A</xref>, green dashed line). The performance on pychometric trials is also better for shorter inter-stimulus delay intervals, as has been shown in previous work [<xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c7">7</xref>]. In our model, errors are caused by the displacement of the activity bump in the WM network, due to the inputs from the PPC network. These displacements in the WM activity bump can result in different outcomes: by displacing it <italic>away</italic> from the second stimulus, they either do not affect the performance or improve it (<xref rid="fig2" ref-type="fig">Fig. 2 B</xref> right panel, “Bias+”), if noise is present. Conversely, the performance can suffer, if the displacement of the activity bump is <italic>towards</italic> the second stimulus (<xref rid="fig2" ref-type="fig">Fig. 2 B</xref> left panel, “Bias-”). Note, however, that in these two specific trials, the activity bump in PPC is strong, and it displaces the activity bump in the WM network, but this is not the only kind of dynamics present in the network (see <xref ref-type="sec" rid="s2c">Sect.1.3</xref> for a more detailed analysis of the network dynamics).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Contraction bias and short-term sensory history effects as a result of PPC network activity.</title>
<p><bold>(A)</bold> Performance of network model for psychometric stimuli (colored lines) is not error-free (green dashed lines). A shorter inter-stimulus delay interval yields a better performance. <bold>(B)</bold> Errors occur due to the displacement of the bump representing the first stimulus <italic>s</italic><sub>1</sub> in the WM network. Depending on the direction of this displacement with respect to <italic>s</italic><sub>2</sub>, this can give rise to trials in which the comparison task becomes harder (easier), leading to negative (positive) biases (top and bottom panels). Top sub-panel: stimuli presented to both networks in time. Middle/ bottom sub-panels show activity of WM and PPC networks (in green). <bold>(C)</bold> Left: performance is affected by contraction bias – a gradual accumulation of errors for stimuli below (above) the diagonal upon increasing (decreasing) <italic>s</italic><sub>1</sub>. Colorbar indicates fraction of trials classified as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. Middle and Right: for comparison, data from the auditory version of the task performed in humans and rats. Data from Ref. [<xref ref-type="bibr" rid="c7">7</xref>]. <bold>(D)</bold> Panel 1: For each combination of current (x-axis) and previous trial’s stimulus pair (y-axis), fraction of trials classified as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub> (colorbar). Performance is affected by preceding trial’s stimulus pair (modulation along the y-axis). For readability, only some tick-labels are shown. Panel 2: bias, quantifying the (attractive) effect of previous stimulus pairs. Colored lines correspond to linear fits of this bias for each pair of stimuli in the current trial. Black dots correspond to average over all current stimuli, and black line is a linear fit. These history effects are attractive: the smaller the previous stimulus, the higher the probability of classifying the first stimulus of the current trial <italic>s</italic><sub>1</sub> as small, and vice-versa. Panel 3: human auditory trials. Percentage of trials in which humans chose left for each combination of current and previous stimuli; vertical modulation indicates attractive effect of preceding trial. Panel 4: Percentage of trials in which humans chose left minus the average value of left choices, as a function of the stimuli of the previous trial, for fixed previous trial response choice and reward. Panel 5 and 6: same as panels 3 and 4 but with rat auditory trials. Data from Ref. [<xref ref-type="bibr" rid="c7">7</xref>]. <bold>(E)</bold> Top: performance of network, when the weights from the PPC to the WM network is weakened, is improved for psychometric stimuli (yellow curve), relative to the intact network (black curve). Bottom: psychometric curves for rats (only shown for one rat) are closer to error-free during PPC inactivation (yellow) than during control trials (black). <bold>(F)</bold> Left: the attractive bias due to the effect of the previous trial is present with the default weights (black line), but is eliminated with reduced weights (yellow line). Right: while there is bias induced by previous stimuli in the control experiment (black), this bias is reduced under PPC inactivation (yellow). Experimental figures reproduced with permission from Ref.[<xref ref-type="bibr" rid="c7">7</xref>].</p></caption>
<graphic xlink:href="491352v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Performance on stimulus pairs that are equally distant from the <italic>s</italic><sub>1</sub> = <italic>s</italic><sub>2</sub> diagonal can be similarly impacted and the network produces a pattern of errors that is consistent with contraction bias: performance is at its minimum for stimulus pairs in which <italic>s</italic><sub>1</sub> is either largest or smallest, and at its maximum for stimulus pairs in which <italic>s</italic><sub>2</sub> is largest or smallest (<xref rid="fig2" ref-type="fig">Fig. 2 C</xref>, left panel) [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c40">40</xref>]. These results are consistent with the performance of humans and rats on the auditory task, as previously reported (<xref rid="fig2" ref-type="fig">Fig. 2 C</xref>, middle and right panels, data from Akrami et al 2018 [<xref ref-type="bibr" rid="c7">7</xref>]).</p>
<p>Can the same circuit also give rise to short-term sensory history biases [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c41">41</xref>]? We analyzed the fraction of trials the network response was “<italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>” in the current trial conditioned on stimulus pairs presented in the previous trial, and we found that the network behavior is indeed modulated by the preceding trial’s stimulus pairs (<xref rid="fig2" ref-type="fig">Fig. 2 D</xref>, panel 1). We quantified these history effects as well as how many trials back they extend to. We computed the bias by plotting, for each particular pair (of stimuli) presented at the current trial, the fraction of trials the network response was “<italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>” as a function of the pair presented in the previous trial minus the mean performance over all previous trial pairs (<xref rid="fig2" ref-type="fig">Fig. 2 D</xref>, panel 2) [<xref ref-type="bibr" rid="c7">7</xref>]. Independent of the current trial, the previous trial exerts an “attractive” effect, expressed by the negative slope of the line: when the previous pair of stimuli is small, <italic>s</italic><sub>1</sub> in the current trial is, on average, misclassified as smaller than it actually is, giving rise to the attractive bias in the comparison performance; the converse holds true when the previous pair of stimuli happens to be large. These effects extend to two trials back, and are consistent with the performance of humans and rats on the auditory task (<xref rid="fig2" ref-type="fig">Fig. 2 D</xref>, panels 3-6, data from Akrami et al 2018 [<xref ref-type="bibr" rid="c7">7</xref>]).</p>
<p>It has been shown that inactivating the PPC, in rats performing the auditory delayed comparison task, markedly reduces the magnitude of contraction bias, without impacting non-sensory biases [<xref ref-type="bibr" rid="c7">7</xref>]. We assay the causal role of the PPC in generating the sensory history effects as well as contraction bias by weakening the connections from the PPC to the WM network, mimicking the inactivation of the PPC. In this case, we see that the performance for the psychometric stimuli is greatly improved (yellow curve, <xref rid="fig2" ref-type="fig">Fig. 2 E</xref>, top panel), consistent also with the inactivation of the PPC in rodents (yellow curve, <xref rid="fig2" ref-type="fig">Fig. 2 E</xref>, bottom panel, data from Akrami et al 2018 [<xref ref-type="bibr" rid="c7">7</xref>]). Performance is improved also for all pairs of stimuli in the stimulus set (<xref rid="figS3" ref-type="fig">Fig. S3 A</xref>). The breakdown of the network response in the current trial conditioned on the specific stimulus pair preceding it reveals that the previous trial no longer exerts a notable modulating effect on the current trial (<xref rid="figS3" ref-type="fig">Fig. S3 B</xref>). Quantifying this bias by subtracting the mean performance over all of the previous pairs reveals that the attractive bias is virtually eliminated (yellow curve, <xref rid="fig2" ref-type="fig">Fig. 2 F</xref>, left panel), consistent with findings in rats (<xref rid="fig2" ref-type="fig">Fig. 2 F</xref>, right panel, data from Akrami et al 2018 [<xref ref-type="bibr" rid="c7">7</xref>]).</p>
<p>Together, our results suggest a possible circuit through which both contraction bias and short-term history effects in a parametric working memory task may arise. The main features of our model are two continuous attractor networks, both integrating the same external inputs, but operating over different timescales. Crucially, the slower one, a model of the PPC, includes neuronal adaptation, and provides input to the faster one, intended as a WM circuit. In the next section, we show how the slow integration and firing rate adaptation in the PPC network give rise to the observed effects of sensory history.</p>
</sec>
<sec id="s2c">
<label>1.3</label>
<title>Multiple timescales at the core of short-term sensory history effects</title>
<p>The activity bumps in the PPC and WM networks undergo different dynamics, due to the different timescales with which they integrate inputs, the presence of adaptation in the PPC, and the presence of global inhibition. The WM network integrates inputs over a shorter timescale, and therefore the activity bump follows the external input with high fidelity (<xref rid="fig3" ref-type="fig">Fig. 3 A</xref> (purple bumps) and B (purple line)). The PPC network, instead, has a longer integration timescale, and therefore fails to sufficiently integrate the input to induce a displacement of the bump to the location of a new stimulus, at each single trial. This is mainly due to the competition between the inputs from the recurrent connections sustaining the bump, and the external stimuli that are integrated elsewhere: if the former is stronger, the bump is not displaced. If, however, these inputs are weaker, they will not displace it, but may still exert a weakening effect via the global inhibition in the connectivity. The external input, as well as the presence of adaptation (<xref rid="figS1" ref-type="fig">Fig. S1 B</xref> and <xref ref-type="fig" rid="figS1">C</xref>) induce a small continuous drift of the activity bump that is already present from the previous trials (lower right panel of <xref rid="fig2" ref-type="fig">Fig. 2 B</xref>, <xref rid="fig3" ref-type="fig">Fig. 3 A</xref> (pink bumps) and B (pink line)). The build-up of adaptation in the PPC network, combined with the global inhibition from other neurons receiving external inputs, can extinguish the bump in that location (see also <xref rid="figS1" ref-type="fig">Fig. S1</xref> for more details). Following this, the PPC network can make a transition to an incoming stimulus position (that may be either <italic>s</italic><sub>1</sub> or <italic>s</italic><sub>2</sub>), and a new bump is formed. The resulting dynamics in the PPC are a mixture of slow drift over a few trials, followed by occasional jumps (<xref rid="fig3" ref-type="fig">Fig. 3 A</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Multiple timescales at the core of short-term sensory history effects.</title>
<p><bold>(A)</bold> Schematics of activity bump dynamics in the WM vs PPC network. Whereas the WM responds quickly to external inputs, the bump in the PPC drifts slowly and adapts, until it is extinguished and a new bump forms. <bold>(B)</bold> The location of the activity bump in both the PPC (pink line) and the WM (purple line) networks, immediately before the onset of the second stimulus <italic>s</italic><sub>2</sub> of each trial. This location corresponds to the amplitude of the stimulus being encoded. The bump in the WM network closely represents the stimulus <italic>s</italic><sub>1</sub> (shown in colored dots, each color corresponding to a different delay interval). The PPC network, instead, being slower to integrate inputs, displays a continuous drift of the activity bump across a few trials, before it jumps to a new stimulus location, due to the combined effect of inhibition from incoming inputs and adaptation that extinguishes previous activity. <bold>(C)</bold> Fraction of trials in which the bump location corresponds to the base stimulus that has been presented <inline-formula><inline-graphic xlink:href="491352v3_inline36.gif" mimetype="image" mime-subtype="gif"/></inline-formula> in the current trial, as well as the two preceding trials <inline-formula><inline-graphic xlink:href="491352v3_inline37.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. In the WM network, in the majority of trials, the bump coincides with the first stimulus of the current trial <inline-formula><inline-graphic xlink:href="491352v3_inline38.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. In a smaller fraction of the trials, it corresponds to the previous stimulus <inline-formula><inline-graphic xlink:href="491352v3_inline39.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, due to the input from the PPC. In the PPC network instead, a smaller fraction of trials consist of the activity bump coinciding with the current stimulus <inline-formula><inline-graphic xlink:href="491352v3_inline40.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Relative to the WM network, the bump is more likely to coincide with the previous trial’s comparison stimulus <inline-formula><inline-graphic xlink:href="491352v3_inline41.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. <bold>(D)</bold> During the inter-stimulus delay interval, in the absence of external sensory inputs, the activity bump in the WM network is mainly sustained endogenously by the recurrent inputs. It may, however, be destabilized by the continual integration of inputs from the PPC. <bold>(E)</bold> As a result, with an increasing delay interval, given that more errors are made, contraction bias increases. Green (orange) bars correspond to the performance in Bias+ (Bias-) regions, relative to the mean performance over all pairs (<xref ref-type="fig" rid="fig1">Fig. 1 C</xref>). <bold>(F)</bold> Left and middle: longer delay intervals allow for a longer integration times which in turn lead to a larger frequency of WM disruptions due to previous trials, leading to a larger previous-trial attractive biases (2<italic>s</italic> vs. 6<italic>s</italic> vs. 10<italic>s</italic>). Right: Weak repulsive effects for larger delays become apparent. Colored dots correspond to the bias computed for different values of the inter-stimulus delay interval, while colored lines correspond to their linear fits. <bold>(G)</bold> When neuronal adaptation is at its lowest in the PPC i.e. following a bump jump, the WM bump is maximally susceptible to inputs from the PPC. The attractive bias (towards previous stimuli) is present in trials in which the PPC network underwent a jump in the previous trial (black triangles, with black line a linear fit). Such biases are absent in trials where no jumps occur in the PPC in the previous trial (black dots, with dashed line a linear fit). Colored lines correspond to bias for specific pairs of stimuli in the current trial, regular lines for the jump condition, and dashed for the no jump condition.</p></caption>
<graphic xlink:href="491352v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As a result of such dynamics, relative to the WM network, the activity bump in the PPC represents the stimuli corresponding to the current trial in a smaller fraction of the trials, and represents stimuli presented in the previous trial in a larger fraction of the trials (<xref rid="fig3" ref-type="fig">Fig. 3 C</xref>). This yields short-term sensory history effects in our model (<xref rid="fig2" ref-type="fig">Fig. 2 D</xref>, and <xref ref-type="fig" rid="fig2">E</xref>), as input from the PPC lead to the displacement of the WM bump to other locations (<xref rid="fig3" ref-type="fig">Fig. 3 D</xref>). Given that neurons in the WM network integrate this input, once it has built up sufficiently, it can surpass the self-sustaining inputs from the recurrent connections in the WM network. The WM bump, then, can move to a new location, given by the position of the bump in the PPC (<xref rid="fig3" ref-type="fig">Fig. 3 D</xref>). As the input from the PPC builds up gradually, the probability of bump displacement in WM increases over time. This in return leads to an increased probability of contraction bias (<xref rid="fig3" ref-type="fig">Fig. 3 E</xref>), and short-term history (one-trial back) biases (<xref rid="fig3" ref-type="fig">Fig. 3 F</xref>), as the inter-stimulus delay interval increases.</p>
<p>Additionally, a non-adapted input from the PPC has a larger likelihood of displacing the WM bump. This is highest immediately following the formation of a new bump in the PPC, or in other words, following a “bump jump” (<xref rid="fig3" ref-type="fig">Fig. 3 F</xref>). As a result, one can reason that those trials immediately following a jump in the PPC are the ones that should yield the maximal bias towards stimuli presented in the previous trial. We therefore separated trials according to whether or not a jump has occurred in the PPC in the preceding trial (we define a jump to have occurred if the bump location across two consecutive trials in the PPC is displaced by an amount larger than the typical width of the bump (<xref ref-type="sec" rid="s4a">Sect. 3.1</xref>)). In line with this reasoning, only the set that included trials with jumps in the preceding trial yields a one-trial back bias (<xref rid="fig3" ref-type="fig">Fig. 3 G</xref>).</p>
<p>Removing neuronal adaptation entirely from the PPC network further corroborates this result. In this case, the network dynamics show a very different behavior: the activity bump in the PPC undergoes a smooth drift (<xref rid="figS2" ref-type="fig">Fig. S2 A</xref>), and the bump distribution is much more peaked around the mean (<xref rid="figS2" ref-type="fig">Fig. S2 B</xref>), relative to when adaptation is present (<xref rid="fig4" ref-type="fig">Fig. 4 A</xref>). In this regime, there are no jumps in the PPC (<xref rid="figS2" ref-type="fig">Fig. S2 A</xref>), and the activity bump corresponds to the stimuli presented in the previous trial in a fewer fraction of the trials (<xref rid="figS2" ref-type="fig">Fig. S2 C</xref>), relative to when adaptation is present (<xref rid="fig3" ref-type="fig">Fig. 3 B</xref>). As a result, no short-term history effects can be observed (<xref rid="figS2" ref-type="fig">Fig. S2 C</xref> and <xref ref-type="fig" rid="figS2">D</xref>), even though a strong contraction bias persists (<xref rid="figS2" ref-type="fig">Fig. S2 E</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Errors are drawn from the marginal distribution of stimuli, giving rise to contraction bias.</title>
<p><bold>(A)</bold> The bump locations in both the WM network (in pink) and the PPC network (in purple) have identical distributions to that of the input stimulus (marginal over <italic>s</italic><sub>1</sub> or <italic>s</italic><sub>2</sub>, shown in gray). <bold>(B)</bold> A simple mathematical model illustrates how contraction bias emerges as a result of a volatile working memory for <italic>s</italic><sub>1</sub>. A given trial consists of two stimuli <inline-formula><inline-graphic xlink:href="491352v3_inline42.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="491352v3_inline43.gif" mimetype="image" mime-subtype="gif"/></inline-formula> . We assume that the encoding of the second stimulus <inline-formula><inline-graphic xlink:href="491352v3_inline44.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is error-free, contrary to the first stimulus that is prone to change, with probability <italic>ϵ</italic>. Furthermore, when <italic>s</italic><sub>1</sub> does change, it is replaced by another stimulus, <italic>ŝ</italic> (imposed by the input from the PPC in our network model). Therefore, <italic>ŝ</italic> is drawn from the marginal distribution of bump locations in the PPC, which is similar to the marginal stimulus distribution (see panel B), <italic>p</italic><sub><italic>m</italic></sub> (see also <xref ref-type="sec" rid="s5b">Sect. 4.2</xref>). Depending on the new location of <italic>ŝ</italic>, the comparison to <italic>s</italic><sub>2</sub> can either lead to an erroneous choice (Bias-, with probability <italic>p</italic><sub><italic>e</italic></sub>) or a correct one (Bias+, with probability <italic>p</italic><sub><italic>c</italic></sub> = 1− <italic>p</italic><sub><italic>e</italic></sub>). <bold>(C)</bold> The distribution of bump locations in PPC (from which replacements <italic>ŝ</italic> are sampled) is overlaid on the stimulus set, and repeated for each value of <italic>s</italic><sub>2</sub>. For pairs below the diagonal, where <italic>s</italic><sub>1</sub> <italic>&gt; s</italic><sub>2</sub> (blue squares), the trial outcome will be an error if the displaced WM bump <italic>ŝ</italic> ends up above the diagonal (red section of the <italic>p</italic><sub><italic>m</italic></sub> distribution). The probability to make an error, <italic>p</italic><sub><italic>e</italic></sub>, equals the integral of <italic>p</italic><sub><italic>m</italic></sub> over values above the diagonal (red part), which increases as <italic>s</italic><sub>1</sub> increases. Vice versa, for pairs above the diagonal (<italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>, red squares), <italic>p</italic><sub><italic>e</italic></sub> equals the integral of <italic>p</italic><sub><italic>m</italic></sub> over values below the diagonal, which increases as <italic>s</italic><sub>1</sub> decreases. <bold>(D)</bold> The performance of the attractor network as a function of the first stimulus <italic>s</italic><sub>1</sub>, in red dots for pairs of stimuli where <italic>s</italic><sub>1</sub> <italic>&gt; s</italic><sub>2</sub>, and in blue dots for pairs of stimuli where <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. The solid lines are fits of the performance of the network using <xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>, with <italic>ϵ</italic> as a free parameter. <bold>(E)</bold> Numbers correspond to the performance, same as in (D), while colors expresses the fraction classified as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub> (colorbar), to illustrate the contraction bias. <bold>(F)</bold> Performance of rats performing the auditory delayed-comparison task in Ref.[<xref ref-type="bibr" rid="c7">7</xref>]. Dots correspond to the empirical data, while the lines are fits with the statistical model, using the distribution of stimuli. The additional parameter <italic>δ</italic> captures the lapse rate. <bold>(G)</bold> Same as (F), but with humans performing the task. Data in (F) and (G) reproduced with permission from Ref.[<xref ref-type="bibr" rid="c7">7</xref>].</p></caption>
<graphic xlink:href="491352v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As in the study in Ref.[<xref ref-type="bibr" rid="c7">7</xref>], we can further study the impact of the PPC on the dynamics of the WM network by weakening the weights from the PPC to the WM network, mimicking the inactivation of PPC (<xref rid="fig2" ref-type="fig">Fig. 2 E</xref> and <xref ref-type="fig" rid="fig2">F</xref>, <xref rid="figS3" ref-type="fig">Fig. S3 A</xref> and <xref ref-type="fig" rid="figS3">B</xref>). Under this manipulation, the trajectory of the activity bump in the WM network immediately before the onset of the second stimulus <italic>s</italic><sub>2</sub> closely follows the external input, consistent with an enhanced WM function (<xref rid="figS3" ref-type="fig">Fig. S3 C</xref> and <xref ref-type="fig" rid="figS3">D</xref>).</p>
<p>The drift-jump dynamics in our model of the PPC give rise to short-term (notably one and two-trial back) sensory history effects in the performance of the WM network. In addition, we observe an equally salient contraction bias (bias towards the sensory mean) in the WM network’s performance, increasing with the delay period (<xref rid="fig3" ref-type="fig">Fig. 3 E</xref>). However, we find that the activity bump in both the WM and the PPC network corresponds to the mean over all stimuli in only a small fraction of trials, expected by chance (<xref rid="fig3" ref-type="fig">Fig. 3 B</xref>, see <xref ref-type="sec" rid="s5a">Sect. 4.1</xref> for how it is calculated). Rather, the bump is located more often at the current trial stimulus <inline-formula><inline-graphic xlink:href="491352v3_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and to a lesser extent, at the location of stimuli presented at the previous trial <inline-formula><inline-graphic xlink:href="491352v3_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. As a result, contraction bias in our model cannot be attributed to the representation of the running sensory average in the PPC. In the next section, we show how contraction bias arises as an averaged effect, when single trial errors occur due to short-term sensory history biases.</p>
</sec>
<sec id="s2d">
<label>1.4</label>
<title>Errors are drawn from the marginal distribution of stimuli, giving rise to contraction bias</title>
<p>In order to illustrate the statistical origin of contraction bias in our network model, we consider a mathematical scheme of its performance (<xref rid="fig4" ref-type="fig">Fig. 4 B</xref>). In this simple formulation, we assume that the first stimulus to be kept in working memory, <inline-formula><inline-graphic xlink:href="491352v3_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, is volatile. As a result, in a fraction <italic>ϵ</italic> of the trials, it is susceptible to replacement with another stimulus <italic>ŝ</italic> (by the input from the PPC, that has a given distribution <italic>p</italic><sub><italic>m</italic></sub> (<xref rid="fig4" ref-type="fig">Fig. 4 A</xref>)). However, this replacement does not always lead to an error, as evidenced by Bias- and Bias+ trials (i.e. those trials in which the performance is affected, negatively and positively, respectively (<xref rid="fig2" ref-type="fig">Fig. 2 B</xref>)). For each stimulus pair, the probability to make an error, <italic>p</italic><sub><italic>e</italic></sub>, is integral of <italic>p</italic><sub><italic>m</italic></sub> over values lying on the wrong side of the <italic>s</italic><sub>1</sub> = <italic>s</italic><sub>2</sub> diagonal (<xref rid="fig4" ref-type="fig">Fig. 4 C</xref>). For instance, for stimulus pairs below the diagonal (<xref rid="fig4" ref-type="fig">Fig. 4 C</xref>, blue squares) the trial outcome is erroneous only if <italic>ŝ</italic> is displaced above the diagonal (red part of the distribution). As one can see, the area above the diagonal increases as <italic>s</italic><sub>1</sub> increases, giving rise to a gradual increase in error rates (<xref rid="fig4" ref-type="fig">Fig. 4 C</xref>). This mathematical model can capture the performance of the attractor network model, as can be seen through the fit of the network performance, when using the bump distribution in the PPC as <italic>p</italic><sub><italic>m</italic></sub>, and <italic>ϵ</italic> as a free parameter (see <xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref> in <xref ref-type="sec" rid="s5b">Sect. 4.2</xref>, <xref rid="fig4" ref-type="fig">Fig. 4 D, E</xref>).</p>
<p>Can this simple statistical model also capture the behavior of rats and humans (<xref rid="fig2" ref-type="fig">Fig. 2 C</xref>)? We carried out the same analysis for rats and humans, by replacing the bump location distribution of PPC with that of the marginal distribution of the stimuli provided in the task, based on the observation that the former is well-approximated by the latter (<xref rid="fig4" ref-type="fig">Fig. 4 A</xref>). In this case, we see that the model roughly captures the empirical data (<xref rid="fig4" ref-type="fig">Fig. 4 F</xref> and <xref ref-type="fig" rid="fig4">G</xref>), with the addition of another parameter <italic>δ</italic> that accounts for the lapse rate. Interestingly, such “lapse” also occurs in the network model (as seen by the small amount of errors for pairs of stimuli where <italic>s</italic><sub>2</sub> is smallest and largest (<xref rid="fig4" ref-type="fig">Fig. 4 E</xref>). This occurs because of the drift present in the PPC network, that eventually, for long enough delay intervals, causes the bump to arrive at the boundaries of the attractor, which would result in an error.</p>
<p>This simple analysis implies that contraction bias in the WM network in our model is not the result of the representation of the mean stimulus in the PPC, but is an effect that emerges as a result of the PPC network’s sampling dynamics, mostly from recently presented stimuli. Indeed, a “contraction to the mean” hypothesis only provides a general account of which pairs of stimuli should benefit from a better performance and which should suffer, but does not explain the gradual accumulation of errors upon increasing (decreasing) <italic>s</italic><sub>1</sub>, for pairs below (above) the <italic>s</italic><sub>1</sub> = <italic>s</italic><sub>2</sub> diagonal [<xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c7">7</xref>]. Notably, it cannot explain why the performance in trials with pairs of stimuli where <italic>s</italic><sub>2</sub> is most distant from the mean stand to benefit the most from it. All together, our model suggests that contraction bias may be a simple consequence of errors occurring at single trials, driven by inputs from the PPC that follow a distribution similar to that of the external input (<xref rid="fig4" ref-type="fig">Fig. 4 B</xref>).</p>
</sec>
<sec id="s2e">
<label>1.5</label>
<title>Contraction bias in continuous recall</title>
<p>Can contraction bias also be observed in the activity of the WM network prior to binary decision-making? Many studies have evidenced contraction bias also in delayed estimation (or production) paradigms, where subjects must retain the value of a continuous parameter in WM and reproduce it after a delay [<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c42">42</xref>]. Given that we observe contraction bias in the behavior of the network, we reasoned that this should also be evident prior to binary decision-making. Similar to delayed estimation tasks, we therefore analyzed the position of the bump <italic>ŝ</italic>, at the end of the delay interval, for each value of <italic>s</italic><sub>1</sub>. Consistent with our reasoning, we observe contraction bias of the value of <italic>ŝ</italic>, as evidenced by the systematic departure of the curve corresponding to the bump location from that of the nominal value of the stimulus (<xref rid="fig5" ref-type="fig">Fig. 5 A</xref>). We also find that this contraction bias becomes greater as the delay interval increases (<xref rid="fig5" ref-type="fig">Fig. 5 A</xref>, right). We next analyzed the effect of the previous trial on the current trial by computing the displacement of the bump during the WM delay, as a function of the distance between the current trial’s stimulus and the previous trial’s stimulus <italic>s</italic><sub>1</sub>(<italic>t</italic>) − <italic>s</italic><sub>2</sub>(<italic>t</italic>− 1) (<xref rid="fig5" ref-type="fig">Fig. 5 B</xref>). We found that when this distance is larger, the displacement of the bump during WM is on average also larger (<xref rid="fig5" ref-type="fig">Fig. 5 B</xref>). This displacement is also attractive. Breaking down these effects by delay, we find that longer delays lead to greater attraction (<xref rid="fig5" ref-type="fig">Fig. 5 B</xref>, right).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Contraction bias in continuous recall.</title>
<p><bold>(A)</bold> We observe contraction bias of the bump of activity after the delay period ŝ: the average <italic>ŝ</italic> over trials (black dots) deviates from the identity line (diagonal dashed line) toward the mean of the marginal stimulus distribution (0.5). This effect is stronger as the delay interval is longer (left to right panel). <bold>(B)</bold> This contraction bias is actually largely due to the effect of the previous trial: the larger the difference between the current trial and the previous trial’s stimulus <italic>s</italic><sub>2</sub>(<italic>t−</italic> 1), the larger is this attractive effect on average. Accordingly with panel (A), this effect is stronger for longer delay intervals (left to right panel). <bold>(C)</bold> The distribution of the bump displacement during delay period is characterized by two modes: a main one centered around 0, corresponding to correct trials where the WM bump is not displaced during the delay interval, and another one centered around <italic>s</italic><sub>1</sub>(<italic>t</italic>) − <italic>s</italic><sub>2</sub>(<italic>t−</italic> 1), where the bump is displaced during WM (delay interval is randomly selected between 2, 4 and 10 seconds. We show here this distribution for three values of <italic>s</italic><sub>2</sub>(<italic>t −</italic> 1).</p></caption>
<graphic xlink:href="491352v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>These results point to attractive effects of the previous trial, leading in turn to contraction bias in our model. To better understand the dynamics leading to them, we next looked at the distribution of bump displacements conditioned on a specific value of the second stimulus of the previous trial <italic>s</italic><sub>2</sub>(<italic>t −</italic>1) (<xref rid="fig5" ref-type="fig">Fig. 5 C</xref>). These distributions are characterized by a mode around 0, corresponding to a majority of trials in which the bump is not displaced, and another mode around <italic>s</italic><sub>1</sub>(<italic>t</italic>) − <italic>s</italic><sub>2</sub>(<italic>t</italic>−1), corresponding to the displacement in the direction of the preceding trial’s stimulus described in <xref ref-type="sec" rid="s2c">Sect. 1.3</xref> and <xref rid="fig2" ref-type="fig">Fig. 2 B</xref>. However, note that the variance of this second mode can be large, reflecting displacements to locations other than <italic>s</italic><sub>2</sub>(<italic>t−</italic> 1), due to the complex dynamics in both networks that we have described in detail in <xref ref-type="sec" rid="s2c">Sect. 1.3</xref>.</p>
</sec>
<sec id="s2f">
<label>1.6</label>
<title>Model predictions</title>
<sec id="s2f1">
<label>1.6.1</label>
<title>The stimulus distribution impacts the pattern of contraction bias through its cumulative</title>
<p>In our model, the pattern of errors is determined by the cumulative distribution of stimuli from the correct decision boundary <italic>s</italic><sub>1</sub> = <italic>s</italic><sub>2</sub> to the left (right) for pairs of stimuli below (above) the diagonal (<xref rid="fig4" ref-type="fig">Fig. 4 C</xref> and <xref rid="figS4" ref-type="fig">Fig. S4 A</xref>). This implies that using a stimulus set in which this distribution is deformed makes different predictions for the gradient of performance across different stimulus pairs. A distribution that is symmetric (<xref rid="figS4" ref-type="fig">Fig. S4 A</xref>) yields an equal performance for pairs below and above the <italic>s</italic><sub>1</sub> = <italic>s</italic><sub>2</sub> diagonal (blue and red lines) when <italic>s</italic><sub>1</sub> is at the mean (as well as the median, given the symmetry of the distribution). A distribution that is skewed, instead, yields an equal performance when <italic>s</italic><sub>1</sub> is at the median for both pairs below and above the diagonal. For a negatively skewed distribution (<xref rid="figS4" ref-type="fig">Fig. S4 B</xref>) or positively skewed distribution (<xref rid="figS4" ref-type="fig">Fig. S4 C</xref>) the performance curves for pairs of stimuli below and above the diagonal show different concavity. For a distribution that is bimodal, the performance as a function of <italic>s</italic><sub>1</sub> resembles a saddle, with equal performance for intermediate values of <italic>s</italic><sub>1</sub> (<xref rid="figS4" ref-type="fig">Fig. S4 D</xref>). These results indicate that although the performance is quantitatively shaped by the form of the stimulus distribution, it persists as a monotonic function of <italic>s</italic><sub>1</sub> under a wide variety of manipulations of the distributions. This is a result of the property of the cumulative function, and may underlie the ubiquity of contraction bias under different experimental conditions.</p>
<p>We compare the predictions from our simple statistical model to the Bayesian model in [<xref ref-type="bibr" rid="c41">41</xref>], outlined in <xref ref-type="sec" rid="s5c">Sec. 4.3</xref>. We compute the predicted performance of an ideal Bayesian decision maker, using a value of the uncertainty in the representation of the first stimulus (<italic>σ</italic> = 0.12) that yields the best fit with the performance of the statistical model (where the free parameter is <italic>ϵ</italic> = 0.5, <xref rid="figS4" ref-type="fig">Fig. S4 A, B, C</xref>, and <xref ref-type="fig" rid="figS4">D</xref>, second panels). Our model makes different predictions across all types of distributions from that of the Bayesian model. Across all of the distributions (used as priors, in the Bayesian model), the main difference is that of a monotonic dependence of performance as a function of <italic>s</italic><sub>1</sub> for our model (<xref rid="figS4" ref-type="fig">Fig. S4 A, B, C</xref>, and <xref ref-type="fig" rid="figS4">D</xref>, second panels). The biggest difference can be seen with a prior in which pairs of stimuli with extreme values are much more probable than middle-range values. Indeed, in the case of a bimodal prior, for pairs of stimuli where our model would predict a worse-than-average performance (<xref rid="figS4" ref-type="fig">Fig. S4 D</xref>, third panel), the Bayesian model predicts a very good performance (<xref rid="figS4" ref-type="fig">Fig. S4 D</xref>, fourth panel).</p>
<p>Do human subjects perform as predicted by our model (<xref rid="fig6" ref-type="fig">Fig. 6 A</xref>)? We tested 34 human subjects on the auditory modality of the task. The experimental protocol was identical to the one used in Ref.[<xref ref-type="bibr" rid="c7">7</xref>]. Briefly, participants were presented with two sounds separated by a delay interval that varied across trials (randomly selected from 2, 4 and 6 seconds). After the second sound, participants were required to decide which sound was louder by pressing the appropriate key. We tested two groups of participants on two stimulus distributions: a negatively skewed and a bimodal distribution (<xref rid="fig6" ref-type="fig">Fig. 6 A</xref>, see <xref ref-type="sec" rid="s4c">Sect. 3.3</xref> for more details). Participants performed the task with a mean accuracy of approximately 75%, across stimulus distribution groups and across pairs of stimuli (<xref rid="fig6" ref-type="fig">Fig. 6 B</xref>). The experimental data was compatible with the predictions of our model. First, for the negatively skewed stimulus distribution condition, we observe a shift of the point of equal performance to the right, relative to a symmetric distribution (<xref rid="fig6" ref-type="fig">Fig. 6 C</xref>, left panel). For the bimodal condition, such a shift is not observed, as predicted by our model (<xref rid="fig6" ref-type="fig">Fig. 6 C</xref>, right panel). Second, the monotonic behavior of the performance, as a function of <italic>s</italic><sub>1</sub> also holds, across both distributions (<xref rid="fig6" ref-type="fig">Fig. 6 C</xref>). Our model provides a simple explanation: the percent correct on any given pair is given by the probability that, given a shift in the working memory representation, this representation still does not affect the outcome of the trial (<xref rid="fig4" ref-type="fig">Fig. 4 C</xref>). This probability, is given by cumulative of the probability distribution of working memory representations, for which we assume the marginal distribution of the stimuli to be a good approximation (<xref rid="fig4" ref-type="fig">Fig. 4 A</xref>). As a result, performance is a monotonic function of <italic>s</italic><sub>1</sub>, independent of the shape of the distribution, while the same does not always hold true for the Bayesian model (<xref rid="fig6" ref-type="fig">Fig. 6 C</xref>).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>The stimulus distribution impacts the pattern of contraction bias through its cumulative.</title>
<p><bold>(A)</bold> Left panel: prediction of performance (left y-axis) of our statistical model (solid lines) and the Bayesian model (dashed lines) for a negatively skewed stimulus distribution (gray bars, to be read with the right y-axis). Blue (red): performance as a function of <italic>s</italic><sub>1</sub> for pairs of stimuli where <italic>s</italic><sub>1</sub> <italic>&gt; s</italic><sub>2</sub> (<italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>). Vertical dashed line: median of distribution. Right: same as left, but for a bimodal distribution. <bold>(B)</bold> The distribution of performance across different stimuli pairs and subjects for the negatively skewed (gray) and the bimodal distribution (black). On average, across both distributions, participants performed with an accuracy of 75%. <bold>(C)</bold> Left: mean performance of human subjects on the negatively skewed distribution (dots, error-bars correspond to the standard deviation across different participants). Solid (dashed) lines correspond to fits of the mean performance of subjects with the statistical (Bayesian) model, <italic>ϵ</italic> = 0.55 (<italic>σ</italic> = 0.38). Red (blue): performance as a function of <italic>s</italic><sub>1</sub> for pairs of stimuli where <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub> (<italic>s</italic><sub>1</sub> <italic>&gt; s</italic><sub>2</sub>), to be read with the left y-axis. The marginal stimulus distribution is shown in gray bars, to be read with the right y-axis. Right: same as left panel, but for the bimodal distribution. Here <italic>ϵ</italic> = 0.54 (<italic>σ</italic> = 0.73). <bold>(D)</bold> Left: goodness of fit, as expressed by the mean-squared-error (MSE) between the empirical curve and the fitted curve (statistical model in the x-axis and the Bayesian model in the y-axis), computed individually for each participant and each distribution. Right: goodness of fit, computed for the average performance over participants in each distribution.</p></caption>
<graphic xlink:href="491352v3_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We further fit the performance of each participant, using both our statistical model and the Bayesian model, by minimizing the mean squared error loss (MSE) between the empirical curve and the model, with <italic>ϵ</italic> and <italic>σ</italic> as free parameters (<xref rid="fig6" ref-type="fig">Fig. 6 C</xref>), respectively (for the Bayesian model, we used the marginal distribution of the stimuli <italic>p</italic><sub><italic>m</italic></sub> as the prior). Across participants in both distributions, our statistical model yielded a better fit of the performance, relative to the Bayesian model (<xref rid="fig6" ref-type="fig">Fig. 6 D</xref>, left panel). We further fit the mean performance across all participants within a given distribution group, and similarly found that the statistical model yields a better fit, using the MSE as a goodness of fit metric (<xref rid="fig6" ref-type="fig">Fig. 6 D</xref>, right panel).</p>
<p>Finally, in order to better understand the parameters that affect the occurrence of errors in human participants, we computed the performance and fraction classified as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub> separately for different delay intervals. We found that the larger the delay interval, the lower the average performance (<xref rid="fig7" ref-type="fig">Fig. 7 A</xref>), accompanied by a larger contraction bias for larger intervals (<xref rid="fig7" ref-type="fig">Fig. 7 B</xref>). We further analyzed the fraction of trials in which subjects responded <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>, conditioned on the specific pair of stimuli presented in the current and the previous trial (<xref rid="fig7" ref-type="fig">Fig. 7 C</xref>) for all distributions (one negatively skewed, and two bimodal distributions, of which only one is shown in <xref rid="fig6" ref-type="fig">Fig. 6 C</xref>). Compatible with the previous results [<xref ref-type="bibr" rid="c7">7</xref>], we found attractive history effects that increased with the delay interval (<xref rid="fig7" ref-type="fig">Fig. 7 D</xref> and <xref ref-type="fig" rid="fig7">E</xref>).</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7:</label>
<caption><title>Attractive effects of the previous trials lead to contraction bias in human subjects, both increasing with delay interval.</title>
<p><bold>(A)</bold> The performance (in percentage correct, shown in numbers above each stimulus pair) of human subjects is better with lower delay intervals (left, 2 seconds), than with higher delay intervals (right, 6 seconds). Colorbar expresses the fraction of trials in which participants responded that <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. Results are for the negatively skewed stimulus distribution, noted (N). <bold>(B)</bold> Concurrently, contraction bias on bias+ and bias-trials (quantification explained in text) also increases with an increased delay interval, for both stimulus distributions (negatively skewed in gray and bimodal in black). <bold>(C)</bold> History matrix, expressing the fraction of trials in which subjects responded <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub> (in color) for every pair of current (x-xis) and previous (y-axis) stimuli, for negatively skewed and bimodal stimulus distributions (N+B). The one-trial back history effects can be seen through the vertical modulation of the color. Colorbar codes for the fraction of trials in which subjects responded <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. <bold>(D)</bold> History matrices (as in (C)), computed for all distributions, and separated according to delay intervals (left: 2 seconds and right: 6 seconds). <bold>(E)</bold> Bias, quantifying the (attractive) effect of previous stimulus pairs, for 1− 3 trials back in history. The attractive bias, computed for all distributions, increases with the delay interval separating the two stimuli (light to dark green: increasing delay).</p></caption>
<graphic xlink:href="491352v3_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2f2">
<label>1.6.2</label>
<title>A prolonged inter-trial interval improves average performance and reduces attractive bias</title>
<p>If errors are due to the persistence of activity resulting from previous trials, what then, is the effect of the inter-trial interval (ITI)? In our model, a shorter ITI (relative to the default value of 6<italic>s</italic> used in <xref rid="fig2" ref-type="fig">Figs. 2</xref> and <xref rid="fig3" ref-type="fig">3</xref>) results in a worse performance and vice versa (<xref rid="fig8" ref-type="fig">Fig. 8 A, B, C</xref>). This change in performance is reflected in reduced biases toward the previous trial (<xref rid="fig8" ref-type="fig">Fig. 8 D</xref> and <xref ref-type="fig" rid="fig8">E</xref>). A prolonged ITI allows for a drifting bump to vanish due to the effect of adaptation: as a result, the performance improves with increasing ITI and conversely, worsens with a shorter ITI.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8:</label>
<caption><title>A prolonged inter-trial interval (ITI) improves average performance and reduces attractive biases. Working memory is attracted towards short-term and repelled from long-term sensory history.</title>
<p><bold>(A)</bold> Performance of the network model for the psychometric stimuli improves with an increasing inter-trial interval. Errorbars (not visible) correspond to the s.e.m. over different simulations. <bold>(B)</bold> The network performance (numbers next to stimulus pairs) is on average better for longer ITIs (right panel, ITI=11<italic>s</italic>), compared to shorter ones (left panel, ITI=2.2<italic>s</italic>). Colorbar indicates the fraction of trials classified as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. <bold>(C)</bold> Quantifying contraction bias separately for bias+ trials (green) and bias-trials (orange) yields a decreasing bias as the inter-trial interval increases. <bold>(D)</bold> The bias, quantifying the (attractive) effect of the previous trial, decreases with ITI. Darker shades of purple correspond to increasing values of the ITI, with dots corresponding to simulation values and lines to linear fits. <bold>(E)</bold> Performance is modulated by the previous stimulus pairs (modulation along the y-axis), more for a short ITI (left, ITI=2.2<italic>s</italic>) than for a longer ITI (right, ITI=11<italic>s</italic>). The colorbar corresponds to the fraction classified <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. <bold>(F)</bold> The distribution of ITIs in the human experiment is bimodal. We define as having a “short” ITI, those trials where the preceding ITI is shorter than 3 seconds and conversely for “long” ITI. <bold>(G)</bold> The human performance for the negatively skewed stimulus distribution is on average worse for shorter ITIs (left panel), compared to longer ones (right panel). Colorbar indicates the fraction of trials subjects responded <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. <bold>(H)</bold> The bias, quantifying the (attractive) effect of the previous trial, increases with ITI in human subjects. Darker shades of purple correspond to increasing values of the ITI, with dots corresponding to empirical values and lines to linear fits. <bold>(I)</bold> Although the stimuli shown up to two trials back yield attractive effects, those further back in history yield repulsive effects, notably when the ITI is larger. Such repulsive effects extend to up to 6 trials back.</p></caption>
<graphic xlink:href="491352v3_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Do human subjects express less bias with longer ITIs, as predicted by our model? In our simulations, we set the ITI to either 2.2, 6 or 11 seconds, whereas in the experiment, since it is self-paced, the ITI can vary considerably. In order to emulate the simulation setting as closely as possible, we divided trials into two groups: “short” ITIs (shorter than 3 seconds), and “long” ITIs (longer than 3 seconds). This choice was motivated by the shape of the distribution of ITIs, which is bimodal, with a peak around 1 second, and another after 3 seconds (<xref rid="fig8" ref-type="fig">Fig. 8 F</xref>). Given the shape of the ITI distribution, we did not divide the ITIs into smaller intervals as this would result in too little data in some intervals. In line with our model, we found a better average performance with increasing ITI accompanied by decreasing contraction bias (<xref rid="fig8" ref-type="fig">Fig. 8 G</xref>). In order to quantify one-trial back effects, we used data pertaining to all of the distributions we tested – the negatively skewed, and also two bimodal distributions (of which only one was shown in this manuscript, in <xref rid="fig6" ref-type="fig">Fig. 6 C</xref>). This allowed us to obtain clear one-trial-back attractive biases, decreasing with increasing ITI (<xref rid="fig8" ref-type="fig">Fig. 8 H</xref>), in line with our model predictions (<xref rid="fig8" ref-type="fig">Fig. 8 B</xref> and <xref ref-type="fig" rid="fig8">D</xref>).</p>
</sec>
<sec id="s2f3">
<label>1.6.3</label>
<title>Working memory is attracted towards short-term and repelled from long-term sensory history</title>
<p>Although contraction bias is robustly found in different contexts, surprisingly similar tasks, such as perceptual estimation tasks, sometimes highlight opposite effects, i.e. repulsive effects [<xref ref-type="bibr" rid="c43">43</xref>–<xref ref-type="bibr" rid="c45">45</xref>]. Interestingly, recent studies have found both effects in the same experiment: in a study of visual orientation estimation [<xref ref-type="bibr" rid="c18">18</xref>], it has been found that attraction and repulsion have different timescales; while perceptual decisions about orientation are attracted towards recently perceived stimuli (timescale of a few seconds), they are repelled from stimuli that are shown further back in time (timescale of a few minutes). Moreover, in the same study, they find that the long-term repulsive bias is spatially specific, in line with sensory adaptation [<xref ref-type="bibr" rid="c46">46</xref>–<xref ref-type="bibr" rid="c48">48</xref>] and in contrast to short-term attractive serial dependence [<xref ref-type="bibr" rid="c18">18</xref>]. Given that adaptation is a main feature of our model of the PPC, we sought to determine whether such repulsive effects can emerge from the model. We extended the calculation of the bias to up to ten trials back, and quantified the slope of the bias as a function of the previous trial stimulus pair. We observe robust repulsive effects appear after the third trial back in history, and up to six trials back (<xref rid="fig8" ref-type="fig">Fig. 8 I</xref>). In our model, both short-term attractive effects and longer-term repulsive effects can be attributed to the multiple timescales over which the networks operate. The short-term attractive effects occur due to the long time it takes for the adaptive threshold to build up in the PPC, and the short timescale with which the WM network integrates input from the PPC. The longer-term repulsive effects occur when the activity bump in the PPC persists in one location and causes adaptation to slowly build up, effectively increasing the activation threshold. The raised threshold takes equally long to return to baseline, preventing activity bumps to form in that location and thereby creating repulsion toward all the other locations in the network. Crucially, however, the amplitude of such effects depend on the inter-trial interval; in particular, for shorter inter-trial intervals, the repulsive effects are less observable.</p>
</sec>
</sec>
<sec id="s2g">
<label>1.7</label>
<title>The timescale of adaptation in the PPC network can control perceptual biases similar to those observed in dyslexia and autism</title>
<p>In a recent study [<xref ref-type="bibr" rid="c16">16</xref>], a similar PWM task with auditory stimuli was studied in human neurotypical (NT), autistic spectrum (ASD) and dyslexic (DYS) subjects. Based on an analysis using a generalized linear model (GLM), a double dissociation between different subject groups was suggested: ASD subjects exhibit a stronger bias towards long-term statistics – compared to NT subjects –, while for DYS subjects, a higher bias is present towards short-term statistics.</p>
<p>We investigated our model to see if it is able to show similar phenomenology, and if so, what are the relevant parameters controlling the timescale of the biases in behavior. We identified the adaptation timescale in the PPC as the parameter that affects the extent of the short-term bias, consistent with previous literature [<xref ref-type="bibr" rid="c49">49</xref>], [<xref ref-type="bibr" rid="c50">50</xref>]. Calculating the mean bias towards the previous trial stimulus pair (<xref rid="fig9" ref-type="fig">Fig. 9 A</xref>), we find that a shorter-than-NT adaptation timescale yields a larger bias towards the previous trial stimulus. Indeed, a shorter timescale for neuronal adaptation implies a faster process for the extinction of the bump in PPC – and the formation of a new bump that remains stable for a few trials – producing “jumpier” dynamics that lead to a larger number of one-trial back errors. In contrast, increasing this timescale with respect to NT gives rise to a stable bump for a longer time, ultimately yielding a smaller short-term bias. This can be seen in the detailed breakdown of the network’s behavior on the current trial, when conditioned on the stimuli presented at the previous trial (<xref rid="fig9" ref-type="fig">Fig. 9 B</xref>, see also <xref ref-type="sec" rid="s2c">Sect. 1.3</xref> for a more detailed explanation of the dynamics). We performed a GLM analysis as in Ref. [<xref ref-type="bibr" rid="c16">16</xref>] to the network behavior, with stimuli from four trials back and the mean stimulus as regressors (see <xref ref-type="sec" rid="s5d">Sect. 4.4</xref>). This analysis shows that a reduction in the PPC adaptation timescale with respect to NT, produces behavioral changes qualitatively compatible with data from DYS subjects; on the contrary, an increase of this timescale yields results consistent with ASD data (<xref rid="fig9" ref-type="fig">Fig. 9 C</xref>).</p>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9:</label>
<caption><title>Apparent trade-off between short- and long-term biases, controlled by the timescale of neural adaptation.</title>
<p><bold>(A)</bold> the bias exerted on the current trial by the previous trial (see main text for how it is computed), for three values of the adaptation timescale that mimic similar behavior to the three cohorts of subjects. <bold>(B)</bold> As in (<xref ref-type="fig" rid="fig2">Fig. 2 D</xref>), for three different values of adaptation timescale. The colorbar corresponds to the fraction classified <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. <bold>(C)</bold> GLM weights corresponding to the three values of the adaptation parameter marked in (<xref ref-type="fig" rid="figS6">Fig. S6 A</xref>), including up to 4 trials back. In a GLM variant incorporating a small number of past trials as regressors, the model yields a high weight for the running mean stimulus regressor. Errorbars correspond to the standard deviation across different simulations. <bold>(D)</bold> Same as in C, but including regressors corresponding to the past 10 trials as well as the running mean stimulus. With a larger number of regressors extending into the past, the model yields a small weight for the running mean stimulus regressor. Errorbars correspond to the standard deviation across different simulations. <bold>(E)</bold> The weight of the running mean stimulus regressor as a function of extending the number of past trial regressors decays upon increasing the number of previous-trial stimulus regressors.</p></caption>
<graphic xlink:href="491352v3_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>This GLM analysis suggests that dissociable short- and long-term biases may be present in the network behavior. Having access to the full dynamics of the network, we sought to determine how it translates into such dissociable short- and long-term biases. Given that all the behavior arises from the location of the bump on the attractor, we quantified the fraction of trials in which the bump in the WM network, before the onset of the second stimulus, was present in the vicinity of any of the previous trial’s stimuli (<xref rid="figS6" ref-type="fig">Fig. S6 B</xref>, right panel, and C), as well as the vicinity of the mean over the sensory history (<xref rid="figS6" ref-type="fig">Fig. S6 B</xref>, left panel, and C). While the bump location correlated well with the GLM weights corresponding to the previous trial’s stimuli regressor (comparing the right panels of <xref rid="figS6" ref-type="fig">Fig. S6 A</xref> and <xref ref-type="fig" rid="figS6">B</xref>), surprisingly, it did not correlate with the GLM weights corresponding to the mean stimulus regressor (comparing the left panels of <xref rid="figS6" ref-type="fig">Fig. S6 A</xref> and <xref ref-type="fig" rid="figS6">B</xref>). In fact, we found that the bump was in a location given by the stimuli of the past two trials, as well as the mean over the stimulus history, in a smaller fraction of trials, as the adaptation timescale parameter was made larger (<xref rid="figS6" ref-type="fig">Fig. S6 C</xref>).</p>
<p>Given that the weights, after four trials in the past, were still non-zero, we extended the GLM regression by including a larger number of past stimuli as regressors. We found that doing this greatly reduced the weight of the mean stimulus regressor (<xref rid="fig9" ref-type="fig">Fig. 9 C, D</xref> and <xref ref-type="fig" rid="fig9">E</xref>, see <xref ref-type="sec" rid="s5d">Sect. 4.4</xref> and <xref ref-type="sec" rid="s5d">4.4</xref> for more details). Therefore, we propose an alternative interpretation of the GLM results given in Ref. [<xref ref-type="bibr" rid="c16">16</xref>]. In our model, the increased (reduced) weight for long-term mean in the ASD (DYS) subjects can be explained as an effect of a larger (smaller) window in time of short-term biases, without invoking a double dissociation mechanism (<xref rid="fig9" ref-type="fig">Fig. 9 D</xref> and <xref ref-type="fig" rid="fig9">E</xref>). In <xref ref-type="sec" rid="s5d">Sect. 4.4</xref>, we provide a mathematical argument for this, which is empirically shown by including a large number of individual stimuli from previous trials in the regression analysis.</p>
</sec>
</sec>
<sec id="s3">
<label>2</label>
<title>Discussion</title>
<sec id="s3a">
<label>2.1</label>
<title>Contraction bias in the delayed comparison task: simply a statistical effect or more?</title>
<p>Contraction bias is an effect emerging in working memory tasks, where in the averaged behavior of a subject, the magnitude of the item held in memory appears to be larger than it actually is when it is “small” and, vice-versa, it appears to be smaller when it is “large” [<xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c52">52</xref>, <xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c53">53</xref>, <xref ref-type="bibr" rid="c54">54</xref>]. Recently, Akrami et al [<xref ref-type="bibr" rid="c7">7</xref>] have found that contraction bias as well as short-term history-dependent effects occur in an auditory delayed comparison task in rats and humans: the comparison performance in a given trial, depends on the stimuli shown in preceding trials (up to three trials back) [<xref ref-type="bibr" rid="c7">7</xref>], similar to previous findings in human 2AFC paradigms [<xref ref-type="bibr" rid="c5">5</xref>]. These findings raise the question: does contraction bias occur independently of short-term history effects, or does it emerge as a result of the latter?</p>
<p>Akrami et al [<xref ref-type="bibr" rid="c7">7</xref>] have also found the PPC to be a critical node for the generation of such effects, as its optogenetic inactivation (specifically during the delay interval) greatly attenuated both effects. WM was found to remain intact, suggesting that its content was perhaps read-out in another region. Electrophysiological recordings as well as optogenetic inactivation results in the same study suggest that while sensory history information is provided by the PPC, its integration with the WM content must happen somewhere downstream to the PPC. Different brain areas can fit the profile. For instance there are known projections from the PPC to mPFC in rats [<xref ref-type="bibr" rid="c55">55</xref>], where neural correlates of parametric working memory have been found [<xref ref-type="bibr" rid="c40">40</xref>]. Building on these findings, we suggest a minimal two-module model aimed at better understanding the interaction between contraction bias and short-term history effects. These two modules capture properties of the PPC (in providing sensory history signals) and a downstream network holding working memory content. Our WM and PPC networks, despite having different timescales, are both shown to encode information about the marginal distribution of the stimuli (<xref rid="fig4" ref-type="fig">Fig. 4 A</xref>). Although they have similar activity distributions to that of the external stimuli, they have different memory properties, due to the different timescales with which they process incoming stimuli. The putative WM network, from which information to solve the task is read-out, receives additional input from the PPC network. The PPC is modelled as integrating inputs slower relative to the WM network, and is also endowed with firing rate adaptation, the dynamics of which yield short-term history biases and consequently, contraction bias.</p>
<p>It must be noted, however, that short-term history effects (due to firing rate adaptation) do not necessarily need to be invoked in order to recover contraction bias: as long as errors are made following random samples from a distribution in the same range as that of the stimuli, contraction bias should be observed [<xref ref-type="bibr" rid="c56">56</xref>]. Indeed, when we manipulated the parameters of the PPC network in such a way that short-term history effects were eliminated (by removing the firing-rate adaptation), contraction bias persisted. As a result, our model suggests that contraction bias may not simply be given by a regression towards the mean of the stimuli during the inter-stimulus interval [<xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c58">58</xref>], but brought about by a richer dynamics occurring at the level of individual trials [<xref ref-type="bibr" rid="c2">2</xref>], more in line with the idea of random sampling [<xref ref-type="bibr" rid="c59">59</xref>].</p>
<p>The model makes predictions as to how the pattern of errors may change when the distribution of stimuli is manipulated, either at the level of the presented stimuli or through the network dynamics. When we tested these predictions experimentally, by manipulating the skewness of the stimulus distribution, such that the median and the mean were dissociated (<xref rid="fig6" ref-type="fig">Fig. 6 A</xref>) the results from our human psychophysics experiments were in agreement with the model predictions. In further support of this, in a recent tactile categorization study [<xref ref-type="bibr" rid="c45">45</xref>], where rats were trained to categorize tactile stimuli according to a boundary set by the experimenter, the authors have shown that rats set their decision boundary according to the statistical structure of the stimulus set to which they are exposed. More studies are needed to fully verify the extent to which the statistical structure of the stimuli affect the performance. Finally, we note that in our model, the stimulus distribution is not explicitly learned (but see [<xref ref-type="bibr" rid="c60">60</xref>]): instead, the PPC dynamics follows the input, and its marginal distribution of activity is similar to that of the external input. This is in agreement with Ref. [<xref ref-type="bibr" rid="c45">45</xref>], where the authors used different stimulus ranges across different sessions and noted that rats initiated each session without any residual influence of the previous session’s range/boundary on the current session, ruling out long-term learning of the input structure.</p>
<p>Importantly, our results are not limited to the delayed “comparison” paradigm, where binary decision making occurs. We show that by analyzing the location of the WM bump at the end of the delay interval, similar to the continuous recall tasks, we can retrieve the averaged effects of contraction bias, similar to previous reports [<xref ref-type="bibr" rid="c42">42</xref>]. Such continuous readout of the memory reveals a rich dynamics of errors at the level of individual trials, similar to the delayed comparison case, but to our knowledge this has not been studied in previous experimental studies. Papadimitriou et al [<xref ref-type="bibr" rid="c15">15</xref>] have characterised residual error distribution, in an orientation recall task, when limiting previous trials to orientations in the range of +35 to +85 degrees relative to the current trial. This distribution is unimodal, leading the authors to conclude that the current trial shows a small but systematic bias toward the location of the memorandum of the previous trial. It remains to be tested whether the error distribution remains unimodal, if conditioned on other values of the current and previous orientations, similar to our analysis in <xref rid="fig5" ref-type="fig">Fig. 5 C</xref>.</p>
</sec>
<sec id="s3b">
<label>2.2</label>
<title>Attractor mechanism riding on multiple timescales</title>
<p>Our model assumes that the stimulus is held in working memory through the persistent activity of neurons, building on the discovery of persistent selective activity in a number of cortical areas, including the prefrontal cortex (PFC), during the delay interval [<xref ref-type="bibr" rid="c61">61</xref>–<xref ref-type="bibr" rid="c67">67</xref>]. To explain this finding, we have used the attractor framework, in which recurrently connected neurons mutually excite one another to form reverberation of activity within populations of neurons coding for a given stimulus [<xref ref-type="bibr" rid="c68">68</xref>–<xref ref-type="bibr" rid="c70">70</xref>]. However, subsequent work has shown that persistent activity related to the stimulus is not always present during the delay period and that the activity of neurons displays far more heterogeneity than previously thought [<xref ref-type="bibr" rid="c71">71</xref>]. It has been proposed that short-term synaptic facilitation may dynamically operate to bring a WM network across a phase transition from a silent to a persistently active state [<xref ref-type="bibr" rid="c72">72</xref>, <xref ref-type="bibr" rid="c73">73</xref>]. Such mechanisms may further contribute to short-term biases [<xref ref-type="bibr" rid="c74">74</xref>], an alternative possibility that we have not specifically considered in this model.</p>
<p>An important model feature that is crucial in giving rise to all of its behavioral effects is its operation over multiple timescales (<xref rid="figS2" ref-type="fig">Fig. S2 F</xref>). Such timescales have been found to govern the processing of information in different areas of the cortex [<xref ref-type="bibr" rid="c30">30</xref>–<xref ref-type="bibr" rid="c32">32</xref>], and may reflect the heterogeneity of connections across different cortical areas [<xref ref-type="bibr" rid="c75">75</xref>].</p>
</sec>
<sec id="s3c">
<label>2.3</label>
<title>Relation to other models</title>
<p>In many early studies, groups of neurons whose activity correlates monotonically with the stimulus feature, known as “plus” and “minus” neurons, have been found in the PFC [<xref ref-type="bibr" rid="c65">65</xref>, <xref ref-type="bibr" rid="c76">76</xref>]. Such neurons have been used as the starting point in the construction of many models [<xref ref-type="bibr" rid="c77">77</xref>, <xref ref-type="bibr" rid="c78">78</xref>, <xref ref-type="bibr" rid="c71">71</xref>, <xref ref-type="bibr" rid="c79">79</xref>]. It is important, however, to note that depending on the area, the fraction of such neurons can be small [<xref ref-type="bibr" rid="c40">40</xref>], and that the majority of neurons exhibit firing profiles that vary largely during the delay period [<xref ref-type="bibr" rid="c80">80</xref>]. Such heterogeneity of the PFC neurons’ temporal firing profiles have prompted the successful construction of models that have not included the basic assumption of plus and minus neurons, but these have largely focused on the plausibility of the dynamics of neurons observed, with little connection to behavior [<xref ref-type="bibr" rid="c71">71</xref>].</p>
<p>A separate line of research has addressed behavior, by focusing on normative models to account for contraction bias [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c81">81</xref>]. The abstract mathematical model that we present (<xref rid="fig4" ref-type="fig">Fig. 4</xref>), can be compatible with a Bayesian framework [<xref ref-type="bibr" rid="c19">19</xref>] in the limit of a very broad likelihood for the first stimulus and a very narrow one for the second stimulus, and where the prior for the first stimulus is replaced by the distribution of <italic>ŝ</italic>, following the model in <xref rid="fig4" ref-type="fig">Fig. 4 B</xref> (see <xref ref-type="sec" rid="s5b">Sect. 4.2</xref> for details). However, it is important to note that our model is conceptually different, i.e. subjects do not have access to the full prior distribution, but only to <italic>samples</italic> of the prior. We show that having full knowledge of the underlying sensory distribution is not needed to present contraction bias effects. Instead, a point estimate of past events that is updated trial to trial suffices to show similar results. This suggests a possible mechanism for the brain to approximate Bayesian inference and it remains open whether similar mechanisms (based on interaction of networks with different integration timescales) can approximate other Bayesian computations. It is also important to note the differences between the predictions from the two models. As shown in <xref rid="fig6" ref-type="fig">Figs. 6 A</xref> and <xref ref-type="fig" rid="figS4">S4</xref>, depending on the specific sensory distributions, the two models can have qualitatively different testable predictions. Data from our human psychophysical experiments, utilizing auditory Parametric Working Memory, show better agreement with our model predictions as compared to the Bayesian model.</p>
<p>Moreover, an ideal Bayesian observer model alone cannot capture the temporal pattern of short-term attraction and long-term repulsion observed in some tasks, and the model has had to be supplemented with efficient encoding and Bayesian decoding of information in order to capture both effects [<xref ref-type="bibr" rid="c18">18</xref>]. In our model, both effects emerge naturally as a result of neuronal adaptation, but their amplitudes crucially depend on the time parameters of the task, perhaps explaining the sometimes contradictory effects reported across different tasks.</p>
<p>Finally, while such attractive and repulsive effects in performance may be suboptimal in the context of a task designed in a laboratory setting, this may not be the case in more natural environments. For example, it has been suggested that integrating information over time serves to preserve perceptual continuity in the presence of noisy and discontinuous inputs [<xref ref-type="bibr" rid="c6">6</xref>]. This continuity of perception may be necessary to solve more complex tasks or make decisions, particularly in a non-stationary environment, or in a noisy environment.</p>
</sec>
</sec>
<sec id="s4">
<label>3</label>
<title>Methods</title>
<sec id="s4a">
<label>3.1</label>
<title>The model</title>
<p>Our model is composed of two populations of <italic>N</italic> neurons, representing the PPC network and the putative WM network. We consider that each population is organized as a continuous line attractor, with recurrent connectivity described by an interaction matrix <italic>J</italic><sub><italic>ij</italic></sub>, whose entries represent the strength of the interaction between neuron <italic>i</italic> and <italic>j</italic>. The activation function of the neurons is a logistic function, i.e. the output <italic>r</italic><sub><italic>i</italic></sub> of neuron <italic>i</italic>, given the input <italic>h</italic><sub><italic>i</italic></sub>, is
<disp-formula id="eqn1">
<graphic xlink:href="491352v3_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>β</italic> is the neuronal gain. The variables <italic>r</italic><sub><italic>i</italic></sub> take continuous values between 0 and 1, and represent the firing rates of the neurons. The input <italic>h</italic><sub><italic>i</italic></sub> to a neuron is given by
<disp-formula id="eqn2">
<graphic xlink:href="491352v3_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>τ</italic> is the timescale for the integration of inputs. In the first term on the right hand side, <italic>J</italic><sub><italic>ij</italic></sub><italic>r</italic><sub><italic>j</italic></sub> represents the input to neuron <italic>i</italic> from neuron <italic>j</italic>, and <inline-formula><inline-graphic xlink:href="491352v3_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> corresponds to the external inputs. The recurrent connections are given by
<disp-formula id="eqn3">
<graphic xlink:href="491352v3_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
with
<disp-formula id="eqn4">
<graphic xlink:href="491352v3_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The interaction kernel, <italic>K</italic>, is assumed to be the result of a time-averaged Hebbian plasticity rule: neurons with nearby firing fields will fire concurrently and strengthen their connections, while firing fields far apart will produce weak interactions [<xref ref-type="bibr" rid="c82">82</xref>]. Neuron <italic>i</italic> is associated with the firing field <italic>x</italic><sub><italic>i</italic></sub> = <italic>i/N</italic> . The form of <italic>K</italic> expresses a connectivity between neurons <italic>i</italic> and <italic>j</italic> that is exponentially decreasing with the distance between their respective firing fields, proportional to |<italic>i</italic> − <italic>j</italic>|; the exponential rate of decrease is set by the constant d<sub>0</sub>, i.e. the typical range of interaction. The amplitude of the kernel is also rescaled by <italic>d</italic><sub>0</sub>, in such a way that ∑ <sub><italic>i,j</italic></sub> <italic>K</italic><sub><italic>ij</italic></sub> is constant. The strength of the excitatory weights is set by <italic>J</italic><sub><italic>e</italic></sub>; the normalization of <italic>K</italic>, together with the sigmoid activation function saturating to 1, implies that <italic>J</italic><sub><italic>e</italic></sub> is also the maximum possible input received by any neuron due to the recurrent connections. The constant <italic>J</italic><sub>0</sub>, instead, contributes to a linear global inhibition term. Its value needs to be chosen depending on <italic>J</italic><sub><italic>e</italic></sub> and <italic>d</italic><sub>0</sub>, so that the balance between excitatory and inhibitory inputs ensures that the activity remains localized along the attractor, i.e. it does not either vanish or equal 1 everywhere; together, these three constants set the width of the bump of activity.</p>
<p>The two networks in our model are coupled through excitatory connections from the PPC to the WM network. Therefore, we introduce two equations analogous to <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref>, one for each network. The coupling between the two will enter as a firing-rate dependent input, in addition to <italic>I</italic><sup>ext</sup>. The dynamics of the input to a neuron in the WM network writes
<disp-formula id="eqn5">
<graphic xlink:href="491352v3_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>j</italic><sup><italic>W</italic></sup> indexes neurons in the WM network, and <inline-formula><inline-graphic xlink:href="491352v3_inline4a.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the timescale for the integration of inputs in the WM network. The first term in the r.h.s corresponds to inputs from recurrent connections within the WM network. The second term, corresponds to inputs from the PPC network. Finally, the last term corresponds to the external inputs used to give stimuli to the network. Similarly, for the PPC network we have
<disp-formula id="eqn6">
<graphic xlink:href="491352v3_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>j</italic><sup><italic>P</italic></sup> indexes neurons in the PPC, and where <italic>τ</italic> <sup><italic>P</italic></sup> is the timescale for the integration of inputs in the PPC network; importantly, we set this to be longer than the analogous quantity for the WM network, <inline-formula><inline-graphic xlink:href="491352v3_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (see <xref ref-type="table" rid="tbl1">Tab. 1</xref>). The first and third terms in the r.h.s are analogous to the corresponding ones for the WM network: inputs from within the network and from the stimuli. The second term instead, corresponds to adaptive thresholds with dynamics specified by
<disp-formula id="eqn7">
<graphic xlink:href="491352v3_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
modelling neuronal adaptation, where <inline-formula><inline-graphic xlink:href="491352v3_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <italic>D</italic><sup><italic>P</italic></sup> set its timescale and its amplitude. We are interested in the condition where the timescale of the evolution of the input current is much smaller relative to that of the adaptation <inline-formula><inline-graphic xlink:href="491352v3_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. For a constant <inline-formula><inline-graphic xlink:href="491352v3_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, we find that depending on the value of <italic>D</italic><sup><italic>P</italic></sup>, the bump of activity shows different behaviors. For low values of <italic>D</italic><sup><italic>P</italic></sup>, the bump remains relatively stable (<xref rid="figS1" ref-type="fig">Fig. S1 C</xref> (1)). Upon increasing <italic>D</italic><sup><italic>P</italic></sup>, the bump gradually starts to drift (<xref rid="figS1" ref-type="fig">Fig. S1 C</xref> (2-3)). Upon increasing <italic>D</italic><sup><italic>P</italic></sup> even further, a phase transition leads to an abrupt dissipation of the bump (<xref rid="figS1" ref-type="fig">Fig. S1 C</xref> (4)).</p>
<p>Note that, while the transition from bump stability to drift occurs gradually, the transition from drift to dissipation is abrupt. This abruptness in the transition from the drift to the dissipation regime may imply that only one of the two behaviors is possible in our model of the PPC (<xref ref-type="sec" rid="s2c">Sect. 1.3</xref>). In fact, our network model of the PPC operates in the “drift” regime <inline-formula><inline-graphic xlink:href="491352v3_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. However, we also observe dissipation of the bump, which is mainly responsible for the jumps observed in the model. This occurs due to the inputs from incoming external stimuli, that affect the bump via the global inhibition in the model (<xref rid="figS1" ref-type="fig">Fig. S1 A</xref>). Therefore external stimuli can allow the network to temporarily cross the sharp drift/dissipation boundary shown in <xref rid="figS1" ref-type="fig">Fig. S1 B</xref>. As a result, the combined effect of adaptation, together with external inputs and global inhibition result in the drift/jump dynamics described in the main text.</p>
<p>Finally, both networks have a linear geometry with free boundary conditions, i.e. no condition is imposed on the profile activity at neuron 1 or <italic>N</italic> .</p>
</sec>
<sec id="s4b">
<label>3.2</label>
<title>Simulation</title>
<p>We performed all the simulations using custom Python code. Differential equations were numerically integrated with a time step of <italic>dt</italic> = 0.001 using the forward Euler method. The activity of neurons in both circuits were initialized to <italic>r</italic> = 0. Each stimulus was presented for 400 ms. A stimulus is introduced as a “box” of unit amplitude and of width 2 <italic>δs</italic> around <italic>s</italic> in stimulus space: in a network with <italic>N</italic> neurons, the stimulus is given by setting <inline-formula><inline-graphic xlink:href="491352v3_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula> in <xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref> for neurons with index <italic>i</italic> within (<italic>s</italic> ± <italic>δs</italic>) × <italic>N</italic>, and <inline-formula><inline-graphic xlink:href="491352v3_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for all the others. Only the activity in the WM network was used to assess performance. To do that, the activity vector was recorded at two time-points: 200 ms before and after the onset of the second stimulus <italic>s</italic><sub>2</sub>. Then, the neurons with the maximal activity were identified at both time-points, and compared to make a decision. This procedure was done for 50 different simulations with 1000 consecutive trials in each, with a fixed inter-trial interval separating two consecutive trials, fixed to 5 seconds. The inter-stimulus intervals were set according to two different experimental designs, as explained below.</p>
<sec id="s4b1">
<label>3.2.1</label>
<title>Interleaved design</title>
<p>As in the study in Ref. [<xref ref-type="bibr" rid="c7">7</xref>], an inter-stimulus interval of either 2, 6 or 10 seconds was randomly selected. The delay interval is defined as the time elapsed from the end of the first stimulus to the beginning of the second stimulus. This procedure was used to produce <xref rid="fig1" ref-type="fig">Figs. 1</xref>, <xref rid="fig2" ref-type="fig">2</xref>, <xref rid="fig3" ref-type="fig">3</xref>, <xref rid="fig7" ref-type="fig">7</xref>, <xref ref-type="fig" rid="figS2">S2</xref>, <xref ref-type="fig" rid="figS3">S3</xref>.</p>
</sec>
<sec id="s4b2">
<label>3.2.2</label>
<title>Block design</title>
<p>In order to provide a comparison to the interleaved design, but also to simulate the design in Ref. [<xref ref-type="bibr" rid="c16">16</xref>], we also ran simulations with a block design, where the inter-stimulus intervals were kept fixed throughout the trials. Other than this, the procedure and parameters used were exactly the same as in the interleaved case. This procedure was used to produce <xref rid="fig9" ref-type="fig">Figs. 9</xref> and <xref ref-type="fig" rid="figS6">S6</xref>.</p>
</sec>
</sec>
<sec id="s4c">
<label>3.3</label>
<title>Human auditory experiment - delayed comparison task</title>
<p>Subjects received, in each trial, a pair of sounds played from ear-surrounding headphones. The subject self-initiated each trial by pressing the space bar on the keyboard. The first sound was then presented together with a blue square on the left side of a computer monitor in front of the subject. This was followed by a delay period, indicated by ‘WAIT!’ on the screen, then the second sound was presented together with a red square on the right side of the screen. At the end of the second stimulus, subjects had 2 seconds to decide which one was louder, then indicate their choice by pressing the ‘s’ key if they thought that the first sound was louder, or the ‘l’ key if they thought that the second sound was louder. Written feedback about the correctness of their response was provided on the screen for each individual trial. Every ten trials, participants received feedback on their running mean performance calculated up to that trial. Participants then had to press spacebar to go to the next trial (the experiment was hence self-paced).</p>
<p>The two auditory stimuli, <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub>, separated by a variable delay (of 2, 4 and 6 seconds), were played for 400 ms, with short delay periods of 250 ms inserted before <italic>s</italic><sub>1</sub> and after <italic>s</italic><sub>2</sub>. The stimuli consisted of broadband noise 2000-20000 Hz, generated as a series of sound pressure level (SPL) values sampled from a zero-mean normal distribution. The overall mean intensity of sounds varied from 60-92 dB. Participants had to judge which out of the two stimuli, <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub>, was louder (had the greater SPL standard deviation).</p>
<p>We recruited 10 subjects for the negatively skewed distribution and 24 subjects for the bimodal distribution. The study was approved by the University College London (UCL) Research Ethics Committee [16159/001] (London, UK). Each participant performed approximately 400 trials for a given distribution. Several participants took part in both distributions.</p>
</sec>
</sec>
</body>
<back>
<sec id="s5">
<label>4</label>
<title>Supplementary Material</title>
<sec id="s5a">
<label>4.1</label>
<title>Computing bump location</title>
<p>In order to check whether the bump is in a target location (<xref rid="fig3" ref-type="fig">Figs. 3 B</xref>, <xref ref-type="fig" rid="figS2">S2 B</xref>, and <xref ref-type="fig" rid="figS3">S3 D</xref>), we check whether the position of the neuron with the maximal firing rate is within a distance of ±5% of the length of the whole line attractor from the target location (<xref rid="fig3" ref-type="fig">Figs. 3 A</xref>, <xref ref-type="fig" rid="figS2">S2 A</xref> and <xref ref-type="fig" rid="figS3">S3 C</xref>). In these figures, we compare the probability that, in a given trial, the activity of the WM network is localized around one of the previous stimuli (estimated from the simulation of the dynamics, histograms) with the probability of this happening due to chance (horizontal dashed line). Here we detail the calculation of the chance probability. In general, if we have two discrete independent random variables, <inline-formula><inline-graphic xlink:href="491352v3_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <italic>Ŷ</italic>, with probability distributions <italic>p</italic><sub><italic>X</italic></sub> and <italic>p</italic><sub><italic>Y</italic></sub>, the probability of them having the same value is
<disp-formula id="ueqn1">
<graphic xlink:href="491352v3_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>i, j</italic> are the indices for different values of the two random variables and 𝕀(<italic>x</italic><sub><italic>i</italic></sub> = <italic>y</italic><sub><italic>j</italic></sub>) equals 1 where <italic>x</italic><sub><italic>i</italic></sub> = <italic>x</italic><sub><italic>j</italic></sub> and 0 otherwise. If the two random variables are identically distributed, the above expression writes
<disp-formula id="ueqn2">
<graphic xlink:href="491352v3_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
In our case, the two identically distributed random variables are “bump location at the current trial” and the “target bump location” (that are <inline-formula><inline-graphic xlink:href="491352v3_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and ⟨<italic>s</italic>⟩). With the exception of the mean stimulus ⟨<italic>s</italic>⟩, all the other variables are identically distributed, with probability <italic>p</italic><sub><italic>m</italic></sub> (that is the marginal distribution over <italic>s</italic><sub>1</sub> or <italic>s</italic><sub>2</sub>). We note that the bump location in the WM network follows a very similar distribution to <italic>p</italic><sub><italic>m</italic></sub> (<xref rid="fig4" ref-type="fig">Fig. 4 A</xref>). Then, we compute the chance probability with the above relationship, where <italic>p</italic><sub><italic>X</italic></sub> ≡ <italic>p</italic><sub><italic>m</italic></sub>. For the mean stimulus, instead, we have a probability which is simply equal to 1 for <italic>s</italic> = 0.5 and 0 elsewhere; therefore, the chance probability for the bump location to be at the mean stimulus, then is <italic>p</italic><sub><italic>m</italic></sub>(0.5).</p>
<p>The excess probability (with respect to chance) for the bump location to equal one of the previous stimuli gives a measure of the correlation between these two; in other terms, of the amount of information retained by the network about previous stimuli.</p>
</sec>
<sec id="s5b">
<label>4.2</label>
<title>The probability to make errors is proportional to the cumulative distribution of the stimuli, giving rise to contraction bias</title>
<p>In order to illustrate the statistical origin of contraction bias consistent with our network model, we consider a simplified mathematical model of its performance (<xref rid="fig4" ref-type="fig">Fig. 4 B</xref>). By definition of the delayed comparison task, the optimal decision maker produces a label <italic>y</italic> equal to 1 if <inline-formula><inline-graphic xlink:href="491352v3_inline14.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and 0 if <inline-formula><inline-graphic xlink:href="491352v3_inline15.gif" mimetype="image" mime-subtype="gif"/></inline-formula>; the impossible cases <inline-formula><inline-graphic xlink:href="491352v3_inline16.gif" mimetype="image" mime-subtype="gif"/></inline-formula> are excluded from the set of stimuli, but would produce a label which is either 0 or 1 with 50% probability. That is
<disp-formula id="eqn8">
<graphic xlink:href="491352v3_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
In this simplified scheme, at each trial <italic>t</italic>, the two stimuli <inline-formula><inline-graphic xlink:href="491352v3_inline17.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="491352v3_inline18.gif" mimetype="image" mime-subtype="gif"/></inline-formula> are perfectly perceived with a finite probability 1− <italic>ϵ</italic>, with <italic>ϵ &lt;</italic> 1. Under the assumption that the decision maker behaves optimally based on the perceived stimuli, a correct perception would necessarily lead to the correct label. However, with probability <italic>ϵ</italic>, the first stimulus is randomly selected from a buffer of stimuli, i.e. is replaced by a random variable <italic>ŝ</italic><sub>1</sub> that has a probability distribution <inline-formula><inline-graphic xlink:href="491352v3_inline19.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p>The probability distribution <inline-formula><inline-graphic xlink:href="491352v3_inline20.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the statistics of previously shown stimuli. The information about the previous stimulus is given by the activity of the “slower” PPC network. As shown above, after the presentation of the first stimulus of the trial, the bump of activity is seen to jump to the position encoding one of the previously presented stimuli, <inline-formula><inline-graphic xlink:href="491352v3_inline21.gif" mimetype="image" mime-subtype="gif"/></inline-formula> etc. with decreasing probability (<xref rid="fig3" ref-type="fig">Fig. 3 C</xref>). Therefore, in calculating the performance in the task, we can take <inline-formula><inline-graphic xlink:href="491352v3_inline22.gif" mimetype="image" mime-subtype="gif"/></inline-formula> to be the marginal distribution of the stimulus <italic>s</italic><sub>1</sub> or <italic>s</italic><sub>2</sub> across trials, as in the histogram (<xref rid="fig4" ref-type="fig">Fig. 4 A</xref>).</p>
<p>The probability of a misclassification is then given by the probability that, given the pair <inline-formula><inline-graphic xlink:href="491352v3_inline23.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, at trial <italic>t</italic>,</p>
<list list-type="order">
<list-item><p>the first stimulus is replaced by a random value, which happens with probability <italic>ϵ</italic>, and</p></list-item>
<list-item><p>the value of <italic>ŝ</italic><sub>1</sub> replaced is larger than <inline-formula><inline-graphic xlink:href="491352v3_inline24.gif" mimetype="image" mime-subtype="gif"/></inline-formula> when <inline-formula><inline-graphic xlink:href="491352v3_inline25.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is smaller and viceversa (<xref rid="fig4" ref-type="fig">Fig. 4 C</xref>). In summary, the probability of an error at trial <italic>t</italic> is given by
<disp-formula id="eqn9">
<graphic xlink:href="491352v3_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p></list-item>
</list>
</sec>
<sec id="s5c">
<label>4.3</label>
<title>Bayesian description of contraction bias</title>
<p>We reproduce here the theoretical result from [<xref ref-type="bibr" rid="c41">41</xref>], which provides a normative model for contraction bias in the Bayesian inference framework, and apply it to the different stimulus distributions described in <xref ref-type="sec" rid="s2f1">Sect. 1.6.1</xref>.</p>
<p>A stimulus with value <italic>s</italic> is encoded by the agent through a noisy representation <inline-formula><inline-graphic xlink:href="491352v3_inline26.gif" mimetype="image" mime-subtype="gif"/></inline-formula> ∼<italic>ℓ</italic>(·|<italic>s</italic>). Before the presentation of the stimulus, the agent has an expectation of its possible values which is described by the probability <italic>π</italic>. Assuming that it has access to the internal representation <italic>r</italic>, as well as the probability distributions <italic>ℓ</italic> and <italic>π</italic>, the agent can infer the perceived stimulusŝ through Bayes rule:
<disp-formula id="eqn10">
<graphic xlink:href="491352v3_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>p</italic>(<italic>r</italic>) = ∫<italic>ds</italic><sup><italic>′</italic></sup> <italic>ℓ</italic>(<italic>r|s</italic><sup><italic>′</italic></sup>) <italic>π</italic>(<italic>s</italic><sup><italic>′</italic></sup>). In this Bayesian setting, the probability distributions for the noisy representation and for the expected measurement are interpreted as the <italic>likelihood</italic> and the <italic>prior</italic>, respectively.</p>
<p>In the delayed comparison task, at the time of the decision, the two stimuli <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> are assumed to be encoded independently, although with different uncertainties, due to the different delays leading to the time of decision: <italic>ℓ</italic>(<italic>r</italic><sub>1</sub>, <italic>r</italic><sub>2</sub>| <italic>s</italic><sub>1</sub>, <italic>s</italic><sub>2</sub>) = <italic>ℓ</italic><sub>1</sub>(<italic>r</italic><sub>1</sub>| <italic>s</italic><sub>1</sub>) <italic>ℓ</italic><sub>2</sub>(<italic>r</italic><sub>2|</sub> <italic>s</italic><sub>2</sub>), with var[<italic>ℓ</italic><sub>1</sub>] <italic>&gt;</italic> var[<italic>ℓ</italic><sub>2</sub>]. Similarly, the expected values of the stimuli are assumed to be independent but also identically distributed: <italic>π</italic>(<italic>s</italic><sub>1</sub>, <italic>s</italic><sub>2</sub>) = <italic>π</italic>(<italic>s</italic><sub>1</sub>) <italic>π</italic>(<italic>s</italic><sub>2</sub>).</p>
<p>The optimal Bayesian decision maker uses the inference of the stimuli through <xref ref-type="disp-formula" rid="eqn10">Eq. (10)</xref> to produce an estimate of the probability that <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>, given the internal representations,
<disp-formula id="eqn11">
<graphic xlink:href="491352v3_eqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where Θ is the Heaviside function, and yields a label <italic>ŷ</italic>= 1 (truth value of “<italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>”) when such probability is higher than 1<italic>/</italic>2, and <italic>ŷ</italic> = 0 otherwise. Therefore, the probability that the Bayesian decision maker yields the response “<italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>” given the <italic>true</italic> values of the stimuli <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> is the average of the label <italic>ŷ</italic> over the possible values of their representations, i.e. over the likelihood:
<disp-formula id="eqn12">
<graphic xlink:href="491352v3_eqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
<sec id="s5c1">
<label>4.3.1</label>
<title>Application to our study</title>
<p>In modelling our data, we assume that the likelihood functions <italic>ℓ</italic><sub>1</sub>(·| <italic>s</italic><sub>1</sub>) and <italic>ℓ</italic><sub>2</sub>(·|<italic>s</italic><sub>2</sub>) are Gaussian with mean equal to the stimulus, but with different standard deviations, <italic>σ</italic><sub>1</sub> and <italic>σ</italic><sub>2</sub>, respectively, as in [<xref ref-type="bibr" rid="c41">41</xref>]. We restrict to the particular case where <italic>σ</italic><sub>2</sub> = 0, i.e. there is no uncertainty in the representation of the second stimulus, since there is negligible delay between its presentation and the decision. We instead assume a finite standard deviation <italic>σ</italic><sub>1</sub> = <italic>σ</italic>, which we use as the only free parameter of this model to produce <xref ref-type="fig" rid="figS4">Figs.S4 A-D</xref>, panels 2 and 4.</p>
<p>The prior <italic>π</italic> is chosen to be the marginal distribution of the first stimulus – identical to the marginal of the second stimulus, because of symmetry.</p>
<p>When <italic>σ</italic><sub>2</sub> = 0, <italic>ℓ</italic><sub>2</sub>(<italic>r</italic>|<italic>s</italic>) = <italic>δ</italic>(<italic>r</italic> − <italic>s</italic>) (Dirac delta), and the predicted response probability, <xref ref-type="disp-formula" rid="eqn12">Eq. (12)</xref>, reduces to
<disp-formula id="eqn13">
<graphic xlink:href="491352v3_eqn13.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
</sec>
<sec id="s5d">
<label>4.4</label>
<title>Generalized Linear Model (GLM)</title>
<sec id="s5d1">
<title>GLM as in Lieder et al</title>
<p>Similarly to Ref. [<xref ref-type="bibr" rid="c16">16</xref>], we performed a multivariate logistic regression (an instance of generalized linear model, GLM) to the output of the network in the delayed discrimination task with recent stimuli values as covariates:
<disp-formula id="eqn14">
<graphic xlink:href="491352v3_eqn14.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>σ</italic> is the sigmoidal function <inline-formula><inline-graphic xlink:href="491352v3_inline27.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the mean of the stimuli presented at trial <italic>τ, h</italic> is the number of “history” terms in the regression, and ⟨<italic>s</italic>⟩ is the mean of the stimuli within and across trials up to the current one. As in Ref. [<xref ref-type="bibr" rid="c16">16</xref>], we choose <italic>h</italic> = 4, i.e. we include in the short-term history, the four trials prior to the current one. The first term in <xref ref-type="disp-formula" rid="eqn14">Eq. (14)</xref>, with weight <italic>α</italic>, controls the slope of the psychometric curve. The remaining terms, combined linearly with weights <italic>w</italic>, contribute to biases expressing the long and short-term memory. In Ref. [<xref ref-type="bibr" rid="c16">16</xref>], it is shown that subjects on the autistic syndrome (ASD) conserve the higher long-term weights, <italic>w</italic><sub><italic>mean</italic></sub>, while losing the short-term weights expressed by neurotypical (NT) subjects. In contrast, dyslexic (DYS) subjects conserve a higher bias from the recent stimuli, <italic>w</italic><sub>1</sub>, while losing the higher long-term weights, also expressed by neurotypical subjects.</p>
<p>In order to gain insight into this regression model in terms of our network, we also performed a linear regression of the bump of activity just before the onset of the second stimulus, denoted <inline-formula><inline-graphic xlink:href="491352v3_inline28.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, versus the same variables:
<disp-formula id="eqn15">
<graphic xlink:href="491352v3_eqn15.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
In this case, we see that the weights <italic>w</italic> in the linear regression for <inline-formula><inline-graphic xlink:href="491352v3_inline29.gif" mimetype="image" mime-subtype="gif"/></inline-formula> have the same qualitative behavior as the weights for the bias term in the GLM regression for the performance (not shown). This is expected, since the decision-making rule in the network –based on the bump location just before and during the second stimulus, <inline-formula><inline-graphic xlink:href="491352v3_inline30.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="491352v3_inline31.gif" mimetype="image" mime-subtype="gif"/></inline-formula> respectively– is deterministic, following <inline-formula><inline-graphic xlink:href="491352v3_inline32.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Therefore, the bias term in the GLM performed in Ref. [<xref ref-type="bibr" rid="c16">16</xref>], <xref ref-type="disp-formula" rid="eqn14">Eq. (14)</xref>, corresponds to the displacement of the bump location <inline-formula><inline-graphic xlink:href="491352v3_inline33.gif" mimetype="image" mime-subtype="gif"/></inline-formula> with respect to the actual stimulus <inline-formula><inline-graphic xlink:href="491352v3_inline34.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, modelled to be linearly dependent on the displacement of previous stimuli from <inline-formula><inline-graphic xlink:href="491352v3_inline35.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
</sec>
<sec id="s5d2">
<title>Regression model with infinite history</title>
<p>In the regression formulas in <xref ref-type="disp-formula" rid="eqn14">Eqs. (14)</xref> and <xref ref-type="disp-formula" rid="eqn15">(15)</xref>, it is possible to give an interpretation of the parameter <italic>w</italic><sub><italic>mean</italic></sub>, that is the weight of the contribution from the covariate corresponding to the mean of the past stimuli. Let us consider two regression models, one in which, in addition to a regressor corresponding to the mean stimulus, regressors corresponding to the stimulus history are included up to trial <italic>h</italic>, and another in which <italic>h</italic> =∞, i.e. infinitely many past stimuli are included as regressors. In this case, <xref ref-type="disp-formula" rid="eqn15">Eq. (15)</xref> rewrites
<disp-formula id="eqn16">
<graphic xlink:href="491352v3_eqn16.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
If we assume that the weights obtained from the regression have roughly an exponential dependence on time (<xref rid="fig9" ref-type="fig">Fig. 9 C</xref> and <xref ref-type="fig" rid="fig9">D</xref>), we can write
<disp-formula id="eqn17">
<graphic xlink:href="491352v3_eqn17.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
By equating <xref ref-type="disp-formula" rid="eqn15">Eqs. (15)</xref> and <xref ref-type="disp-formula" rid="eqn16">(16)</xref>, we would find that
<disp-formula id="eqn18">
<graphic xlink:href="491352v3_eqn18.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where
<disp-formula id="eqn19">
<graphic xlink:href="491352v3_eqn19.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
that is an average over the geometric distribution <italic>g</italic><sub><italic>j</italic></sub> = (1 − <italic>γ</italic>) <italic>γ</italic><sup><italic>j</italic></sup>, from time <italic>t</italic> − (<italic>h</italic> + 1) backward. Since for <italic>γ</italic> large enough we have ⟨<italic>s</italic>⟩<sub><italic>γ</italic></sub> = ⟨<italic>s</italic>⟩, we can identify
<disp-formula id="eqn20">
<graphic xlink:href="491352v3_eqn20.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This derivation indicates that the magnitude <italic>w</italic><sub><italic>mean</italic></sub> in the infinite history model, given by <xref ref-type="disp-formula" rid="eqn15">Eq. (15)</xref>, is a function of the discount factor <italic>γ</italic> as well as the weight of the first trial left out from the finite-history regression (<italic>w</italic><sub><italic>h</italic>+1</sub>). A higher <italic>γ</italic> value, i.e. a longer timescale for damping of the weights extending into the stimulus history, yields a higher <italic>w</italic><sub><italic>mean</italic></sub>. We can obtain <italic>γ</italic> for each condition (NT, ASD and DYS) by fitting the weights obtained as a function of trials extending into the history (<xref rid="fig9" ref-type="fig">Fig. 9 C</xref> and <xref ref-type="fig" rid="fig9">D</xref>). As predicted by <xref ref-type="disp-formula" rid="eqn20">Eq. (20)</xref>, a larger window for short-term history effects (as in the ASD case relative to NT) yields a larger weight for the covariate corresponding to the mean stimulus. Finally, <xref ref-type="disp-formula" rid="eqn20">Eq. (20)</xref> also predicts that <italic>w</italic><sub><italic>mean</italic></sub> is proportional to <italic>w</italic><sub><italic>h</italic>+1</sub>, the number of trials back we consider in the regression, <italic>h</italic>, implying that the number of covariates that we choose to include in the model may greatly affect the results. Both of these predictions are corroborated by plotting directly the value of <italic>w</italic><sub><italic>mean</italic></sub> obtained from the regression (<xref rid="fig9" ref-type="fig">Fig. 9 E</xref>).</p>
</sec>
</sec>
<sec id="s5e">
<label>4.5</label>
<title>Supplementary Figures</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1:</label>
<caption><title>Dynamics of responses in a one-dimensional continuous attractor network, in the presence of adaptation.</title>
<p><bold>(A)</bold> We study a one dimensional line attractor in which neurons code for a stimulus feature that varies along a physical dimension, such as amplitude of an auditory stimulus. The connections between pairs of neurons is a decreasing, symmetric function of the distance between their preferred firing locations, allowing for a bump of activity to form and self-sustain when sufficient input is given to the network. However, this self-sustaining activity may be disrupted if neuronal adaptation is present. In particular, drifting dynamics may be observed. <bold>(B)</bold> Left: phase diagram of the average drift velocity as a function of the adaptation timescale <inline-formula><inline-graphic xlink:href="491352v3_inline45.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and amplitude <italic>D</italic><sup><italic>P</italic></sup> . The average drift velocity is simply computed as the distance travelled by the center of the bump in a duration of 50 seconds. Color codes for the average drift velocity (a.u.). Numbers indicate four points for which sample dynamics are shown in (C). <bold>(C)</bold> We observe three main phases: in the first, the activity bump is stable when no or little neuronal adaptation is present (point 4). Larger values of neural adaptation induce drift of the activity bump; the average drift velocity increases upon increasing the neural adaptation (points 2 and 3). Finally, increasing it even further leads to the dissipation of the activity bump (point 1). The boundary between the drift and dissipation phases is abrupt. In these simulations, periodic boundary conditions have been used in order to compute the average average drift velocity over longer durations.</p></caption>
<graphic xlink:href="491352v3_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2:</label>
<caption><title>The role of neuronal adaptation in generating short-term history biases.</title>
<p>In order to better understand the network mechanisms that give rise to short-term history effects, we removed neural adaptation in the PPC network and assessed the performance in the WM network. <bold>(A)</bold> As in (<xref rid="fig3" ref-type="fig">Fig. 3 B</xref>). We track the location of the bump, in the PPC (pink), and in the WM network (purple) before the onset of the second stimulus (the pink curve cannot be seen as the purple curve goes perfectly on top). In this case, the displacement of the bump of activity is smooth and new sensory stimuli (colored dots) induce only a minimal shift in the location of the bump. This behavior is to be contrasted with the case in which there is adaptation in the PPC network, inducing jumps in the bump location (<xref rid="fig3" ref-type="fig">Fig. 3 A</xref>). An additional effect of no neural adaptation is that the activity in the PPC network, completely overrides the activity in the WM network. <bold>(B)</bold> As in (<xref rid="fig4" ref-type="fig">Fig. 4 A</xref>). Marginal distribution of the bump location in both networks (pink for PPC, purple for WM) before the onset of <italic>s</italic><sub>2</sub> is more peaked than the marginal distribution of the stimuli (gray), as a result of the absence of “jumps”. <bold>(C)</bold> As in (<xref rid="fig3" ref-type="fig">Fig. 3 C</xref>). We compute the fraction of times the bump is in a given location, current trial <inline-formula><inline-graphic xlink:href="491352v3_inline46.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, four preceding trials <inline-formula><inline-graphic xlink:href="491352v3_inline47.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, the running mean stimulus, or all other locations (overlapping sets). In this case, in the majority of the trials, the bump is either at the running mean stimulus, or any other location. The fraction of trials in which it is in the position of the four previous stimuli roughly corresponds to chance occurrence (dashed black lines), with only a minor increase for the current stimulus. <bold>(D)</bold> As in (<xref rid="fig2" ref-type="fig">Fig. 2 D</xref>). Left: The network behavior conditioned on the previous trial stimulus pair does not exhibit any previous-trial attractive dependence (vertical modulation). Colorbar corresponds to the fraction classified as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. Right: This attractive dependence can also be expressed through the bias measure (see main text for how it is computed). Colored lines correspond to current trial pairs, the black dots to the mean over all current trial pairs, and the black line to its linear fit. <bold>(E)</bold> As in (<xref rid="fig2" ref-type="fig">Fig. 2 C</xref>). Although there are no attractive previous trial effects, the performance expresses a very strong contraction bias, and performance is as if the decision boundary is orthogonal to the optimal decision boundary. Color codes for fraction of trials in which a <italic>s</italic><sub>1</sub> <italic>&gt; s</italic><sub>2</sub> classification is made. <bold>(F)</bold> Phase diagram with <inline-formula><inline-graphic xlink:href="491352v3_inline48.gif" mimetype="image" mime-subtype="gif"/></inline-formula> on the x-axis, <italic>τ</italic> <sup><italic>P</italic></sup> on the y-axis, and in color, the fraction of trials in which the bump, before the network is stimulated with the second stimulus, is in the vicinity of a target (specified in the title of each panel). White dot corresponds to parameters of the default network <xref ref-type="table" rid="tbl1">Tab. 1</xref>.</p></caption>
<graphic xlink:href="491352v3_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Figure S3:</label>
<caption><title>Inactivating the inputs from the PPC network improves performance, in line with experimental findings.</title>
<p><bold>(A)</bold> As in (<xref rid="fig2" ref-type="fig">Fig. 2 C</xref>). The performance of the network when the strength of the inputs from the PPC to the WM network is weakened (modelling the optogenetic inactivation of the PPC) is dramatically improved, and contraction bias is virtually eliminated. The colorbar corresponds to the fraction classified as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. <bold>(B)</bold> As in (<xref rid="fig2" ref-type="fig">Fig. 2 D</xref>). The performance for each stimulus pair in the current trial is improved and no modulation by the previous stimulus pairs can be observed. The colorbar corresponds to the fraction classified as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. <bold>(C)</bold> As in (<xref rid="fig3" ref-type="fig">Fig. 3 B</xref>). This improvement of the performance can be traced back to how well the activity bump in the WM network (in purple), before the onset of the second stimulus <italic>s</italic><sub>2</sub>, tracks the first stimulus <italic>s</italic><sub>1</sub> (shown in colored dots, each corresponding to a different value of the inter-stimulus delay interval). Relative to the case in which inputs from the PPC are intact (<xref rid="fig3" ref-type="fig">Fig. 3 A</xref>), it can be seen that the location of the bump tracks the first stimulus with high fidelity. The activity in the PPC (in pink), instead, is identical to that shown previously (<xref rid="fig6" ref-type="fig">Fig. 6 A</xref>), as all the other parameters are kept constant. <bold>(D)</bold> As in (<xref rid="fig2" ref-type="fig">Fig. 2 C</xref>). The bump location can be quantified not only for the stimulus <italic>s</italic><sub>1</sub> of the current trial (colored dots, each color corresponding to a given delay interval), but for the four preceding stimuli from the two previous trials (from <inline-formula><inline-graphic xlink:href="491352v3_inline49.gif" mimetype="image" mime-subtype="gif"/></inline-formula> back to <inline-formula><inline-graphic xlink:href="491352v3_inline50.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). With weaker inputs from the PPC (pink), the WM (purple) function of the circuit is disrupted less frequently, and in the majority of the trials, the bump of activity corresponds to the first stimulus <inline-formula><inline-graphic xlink:href="491352v3_inline51.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p></caption>
<graphic xlink:href="491352v3_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Figure S4:</label>
<caption><title>The stimulus distribution impacts the pattern of contraction bias.</title>
<p>The model makes different predictions for the performance, depending on the shape of the stimulus distribution. <bold>(A)</bold> Panel 1: schema of model prediction. Regions shaded in red correspond to the probability of correct comparison, for stimulus pairs above the diagonal, when replacing <italic>s</italic><sub>1</sub> with a random value sampled from the marginal distribution with a resampling probability <italic>ϵ</italic> = 0.25 (see <xref rid="fig4" ref-type="fig">Fig. 4</xref>). Panel 2: prediction of both models for a unimodal symmetric (in this case quasi-uniform) stimulus distribution, statistical model (solid line) and Bayesian model (dashed line). The marginal stimulus distribution is shown in grey bars (to be read with the right y-axis). The value of <italic>s</italic><sub>1</sub> for which there is equal performance for pairs of stimuli below and above the diagonal is indicated by the vertical dashed line, corresponding to the median of the distribution. Panel 3: for each stimulus pair, fraction of trials classified as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub> (colorbar), for statistical model. Panel 4: same as panel 3, but for Bayesian model of equal average performance (corresponding to a width of the likelihood of <italic>σ</italic> = 0.08 (see <xref ref-type="sec" rid="s2f1">Sect. 1.6.1</xref> and <xref ref-type="sec" rid="s5c">Sect. 4.3</xref>). <bold>(B)</bold> Similar to A, for a negatively skewed distribution. <bold>(C)</bold> Similar to A, for a positively skewed distribution. <bold>(D)</bold> Similar to A, for a bimodal distribution.</p></caption>
<graphic xlink:href="491352v3_figS4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Figure S5:</label>
<caption><title>Model predictions for a block design.</title>
<p><bold>(A)</bold> As in (<xref rid="fig2" ref-type="fig">Fig. 2 A</xref>). Performance of the network model for the psychometric stimuli improves with a short delay interval and worsens as this delay is increased. <bold>(B)</bold> As in (<xref rid="fig2" ref-type="fig">Fig. 2 C</xref>). Performance is affected by contraction bias – a gradual accumulation of errors for stimuli below (above) the diagonal upon increasing (decreasing) <italic>s</italic><sub>1</sub>. As the delay interval increases, the contraction bias is increased which results in reduced performance across all pairs. Colorbar indicates the fraction of trials classified as <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. <bold>(C)</bold> As in (<xref rid="fig3" ref-type="fig">Fig. 3 C</xref>). The location of the bump that corresponds to the value of <italic>s</italic><sub>1</sub> occupies a smaller fraction of trials, as the delay interval increases. <bold>(D)</bold> As in (<xref rid="fig2" ref-type="fig">Fig. 2 D</xref>). Performance is affected by the previous stimulus pairs (modulation along the y-axis), and becomes worse as the delay interval is increased. The colorbar corresponds to the fraction classified <italic>s</italic><sub>1</sub> <italic>&lt; s</italic><sub>2</sub>. <bold>(E)</bold> As in (<xref rid="fig3" ref-type="fig">Fig. 3 F</xref>). Bias, quantifying the (attractive) effect of the previous stimulus pairs, each color corresponding to a different delay interval. These history effects are attractive: the larger the previous trial stimulus pair, the higher the probability of classifying the first stimulus <italic>s</italic><sub>1</sub> as large, and vice-versa. Middle/right panels: same as the left panel, for stimuli extending two and three trials back. <bold>(F)</bold> Quantifying contraction bias separately for Bias+ trials (green) and Bias-trials (orange) yields an increasing bias as the inter-stimulus interval increases.</p></caption>
<graphic xlink:href="491352v3_figS5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS6" position="float" fig-type="figure">
<label>Figure S6:</label>
<caption><title>Apparent trade-off between short- and long-term biases, controlled by the timescale of neural adaptation.</title>
<p><bold>(A)</bold> Left: GLM weight associated with the regressor corresponding to the mean stimulus across trials (value indicated by colorbar), as a function of the strength of the weights from the PPC to the WM network (x-axis), and the adaptation timescale in the PPC (y-axis). Right: Same as left panel, but displaying the GLM weight associated with the regressor corresponding to the previous trial’s stimulus. These two panels indicate that the adaptation timescale <italic>seemingly</italic> exerts a trade-off between the two biases: while decreasing it increases short-term sensory history biases, increasing it increases long-term sensory history biases. The values of the adaptation parameter marked by the three colored dots (in red, blue and green) can mimic behaviors similar to dyslexic, neurotypical, and autistic spectrum subjects (see also <xref rid="fig9" ref-type="fig">Fig. 9</xref>). <bold>(B)</bold> Left: phase diagram of the fraction of trials in which the activity bump at the end of the delay interval is in the location of the running mean stimulus as a function of the strength of the weights from the PPC to the WM network (x-axis), and the adaptation timescale in the PPC (y-axis). Right: Same as (left), but for the location of any of the two stimuli presented in the previous trial. <bold>(C)</bold> The fraction of trials in which the activity bump at the end of the delay interval corresponds to different locations shown in the x-axis, for three different values of the adaptation timescale parameter, corresponding to qualitatively similar to dyslexic, neurotypical, and autistic spectrum subjects, shown in colors.</p></caption>
<graphic xlink:href="491352v3_figS6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s5f">
<label>4.6</label>
<title>Parameters</title>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><title>Simulation parameters <xref rid="figS1" ref-type="fig">Fig. S1</xref>.</title></caption>
<graphic xlink:href="491352v3_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><title>Simulation parameters <xref rid="fig9" ref-type="fig">Fig. 9</xref> and <xref rid="figS6" ref-type="fig">Fig. S6</xref>. Other parameters as in <xref ref-type="table" rid="tbl1">Tab. 1</xref></title></caption>
<graphic xlink:href="491352v3_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We are grateful to Loreen Hertäg for helpful comments on our figures, and Arash Fassihi for helpful discussions. We also thank Guilhem Ibos for pointing out a typo in our figure legends in a previous version of this manuscript. This work was supported by BBSRC BB/N013956/1, BB/N019008/1, Wellcome Trust 200790/Z/16/Z, Simons Foundation 564408, EPSRC EP/R035806/1, Gatsby Charitable Foundation 562980 and Wellcome Trust 562763.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><collab>Harry Levi Hollingworth</collab>. <article-title>The central tendency of judgment</article-title>. <source>The Journal of Philosophy, Psychology and Scientific Methods</source>, <volume>7</volume>(<issue>17</issue>):<fpage>461</fpage>–<lpage>469</lpage>, <year>1910</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="other"><string-name><given-names>Jerwen</given-names> <surname>Jou</surname></string-name>, <string-name><given-names>Gary E</given-names> <surname>Leka</surname></string-name>, <string-name><given-names>Dawn M</given-names> <surname>Rogers</surname></string-name>, and <string-name><given-names>Yolanda E</given-names> <surname>Matus</surname></string-name>. <article-title>Contraction bias in memorial quantifying judgment: Does it come from a stable compressed memory representation or a dynamic adaptation process?</article-title> <source>The American journal of psychology</source>, pages <fpage>543</fpage>–<lpage>564</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>JE</given-names> <surname>Berliner</surname></string-name>, <string-name><given-names>NI</given-names> <surname>Durlach</surname></string-name>, and <string-name><given-names>LD</given-names> <surname>Braida</surname></string-name>. <article-title>Intensity perception. vii. further data on roving-level discrimination and the resolution and bias edge effects</article-title>. <source>The Journal of the Acoustical Society of America</source>, <volume>61</volume>(<issue>6</issue>):<fpage>1577</fpage>–<lpage>1585</lpage>, <year>1977</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>Åke</given-names> <surname>Hellstr öm.</surname></string-name> <article-title>The time-order error and its relatives: Mirrors of cognitive processes in comparing</article-title>. <source>Psychological Bulletin</source>, <volume>97</volume>(<issue>1</issue>):<fpage>35</fpage>, <year>1985</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>Ofri</given-names> <surname>Raviv</surname></string-name>, <string-name><given-names>Merav</given-names> <surname>Ahissar</surname></string-name>, and <string-name><given-names>Yonatan</given-names> <surname>Loewenstein</surname></string-name>. <article-title>How recent history affects perception: the normative approach and its heuristic approximation</article-title>. <source>PLoS Comput Biol</source>, <volume>8</volume>(<issue>10</issue>):<fpage>e1002731</fpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>Jason</given-names> <surname>Fischer</surname></string-name> and <string-name><given-names>David</given-names> <surname>Whitney</surname></string-name>. <article-title>Serial dependence in visual perception</article-title>. <source>Nature neuroscience</source>, <volume>17</volume>(<issue>5</issue>):<fpage>738</fpage>–<lpage>743</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>Athena</given-names> <surname>Akrami</surname></string-name>, <string-name><given-names>Charles D</given-names> <surname>Kopec</surname></string-name>, <string-name><given-names>Mathew E</given-names> <surname>Diamond</surname></string-name>, and <string-name><given-names>Carlos D</given-names> <surname>Brody</surname></string-name>. <article-title>Posterior parietal cortex represents sensory history and mediates its effects on behaviour</article-title>. <source>Nature</source>, <volume>554</volume>(<issue>7692</issue>):<fpage>368</fpage>–<lpage>372</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>Anastasia</given-names> <surname>Kiyonaga</surname></string-name>, <string-name><given-names>Jason M</given-names> <surname>Scimeca</surname></string-name>, <string-name><given-names>Daniel P</given-names> <surname>Bliss</surname></string-name>, and <string-name><given-names>David</given-names> <surname>Whitney</surname></string-name>. <article-title>Serial dependence across perception, attention, and memory</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>21</volume>(<issue>7</issue>):<fpage>493</fpage>–<lpage>497</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>Guido Marco</given-names> <surname>Cicchini</surname></string-name>, <string-name><given-names>Kyriaki</given-names> <surname>Mikellidou</surname></string-name>, and <string-name><given-names>David</given-names> <surname>Burr</surname></string-name>. <article-title>Serial dependencies act directly on perception</article-title>. <source>Journal of vision</source>, <volume>17</volume>(<issue>14</issue>):<fpage>6</fpage>–<lpage>6</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>Stefan</given-names> <surname>Czoschke</surname></string-name>, <string-name><given-names>Cora</given-names> <surname>Fischer</surname></string-name>, <string-name><given-names>Julia</given-names> <surname>Beitner</surname></string-name>, <string-name><given-names>Jochen</given-names> <surname>Kaiser</surname></string-name>, and <string-name><given-names>Christoph</given-names> <surname>Bledowski</surname></string-name>. <article-title>Two types of serial dependence in visual working memory</article-title>. <source>British Journal of Psychology</source>, <volume>110</volume>(<issue>2</issue>):<fpage>256</fpage>–<lpage>267</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>David</given-names> <surname>Alais</surname></string-name>, <string-name><given-names>Garry</given-names> <surname>Kong</surname></string-name>, <string-name><given-names>Colin</given-names> <surname>Palmer</surname></string-name>, and <string-name><given-names>Colin</given-names> <surname>Clifford</surname></string-name>. <article-title>Eye gaze direction shows a positive serial dependency</article-title>. <source>Journal of vision</source>, <volume>18</volume>(<issue>4</issue>):<fpage>11</fpage>–<lpage>11</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>Mauro</given-names> <surname>Manassi</surname></string-name>, <string-name><given-names>Alina</given-names> <surname>Liberman</surname></string-name>, <string-name><given-names>Anna</given-names> <surname>Kosovicheva</surname></string-name>, <string-name><given-names>Kathy</given-names> <surname>Zhang</surname></string-name>, and <string-name><given-names>David</given-names> <surname>Whitney</surname></string-name>. <article-title>Serial dependence in position occurs at the time of perception</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>25</volume>(<issue>6</issue>):<fpage>2245</fpage>–<lpage>2253</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>Mauro</given-names> <surname>Manassi</surname></string-name>, <string-name><given-names>Alina</given-names> <surname>Liberman</surname></string-name>, <string-name><given-names>Wesley</given-names> <surname>Chaney</surname></string-name>, and <string-name><given-names>David</given-names> <surname>Whitney</surname></string-name>. <article-title>The perceived stability of scenes: serial dependence in ensemble representations</article-title>. <source>Scientific reports</source>, <volume>7</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>9</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>Marta S ú</given-names> <surname>arez-Pinilla</surname></string-name>, <string-name><given-names>Anil K</given-names> <surname>Seth</surname></string-name>, and <string-name><given-names>Warrick</given-names> <surname>Roseboom</surname></string-name>. <article-title>Serial dependence in the perception of visual variance</article-title>. <source>Journal of Vision</source>, <volume>18</volume>(<issue>7</issue>):<fpage>4</fpage>–<lpage>4</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>Charalampos</given-names> <surname>Papadimitriou</surname></string-name>, <string-name><given-names>Afreen</given-names> <surname>Ferdoash</surname></string-name>, and <string-name><given-names>Lawrence H</given-names> <surname>Snyder</surname></string-name>. <article-title>Ghosts in the machine: memory interference from the previous trial</article-title>. <source>Journal of neurophysiology</source>, <volume>113</volume>(<issue>2</issue>):<fpage>567</fpage>–<lpage>577</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>Itay</given-names> <surname>Lieder</surname></string-name>, <string-name><given-names>Vincent</given-names> <surname>Adam</surname></string-name>, <string-name><given-names>Or</given-names> <surname>Frenkel</surname></string-name>, <string-name><given-names>Sagi</given-names> <surname>Jaffe-Dax</surname></string-name>, <string-name><given-names>Maneesh</given-names> <surname>Sahani</surname></string-name>, and <string-name><given-names>Merav</given-names> <surname>Ahissar</surname></string-name>. <article-title>Perceptual bias reveals slow-updating in autism and fast-forgetting in dyslexia</article-title>. <source>Nature neuroscience</source>, <volume>22</volume>(<issue>2</issue>):<fpage>256</fpage>–<lpage>264</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>J õ ao</given-names> <surname>Barbosa</surname></string-name> and <string-name><given-names>Albert</given-names> <surname>Compte</surname></string-name>. <article-title>Build-up of serial dependence in color working memory</article-title>. <source>Scientific reports</source>, <volume>10</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>7</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>Matthias</given-names> <surname>Fritsche</surname></string-name>, <string-name><given-names>Eelke</given-names> <surname>Spaak</surname></string-name>, and <string-name><given-names>Floris P</given-names> <surname>De Lange</surname></string-name>. <article-title>A bayesian and efficient observer model explains concurrent attractive and repulsive history biases in visual perception</article-title>. <source>Elife</source>, <volume>9</volume>:<fpage>e55389</fpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>Paymon</given-names> <surname>Ashourian</surname></string-name> and <string-name><given-names>Yonatan</given-names> <surname>Loewenstein</surname></string-name>. <article-title>Bayesian inference underlies the contraction bias in delayed comparison tasks</article-title>. <source>PloS one</source>, <volume>6</volume>(<issue>5</issue>):<fpage>e19551</fpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name> and <string-name><given-names>Emilio</given-names> <surname>Salinas</surname></string-name>. <article-title>Flutter discrimination: neural codes, perception, memory and decision making</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>4</volume>(<issue>3</issue>):<fpage>203</fpage>–<lpage>218</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><given-names>H Sebastian</given-names> <surname>Seung</surname></string-name>. <article-title>Continuous attractors and oculomotor control</article-title>. <source>Neural Networks</source>, <volume>11</volume>(<issue>7-8</issue>):<fpage>1253</fpage>–<lpage>1258</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name>. <article-title>Synaptic reverberation underlying mnemonic persistent activity</article-title>. <source>Trends in neurosciences</source>, <volume>24</volume>(<issue>8</issue>):<fpage>455</fpage>–<lpage>463</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><given-names>Weishun</given-names> <surname>Zhong</surname></string-name>, <string-name><given-names>Zhiyue</given-names> <surname>Lu</surname></string-name>, <string-name><given-names>David J</given-names> <surname>Schwab</surname></string-name>, and <string-name><given-names>Arvind</given-names> <surname>Murugan</surname></string-name>. <article-title>Nonequilibrium statistical mechanics of continuous attractors</article-title>. <source>Neural Computation</source>, <volume>32</volume>(<issue>6</issue>):<fpage>1033</fpage>–<lpage>1068</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>Davide</given-names> <surname>Spalla</surname></string-name>, <string-name><given-names>Isabel Maria</given-names> <surname>Cornacchia</surname></string-name>, and <string-name><given-names>Alessandro</given-names> <surname>Treves</surname></string-name>. <article-title>Continuous attractors for dynamic memories</article-title>. <source>Elife</source>, <volume>10</volume>:<fpage>e69499</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><given-names>Si</given-names> <surname>Wu</surname></string-name> and <string-name><given-names>Shun-ichi</given-names> <surname>Amari</surname></string-name>. <article-title>Computing with continuous attractors: stability and online aspects</article-title>. <source>Neural computation</source>, <volume>17</volume>(<issue>10</issue>):<fpage>2215</fpage>–<lpage>2239</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><given-names>Si</given-names> <surname>Wu</surname></string-name>, <string-name><given-names>KY Michael</given-names> <surname>Wong</surname></string-name>, <string-name><given-names>CC Alan</given-names> <surname>Fung</surname></string-name>, <string-name><given-names>Yuanyuan</given-names> <surname>Mi</surname></string-name>, and <string-name><given-names>Wenhao</given-names> <surname>Zhang</surname></string-name>. <article-title>Continuous attractor neural networks: candidate of a canonical model for neural information representation</article-title>. <source>F1000Research</source>,<volume>5</volume>, <year>2016</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>CC Alan</given-names> <surname>Fung</surname></string-name>, <string-name><given-names>KY Michael</given-names> <surname>Wong</surname></string-name>, and <string-name><given-names>Si</given-names> <surname>Wu</surname></string-name>. <article-title>Dynamics of neural networks with continuous attractors</article-title>. <source>EPL (Europhysics Letters)</source>, <volume>84</volume>(<issue>1</issue>):<fpage>18002</fpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><given-names>CC Alan</given-names> <surname>Fung</surname></string-name>, <string-name><given-names>KY Michael</given-names> <surname>Wong</surname></string-name>, and <string-name><given-names>Si</given-names> <surname>Wu</surname></string-name>. <article-title>A moving bump in a continuous manifold: a comprehensive study of the tracking dynamics of continuous attractor neural networks</article-title>. <source>Neural Computation</source>, <volume>22</volume>(<issue>3</issue>):<fpage>752</fpage>–<lpage>792</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="other"><string-name><given-names>Thomas P</given-names> <surname>Trappenberg</surname></string-name>. <article-title>Continuous attractor neural networks</article-title>. <source>In Recent developments in biologically inspired computing</source>, pages <fpage>398</fpage>–<lpage>425</lpage>. Igi Global, <year>2005</year>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>John D</given-names> <surname>Murray</surname></string-name>, <string-name><given-names>Alberto</given-names> <surname>Bernacchia</surname></string-name>, <string-name><given-names>David J</given-names> <surname>Freedman</surname></string-name>, <string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name>, <string-name><given-names>Jonathan D</given-names> <surname>Wallis</surname></string-name>, <string-name><given-names>Xinying</given-names> <surname>Cai</surname></string-name>, <string-name><given-names>Camillo</given-names> <surname>Padoa-Schioppa</surname></string-name>, <string-name><given-names>Tatiana</given-names> <surname>Pasternak</surname></string-name>, <string-name><given-names>Hyojung</given-names> <surname>Seo</surname></string-name>, <string-name><given-names>Daeyeol</given-names> <surname>Lee</surname></string-name>, <etal>et al.</etal> <article-title>A hierarchy of intrinsic timescales across primate cortex</article-title>. <source>Nature neuroscience</source>, <volume>17</volume>(<issue>12</issue>):<fpage>1661</fpage>–<lpage>1663</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><string-name><given-names>Joshua H</given-names> <surname>Siegle</surname></string-name>, <string-name><given-names>Xiaoxuan</given-names> <surname>Jia</surname></string-name>, <string-name><given-names>Séverine</given-names> <surname>Durand</surname></string-name>, <string-name><given-names>Sam</given-names> <surname>Gale</surname></string-name>, <string-name><given-names>Corbett</given-names> <surname>Bennett</surname></string-name>, <string-name><given-names>Nile</given-names> <surname>Graddis</surname></string-name>, <string-name><given-names>Greggory</given-names> <surname>Heller</surname></string-name>, <string-name><given-names>Tamina K</given-names> <surname>Ramirez</surname></string-name>, <string-name><given-names>Hannah</given-names> <surname>Choi</surname></string-name>, <string-name><given-names>Jennifer A</given-names> <surname>Luviano</surname></string-name>, <etal>et al.</etal> <article-title>Survey of spiking in the mouse visual system reveals functional hierarchy</article-title>. <source>Nature</source>, <volume>592</volume>(<issue>7852</issue>):<fpage>86</fpage>–<lpage>92</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><given-names>Richard</given-names> <surname>Gao</surname></string-name>, <string-name><given-names>Ruud L</given-names> <surname>van den Brink</surname></string-name>, <string-name><given-names>Thomas</given-names> <surname>Pfeffer</surname></string-name>, and <string-name><given-names>Bradley</given-names> <surname>Voytek</surname></string-name>. <article-title>Neuronal timescales are functionally dynamic and shaped by cortical microarchitecture</article-title>. <source>Elife</source>, <volume>9</volume>:<fpage>e61277</fpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="other"><string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Junjie</given-names> <surname>Jiang</surname></string-name>, and <string-name><given-names>Ulises</given-names> <surname>Pereira-Obilinovic</surname></string-name>. <article-title>Bifurcation in space: Emergence of function modularity in the neocortex</article-title>. <source>bioRxiv</source>, pages <fpage>2023</fpage>–<lpage>06</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><string-name><given-names>Jorge F</given-names> <surname>Mej ías</surname></string-name> and <string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name>. <article-title>Mechanisms of distributed working memory in a large-scale network of macaque neocortex</article-title>. <source>Elife</source>, <volume>11</volume>:<fpage>e72136</fpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="other"><string-name><given-names>Xingyu</given-names> <surname>Ding</surname></string-name>, <string-name><given-names>Sean</given-names> <surname>Froudist-Walsh</surname></string-name>, <string-name><given-names>Jorge</given-names> <surname>Jaramillo</surname></string-name>, <string-name><given-names>Junjie</given-names> <surname>Jiang</surname></string-name>, and <string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name>. <article-title>Predicting distributed working memory activity in a large-scale mouse brain: the importance of the cell type-specific connectome</article-title>. <source>bioRxiv</source>, pages <fpage>2022</fpage>–<lpage>12</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><string-name><given-names>Adrian</given-names> <surname>Hernandez</surname></string-name>, <string-name><given-names>Emilio</given-names> <surname>Salinas</surname></string-name>, <string-name><given-names>Rafael</given-names> <surname>Garcia</surname></string-name>, and <string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name>. <article-title>Discrimination in the sense of flutter: new psychophysical measurements in monkeys</article-title>. <source>Journal of Neuroscience</source>, <volume>17</volume>(<issue>16</issue>):<fpage>6391</fpage>–<lpage>6400</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><string-name><given-names>Robert J</given-names> <surname>Sinclair</surname></string-name> and <string-name><given-names>Harold</given-names> <surname>Burton</surname></string-name>. <article-title>Discrimination of vibrotactile frequencies in a delayed pair comparison task</article-title>. <source>Perception &amp; psychophysics</source>, <volume>58</volume>(<issue>5</issue>):<fpage>680</fpage>–<lpage>692</lpage>, <year>1996</year>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><given-names>Arash</given-names> <surname>Fassihi</surname></string-name>, <string-name><given-names>Athena</given-names> <surname>Akrami</surname></string-name>, <string-name><given-names>Vahid</given-names> <surname>Esmaeili</surname></string-name>, and <string-name><given-names>Mathew E</given-names> <surname>Diamond</surname></string-name>. <article-title>Tactile perception and working memory in rats and humans</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>111</volume>(<issue>6</issue>):<fpage>2331</fpage>–<lpage>2336</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><given-names>Arash</given-names> <surname>Fassihi</surname></string-name>, <string-name><given-names>Athena</given-names> <surname>Akrami</surname></string-name>, <string-name><given-names>Francesca</given-names> <surname>Pulecchi</surname></string-name>, <string-name><given-names>Vinzenz</given-names> <surname>Sch önfelder</surname></string-name>, and <string-name><given-names>Mathew E</given-names> <surname>Diamond</surname></string-name>. <article-title>Transformation of perception from sensory to motor cortex</article-title>. <source>Current Biology</source>, <volume>27</volume>(<issue>11</issue>):<fpage>1585</fpage>–<lpage>1596</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><string-name><given-names>Vahid</given-names> <surname>Esmaeili</surname></string-name> and <string-name><given-names>Mathew E</given-names> <surname>Diamond</surname></string-name>. <article-title>Neuronal correlates of tactile working memory in prefrontal and vibrissal somatosensory cortex</article-title>. <source>Cell reports</source>, <volume>27</volume>(<issue>11</issue>):<fpage>3167</fpage>–<lpage>3181</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><given-names>Yonatan</given-names> <surname>Loewenstein</surname></string-name>, <string-name><given-names>Ofri</given-names> <surname>Raviv</surname></string-name>, and <string-name><given-names>Merav</given-names> <surname>Ahissar</surname></string-name>. <article-title>Dissecting the roles of supervised and unsupervised learning in perceptual discrimination judgments</article-title>. <source>Journal of Neuroscience</source>, <volume>41</volume>(<issue>4</issue>):<fpage>757</fpage>–<lpage>765</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><string-name><given-names>Mehrdad</given-names> <surname>Jazayeri</surname></string-name> and <string-name><given-names>Michael N</given-names> <surname>Shadlen</surname></string-name>. <article-title>Temporal context calibrates interval timing</article-title>. <source>Nature neuroscience</source>, <volume>13</volume>(<issue>8</issue>):<fpage>1020</fpage>–<lpage>1026</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><string-name><given-names>Matthias</given-names> <surname>Fritsche</surname></string-name>, <string-name><given-names>Pim</given-names> <surname>Mostert</surname></string-name>, and <string-name><given-names>Floris P</given-names> <surname>de Lange</surname></string-name>. <article-title>Opposite effects of recent history on perception and decision</article-title>. <source>Current Biology</source>, <volume>27</volume>(<issue>4</issue>):<fpage>590</fpage>–<lpage>595</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><string-name><given-names>Lux</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Arielle</given-names> <surname>Chan</surname></string-name>, <string-name><given-names>Shah M</given-names> <surname>Iqbal</surname></string-name>, and <string-name><given-names>Daniel</given-names> <surname>Goldreich</surname></string-name>. <article-title>An adaptation-induced repulsion illusion in tactile spatial perception</article-title>. <source>Frontiers in human neuroscience</source>, <volume>11</volume>:<fpage>331</fpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><string-name><surname>I Hachen</surname>, <given-names>S Reinartz</given-names></string-name>, <string-name><surname>R Brasselet</surname>, <given-names>A Stroligo</given-names></string-name>, and <string-name><given-names>ME</given-names> <surname>Diamond</surname></string-name>. <article-title>Dynamics of history-dependent perceptual judgment</article-title>. <source>Nature communications</source>, <volume>12</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>15</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><string-name><given-names>Tomas</given-names> <surname>Knapen</surname></string-name>, <string-name><given-names>Martin</given-names> <surname>Rolfs</surname></string-name>, <string-name><given-names>Mark</given-names> <surname>Wexler</surname></string-name>, and <string-name><given-names>Patrick</given-names> <surname>Cavanagh</surname></string-name>. <article-title>The reference frame of the tilt aftereffect</article-title>. <source>Journal of Vision</source>, <volume>10</volume>(<issue>1</issue>):<fpage>8</fpage>–<lpage>8</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><string-name><given-names>Marco</given-names> <surname>Boi</surname></string-name>, <string-name><given-names>Haluk Ö</given-names> <surname>ğmen</surname></string-name>, and <string-name><given-names>Michael H</given-names> <surname>Herzog</surname></string-name>. <article-title>Motion and tilt aftereffects occur largely in retinal, not in object, coordinates in the ternus–pikler display</article-title>. <source>Journal of Vision</source>, <volume>11</volume>(<issue>3</issue>):<fpage>7</fpage>–<lpage>7</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><string-name><given-names>Sebastiaan</given-names> <surname>Mathôt</surname></string-name> and <string-name><given-names>Jan</given-names> <surname>Theeuwes</surname></string-name>. <article-title>A reinvestigation of the reference frame of the tilt-adaptation aftereffect</article-title>. <source>Scientific reports</source>, <volume>3</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>7</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><string-name><given-names>Sagi</given-names> <surname>Jaffe-Dax</surname></string-name>, <string-name><given-names>Eva</given-names> <surname>Kimel</surname></string-name>, and <string-name><given-names>Merav</given-names> <surname>Ahissar</surname></string-name>. <article-title>Shorter cortical adaptation in dyslexia is broadly distributed in the superior temporal lobe and includes the primary auditory cortex</article-title>. <source>ELife</source>, <volume>7</volume>:<fpage>e30018</fpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><string-name><given-names>Sagi</given-names> <surname>Jaffe-Dax</surname></string-name>, <string-name><given-names>Or</given-names> <surname>Frenkel</surname></string-name>, and <string-name><given-names>Merav</given-names> <surname>Ahissar</surname></string-name>. <article-title>Dyslexics’ faster decay of implicit memory for sounds and words is manifested in their shorter neural adaptation</article-title>. <source>Elife</source>, <volume>6</volume>:<fpage>e20557</fpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="book"><collab>Daniel Algom</collab>. <chapter-title>8 memory psychophysics: An examination of its perceptual and cognitive prospects</chapter-title>. <source>In Advances in psychology</source>, volume <volume>92</volume>, pages <fpage>441</fpage>–<lpage>513</lpage>. <publisher-name>Elsevier</publisher-name>, <year>1992</year>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="book"><collab>Eustace Christopher Poulton and Simon Poulton</collab>. <source>Bias in quantifying judgements</source>. <publisher-loc>Taylor &amp; Francis</publisher-loc>, <year>1989</year>.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><string-name><given-names>Claudia</given-names> <surname>Preuschhof</surname></string-name>, <string-name><given-names>Torsten</given-names> <surname>Schubert</surname></string-name>, <string-name><given-names>Arno</given-names> <surname>Villringer</surname></string-name>, and <string-name><given-names>Hauke R</given-names> <surname>Heekeren</surname></string-name>. <article-title>Prior information biases stimulus representations during vibrotactile decision making</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>22</volume>(<issue>5</issue>):<fpage>875</fpage>–<lpage>887</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><string-name><given-names>Maria</given-names> <surname>Olkkonen</surname></string-name>, <string-name><given-names>Patrice F</given-names> <surname>McCarthy</surname></string-name>, and <string-name><given-names>Sarah R</given-names> <surname>Allred</surname></string-name>. <article-title>The central tendency bias in color perception: Effects of internal and external noise</article-title>. <source>Journal of vision</source>, <volume>14</volume>(<issue>11</issue>):<fpage>5</fpage>–<lpage>5</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="other"><string-name><given-names>Grethe M</given-names> <surname>Olsen</surname></string-name>, <string-name><given-names>Karoline</given-names> <surname>Hovde</surname></string-name>, <string-name><given-names>Hideki</given-names> <surname>Kondo</surname></string-name>, <string-name><given-names>Teri</given-names> <surname>Sakshaug</surname></string-name>, <string-name><given-names>Hanna</given-names> <surname>Haaland Sømme</surname></string-name>, <string-name><given-names>Jonathan R</given-names> <surname>Whitlock</surname></string-name>, and <string-name><given-names>Menno P</given-names> <surname>Witter</surname></string-name>. <article-title>Organization of posterior parietal–frontal connections in the rat</article-title>. <source>Frontiers in systems neuroscience</source>, page <fpage>38</fpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="other"><string-name><given-names>Ke</given-names> <surname>Tong</surname></string-name> and <string-name><surname>Chad Dub</surname> <given-names>é.</given-names></string-name> <article-title>A tale of two literatures: A fidelity-based integration account of central tendency bias and serial dependency</article-title>. <source>Computational Brain &amp; Behavior</source>, pages <fpage>1</fpage>–<lpage>21</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="journal"><string-name><given-names>Muhsin</given-names> <surname>Karim</surname></string-name>, <string-name><given-names>Justin A</given-names> <surname>Harris</surname></string-name>, <string-name><given-names>Angela</given-names> <surname>Langdon</surname></string-name>, and <string-name><given-names>Michael</given-names> <surname>Breakspear</surname></string-name>. <article-title>The influence of prior experience and expected timing on vibrotactile discrimination</article-title>. <source>Frontiers in neuroscience</source>, <volume>7</volume>:<fpage>255</fpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c58"><label>[58]</label><mixed-citation publication-type="journal"><string-name><given-names>Stephen M</given-names> <surname>Kerst</surname></string-name> and <string-name><given-names>James H</given-names> <surname>Howard</surname></string-name>. <article-title>Memory psychophysics for visual area and length</article-title>. <source>Memory &amp; Cognition</source>, <volume>6</volume>(<issue>3</issue>):<fpage>327</fpage>–<lpage>335</lpage>, <year>1978</year>.</mixed-citation></ref>
<ref id="c59"><label>[59]</label><mixed-citation publication-type="journal"><string-name><given-names>Dobromir</given-names> <surname>Rahnev</surname></string-name> and <string-name><given-names>Rachel N</given-names> <surname>Denison</surname></string-name>. <article-title>Suboptimality in perceptual decision making</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>41</volume>, <year>2018</year>.</mixed-citation></ref>
<ref id="c60"><label>[60]</label><mixed-citation publication-type="journal"><string-name><given-names>Amadeus</given-names> <surname>Maes</surname></string-name>, <string-name><given-names>Mauricio</given-names> <surname>Barahona</surname></string-name>, and <string-name><given-names>Claudia</given-names> <surname>Clopath</surname></string-name>. <article-title>Long-and short-term history effects in a spiking network model of statistical learning</article-title>. <source>Scientific Reports</source>, <volume>13</volume>(<issue>1</issue>):<fpage>12939</fpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c61"><label>[61]</label><mixed-citation publication-type="journal"><string-name><given-names>Joaquin M</given-names> <surname>Fuster</surname></string-name> and <string-name><given-names>Garrett E</given-names> <surname>Alexander</surname></string-name>. <article-title>Neuron activity related to short-term memory</article-title>. <source>Science</source>, <volume>173</volume>(<issue>3997</issue>):<fpage>652</fpage>–<lpage>654</lpage>, <year>1971</year>.</mixed-citation></ref>
<ref id="c62"><label>[62]</label><mixed-citation publication-type="journal"><string-name><given-names>Yasushi</given-names> <surname>Miyashita</surname></string-name> and <string-name><given-names>Han Soo</given-names> <surname>Chang</surname></string-name>. <article-title>Neuronal correlate of pictorial short-term memory in the primate temporal cortex</article-title>. <source>Nature</source>, <volume>331</volume>(<issue>6151</issue>):<fpage>68</fpage>–<lpage>70</lpage>, <year>1988</year>.</mixed-citation></ref>
<ref id="c63"><label>[63]</label><mixed-citation publication-type="journal"><string-name><given-names>Shintaro</given-names> <surname>Funahashi</surname></string-name>, <string-name><given-names>Charles J</given-names> <surname>Bruce</surname></string-name>, and <string-name><given-names>Patricia S</given-names> <surname>Goldman-Rakic</surname></string-name>. <article-title>Mnemonic coding of visual space in the monkey’s dorsolateral prefrontal cortex</article-title>. <source>Journal of neurophysiology</source>, <volume>61</volume>(<issue>2</issue>):<fpage>331</fpage>–<lpage>349</lpage>, <year>1989</year>.</mixed-citation></ref>
<ref id="c64"><label>[64]</label><mixed-citation publication-type="journal"><string-name><given-names>Shintaro</given-names> <surname>Funahashi</surname></string-name>, <string-name><given-names>Charles J</given-names> <surname>Bruce</surname></string-name>, and <string-name><given-names>Patricia S</given-names> <surname>Goldman-Rakic</surname></string-name>. <article-title>Visuospatial coding in primate prefrontal neurons revealed by oculomotor paradigms</article-title>. <source>Journal of neurophysiology</source>, <volume>63</volume>(<issue>4</issue>):<fpage>814</fpage>–<lpage>831</lpage>, <year>1990</year>.</mixed-citation></ref>
<ref id="c65"><label>[65]</label><mixed-citation publication-type="journal"><string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name>, <string-name><given-names>Carlos D</given-names> <surname>Brody</surname></string-name>, <string-name><given-names>Adrián</given-names> <surname>Hernández</surname></string-name>, and <string-name><given-names>Luis</given-names> <surname>Lemus</surname></string-name>. <article-title>Neuronal correlates of parametric working memory in the prefrontal cortex</article-title>. <source>Nature</source>, <volume>399</volume>(<issue>6735</issue>):<fpage>470</fpage>–<lpage>473</lpage>, <year>1999</year>.</mixed-citation></ref>
<ref id="c66"><label>[66]</label><mixed-citation publication-type="journal"><string-name><given-names>Emilio</given-names> <surname>Salinas</surname></string-name>, <string-name><given-names>Adrian</given-names> <surname>Hernandez</surname></string-name>, <string-name><given-names>Antonio</given-names> <surname>Zainos</surname></string-name>, and <string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name>. <article-title>Periodicity and firing rate as candidate neural codes for the frequency of vibrotactile stimuli</article-title>. <source>Journal of neuroscience</source>, <volume>20</volume>(<issue>14</issue>):<fpage>5503</fpage>–<lpage>5515</lpage>, <year>2000</year>.</mixed-citation></ref>
<ref id="c67"><label>[67]</label><mixed-citation publication-type="journal"><string-name><given-names>Xiaoxing</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Wenjun</given-names> <surname>Yan</surname></string-name>, <string-name><given-names>Wenliang</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Hongmei</given-names> <surname>Fan</surname></string-name>, <string-name><given-names>Ruiqing</given-names> <surname>Hou</surname></string-name>, <string-name><given-names>Yulei</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Zhaoqin</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Chaofan</given-names> <surname>Ge</surname></string-name>, <string-name><given-names>Shumin</given-names> <surname>Duan</surname></string-name>, <string-name><given-names>Albert</given-names> <surname>Compte</surname></string-name>, <etal>et al.</etal> <article-title>Active information maintenance in working memory by a sensory cortex</article-title>. <source>Elife</source>, <volume>8</volume>:<fpage>e43191</fpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c68"><label>[68]</label><mixed-citation publication-type="journal"><string-name><given-names>John J</given-names> <surname>Hopfield</surname></string-name>. <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>Proceedings of the national academy of sciences</source>, <volume>79</volume>(<issue>8</issue>):<fpage>2554</fpage>–<lpage>2558</lpage>, <year>1982</year>.</mixed-citation></ref>
<ref id="c69"><label>[69]</label><mixed-citation publication-type="book"><string-name><given-names>Daniel J</given-names> <surname>Amit</surname></string-name> and <string-name><given-names>Daniel J</given-names> <surname>Amit</surname></string-name>. <source>Modeling brain function: The world of attractor neural networks</source>. <publisher-name>Cambridge university press</publisher-name>, <year>1992</year>.</mixed-citation></ref>
<ref id="c70"><label>[70]</label><mixed-citation publication-type="journal"><string-name><given-names>Francesco P</given-names> <surname>Battaglia</surname></string-name> and <string-name><given-names>Alessandro</given-names> <surname>Treves</surname></string-name>. <article-title>Stable and rapid recurrent processing in realistic autoassociative memories</article-title>. <source>Neural Computation</source>, <volume>10</volume>(<issue>2</issue>):<fpage>431</fpage>–<lpage>450</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c71"><label>[71]</label><mixed-citation publication-type="journal"><string-name><given-names>Omri</given-names> <surname>Barak</surname></string-name>, <string-name><given-names>David</given-names> <surname>Sussillo</surname></string-name>, <string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name>, <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name>, and <string-name><given-names>LF</given-names> <surname>Abbott</surname></string-name>. <article-title>From fixed points to chaos: three models of delayed discrimination</article-title>. <source>Progress in neurobiology</source>, <volume>103</volume>:<fpage>214</fpage>–<lpage>222</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c72"><label>[72]</label><mixed-citation publication-type="journal"><string-name><given-names>Gianluigi</given-names> <surname>Mongillo</surname></string-name>, <string-name><given-names>Omri</given-names> <surname>Barak</surname></string-name>, and <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name>. <article-title>Synaptic theory of working memory</article-title>. <source>Science</source>, <volume>319</volume>(<issue>5869</issue>):<fpage>1543</fpage>–<lpage>1546</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c73"><label>[73]</label><mixed-citation publication-type="journal"><string-name><given-names>Omri</given-names> <surname>Barak</surname></string-name> and <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name>. <article-title>Persistent activity in neural networks with dynamic synapses</article-title>. <source>PLoS Comput Biol</source>, <volume>3</volume>(<issue>2</issue>):<fpage>e35</fpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c74"><label>[74]</label><mixed-citation publication-type="journal"><string-name><given-names>Joao</given-names> <surname>Barbosa</surname></string-name>, <string-name><given-names>Heike</given-names> <surname>Stein</surname></string-name>, <string-name><given-names>Rebecca L</given-names> <surname>Martinez</surname></string-name>, <string-name><given-names>Adrià</given-names> <surname>Galan-Gadea</surname></string-name>, <string-name><given-names>Sihai</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Josep</given-names> <surname>Dalmau</surname></string-name>, <string-name><given-names>Kirsten</given-names> <surname>Adam</surname></string-name>, <string-name><given-names>Josep</given-names> <surname>Valls-Solé</surname></string-name>, <string-name><given-names>Christos</given-names> <surname>Constantinidis</surname></string-name>, and <string-name><given-names>Albert</given-names> <surname>Compte</surname></string-name>. <article-title>Interplay between persistent activity and activity-silent dynamics in the prefrontal cortex underlies serial biases in working memory</article-title>. <source>Nature neuroscience</source>, <volume>23</volume>(<issue>8</issue>):<fpage>1016</fpage>–<lpage>1024</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c75"><label>[75]</label><mixed-citation publication-type="other"><string-name><given-names>Merav</given-names> <surname>Stern</surname></string-name>, <string-name><given-names>Nicolae</given-names> <surname>Istrate</surname></string-name>, and <string-name><given-names>Luca</given-names> <surname>Mazzucato</surname></string-name>. <article-title>A reservoir of timescales in random neural networks</article-title>. <source>bioRxiv</source>, <year>2021</year>.</mixed-citation></ref>
<ref id="c76"><label>[76]</label><mixed-citation publication-type="journal"><string-name><given-names>Omri</given-names> <surname>Barak</surname></string-name>, <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name>, and <string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name>. <article-title>Neuronal population coding of parametric working memory</article-title>. <source>Journal of Neuroscience</source>, <volume>30</volume>(<issue>28</issue>):<fpage>9424</fpage>–<lpage>9430</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c77"><label>[77]</label><mixed-citation publication-type="journal"><string-name><given-names>Paul</given-names> <surname>Miller</surname></string-name>, <string-name><given-names>Carlos D</given-names> <surname>Brody</surname></string-name>, <string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name>, and <string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name>. <article-title>A recurrent network model of somatosensory parametric working memory in the prefrontal cortex</article-title>. <source>Cerebral Cortex</source>, <volume>13</volume>(<issue>11</issue>):<fpage>1208</fpage>–<lpage>1218</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c78"><label>[78]</label><mixed-citation publication-type="journal"><string-name><given-names>Christian K</given-names> <surname>Machens</surname></string-name>, <string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name>, and <string-name><given-names>Carlos D</given-names> <surname>Brody</surname></string-name>. <article-title>Flexible control of mutual inhibition: a neural model of two-interval discrimination</article-title>. <source>Science</source>, <volume>307</volume>(<issue>5712</issue>):<fpage>1121</fpage>–<lpage>1124</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c79"><label>[79]</label><mixed-citation publication-type="journal"><string-name><given-names>Omri</given-names> <surname>Barak</surname></string-name> and <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name>. <article-title>Working models of working memory</article-title>. <source>Current opinion in neurobiology</source>, <volume>25</volume>:<fpage>20</fpage>–<lpage>24</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c80"><label>[80]</label><mixed-citation publication-type="journal"><string-name><given-names>Christian K</given-names> <surname>Machens</surname></string-name>, <string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name>, and <string-name><given-names>Carlos D</given-names> <surname>Brody</surname></string-name>. <article-title>Functional, but not anatomical, separation of “what” and “when” in prefrontal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>30</volume>(<issue>1</issue>):<fpage>350</fpage>–<lpage>360</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c81"><label>[81]</label><mixed-citation publication-type="journal"><string-name><given-names>Emilio</given-names> <surname>Salinas</surname></string-name>. <article-title>Prior and prejudice</article-title>. <source>Nature neuroscience</source>, <volume>14</volume>(<issue>8</issue>):<fpage>943</fpage>–<lpage>945</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c82"><label>[82]</label><mixed-citation publication-type="journal"><string-name><given-names>Henry WP</given-names> <surname>Dalgleish</surname></string-name>, <string-name><given-names>Lloyd E</given-names> <surname>Russell</surname></string-name>, <string-name><given-names>Adam M</given-names> <surname>Packer</surname></string-name>, <string-name><given-names>Arnd</given-names> <surname>Roth</surname></string-name>, <string-name><given-names>Oliver M</given-names> <surname>Gauld</surname></string-name>, <string-name><given-names>Francesca</given-names> <surname>Greenstreet</surname></string-name>, <string-name><given-names>Emmett J</given-names> <surname>Thompson</surname></string-name>, and <string-name><given-names>Michael</given-names> <surname>Häusser</surname></string-name>. <article-title>How many neurons are sufficient for perception of cortical activity?</article-title> <source>Elife</source>, <volume>9</volume>:<fpage>e58889</fpage>, <year>2020</year>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86725.2.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Sharpee</surname>
<given-names>Tatyana O</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Salk Institute for Biological Studies</institution>
</institution-wrap>
<city>La Jolla</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> study combines disparate results from both psychophysics and neural silencing experiments to suggest a new interpretation of how animals and humans represent and interpret recent events in our memory. A key aspect of the model put forward here is the presence of discrete jumps in neural activity within the posterior parietal region of the cortex. The model is distinct from other models, and the authors provide <bold>convincing</bold> evidence to support it both from existing results as well as from novel experiments.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86725.2.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This paper aims to explain recent experimental results that showed deactivating the PPC in rats reduced both the contraction bias and the recent history bias during working memory tasks. The authors propose a two-component attractor model, with a slow PPC area and a faster WM area (perhaps mPFC, but unspecified). Crucially, the PPC memory has slow adaptation that causes it to eventually decay and then suddenly jump to the value of the last stimulus. These discrete jumps lead to an effective sampling of the distribution of stimuli, as opposed to a gradual drift towards the mean that was proposed by other models. Because these jumps are single-trial events, and behavior on single events is binary, various statistical measures are proposed to support this model. To facilitate this comparison, the authors derive a simple probabilistic model that is consistent with both the mechanistic model and behavioral data from humans and rats. The authors show data consistent with model predictions: longer interstimulus intervals (ISIs) increase biases due to a longer effect over the WM, while longer intertrial intervals (ITIs) reduce biases. Finally, they perform new experiments using skewed or bimodal stimulus distributions, in which the new model better fits the data compared to Bayesian models.</p>
<p>The mechanistic proposed model is simple and elegant, and it captures both biases that were previously observed in behavior, and how these are affected by the ISI and ITI (as explained above). Their findings help rethink whether our understanding of contraction bias is correct.</p>
<p>On the other hand, the main proposal - discrete jumps in PPC - is only indirectly verified. The majority of the behavioral predictions stem from the probabilistic model, which is consistent with the mechanistic one, but does not necessitate it.</p>
<p>
The revised submission uses the self-paced nature of the experiments to confirm the systematic change in bias with inter-trial-interval, as predicted by the model. This analysis strengthens the hypothesis.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86725.2.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Working memory is not error free. Behavioral reports of items held in working memory display several types of bias, including contraction bias and serial dependence. Recent work from Akrami and colleagues demonstrates that inactivating rodent PPC reduces both forms of bias, raising the possibility of a common cause.</p>
<p>In the present study, Boboeva, Pezotta, Clopath, and Akrami introduce circuit and descriptive variants of a model in which the contents of working memory can be replaced samples from recent sensory history. This volatility manifests as contraction bias and serial dependence in simulated behavior, parsimoniously explaining both sources of bias. The authors validate their model by showing that it can recapitulate previously published and novel behavioral results in rodents and neurotypical and atypical humans.</p>
<p>Both the modeling and the experimental work is rigorous, providing convincing evidence that a model of working memory in which reports sometimes sample past experience can produce both contraction bias and serial dependence, and that this model is consistent with behavioral observations across rodents and humans in the parametric working memory (PWM) task.</p>
<p>These efforts constitute an admirable initial validation of the proposed model, and the authors present several novel predictions that will allow for further tests in future experiments. First, the authors note that their circuit model predicts a bimodal error distribution in delayed estimation paradigms (due to noisy sampling of sensory history on a subset of trials) that merges into a unimodal distribution when recent sensory history and the current to-be-reported stimulus have very similar values (Fig. 5c). Analysis of extent delayed estimation datasets (e.g., <ext-link ext-link-type="uri" xlink:href="https://osf.io/jmkc9/">https://osf.io/jmkc9/</ext-link>) or new experiments will provide the opportunity for a straightforward test of this hypothesis.</p>
<p>Second, the bulk of the modeling efforts presented here are devoted to a circuit-level description of how putative posterior parietal cortex (PPC) and working-memory (WM) related networks may interact to produce such volatility and biases in memory. This effort is extremely useful because it allows the model to be constrained by neural observations and manipulations in addition to behavior, and the authors begin this line of inquiry here (by showing that the circuit model can account for effects of optogenetic inactivation of rodent PPC). As the authors note, population electrophysiology in PPC and WM-related areas and single-trial analyses will play an important role in the ultimate validation of this model.</p>
<p>Finally, it is noteworthy that, in the spirit of moving away from an overreliance on p-values (e.g., Amrhein et al., PeerJ 2017), the authors eschew conventional hypothesis testing when reporting their experimental results. The p-values aren't missed, in large part thanks to excellent visualizations and apparently large effect sizes. It's unclear how well this approach would generalize to other questions and datasets; nevertheless, this study provides an interesting data point in the ongoing conversation around reproducibility and rigor.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86725.2.sa3</article-id>
<title-group>
<article-title>Author Response</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Boboeva</surname>
<given-names>Vezha</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2476-8714</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Pezzotta</surname>
<given-names>Alberto</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8998-7942</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Clopath</surname>
<given-names>Claudia</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4507-8648</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Akrami</surname>
<given-names>Athena</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5711-0903</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We thank the editors and the reviewers for their assessment of our revised manuscript. Please see bellow, our answers to the recommendations by reviewer #2.</p>
<disp-quote content-type="editor-comment">
<p>Figure S2F - Seems like a very narrow range of parameters. Is there some fine tuning here?</p>
</disp-quote>
<p>The range of values of tau_P that yields previous-trial biases is bounded by below and above for the following reasons: above a certain value of tau_P (therefore large integration time), the bump that had formed in the previous trial is not strong enough to remain stable for a long time, and therefore dissipates by the time the current trial starts (especially when adaptation is fast, towards the left of the third panel). Below a certain value, instead, this integration timescale is small enough to quickly form a representation of the current trial, hence the bump from the previous trial quickly dissipates (due to mutual inhibition). This interplay between the integration and the adaptation timescale as well as considering a phenomenon which is bounded in time (how close the activity bump is to the second stimulus of the previous trial which is presented between -22.4 and -5.6 seconds from the moment we are considering) yields a region for tau_P which is bounded. This region, however, appears narrow due to the limited number of points we have considered for the simulation grid.</p>
<disp-quote content-type="editor-comment">
<p>Regarding my comment on lapse at the boundaries (old line 221). Lapse parameters in psychometric curves correspond to errors on the &quot;easy&quot; trials. But the mechanistic explanation for lapse trials is that there is a non-zero probability for the subject to respond in a manner that is random and independent of the stimulus. In the case of extreme stimuli, this is the only reason for errors, and thus looking at the edges of the psychometric curves allows to calculate lapse rate. But - the usual assumption for underlying mechanism is that the subject lapses in all trials, regardless of stimulus. If I understand correctly, this is different than the mechanistic reason for lapses in the network model, which was described as something that happens more in the edges than in the center. Or more generally, to be a stimulus-dependent effect.</p>
</disp-quote>
<p>We thank the reviewer for this clarification. The reviewer is right that in our mechanistic model, lapses (as defined by errors on easy trials) are more likely to occur for extreme stimuli, due to the vicinity to the boundary of the attractor. Such errors also occur for non-extreme stimuli, when delay intervals are long enough for the bump in PPC to drift to the boundaries. In experiments, lapse trials as described by the reviewer occur due to multiple different reasons; for lapse that is independent of the stimuli, mechanisms such as attention have been thought to play a role, this however is not included in our model.</p>
<disp-quote content-type="editor-comment">
<p>What are the parameters for the distributions (skewed, bimodal, ...)?</p>
</disp-quote>
<p>These parameters are reported in the legend of Fig.6, where the distributions appear.</p>
<disp-quote content-type="editor-comment">
<p>Bump with adaptation. Sorry for the draft-like comment. I don't think the existing studies are in the form you describe. I do think it might be useful to point readers to these studies. If an interested reader wishes to understand network dynamics in this and similar scenarios, it might be useful to have the pointers. The reference I had in mind was Romani, S., &amp; Tsodyks, M. (2015). Short‐term plasticity based network model of place cells dynamics. Hippocampus, 25(1), 94-105.</p>
</disp-quote>
<p>We thank the reviewer for the clarification, and we will include this reference in the Version of Record.</p>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>eLife assessment</bold></p>
<p>This is an important study about the mechanisms underlying our capacity to represent and hold recent events in our memory and how they are influenced by past experiences. A key aspect of the model put forward here is the presence of discrete jumps in neural activity with the posterior parietal region of the cortex. The strength of evidence is largely solid, with some weaknesses noted in the methodology. Both reviewers suggested ways in which this aspect of the model can to be tested further and resolve conflicts with previously published experimental results, in particular the study by Papadimitriou et al 2014 in Journal of Neurophysiology.</p>
</disp-quote>
<p>We thank the editors for their assessment. As mentioned in the cover letter, we have addressed all the reviewers’ concerns and would like to request and update of the assessment to reflect the revisions we have made.</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
</disp-quote>
<p>We thank both reviewers for their careful reading and feedback that helped clarify many aspects of the model. Below, we address their comments.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>This paper aims to explain recent experimental results that showed deactivating the PPC in rats reduced both the contraction bias and the recent history bias during working memory tasks. The authors propose a twocomponent attractor model, with a slow PPC area and a faster WM area (perhaps mPFC, but unspecified). Crucially, the PPC memory has slow adaptation that causes it to eventually decay and then suddenly jump to the value of the last stimulus. These discrete jumps lead to an effective sampling of the distribution of stimuli, as opposed to a gradual drift towards the mean that was proposed by other models. Because these jumps are single-trial events, and behavior on single events is binary, various statistical measures are proposed to support this model. To facilitate this comparison, the authors derive a simple probabilistic model that is consistent with both the mechanistic model and behavioral data from humans and rats. The authors show data consistent with model predictions: longer interstimulus intervals (ISIs) increase biases due to a longer effect over the WM, while longer intertrial intervals (ITIs) reduce biases. Finally, they perform new experiments using skewed or bimodal stimulus distributions, in which the new model better fits the data compared to Bayesian models.</p>
<p>The mechanistic proposed model is simple and elegant, and it captures both biases that were previously observed in behavior, and how these are affected by the ISI and ITI (as explained above). Their findings help rethink whether our understanding of contraction bias is correct.</p>
<p>On the other hand, the main proposal - discrete jumps in PPC - is only indirectly verified.</p>
</disp-quote>
<p>We agree with the reviewer that the evidence for discrete jumps in PPC has been provided in behavioural results (short-term, n-back trial biases), and not from neural data. However, we believe electrophysiological investigations are out of the scope of the current manuscript and future works are needed to further verify the results.</p>
<disp-quote content-type="editor-comment">
<p>The model predicts a systematic change in bias with inter-trial-interval. Unless I missed it, this is not shown in the experimental data. Perhaps the self-paced nature of the experiments allows to test this?</p>
</disp-quote>
<p>We thank the reviewer for this great suggestion.</p>
<p>We had not previously looked at this in the data for the reason that in the simulations, the ITI is set to either 2.2, 6 or 11 seconds, whereas the experiment is self-paced. Therefore, any comparison with the simulation should be made carefully.</p>
<p>However, after the reviewer’s suggestion, we did look at the change in the bias with the inter-trial interval, by dividing trials according to ITIs lower than 3 seconds (“short” ITI), and higher than 3 seconds (“long” ITI). This choice was motivated by the shape of the distribution of ITIs, which is bimodal, with a peak around 1 second, and another after 3 seconds (new Fig 8F). Hence, we chose 3 seconds as it seemed a natural division. However, 3 seconds also happens to be approximately the 75th percentile of the distribution, and this means that there is much more data in the “short” ITI than the “long” ITI set. In order to have sufficient data in the “long” ITI for clearer effects we used all of our dataset – the negatively skewed, and also two bimodal distributions (of which only one was shown in the manuscript, for succinctness). This larger dataset allows us to clearly see not only a decreasing contraction bias with increasing ITI (Fig 8G), but also a decreasing onetrial-back attractive bias with increasing ITI (Fig 8H). We have uploaded all the datasets as well as scripts used to analyze them to this repository:
<ext-link ext-link-type="uri" xlink:href="https://github.com/vboboeva/ParametricWorkingMemory_Data">https://github.com/vboboeva/ParametricWorkingMemory_Data</ext-link>.</p>
<disp-quote content-type="editor-comment">
<p>The data in some of the figures in the paper are hard to read. For instance, Figure 3B might be easier to  understand if only the first 20 trials or so are shown with larger spacing. Likewise, Figure 5C contains many overlapping curves that are hard to make out.</p>
</disp-quote>
<p>We have limited the dynamics in Fig 3B to the first 50 trials for better visibility. Likewise, as suggested, we report the standard error of the mean instead of the standard deviation in old Fig 5C (new Fig 6C) – this allows for the different curves to be better discernible.</p>
<disp-quote content-type="editor-comment">
<p>There is a gap between the values of tau_PPC and tau_WM. First - is this consistent with reports of slower timescales in PFC compared to other areas?</p>
</disp-quote>
<p>Recent studies by Xiao-Jing Wang and colleagues (Refs. 1-3 below) suggest that may be the case. In Wang et al 2023, Ref 1 below), the authors use a generative model to study the concept of bifurcation in space in working memory, that is accompanied by an inverted-V shape of the time constants as a function of cortical hierarchy.</p>
<p>Briefly, they propose a generative model of the cortex with modularity, incorporating repeats of a canonical local circuit connected via long-range connections. In particular, the authors define a hierarchy for each local circuit. At a critical point in this hierarchy axis, there is a phase transition from monostability to bistability in the firing rate. This means that a local circuit situated below the critical point will only display a low activity steady state, while those above the critical point additionally display a persistent activity steady state.</p>
<p>The model predicts a critical slowing down of the neural fluctuations at the critical point, resulting in an inverted-V shape of the time constants as a function of the hierarchy. They test the predictions of their model – the bifurcation in space and that inverted-V-shaped time constants as a function of the hierarchy - on connectome-based models of the macaque and mouse cortex. Interestingly both datasets show similar behavior. In particular, during working memory, frontal areas (higher in the hierarchy, e.g. area 24c in macaques) has a smaller time constant relative to posterior parietal areas (lower in the hierarchy, like LIP or f7). We have now cited this new work.</p>
<p>[1] <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2023.06.04.543639v1">https://www.biorxiv.org/content/10.1101/2023.06.04.543639v1</ext-link></p>
<p>[2] <ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/articles/72136">https://elifesciences.org/articles/72136</ext-link></p>
<p>[3] <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.12.05.519094v3.abstract">https://www.biorxiv.org/content/10.1101/2022.12.05.519094v3.abstract</ext-link></p>
<disp-quote content-type="editor-comment">
<p>Second - is it important for the model, or is it mostly the adaptation timescale in PPC that matters?</p>
</disp-quote>
<p>We have run simulations producing a phase diagram with tau_theta^P on the x-axis, tau^P on the y-axis, and in color, the fraction of trials in which the bump is in the vicinity of a target (Fig S2 F), before the network is presented with the second stimulus. This target can be the first stimulus s_1 (left), mean over stimuli (middle) and previous trial’s stimulus (right)). White point corresponds to parameters of the default network.</p>
<p>In this phase diagram, the lowest value that tau_P takes is tau_WM=0.01. When tau_P=tau_WM, the bump is rarely in the vicinity of 1-trial-back stimulus, and we can see that tau_PPC should be greater than tau_WM in order for the model to yield 1-trial back effects. We conclude that it is indeed important for tau_PPC &gt; tau_WM.</p>
<p>We have included this in Fig S2 F of the manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Regarding the relation to other models, the model by Hachen et al (Ref 45) also has two interacting memory systems. It could be useful to better state the connection, if it exists.</p>
</disp-quote>
<p>The model proposed by Hachen et al is conceptually different in that one module stores the mean of the sensory stimulus; it could be related to a variant of our model where adaptation is turned off in the PPC network (Fig S2 A). However, the task they model is also different: subjects have to learn the location of a boundary according to which the stimulus is classified as ‘weak’ or ‘strong’, set by the experimenter. Hence, it is a task where learning is needed - this contrasts with the task we are modelling, where only working memory is required. How task demands reconfigure existing circuits via dynamics and/or learning to perform different computations is a fascinating area of research that is outside the scope of this work.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Working memory is not error free. Behavioral reports of items held in working memory display several types of bias, including contraction bias and serial dependence. Recent work from Akrami and colleagues demonstrates that inactivating rodent PPC reduces both forms of bias, raising the possibility of a common cause.</p>
<p>In the present study, Boboeva, Pezzotta, Clopath, and Akrami introduce circuit and descriptive variants of a model in which the contents of working memory can be replaced by previously remembered items. This volatility manifests as contraction bias and serial dependence in simulated behavior, parsimoniously explaining both sources of bias. The authors validate their model by showing that it can recapitulate previously published and novel behavioral results in rodents and neurotypical and atypical humans.</p>
<p>Both the modeling and the experimental work is rigorous, providing compelling evidence that a model of working memory in which reports sometimes sample past experience can produce both contraction bias and serial dependence, and that this model is consistent with behavioral observations across rodents and humans in the parametric working memory (PWM) task.</p>
<p>Evidence for the model advanced by the authors, however, remains incomplete. The model makes several bold predictions about behavior and neural activity, untested here, that either conflict with previous findings or have yet to be reported but are necessary to appropriately constrain the model.</p>
<p>First, in the most general (descriptive) formulation of the Boboeva et al. model, on a fraction of trials items in working memory are replaced by items observed on previous trials. In delayed estimation paradigms, which allow a more direct behavioral readout of memory items on a trial-by-trial basis than the PWM task considered here, reports should therefore be locked to previous items on a fraction of trials rather than display a small but consistent bias towards previous items. However, the latter has been reported (e.g., in primate spatial working memory, Papadimitriou et al., J Neurophysiol 2014). The ready availability of delayed estimation datasets online (e.g., from Rademaker and colleagues, <ext-link ext-link-type="uri" xlink:href="https://osf.io/jmkc9/">https://osf.io/jmkc9/</ext-link>) will facilitate in-depth investigation and reconciliation of this issue.</p>
</disp-quote>
<p>As pointed out by the reviewer, in the PWM task that we are modelling here, the activity in the network is used to make a binary decision. However, it is possible to directly analyse the network activity before the onset of the second stimulus.</p>
<p>In their manuscript, Papadimitriou et al. study a memory-guided saccade task in nonhuman primates and argue that the animals display a small but consistent bias towards previous items (Fig 2). In that figure, the authors compute the error as the difference between the saccade direction and target direction in each trial. They compute this error for all trials in which the preceding trial’s target direction is between 35° and 85° relative to the current trial (counterclockwise with respect to the current trial’s target). They discover that the residual error distribution is unimodal with a mode at 1.29° and a mean at 2.21° (positive, so towards the preceding target’s direction), from which they deduce a small but systematic bias towards previous trial targets.</p>
<p>We have computed a similar measure for our network with default parameters (Table 1), by subtracting the location of the bump at the end of the delay interval (s_hat(t), ‘saccade’) from the initial location of the first stimulus in the current trial (s1(t) or the ‘target’). We have done this for all trials where s1(t)=0.2, and where s2(t-1) takes specific values. These distributions are characterized by two modes. The first corresponds to those trials where the bump is not displaced in WM (i.e. mean of zero). We can also see the appearance of a second mode at the location of s1(t) - s2(t-1), corresponding to the displacements towards the preceding trial’s stimulus described in the main text. If, instead, we limit the analysis to a small range of previous trials close to s1(t) (similar to Papadimitriou et al) then the distribution of residual errors will appear unimodal, as the two modes merge. Importantly, note that there is a large variability around the second mode, expressing a more complex dynamics in the network. As can be seen in Fig 3B, the location of the bump is not always slaved to the one in the PPC in a straightforward way -- due to the adaptation in the PPC, the global inhibition in the connectivity kernel, as well as interleaved design for various delay intervals, the WM bump can be displaced in nontrivial ways (see also Recommendation no 4), yielding the dispersion around the second peak. It remains to be seen whether such patterns can be observed in the data from previous works on continuous working memory recall (including Papadimitriou et al). However, to our knowledge, such detailed and full analysis of errors at the level of individual trials has not been done.</p>
<p>In summary, this analysis shows that the type of dynamics in our network is not one of the two cases: 1) small and systematic bias in each and every trial or 2) large error that occurs only rarely; rather, the dispersion around both modes suggests that the dynamics in our model are a mixture of these two limit cases.</p>
<p>We have also performed another typical analysis, reported in several continuous recall tasks (e.g. Jazayeri and Shadlen 2010) where contraction bias has been reported. We plot WM bump locations after the delay period for every trial (s_hat(t)), and their averages, against the nominal value of s1(t). We see that the mean WM location deviates from the identity line toward the mean values of s1(t), again showing contraction bias as an average effect, while individual trials follow the dynamics explained above.</p>
<p>We have now included a new section on continuous recall (Sect. 1.5 and a new figure (Fig 5)), which details the two above-mentioned analyses. The analysis of freely available datasets of delayed estimation tasks, unfortunately, is out of the scope of this work, and we leave such analyses to future studies.</p>
<disp-quote content-type="editor-comment">
<p>Second, the bulk of the modeling efforts presented here are devoted to a circuit-level description of how putative posterior parietal cortex (PPC) and working-memory (WM) related networks may interact to produce such volatility and biases in memory. This effort is extremely useful because it allows the model to be constrained by neural observations and manipulations in addition to behavior, and the authors begin this line of inquiry here (by showing that the circuit model can account for effects of optogenetic inactivation of rodent PPC).</p>
<p>Further experiments, particularly electrophysiology in PPC and WM-related areas, will allow further validation of the circuit model. For example, the model makes the strong prediction that WM-related activity should display 'jumps' to states reflecting previously presented items on some trials. This hypothesis is readily testable using modern high-density recording techniques and single-trial analyses.</p>
</disp-quote>
<p>As mentioned in response to the previous comment, we note again that in the WM network, the bump ‘displacement’ has a complex dynamics -- the examples we have provided in Fig 1A and 2B mainly show the cases in which jumps occur in the WM network, but this is not the only type of dynamics we observe in the model. We do have instances in which the continuity of the model causes drift across values, and we have now replaced the right panel in Fig 2B with one such instance, in order to emphasize that this displacement towards the previous trial’s stimulus (s2(t-1)) can occur in various ways. For a more thorough analysis, we have analyzed the distance between s1(t) and the position of the bump in the WM network at the end of the delay period s_hat(t), conditioned on specific values of s1(t) and s2(t-1) (Fig 5C). In this figure, we can see the appearance of two modes: one centered around 0, corresponding to the correct trials where the stimulus is kept in WM (s1(t) = s_hat(t)), and another mode centered around s2(t-1), the location of the second stimulus of the previous trial, where the bump is displaced. Note, as we explain in Sect. 1.5, the large dispersion around this second mode, which suggests that the bump is not always displaced to that specific location and may undergo drift.</p>
<p>We agree with the reviewer that future electrophysiological experiments (or analysis of existing datasets) are necessary for validation of these results.</p>
<disp-quote content-type="editor-comment">
<p>Finally, while there has been a refreshing movement away from an overreliance on p-values in recent years (e.g., Amrhein et al., PeerJ 2017), hypothesis testing, when used appropriately, provides the reader with useful information about the amount of variability in experimental datasets. While the excellent visualizations and apparently strong effect sizes in the paper mitigate the need for p-values to an extent, the paucity of statistical analysis does impede interpretation of a number of panels in the paper (e.g., the results for the negatively skewed distribution in 5D, the reliability of the attractive effects in 6a/b for 2- and 3- trials back).</p>
</disp-quote>
<p>We share the reviewer’s criticism towards the misuse of p-values – in order for a clearer interpretation of old Fig 5D (new Fig 7E), we have looked at the 2 and 3 trials-back biases by using all of our dataset – the negatively skewed, and also two bimodal distributions (of which only one was shown in the manuscript). This larger dataset of 43 subjects (approximately 17,200 trials) allows us to clearly see the 2 and 3 trial back attractive biases, and the effect that the delay interval exerts on them.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p>
<p>Fig 5 A&amp;C - It might be beneficial to separate the distribution of stimuli from the performance. It is hard to read the details of the performance, especially with error bars.</p>
</disp-quote>
<p>Following the next recommendation, we have exchanged the standard deviation to standard errors of the mean, hopefully this allows to better read the performance.</p>
<disp-quote content-type="editor-comment">
<p>Fig 5C. The number of participants should be written. Perhaps standard errors instead of standard deviation?</p>
</disp-quote>
<p>We have now changed the standard deviation to standard errors of the mean and included the number of participants in the figure.</p>
<disp-quote content-type="editor-comment">
<p>Fig 2B - hard to understand, because there is no marking of where &quot;perfect&quot; memory of s1 would be.</p>
</disp-quote>
<p>The perfect memory of s1 is shown in the upper panel as black bars.</p>
<disp-quote content-type="editor-comment">
<p>Fig 3B. dot number 9 (blue, around 0.7) - why is WM higher than stimulus?</p>
</disp-quote>
<p>This trial has a long ISI (blue means 10s). During this delay, the bump in the PPC, under the influence of adaptation, drifts far below the first stimulus (note that the previous trial also had its first stimulus in the same location, as a result of which the adaptative thresholds have built up significantly, causing the bump to move away from that location). During this delay period, neurons in the WM network receive inputs from the PPC network: if this input is strong enough, it can disrupt an existing bump; if not, this input still exerts inhibiting influence on the existing bump via the global inhibition in the connectivity. This can cause an existing bump to slowly drift in a random direction, and finally dissipate. Note that the lines in Fig 2B represent the neuron with the maximal activity, this activity may be a stable bump, or an unstable bump that may soon dissipate.</p>
<p>Other examples with similar dynamics include trials 43 and 54.</p>
<disp-quote content-type="editor-comment">
<p>L167 fewer -&gt; smaller</p>
</disp-quote>
<p>We have now corrected this.</p>
<disp-quote content-type="editor-comment">
<p>Fig 3C - bump can also be in between. Is this binned?</p>
</disp-quote>
<p>We have not binned the length of the attractor; to produce that figure, we check whether the position of the neuron with the maximal firing rate is within a distance of ±5% of the length of the whole line attractor from the target location.</p>
<disp-quote content-type="editor-comment">
<p>L221 Lapse at the boundary of attractor. This seems very different from behavior.
Specifically, if it is in the boundaries, it should be stimulus dependent.</p>
</disp-quote>
<p>Very sorry, we did not manage to understand the reviewer’s comment.</p>
<disp-quote content-type="editor-comment">
<p>L236 are -&gt; is</p>
</disp-quote>
<p>We have now corrected this.</p>
<disp-quote content-type="editor-comment">
<p>Fig S4 - should be mostly in main text.</p>
</disp-quote>
<p>Part of this figure is in Fig 6A, but given the amount of detail, we think Supplementary Material is better suited.</p>
<disp-quote content-type="editor-comment">
<p>L253-254. Differences across all distributions - very minor except the bimodal case.</p>
</disp-quote>
<p>That is correct, this is why we conducted the experiment with the bimodal distribution, to better differentiate the predictions of the two models.</p>
<disp-quote content-type="editor-comment">
<p>L273 extra comma after &quot;This probability&quot;</p>
</disp-quote>
<p>We have now corrected this.</p>
<disp-quote content-type="editor-comment">
<p>ITI was only introduced in section 1.5.2. Perhaps worth mentioning the default 5s value earlier in the paper.</p>
</disp-quote>
<p>We have now mentioned this in line 97-98.</p>
<disp-quote content-type="editor-comment">
<p>Fig S6B title: perhaps &quot;previous stimuli&quot;?</p>
</disp-quote>
<p>We have now corrected this.</p>
<disp-quote content-type="editor-comment">
<p>L364 i&quot;n A given trial&quot;</p>
<p>Equation 2 - no decay term?</p>
</disp-quote>
<p>Thank you for pointing out this error, we have now corrected this.</p>
<disp-quote content-type="editor-comment">
<p>Equation 5,6 are j^W and j^P indices of neurons in those populations?</p>
</disp-quote>
<p>Yes, j^W indexes neurons in the WM network, and j^P those in the PPC. We have now added this in the text for clarity.</p>
<disp-quote content-type="editor-comment">
<p>Bump with adaptation - other REFs? Sandro?</p>
</disp-quote>
<p>We are aware of continuous bump attractors implementing short-term synaptic plasticity in various studies (including by Sandro Romani), but not in the form we have described. May the reviewer kindly point us towards the relevant literature.</p>
<disp-quote content-type="editor-comment">
<p>Free boundary - what is the connectivity for neurons 1 and N? Is it weaker than others? Is the integral still 1? Does this induce some bias on the extreme values?</p>
</disp-quote>
<p>The connectivity of the network is all-to-all. However, as expressed by Eq. (3), the distance-dependent contribution to the weights, K, decreases exponentially as we move from neuron 1 onwards, and from neuron N down. The sum (or integral, in the large-N limit) of the K_ij for j on either side of neuron i is unity only when i is sufficiently far from 1 or N. We have rephrased the paragraph starting in line 516 to make this clearer.</p>
<p>The presence of a boundary could introduce a bias in theory, but in practice, it affects the dynamics only when the bump drifts sufficiently close to it. The smallest stimulus in the simulated task has amplitude 0.2, with width 0.05, which implies the activation of 50 neurons on either side of neuron 400. If one compares this with the width of the kernel K in stimulus space (d_0 = 0.02), which spans ~10 neurons, we can see that the bump of activity stays mostly far from the boundary. It is possible, though it is observed rarely, when several consecutive long delay intervals happen to occur, that the bump in PPC drifts beyond the location corresponding to either the minimum or maximum stimulus.</p>
<disp-quote content-type="editor-comment">
<p>Code availability?</p>
</disp-quote>
<p>Code simulating the dynamics of the network as well as analysing the resulting data can be found in the following repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/vboboeva/ParametricWorkingMemory">https://github.com/vboboeva/ParametricWorkingMemory</ext-link>
Code used to analyse human behavioural data and fit them with our statistical model can be found in this repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/vboboeva/ParametricWorkingMemory_Data">https://github.com/vboboeva/ParametricWorkingMemory_Data</ext-link>
Code used to run the auditory PWM experiments with human subjects (adapted from Akrami et al 2018) can be found here: <ext-link ext-link-type="uri" xlink:href="https://github.com/vboboeva/Auditory_PWM_human">https://github.com/vboboeva/Auditory_PWM_human</ext-link></p>
<disp-quote content-type="editor-comment">
<p>L547 stimuli</p>
</disp-quote>
<p>We have now corrected this.</p>
<disp-quote content-type="editor-comment">
<p>Equation 14 uses both stimuli. Was this the same for the rest of analysis in the paper (first figures for instance)?</p>
</disp-quote>
<p>This equation was used for all GLM analyses (Figs 9 and S6).</p>
<disp-quote content-type="editor-comment">
<p>D0 is very small (0.02). Does this mean that activity is essentially discrete in the model? Fig 1A &amp; 2B - the two examples of model activity suggest this is the case. In other words - are there cases where the continuity of the model causes drift across values? Can you show an example (similar to Fig 1A)?</p>
</disp-quote>
<p>Since this point has been raised beforehand, we refer to the first comment, Fig 2B and Sect. 1.5 for the response to this question.</p>
<disp-quote content-type="editor-comment">
<p>Table 1 - inter trial interval 6. Text says 5</p>
</disp-quote>
<p>We have now corrected this in the text.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<p>In addition to my review above, I just have a few minor comments:</p>
<list list-type="bullet">
<list-item><p>If I understood correctly, the squares inside the purple rectangle in Figure 1B are meant to show a gradation from red to blue, but this was hard to make out in the pdf.</p>
</list-item></list>
</disp-quote>
<p>Actually the squares are all on one side or the other of the diagonal, therefore they do not have any gradation.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>line 164: &quot;The resulting dynamics... [are]?&quot;</p>
</list-item></list>
</disp-quote>
<p>We have corrected this in the text.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>Fig 7B legend: &quot;The network performance is on average worse for longer ITIs&quot; – correct?</p>
</list-item></list>
</disp-quote>
<p>This was a mistake, we have replaced worse with better.</p>
<disp-quote content-type="editor-comment">
<p>Other comments</p>
</disp-quote>
<p>We realized that the colorbar reported the incorrect fraction classified in Figs 1B, 2C, 7B (new 8B), S2C, S3A, S5B. We have corrected this in the new version of the manuscript.</p>
<p>We also found a minor mistake in one of our analysis codes that computed the n-trial back biases for different delay intervals. This did not change our results, actually made the effects clearer. The figures concerned are Fig 3F and new Fig 7E.</p>
</body>
</sub-article>
</article>