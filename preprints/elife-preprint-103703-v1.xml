<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">103703</article-id>
<article-id pub-id-type="doi">10.7554/eLife.103703</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.103703.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.4</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Permute-match tests: Detecting significant correlations between time series despite nonstationarity and limited replicates</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Yuan</surname>
<given-names>Alex E</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>alexericyuan@gmail.com</email>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Shou</surname>
<given-names>Wenying</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<email>wenying.shou@gmail.com</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00cvxb145</institution-id><institution>Molecular and Cellular Biology PhD program, University of Washington</institution></institution-wrap>, <city>Seattle</city>, <country country="US">United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Centre for Life’s Origins and Evolution, Department of Genetics, Evolution and Environment, University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Krishna</surname>
<given-names>Sandeep</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Centre for Biological Sciences­‐Tata Institute of Fundamental Research</institution>
</institution-wrap>
<city>Bangalore</city>
<country>India</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Walczak</surname>
<given-names>Aleksandra M</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>CNRS</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-02-26">
<day>26</day>
<month>02</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP103703</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-11-07">
<day>07</day>
<month>11</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-11-10">
<day>10</day>
<month>11</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.03.13.531689"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Yuan &amp; Shou</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Yuan &amp; Shou</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-103703-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Researchers in fields from ecology to neuroscience analyze correlations between pairs of time series, often working with nonstationary data, wherein statistical properties change over time. This commonly involves a statistical test to determine whether an observed correlation is stronger than expected under the null hypothesis of independence. Testing for dependence between nonstationary time series with only one experimental replicate is exceedingly challenging. However, with many replicates, a nonparametric trial-swapping permutation test can be employed, comparing within-replicate correlations to between-replicate correlations. Although largely assumption-free, this test is severely limited by the number of replicates because its minimum achievable <italic>p</italic>-value is 1<italic>/n</italic>! where <italic>n</italic> is the number of replicates. This curtails its applicability to many biomedical studies, where <italic>n</italic> is frequently as low as 3, which would render significance thresholds like 0.05 unattainable. To address this, we propose modified permutation tests that can report lower <italic>p</italic>-values of 2<italic>/n</italic><sup><italic>n</italic></sup> or 1<italic>/n</italic><sup><italic>n</italic></sup> when there is strong evidence of dependence. We prove that the tests guarantee a false positive rate at or below the significance level, as long as replicates come from independent and identical experiments. We demonstrate this approach by confirming the observation that groups of zebrafish swim faster when directionally aligned, using an existing dataset with 3 biological replicates.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The title has been revised to include the name of the new test. The introduction has been revised to better motivate the need for tests that handle small replicate counts.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Scientists frequently look for correlations between variables to identify potentially important relationships, or to support conceptual models. In disciplines with a focus on dynamics such as ecology and physiology, it is common to measure correlations between time series. Many important biological processes are nonstationary, meaning that their statistical properties (e.g. mean or variance) change systematically across time. Such processes range from the spread of an invasive species to a cell’s response to a new environmental stress.</p>
<p>Interpreting a correlation between a pair of nonstationary time series can be highly fraught because it is easy to obtain a seemingly impressive correlation between two time series that have no meaningful relationship [<xref ref-type="bibr" rid="c1">1</xref>]. For example, the sizes of any two exponentially-growing populations will be correlated over time due to a shared growth law, even if the populations lack any interaction or shared influences. To avoid overinterpreting spurious correlations, it helps to distinguish between the concepts of “correlation” and “dependence”. In time series research, the term “correlation” is often used procedurally [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>]. Similarly, here we define a correlation function (<italic>ρ</italic>) to be any function that takes two time series and produces a statistic, although it is usually interpreted as a measure of similarity or relatedness.</p>
<p>In contrast to correlation, “dependence” is a hypothesis about the relationship between variables, and it has clearer scientific implications. Two events <italic>A</italic> and <italic>B</italic> are called dependent if the probability that they both occur <italic>P</italic> (<italic>A, B</italic>) differs from the product of their individual probabilities <italic>P</italic> (<italic>A</italic>)<italic>P</italic> (<italic>B</italic>). Similarly, two temporal processes are dependent if the probability of observing any particular pair of trajectories differs from the product of the probabilities of individual trajectories. (The formal definition of dependence extends this idea to continuous variables, where discrete probabilities may be replaced by probability densities [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>].) The importance of dependence relationships can be attributed to Reichenbach’s common cause principle, which states that if two variables are dependent, then either they share a common causal influence, or one variable causally influences the other (possibly indirectly) [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c8">8</xref>]. Thus, it is useful to to first test whether an observed correlation indicates dependence before pursuing specific mechanistic explanations.</p>
<p>There are a handful of systematic approaches to testing for dependence between nonstationary time series. However, most are fairly limited in their scope. First, when possible, a nonstationary time series can be transformed to become stationary, meaning that its statistical properties do not change systematically across time. This enables access to a wide arsenal of tests applicable to stationary data. Transformations include subtracting a trend, taking the derivative (more precisely, “differencing” between neighboring points), or choosing a stationary-seeming window of time [<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c10">10</xref>]. However, it is easy to see potential pathologies in each of these: Taking the derivative of an exponential curve just produces another exponential curve; subtracting a fitted linear trend from the random walk <italic>X</italic>(<italic>t</italic>) = <italic>X</italic>(<italic>t</italic> − 1) + <italic>ϵ</italic>(<italic>t</italic>) (where <italic>ϵ</italic>(<italic>t</italic>) is random noise) does not make it stationary [<xref ref-type="bibr" rid="c9">9</xref>]; similarly, searching for a stationary window of the same random walk process is futile since the variance of <italic>X</italic>(<italic>t</italic>) increases with each step. In a second approach, one may compare the observed correlation with correlations obtained when one time series is replaced by a synthetic replicate, where synthetic replicates are generated in a way that reflects the original nonstationary process [<xref ref-type="bibr" rid="c11">11</xref>]. However, these require a correct model of how the statistical properties of the process evolve over time. Lastly, there are tests within the econometrics literature that can provide evidence for dependence between random-walk-like nonstationary processes by detecting a property called cointegration, but cointegration only occurs when some linear combination of the time series is stationary [<xref ref-type="bibr" rid="c12">12</xref>].</p>
<p>Alternatively, an approach based on permutations is possible when there are multiple identically distributed and independent (iid) replicates (or trials; we use “replicates” and “trials” interchangeably). In this case, one may evaluate the significance of a within-replicate correlation by comparing it to between-replicate correlations. That is, if <italic>X</italic><sub><italic>i</italic></sub> and <italic>Y</italic><sub><italic>i</italic></sub> are time series of variables <italic>X</italic> and <italic>Y</italic> from replicate <italic>i</italic>, the correlation of (<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) may be compared to the correlation of (<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>j≠ i</italic></sub>). If the two variables are dependent, within-replicate correlations should tend to be stronger than between-replicate correlations. This approach is sometimes called “inter-subject surrogates” [<xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c14">14</xref>].</p>
<p>The inter-subject surrogate approach can be used to test for dependence in each trial separately [<xref ref-type="bibr" rid="c15">15</xref>]. In this case, a simple nonparametric test of dependence between, for instance, <italic>X</italic><sub>1</sub> and <italic>Y</italic><sub>1</sub> can be performed by computing the correlation <italic>ρ</italic>(<italic>X</italic><sub>1</sub>, <italic>Y</italic><sub><italic>j</italic></sub>) for <italic>j</italic> = 1, …, <italic>n</italic> and writing down a <italic>p</italic>-value as the proportion of these correlations that are greater than or equal to <italic>ρ</italic>(<italic>X</italic><sub>1</sub>, <italic>Y</italic><sub>1</sub>) [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>]. For this approach, at least <italic>n</italic> = 20 trials are needed if one wishes to possibly obtain a <italic>p</italic>-value of 0.05 or below. This procedure checks for dependence in trial 1 specifically; assessing dependence in a different trial via this method would involve an analogous test.</p>
<p>To reduce the required number of trials below 20, a straightforward strategy is to perform a single permutation test (<xref rid="fig1" ref-type="fig">Fig 1A</xref>) using the data from all replicates [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>]. As an example with <italic>n</italic> = 4 trials, the test procedure begins by computing the mean within-trial correlation:
<disp-formula id="ueqn1">
<graphic xlink:href="531689v4_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Next, as a null model, recompute the mean correlation after permuting the <italic>Y</italic> time series while holding the <italic>X</italic> time series in the original order. This is the same as permuting <italic>X</italic>s and maintaining the order of the <italic>Y</italic> s. For instance, one such permutation might be:
<disp-formula id="ueqn2">
<graphic xlink:href="531689v4_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>A <italic>p</italic>-value can be calculated as the proportion of permutations (including the original ordering) that produce a mean correlation that is as strong as, or stronger than, <italic>ρ</italic><sub><italic>orig</italic></sub> (<xref rid="fig1" ref-type="fig">Fig 1A</xref>). One may then detect a correlation at the significance level <italic>α</italic> if <italic>p</italic> ≤ <italic>α</italic>. We emphasize that these permutations are obtained by swapping trials, not by swapping time points. This test has been used to detect correlations between time series in neuroscience and psychology settings [<xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c21">21</xref>]. It has also been used to detect correlations between variables measured in brain images, which can have similar nonstationarity challenges as time series [<xref ref-type="bibr" rid="c22">22</xref>]. A noteworthy advantage of this approach is that it is valid (meaning that the false positive rate is guaranteed to not exceed <italic>α</italic>) under very mild assumptions. Namely, the test is valid if the <italic>X</italic><sub><italic>i</italic></sub> trials are exchangeable with one another (i.e. all permutations of the sequence <italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub> have the same joint probability distribution), or if the <italic>Y</italic><sub><italic>i</italic></sub> trials are exchangeable (see Corollary 4 in Appendix 1).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><p>The permutation test, perfect match concept, and permute-match tests. (<bold>A</bold>) The permutation test. Circles indicate the average correlation obtained with (grey) or without (pink) trial swapping. Here, <italic>N</italic><sub>≥</sub> is the number of average correlations (including the original correlation) that are equal to or larger than the original correlation. <italic>p</italic><sub><italic>perm</italic></sub> is then <italic>N</italic><sub>≥</sub><italic>/n</italic>! because <italic>n</italic>! is the total number of average correlations, including the original. (<bold>B</bold>) Illustration of a <italic>Y</italic> -perfect match, represented as a table of correlations wherein each diagonal entry is the greatest in its own row. Each line with a “<italic>&gt;</italic>” or “<italic>&lt;</italic>” symbol denotes a required ordering relationship between the two numbers at either end of the line. Note that this example has a <italic>Y</italic> -perfect match, but not an <italic>X</italic>-perfect match. For an <italic>X</italic>-perfect match, each diagonal entry would need to be the greatest in its own column. (<bold>C</bold>) If an <italic>X</italic>-or <italic>Y</italic> -perfect match occurs, then the original correlation, <italic>ρ</italic><sub><italic>orig</italic></sub> is always greater than any shuffled correlation <italic>ρ</italic><sub><italic>shfl</italic></sub>. Top: If a <italic>Y</italic> -perfect match occurs, then each <italic>Y</italic><sub><italic>i</italic></sub> gives the greatest correlation when it s paired with the <italic>X</italic><sub><italic>i</italic></sub> from the same trial. A shuffled correlation <italic>ρ</italic><sub><italic>shfl</italic></sub> pairs <italic>Y</italic><sub><italic>i</italic></sub>s from some trials with <italic>X</italic><sub><italic>j</italic></sub>s from different trials, thereby reducing the correlation. Lines with symbols “<italic>&gt;</italic>“, “<italic>&lt;</italic>“, and “=” denote comparisons between terms. Bottom: If an <italic>X</italic>-perfect match occurs, a similar argument can be applied. (D) Since a perfect match ensures that the original correlation is greater than any shuffled correlation, a perfect match also ensures that <italic>p</italic><sub><italic>perm</italic></sub> takes on its lowest possible value of 1<italic>/n</italic>!. (E) The simultaneous permute-match<sub>(<italic>X</italic>;<italic>Y</italic>)</sub> test. (F) The sequential permute-match<sub>(<italic>X</italic>▸<italic>Y</italic>)</sub> test; note that the permute-match<sub>(<italic>Y</italic> ▸<italic>X</italic>)</sub> test is defined analogously.</p></caption>
<graphic xlink:href="531689v4_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Yet, even the permutation test remains considerably limited by the number of trials. The lowest <italic>p</italic>-value that can be obtained with <italic>n</italic> replicates is 1<italic>/n</italic>! since there are <italic>n</italic>! possible permutations. For example, with <italic>n</italic> = 3, the lowest possible <italic>p</italic>-value is 1<italic>/</italic>3! ≈ 0.17 and with <italic>n</italic> = 4, the lowest is 1<italic>/</italic>4! ≈ 0.04. These minima apply even if the average within-trial correlation is much greater than the average between-trial correlation. While replicate counts of 4 and 5 can produce <italic>p</italic>-values below the conventional 0.05 threshold, these <italic>p</italic>-values remain modest. This limitation is particularly problematic when multiple hypothesis testing is required, as the modest <italic>p</italic>-values may no longer be significant after applying corrections such as the Bonferroni method.</p>
<p>The challenge of limited replicates is a practical reality in many experimental settings due to cost and feasibility concerns [<xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref>]. Factors outside the control of investigators further restrict the number of useful replicates. For example, a recently published study of cerebral ischemia in pigs began with 6 animals, but lost 2 due to death and experimental mishap, so complete records exist for only 4 pigs [<xref ref-type="bibr" rid="c26">26</xref>]. Similarly, in an animal migration study, authors affixed GPS tags to 13 juvenile cuckoos, but only 5 of them produced GPS records suitable for the study due to heterogeneous behavior among cuckoos [<xref ref-type="bibr" rid="c27">27</xref>]. Finally, secondary analysis of public data from earlier studies can be a resource-efficient mode of research [<xref ref-type="bibr" rid="c28">28</xref>], and this approach is necessarily limited to the number of replicates within the existing dataset.</p>
<p>In this article, we show that by adding additional steps to the permutation test, we may achieve <italic>p</italic>-values as low as 1<italic>/n</italic><sup><italic>n</italic></sup>. For <italic>n</italic> = 3 or 4 respectively, the lowest possible <italic>p</italic>-value is then ≈ 0.04 or 0.004. This new result only requires that the replicates be iid. Thus, this modified permutation test allows the data analyst to detect dependence with stronger confidence when there is sufficient evidence to do so. We illustrate this approach using simulations as well as a real world example involving recordings of zebrafish swimming behavior with only 3 replicates.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>The concept of an <italic>X</italic>-perfect or <italic>Y</italic> -perfect match</title>
<p>Central to our approach is the concept of an <italic>X</italic>-perfect match or <italic>Y</italic> -perfect match. To motivate the ideas, suppose that a group of <italic>n</italic> graduate students <bold><italic>X</italic></bold> = (<italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) has been paired with a group of <italic>n</italic> advisors <bold><italic>Y</italic></bold> = (<italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub>) so that the <italic>i</italic>th student (<italic>X</italic><sub><italic>i</italic></sub>) is paired with the <italic>i</italic>th advisor (<italic>Y</italic><sub><italic>i</italic></sub>). Moreover, let <italic>ρ</italic>(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>j</italic></sub>) be a number that measures how well the <italic>i</italic>th student and the <italic>j</italic>th advisor get along. We say that the <italic>i</italic>th student is “happy” if they get along with their own advisor strictly better than they get along with any other advisor, meaning that <italic>ρ</italic>(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) <italic>&gt; ρ</italic>(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>j</italic></sub>) for all <italic>j</italic> ≠ <italic>i</italic>. Similarly, the <italic>i</italic>th advisor is “happy” if <italic>ρ</italic>(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) <italic>&gt; ρ</italic>(<italic>X</italic><sub><italic>j</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) for all <italic>j</italic> ≠ <italic>i</italic>. The arrangement of student-advisor pairs is <italic>X</italic>-perfect if all students are happy, and <italic>Y</italic> -perfect if all advisors are happy.</p>
<p>Analogously, if <bold><italic>X</italic></bold> = (<italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) and <bold><italic>Y</italic></bold> = (<italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub>) are collections of time series with <italic>n</italic> trials each, and if <italic>ρ</italic> is some correlation function, we say that an <italic>X</italic>-perfect match has occurred if (and only if) for all <italic>X</italic> trials,
<disp-formula id="ueqn3">
<graphic xlink:href="531689v4_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Similarly, a <italic>Y</italic> -perfect match has occurred if and only if:
<disp-formula id="ueqn4">
<graphic xlink:href="531689v4_ueqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Throughout the article, we use boldface <bold><italic>X</italic></bold> or <bold><italic>Y</italic></bold> to indicate a collection of trials, <italic>X</italic><sub><italic>i</italic></sub> or <italic>Y</italic><sub><italic>i</italic></sub> to indicate an individual trial, and <italic>X</italic> or <italic>Y</italic> to refer to the variable in general.</p>
<p>A perfect match (either <italic>X</italic>-perfect or <italic>Y</italic> -perfect) provides especially strong evidence to support the hypothesis that <bold><italic>X</italic></bold> and <bold><italic>Y</italic></bold> are dependent. With a perfect match, the original correlation <italic>ρ</italic><sub><italic>orig</italic></sub> is strictly greater than any of the shuffled correlations, as illustrated in <xref rid="fig1" ref-type="fig">Fig 1C</xref>. Thus, a perfect match guarantees <italic>p</italic><sub><italic>perm</italic></sub> = 1<italic>/n</italic>!, the lowest <italic>p</italic>-value achievable with the permutation test (<xref rid="fig1" ref-type="fig">Fig 1D</xref>). Furthermore, letting <italic>P</italic> denote probability, we can prove that
<disp-formula id="ueqn5">
<graphic xlink:href="531689v4_ueqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
under the null hypothesis <italic>H</italic><sub>0</sub> wherein (1) the <italic>Y</italic><sub><italic>i</italic></sub> trials are iid, (2) the <italic>X</italic><sub><italic>i</italic></sub> trials are iid, and (3) <bold><italic>X</italic></bold> and <bold><italic>Y</italic></bold> are independent (Lemma 6 in Appendix 2). By an analogous argument (Lemma 7 in Appendix 2), under <italic>H</italic><sub>0</sub> we have <italic>P</italic> (<italic>Y</italic> −perfect match) ≤ 1<italic>/n</italic><sup><italic>n</italic></sup> and thus
<disp-formula id="eqn1">
<graphic xlink:href="531689v4_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Permute-match tests: modified permutation tests of dependence</p>
<p>We now describe tests for dependence between nonstationary time series based on the ideas just laid out, which we will call permute-match tests. Suppose that an experiment produces time series <bold><italic>X</italic></bold> = (<italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) and <bold><italic>Y</italic></bold> = (<italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub>), where <italic>X</italic><sub><italic>i</italic></sub> and <italic>Y</italic><sub><italic>i</italic></sub> are time series obtained from the <italic>i</italic>th replicate, and we want to test whether <bold><italic>X</italic></bold> and <bold><italic>Y</italic></bold> are dependent. For example, we may have video recordings of <italic>n</italic> animals in separate but identically constructed enclosures; for the <italic>i</italic>th animal, we extract a time series of movement speed (<italic>X</italic><sub><italic>i</italic></sub>) and a time series of the distance from a light source (<italic>Y</italic><sub><italic>i</italic></sub>). Using these data, we may wish to investigate whether the animals under study tend to move at different speeds depending on their distance from the light source. We introduce two tests: simultaneous permute-match and sequential permute-match. As we will see, the former can be more reproducible while the latter can be more powerful.</p>
<p>In the simultaneous permute-match test (<xref rid="fig1" ref-type="fig">Fig 1E</xref>), we check for both an <italic>X</italic>−perfect and a <italic>Y</italic> − perfect match. If either the <italic>X</italic>-or <italic>Y</italic> -perfect match occurs, we write down a <italic>p</italic>-value to be <italic>p</italic> = 2<italic>/n</italic><sup><italic>n</italic></sup> per <xref ref-type="disp-formula" rid="eqn1">equation 1</xref>. If neither <italic>X</italic> nor <italic>Y</italic> achieves a perfect match, then we fall back to the permutation test: <italic>p</italic> = <italic>p</italic><sub><italic>perm</italic></sub> = <italic>N</italic><sub>≥</sub><italic>/n</italic>! where <italic>N</italic><sub>≥</sub> is the number of all <italic>n</italic>! possible permutations (including the original ordering) that produce an average correlation that is at least as large as the original ordering (<xref rid="fig1" ref-type="fig">Fig 1A</xref>).</p>
<p>In the sequential permute-match test, we begin by choosing a variable (either <italic>X</italic> or <italic>Y</italic>) for the first perfect match test. For example, suppose we choose <italic>X</italic> first (in which case we refer to the procedure as the “permute-match<sub>(<italic>X</italic>▸<italic>Y</italic>)</sub>” test). If an <italic>X</italic>-perfect match is observed, then <italic>p</italic> = 1<italic>/n</italic><sup><italic>n</italic></sup> (<xref rid="fig1" ref-type="fig">Fig 1F</xref>). If <italic>X</italic>-perfect match is not observed, we then check for a <italic>Y</italic> -perfect match, and write <italic>p</italic> = 2<italic>/n</italic><sup><italic>n</italic></sup> if a <italic>Y</italic> -perfect match is observed. If neither an <italic>X</italic>-perfect nor <italic>Y</italic> -perfect match occurs, then <italic>p</italic> = <italic>p</italic><sub><italic>perm</italic></sub>. A permute-match<sub>(<italic>Y</italic> ▸<italic>X</italic>)</sub> test is defined analogously.</p>
<p>Under <italic>H</italic><sub>0</sub> (i.e. the <italic>Y</italic><sub><italic>i</italic></sub> replicates are iid, the <italic>X</italic><sub><italic>i</italic></sub> replicates are iid, and <bold><italic>X</italic></bold> and <bold><italic>Y</italic></bold> are independent), all the above tests are valid, meaning that for any significance level <italic>α</italic>, we have <italic>P</italic> (<italic>p</italic> ≤ <italic>α</italic>) ≤ <italic>α</italic>. This fact is proven as Theorems 10-12 in Appendix 2.</p>
<p>The permute-match tests (<xref rid="fig1" ref-type="fig">Fig 1E-F</xref>) are “upgrades” to the permutation test (<xref rid="fig1" ref-type="fig">Fig 1A</xref>) because permute-match tests always report the same or a lower <italic>p</italic>-value (since 1<italic>/n</italic><sup><italic>n</italic></sup> ≤ 2<italic>/n</italic><sup><italic>n</italic></sup> <italic>&lt;</italic> 1<italic>/n</italic>! for all integers <italic>n</italic> ≥ 2; see Lemma 9 in Appendix 1). In exchange for lower <italic>p</italic>-values, the permute-match tests have a slightly more restrictive data requirement than the permutation test. The permutation test is valid either if the <italic>X</italic><sub><italic>i</italic></sub> trials are exchangeable, or if the <italic>Y</italic><sub><italic>i</italic></sub> trials are exchangeable (Corollary 4 in Appendix 1). The permute-match tests require that all <italic>X</italic><sub><italic>i</italic></sub> trials are iid and that <italic>Y</italic><sub><italic>i</italic></sub> trials are iid. If trials are iid, then they are necessarily exchangeable. However, exchangeable trials are not always iid. For example, the first five cards drawn from a shuffled deck are exchangeable because all possible orderings of cards are equally likely, but they are not iid because if the first card is an ace of hearts, the second card cannot be the ace of hearts. In practice, biological experimental designs typically use replicates that are both exchangeable and iid, so the more restrictive requirement of the permute-match test is often inconsequential.</p>
<p>The different tests - permutation test, simultaneous permute-match test, and sequential permute-match tests - are valid tests of dependence given iid replicates (Theorems 10-12 in in Appendix 1). In other words, they all guarantee false positive rates at or below the significance level. Two subtle aspects of the permutematch tests are worth mentioning here. First, no multiple testing correction is applied to account for the fact that both match tests and a permutation test are used. In other words, although the simultaneous permute-match<sub>(<italic>X</italic>;<italic>Y</italic>)</sub> test assigns <italic>p</italic> = 2<italic>/n</italic><sup><italic>n</italic></sup> instead of <italic>p</italic> = 1<italic>/n</italic><sup><italic>n</italic></sup> when an <italic>X</italic>-or <italic>Y</italic> -perfect match occurs as a Bonferroni-type correction, no such correction is needed when combining the match test and the permutation test (<xref rid="fig1" ref-type="fig">Fig 1E</xref>). This is because the permutation test and perfect match events are <italic>nested</italic>. That is, an <italic>X</italic>-or <italic>Y</italic> -perfect match is possible only if <italic>p</italic><sub><italic>perm</italic></sub> is already at its lowest possible value of 1<italic>/n</italic>! (<xref rid="fig1" ref-type="fig">Fig 1C-D</xref>). Thus, unlike combining un-nested tests where each can separately contribute false positives, we can safely combine the checks for perfect matches with the permutation test. The second subtlety refers specifically to the sequential permute-match tests. These tests use the lower <italic>p</italic>-value of 1<italic>/n</italic><sup><italic>n</italic></sup> if the first perfect match occurs, but use the more conservative “Bonferroni-corrected” <italic>p</italic>-value of 2<italic>/n</italic><sup><italic>n</italic></sup> if only the second match occurs (<xref rid="fig1" ref-type="fig">Fig 1F</xref>). This superficially resembles the practice of conducting additional tests merely because earlier tests did not result in a detection -a form of <italic>p</italic>-hacking that generally results in an invalid final <italic>p</italic>-value. However, our sequential permute-match procedure is actually valid because it combines binary events instead of continuous variables. See Appendix 3 for a detailed discussion of this point.</p>
</sec>
<sec id="s2b">
<title>Permute-match test variants may differ in statistical power</title>
<p>Although the different tests - permutation test, simultaneous permute-match test, and sequential permutematch tests - are all valid in the sense of correctly controlling false positive rates, how do they vary in power - the probability of detecting true dependence? The answer depends on the number of replicates <italic>n</italic> and the desired significance level <italic>α</italic>. There are four regimes to consider (<xref rid="fig2" ref-type="fig">Fig 2A</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><p>Statistical power of various permutation test variants as illustrated using a simple nonstationary system. (<bold>A</bold>) Summary of test power as a function of the significance level <italic>α</italic> and the number of replicates <italic>n</italic>. (<bold>B, C</bold>) System equations and example dynamics. The processes <italic>X</italic> and <italic>Y</italic> are given by a linear trend with additive noise on a time grid <italic>t</italic> = 1, 2, …, 100. The noise terms <italic>ϵ</italic><sub><italic>X,i</italic></sub>(<italic>t</italic>) and <italic>ϵ</italic><sub><italic>Y,i</italic></sub>(<italic>t</italic>) are drawn from a bivariate normal distribution with a mean of 0, variance of 1, and covariance of <italic>r</italic><sub><italic>X,Y</italic></sub>. The chart shows an example pair of time series where <italic>X</italic> and <italic>Y</italic> are dependent (<italic>r</italic><sub><italic>X,Y</italic></sub> = 0.3). (<bold>C</bold>) Statistical power of the permutation test and various permute-match tests as a function of the replicate number <italic>n</italic>, significance level <italic>α</italic>, and strength of dependence <italic>r</italic><sub><italic>X,Y</italic></sub>. Power was calculated from 5000 simulations at each value of <italic>r</italic><sub><italic>X,Y</italic></sub> between <italic>r</italic><sub><italic>X,Y</italic></sub> = 0 and 0.54 in steps of size 0.01. We chose the Pearson correlation coefficient as our correlation function <italic>ρ</italic>.</p></caption>
<graphic xlink:href="531689v4_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Regime 1: when <italic>α</italic> ≥ 1<italic>/n</italic>!, all tests have the same power. If the permutation test detects dependence, permute-match tests will too since they fall back to a permutation test in the “worst case” (<xref rid="fig2" ref-type="fig">Fig 2A</xref>, column 1). Conversely, if the permutation test did not detect dependence (i.e. <italic>p</italic><sub><italic>perm</italic></sub> <italic>&gt; α</italic>), then it follows that <italic>p</italic><sub><italic>perm</italic></sub> <italic>&gt;</italic> 1<italic>/n</italic>!, which implies that neither an <italic>X</italic>-perfect nor <italic>Y</italic> -perfect match occurred (<xref rid="fig1" ref-type="fig">Fig 1D</xref>), and so the permute-match tests cannot have detected dependence either.</p>
<p>Regime 2: when 1<italic>/n</italic>! <italic>&gt; α</italic> ≥ 2<italic>/n</italic><sup><italic>n</italic></sup>, all permute-match tests are tied for highest power (<xref rid="fig2" ref-type="fig">Fig 2A</xref>, column 2). In this regime, the permutation test has zero power, since its <italic>p</italic>-value is limited at 1<italic>/n</italic>!. Conversely, if either an <italic>X</italic>-perfect or a <italic>Y</italic> -perfect match occurs, then, the sequential permute-match tests as well as the simultaneous permute-match<sub>(<italic>X</italic>;<italic>Y</italic>)</sub> test will all detect dependence.</p>
<p>Regime 3: when 2<italic>/n</italic><sup><italic>n</italic></sup> <italic>&gt; α</italic> ≥ 1<italic>/n</italic><sup><italic>n</italic></sup>, the simultaneous permute-match<sub>(<italic>X</italic>;<italic>Y</italic>)</sub> test will have no power as the desired <italic>p</italic>-value is below the lowest possible <italic>p</italic>-value achievable by the test. Only the permute-match<sub>(<italic>X</italic>▸<italic>Y</italic>)</sub> or <sub>(<italic>Y</italic> ▸<italic>X</italic>)</sub> tests now have power (<xref rid="fig2" ref-type="fig">Fig 2A</xref>, column 3). Note that permute-match<sub>(<italic>X</italic>▸<italic>Y</italic>)</sub> and permute-match<sub>(<italic>Y</italic> ▸<italic>X</italic>)</sub> test may differ in power, as can be seen in the upper left panel of <xref rid="fig2" ref-type="fig">Fig 2D</xref>. We do not currently know how to pre-diagnose which of these two tests will be most powerful based on a given dataset, so the choice of which test to run in this case is arbitrary.</p>
<p>Regime 4: when <italic>α &lt;</italic> 1<italic>/n</italic><sup><italic>n</italic></sup>, no test has any power even when a perfect match occurs.</p>
<p><xref rid="fig2" ref-type="fig">Figure 2B-D</xref> illustrates these different scenarios using a simulated nonstationary system and some common significance cutoffs. We simulated time series of two variables (<italic>X</italic> and <italic>Y</italic>) from a small number of replicates (between 3 and 5). Here, the time series were produced from a pair of linear time trends with coupled additive noise (<italic>r</italic><sub><italic>X,Y</italic></sub> determines the strength of coupling; <xref rid="fig2" ref-type="fig">Fig 2B</xref>). We chose the Pearson correlation coefficient as our correlation function <italic>ρ</italic>. The various sub-panels of <xref rid="fig2" ref-type="fig">Fig 2D</xref> illustrate the different aforementioned regimes.</p>
<p>The above example was chosen for ease of presentation - in fact, the example is so simple that it may be correctly treated by just fitting and removing the linear trend. In Appendix 4, we show that the same ideas hold in an example with a more complex nonstationary data-generating process (a logistic map with time-varying parameters) and a nonlinear correlation function (cross-map skill).</p>
</sec>
<sec id="s2c">
<title>An example from animal behavior science</title>
<p>Living in groups is a common experience among animals. For example, at least half of fish species are thought to form groups at some stage of life [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c30">30</xref>]. The properties of these groups can impart a variety of important fitness effects [<xref ref-type="bibr" rid="c31">31</xref>]. In groups of fish, coordinated swimming may facilitate foraging (e.g. by enabling fish to “communicate” the location of food to others) and predator escape (e.g. by confusing predators) [<xref ref-type="bibr" rid="c32">32</xref>, <xref ref-type="bibr" rid="c30">30</xref>]. One study [<xref ref-type="bibr" rid="c30">30</xref>] used videos of small groups of zebrafish (8 fish per group) to observe that fish swam faster during video segments when they were in a high-polarization state (i.e. when they were directionally aligned) than during segments when they were in a low-polarization state. A correlation between polarization and speed might indicate statistical dependence between the two variables, or it might just be a consequence of temporal trends (e.g. polarization and swimming speed both happen to decrease with time).</p>
<p>Using a publicly available dataset [<xref ref-type="bibr" rid="c33">33</xref>] containing fish trajectories from 3 replicate 10-minute videos of small groups of juvenile <italic>Danio rerio</italic> zebrafish (10 fish per group), we performed a permute-match test of dependence between polarization and fish swimming speed. As we will see, although these quantities are potentially nonstationary, the permute-match test nevertheless detects a statistical dependence between them.</p>
<p>To quantify polarization, we use “circular variance” (<italic>v</italic><sub><italic>circ</italic></sub>; see Methods), a common measure of angular dispersion [<xref ref-type="bibr" rid="c34">34</xref>]. Since high polarization means low dispersion, we quantify polarization as 1 − <italic>v</italic><sub><italic>circ</italic></sub>, and call this quantity the <italic>circular concentration</italic>, since it indicates “how concentrated the [circular] data is toward the center” ([<xref ref-type="bibr" rid="c35">35</xref>], page 15). Circular concentration is bounded between 0 (low alignment) and 1 (perfect alignment). To quantify speed, we took the “average individual speed”, which is a term we use to denote an average across individuals, not across time. More precisely, the average individual speed of a 10-fish group at time <italic>t</italic> is (<italic>s</italic><sub>1,<italic>t</italic></sub> + <italic>s</italic><sub>2,<italic>t</italic></sub> + · · · + <italic>s</italic><sub>10,<italic>t</italic></sub>)<italic>/</italic>10 where <italic>s</italic><sub><italic>i,t</italic></sub> is the speed of fish <italic>i</italic> at time <italic>t</italic>. Note that average individual speed is distinct from the speed of the group center, which has also been studied in <italic>Danio</italic> fish [<xref ref-type="bibr" rid="c31">31</xref>].</p>
<p>Neither average individual speed nor circular concentration is obviously stationary (<xref rid="fig3" ref-type="fig">Fig 3A</xref>). By visual inspection, the average individual speed seems to decrease across time, and all time series are deemed nonstationary by a Kwiatkowski–Phillips–Schmidt–Shin test (<italic>p &lt;</italic> 0.01), and so we may be on shaky ground to use methods that require stationarity. Additionally, since only 3 trials are available, the permutation test and the simultaneous permute-match test cannot detect dependence at the 0.05 level, so we perform a sequential permute-match test.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><p>A sequential permute-match test detects dependence between average individual speed and circular concentration in small groups of zebrafish. (<bold>A</bold>) Time series of average individual speed and circular concentration for the three replicate videos. Black curves show original time series, and red curves show a 30-second moving average. Average individual speed appears to decrease with time in all trials. All 12 time series (2 variables × 3 trials × 2 smoothing conditions) were deemed nonstationary by a Kwiatkowski– Phillips–Schmidt–Shin (KPSS; [<xref ref-type="bibr" rid="c37">37</xref>]) test (<italic>p &lt;</italic> 0.01). Note that the KPSS test seeks to reject a stationary null hypothesis in contrast to other common tests, whose null hypotheses are nonstationary. (<bold>B</bold>) Pearson correlation between circular concentration and average individual speed, both within trials and between trials, using the full 10 minutes of data. Table entries are shaded by correlation. We observe a speed-perfect match (and a circular concentration-perfect match), and thus detect dependence with <italic>p</italic> = 1<italic>/</italic>3<sup>3</sup> ≈ 0.04. (<bold>C</bold>) A parametric test also detects dependence. As a parametric alternative, for each trial we averaged values of speed and circular concentration over the full 10 minutes (e.g. the scatter plot shown, where each point is one trial). The sample Pearson correlation of the time-averaged variables is 0.99996, and a one-tailed test of significance gives <italic>p</italic> ≈ 0.003. (<bold>D</bold>) Permute-match tests detected a significant correlation between speed and circular concentration more consistently than the parametric test. We truncated time series to different lengths starting from the first frame, and compared the parametric test with the two possible permute-match tests. Length was varied between 20 seconds and 10 minutes in 20-second increments, with each increment representing 640 frames since the frame rate is 32 frames per second. We used the Pearson correlation (not its magnitude) in the permute-match tests since the alternative hypothesis is that the correlation is positive, not merely nonzero.</p></caption>
<graphic xlink:href="531689v4_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We arbitrarily started with average individual speed and identified a “speed”-perfect match, indicating a significant correlation between average individual speed and circular concentration (<xref rid="fig3" ref-type="fig">Fig 3B</xref>; <italic>p</italic> = 1<italic>/</italic>3<sup>3</sup> ≈ 0.04). Significance does not depend on the choice of which match is tested, since both a “speed”-perfect and a “circular concentration”-perfect match is obtained. Note that although trials are independent of each other, all between-trial correlations from the full dataset are positive (<xref rid="fig3" ref-type="fig">Fig 3B</xref>), illustrating the danger in applying naive data analysis methods to data that are autocorrelated or even nonstationary.</p>
<p>To try a parametric alternative, for each trial we averaged values of average individual speed and circular concentration over the full 10 minutes (<xref rid="fig3" ref-type="fig">Fig 3C</xref>; where each point is one trial). The sample Pearson correlation of the time-averaged variables is 0.99996, and a one-tailed test of significance (using the function stats.pearsonr from the Python package Scipy [<xref ref-type="bibr" rid="c36">36</xref>]) also detects dependence (<italic>p</italic> ≈ 0.003), consistent with the permute-match tests. This test relies on a null distribution derived under the assumption that the three points in <xref rid="fig3" ref-type="fig">Fig 3C</xref> are drawn from a bivariate Gaussian distribution with zero covariance. We view this test as comparable to the permute-match tests because although it requires a parametric assumption, it can be valid even when the time series are nonstationary.</p>
<p>Since data are limited in many scientific applications, we asked whether the results of the sequential permute-match tests and the parametric Pearson correlation test were consistent across different time series lengths. We truncated time series to various lengths (from 20 seconds to 10 minutes), and checked whether each test reported a significant (<italic>p</italic> ≤ 0.05) correlation (<xref rid="fig3" ref-type="fig">Fig 3D</xref>). Both sequential permute-match tests reported a significant correlation at all lengths tested, whereas the parametric test was inconsistent, finding a significant correlation for about one third of lengths.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Outside the context of time series, permutation tests have been celebrated because they require only minimal assumptions [<xref ref-type="bibr" rid="c38">38</xref>]. To satisfy the requirements of permutation tests, it is sufficient (see Corollary 4 in Appendix 1) to collect data from exchangeable replicates. Data in each trial can be autocorrelated (e.g. temporally or spatially) and nonstationary. No distributional assumptions are required, and the correlation function can even be asymmetric so that <italic>ρ</italic>(<italic>X, Y</italic>) ≠ <italic>ρ</italic>(<italic>Y, X</italic>) as occurs when correlations are based on techniques that use one time series to predict values of another (e.g. Appendix 4). Such radical freedom from assumptions stands in stark contrast to the situation in the analysis of single-replicate time series, where the practitioner may be forced to make assumptions that can be difficult to verify. For example, most statistical tests of correlation between two time series require stationary data at a minimum [<xref ref-type="bibr" rid="c39">39</xref>]. Yet, it is difficult to verify that a single time series is stationary because stationarity is a property of an entire ensemble of time series [<xref ref-type="bibr" rid="c39">39</xref>], so that checking for stationarity in a single time series is philosophically analogous to checking for the Gaussianity of a single data point.</p>
<p>However, applying a trial-swapping permutation test to check for significant correlations requires that a sufficient number of trials be available to permute amongst one another. When only small numbers of trials are available, the permutation test is severely limited by mathematics. The minimum <italic>p</italic>-value that can possibly be achieved by a permutation test is 1<italic>/n</italic>!, which will provide only modest evidence against a null hypothesis when <italic>n</italic> = 4 and is essentially useless when <italic>n</italic> = 3, regardless of how strong the true dependence may be. This limitation is particularly severe for researchers testing several related hypotheses, as this ideally requires a test that can produce <italic>p</italic>-values sufficiently low to maintain significance even after a multiple-testing correction.</p>
<p>Here we have described modified permutation tests–the sequential and simultaneous permute-match tests–that have access to lower <italic>p</italic>-values. In the sequential permute-match test, if the first variable does not display a perfect match, this test falls back to the simultaneous permute-match test. Thus, the sequential permute-match test is more powerful than the simultaneous test. However, the sequential test requires the arbitrary choice of checking for an <italic>X</italic>-or <italic>Y</italic> -perfect match first, making it potentially less reproducible between studies than the simultaneous test, which does not involve an arbitrary choice. If neither an <italic>X</italic>-nor <italic>Y</italic> -perfect match is obtained, both tests default to a permutation test. This step is valid because the tests are nested in the sense that a perfect match can only occur when the permutation <italic>p</italic>-value takes on its lowest possible value (Lemma 8 in Appendix 1).</p>
<p>It seems likely that the tests could be further modified to report an even lower <italic>p</italic>-value when both an <italic>X</italic>-and <italic>Y</italic> -perfect match occur, as in <xref rid="fig3" ref-type="fig">Fig 3B</xref>. However, we have not yet determined a sharp upper bound on the probability of this two-way match event. This problem is left for future efforts.</p>
<p>Although we have here used language and examples involving time series, the permute-match test can in principle be applied to other scenarios where iid replicates are available, but data within each replicate are dependent. One example is spatial data in brain imaging, where the permutation test has been performed using multiple scanned brains [<xref ref-type="bibr" rid="c22">22</xref>]. Beyond spatial processes, dependent data also appear in nucleotide sequences and natural language text. Overall, advances in methods that take advantage of multiple replicates may facilitate statistical testing without requiring assumptions that are difficult to verify.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Data preprocessing</title>
<p>We obtained fish trajectory data [<xref ref-type="bibr" rid="c33">33</xref>] from the web address at <ext-link ext-link-type="uri" xlink:href="https://drive.google.com/drive/folders/1UmzlX-yJhzQ5KX5rGry8wZgXvcz6HefD">https://drive.google.com/drive/folders/1UmzlX-yJhzQ5KX5rGry8wZgXvcz6HefD</ext-link>. For the first trial we used the file at the path “10/1/trajecto-ries_wo_gaps.npy” (where “10” indicates the number of fish and “1” indicates the first trial). For the second and third trials, the file path was the same except it began with “10/2/” and “10/3/” respectively. These files contain sequences of fish positions indexed by video frame, as well as constants such as frame rate and approximate fish body length.</p>
<p>We estimated the velocity of each fish as
<disp-formula id="ueqn6">
<graphic xlink:href="531689v4_ueqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Where <inline-formula><inline-graphic xlink:href="531689v4_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a 2-dimensional column vector specifying the position of the <italic>i</italic>th fish in units of body length at video frame <inline-formula><inline-graphic xlink:href="531689v4_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a 2-dimensional column vector specifying the fish velocity in units of body length per second at video frame <italic>t</italic>, and <italic>R</italic> is the frame rate (32 frames per second). A group’s average individual speed at each time was then given by
<disp-formula id="ueqn7">
<graphic xlink:href="531689v4_ueqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>N</italic> is the number of fish. The circular concentration <italic>C</italic><sub><italic>t</italic></sub> of a group at each time was given by the formula
<disp-formula id="ueqn8">
<graphic xlink:href="531689v4_ueqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where
<disp-formula id="ueqn9">
<graphic xlink:href="531689v4_ueqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Here, atan2 is the 2-argument arctangent function (i.e. “arctan2” in the Python package Numpy, ver. 1.21.6). Also, <italic>v</italic><sub><italic>x,i,t</italic></sub> and <italic>v</italic><sub><italic>y,i,t</italic></sub> denote the <italic>x</italic> and <italic>y</italic> components of the velocity vector <inline-formula><inline-graphic xlink:href="531689v4_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The calculation was carried out using the function “stats.circstats.circvar” in the Python package Astropy (ver. 3.2.2) [<xref ref-type="bibr" rid="c40">40</xref>].</p>
</sec>
<sec id="s5">
<title>Statistical analysis</title>
<p>The permute-match test is described in <xref rid="fig1" ref-type="fig">Fig 1</xref> and its validity is proved in Appendix 2. For the KPSS test, we used the function “statsmodels.tsa.stattools.kpss” in the Python package Statsmodels (ver. 0.10.1) [<xref ref-type="bibr" rid="c41">41</xref>]. We set the “regression” argument to “c” (which tests the null hypothesis of stationarity rather than trend-stationarity), and we set the “nlags” argument to “auto” (which means that the number of lags used for testing stationarity is automatically chosen by a data-dependent method).</p>
</sec>
</sec>
</body>
<back>
<sec id="s7" sec-type="data-availability">
<title>Data availability</title>
<p>All code used, along with execution instructions, is within S1 Code. The time series data analyzed in this paper can be obtained via the following link: <ext-link ext-link-type="uri" xlink:href="https://drive.google.com/drive/folders/1UmzlX-yJhzQ5KX5rGry8wZgXvcz6HefD">https://drive.google.com/drive/folders/1UmzlX-yJhzQ5KX5rGry8wZgXvcz6HefD</ext-link></p>
</sec>
<sec id="suppd1e1943" sec-type="supplementary-material">
<title>Additional files</title>
<supplementary-material id="d1e1934">
<label>S1 Code</label>
<media xlink:href="supplements/531689_file02.zip"/>
</supplementary-material>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Granger</surname> <given-names>CW</given-names></string-name>, <string-name><surname>Newbold</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Spurious regressions in econometrics</article-title>. <source>Journal of econometrics</source>. <year>1974</year>;<volume>2</volume>(<issue>2</issue>):<fpage>111</fpage>–<lpage>20</lpage>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yule</surname> <given-names>GU</given-names></string-name></person-group>. <article-title>Why do we sometimes get nonsense-correlations between Time-Series?–a study in sampling and the nature of time-series</article-title>. <source>Journal of the royal statistical society</source>. <year>1926</year>;<volume>89</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>63</lpage>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weiss</surname> <given-names>S</given-names></string-name>, <string-name><surname>Van Treuren</surname> <given-names>W</given-names></string-name>, <string-name><surname>Lozupone</surname> <given-names>C</given-names></string-name>, <string-name><surname>Faust</surname> <given-names>K</given-names></string-name>, <string-name><surname>Friedman</surname> <given-names>J</given-names></string-name>, <string-name><surname>Deng</surname> <given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Correlation detection strate-gies in microbial data sets vary widely in sensitivity and precision</article-title>. <source>The ISME journal</source>. <year>2016</year>;<volume>10</volume>(<issue>7</issue>):<fpage>1669</fpage>–<lpage>81</lpage>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Coenen</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Weitz</surname> <given-names>JS</given-names></string-name></person-group>. <article-title>Limitations of correlation-based inference in complex virus-microbe communities</article-title>. <source>MSystems</source>. <year>2018</year>;<volume>3</volume>(<issue>4</issue>):<fpage>e00084</fpage>–<lpage>18</lpage>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Rosenthal</surname> <given-names>JS</given-names></string-name></person-group>. <source>First Look At Rigorous Probability Theory, A</source>. <publisher-name>World Scientific Publishing Company</publisher-name>; <year>2006</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Ross</surname> <given-names>SM</given-names></string-name></person-group>. <source>A first course in probability</source>. <publisher-name>Pearson</publisher-name>; <year>2014</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Peters</surname> <given-names>J</given-names></string-name>, <string-name><surname>Janzing</surname> <given-names>D</given-names></string-name>, <string-name><surname>Schölkopf</surname> <given-names>B.</given-names></string-name></person-group> <source>Elements of causal inference: foundations and learning algorithms</source>. <publisher-name>MIT press</publisher-name>; <year>2017</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hitchcock</surname> <given-names>C</given-names></string-name>, <string-name><surname>Rédei</surname> <given-names>M.</given-names></string-name></person-group> <chapter-title>Reichenbach’s Common Cause Principle</chapter-title>. In: <person-group person-group-type="editor"><string-name><surname>Zalta</surname> <given-names>EN</given-names></string-name>, editor</person-group>. <source>The Stanford Encyclopedia of Philosophy. spring 2020</source> ed. <publisher-name>Metaphysics Research Lab, Stanford University</publisher-name>; <year>2020</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chan</surname> <given-names>KH</given-names></string-name>, <string-name><surname>Hayya</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Ord</surname> <given-names>JK</given-names></string-name></person-group>. <article-title>A note on trend removal methods: The case of polynomial regression versus variate differencing</article-title>. <source>Econometrica: Journal of the Econometric Society</source>. <year>1977</year>:<fpage>737</fpage>–<lpage>44</lpage>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Isliker</surname> <given-names>H</given-names></string-name>, <string-name><surname>Kurths</surname> <given-names>J.</given-names></string-name></person-group> <article-title>A test for stationarity: finding parts in time series apt for correlation dimension estimates</article-title>. <source>International Journal of Bifurcation and Chaos</source>. <year>1993</year>;<volume>3</volume>(<issue>06</issue>):<fpage>1573</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Guarin</surname> <given-names>D</given-names></string-name>, <string-name><surname>Orozco</surname> <given-names>A</given-names></string-name>, <string-name><surname>Delgado</surname> <given-names>E.</given-names></string-name></person-group> <article-title>A new surrogate data method for nonstationary time series</article-title>. <source>arXiv</source>; <year>2010</year>. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1008.1804">https://arxiv.org/abs/1008.1804</ext-link>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Greene</surname> <given-names>WH</given-names></string-name></person-group>. <source>Econometric Analysis</source>. <publisher-name>Pearson</publisher-name>; <year>2012</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Iatsenko</surname> <given-names>D</given-names></string-name>, <string-name><surname>Bernjak</surname> <given-names>A</given-names></string-name>, <string-name><surname>Stankovski</surname> <given-names>T</given-names></string-name>, <string-name><surname>Shiogai</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Owen-Lynch</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Clarkson</surname> <given-names>P</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Evolution of car-diorespiratory interactions with age</article-title>. <source>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</source>. <year>2013</year>;<volume>371</volume>(<issue>1997</issue>):<fpage>20110622</fpage>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lancaster</surname> <given-names>G</given-names></string-name>, <string-name><surname>Iatsenko</surname> <given-names>D</given-names></string-name>, <string-name><surname>Pidde</surname> <given-names>A</given-names></string-name>, <string-name><surname>Ticcinelli</surname> <given-names>V</given-names></string-name>, <string-name><surname>Stefanovska</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Surrogate data for hypothesis testing of physical systems</article-title>. <source>Physics Reports</source>. <year>2018</year>;<volume>748</volume>:<fpage>1</fpage>–<lpage>60</lpage>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moulder</surname> <given-names>RG</given-names></string-name>, <string-name><surname>Boker</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Ramseyer</surname> <given-names>F</given-names></string-name>, <string-name><surname>Tschacher</surname> <given-names>W.</given-names></string-name></person-group> <article-title>Determining synchrony between behavioral time series: An application of surrogate data generation for establishing falsifiable null-hypotheses</article-title>. <source>Psycho-logical methods</source>. <year>2018</year>;<volume>23</volume>(<issue>4</issue>):<fpage>757</fpage>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schreiber</surname> <given-names>T</given-names></string-name>, <string-name><surname>Schmitz</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Surrogate time series</article-title>. <source>Physica D: Nonlinear Phenomena</source>. <year>2000</year>;<volume>142</volume>(<issue>3-4</issue>):<fpage>346</fpage>–<lpage>82</lpage>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname> <given-names>AE</given-names></string-name>, <string-name><surname>Shou</surname> <given-names>W.</given-names></string-name></person-group> <article-title>Data-driven causal analysis of observational biological time series</article-title>. <source>eLife</source>. <year>2022</year>;<volume>11</volume>:<elocation-id>e72518</elocation-id>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Martin</surname> <given-names>DC</given-names></string-name>, <string-name><surname>Buffington</surname> <given-names>V</given-names></string-name>, <string-name><surname>Becker</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Randomization test of paired data: Application to evoked responses</article-title>. <source>Psychophysiology</source>. <year>1981</year>;<volume>18</volume>(<issue>5</issue>):<fpage>524</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ernst</surname> <given-names>MD</given-names></string-name></person-group>. <article-title>Permutation methods: a basis for exact inference</article-title>. <source>Statistical Science</source>. <year>2004</year>:<fpage>676</fpage>–<lpage>85</lpage>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buffington</surname> <given-names>V</given-names></string-name>, <string-name><surname>Martin</surname> <given-names>DC</given-names></string-name>, <string-name><surname>Becker</surname> <given-names>J.</given-names></string-name></person-group> <article-title>VER similarity between alcoholic probands and their first-degree relatives</article-title>. <source>Psychophysiology</source>. <year>1981</year>;<volume>18</volume>(<issue>5</issue>):<fpage>529</fpage>–<lpage>33</lpage>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Albert</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bouret</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Fromont</surname> <given-names>M</given-names></string-name>, <string-name><surname>Reynaud-Bouret</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Surrogate data methods based on a shuffling of the trials for synchrony detection: the centering issue</article-title>. <source>Neural Computation</source>. <year>2016</year>;<volume>28</volume>(<issue>11</issue>):<fpage>2352</fpage>–<lpage>92</lpage>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weinstein</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Vandekar</surname> <given-names>SN</given-names></string-name>, <string-name><surname>Adebimpe</surname> <given-names>A</given-names></string-name>, <string-name><surname>Tapera</surname> <given-names>TM</given-names></string-name>, <string-name><surname>Robert-Fitzgerald</surname> <given-names>T</given-names></string-name>, <string-name><surname>Gur</surname> <given-names>RC</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>A simple permutation-based test of intermodal correspondence</article-title>. <source>Human brain mapping</source>. <year>2021</year>;<volume>42</volume>(<issue>16</issue>):<fpage>5175</fpage>–<lpage>87</lpage>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bacchetti</surname> <given-names>P</given-names></string-name>, <string-name><surname>Deeks</surname> <given-names>SG</given-names></string-name>, <string-name><surname>McCune</surname> <given-names>JM</given-names></string-name></person-group>. <article-title>Breaking free of sample size dogma to perform innovative translational research</article-title>. <source>Science translational medicine</source>. <year>2011</year>;<volume>3</volume>(<issue>87</issue>):<fpage>87ps24</fpage>–<lpage>4</lpage>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vesterinen</surname> <given-names>HV</given-names></string-name>, <string-name><surname>Egan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Deister</surname> <given-names>A</given-names></string-name>, <string-name><surname>Schlattmann</surname> <given-names>P</given-names></string-name>, <string-name><surname>Macleod</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Dirnagl</surname> <given-names>U.</given-names></string-name></person-group> <article-title>Systematic survey of the design, statistical analysis, and reporting of studies published in the 2008 volume of the Journal of Cerebral Blood Flow and Metabolism</article-title>. <source>Journal of Cerebral Blood Flow &amp; Metabolism</source>. <year>2011</year>;<volume>31</volume>(<issue>4</issue>):<fpage>1064</fpage>–<lpage>72</lpage>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ristic-Djurovic</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Cirkovic</surname> <given-names>S</given-names></string-name>, <string-name><surname>Mladenovic</surname> <given-names>P</given-names></string-name>, <string-name><surname>Romcevic</surname> <given-names>N</given-names></string-name>, <string-name><surname>Trbovich</surname> <given-names>AM</given-names></string-name></person-group>. <article-title>Analysis of methods com-monly used in biomedicine for treatment versus control comparison of very small samples</article-title>. <source>Com-puter Methods and Programs in Biomedicine</source>. <year>2018</year>;<volume>157</volume>:<fpage>153</fpage>–<lpage>62</lpage>. <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S0169260717307344">https://www.sciencedirect.com/science/article/pii/S0169260717307344</ext-link>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frasch</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Walter</surname> <given-names>B</given-names></string-name>, <string-name><surname>Herry</surname> <given-names>CL</given-names></string-name>, <string-name><surname>Bauer</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Multimodal pathophysiological dataset of gradual cerebral ischemia in a cohort of juvenile pigs</article-title>. <source>Scientific Data</source>. <year>2021</year>;<volume>8</volume>(<issue>1</issue>):<fpage>4</fpage>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vega</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Willemoes</surname> <given-names>M</given-names></string-name>, <string-name><surname>Thomson</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Tolvanen</surname> <given-names>J</given-names></string-name>, <string-name><surname>Rutila</surname> <given-names>J</given-names></string-name>, <string-name><surname>Samaš</surname> <given-names>P</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>First-time migration in juvenile common cuckoos documented by satellite tracking</article-title>. <source>PLoS One</source>. <year>2016</year>;<volume>11</volume>(<issue>12</issue>):<fpage>e0168940</fpage>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Greene</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Garmire</surname> <given-names>LX</given-names></string-name>, <string-name><surname>Gilbert</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Ritchie</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Hunter</surname> <given-names>LE</given-names></string-name></person-group>. <article-title>Celebrating parasites</article-title>. <source>Nature genetics</source>. <year>2017</year>;<volume>49</volume>(<issue>4</issue>):<fpage>483</fpage>–<lpage>4</lpage>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shaw</surname> <given-names>E.</given-names></string-name></person-group> <article-title>Schooling fishes</article-title>. <source>American Scientist</source>. <year>1978</year>;<volume>66</volume>(<issue>2</issue>):<fpage>166</fpage>–<lpage>75</lpage>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miller</surname> <given-names>N</given-names></string-name>, <string-name><surname>Gerlai</surname> <given-names>R.</given-names></string-name></person-group> <article-title>From schooling to shoaling: patterns of collective motion in zebrafish (Danio rerio)</article-title>. <source>PloS one</source>. <year>2012</year>;<volume>7</volume>(<issue>11</issue>):<fpage>e48865</fpage>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Viscido</surname> <given-names>SV</given-names></string-name>, <string-name><surname>Parrish</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Grünbaum</surname> <given-names>D.</given-names></string-name></person-group> <article-title>Individual behavior and emergent properties of fish schools: a comparison of observation and theory</article-title>. <source>Marine Ecology Progress Series</source>. <year>2004</year>;<volume>273</volume>:<fpage>239</fpage>–<lpage>49</lpage>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lopez</surname> <given-names>U</given-names></string-name>, <string-name><surname>Gautrais</surname> <given-names>J</given-names></string-name>, <string-name><surname>Couzin</surname> <given-names>ID</given-names></string-name>, <string-name><surname>Theraulaz</surname> <given-names>G.</given-names></string-name></person-group> <article-title>From behavioural analyses to models of collective motion in fish schools</article-title>. <source>Interface focus</source>. <year>2012</year>;<volume>2</volume>(<issue>6</issue>):<fpage>693</fpage>–<lpage>707</lpage>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Romero-Ferrero</surname> <given-names>F</given-names></string-name>, <string-name><surname>Bergomi</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Hinz</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Heras</surname> <given-names>FJ</given-names></string-name>, <string-name><surname>De Polavieja</surname> <given-names>GG</given-names></string-name></person-group>. <article-title>Idtracker</article-title>. <source>ai: tracking all individuals in small or large collectives of unmarked animals. Nature methods</source>. <year>2019</year>;<volume>16</volume>(<issue>2</issue>):<fpage>179</fpage>–<lpage>82</lpage>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berens</surname> <given-names>P.</given-names></string-name></person-group> <article-title>CircStat: a MATLAB toolbox for circular statistics</article-title>. <source>Journal of statistical software</source>. <year>2009</year>;<volume>31</volume>:<fpage>1</fpage>–<lpage>21</lpage>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Jammalamadaka</surname> <given-names>SR</given-names></string-name>, <string-name><surname>Sengupta</surname> <given-names>A.</given-names></string-name></person-group> <source>Topics in circular statistics</source>. vol. <volume>5</volume>. <publisher-name>world scientific</publisher-name>; <year>2001</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Virtanen</surname> <given-names>P</given-names></string-name>, <string-name><surname>Gommers</surname> <given-names>R</given-names></string-name>, <string-name><surname>Oliphant</surname> <given-names>TE</given-names></string-name>, <string-name><surname>Haberland</surname> <given-names>M</given-names></string-name>, <string-name><surname>Reddy</surname> <given-names>T</given-names></string-name>, <string-name><surname>Cournapeau</surname> <given-names>D</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python</article-title>. <source>Nature Methods</source>. <year>2020</year>;<volume>17</volume>:<fpage>261</fpage>–<lpage>72</lpage>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kwiatkowski</surname> <given-names>D</given-names></string-name>, <string-name><surname>Phillips</surname> <given-names>PC</given-names></string-name>, <string-name><surname>Schmidt</surname> <given-names>P</given-names></string-name>, <string-name><surname>Shin</surname> <given-names>Y.</given-names></string-name></person-group> <article-title>Testing the null hypothesis of stationarity against the alternative of a unit root: How sure are we that economic time series have a unit root?</article-title> <source>Journal of econometrics</source>. <year>1992</year>;<volume>54</volume>(<issue>1-3</issue>):<fpage>159</fpage>–<lpage>78</lpage>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kulkarni</surname> <given-names>RU</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>CL</given-names></string-name>, <string-name><surname>Bertozzi</surname> <given-names>CR</given-names></string-name></person-group>. <article-title>Analyzing nested experimental designs-A user-friendly resampling method to determine experimental significance</article-title>. <source>PLoS computational biology</source>. <year>2022</year>;<volume>18</volume>(<issue>5</issue>):<fpage>e1010061</fpage>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Yuan</surname> <given-names>AE</given-names></string-name>, <string-name><surname>Shou</surname> <given-names>W.</given-names></string-name></person-group> <article-title>An exactly valid and distribution-free statistical significance test for correlations between time series</article-title>. <source>bioRxiv</source>. <year>2022</year>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Robitaille</surname> <given-names>TP</given-names></string-name>, <string-name><surname>Tollerud</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Greenfield</surname> <given-names>P</given-names></string-name>, <string-name><surname>Droettboom</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bray</surname> <given-names>E</given-names></string-name>, <string-name><surname>Aldcroft</surname> <given-names>T</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Astropy: A community Python package for astronomy</article-title>. <source>Astronomy &amp; Astrophysics</source>. <year>2013</year>;<volume>558</volume>:<fpage>A33</fpage>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Seabold</surname> <given-names>S</given-names></string-name>, <string-name><surname>Perktold</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Statsmodels: Econometric and statistical modeling with python</article-title>. In: <conf-name>Proceedings of the 9th Python in Science Conference</conf-name>. vol. <volume>57</volume>. <conf-loc>Austin, TX</conf-loc>; <year>2010</year>. p. <fpage>10</fpage>–<lpage>25080</lpage>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lehmann</surname> <given-names>EL</given-names></string-name>, <string-name><surname>Romano</surname> <given-names>JP</given-names></string-name></person-group>. <source>Testing statistical hypotheses</source>. vol. <volume>3</volume>. <publisher-name>Springer</publisher-name>; <year>2005</year>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hemerik</surname> <given-names>J</given-names></string-name>, <string-name><surname>Goeman</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Exact testing with random permutations</article-title>. <source>Test</source>. <year>2018</year>;<volume>27</volume>(<issue>4</issue>):<fpage>811</fpage>–<lpage>25</lpage>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Steele</surname> <given-names>JM</given-names></string-name></person-group>. <source>The Cauchy-Schwarz Master Class: An Introduction to the Art of Mathematical In-equalities</source>. <publisher-name>Cambridge University Press</publisher-name>; <year>2004</year>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sugihara</surname> <given-names>G</given-names></string-name>, <string-name><surname>May</surname> <given-names>R</given-names></string-name>, <string-name><surname>Ye</surname> <given-names>H</given-names></string-name>, <string-name><given-names>Hsieh</given-names> <surname>Ch</surname></string-name>, <string-name><surname>Deyle</surname> <given-names>E</given-names></string-name>, <string-name><surname>Fogarty</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Detecting causality in complex ecosystems</article-title>. <source>Science</source>. <year>2012</year>;<volume>338</volume>(<issue>6106</issue>):<fpage>496</fpage>–<lpage>500</lpage>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ye</surname> <given-names>H</given-names></string-name>, <string-name><surname>Deyle</surname> <given-names>ER</given-names></string-name>, <string-name><surname>Gilarranz</surname> <given-names>LJ</given-names></string-name>, <string-name><surname>Sugihara</surname> <given-names>G.</given-names></string-name></person-group> <article-title>Distinguishing time-delayed causal interactions using convergent cross mapping</article-title>. <source>Scientific reports</source>. <year>2015</year>;<volume>5</volume>:<fpage>14750</fpage>.</mixed-citation></ref>
</ref-list>
<app-group>
<app id="app1">
<label>Appendix</label>
<p>In Appendix 1, we review the basic permutation test of independence and a proof of its validity. This is because, although these results are known to the statistical community, they are often presented in an abstract form whose connection to independence testing may not be obvious to the nonspecialist, or parts of the argument are simply left as an exercise to the reader. In Appendix 2, we provide the theoretical justification for the permute-match test, which is the main topic of this work. Appendix 3 expands on a brief claim made in the main text about <italic>p</italic>-values of sequential statistical tests, and Appendix 4 contains supplementary data.</p>
<sec id="s6">
<label>1</label>
<title>Justification of the permutation test of independence</title>
<p>In this section we provide a proof that the permutation test of independence is valid. No major novelty is claimed in this subsection. For instance, the results of Lemma 3 can be mostly reconstructed by piecing together various theorems, examples, and homework problems from section 15.2.1 of Lehmann and Romano [<xref ref-type="bibr" rid="c42">42</xref>]. Nevertheless, we present the complete argument here as a courtesy to the reader. Related proofs or proof sketches of various kinds of permutation tests can be found in [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c43">43</xref>].</p>
<p>The following lemma describes a general rank-based method to test whether the distribution of a random variable changes upon applying a set of transformations. This lemma and proof are based on Theorem 15.2.1 in Lehmann and Romano [<xref ref-type="bibr" rid="c42">42</xref>]. We begin with this result because it comes first in the chain of logical steps that justify the permutation test, but it is somewhat abstract, and so the reader who prefers to start out with concrete concepts may wish to skip to Def 2 and return to this lemma when its necessity becomes apparent later. As a notational clarification, note that for the transformation <italic>h</italic><sub><italic>i</italic></sub>, to denote “<italic>h</italic><sub><italic>i</italic></sub> applied to <italic>Z</italic>” we write <italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic> rather than the more traditional <italic>h</italic><sub><italic>i</italic></sub>(<italic>Z</italic>).</p>
<statement id="lem1">
<label>Lemma 1</label>
<p>Let <italic>Z</italic> ∈ Ƶ be a random variable. Let <italic>H</italic> = {<italic>h</italic><sub>1</sub>, …, <italic>h</italic><sub><italic>m</italic></sub>} be a set of functions from Ƶ to Ƶ such that:
<list list-type="order">
<list-item><p>the probability distributions of <italic>Z</italic> and <italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic> are the same for all functions <italic>h</italic><sub><italic>i</italic></sub> in <italic>H</italic>, and</p></list-item>
<list-item><p>the unordered sets {<italic>h</italic><sub>1</sub><italic>Z</italic>, …, <italic>h</italic><sub><italic>m</italic></sub><italic>Z</italic>} and {<italic>h</italic><sub>1</sub><italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic>, …, <italic>h</italic><sub><italic>m</italic></sub><italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic>} are equal for all <italic>h</italic><sub><italic>i</italic></sub> in <italic>H</italic>.</p></list-item>
</list></p>
<p>Let the statistic <italic>T</italic> be a function from <italic>Ƶ</italic> to ℝ. Given some <italic>z</italic> ∈ <italic>Ƶ</italic>, let the ordered values of {<italic>T</italic> (<italic>h</italic><sub>1</sub><italic>z</italic>), …, <italic>T</italic> (<italic>h</italic><sub><italic>m</italic></sub><italic>z</italic>)} be
<disp-formula id="ueqn10">
<graphic xlink:href="531689v4_ueqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Choose some significance level <italic>α</italic> ∈ [0, 1] and let the r ank <italic>k</italic> be
<disp-formula id="eqnA_1">
<graphic xlink:href="531689v4_eqnA_1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where ⌊<italic>mα</italic>⌋ is the largest integer less than or equal to <italic>mα</italic>. Then,
<disp-formula id="ueqn11">
<graphic xlink:href="531689v4_ueqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>P</italic> (·) denotes the probability of an event.</p>
<p><bold>Remark:</bold> Before proceeding to the proof, let us walk through the lemma, using a concrete example to help with the most abstract aspects. Suppose that random variable <italic>Z</italic> is the result of a fair coin flip. That is, <italic>Z</italic> = 0 with 50% chance and <italic>Z</italic> = 1 with 50% chance. Then Ƶ (the set of valid <italic>Z</italic> values) is the the set {0, 1}, and <italic>z</italic> can take on the value of 0 or 1. Next the lemma introduces <italic>H</italic>, which is a set of functions that need to satisfy certain requirements with respect to <italic>Z</italic>. Let’s choose <italic>H</italic> = {<italic>h</italic><sub>1</sub>, <italic>h</italic><sub>2</sub>} where <italic>h</italic><sub>1</sub> “turns the coin over” and <italic>h</italic><sub>2</sub> leaves the coin as it is. That is, <italic>h</italic><sub>1</sub><italic>z</italic> = 1 − <italic>z</italic> and <italic>h</italic><sub>2</sub><italic>z</italic> = <italic>z</italic>. To check that <italic>H</italic> satisfies requirement (1), note that flipping the f air c oin over does n ot change the p robability d istribution of i ts outcome, and neither does leaving it alone. To see that <italic>H</italic> satisfies requirement (2), we need to check that
<disp-formula id="ueqn12">
<graphic xlink:href="531689v4_ueqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>If <italic>Z</italic> = 0, then the above expression becomes
<disp-formula id="ueqn13">
<graphic xlink:href="531689v4_ueqn13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and if <italic>Z</italic> = 1, then it is
<disp-formula id="ueqn14">
<graphic xlink:href="531689v4_ueqn14.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and since these are unordered sets, they are all equal, so we have verified that <italic>H</italic> satisfies requirement (2). Next, we need a function <italic>T</italic>. For example, choose <italic>T</italic> (<italic>z</italic>) = <italic>z</italic> + 10. Thus, for <italic>z</italic> = 0 we have {<italic>T</italic> (<italic>h</italic><sub>1</sub><italic>z</italic>), <italic>T</italic> (<italic>h</italic><sub>2</sub><italic>z</italic>)} = {11, 10}. The lemma then introduces a ranking notation where <italic>T</italic> <sup>(<italic>i</italic>)</sup>(<italic>Z</italic>) is the <italic>i</italic>th smallest term in the sequence. This notation is useful as we will be dealing with the set {<italic>T</italic> (<italic>h</italic><sub>1</sub><italic>Z</italic>), …, <italic>T</italic> (<italic>h</italic><sub><italic>m</italic></sub><italic>Z</italic>)} for potentially large values of <italic>m</italic>. Returning to our example, if <italic>z</italic> = 0, then <italic>T</italic> <sup>(1)</sup>(0) = 10 and <italic>T</italic> <sup>(2)</sup>(0) = 11. Similarly for <italic>z</italic> = 1, <italic>T</italic> <sup>(1)</sup>(1) = 10 and <italic>T</italic> <sup>(2)</sup>(1) = 11. Also, in the statement of the lemma, <italic>T</italic> <sup>(<italic>i</italic>)</sup> is defined as a function of <italic>z</italic>, not <italic>Z</italic>. This is to emphasize that the ordering depends on the particular outcome of the random variable and is not fixed. Finally, the lemma makes a claim about the probability that <italic>T</italic> (<italic>Z</italic>) exceeds <italic>T</italic> <sup>(<italic>k</italic>)</sup>(<italic>Z</italic>), which is the <italic>k</italic>th lowest statistic in the set. In the example, if <italic>α</italic> = 0.05, then <italic>k</italic> = 2 − ⌊0.1⌋ = 2. <italic>T</italic> <sup>(2)</sup>(<italic>Z</italic>) is always going to be the second smallest, i.e. the largest, element of <italic>T</italic> (<italic>h</italic><sub>1</sub><italic>z</italic>), <italic>T</italic> (<italic>h</italic><sub>2</sub><italic>z</italic>), which is 11. Of course, the probability of <italic>T</italic> (<italic>Z</italic>) being <italic>even greater</italic> than the largest number is 0, and since 0 is less than <italic>α</italic> = 0.05 we have verified the lemma in this case. As another example, suppose <italic>α</italic> = 0.5. Then <italic>k</italic> = 2 − ⌊1⌋ = 1. <italic>T</italic> <sup>(<italic>k</italic>)</sup>(<italic>Z</italic>) is then <italic>T</italic> <sup>(1)</sup>(<italic>Z</italic>), the smallest element of {<italic>T</italic> (<italic>h</italic><sub>1</sub><italic>z</italic>), <italic>T</italic> (<italic>h</italic><sub>2</sub><italic>z</italic>)}. The probability of <italic>T</italic> (<italic>Z</italic>) being greater than the smallest number is 0.5 ≤ <italic>α</italic> = 0.5, which verifies the lemma for <italic>α</italic> = 0.5.</p>
</statement>
<p><bold>Proof of Lemma 1:</bold> Let <italic>I</italic>(<italic>A</italic>) be the indicator function for the event <italic>A</italic> (meaning that <italic>I</italic>(<italic>A</italic>) = 1 if <italic>A</italic> occurs and <italic>I</italic>(<italic>A</italic>) = 0 otherwise).</p>
<p>First suppose that <italic>T</italic> <sup>(<italic>k</italic>)</sup>(<italic>Z</italic>) is not tied with any other <italic>T</italic> <sup>(<italic>i</italic>)</sup>(<italic>Z</italic>). Then Eq. A-1 implies that there are ⌊<italic>mα</italic>⌋ values of <italic>T</italic> <sup>(<italic>i</italic>)</sup>(<italic>Z</italic>) that are greater than <italic>T</italic> <sup>(<italic>k</italic>)</sup>(<italic>Z</italic>). That is,
<disp-formula id="ueqn15">
<graphic xlink:href="531689v4_ueqn15.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>To arrive at the second equality, we used the fact that <italic>T</italic> <sup>(<italic>k</italic>)</sup>(<italic>Z</italic>) = <italic>T</italic> <sup>(<italic>k</italic>)</sup>(<italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic>), which follows from the second requirement of the lemma (i.e. {<italic>h</italic><sub>1</sub><italic>Z</italic>, …, <italic>h</italic><sub><italic>m</italic></sub><italic>Z}</italic> = {<italic>h</italic><sub>1</sub><italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic>, …, <italic>h</italic><sub><italic>m</italic></sub><italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic>).</p>
<p>Alternatively, if there is possibly a tie for <italic>T</italic> <sup>(<italic>k</italic>)</sup>(<italic>Z</italic>) (meaning that there may be some <italic>j</italic> ≠ <italic>k</italic> such that <italic>T</italic> <sup>(<italic>j</italic>)</sup>(<italic>Z</italic>) = <italic>T</italic> <sup>(<italic>k</italic>)</sup>(<italic>Z</italic>)), then we have a similar formula, but with an inequality instead of an equality:
<disp-formula id="ueqn16">
<graphic xlink:href="531689v4_ueqn16.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>This version with the inequality is of course general since it is true under both cases. Using this formula,
<disp-formula id="ueqn17">
<graphic xlink:href="531689v4_ueqn17.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Since <italic>Z</italic> and <italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic> have the same distribution, we may remove the <italic>h</italic><sub><italic>i</italic></sub> in the above formula, and we have
<disp-formula id="ueqn18">
<graphic xlink:href="531689v4_ueqn18.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Dividing through by <italic>m</italic> gives
<disp-formula id="ueqn19">
<graphic xlink:href="531689v4_ueqn19.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
as required.</p>
<p>Next we give a definition of the permutation test. The definition here is somewhat more general than in the main text. As with <italic>h</italic><sub><italic>i</italic></sub>, we will denote “<italic>g</italic><sub><italic>i</italic></sub> applied to <italic>Z</italic>” by writing <italic>g</italic><sub><italic>i</italic></sub><italic>Z</italic>.</p>
<p>Definition 2 <italic>The permutation test of independence</italic></p>
<p>Let <bold><italic>X</italic></bold> = (<italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) and <bold><italic>Y</italic></bold> = (<italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub>) be sequences of random variables. Let <italic>G</italic> = {<italic>g</italic><sub>1</sub>, …, <italic>g</italic><sub><italic>n</italic>!</sub>} be the complete set of functions that permute a sequence of length <italic>n</italic>. For example, if <bold><italic>Y</italic></bold> is (2, 7, 4), then <italic>g</italic><sub><italic>i</italic></sub><bold><italic>Y</italic></bold> might be (2, 4, 7). Define the statistic <italic>T</italic> (<bold><italic>X, Y</italic></bold>) to be a function that returns a real number, typically interpreted as the overall correlation strength. Repeatedly compute the statistic after permuting the elements of <bold><italic>Y</italic></bold>. That is, compute
<disp-formula id="ueqn20">
<graphic xlink:href="531689v4_ueqn20.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Let <italic>N</italic><sub>≥</sub> be the number of permuted statistic values that are at least as large as the original statistic value. That is,
<disp-formula id="ueqn21">
<graphic xlink:href="531689v4_ueqn21.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>I</italic>(<italic>A</italic>) is the indicator function for the event <italic>A</italic> (meaning that <italic>I</italic>(<italic>A</italic>) = 1 if <italic>A</italic> occurs and <italic>I</italic>(<italic>A</italic>) = 0 otherwise). Then the <italic>p</italic>-value of the test is given by
<disp-formula id="ueqn22">
<graphic xlink:href="531689v4_ueqn22.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>We now prove the validity of the permutation test.</p>
<statement id="lem3">
<label>Lemma 3</label>
<p><italic>The permutation test of independence is valid when</italic> <bold><italic>Y</italic></bold> <italic>is exchangeable</italic>.</p>
<p>Let <bold><italic>X</italic></bold> = (<italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) and <bold><italic>Y</italic></bold> = (<italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub>) be sequences of random variables such that <bold><italic>Y</italic></bold> is exchangeable and where <bold><italic>X</italic></bold> is independent of <bold><italic>Y</italic></bold>. Perform the permutation test of independence (Def. 2) to obtain <italic>p</italic><sub><italic>perm</italic></sub>. Then, <italic>P</italic> (<italic>p</italic><sub><italic>perm</italic></sub> ≤ <italic>α</italic>) ≤ <italic>α</italic> for any <italic>α</italic> ∈ [0, 1].</p>
<p><bold>Proof:</bold> Here we use the symbols <italic>g</italic><sub><italic>i</italic></sub> and <italic>T</italic> with their meanings from Def. 2.</p>
<p>We first set up the problem in a way that allows us to apply Lemma 1. To construct the random variable <italic>Z</italic> and transformation set <italic>H</italic> for Lemma 1, we choose <italic>Z</italic> = (<bold><italic>X, Y</italic></bold>) and <italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic> = (<bold><italic>X</italic></bold>, <italic>g</italic><sub><italic>i</italic></sub><bold><italic>Y</italic></bold>). Lemma 1 has two requirements. First, <italic>Z</italic> and <italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic> must have the same distribution. This requirement is satisfied: Since <bold><italic>Y</italic></bold> is exchangeable and <bold><italic>X</italic></bold> is independent of <bold><italic>Y</italic></bold>, it follows that (<bold><italic>X, Y</italic></bold>) has the same distribution as (<bold><italic>X</italic></bold>, <italic>g</italic><sub><italic>i</italic></sub><bold><italic>Y</italic></bold>). The second requirement is that {<italic>h</italic><sub>1</sub><italic>Z</italic>, …, <italic>h</italic><sub><italic>m</italic></sub><italic>Z}</italic> = {<italic>h</italic><sub>1</sub><italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic>, …, <italic>h</italic><sub><italic>m</italic></sub><italic>h</italic><sub><italic>i</italic></sub><italic>Z</italic>}. This requirement is also satisfied: The set of permutations of <bold><italic>Y</italic></bold> is the same as the set of permutations of <italic>g</italic><sub><italic>i</italic></sub><bold><italic>Y</italic></bold>. Since both requirements are satisfied, we may apply Lemma 1.</p>
</statement>
<p>We now prove the result directly. Below, <italic>A</italic> ↔ <italic>B</italic> means “<italic>A</italic> if and only if <italic>B</italic>”.
<disp-formula id="ueqn23">
<graphic xlink:href="531689v4_ueqn23.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>As in Eq. A-1, let us define <italic>k</italic> = <italic>m</italic> − ⌊<italic>mα</italic>⌋, where <italic>n</italic>! = <italic>m</italic>. Then, the final line above says “the number of permuted <bold><italic>Y</italic></bold> s that produce a smaller <italic>T</italic> than the original <bold><italic>Y</italic></bold> is greater than or equal to <italic>k</italic>.” Said another way, “when we rank the <italic>T</italic> s from least to greatest, the <italic>T</italic> from the original <bold><italic>Y</italic></bold> will have a higher rank than <italic>k</italic>”. This in turn is equivalent to <italic>T</italic> (<bold><italic>X, Y</italic></bold>) <italic>&gt; T</italic> <sup>(<italic>k</italic>)</sup>(<bold><italic>X, Y</italic></bold>). Thus, we may directly apply Lemma 1, thereby obtaining
<disp-formula id="ueqn24">
<graphic xlink:href="531689v4_ueqn24.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
as required.</p>
<p>Lemma 3 is “asymmetric” in that it requires <bold><italic>Y</italic></bold> to be exchangeable and says nothing about <bold><italic>X</italic></bold>. It is possible to write down a variant of this lemma where either an exchangeable <bold><italic>Y</italic></bold> or an exchangeable <bold><italic>X</italic></bold> is sufficient, but this requires an extra condition on <italic>T</italic>. Specifically, it is required that applying the same permutation to both <bold><italic>X</italic></bold> and <bold><italic>Y</italic></bold> must leave the value of <italic>T</italic> (<bold><italic>X, Y</italic></bold>) unchanged. That is, <italic>T</italic> (<bold><italic>X, Y</italic></bold>) = <italic>T</italic> (<italic>g</italic><sub><italic>i</italic></sub><bold><italic>X</italic></bold>, <italic>g</italic><sub><italic>i</italic></sub><bold><italic>Y</italic></bold>) for any permutation function <italic>g</italic><sub><italic>i</italic></sub>. Importantly, the form of <italic>T</italic> that is used for the permute-match test (i.e. <inline-formula><inline-graphic xlink:href="531689v4_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula> satisfies this requirement because in this case, <italic>T</italic> (<italic>g</italic><sub><italic>i</italic></sub><bold><italic>X</italic></bold>, <italic>g</italic><sub><italic>i</italic></sub><bold><italic>Y</italic></bold>) simply rearranges the order of the terms in the summation, which clearly has no effect on the value of <italic>T</italic>. We establish this formally in the corollary below.</p>
<statement id="Cor4">
<label>Corollary 4</label>
<p><italic>If T is “nice”, then the permutation test is valid when either</italic> <bold><italic>X</italic></bold> <italic>or</italic> <bold><italic>Y</italic></bold> <italic>is exchangeable</italic>.</p>
<p>Let <bold><italic>X</italic></bold> = (<italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) and <bold><italic>Y</italic></bold> = (<italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub>) be sequences of random variables such that at least one of (<bold><italic>X, Y</italic></bold>) is exchangeable and where <bold><italic>X</italic></bold> is independent of <bold><italic>Y</italic></bold>. Perform the permutation test of independence (Def. 2) using a correlation function with the “nice” property that
<disp-formula id="eqnA_2">
<graphic xlink:href="531689v4_eqnA_2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
for any permutation function <italic>g</italic><sub><italic>i</italic></sub>. Then, <italic>P</italic> (<italic>p</italic><sub><italic>perm</italic></sub> ≤ <italic>α</italic>) ≤ <italic>α</italic> for any <italic>α</italic> ∈ [0, 1].</p>
<p><bold>Proof:</bold> Lemma 3 already covers the case where <bold><italic>Y</italic></bold> is exchangeable. We now consider the case where <bold><italic>X</italic></bold> is exchangeable, but not <bold><italic>Y</italic></bold>.</p>
</statement>
<p>We proceed by showing that the permutation test where <bold><italic>Y</italic></bold> is permuted is equivalent to the permutation test where <bold><italic>X</italic></bold> is permuted. Notice that to show this equivalence it is sufficient to establish that
<disp-formula id="ueqn25">
<graphic xlink:href="531689v4_ueqn25.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the left and right sides both denote unordered sets. It will be useful to refer to the inverse permutation <inline-formula><inline-graphic xlink:href="531689v4_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which is the permutation that “undoes” <italic>g</italic><sub><italic>i</italic></sub>. More precisely, <inline-formula><inline-graphic xlink:href="531689v4_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is defined by the relation <inline-formula><inline-graphic xlink:href="531689v4_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Using Eq. A-2, we have:
<disp-formula id="eqnA_3">
<graphic xlink:href="531689v4_eqnA_3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Note that the inverse permutation <inline-formula><inline-graphic xlink:href="531689v4_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is guaranteed to exist because any permutation <italic>g</italic><sub><italic>i</italic></sub> can be “undone” by some other permutation <inline-formula><inline-graphic xlink:href="531689v4_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. In the edge case where <italic>g</italic><sub><italic>i</italic></sub> is the trivial identity permutation, <inline-formula><inline-graphic xlink:href="531689v4_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is also the identity permutation. Additionally, the set of permutation functions is the same as the set of inverse permutation functions, meaning that
<disp-formula id="eqnA_4">
<graphic xlink:href="531689v4_eqnA_4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
because each permutation is an inverse permutation (because <italic>g</italic><sub><italic>i</italic></sub> inverts <italic>g</italic><sup>−1</sup>), and each inverse permutation is a permutation. It follows that
<disp-formula id="ueqn26">
<graphic xlink:href="531689v4_ueqn26.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the first equality follows from Eq. A-3 and the second equality follows from Eq. A-4. This shows that the permutation test where <bold><italic>Y</italic></bold> is permuted is equivalent to the permutation test where <bold><italic>X</italic></bold> is permuted.</p>
<p>From Def. 2 and Lemma 3 it is clear that a permutation test where <bold><italic>X</italic></bold> is permuted instead of <bold><italic>Y</italic></bold> would be valid (i.e. <italic>P</italic> (<italic>p</italic><sub><italic>perm</italic></sub> ≤<italic>α</italic>) ≤<italic>α</italic>) if <bold><italic>X</italic></bold> is exchangeable. Since we have just now shown that the present procedure is equivalent to a permutation test where <bold><italic>X</italic></bold> is permuted instead of <bold><italic>Y</italic></bold>, it follows that this procedure is valid when <bold><italic>X</italic></bold> is exchangeable, which completes the proof.</p>
</sec>
<sec id="s6a">
<label>2</label>
<title>Validity of the permute-match test</title>
<p>We now justify the validity of the permute-match test, which is the primary contribution of the present work. Recall from the main text that the null hypothesis of this test is that <italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub> are iid, <italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub> are iid and <bold><italic>Y</italic></bold> is independent of <bold><italic>X</italic></bold>.</p>
<statement id="Def5">
<label>Definition 5</label>
<p><italic>The perfect match e vents (M</italic><sub><italic>X</italic></sub> <italic>and M</italic><sub><italic>Y</italic></sub> <italic>)</italic></p>
<p>Let <bold><italic>X</italic></bold> = (<italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) and <bold><italic>Y</italic></bold> = (<italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub>) be sequences of random variables. Let <italic>ρ</italic> (the “correlation function”) be a function that maps a pair (<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>j</italic></sub>) to a real number. We say that the event <italic>M</italic><sub><italic>Y</italic></sub> (also called a “<italic>Y</italic> -perfect match”) occurs if and only if:
<disp-formula id="ueqn27">
<graphic xlink:href="531689v4_ueqn27.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
for all pairs (<italic>i, j</italic>) such that <italic>i ≠ j</italic>.</p>
<p>Similarly, the event <italic>M</italic><sub><italic>X</italic></sub> (also called an “<italic>X</italic>-perfect match”) occurs if and only if
<disp-formula id="ueqn28">
<graphic xlink:href="531689v4_ueqn28.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
for all pairs (<italic>i, j</italic>) such that <italic>i≠ j</italic>.</p>
</statement>
<statement id="lem6">
<label>Lemma 6</label>
<p>Let <bold><italic>X</italic></bold> = (<italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) be a sequence of random variables and let <bold><italic>Y</italic></bold> = (<italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub>) be a sequence of iid random variables. Let <bold><italic>X</italic></bold> and <bold><italic>Y</italic></bold> be independent. Then, the probability of a <italic>Y</italic> -perfect match is at most 1<italic>/n</italic><sup><italic>n</italic></sup>.</p>
<p><bold>Proof:</bold> Let us define the random variables (<italic>C</italic><sub>1</sub>, …, <italic>C</italic><sub><italic>n</italic></sub>) as follows:
<disp-formula id="ueqn29">
<graphic xlink:href="531689v4_ueqn29.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>That is <italic>C</italic><sub><italic>i</italic></sub> ∈<italic>{</italic>1, …, <italic>n}</italic> is defined to be the choice of <italic>j</italic> that m aximizes <italic>ρ</italic>(<italic>X</italic><sub><italic>j</italic></sub>, <italic>Y</italic> <sub><italic>i</italic></sub>). In the case of a multiway tie, <italic>C</italic><sub><italic>i</italic></sub> is the lowest from among the maximizing index values. (For example, if <italic>j</italic> = 3 and <italic>j</italic> = 7 both produced the greatest value of <italic>ρ</italic>(<italic>X</italic><sub><italic>j</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>), then <italic>C</italic><sub><italic>i</italic></sub> would be 3 since 3 <italic>&lt;</italic> 7.) These <italic>C</italic><sub><italic>i</italic></sub> variables are useful because if a <italic>Y</italic> -perfect match occurs, then it must be the case that
<disp-formula id="ueqn30">
<graphic xlink:href="531689v4_ueqn30.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Notice that <italic>C</italic><sub>1</sub>, …, <italic>C</italic><sub><italic>n</italic></sub> are iid given <bold><italic>X</italic></bold> = <bold><italic>x</italic></bold> for any particular <bold><italic>x</italic></bold> that <bold><italic>X</italic></bold> may take. This is because <italic>C</italic><sub><italic>i</italic></sub> is a function of only <italic>Y</italic><sub><italic>i</italic></sub> and <bold><italic>X</italic></bold>, so once we condition on <italic>X</italic> = <bold><italic>x</italic></bold>, each <italic>C</italic><sub><italic>i</italic></sub> is then a function of only <italic>Y</italic><sub><italic>i</italic></sub>. Moreover, the <italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub> are of course iid given <bold><italic>X</italic></bold> = <bold><italic>x</italic></bold> because <bold><italic>Y</italic></bold> and <bold><italic>X</italic></bold> are independent.</p>
</statement>
<p>Since the <italic>C</italic><sub><italic>i</italic></sub> terms are identically distributed given <bold><italic>X</italic> = <italic>x</italic></bold>, we have
<disp-formula id="ueqn31">
<graphic xlink:href="531689v4_ueqn31.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
for all <italic>i</italic>. Therefore we have
<disp-formula id="ueqn32">
<graphic xlink:href="531689v4_ueqn32.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>By dividing the above equation through by <italic>n</italic>, we may write
<disp-formula id="eqnA_5">
<graphic xlink:href="531689v4_eqnA_5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the inequality comes from the AM-GM inequality (e.g. [<xref ref-type="bibr" rid="c44">44</xref>] pg. 20).</p>
<p>Since the <italic>C</italic><sub><italic>i</italic></sub> terms are independent given <bold><italic>X</italic></bold> = <bold><italic>x</italic></bold>, we have
<disp-formula id="eqnA_6">
<graphic xlink:href="531689v4_eqnA_6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Substituting Eq. A-6 into the right side of inequality A-5 and raising both sides to the <italic>n</italic>th power gives us
<disp-formula id="ueqn33">
<graphic xlink:href="531689v4_ueqn33.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Since <bold><italic>X</italic></bold> must take on some value <bold><italic>x</italic></bold>, it is clear that <italic>P</italic> (<italic>C</italic><sub>1</sub> = 1, …, <italic>C</italic><sub><italic>n</italic></sub> = <italic>n</italic>) ≤ 1<italic>/n</italic><sup><italic>n</italic></sup>. More formally, applying the law of total probability we find
<disp-formula id="eqnA_7">
<graphic xlink:href="531689v4_eqnA_7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Since a <italic>Y</italic> -perfect match can only occur when (<italic>C</italic><sub>1</sub> = 1, …, <italic>C</italic><sub><italic>n</italic></sub> = <italic>n</italic>), we may then write
<disp-formula id="eqnA_8">
<graphic xlink:href="531689v4_eqnA_8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Combining inequalities A-7 and A-8 completes the proof.</p>
<statement id="lem7">
<label>Lemma 7</label>
<p>Let <bold><italic>X</italic></bold> = (<italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) be a sequence of iid random variables and let <bold><italic>Y</italic></bold> = (<italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub>) be a sequence of random variables. Let <bold><italic>X</italic></bold> and <bold><italic>Y</italic></bold> be independent. Then, the probability of an <italic>X</italic>-perfect match is at most 1<italic>/n</italic><sup><italic>n</italic></sup>.</p>
<p><bold>Proof:</bold> The argument is analogous to that of Lemma 6. The main differences are that in this case we define <inline-formula><inline-graphic xlink:href="531689v4_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula> instead of <inline-formula><inline-graphic xlink:href="531689v4_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and here we condition on <bold><italic>Y</italic></bold> = <bold><italic>y</italic></bold> instead of <bold><italic>X</italic></bold> = <bold><italic>x</italic></bold>.</p>
</statement>
<statement id="lem8">
<label>Lemma 8</label>
<p><italic>A perfect match implies p</italic><sub><italic>perm</italic></sub> = 1<italic>/n</italic>!</p>
<p>Let <bold><italic>X</italic></bold> = (<italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) and <bold><italic>Y</italic></bold> = (<italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub>) be sequences of random variables. Let <italic>ρ</italic> be a function that maps a pair (<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>j</italic></sub>) to a real number. Define the average correlation
<disp-formula id="eqnA_9">
<graphic xlink:href="531689v4_eqnA_9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Perform the permutation test of independence (Def. 2) using <italic>T</italic> as the statistic, and obtain the <italic>p</italic>-value <italic>p</italic><sub><italic>perm</italic></sub>. Also check for an <italic>X</italic>-perfect and <italic>Y</italic> -perfect match test (Def. 5) using <italic>ρ</italic> as the correlation function. Then, the occurrence of either an <italic>X</italic>-perfect match or a <italic>Y</italic> -perfect match implies that <italic>p</italic><sub><italic>perm</italic></sub> = 1<italic>/n</italic>!.</p>
<p><bold>Proof:</bold> This claim is shown by a visual argument in <xref rid="fig1" ref-type="fig">Fig 1C</xref>. Here we walk through the same logic in prose. Suppose a <italic>Y</italic> -perfect match occurs, meaning that
<disp-formula id="ueqn34">
<graphic xlink:href="531689v4_ueqn34.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>In other words, for each <italic>Y</italic><sub><italic>i</italic></sub>, its correlation term <italic>ρ</italic>(·, <italic>Y</italic><sub><italic>i</italic></sub>) is strictly maximized when <italic>Y</italic><sub><italic>i</italic></sub> is paired with <italic>X</italic><sub><italic>i</italic></sub>. Applying a permutation to <bold><italic>Y</italic></bold> (other than the trivial identity permutation) means that for at least one choice of <italic>i</italic>, the <italic>ρ</italic>(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) term in Eq. A-9 becomes replaced with <italic>ρ</italic>(<italic>X</italic><sub><italic>j</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) for some <italic>j</italic> ≠ <italic>i</italic>. But <italic>ρ</italic>(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) <italic>&gt; ρ</italic>(<italic>X</italic><sub><italic>j</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>).</p>
</statement>
<p>Therefore, <italic>T</italic> (<bold><italic>X, Y</italic></bold>) must be strictly greater than all permuted versions <italic>T</italic> (<bold><italic>X</italic></bold>, <italic>g</italic><sub><italic>i</italic></sub><bold><italic>Y</italic></bold>) (other than when <italic>g</italic><sub><italic>i</italic></sub> is the identity permutation). It follows that <italic>p</italic><sub><italic>perm</italic></sub> = 1<italic>/n</italic>!.</p>
<p>Suppose now that an <italic>X</italic>-perfect match occurs. It follows that for each <italic>X</italic><sub><italic>i</italic></sub> its correlation term <italic>ρ</italic>(<italic>X</italic><sub><italic>i</italic></sub>, ·) is strictly maximized when <italic>X</italic><sub><italic>i</italic></sub> is paired with <italic>Y</italic><sub><italic>i</italic></sub>. Applying a permutation to <bold><italic>X</italic></bold> (other than the identity permutation) means that for at least one choice of <italic>i</italic>, the <italic>ρ</italic>(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) term in Eq. A-9 becomes replaced with <italic>ρ</italic>(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>j</italic></sub>) for some <italic>j</italic> ≠ <italic>i</italic>. Therefore, <italic>T</italic> (<bold><italic>X, Y</italic></bold>) is be strictly greater than all permuted versions <italic>T</italic> (<italic>g</italic><sub><italic>i</italic></sub><bold><italic>X, Y</italic></bold>) whenever <italic>g</italic><sub><italic>i</italic></sub> is not the identity permutation. So <italic>p</italic><sub><italic>perm</italic></sub> = 1<italic>/n</italic>!.</p>
<statement id="lem9">
<label>Lemma 9</label>
<p>1<italic>/n</italic>! ≥ 2<italic>/n</italic><sup><italic>n</italic></sup> for all integers <italic>n &gt;</italic> 1, with equality only when <italic>n</italic> = 2.</p>
<p><bold>Proof:</bold> When <italic>n</italic> = 2 it is clear that 1<italic>/n</italic>! = 2<italic>/n</italic><sup><italic>n</italic></sup> = 1<italic>/</italic>2.</p>
</statement>
<p>For <italic>n &gt;</italic> 2, we establish 1<italic>/n</italic>! <italic>&gt;</italic> 2<italic>/n</italic><sup><italic>n</italic></sup> by an inductive argument. For the base case, suppose <italic>n</italic> = 3. Then, 1<italic>/n</italic>! <italic>&gt;</italic> 2<italic>/n</italic><sup><italic>n</italic></sup> becomes 1<italic>/</italic>6 <italic>&gt;</italic> 2<italic>/</italic>27, which is true.</p>
<p>For the inductive step, suppose the target inequality 1<italic>/n</italic>! <italic>&gt;</italic> 2<italic>/n</italic><sup><italic>n</italic></sup> holds. Multiplying the target inequality on both sides by 1<italic>/</italic>(<italic>n</italic> + 1), we obtain
<disp-formula id="ueqn35">
<graphic xlink:href="531689v4_ueqn35.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>This shows that 1<italic>/n</italic>! <italic>&gt;</italic> 2<italic>/n</italic><sup><italic>n</italic></sup> implies 1<italic>/</italic>(<italic>n</italic> + 1)! <italic>&gt;</italic> 2<italic>/</italic>(<italic>n</italic> + 1)<sup><italic>n</italic>+1</sup>. We conclude by the inductive principle that the target inequality is true for <italic>n &gt;</italic> 2.</p>
<statement id="The10">
<label>Theorem 10</label>
<p><italic>The permute-match</italic><sub><italic>X</italic>▸<italic>Y</italic></sub> <italic>test is valid</italic>.</p>
<p>Let <bold><italic>X</italic></bold> = (<italic>X</italic><sub>1</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) and <bold><italic>Y</italic></bold> = (<italic>Y</italic><sub>1</sub>, …, <italic>Y</italic><sub><italic>n</italic></sub>) be sequences of iid random variables. Let <bold><italic>X</italic></bold> and <bold><italic>Y</italic></bold> be independent. Let the correlation function <italic>ρ</italic> be a function that maps a pair (<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>j</italic></sub>) to a real number. Define the average correlation
<disp-formula id="ueqn36">
<graphic xlink:href="531689v4_ueqn36.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Perform the permutation test of independence (Def. 2) using <italic>T</italic> as the statistic, and obtain the <italic>p</italic>-value <italic>p</italic><sub><italic>perm</italic></sub>. Also check for an <italic>X</italic>-perfect match test and a <italic>Y</italic> -perfect match test (Def. 5) using <italic>ρ</italic> as the correlation function. Let
<disp-formula id="ueqn37">
<graphic xlink:href="531689v4_ueqn37.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Then <italic>P</italic> (<italic>p</italic> ≤ <italic>α</italic>) for <italic>α</italic> ∈ [0, 1] and <italic>n &gt;</italic> 1.</p>
<p><bold>Proof:</bold> For notational convenience, we denote the events of an <italic>X</italic>-perfect match and <italic>Y</italic> -perfect match as <italic>M</italic><sub><italic>X</italic></sub> and <italic>M</italic><sub><italic>Y</italic></sub>.</p>
</statement>
<p>There are four cases to consider. Either (case i) <italic>α</italic> ≥ 1<italic>/n</italic>!, or (case ii) 1<italic>/n</italic>! <italic>&gt; α</italic> ≥ 2<italic>/n</italic><sup><italic>n</italic></sup>, or (case iii) 2<italic>/n</italic><sup><italic>n</italic></sup> <italic>&gt; α</italic> ≥ 1<italic>/n</italic><sup><italic>n</italic></sup>, or (case iv) <italic>α &lt;</italic> 1<italic>/n</italic><sup><italic>n</italic></sup>. Note that Lemma 9 tells us that 1<italic>/n</italic>! ≥ 2<italic>/n</italic><sup><italic>n</italic></sup>.</p>
<p>Case i: Suppose <italic>α</italic> ≥ 1<italic>/n</italic>!. In this case, <italic>p</italic> ≤ <italic>α</italic> if <italic>M</italic><sub><italic>X</italic></sub> occurs or <italic>M</italic><sub><italic>Y</italic></sub> occurs or <italic>p</italic><sub><italic>perm</italic></sub> ≤ <italic>α</italic>.
<disp-formula id="ueqn38">
<graphic xlink:href="531689v4_ueqn38.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>This may be split into 3 terms via the identity <italic>P</italic> (<italic>A</italic> or <italic>B</italic>) = <italic>P</italic> (<italic>A</italic> and <italic>B</italic>)+<italic>P</italic> (<italic>A</italic> and not <italic>B</italic>)+<italic>P</italic> ((not <italic>A</italic>) and <italic>B</italic>), as follows:
<disp-formula id="ueqn39">
<graphic xlink:href="531689v4_ueqn39.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>However, by Lemma 8, if either <italic>M</italic><sub><italic>X</italic></sub> or <italic>M</italic><sub><italic>Y</italic></sub> occurs, then <italic>p</italic><sub><italic>perm</italic></sub> = 1<italic>/n</italic>!, which would in turn imply <italic>p</italic><sub><italic>perm</italic></sub> ≤ <italic>α</italic> under case i. That is, the term <italic>P</italic> (<italic>p</italic><sub><italic>perm</italic></sub> <italic>&gt; α</italic> and (<italic>M</italic><sub><italic>X</italic></sub> or <italic>M</italic><sub><italic>Y</italic></sub>)) in the above summation is zero. Removing this term, we have
<disp-formula id="ueqn40">
<graphic xlink:href="531689v4_ueqn40.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the final inequality is due to Lemma 3. This establishes the claim for case i.</p>
<p>Case ii: Suppose 1<italic>/n</italic>! <italic>&gt; α</italic> ≥ 2<italic>/n</italic><sup><italic>n</italic></sup>. In this case, <italic>p</italic><sub><italic>perm</italic></sub> <italic>&gt; α</italic> since <italic>p</italic><sub><italic>perm</italic></sub> cannot be less than 1<italic>/n</italic>!, so we have
<disp-formula id="ueqn41">
<graphic xlink:href="531689v4_ueqn41.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>From Lemmas 6-7 we know <italic>P</italic> (<italic>M</italic><sub><italic>X</italic></sub>) ≤ 1<italic>/n</italic><sup><italic>n</italic></sup> and <italic>P</italic> (<italic>M</italic><sub><italic>Y</italic></sub>) ≤ 1<italic>/n</italic><sup><italic>n</italic></sup>. Thus the above inequality becomes
<disp-formula id="ueqn42">
<graphic xlink:href="531689v4_ueqn42.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
which establishes the claim in case ii.</p>
<p>Case iii: Suppose 2<italic>/n</italic><sup><italic>n</italic></sup> <italic>&gt; α</italic> ≥ 1<italic>/n</italic><sup><italic>n</italic></sup>. In this case, only <italic>M</italic><sub><italic>X</italic></sub> will give us <italic>p</italic> ≤ <italic>α</italic>. So we have
<disp-formula id="ueqn43">
<graphic xlink:href="531689v4_ueqn43.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
which verifies the claim in case iii.</p>
<p>Case iv: If <italic>α &lt;</italic> 1<italic>/n</italic><sup><italic>n</italic></sup>, then, <italic>p α</italic> is impossible so <italic>P</italic> (<italic>p</italic> ≤<italic>α</italic>) = 0 ≤<italic>α</italic>, so the claim is trivially satisfied in case iv.</p>
<p>Having been shown in all four cases, the claim has been proven.</p>
<statement id="The11">
<label>Theorem 11</label>
<p><italic>The permute-match</italic><sub><italic>Y</italic> ▸<italic>X</italic></sub> <italic>test is valid</italic>.</p>
<p>Consider the same setting as Theorem 10, except that now
<disp-formula id="ueqn44">
<graphic xlink:href="531689v4_ueqn44.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Then, <italic>P</italic> (<italic>p</italic> ≤ <italic>α</italic>) for <italic>α</italic> ∈ [0, 1] and <italic>n &gt;</italic> 1.</p>
<p><bold>Proof:</bold> The proof is analogous to that of Theorem 11. In fact, the only thing we need to change here is that in case iii, we use the fact that <italic>P</italic> (<italic>M</italic><sub><italic>Y</italic></sub>) ≤ 1<italic>/n</italic><sup><italic>n</italic></sup> instead of that <italic>P</italic> (<italic>M</italic><sub><italic>X</italic></sub>) ≤ 1<italic>/n</italic><sup><italic>n</italic></sup>.</p>
<p><bold>Theorem 12</bold> <italic>The simultaneous permute-match</italic><sub>(<italic>X</italic>;<italic>Y</italic>)</sub> <italic>test is valid</italic>.</p>
</statement>
<p>Consider the same setting as Theorem 10, except that now
<disp-formula id="ueqn45">
<graphic xlink:href="531689v4_ueqn45.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Then, <italic>P</italic> (<italic>q</italic> ≤ <italic>α</italic>) for <italic>α</italic> ∈ [0, 1] and <italic>n &gt;</italic> 1.</p>
<p><bold>Proof:</bold> We first show by cases that <italic>p</italic> of Theorem 10 is always less than or equal to <italic>q</italic>. First, if an <italic>X</italic>-perfect match occurs, then <italic>p</italic> = 1<italic>/n</italic><sup><italic>n</italic></sup> <italic>&lt;</italic> 2<italic>/n</italic><sup><italic>n</italic></sup> = <italic>q</italic>. Second, if there is a <italic>Y</italic> -perfect match but not an <italic>X</italic>-perfect match, then <italic>p</italic> = 1<italic>/n</italic><sup><italic>n</italic></sup> = <italic>q</italic>, Third, if neither an <italic>X</italic>-perfect nor a <italic>Y</italic> -perfect match occurs, then <italic>p</italic> = <italic>p</italic><sub><italic>perm</italic></sub> = <italic>q</italic>. Overall, <italic>p ≤ q</italic>. It follows that <italic>q ≤ α</italic> implies <italic>p ≤ α</italic>.</p>
<p>Then it follows from Theorem 10 that
<disp-formula id="ueqn46">
<graphic xlink:href="531689v4_ueqn46.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
so <italic>P</italic> (<italic>q</italic> ≤ <italic>α</italic>) ≤ <italic>α</italic> as required.</p>
</sec>
<sec id="s6b">
<label>3</label>
<title>The sequential permute-match test versus a similar flawed procedure</title>
<p>In the main text we briefly noted that the sequential permute-match test resembles the flawed practice of conducting additional tests merely because earlier tests did not result in a detection. Here we provide a detailed explanation of why this practice generally results in an invalid <italic>p</italic>-value, and point out that the sequential permute-match test does not have this problem.</p>
<p>To spell out the flawed practice, suppose a researcher runs one test (test <italic>X</italic>) and obtains a <italic>p</italic>-value, <italic>p</italic><sub><italic>X</italic></sub>. If <italic>p</italic><sub><italic>X</italic></sub> is below their desired significance level <italic>α</italic>, they stop there and report <italic>p</italic><sub><italic>X</italic></sub>. Conversely, if <italic>p</italic><sub><italic>X</italic></sub> <italic>&gt; α</italic>, this researcher performs another test (test <italic>Y</italic>) that assesses the same biological hypothesis in a slightly different way, obtaining a second <italic>p</italic>-value, <italic>p</italic><sub><italic>Y</italic></sub>. However, the researcher has a vague understanding that if one conducts multiple tests, a correction is required, so at this point they perform a Bonferroni correction to account for two tests and report 2<italic>p</italic><sub><italic>Y</italic></sub>. Overall, the <italic>p</italic>-value obtained from this series of steps is:
<disp-formula id="eqnA_10">
<graphic xlink:href="531689v4_eqnA_10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>One may ask whether this overall procedure has the desired property (known as ‘validity’) that it prevents the false positive rate from exceeding the significance level. Unfortunately, this procedure is generally not valid, meaning that it commonly leads to <italic>P</italic> (<italic>p ≤α</italic>) <italic>&gt; α</italic> under the null hypothesis.</p>
<p>To demonstrate this fact mathematically, we make three assumptions. First, we assume that the null hypothesis is true for both test <italic>X</italic> and <italic>Y</italic> so that <italic>P</italic> (<italic>p ≤α</italic>) is the false positive rate. Second, we assume that <italic>p</italic><sub><italic>X</italic></sub> and <italic>p</italic><sub><italic>Y</italic></sub> are both random variables following a uniform distribution between 0 and 1. Finally, we assume that the significance level <italic>α</italic> is less than 1<italic>/</italic>2.</p>
<p>The false positive rate of the procedure in Eq A-10 depends on the relationship between the two tests. If tests <italic>X</italic> and <italic>Y</italic> tend to report the same result, they will behave more like a single test and the false positive rate of Eq A-10 will be lower; if the tests frequently report different results, they will behave like two genuinely distinct tests, and the false positive rate will be greater. This relationship is quantified in Table A-1, which describes the joint and marginal distributions of the <italic>X</italic> and <italic>Y</italic> test outcomes. We write the probability that test <italic>X</italic> is significant (or not) along the bottom row, and the probability that test <italic>Y</italic> is significant (or not) along the rightmost column. We then define a parameter (<italic>P</italic> <sup><italic>′</italic></sup>) which is the probability that test <italic>Y</italic> is significant while test <italic>X</italic> is not. We then fill out the rest of the table, corresponding to the probabilities of the other possible test results, by ensuring that the rows and columns of the 2 × 2 “Joint probability” table sum to the entries in the “Total probability” row and column.</p>
<fig id="figA_1" position="float" fig-type="figure">
<label>Figure A-1:</label>
<caption><p>The procedure of Eq A-10 produces a false positive rate that generally exceeds <italic>α</italic>, and depends on the relationship between tests <italic>X</italic> and <italic>Y</italic>. This relationship <italic>X</italic> and <italic>Y</italic> can be quantified by <italic>P</italic><sup><italic>′</italic></sup>, the probability that test <italic>Y</italic> is significant (i.e. 2<italic>p</italic><sub><italic>Y</italic></sub> <italic>≤α</italic>) but test <italic>X</italic> is not significant (i.e. <italic>p</italic><sub><italic>X</italic></sub> <italic>&gt; α</italic>). The false positive range is shown over the full range of <italic>P</italic><sup><italic>′</italic></sup>, from 0 to <italic>α/</italic>2. The only way for the overall procedure of Eq A-10 to be valid is when <italic>P</italic><sup><italic>′</italic></sup> = 0, where tests <italic>X</italic> and <italic>Y</italic> are so tightly coupled that a significant result in test <italic>Y</italic> deterministically ensures that test <italic>X</italic> is also significant. Other than this edge case, the false positive rate of the overall procedure will exceed <italic>α</italic>.</p></caption>
<graphic xlink:href="531689v4_figA_1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<table-wrap id="tblA_1" orientation="portrait" position="float">
<label>Table A-1:</label>
<caption><p>Joint and marginal probabilities of the outcomes of tests <italic>X</italic> and <italic>Y</italic>, assuming that <italic>p</italic><sub><italic>X</italic></sub> and <italic>p</italic><sub><italic>Y</italic></sub> both follow Unif(0, 1). The parameter <italic>P</italic><sup><italic>′</italic></sup> is the probability that test <italic>Y</italic> is significant but test <italic>X</italic> is not.</p></caption>
<graphic xlink:href="531689v4_tblA_1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>Each joint probability is of course bounded between 0 and 1. Thus, moving clockwise from the upper left of the 2 × 2 inner table we have the following constraints on <italic>P</italic><sup><italic>′</italic></sup>:
<disp-formula id="ueqn47">
<graphic xlink:href="531689v4_ueqn47.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Among these constraints, the tightest bounds on <italic>P</italic> <sup><italic>′</italic></sup> are 0 ≤<italic>P</italic> <sup><italic>′</italic></sup> <italic>≤α/</italic>2. Notice that the false positive rate of the overall procedure is given by:
<disp-formula id="eqnA_11">
<graphic xlink:href="531689v4_eqnA_11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Fig A-1 plots Eq A-11 within the allowed bounds of <italic>P</italic><sup><italic>′</italic></sup>, noting the extreme cases of <italic>P</italic><sup><italic>′</italic></sup> = 0 and <italic>P</italic><sup><italic>′</italic></sup> = <italic>α/</italic>2, as well as the case of independence in which <italic>P</italic><sup><italic>′</italic></sup> = <italic>P</italic> (2<italic>p</italic><sub><italic>Y</italic></sub> <italic>≤α</italic>) × (<italic>p</italic><sub><italic>X</italic></sub> <italic>&gt; α</italic>). Other than the extreme case of <italic>P</italic><sup><italic>′</italic></sup> = 0, in which a significant <italic>Y</italic> test result deterministically ensures that the <italic>X</italic> test is also significant, the false positive rate of the overall procedure, <italic>P</italic> (<italic>p ≤α</italic>), will be greater than <italic>α</italic>. Thus the procedure is not valid.</p>
<p>The approach for the sequential permute-match test (<xref rid="fig1" ref-type="fig">Fig 1F</xref>) is different because it is based on events, not continuous random variables. Perhaps counterintuitively, we can actually get away with a similar recipe while producing a valid <italic>p</italic>-value. To best compare our approach to the flawed procedure above, we presently leave out the permutation part and focus only on the matching test component in the following proposition:</p>
<statement id="Pre13">
<label>Proposition 13</label>
<p>Let <italic>M</italic><sub><italic>X</italic></sub> and <italic>M</italic><sub><italic>Y</italic></sub> be events with <italic>P</italic> (<italic>M</italic><sub><italic>X</italic></sub>) ≤ 1<italic>/n</italic><sup><italic>n</italic></sup> and <italic>P</italic> (<italic>M</italic><sub><italic>Y</italic></sub>) ≤ 1<italic>/n</italic><sup><italic>n</italic></sup>. Let
<disp-formula id="eqnA_12">
<graphic xlink:href="531689v4_eqnA_12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Then, <italic>P</italic> (<italic>p</italic> ≤ <italic>α</italic>) ≤ <italic>α</italic> for 0 ≤ <italic>α</italic> ≤ 1 and for all integers <italic>n</italic> ≥ 2.</p>
<p><bold>Proof:</bold> We consider four cases, each corresponding to possible values of <italic>α</italic>.</p>
<p>First, if <italic>α</italic> = 1, then <italic>P</italic> (<italic>p</italic> ≤<italic>α</italic>) ≤<italic>α</italic> trivially because probability does not exceed 1.</p>
<p>Second is the case 1 <italic>&gt; α</italic>≥ 2<italic>/n</italic><sup><italic>n</italic></sup>. In this case, either <italic>M</italic><sub><italic>X</italic></sub> or <italic>M</italic><sub><italic>Y</italic></sub> is sufficient to achieve <italic>p</italic> ≤<italic>α</italic>. So we have:
<disp-formula id="ueqn48">
<graphic xlink:href="531689v4_ueqn48.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
as required.</p>
</statement>
<p>Third, consider the case 2<italic>/n</italic><sup><italic>n</italic></sup> <italic>&gt; α</italic> ≥ 1<italic>/n</italic><sup><italic>n</italic></sup>. In this case, only <italic>M</italic><sub><italic>X</italic></sub> will give us <italic>p</italic> ≤ <italic>α</italic>. So we have
<disp-formula id="ueqn49">
<graphic xlink:href="531689v4_ueqn49.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
as required.</p>
<p>Finally consider the case <italic>α &lt;</italic> 1<italic>/n</italic><sup><italic>n</italic></sup>. In this case <italic>p≤ α</italic> is impossible so <italic>P</italic> (<italic>p ≤α</italic>) = 0 ≤<italic>α</italic>, as required. Since the claim holds under our (exhaustive) set of cases, the proof is complete.</p>
<p>The same argument holds if 1<italic>/n</italic><sup><italic>n</italic></sup> and 2<italic>/n</italic><sup><italic>n</italic></sup> is replaced <italic>q</italic> and 2<italic>q</italic> for an arbitrary <italic>q</italic> between 0 and 1, but we use 1<italic>/n</italic><sup><italic>n</italic></sup> and 2<italic>/n</italic><sup><italic>n</italic></sup> to highlight the connection to the permute-match test. Our complete proof full (Theorem 10) followed largely the same steps as shown here. Overall, we hope that readers of this section now have a deeper understanding of why the sequential permute-match test is valid, and an appreciation of why similar approaches are invalid in the more standard context where statistical tests are not simply binary event checks.</p>
</sec>
<sec id="s6c">
<label>4</label>
<title>Illustration of permute-match test with logistic map system</title>
<fig id="figA_2" position="float" fig-type="figure">
<label>Figure A-2:</label>
<caption><p>Statistical power of permute-match tests and the permutation test in a nonlinear and nonstationary system. (<bold>A</bold>) System equations. (<bold>B</bold>) Example dynamics. The processes <italic>X</italic> and <italic>Y</italic> are given by a coupled logistic map on a time grid <italic>t</italic> = 1, 2, …, 100. The system is nonstationary because the parameter <italic>r</italic>(<italic>t</italic>) varies with time from 3.72 when <italic>t</italic> = 1 to 3.82 when <italic>t</italic> = 99. To see the nonstationarity clearly, we plot <italic>X</italic><sub><italic>i</italic></sub>(<italic>t</italic>) against <italic>X</italic><sub><italic>i</italic></sub>(<italic>t</italic> + 1) and color points by time, showing that as time progresses, there is an upward drift in the parabola that the points lie on. To better show the trend, 10 replicates are shown simultaneously in this chart. (<bold>D</bold>) Statistical power of the permutation test and permute-match tests as a function of the number of replicates, the significance level, and <italic>r</italic><sub><italic>X,Y</italic></sub>. Power was calculated from 5000 simulations at each value of <italic>r</italic><sub><italic>X,Y</italic></sub> between <italic>r</italic><sub><italic>X,Y</italic></sub> = 0 and <italic>r</italic><sub><italic>X,Y</italic></sub> = 0.2 in steps of size 0.005. The correlation statistic (<italic>ρ</italic>) was cross-map skill, which is known to readily detect dependence between <italic>X</italic> and <italic>Y</italic> in this system [<xref ref-type="bibr" rid="c45">45</xref>]. For the cross-map skill calculation, we used <italic>Y</italic> to estimate <italic>X</italic>, which corresponds to a scenario where the data analyst hypothesizes that <italic>X</italic> influences <italic>Y</italic>. Cross-map skill requires two parameters, the embedding dimension and the embedding lag, and these were set to 2 and 1 respectively following prior works that used the logistic map for benchmarking [<xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c46">46</xref>].</p></caption>
<graphic xlink:href="531689v4_figA_2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</app>
</app-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103703.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Krishna</surname>
<given-names>Sandeep</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Centre for Biological Sciences­‐Tata Institute of Fundamental Research</institution>
</institution-wrap>
<city>Bangalore</city>
<country>India</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This manuscript reports an <bold>important</bold> new statistical method for calculating the significance of correlations between two time-series, which provides more accuracy than other methods when the data has few replicates. The proposed method solves a real-life problem that is frequently encountered and is broadly applicable to many realistic datasets in many experimental contexts. The technique is supported with <bold>compelling</bold> mathematical derivations as well as analysis of both computer-generated and previously published experimental data.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103703.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The manuscript puts forward a statistical method to more accurately report the significance of correlations within data. The motivation for this study is two-fold. First, the publication of biological studies demands the report of p-values, and it is widely accepted that p-values below the arbitrary threshold of 0.05 give the authors of such studies justification to draw conclusions about their data. Second, many biological studies are limited by the number of replicate samples that are feasible, with replicates of less than 5 typical. The authors report a statistical tool that uses a permute-match approach to calculate p-values. Notably, the proposed method reduces p-values from around 0.2 to 0.04 as compared to a standard permutation test with a small sample size. The approach is clearly explained, including detailed mathematical explanations and derivations. The advantage of the approach is also demonstrated through analysis of computer-generated synthetic data with specified correlation and analysis of previously published data related to fish schooling. The authors make a clear case that this method is an improvement over the more standard approach currently used, and also demonstrate the impact of this methodology on the ability to obtain p-values that are the standard for biological research. Overall, this paper is very strong. While the subject matter seems somewhat specialized, I would make the case that this will be an important study that has broad general interest to readers. The findings are very general and applicable to many research contexts. Experimentalists also want to report accurate p-values in their work and better understand how these values are calculated. Although I believe the previous statement is true, I am not sure that many research groups doing biological work are reading specialized statistics journals regularly. Therefore a useful and broadly applicable statistical tool is well placed in this journal.</p>
<p>
Strengths:</p>
<p>The proposed method is broadly applicable to many realistic datasets in many experimental contexts.</p>
<p>The power of this method was demonstrated with both real experimental data and &quot;synthetic&quot; data. The advantages of the tool are clearly reported. The zebrafish data is a great example dataset.</p>
<p>The method solves a real-life problem that is frequently encountered by many experimental groups in the biological sciences.</p>
<p>The writing of the paper is surprisingly clear, given the technical nature of the subject matter. I would not at all consider myself a statistician or mathematician, but I found the text easy to follow. The authors did an impressive job guiding the reader through material that would often be difficult to grasp. The introduction was also well-written and clearly motivated the goals of the study.</p>
<p>Weaknesses:</p>
<p>A few changes could be made if the manuscript is revised. I would consider all of these points minor, but the paper could be improved if these points were addressed.</p>
<p>(1) The caption of Figure 2 doesn't seem to mention panel D. Figure A-2 also does not mention C in the caption.</p>
<p>(2) Figure 2D is a little hard to follow. First, the definition of &quot;Power&quot; is not clear, and I couldn't find the precise definition in the text. Second, the legend for the different lines in 2D is only given in Figure A-2. Perhaps a portion of the caption for Figure 2 is missing?</p>
<p>(3) The concept of circular variance for the fish data was heard to understand/visualize. The equation on line 326 did not help much. If there is a very simple picture that could be added near line 326 that helps to explain Ct and theta, that could be a big help for some readers who do not work on related systems. The analysis performed is understandable, the reader just has to accept that circular variance captions the degree of alignment of the fish.</p>
<p>(4) For the data discussed in Figure 3, I wasn't 100% sure how the time windows were selected. In the caption, it says &quot;time series to different lengths starting from the first frame&quot;. So the 20 s time window was from t=0 to t= 20 s. Would a different result be obtained if a different 20 s window was chosen (from t = 4 min to t = 4 min 20 s just to give a specific example). I suppose by chance one of the time windows would give a p-value less than the target 0.05, that wouldn't be surprising. Maybe a random time window should be selected (although I am not indicating what was reported was incorrect)? A little more discussion on this aspect of the study may be helpful.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103703.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper presented a hypothesis testing procedure for the independence of two time-series that was potentially suitable for nonlinear dependence and for small-sample cases. This should bring potential benefits for biology data.</p>
<p>Strengths:</p>
<p>The test offers good flexibility for different kinds of dependence (through adjusting \rho), and seems to have good finite sample performance compared to the literature. The justification regarding the validity of the test procedure is clear.</p>
<p>Weaknesses:</p>
<p>(1) The size of the test is not guaranteed to (asymptotically) equal \alpha, which may damage the power.</p>
<p>(2) The computational time can be an issue for a moderately large sample size when calculating the X / Y-perfect match. It will be beneficial to include discussions on the implementations of the test.</p>
</body>
</sub-article>
</article>