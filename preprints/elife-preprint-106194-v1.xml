<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">106194</article-id>
<article-id pub-id-type="doi">10.7554/eLife.106194</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106194.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Virtual Brain Inference (VBI): A flexible and integrative toolkit for efficient probabilistic inference on virtual brain models</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4696-9947</contrib-id>
<name>
<surname>Ziaeemehr</surname>
<given-names>Abolfazl</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<email>abolfazl.ziaee-mehr@univ-amu.fr</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8410-4581</contrib-id>
<name>
<surname>Woodman</surname>
<given-names>Marmaduke</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4822-2046</contrib-id>
<name>
<surname>Domide</surname>
<given-names>Lia</given-names>
</name>
<xref ref-type="aff" rid="a2">b</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4540-6293</contrib-id>
<name>
<surname>Petkoski</surname>
<given-names>Spase</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8251-8860</contrib-id>
<name>
<surname>Jirsa</surname>
<given-names>Viktor</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
<email>viktor.jirsa@univ-amu.fr</email>
</contrib>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5289-9837</contrib-id>
<name>
<surname>Hashemi</surname>
<given-names>Meysam</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
<email>meysam.hashemi@univ-amu.fr</email>
</contrib>
<aff id="a1"><label>a</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/035xkbk20</institution-id><institution>Aix Marseille Univ, INSERM, INS, Inst Neurosci Syst</institution></institution-wrap>, <city>Marseille</city>, <country country="FR">France</country></aff>
<aff id="a2"><label>b</label><institution>Codemart</institution>, <city>Cluj-Napoca</city>, <country country="RO">Romania</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Fornito</surname>
<given-names>Alex</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Monash University</institution>
</institution-wrap>
<city>Clayton</city>
<country>Australia</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Marquand</surname>
<given-names>Andre F</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Radboud University Nijmegen</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>†</label><p>These authors contributed equally.</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-05-21">
<day>21</day>
<month>05</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP106194</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-02-11">
<day>11</day>
<month>02</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-01-22">
<day>22</day>
<month>01</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.01.21.633922"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Ziaeemehr et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Ziaeemehr et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-106194-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Network neuroscience has proven essential for understanding the principles and mechanisms underlying complex brain (dys)function and cognition. In this context, whole-brain network modeling–also known as virtual brain modeling–combines computational models of brain dynamics (placed at each network node) with individual brain imaging data (to coordinate and connect the nodes), advancing our understanding of the complex dynamics of the brain and its neurobiological underpinnings. However, there remains a critical need for automated model inversion tools to estimate control (bifurcation) parameters at large scales and across neuroimaging modalities, given their varying spatio-temporal resolutions. This study aims to address this gap by introducing a flexible and integrative toolkit for efficient Bayesian inference on virtual brain models, called Virtual Brain Inference (<monospace>VBI</monospace>). This open-source toolkit provides fast simulations, taxonomy of feature extraction, efficient data storage and loading, and probabilistic machine learning algorithms, enabling biophysically interpretable inference from non-invasive and invasive recordings. Through in-silico testing, we demonstrate the accuracy and reliability of inference for commonly used whole-brain network models and their associated neuroimaging data. <monospace>VBI</monospace> shows potential to improve hypothesis evaluation in network neuroscience through uncertainty quantification, and contribute to advances in precision medicine by enhancing the predictive power of virtual brain models.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Virtual brain models</kwd>
<kwd>Simulation-based inference</kwd>
<kwd>Structural and functional neuroimaging modalities</kwd>
<kwd>Low-dimensional data features</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<label>1.</label><title>Introduction</title>
<p>Understanding the complex dynamics of the brain and their neurobiological underpinnings, with the potential to advance precision medicine [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>], is a central goal in neuroscience. Modeling these dynamics provides crucial insights into causality and mechanisms underlying both normal brain function and various neurological disorders [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c7">7</xref>]. By integrating the average activity of large populations of neurons (e.g., neural mass models; [<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c13">13</xref>]) with information provided by structural imaging modalities (i.e., connectome; [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>]), whole-brain network modeling has proven to be a powerful tractable approach for simulating brain activities and emergent dynamics as recorded by functional imaging modalities (such as (s)EEG/MEG/fMRI; [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c23">23</xref>].</p>
<p>The whole-brain models have been well-established in network neuroscience [<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref>] for understanding the brain structure and function [<xref ref-type="bibr" rid="c26">26</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c30">30</xref>, <xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c32">32</xref>] and investigating the mechanisms underlying brain dynamics at rest [<xref ref-type="bibr" rid="c33">33</xref>, <xref ref-type="bibr" rid="c34">34</xref>, <xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c36">36</xref>], normal aging [<xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c38">38</xref>], and also altered states such as anaesthesia and loss of consciousness [<xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c41">41</xref>, <xref ref-type="bibr" rid="c42">42</xref>]. This class of computational models, also known as virtual brain models [<xref ref-type="bibr" rid="c43">43</xref>, <xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c46">46</xref>], have shown remarkable capability in delineating the pathophysiological causes of a wide range of brain diseases, such as epilepsy [<xref ref-type="bibr" rid="c47">47</xref>, <xref ref-type="bibr" rid="c48">48</xref>, <xref ref-type="bibr" rid="c6">6</xref>], multiple sclerosis [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c50">50</xref>], Alzheimer’s disease [<xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c52">52</xref>], Parkinson’s disease [<xref ref-type="bibr" rid="c53">53</xref>, <xref ref-type="bibr" rid="c54">54</xref>], neuropsychiatric disorders [<xref ref-type="bibr" rid="c55">55</xref>, <xref ref-type="bibr" rid="c56">56</xref>], stroke [<xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c58">58</xref>] and focal lesions [<xref ref-type="bibr" rid="c59">59</xref>]. In particular, they enable the personalized simulation of both normal and abnormal brain activities, along with their associated imaging recordings, thereby stratifying between healthy and diseased states [<xref ref-type="bibr" rid="c60">60</xref>, <xref ref-type="bibr" rid="c61">61</xref>, <xref ref-type="bibr" rid="c52">52</xref>] and potentially informing targeted interventions and treatment strategies [<xref ref-type="bibr" rid="c47">47</xref>, <xref ref-type="bibr" rid="c62">62</xref>, <xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c23">23</xref>]. Although there are only a few tools available for forward simulations at the whole-brain level, e.g., the brain network simulator The Virtual Brain (TVB; [<xref ref-type="bibr" rid="c44">44</xref>]), there is a lack of tools for addressing the inverse problem, i.e., finding the set of control (generative) parameters that best explains the observed data. This study aims to bridge this gap by addressing the inverse problem in large-scale brain networks, a crucial step toward making these models operable for clinical applications.</p>
<p>Accurately and reliably estimating the parameters of whole-brain models remains a formidable challenge, mainly due to the high-dimensionality and non-linearity inherent in brain activity data, as well as the non-trivial effects of noise and network inputs. A large number of previous studies in whole-brain modeling have relied on optimization techniques to identify a single optimal value from an objective function, scoring the model’s performance against observed data [<xref ref-type="bibr" rid="c34">34</xref>, <xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c63">63</xref>, <xref ref-type="bibr" rid="c64">64</xref>]. This approach often involves minimizing metrics such as the Kolmogorov-Smirnov distance or maximizing the Pearson correlation between observed and generated data features such as functional connectivity (FC), functional connectivity dynamics (FCD), and/or power spectral density (PSD). Although fast, such a parametric approach results in only point estimates and fails to capture the relationship between parameters and their associated uncertainty. This limits the generalizability of findings, and hinders identifiability analysis, which explores the uniqueness of solutions. Furthermore, optimization algorithms can easily get stuck in local extrema, requiring multi-start strategies to address potential parameter degeneracies. These additional steps, while necessary, ultimately increase the computational cost. Critically, the estimation heavily depends on the form of the objective function defined for optimization [<xref ref-type="bibr" rid="c65">65</xref>, <xref ref-type="bibr" rid="c66">66</xref>]. These limitations can be overcome by employing Bayesian inference, which naturally quantifies the uncertainty in the estimation and statistical dependencies between parameters, leading to more robust and generalizable models. Bayesian inference is a principal method for updating prior beliefs with information provided by data through the likelihood function, resulting in a posterior probability distribution that encodes all the information necessary for inferences and predictions. This approach has proven essential for understanding the intricate relationships between brain structure and function [<xref ref-type="bibr" rid="c67">67</xref>, <xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c37">37</xref>], as well as for revealing the pathophysiological causes underlying brain disorders [<xref ref-type="bibr" rid="c68">68</xref>, <xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c46">46</xref>, <xref ref-type="bibr" rid="c69">69</xref>].</p>
<p>In this context, simulation-based inference (SBI; [<xref ref-type="bibr" rid="c70">70</xref>, <xref ref-type="bibr" rid="c71">71</xref>, <xref ref-type="bibr" rid="c68">68</xref>, <xref ref-type="bibr" rid="c69">69</xref>]) has gained prominence as an efficient methodology for conducting Bayesian inference in complex models where traditional inference techniques become inapplicable. SBI leverages computational simulations to generate synthetic data and employs advanced probabilistic machine learning methods to infer the joint distribution over parameters that best explain the observed data, along with associated uncertainty. This approach is particularly well-suited for Bayesian inference on whole-brain models, which often exhibit complex dynamics that are difficult to retrieve from neuroimaging data with conventional estimation techniques. Crucially, SBI circumvents the need for explicit likelihood evaluation and the Markovian (sequential) property in sampling. Markov chain Monte Carlo (MCMC) is a standard non-parametric technique and asymptotically exact for sampling from a probability distribution [<xref ref-type="bibr" rid="c72">72</xref>]. However, for Bayesian inference on whole-brain models given high-dimensional data, the likelihood function becomes intractable, rendering MCMC sampling computationally prohibitive. SBI offers significant advantages, such as parallel simulation while leveraging amortized learning, making it effective for personalized inference from large datasets [<xref ref-type="bibr" rid="c69">69</xref>]. Amortization strategies based on artificial neural networks allow for immediate application to arbitrary inference on new recordings without the need for repeated training [<xref ref-type="bibr" rid="c73">73</xref>]. Following an initial computational cost during simulation and training to learn all posterior distributions, subsequent evaluation of new hypotheses can be conducted efficiently, without additional computational overhead for further simulations [<xref ref-type="bibr" rid="c68">68</xref>]. Importantly, SBI sidesteps the convergence issues caused by complex geometries that are often encountered when using gradient-based MCMC methods [<xref ref-type="bibr" rid="c74">74</xref>, <xref ref-type="bibr" rid="c75">75</xref>, <xref ref-type="bibr" rid="c76">76</xref>]. It also substantially outperforms ABC methods, which rely on a threshold to accept or reject samples [<xref ref-type="bibr" rid="c77">77</xref>, <xref ref-type="bibr" rid="c78">78</xref>, <xref ref-type="bibr" rid="c71">71</xref>]. Such a likelihood-free approach provides us with generic inference on complex systems as long as we can provide three modules:
<list list-type="order">
<list-item><p>A prior distribution, describing the possible range of parameters from which random samples can be easily drawn, i.e., <inline-formula><inline-graphic xlink:href="633922v1_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p></list-item>
<list-item><p>A simulator in computer code, that takes parameters as input and generates data as output, i.e., <inline-formula><inline-graphic xlink:href="633922v1_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p></list-item>
<list-item><p>A set of low-dimensional data features, which are informative of the parameters that we aim to infer.</p></list-item>
</list>
These elements prepare us with a training data set <inline-formula><inline-graphic xlink:href="633922v1_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> with a budget of <italic>N<sub>sim</sub></italic> simulations. Then, using a class of deep neural density estimators (such as masked autoregressive flows [<xref ref-type="bibr" rid="c79">79</xref>] or neural spline flows [<xref ref-type="bibr" rid="c80">80</xref>]), we can approximate the posterior distribution of parameters given a set of observed data, i.e., <inline-formula><inline-graphic xlink:href="633922v1_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Therefore, a versatile toolkit should be flexible and integrative, adeptly incorporating these modules to enable efficient Bayesian inference over complex models.</p>
<p>To address the need for widely applicable, reliable, and efficient parameter estimation from different neuroimaging modalities, we introduce Virtual Brain Inference (<monospace>VBI</monospace>), a flexible and integrative toolkit for probabilistic inference at whole-brain level. This open-source toolkit offers fast simulation through just-in-time (JIT) compilation of various brain models in different programming languages (Python/C++) and devices (CPUs/GPUs). It supports space-efficient storage of simulated data (HDF5/NPZ/PT), provides a memory-efficient loader for batched data, and facilitates the extraction of low-dimensional data features (FC/FCD/PSD). Additionally, it enables the training of deep neural density estimators (MAFs/NSFs), making it a versatile tool for inference on various neuroimaging data types ((s)EEG/MEG/fMRI). <monospace>VBI</monospace> leverages high-performance computing, significantly enhancing computational efficiency through parallel processing of large-scale datasets, which would be impractical with current alternative methods. Although SBI has been used for low-dimensional parameter spaces [<xref ref-type="bibr" rid="c71">71</xref>, <xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c81">81</xref>], we demonstrate that it can scale to whole-brain models with high-dimensional known parameters across neuroimaging modalities, as long as informative data features are provided. <monospace>VBI</monospace> is now accessible on the cloud platform EBRAINS (<ext-link ext-link-type="uri" xlink:href="https://ebrains.eu">https://ebrains.eu</ext-link>), enabling users to explore more realistic brain dynamics underlying brain (dys)functioning using Bayesian inference. In the following sections, we will provide an overview of the theoretical foundations of whole-brain models and simulation-based inference, describe the architecture and features of the <monospace>VBI</monospace> toolkit, and demonstrate the validation through a series of case studies using in-silico data. We explore various whole-brain models corresponding to different types of brain recordings: a whole-brain network model of Wilson-Cowan [<xref ref-type="bibr" rid="c8">8</xref>], Jansen-Rit [<xref ref-type="bibr" rid="c82">82</xref>, <xref ref-type="bibr" rid="c83">83</xref>], and Stuart-Landau [<xref ref-type="bibr" rid="c84">84</xref>] for simulating neural activity associated with EEG/MEG signals, the Epileptor [<xref ref-type="bibr" rid="c11">11</xref>] related to stereoelectro-EEG (sEEG) recordings, and Montbrió [<xref ref-type="bibr" rid="c12">12</xref>], and Wong-Wang [<xref ref-type="bibr" rid="c85">85</xref>, <xref ref-type="bibr" rid="c86">86</xref>] mapped to fMRI BOLD signals. Although these models represent source signals and could be applied to other modalities (e.g., Stuart-Landau representing generic oscillatory dynamics), we focused on their capabilities to perform optimally in specific contexts. For instance, some are better suited for encephalographic signals (e.g., EEG/MEG) due to their ability to preserve spectral properties, while others have been used for fMRI data, emphasizing their ability to capture dynamic features such as bistability and time-varying functional connectivity.</p>
</sec>
<sec id="s2">
<label>2.</label><title>Materials and methods</title>
<sec id="s2a">
<label>2.1.</label><title>The virtual brain models</title>
<p>To build a virtual brain model (see <xref rid="fig1" ref-type="fig">Figure 1</xref>), the process begins with parcellating the brain into regions using anatomical data, typically derived from T1-MRI scans. Each region, represented as nodes in the network, is then equipped with a neural mass model to simulate the collective behavior of neurons within that area. These nodes are interconnected using a structural connectivity (SC) matrix, typically obtained from diffusion-weighted magnetic resonance imaging (DW-MRI). The entire network of interconnected nodes is then simulated using neuroinformatic tools, such as The Virtual Brain (TVB; [<xref ref-type="bibr" rid="c18">18</xref>]), replicating the intricate dynamics of brain activity and its associated brain imaging signals ((s)EEG/MEG/fMRI). This approach offers insights into both normal brain function and neurological disorders. In the following, we describe commonly used whole-brain network models corresponding to different types of neuroimaging recordings.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 1.</label>
<caption><title>The workflow of Virtual Brain Inference (<monospace>VBI</monospace>).</title><p>This probabilistic approach is designed to estimate the posterior distribution of control parameters in virtual brain models from whole-brain neuroimaging recordings. (<bold>A</bold>) The process begins with constructing a personalized connectome using diffusion tensor imaging and a brain parcellation atlas. (<bold>B</bold>) The personalized virtual brain model is then assembled. Neural mass models describing the averaged activity of neural populations, in the generic form of <inline-formula><inline-graphic xlink:href="633922v1_inline30.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, are placed to each brain region, and interconnected via the structural connectivity matrix. Initially, the control parameters are randomly drawn from a simple prior distribution. (<bold>C</bold>) Next, the <monospace>VBI</monospace> operates as a simulator that uses these samples to generate time series data associated with neuroimaging recordings. (<bold>D</bold>) We extract a set summary statistics from the low-dimensional features of the simulations (FC, FCD, PSD) for training. (<bold>E</bold>) Subsequently, a class of deep neural density estimators is trained on pairs of random parameters and their corresponding data features to learn the joint posterior distribution of the model parameters. (<bold>F</bold>) Finally, the amortized network allows us to quickly approximate the posterior distribution for new (empirical) data, enabling us to make probabilistic predictions that are consistent with the observed data.</p></caption>
<graphic xlink:href="633922v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<sec id="s2a1">
<label>2.1.1.</label><title>Wilson-Cowan model</title>
<p>The Wilson-Cowan model [<xref ref-type="bibr" rid="c8">8</xref>] is a seminal neural mass model that describes the dynamics of connected excitatory and inhibitory neural populations, at cortical microcolumn level. It has been widely used to understand the collective behavior of neurons and simulate neural activities recorded by methods such as local field potentials (LFPs) and EEG. The model effectively captures phenomena such as oscillations, wave propagation, pattern formation in neural tissue, and responses to external stimuli, offering insights into various brain (dys)functions, particularly in Parkinson’s disease [<xref ref-type="bibr" rid="c87">87</xref>, <xref ref-type="bibr" rid="c88">88</xref>].</p>
<p>We focused on a simplified model for generation of beta oscillation within the cortex-subthalamic nucleus-globus pallidus network [<xref ref-type="bibr" rid="c89">89</xref>]. The model incorporates a closed-loop connection from the STN back to the cortex, represented by a single inhibitory connection with a time delay. However, it does not include feedback via the indirect pathway (cortex-striatum-GPe), as experimental evidence suggests this pathway is not essential for generating beta oscillations [<xref ref-type="bibr" rid="c90">90</xref>]. Instead, the GPe receives a constant inhibitory input from the striatum, consistent with observations from Parkinson’s disease models:
<disp-formula id="eqn1">
<graphic xlink:href="633922v1_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the functions <italic>S</italic>, <italic>G</italic>, <italic>E</italic>, and <italic>I</italic> represent the firing rates of the STN, GPe, and the excitatory and inhibitory populations, respectively. The parameters <italic>T<sub>ij</sub></italic> denote the synaptic connection time delays from population <italic>i</italic> to population <italic>j</italic>, while <italic>T<sub>ii</sub></italic> represents the time delay of self-connections. The synaptic weights, <italic>w<sub>ij</sub></italic>, follow the same subscript conventions as the time delays, indicating the influence of the presynaptic neuron’s firing rate on the postsynaptic neuron. The membrane time constants are denoted by <italic>τ<sub>i</sub></italic>. A constant input, <italic>C</italic>, is provided to the excitatory population in the cortex to account for a constant component of both extrinsic and intrinsic excitatory inputs, while <italic>Str</italic> represents the constant inhibitory input from the striatum to the GPe. Lastly, <italic>F<sub>i</sub></italic> are the activation functions. The nominal parameter values and the prior range for the target parameters are summarized in <xref rid="tbl1" ref-type="table">Table 1</xref>.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Parameter descriptions for capturing whole-brain dynamics using Wilson-Cowan neural mass model.</title></caption>
<graphic xlink:href="633922v1_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s2a2">
<label>2.1.2.</label><title>Jansen-Rit model</title>
<p>The Jansen-Rit neural mass model [<xref ref-type="bibr" rid="c91">91</xref>] has been widely used to simulate physiological signals from various recording methods like intracranial LFPs, and scalp MEG/EEG recordings. For example, it has been shown to recreate responses similar to evoked-related potentials after a series of impulse stimulations [<xref ref-type="bibr" rid="c83">83</xref>, <xref ref-type="bibr" rid="c92">92</xref>], generating high-alpha and low-beta oscillations (with added recurrent inhibitory connections and spike-rate modulation) [<xref ref-type="bibr" rid="c93">93</xref>], and also seizure patterns similar to those seen in temporal lobe epilepsy [<xref ref-type="bibr" rid="c94">94</xref>]. This biologically motivated model comprises of three main populations of neurons: excitatory pyramidal neurons, inhibitory interneurons and excitatory interneurons. These populations interact with each other through synaptic connections, forming a feedback loop that produces oscillatory activity governed by a set of nonlinear ordinary differential equations [<xref ref-type="bibr" rid="c82">82</xref>, <xref ref-type="bibr" rid="c83">83</xref>, <xref ref-type="bibr" rid="c95">95</xref>]:
<disp-formula id="eqn2">
<graphic xlink:href="633922v1_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>P</italic>(<italic>t</italic>) represents an external input current. The model’s output at <italic>i<sub>th</sub></italic> region, which corresponds to the membrane potential of pyramidal cells, is given by <italic>y</italic><sub>1</sub><italic><sub>i</sub> −y</italic><sub>2</sub><italic><sub>i</sub></italic>. The nominal parameter values and the prior range for the target parameters are summarized in <xref rid="tbl2" ref-type="table">Table 2</xref>.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title>Parameter descriptions for capturing whole-brain dynamics using Jansen-Rit neural mass model. EP: excitatory populations, IP: inhibitory populations, PSP: post synaptic potential, PSPA: post synaptic potential amplitude.</title></caption>
<graphic xlink:href="633922v1_tbl2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s2a3">
<label>2.1.3.</label><title>Stuart-Landau oscillator</title>
<p>The Stuart-Landau oscillator [<xref ref-type="bibr" rid="c84">84</xref>] is a generic mathematical model used to describe oscillatory phenomena, particularly those near a Hopf bifurcation, which is often employed to study the nonlinear dynamics of neural activity [<xref ref-type="bibr" rid="c96">96</xref>, <xref ref-type="bibr" rid="c97">97</xref>, <xref ref-type="bibr" rid="c63">63</xref>, <xref ref-type="bibr" rid="c49">49</xref>]. One approach uses this model to capture slow hemodynamic changes in BOLD signal [<xref ref-type="bibr" rid="c96">96</xref>], while others apply it to model fast neuronal dynamics, which can be linked directly to EEG/MEG data [<xref ref-type="bibr" rid="c97">97</xref>, <xref ref-type="bibr" rid="c63">63</xref>, <xref ref-type="bibr" rid="c49">49</xref>]. Note that this is a phenomenological frame-work, and both applications operate on completely different time scales.</p>
<p>In the network, each brain region, characterized by an autonomous Stuart-Landau oscillator, can exhibit either damped or limit-cycle oscillations depending on the bifurcation parameter <italic>a</italic>. If <italic>a &lt;</italic> 0, the system shows damped oscillations, similar to a pendulum under friction. In this regime, the system, when subjected to perturbation, relaxes back to its stable fixed point through damped oscillations with an angular frequency <italic>ω</italic><sub>0</sub>. The rate of amplitude damping is determined by |<italic>a</italic>|. Conversely, if <italic>a &gt;</italic> 0, the system supports limit cycle solutions, allowing for self-sustained oscillations even in the absence of external noise. At <italic>a</italic> = 0, the system undergoes a Hopf bifurcation, i.e., small changes in parameters can lead to large variations in the system’s behavior.</p>
<p>Using whole-brain network modeling of EEG/MEG data [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c63">63</xref>], the oscillators are interconnected via white-matter pathways, with coupling strengths specified by subject-specific DTI fiber counts, i.e., elements of SC matrix. This adjacency matrix is then scaled by a global coupling parameter <italic>G</italic>. Note that coupling between regions accounts for finite conduction times, which are often estimated by dividing the Euclidean distances between nodes by an average conduction velocity <italic>T<sub>jk</sub></italic> = <italic>d<sub>jk</sub></italic>/<italic>v</italic>. Knowing the personalized time-delays [<xref ref-type="bibr" rid="c98">98</xref>, <xref ref-type="bibr" rid="c99">99</xref>], we can use the distance as a proxy, assuming a constant propagation velocity. The distance itself can be defined as either the length of the tracts or the Euclidean distance. Taking this into account, the activity of each regions is given by a set of complex differential equations:
<disp-formula id="eqn3">
<graphic xlink:href="633922v1_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>Z</italic> is a complex variable, and Re[<italic>Z</italic>(<italic>t</italic>)] is the corresponding time series. In this particular realization, each region has a natural frequency of 40 Hz (<italic>ω<sub>j</sub></italic>= <italic>ω</italic><sub>0</sub> = 2<italic>π·</italic>40 <italic>rad/s</italic>), motivated by empirical studies demonstrating the emergence of gamma oscillations from the balance of excitation and inhibition, playing a role in local circuit computations [<xref ref-type="bibr" rid="c100">100</xref>].</p>
<p>In this study, for the sake of simplicity, a common cortico-cortical conduction velocity is estimated, i.e., the distance-dependent average velocities <italic>v<sub>jk</sub></italic> = <italic>v</italic>. We also consider <italic>a</italic> = −5, capturing the highly variable amplitude envelope of gamma oscillations as reported in experimental recordings [<xref ref-type="bibr" rid="c101">101</xref>, <xref ref-type="bibr" rid="c63">63</xref>]. This choice also best reflects the slowest decay time constants of GABA<sub>B</sub> inhibitory receptors–approximately 1 second [<xref ref-type="bibr" rid="c102">102</xref>]. A Gaussian noise with an intensity of <italic>σ</italic> = 10<sup>−4</sup> is added to each oscillator to mimic stochastic fluctuations. The nominal parameter values and the prior range for the target parameters are summarized in <xref rid="tbl3" ref-type="table">Table 3</xref>.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><title>Parameter descriptions for capturing whole-brain dynamics using Stuart-Landau oscillator.</title></caption>
<graphic xlink:href="633922v1_tbl3.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s2a4">
<label>2.1.4.</label><title>Epileptor model</title>
<p>In personalized whole-brain network modeling of epilepsy spread [<xref ref-type="bibr" rid="c47">47</xref>], the dynamics of each brain region are governed by the Epileptor model [<xref ref-type="bibr" rid="c11">11</xref>]. The Epileptor model provides a comprehensive description of epileptic seizures, encompassing the complete taxonomy of system bifurcations to simultaneously reproduce the dynamics of seizure onset, progression, and termination [<xref ref-type="bibr" rid="c103">103</xref>]. The full Epileptor model comprises five state variables that couple two oscillatory dynamical systems operating on three different time scales [<xref ref-type="bibr" rid="c11">11</xref>]. Then motivated by Synergetic theory [<xref ref-type="bibr" rid="c104">104</xref>, <xref ref-type="bibr" rid="c105">105</xref>] and under time-scale separation [<xref ref-type="bibr" rid="c106">106</xref>], the fast variables rapidly collapse on the slow manifold [<xref ref-type="bibr" rid="c107">107</xref>], whose dynamics is governed by the slow variable. This adiabatic approximation yields the 2D reduction of whole-brain model of epilepsy spread, also known as the Virtual Epileptic Patient (VEP) as follows:
<disp-formula id="eqn4">
<graphic xlink:href="633922v1_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>x<sub>i</sub></italic> and <italic>z<sub>i</sub></italic> indicate the fast and slow variables corresponding to <italic>i<sub>th</sub></italic> brain region, respectively, and the set of unknown <italic>η<sub>i</sub></italic> is the spatial map of epileptogenicity to be estimated. In real-world epilepsy applications [<xref ref-type="bibr" rid="c67">67</xref>, <xref ref-type="bibr" rid="c68">68</xref>, <xref ref-type="bibr" rid="c6">6</xref>], we compute the envelope function from sEEG data to perform inference. The nominal parameter values and the prior range for the target parameters are summarized in <xref rid="tbl4" ref-type="table">Table 4</xref>.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4.</label>
<caption><title>Parameter descriptions for capturing whole-brain dynamics using 2D Epileptor neural mass model.</title></caption>
<graphic xlink:href="633922v1_tbl4.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s2a5">
<label>2.1.5.</label><title>Montbrió model</title>
<p>The exact macroscopic dynamics of a specific brain region (represented as a node in the network) can be analytically derived in thermodynamic limit of infinitely all-to-all coupled spiking neurons [<xref ref-type="bibr" rid="c12">12</xref>] or Θ neuron representation [<xref ref-type="bibr" rid="c108">108</xref>]. By assuming a Lorentzian distribution on excitabilities in large ensembles of quadratic integrate- and- fire neurons with synaptic weights <italic>J</italic> and a half-width Δ centered at <italic>η</italic>, the macroscopic dynamics has been derived in terms of the collective firing activity and mean membrane potential [<xref ref-type="bibr" rid="c12">12</xref>]. Then, by coupling the brain regions via an additive current (e.g., in the average membrane potential equations), the dynamics of the whole-brain network can be described as follow [<xref ref-type="bibr" rid="c109">109</xref>, <xref ref-type="bibr" rid="c110">110</xref>]:
<disp-formula id="eqn5">
<graphic xlink:href="633922v1_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>v<sub>i</sub></italic> and <italic>r<sub>i</sub></italic> are the average membrane potential and firing rate, respectively, at the <italic>i<sub>th</sub></italic> brain region, and parameter <italic>G</italic> is the network scaling parameter that modulates the overall impact of brain connectivity on the state dynamics. The <italic>SC<sub>ij</sub></italic> denotes the connection weight between <italic>i<sub>th</sub></italic> and <italic>j<sub>th</sub></italic> regions, and the dynamical noise <italic>ξ</italic>(<italic>t</italic>) ∼ <italic>N</italic>(0<italic>, σ</italic><sup>2</sup>) follows a Gaussian distribution with mean zero and variance <italic>σ</italic><sup>2</sup>.</p>
<p>The model parameters are tuned so that each decoupled node is in a bistable regime, exhibiting a down-state stable fixed point (low-firing rate) and an up-state stable focus (high-firing rate) in the phase-space [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c81">81</xref>]. The bistability is a fundamental property of regional brain dynamics to ensure a switching behavior in the data (e.g., to generate FCD), that has been recognized as representative of realistic dynamics observed empirically [<xref ref-type="bibr" rid="c109">109</xref>, <xref ref-type="bibr" rid="c111">111</xref>, <xref ref-type="bibr" rid="c112">112</xref>].</p>
<p>The solution of the coupled system yields a neuroelectric dataset that describes the evolution of the variables (<italic>r<sub>i</sub></italic>(<italic>t</italic>), <italic>v<sub>i</sub></italic>(<italic>t</italic>)) in each brain region <italic>i</italic>, providing measures of macroscopic activity. The surrogate BOLD activity for each region is then derived by filtering this activity through the Balloon-Windkessel model [<xref ref-type="bibr" rid="c113">113</xref>]. The input current <italic>I<sub>stim</sub></italic> represents the stimulation to selected brain regions, which increase the basin of attraction of the up-state in comparison to the down-state, while the fixed points move farther apart [<xref ref-type="bibr" rid="c109">109</xref>, <xref ref-type="bibr" rid="c111">111</xref>, <xref ref-type="bibr" rid="c112">112</xref>].</p>
<p>The nominal parameter values and the prior range for the target parameters are summarized in <xref rid="tbl5" ref-type="table">Table 5</xref>.</p>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5.</label>
<caption><title>Parameter descriptions for capturing whole-brain dynamics using Montbrió model.</title></caption>
<graphic xlink:href="633922v1_tbl5.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s2a6">
<label>2.1.6.</label><title>Wong-Wang model</title>
<p>Another commonly used whole-brain model for simulation of neural activity is the so-called parameterized dynamics mean-field (pDMF) model [<xref ref-type="bibr" rid="c114">114</xref>, <xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c86">86</xref>]. At each region, it comprises a simplified system of two non-linear coupled differential equations, motivated by the attractor network model, which integrates sensory information over time to make perceptual decisions, known as Wong-Wang model [<xref ref-type="bibr" rid="c85">85</xref>]. This biophysically realistic cortical network model of decision making then has been simplified further into a single-population model [<xref ref-type="bibr" rid="c86">86</xref>], which has been widely used to understand the mechanisms underpinning brain resting state dynamics [<xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c115">115</xref>, <xref ref-type="bibr" rid="c38">38</xref>]. The pDMF model has been also used to study whole-brain dynamics in various brain disorders, including Alzheimer’s disease [<xref ref-type="bibr" rid="c116">116</xref>], schizophrenia [<xref ref-type="bibr" rid="c117">117</xref>], and stroke [<xref ref-type="bibr" rid="c118">118</xref>]. The pDMF model equations are given as:
<disp-formula id="eqn6">
<graphic xlink:href="633922v1_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>H</italic>(<italic>x<sub>i</sub></italic>) and <italic>S<sub>i</sub></italic>, and <italic>x<sub>i</sub></italic> denote the population firing rate, the average synaptic gating variable, and the total input current at the <italic>i<sub>th</sub></italic> brain region, respectively. <italic>ξ<sub>i</sub></italic>(<italic>t</italic>) is uncorrelated standard Gaussian noise and the noise amplitude is controlled by <italic>σ</italic>. The nominal parameter values and the prior range for the target parameters are summarized in <xref rid="tbl6" ref-type="table">Table 6</xref>.</p>
<table-wrap id="tbl6" orientation="portrait" position="float">
<label>Table 6.</label>
<caption><title>Parameter descriptions for capturing whole-brain dynamics using Wong-Wang model.</title></caption>
<graphic xlink:href="633922v1_tbl6.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>According to recent studies [<xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c38">38</xref>], we can parameterize the set of <italic>w</italic>, <italic>I</italic> and <italic>σ</italic> as linear combinations of group-level T1w/T2w myelin maps [<xref ref-type="bibr" rid="c119">119</xref>] and the first principal gradient of functional connectivity:
<disp-formula id="eqn7">
<graphic xlink:href="633922v1_eqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <bold>Mye</bold><italic><sub>i</sub></italic> and <bold>Grad</bold><italic><sub>i</sub></italic> are the average values of the T1w/T2w myelin map and the first FC principal gradient, respectively, within the <italic>i<sub>th</sub></italic> brain region. Therefore, the set of unknown parameters to estimate includes <italic>G</italic> and linear cofficients (<italic>a<sub>w</sub>, b<sub>w</sub>, c<sub>w</sub>, a<sub>I</sub>, b<sub>I</sub>, c<sub>I</sub>, a<sub>σ</sub>, b<sub>σ</sub>, c<sub>σ</sub></italic>) ∈ ℝ<sup>9</sup>, hence 10 parameters in total.</p>
</sec>
<sec id="s2a7">
<label>2.1.7.</label><title>The Balloon-Windkessel model</title>
<p>The Balloon-Windkessel model is a biophysical framework that links neural activity to the BOLD signals detected in fMRI. This is not a neuronal model but rather a representation of neurovascular coupling, describing how neural activity influences hemodynamic responses. The model is characterized by two state variables: venous blood volume (<italic>v</italic>) and deoxyhemoglobin content (<italic>q</italic>). The system’s input is blood flow (<italic>f<sub>in</sub></italic>), and the output is the BOLD signal (<italic>y</italic>):
<disp-formula id="eqn8">
<graphic xlink:href="633922v1_eqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>V</italic><sub>0</sub> represents the resting blood volume fraction, <italic>E</italic><sub>0</sub> is the oxygen extraction fraction at rest, <italic>ɛ</italic> is the ratio of intra- to extravascular signals, <italic>r</italic><sub>0</sub> is the slope of the relationship between the intravascular relaxation rate and oxygen saturation, <italic>ϑ</italic><sub>0</sub> is the frequency offset at the surface of a fully deoxygenated vessel at 1.5T, and <italic>TE</italic> is the echo time. The dynamics of venous blood volume <italic>v</italic> and deoxyhemoglobin content <italic>q</italic> are governed by the Balloon model’s hemodynamic state equations:
<disp-formula id="eqn9">
<graphic xlink:href="633922v1_eqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where τ<sub>0</sub> is the transit time of blood flow, <italic>α</italic> reflects the resistance of the venous vessel (stiffness), and <italic>f</italic>(<italic>t</italic>) denotes blood inflow at time <italic>t</italic>, given by
<disp-formula>
<graphic xlink:href="633922v1_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>s</italic> is an exponentially decaying vasodilatory signal defined by
<disp-formula id="eqn10">
<graphic xlink:href="633922v1_eqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where, ɛ represents the efficacy of neuronal activity <italic>x</italic>(<italic>t</italic>) (i.e., integrated synaptic activity) in generating a signal increase, <italic>τ<sub>s</sub></italic> is the time constant for signal decay, and <italic>τ<sub>f</sub></italic> is the time constant for autoregulatory blood flow feedback [<xref ref-type="bibr" rid="c113">113</xref>]. For parameter values, see <xref rid="tbl7" ref-type="table">Table 7</xref>, taken from [<xref ref-type="bibr" rid="c113">113</xref>, <xref ref-type="bibr" rid="c120">120</xref>, <xref ref-type="bibr" rid="c121">121</xref>]. The resulting time series is downsampled to match the TR value in seconds.</p>
<table-wrap id="tbl7" orientation="portrait" position="float">
<label>Table 7.</label>
<caption><title>Parameter descriptions for the Balloon-Windkessel model to map neural activity to the BOLD signals detected in fMRI.</title></caption>
<graphic xlink:href="633922v1_tbl7.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
</sec>
<sec id="s2b">
<label>2.2.</label><title>Simulation-based inference</title>
<p>In the Bayesian framework [<xref ref-type="bibr" rid="c122">122</xref>], parameter estimation involves quantifying and propagating uncertainty through probability distributions placed on the parameters (prior information before seeing data), which are updated with information provided by the data (likelihood function). The formidable challenge to conducting efficient Bayesian inference is evaluating the likelihood function <italic>p</italic>(<italic>x</italic> | <italic>θ</italic>). This typically involves intractable integrating over all possible trajectories in the latent space: <italic>p</italic>(<italic>x</italic> | <italic>θ</italic>) = <italic>∫ p</italic>(<italic>x, z</italic> | <italic>θ</italic>)<italic>dz</italic>, where <italic>p</italic>(<italic>x, z</italic> | <italic>θ</italic>) is the joint probability density of the data <italic>x</italic> and latent variables <italic>z</italic>, given parameters <italic>θ</italic>. For whole-brain network models with high-dimensional and nonlinear latent spaces, the computational cost can be prohibitive, making likelihood-based inference with MCMC sampling challenging to converge [<xref ref-type="bibr" rid="c76">76</xref>, <xref ref-type="bibr" rid="c67">67</xref>, <xref ref-type="bibr" rid="c123">123</xref>].</p>
<p>Simulation-based inference (SBI; [<xref ref-type="bibr" rid="c70">70</xref>, <xref ref-type="bibr" rid="c71">71</xref>, <xref ref-type="bibr" rid="c68">68</xref>]), or likelihood-free inference [<xref ref-type="bibr" rid="c124">124</xref>, <xref ref-type="bibr" rid="c125">125</xref>, <xref ref-type="bibr" rid="c126">126</xref>], addresses issues with inference on complex systems by using deep networks to learn an invertible transformation between parameters and data, avoiding direct sampling and likelihood evaluation. Given a prior distribution <inline-formula><inline-graphic xlink:href="633922v1_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula>) placed on the parameters <inline-formula><inline-graphic xlink:href="633922v1_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, <italic>N</italic> random simulations are generated (with samples from prior), resulting in pairs <inline-formula><inline-graphic xlink:href="633922v1_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="633922v1_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="633922v1_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the simulated data given <inline-formula><inline-graphic xlink:href="633922v1_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. By training a deep neural density estimator <italic>F</italic> (such as normalizing flows [<xref ref-type="bibr" rid="c79">79</xref>, <xref ref-type="bibr" rid="c80">80</xref>]), we can approximate the posterior <inline-formula><inline-graphic xlink:href="633922v1_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula> with <inline-formula><inline-graphic xlink:href="633922v1_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula> by minimizing the loss function
<disp-formula id="eqn11">
<graphic xlink:href="633922v1_eqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
over network parameters <italic>ϕ</italic>. Once the parameters of the neural network <italic>F</italic> are optimized, for observed data <inline-formula><inline-graphic xlink:href="633922v1_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula> we can readily estimate the target posterior <inline-formula><inline-graphic xlink:href="633922v1_inline14.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. This allows for rapid approximation and sampling from the posterior distribution for any new observed data through a forward pass in the trained network [<xref ref-type="bibr" rid="c68">68</xref>, <xref ref-type="bibr" rid="c69">69</xref>].</p>
<p>This approach uses a class of generative machine learning models known as normalizing flows ([<xref ref-type="bibr" rid="c127">127</xref>, <xref ref-type="bibr" rid="c128">128</xref>]) to transform a simple based distribution into any complex target through a sequence of invertible mappings. Here, generative modeling is an unsupervised machine learning method for modeling a probability distribution given samples drawn from that distribution. The state-of-the-art normalizing flows, such as masked autoregressive flows (MAF; [<xref ref-type="bibr" rid="c79">79</xref>]) and neural spline flows (NSF; [<xref ref-type="bibr" rid="c80">80</xref>]), enable fast and exact density estimation and sampling from high-dimensional distributions. These models learn mappings between input data and probability densities, capturing complex dependencies and multi-modal distributions [<xref ref-type="bibr" rid="c128">128</xref>, <xref ref-type="bibr" rid="c129">129</xref>].</p>
<p>In our work, we integrate the implementation of these models from the open-source SBI tool, leveraging both MAF and NSF architectures. The MAF model comprises 5 flow transforms, each with two blocks and 50 hidden units, tanh nonlinearity and batch normalization after each layer. The NSF model consists of 5 flow transforms, two residual blocks of 50 hidden units each, ReLU nonlinearity, and 10 spline bins. We apply these generative models to virtual brain simulations conducted with random parameters, to approximate the full posterior distribution of parameters from low-dimensional data features. Note that we employ a single round of SBI to benefit from amortization strategy rather than using a sequential approach that is designed to achieve a better fit but only for a specific dataset [<xref ref-type="bibr" rid="c68">68</xref>, <xref ref-type="bibr" rid="c69">69</xref>].</p>
</sec>
<sec id="s2c">
<label>2.3.</label><title>Evaluation of posterior fit</title>
<p>To assess the reliability of Bayesian inference using synthetic data, we evaluate the posterior z-scores (denoted by <italic>z</italic>) against the posterior shrinkage (denoted by <italic>s</italic>), as defined by [<xref ref-type="bibr" rid="c75">75</xref>]:
<disp-formula id="eqn12">
<graphic xlink:href="633922v1_eqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<disp-formula id="eqn13">
<graphic xlink:href="633922v1_eqn13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<p>where <inline-formula><inline-graphic xlink:href="633922v1_inline40.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <italic>θ<sup>∗</sup></italic> are the posterior mean and the true values, respectively, <italic>σ<sub>prior</sub></italic> is the standard deviation of the prior, and <italic>σ<sub>post</sub></italic> is the standard deviation of the posterior. The posterior z-score measures how well the posterior distribution of a parameter captures its true value, while the posterior shrinkage quantifies the contraction of the posterior distribution relative to the prior. A concentration of estimations towards large shrinkages indicates that the posteriors are well-identified, whereas a concentration towards small z-scores signifies that the true values are accurately captured within the posteriors.</p>
</sec>
<sec id="s2d">
<label>2.4.</label><title>Flexible simulator and model building</title>
<p>A key feature of the <monospace>VBI</monospace> pipeline is its modularity and flexibility in integrating various simulators (see <xref rid="fig2" ref-type="fig">Figure 2</xref>). The <italic>Simulation</italic> module of the <monospace>VBI</monospace> pipeline is designed to be easily interchangeable, allowing researchers to replace it with other simulators, such as <monospace>TVB</monospace> [<xref ref-type="bibr" rid="c18">18</xref>] (see <xref rid="figs10" ref-type="fig">Figure S10</xref>), <monospace>Neurolib</monospace> [<xref ref-type="bibr" rid="c130">130</xref>], <monospace>Brian</monospace> [<xref ref-type="bibr" rid="c131">131</xref>], <monospace>Brainpy</monospace> [<xref ref-type="bibr" rid="c132">132</xref>]. This adaptability supports a wide range of simulation needs and computational environments, making the <monospace>VBI</monospace> a versatile tool for inference in system neuroscience. In particular, <italic>Simulation</italic> module offers a comprehensive implementation of commonly used whole-brain models. This is a customized version of implementation from open-source <monospace>TVB</monospace> simulator. While <monospace>VBI</monospace> does not encompass all the features of the original <monospace>TVB</monospace>, it is mainly designed to leverage the computational power of GPU devices and significantly reduce RAM requirements (see <xref rid="figs1" ref-type="fig">Figure S1A</xref>). This optimization ensures that high-performance clusters can be fully utilized, enabling parallel and scalable simulations, as often is required to perform scalable SBI.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Flowchart of the <monospace>VBI</monospace> Structure.</title><p>This toolkit consists of three main modules: (1) The <italic>Simulation</italic> module, implementing various whole-brain models, such as Wilson-Cowan (WCo), Jansen-Rit (JR), Stuart-Landau (SL), Epileptor (EPi), Montbrió (MPR), and Wong-Wang (WW), across different numerical computing libraries (C++, Cupy, PyTorch, Numba). (2) The <italic>Features</italic> module, offering an extensive toolbox for extracting low-dimensional data features, such as spectral, temporal, connectivity, statistical, and information theory features. (3) The <italic>Inference</italic> module, providing neural density estimators (such as MAF and NSF) to approximate the posterior of parameters.</p></caption>
<graphic xlink:href="633922v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2e">
<label>2.5.</label><title>Comprehensive feature extraction</title>
<p><monospace>VBI</monospace> offers a comprehensive toolbox for feature extraction across various datasets. The <italic>Features</italic> module includes but not limited to: (1) <italic>Statistical features</italic>, including mean (average of elements), variance (spread of the elements around mean), kurtosis (tailedness of the distribution of elements), and skewness (the asymmetry of the distribution of elements), that can be applied to any matrix. (2) <italic>Spectral features</italic>, such as low-dimensional summary statistics of power spectrum density (PSD). (3) <italic>Temporal features</italic>, including zero crossings, area under the curve, average power, and envelope. (4) <italic>Connectivity features</italic>, including functional connectivity (FC), which represents the statistical dependencies or correlations between activity patterns of different brain regions, and functional connectivity dynamics (FCD), which captures the temporal variations and transitions in these connectivity patterns over time. These calculations are performed for the whole-brain and/or subnetwork (e.g., limbic system, resting state networks). However, since these matrices are still high-dimensional, we use standard dimensional reduction techniques, such as principal component analysis (PCA) on FC/FCD matrices, to extract their associated low-dimensional summary statistics. (5) <italic>Information theory features</italic>, such as mutual information and transfer entropy.</p>
<p>In this study, we use the term <italic>spatio-temporal data features</italic> to refer to the <italic>statistical features</italic> and <italic>temporal features</italic> derived from time series, while we refer to the <italic>connectivity features</italic> extracted from FC/FCD matrices as <italic>functional data features</italic>.</p>
<p>The <italic>Features</italic> module uses parallel multiprocessing to speed up feature calculation. Additionally, it provides flexibility for users to add their own custom feature calculations with minimal effort and expertise, or to adjust the parameters of existing features based on the type of input time series. The feature extraction module is designed to be interchangeable with existing feature extraction libraries such as <monospace>tsfel</monospace> [<xref ref-type="bibr" rid="c133">133</xref>], <monospace>pyspi</monospace> [<xref ref-type="bibr" rid="c134">134</xref>], <monospace>hctsa</monospace>, [<xref ref-type="bibr" rid="c135">135</xref>], and <monospace>scikit-learn</monospace> [<xref ref-type="bibr" rid="c136">136</xref>]. Note that, some lightweight libraries such as <monospace>catch22</monospace> [<xref ref-type="bibr" rid="c137">137</xref>] are directly accessible from the <monospace>VBI</monospace> feature extraction module.</p>
</sec>
<sec id="s2f">
<label>2.6.</label><title>VBI workflow</title>
<p><xref rid="fig1" ref-type="fig">Figure 1</xref> illustrates an overview of our approach in <monospace>VBI</monospace>, which combines virtual brain models and simulation-based inference to make probabilistic predictions on brain dynamics from neuroimaging recordings. The inputs to the pipeline include the structural imaging data (for building the connectome), functional imaging data such as (s)EEG/MEG, and fMRI as the target for fitting, and prior information as a plausible range over control parameters for generating random simulations. The main computational costs involve model simulations and data feature extraction. The output of the pipeline is the joint posterior distribution of control parameters (such as excitability, synaptic weights, or effective external input) that best explains the observed data. Since the approach is amortized (i.e., it learns across all combinations in the parameter space), it can be readily applied to any new data from a specific subject.</p>
<p>In the first step, non-invasive brain imaging data, such as T1-weighted MRI and Diffusion-weighted MRI (DW-MRI), are collected for a specific subject (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). T1-weighted MRI images are processed to obtain brain parcellation, while DW-MRI images are used for tractography. Using the estimated fiber tracts and the defined brain regions from the parcellation, the connectome (i.e., the complete set of links between brain regions) is constructed by counting the fibers connecting all regions. The SC matrix, with entries representing the connection strength between brain regions, forms the structural component of the virtual brain which constrains the generation of brain dynamics and functional data at arbitrary brain locations (e.g., cortical and subcortical structures).</p>
<p>Subsequently, each brain network node is equipped with a computational model of average neuronal activity, known as neural mass models (see <xref rid="fig1" ref-type="fig">Figure 1B</xref> and <xref rid="s2a" ref-type="sec">subsection 2.1</xref>). They can be represented in the generic form of a dynamical model as <inline-formula><inline-graphic xlink:href="633922v1_inline15.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, with the system variables <inline-formula><inline-graphic xlink:href="633922v1_inline16.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (such as membrane potential and firing rate), the control parameters <inline-formula><inline-graphic xlink:href="633922v1_inline17.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (such as excitability), and the input current <italic>I<sub>input</sub></italic>(such as stimulation). This integration of mathematical mean-field modeling (neural mass models) with anatomical information (connectome) allows us to efficiently analyze functional neuroimaging modalities at the whole-brain level.</p>
<p>To quantify the posterior distribution of control parameters given a set of observations, <inline-formula><inline-graphic xlink:href="633922v1_inline18.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, we first need to define a plausible range for the control parameters based on background knowledge <inline-formula><inline-graphic xlink:href="633922v1_inline19.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, i.e., a simple base distribution known as a prior. We draw random samples from the prior and provide them as input to the <monospace>VBI</monospace> simulator (implemented by <italic>Simulation</italic> module) to generate simulated time series associated with neuroimaging recordings, as shown in <xref rid="fig1" ref-type="fig">Figure 1C</xref>. Subsequently, we extract low-dimensional data features (implemented by <italic>Features</italic> module), as shown in <xref rid="fig1" ref-type="fig">Figure 1D</xref> for FC/FCD/PSD, to prepare the training dataset <inline-formula><inline-graphic xlink:href="633922v1_inline20.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, with a budget of <italic>N<sub>sim</sub></italic> simulations. Then, we use a class of deep neural density estimators, such as MAF or NSF models, as schematically shown in <xref rid="fig1" ref-type="fig">Figure 1E</xref>, to learn all the posterior <inline-formula><inline-graphic xlink:href="633922v1_inline21.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Finally, we can readily sample from <inline-formula><inline-graphic xlink:href="633922v1_inline22.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which determines the probability distribution in parameter space that best explains the observed data. <xref rid="fig2" ref-type="fig">Figure 2</xref> depicts the structure of the <monospace>VBI</monospace> toolkit, which consists of three main modules. The first module, referred to as <italic>Simulation</italic> module, is designed for fast simulation of whole-brain models, such as Wilson-Cowan (<xref rid="s2a1" ref-type="sec">subsubsection 2.1.1</xref>), Jansen-Rit (<xref rid="s2a2" ref-type="sec">subsubsection 2.1.2</xref>), Stuart-Landau (<xref rid="s2a3" ref-type="sec">subsubsection 2.1.3</xref>), Epileptor (subsubsection 2.1.4), Montbrió (<xref rid="s2a5" ref-type="sec">subsubsection 2.1.5</xref>), and Wong-Wang (<xref rid="s2a6" ref-type="sec">subsubsection 2.1.6</xref>). These whole-brain models are implemented across various numerical computing libraries such as Cupy (GPU-accelerated computing with Python), C++ (a high-performance systems programming language), Numba (a just-in-time compiler for accelerating Python code), and PyTorch (an open-source machine learning library for creating deep neural network).</p>
<p>The second module, <italic>Features</italic>, provides a versatile tool for extracting low-dimensional features from simulated time series (see <xref rid="s2e" ref-type="sec">subsection 2.5</xref>). The features include, but are not limited to, <italic>spectral</italic>, <italic>temporal</italic>, <italic>connectivity</italic>, <italic>statistical</italic>, and <italic>information theory</italic> related features, and the associated summary statistics. The third module focuses on <italic>Inference</italic>, i.e., training the deep neural density estimators, such as MAF and NSF (see <xref rid="s2b" ref-type="sec">subsection 2.2</xref>), to learn the joint posterior distribution of control parameters.</p>
</sec>
</sec>
<sec id="s3">
<label>3.</label><title>Results</title>
<p>In the following, we demonstrate the capability of <monospace>VBI</monospace> for inference on the state-of-the-art whole-brain network models using in-silico testing, where the ground truth is known. We apply this approach to simulate neural activity and associated measurements, including (s)EEG/MEG, and fMRI, while also providing diagnostics for the accuracy and reliability of the estimation. Note that for (s)EEG/MEG neuroimaging, we perform inference at the regional level rather than at the sensor level, whereas for fMRI, it is mapped using the Balloon-Windkessel model (see <xref rid="s2a7" ref-type="sec">subsubsection 2.1.7</xref>).</p>
<p>First, we demonstrate the inference on the whole-brain network of Wilson-Cowan model which generates beta oscillations characteristic of Parkinson’s disease [<xref ref-type="bibr" rid="c87">87</xref>, <xref ref-type="bibr" rid="c88">88</xref>]. <xref rid="fig3" ref-type="fig">Figure 3</xref> demonstrates the inference on the synaptic weights in an adapted Wilson-Cowan model (see <xref rid="s2a1" ref-type="sec">subsubsection 2.1.1</xref>). <xref rid="fig3" ref-type="fig">Figure 3A</xref> and <xref rid="fig3" ref-type="fig">B</xref> show the observed and predicted neural activities (e.g., LFP recordings), and the corresponding power spectrum density (PSD) up to 20 Hz, respectively. Here, to estimate the set of unknown parameters <inline-formula><inline-graphic xlink:href="633922v1_inline23.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, we conducted 10k random simulations for training of MAF density estimator. The non-informative prior was placed on all parameters (see <xref rid="tbl1" ref-type="table">Table 1</xref>), and the spatio-temporal features (such as statistical moments of time series) was used for training. <xref rid="fig3" ref-type="fig">Figure 3C</xref> demonstrates an accurate posterior estimation (in red), given the true values (in green). The model training was completed within a few minutes, and sampling from the posterior was nearly instantaneous. <xref rid="fig3" ref-type="fig">Figure 3D</xref> shows the evaluation of the inference by measuring the shrinkage and z-scores of the estimated posterior distributions. This result demonstrates an ideal Bayesian inference and prediction for this class of whole-brain network model. Note that removing the spatio-temporal features of time series and considering only the PSD as the data features leads to larger uncertainty in estimation (see <xref rid="figs2" ref-type="fig">Figure S2</xref>). Nevertheless, the observed and predicted PSD show close agreement.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Bayesian inference on the control parameters of the whole-brain network model of Wilson-Cowan, generating the beta oscillation.</title><p>The inferred parameters are <inline-formula><inline-graphic xlink:href="633922v1_inline31.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where subscripts <italic>S</italic>, <italic>G</italic>, and <italic>C</italic> denote the subthalamic nucleus, globus pallidus, and cortex, respectively. We conducted 10k random simulations for training of MAF density estimator. (<bold>A</bold>) The observed and predicted neural activities. (<bold>B</bold>) The observed and predicted spectral power densities up to 20 Hz. (<bold>C</bold>) The estimated posterior distributions (in red), along with the prior (in blue) and ground-truth values (in green). (<bold>D</bold>) The posterior shrinkage versus z-scores for measuring the accuracy and reliability of the estimates.</p></caption>
<graphic xlink:href="633922v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Then, we demonstrate the inference on heterogeneous control parameters in the whole-brain network of Jansen-Rit (see <xref rid="s2a2" ref-type="sec">subsubsection 2.1.2</xref>), commonly used for modeling EEG/MEG data, e.g., in dementia and Alzheimer’s disease [<xref ref-type="bibr" rid="c138">138</xref>, <xref ref-type="bibr" rid="c139">139</xref>]. <xref rid="fig4" ref-type="fig">Figure 4<bold>A</bold></xref> and <xref rid="fig4" ref-type="fig"><bold>B</bold></xref> show the observed and predicted EEG signals, given by (<italic>y</italic><sub>1</sub><italic><sub>i</sub> − y</italic><sub>2</sub><italic><sub>i</sub></italic>) at each region, while <xref rid="fig4" ref-type="fig">Figure 4C</xref> and <xref rid="fig4" ref-type="fig">D</xref> illustrate the observed and predicted features such as PSD, respectively. <xref rid="fig4" ref-type="fig">Figure 4E</xref> and <xref rid="fig4" ref-type="fig">F</xref> show the estimated posterior distributions of synaptic connections <italic>C<sub>i</sub></italic>, and the global coupling parameter <italic>G</italic>, respectively, given the set of unknown parameters <inline-formula><inline-graphic xlink:href="633922v1_inline24.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Here we conducted 50k random simulations with samples drawn from uniform priors <inline-formula><inline-graphic xlink:href="633922v1_inline24a.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="633922v1_inline24b.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (shown in blue, see <xref rid="tbl2" ref-type="table">Table 2</xref>). After approximately 45 min of training (MAF density estimator), the posterior sampling took only a few seconds. With such a sufficient number of simulations and informative data features, <monospace>VBI</monospace> shows accurate estimation of high-dimensional heterogeneous parameters (given the ground truth, shown in green), leading to a strong correspondence between the observed and predicted PSD of EEG/MEG data. <xref rid="fig4" ref-type="fig">Figure 4G</xref> displays the shrinkage and z-score as the evaluation metrics, indicating an ideal Bayesian estimation for <italic>C<sub>i</sub></italic> parameters, compared to the coupling parameter <italic>G</italic>. This occurred because the network input did not induce a significant change in the intrinsic frequency of activities at regional level, resulting in greater uncertainty in its estimation.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Bayesian inference on heterogeneous control parameters in the whole-brain network of Jansen-Rit model.</title><p>The set of inferred parameters is <inline-formula><inline-graphic xlink:href="633922v1_inline32.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, with the global scaling parameter <italic>G</italic> and average numbers of synapse between neural populations per <italic>C<sub>i</sub></italic> region, given <italic>i</italic> ∈ {1, 2,…, <italic>N<sub>n</sub></italic> = 88} parcelled regions. Summary statistics of power spectrum density (PSD) were used for training, with a budget of 50k simulations. (<bold>A</bold>) and (<bold>B</bold>) illustrate the observed and predicted neural activities, respectively. (<bold>C</bold>) and (<bold>D</bold>) show the observed and predicted data features, such as PSD. (<bold>E</bold>) and (<bold>F</bold>) display the posterior distribution of <italic>C<sub>i</sub></italic> per region, and global coupling <italic>G</italic>, respectively. The ground truth and prior are represented by vertical green lines and a blue distribution, respectively. (<bold>G</bold>) shows the inference evaluation the shrinkage and z-score of the estimated posterior distributions.</p></caption>
<graphic xlink:href="633922v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Note that relying on only alpha-peak while excluding other summary statistics, such as total power (i.e., area under the curve), leads to poor estimation of synaptic connections across brain regions (see <xref rid="figs3" ref-type="fig">Figure S3</xref>). This results in less accurate predictions of the PSD, with more dispersion in their amplitudes. This example demonstrates that <monospace>VBI</monospace> provides a valuable tool for hypothesis evaluation and improved insight into data features by uncertainty quantification, and their impact on predictions.</p>
<p>To demonstrate efficient inference on the whole-brain time delay from EEG/MEG data, we used a whole-brain network model of coupled generic oscillators (StuartLandau model (see <xref rid="s2a3" ref-type="sec">subsubsection 2.1.3</xref>). This model could establish a causal link between empirical spectral changes and the slower conduction velocities observed in multiple sclerosis patients, resulting from immune system attacks on the myelin sheath [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c50">50</xref>]. The parameter set to estimate is <inline-formula><inline-graphic xlink:href="633922v1_inline25.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, consisting of the global scaling parameter <italic>G</italic> and the averaged velocity of signal transmission <italic>V</italic>. The training was performed using a budget of only 2k simulations, which was sufficient due to the low dimensionality of the parameter space. <xref rid="fig5" ref-type="fig">Figure 5A</xref> illustrates the comparison between observed (in green) and predicted neural activities (in red). <xref rid="fig5" ref-type="fig">Figure 5B</xref> shows a close agreement between observed and predicted PSD signals, as the data feature used for training. <xref rid="fig5" ref-type="fig">Figure 5C</xref> and <xref rid="fig5" ref-type="fig">D</xref> provide visualizations of the posterior distributions for the averaged velocity <italic>V</italic> and the global coupling <italic>G</italic>. In these panels, we can see a large shrinkage in the posterior (in red) the uniform prior (in blue) centered around the true values (vertical green lines). Importantly, <xref rid="fig5" ref-type="fig">Figure 5E</xref> presenting the joint posterior distribution, indicates a high correlation of <italic>ρ</italic> = 0.7 between parameters <italic>G</italic> and <italic>V</italic>. This illustrates the advantage of Bayesian estimation in identifying statistical relationships between parameters, which helps to detect degeneracy among them. This is crucial for causal hypothesis evaluation and guiding conclusions in clinical settings. Finally, <xref rid="fig5" ref-type="fig">Figure 5F</xref> illustrates the sensitivity analysis (based on the eigenvalues of the posterior distribution), revealing that the posterior is more sensitive to changes in <italic>V</italic> compared to <italic>G</italic>. This highlights the relative impact of these parameters on the model’s posterior estimates.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Bayesian inference on global scaling parameter <italic>G</italic> and the averaged velocity <italic>V</italic> of signal transmission using the whole-brain network model of Stuart-Landau oscillators.</title><p>The set of estimated parameters is <inline-formula><inline-graphic xlink:href="633922v1_inline33.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and the summary statistics of PSD signals with a budget of 2k simulations were used for training. (<bold>A</bold>) illustrates exemplary observed and predicted neural activities (in green and red, respectively). (<bold>B</bold>) shows the observed and predicted PSD signals (in green and red, respectively). (<bold>C</bold>) and (<bold>D</bold>) display the posterior distribution of averaged velocity <italic>V</italic> and global coupling <italic>G</italic>, respectively. The true values and prior are shown as vertical green lines and a blue distribution, respectively. (<bold>E</bold>) shows the joint posterior distribution indicating a high correlation between posterior samples. (<bold>F</bold>) illustrates the sensitivity analysis based on the eigenvalues of the posterior distribution.</p></caption>
<graphic xlink:href="633922v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Next, we demonstrate the inference on a whole-brain model of epilepsy spread, known as the Virtual Epileptic Patient (VEP; [<xref ref-type="bibr" rid="c47">47</xref>, <xref ref-type="bibr" rid="c76">76</xref>]), used to delineate the epileptogenic and propagation zone networks from the invasive sEEG recordings (<xref rid="s2a4" ref-type="sec">subsubsection 2.1.4</xref>). Here, we used a large value for system time constant <italic>τ</italic> = 90 <italic>ms</italic> (see <xref rid="tbl4" ref-type="table">Table 4</xref>) to generate slow-fast dynamics in pathological areas, corresponding to seizure envelope at each brain region. <xref rid="fig6" ref-type="fig">Figure 6</xref> demonstrates the inference the set of inferred parameters <inline-formula><inline-graphic xlink:href="633922v1_inline26.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, with the global scaling parameter <italic>G</italic> and spatial map of epileptogenicity <italic>η<sub>i</sub></italic>, given <italic>i ∈ {</italic>1, 2<italic>,…, N<sub>n</sub></italic> = 88} parcelled regions. <xref rid="fig6" ref-type="fig">Figure 6A</xref> and <xref rid="fig6" ref-type="fig">B</xref> show the observed and predicted envelope, respectively, at each brain region. Here, the whole brain regions are classified into two epileptogenic zones (in red, corresponding to high excitability), three propagation zones (in yellow, corresponding to excitability close to bifurcation), and the rest as healthy regions (in green, corresponding to low excitability). <xref rid="fig6" ref-type="fig">Figure 6C</xref> and <xref rid="fig6" ref-type="fig">D</xref> illustrate the observed and predicted data features as the total power energy per region, calculated as the area under the curve. Additionally the seizure onset at each region was used as a data feature for training the MAF density estimator. From these panels, we observe accurate recovery of seizure envelopes in pathological regions. <xref rid="fig6" ref-type="fig">Figure 6E</xref> and <xref rid="fig6" ref-type="fig">F</xref> show that the posterior distribution of heterogeneous <italic>η<sub>i</sub></italic>, and global coupling parameter <italic>G</italic>, respectively, indicating 100% accurate recovery of the true values (in green). <xref rid="fig6" ref-type="fig">Figure 6<bold>G</bold></xref> confirms the reliability and accuracy of the estimates through shrinkage and z-score diagnostics. With our efficient implementation, generating 10k whole-brain simulations took less than a minute (using 10 CPU cores). The training took approximately 13 minutes to converge, while posterior sampling required only a few seconds. See <xref rid="figs4" ref-type="fig">Figure S4</xref> for a similar analysis with a faster time separation (<italic>τ</italic> = 10 <italic>ms</italic>). These results demonstrate an ideal and fast Bayesian estimation, despite the stiffness of equations in each region and the high dimensionality of the parameters.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Bayesian inference on the spatial map of epileptogenicity across brain regions in the VEP model.</title><p>The set of inferred parameters is <inline-formula><inline-graphic xlink:href="633922v1_inline34.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, as the global scaling parameter and spatial map of epileptogenicity with <italic>i</italic> ∈ {1, 2,…, <italic>N<sub>n</sub></italic> = 88} parcelled regions. (<bold>A</bold>) The observed seizure envelope generated by the Epileptor model, given two regions as epileptogenic zones (in red) and three regions as propagation zones (in yellow), while the rest are healthy (in green). (<bold>B</bold>) The predicted seizure envelope, by training MAF model on a dataset containing 10k simulations, using only the total power and seizure onset per region as the data features. (<bold>C</bold>) and (<bold>D</bold>) show the observed and predicted data features, respectively. (<bold>E</bold>) and (<bold>F</bold>) show the posterior distributions of heterogeneous control parameters <italic>η<sub>i</sub></italic>, and global coupling parameter <italic>G</italic>, respectively. (<bold>G</bold>) The posterior z-scores versus posterior shrinkages for estimated parameters.</p></caption>
<graphic xlink:href="633922v1_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Targeting the fMRI data, we demonstrate the inference on the whole-brain dynamics using Montbrió model (see <xref rid="s2a5" ref-type="sec">subsubsection 2.1.5</xref>). <xref rid="fig7" ref-type="fig">Figure 7</xref> demonstrates the inference on heterogeneous control parameters of the Montbrió model, operating in a bistable regime (<xref rid="tbl5" ref-type="table">Table 5</xref>). <xref rid="fig7" ref-type="fig">Figure 7A</xref> and <xref rid="fig7" ref-type="fig">B</xref> show the observed and predicted BOLD time series, respectively, while <xref rid="fig7" ref-type="fig">Figure 7C</xref> and <xref rid="fig7" ref-type="fig">D</xref> illustrate the observed and predicted data features, such as the static and dynamical functional connectivity matrices (FC and FCD, respectively). <xref rid="fig7" ref-type="fig">Figure 7E</xref> and <xref rid="fig7" ref-type="fig">F</xref> show the estimated posterior distributions of excitability <italic>η<sub>i</sub></italic> per brain region, and the global coupling parameter <italic>G</italic>. <xref rid="fig7" ref-type="fig">Figure 7G</xref> displays the reliability and accuracy of estimation through the evaluation of posterior shrinkage and z-score (see <xref rid="eqn12" ref-type="disp-formula">Equation 12</xref> and <xref rid="eqn13" ref-type="disp-formula">13</xref>).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Bayesian inference on heterogeneous control parameters in the whole-brain dynamics using Montbrió model.</title><p>The set of inferred parameters is <inline-formula><inline-graphic xlink:href="633922v1_inline35.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, as the global scaling parameter and excitability per region, with i ∈ {1, 2,…, <italic>N<sub>n</sub></italic> = 88} parcelled regions. <monospace>VBI</monospace> provides accurate and reliable posterior estimation using both spatio-temporal and functional data features for training, with a budget of 500k simulations. (<bold>A</bold>) and (<bold>B</bold>) illustrate the observed and predicted BOLD signals, respectively. (<bold>C</bold>) and (<bold>D</bold>) show the observed (upper triangular) and predicted (lower triangular) data features (FC and FCD), respectively. (<bold>E</bold>) and (<bold>F</bold>) display the posterior distribution of excitability parameters <italic>η<sub>i</sub></italic> per region, and global coupling <italic>G</italic>, respectively. The true values and prior are shown as vertical green lines and a blue distribution, respectively. (<bold>G</bold>) shows the inference evaluation by the shrinkage and z-score of the posterior distributions.</p></caption>
<graphic xlink:href="633922v1_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Due to the large number of simulations for training and the informativeness of the data features (both spatio-temporal and functional data features), the results indicate that we achieved accurate parameter estimation, consequently, a close agreement between the observed and predicted features of BOLD data. This required 500k simulations for training (see <xref rid="figs6" ref-type="fig">Figure S6</xref>), given the uniform priors <inline-formula><inline-graphic xlink:href="633922v1_inline27.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="633922v1_inline28.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. After approximately 10 <italic>h</italic> of training (of MAF density estimator), posterior sampling took only 1 min. Our results indicate that training the MAF model was 2 to 4 times faster than the NSF model (see <xref rid="figs1" ref-type="fig">Figure S1B</xref>). Note that removing the spatio-temporal features and considering only FC/FCD as the data features (see <xref rid="figs7" ref-type="fig">Figure S7</xref>) leads to poor estimation of the excitability parameter across brain regions (see <xref rid="figs5" ref-type="fig">Figure S5</xref>). Interestingly, accurate estimation of the only global coupling parameter, <inline-formula><inline-graphic xlink:href="633922v1_inline29.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, from only FC/FCD requires around 100 simulations (see <xref rid="figs8" ref-type="fig">Figure S8</xref>). This showcase demonstrates the capability of <monospace>VBI</monospace> in inferring heterogeneous excitability, given the bistable brain dynamics, for fMRI studies.</p>
<p>Finally, in <xref rid="fig8" ref-type="fig">Figure 8</xref>, we show the inference on the so-called pDMF model, i.e., a whole-brain netwrok model of the reduced Wong-Wang equation (see subsubsection 2.1.6), comprising 10 control parameters: the global scaling of connections <italic>G</italic> and the linear coefficients (<italic>a<sub>w</sub>, b<sub>w</sub>, c<sub>w</sub>, a<sub>I</sub>, b<sub>I</sub>, c<sub>I</sub>, a<sub>σ</sub>, b<sub>σ</sub>, c<sub>σ</sub></italic>) ∈ ℝ<sup>9</sup>. These parameters are introduced to reduce the dimension of whole-brain parameters as recurrent connection strength <italic>w<sub>i</sub></italic>, external input current <italic>I<sub>i</sub></italic>, and noise amplitude <italic>σ<sub>i</sub></italic> for each region (in total, 264 parameters were reduced to 9 dimensions; see <xref rid="eqn7" ref-type="disp-formula">Equation 7</xref>). Here, we used summary statistics of both spatio-temporal and functional data features extracted from simulated BOLD data to train the MAF density estimator, with a budget of 50k simulations. The training took around 160 min to converge, whereas posterior sampling took only a few seconds.</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Bayesian inference on the parametric mean-field model of Wong-Wang (pDMF model), with linear coefficients (<italic>a<sub>w</sub></italic>, <italic>b<sub>w</sub></italic>, <italic>c<sub>w</sub></italic>, <italic>a<sub>I</sub></italic>, <italic>b<sub>I</sub></italic>, <italic>c<sub>I</sub></italic>, <italic>a<sub>σ</sub></italic>, <italic>b<sub>σ</sub></italic>, <italic>c<sub>σ</sub></italic>) ∈ ℝ<sup>9</sup>, reparameterizing the recurrent connection strength <italic>w<sub>i</sub></italic>, external input current <italic>I<sub>i</sub></italic>, and noise amplitude <italic>σ<sub>i</sub></italic> for each region.</title><p>Summary statistics of spatio-temporal and functional data features were used for training, with a budget of 50k simulations. (<bold>A</bold>) The diagonal panels display the ground-true values (in green), the uniform prior (in blue), and the estimated posterior distributions (in red). The upper diagonal panels illustrate the joint posterior distributions between parameters, along with their correlation (<italic>ρ</italic>, in the upper left corners), and ground-truth values (green stars). High-probability areas are color-coded in yellow, while low-probability areas are shown in black. (<bold>B</bold>) The observed and predicted BOLD time series (in green and red, respectively). (<bold>C</bold>) The observed and predicted data features, such as FC/FCD matrices. (<bold>D</bold>) The inference evaluation by calculating the shrinkage and z-score of the estimated posterior distributions.</p></caption>
<graphic xlink:href="633922v1_fig8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The diagonal panels in <xref rid="fig8" ref-type="fig">Figure 8A</xref> show estimated posterior distributions (in red), along with the prior (in blue) and true values (in green). The upper diagonal panels illustrate the joint posterior distributions between parameters (i.e., statistical dependency between parameters). <xref rid="fig8" ref-type="fig">Figure 8B</xref> illustrates the observed and predicted BOLD time series, generated by true and estimated parameters (in blue and red, respectively). From <xref rid="fig8" ref-type="fig">Figure 8C</xref>, we can see a close agreement between the observed and predicted data features (FC/FCD matrices). Note that due to the stochastic nature of the generative process, we do not expect an exact element-wise correspondence between these features, but rather a match in their summary statistics, such as the mean, variance, and higher-order moments (see <xref rid="figs9" ref-type="fig">Figure S9</xref>). <xref rid="fig8" ref-type="fig">Figure 8D</xref> shows the posterior z-score versus shrinkage, indicating less accurate estimation for the coefficients <italic>c<sub>w</sub></italic>, <italic>c<sub>I</sub></italic>, and <italic>c<sub>σ</sub></italic> compared to others, as they are not informed by anatomical data such as the T1w/T2w myelin map and the first FC principal gradient (see <xref rid="eqn7" ref-type="disp-formula">Equation 7</xref>). This showcase demonstrates the advantage of Bayesian inference over optimization in assessing the accuracy and reliability of parameter estimation, whether informed by anatomical data.</p>
<p>Note that in the whole-brain network of Wong-Wang model (6), the global scaling parameter <italic>G</italic> and synaptic coupling <italic>J</italic> exhibit structural non-identifiability, meaning their combined effects on the system cannot be uniquely disentangled. This is evident in the parameter estimations corresponding to selected observations, where the posterior distributions appear diffuse. The joint posterior plots reveal a nonlinear dependency (banana shape) between <italic>G</italic> and <italic>J</italic>, arising from their product in the neural mass equation (see <xref rid="eqn6" ref-type="disp-formula">Equation 6</xref>). Such a nonlinear relationship between parameters poses challenges for deriving causal conclusions, as often occurs in other neural mass models. This is a demonstration of how Bayesian inference facilitates causal hypothesis testing without requiring additional non-identifiability analysis.</p>
</sec>
<sec id="s4">
<label>4.</label><title>Discussion</title>
<p>This study introduces the Virtual Brain Inference (<monospace>VBI</monospace>), a flexible and integrative toolkit designed to facilitate probabilistic inference on complex whole-brain dynamics using connectome-based models (forward problem) and simulation-based inference (inverse problem). The toolkit leverages high-performance programming languages (C++) and dynamic compilers (such as Python’s JIT compiler), alongside the computational power of parallel processors (GPUs), to significantly enhance the speed and efficiency of simulations. Additionally, <monospace>VBI</monospace> integrates popular feature extraction libraries with parallel multiprocessing to efficiently convert simulated time series into low-dimensional summary statistics. Moreover, <monospace>VBI</monospace> incorporates state-of-the-art deep neural density estimators (such as MAF and NSF generative models) to estimate the posterior density of control parameters within whole-brain models given low-dimensional data features. Our results demonstrated the versatility and efficacy of the <monospace>VBI</monospace> toolkit across commonly used whole-brain network models, such as Wilson-Cowan, Jansen-Rit, Stuart-Landau, Epileptor, Montbrió, and Wong-Wang equations placed at each region. The ability to perform parallel and rapid simulations, coupled with a taxonomy of feature extraction, allows for detailed and accurate parameter estimation from associated neuroimaging modalities such as (s)EEG/MEG/fMRI. This is crucial for advancing our understanding of brain dynamics and the underlying mechanisms of various brain disorders. Overall, <monospace>VBI</monospace> represents a substantial improvement over alternative methods, offering a robust framework for both simulation and parameter estimation, and contributing to the advancement of network neuroscience, potentially, to precision medicine.</p>
<p>The alternatives for parameter estimation include optimization techniques [<xref ref-type="bibr" rid="c66">66</xref>, <xref ref-type="bibr" rid="c34">34</xref>, <xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c63">63</xref>, <xref ref-type="bibr" rid="c64">64</xref>], ABC method, and MCMC sampling. Optimization techniques are sensitive to the choice of the objective function (e.g., minimizing distance error or maximizing correlation) and do not provide estimates of uncertainty. Although multiple runs and thresholding can be used to address these issues, such methods often fall short in revealing relationships between parameters, such as identifying degeneracy, which is crucial for reliable causal inference. Alternatively, a technique known as ABC compares observed and simulated data using a distance measure based on summary statistics [<xref ref-type="bibr" rid="c140">140</xref>, <xref ref-type="bibr" rid="c141">141</xref>, <xref ref-type="bibr" rid="c142">142</xref>]. It is known that, ABC methods suffer from the curse of dimensionality, and their performance also depends critically on the tolerance level in the accepted/rejected setting [<xref ref-type="bibr" rid="c71">71</xref>, <xref ref-type="bibr" rid="c70">70</xref>]. The self-tuning variants of MCMC sampling have also been used for model inversion at the whole-brain level [<xref ref-type="bibr" rid="c76">76</xref>, <xref ref-type="bibr" rid="c67">67</xref>]. Although MCMC is unbiased and exact with infinite runs, it can be computationally prohibitive, and sophisticated reparameterization methods are often required to facilitate convergence at whole-brain level [<xref ref-type="bibr" rid="c123">123</xref>, <xref ref-type="bibr" rid="c143">143</xref>]. This becomes more challenging for gradient-based MCMC algorithms, due to the bistability and stiffness of neural mass models. Tailored to Bayes’ rule, SBI sidesteps these issues by relying on expressive deep neural density estimators (such as MAF and NSF) on low-dimensional data features to efficiently approximate the posterior distribution of model parameters. Taking spiking neurons as generative models, this approach has demonstrated superior performance compared to alternative methods, as it does not require model or data features to be differentiable [<xref ref-type="bibr" rid="c71">71</xref>, <xref ref-type="bibr" rid="c81">81</xref>].</p>
<p>In previous studies, we demonstrated the effectiveness of SBI on virtual brain models of neurological [<xref ref-type="bibr" rid="c68">68</xref>, <xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c50">50</xref>, <xref ref-type="bibr" rid="c54">54</xref>], and neurodegenerative diseases [<xref ref-type="bibr" rid="c69">69</xref>, <xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c23">23</xref>] as well as focal intervention [<xref ref-type="bibr" rid="c59">59</xref>] and healthy aging [<xref ref-type="bibr" rid="c37">37</xref>]. In this work, we extended this probabilistic methodology to encompass a broader range of whole-brain network models, highlighting its flexibility and scalability in leveraging diverse computational resources, from CPUs/GPUs to high-performance computing facilities. Our results indicated that the <monospace>VBI</monospace> toolkit effectively estimates posterior distributions of control parameters in whole-brain network modeling, offering a deeper understanding of the mechanisms underlying brain activity. For example, using the Montbrio and Wong-Wang models, we achieved a close match between observed and predicted FC/FCD matrices derived from BOLD time series (<xref rid="fig7" ref-type="fig">Figure 7</xref> and <xref rid="fig8" ref-type="fig">Figure 8</xref>). Additionally, the Jansen-Rit and Stuart-Landau models provided accurate inferences of PSD from neural activity (<xref rid="fig4" ref-type="fig">Figure 4</xref>, and <xref rid="fig5" ref-type="fig">Figure 5</xref>), while the Epileptor model precisely captured the spread of of seizure envelopes (<xref rid="fig6" ref-type="fig">Figure 6</xref>). These results underscore the toolkit’s capability to manage complex, high-dimensional data with precision. Uncertainty quantification using <monospace>VBI</monospace> can illuminate and combine the informativeness of data features (e.g., FC/FCD) and reveal the causal drivers behind interventions [<xref ref-type="bibr" rid="c69">69</xref>, <xref ref-type="bibr" rid="c59">59</xref>]. This adaptability ensures that <monospace>VBI</monospace> can be applied across various neuroimaging modalities, accommodating different computational capabilities and research needs.</p>
<p>Since data features are key in SBI, some factors can lead to the collapse of this method. For instance, high noise levels in observations or dynamical noise can compromise the accurate calculation of data features, undermining the inference process. Identifying the set of low-dimensional data features that are relevant to the control parameters for each case study is another challenge in effectively applying SBI. Nevertheless, the uncertainty of the posterior informs us about the predictive power of these features. Statistical moments of time series could be effective candidates for most models. However, this poses a formidable challenge for inference from empirical data, as certain moments, such as the mean and variance, may be lost during preprocessing steps. The hyperparameter and noise estimation can also be challenging for SBI. Moreover, there is no established rule for determining the number of simulations for training, aside from relying on z-score values during in-silico testing, as it depends on available computational resources.</p>
<p>Various sequential methods, such as SNPE [<xref ref-type="bibr" rid="c125">125</xref>], SNLE [<xref ref-type="bibr" rid="c144">144</xref>], and SNRE [<xref ref-type="bibr" rid="c145">145</xref>], have been proposed to reduce computational costs of SBI by iteratively refining the fit to specific targets. These approaches aim for more precise parameter estimation by progressively adjusting the model based on each new data set or subset, potentially enhancing the accuracy of the fit at the reduced computational effort. The choice of method depends on the specific characteristics and requirements of the problem being addressed [<xref ref-type="bibr" rid="c146">146</xref>]. Our previous study indicates that for inferring whole-brain dynamics of epilepsy spread, the SNPE method outperforms alternative approaches [<xref ref-type="bibr" rid="c68">68</xref>]. Nevertheless, sequential methods can become unstable, with simulators potentially diverging and causing probability mass to leak into regions that lack prior support [<xref ref-type="bibr" rid="c68">68</xref>]. In this study, we used single-round training to benefit from an amortization strategy. This approach brings the costs of simulation and network training upfront, enabling inference on new data to be performed rapidly (within seconds). This strategy facilitates personalized inference at the subject level, as the generative model is tailored by the SC matrix, thereby allowing for rapid hypothesis evaluation specific to each subject (e.g., in delineating the epileptogenic and propagation zones). Note that model comparison across different configurations or model structures, as well-established in dynamic causal modeling [<xref ref-type="bibr" rid="c147">147</xref>, <xref ref-type="bibr" rid="c148">148</xref>], has yet to be explored in this context.</p>
<p>Deep learning algorithms are increasingly gaining traction in the context of whole-brain modeling. The <monospace>VBI</monospace> toolkit leverages a class of deep generative models, called Normalizing Flows (NFs; [<xref ref-type="bibr" rid="c127">127</xref>, <xref ref-type="bibr" rid="c128">128</xref>]), to model probability distributions given samples drawn from those distributions. Using NFs, a base probability distribution (e.g., a standard normal) is transformed into any complex distribution (potentially multi-modal) through a sequence of invertible transformations. Variational autoencoders (VAEs; [<xref ref-type="bibr" rid="c149">149</xref>, <xref ref-type="bibr" rid="c150">150</xref>]) is a class of deep generative models to encode data into a latent space and then decode it back to reconstruct the original data. Recently, Sip et al. [<xref ref-type="bibr" rid="c151">151</xref>] introduced a method using VAEs for nonlinear dynamical system identification, enabling the inference of neural mass models and region- and subject-specific parameters from functional data. VAEs have also been employed for dimensionality reduction of whole-brain functional connectivity [<xref ref-type="bibr" rid="c42">42</xref>], and to investigate various pathologies and their severity by analyzing the evolution of trajectories within a low-dimensional latent space [<xref ref-type="bibr" rid="c52">52</xref>]. Additionally, Generative Adversarial Networks (GANs; [<xref ref-type="bibr" rid="c152">152</xref>, <xref ref-type="bibr" rid="c153">153</xref>]) have demonstrated remarkable success in mapping latent space to data space by learning a manifold induced from a base density [<xref ref-type="bibr" rid="c154">154</xref>]. This method merits further exploration within the context of whole-brain dynamics. To fully harness the potential of deep generative models in large-scale brain network modeling, integrating VAEs and GANs into the <monospace>VBI</monospace> framework would be beneficial. This will elucidate their strengths and limitations within this context and guide future advancements in the field.</p>
<p>In summary, <monospace>VBI</monospace> offers fast simulations, taxonomy of feature extraction, and deep generative models, making it a versatile tool for model-based inference from different neuroimaging modalities, helping researchers to explore brain (dys)functioning in greater depth. This advancement not only enhances our theoretical understanding but also holds promise for practical applications in diagnosing and treating neurological conditions.</p>
</sec>
</body>
<back>
<sec id="s6">
<title>Information Sharing Statement</title>
<p>All code is available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/ins-amu/vbi">https://github.com/ins-amu/vbi</ext-link>).</p>
</sec>
<sec id="s5">
<title>Glossary of technical terms</title>
<p><bold>Bayesian Rule</bold>: A fundamental belief updating principle that calculates the probability of a hypothesis given new evidence.</p>
<p><bold>Deep neural density estimators</bold>: A class of artificial neural network-based approaches that are used to learn and approximate the underlying probability distribution from a given dataset.</p>
<p><bold>Control (generative) parameters</bold>: The bifurcation parameters, setting, or configuration within a generative model that controls the synthesis of data and potentially represents causal relationships.</p>
<p><bold>Generative model</bold>: A statistical, machine learning, or mechanistic model that represents the underlying data distribution to generate new data resembling the original dataset.</p>
<p><bold>Likelihood</bold>: The conditional probability of observing the evidence given a particular hypothesis.</p>
<p><bold>Markov chain Monte Carlo</bold>: A family of stochastic algorithms used for uncertainty quantification by drawing random samples from probability distributions, in which the sampling process does not require knowledge of the entire distribution.</p>
<p><bold>Prior</bold>: The initial probability assigned to a hypothesis before considering new evidence.</p>
<p><bold>Probability distribution</bold>: The statistical description of potential outcomes of random events, where a numerical measure is assigned to the possibility of each specific outcome.</p>
<p><bold>Probability density estimation</bold>: The process of inferring the underlying probability distribution of a random event based on observed data.</p>
<p><bold>Posterior</bold>: The updated probability of a hypothesis after taking into account both prior beliefs and observed evidence.</p>
<p><bold>Simulation-based inference</bold>: A machine learning approach that involves generating synthetic data through forward simulations to make inferences about complex systems, often when analytic or computational solutions are unavailable.</p>
<p><bold>Whole-brain or virtual brain models</bold>: Computational models informed by personalized anatomical data, i.e., a set of equations describing regional brain dynamics placed at each node, which are then connected through structural connectivity matrix.</p>
</sec>
<sec id="s8">
<label>6.</label><title>Supplementary figures</title>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Figure S1.</label>
<caption><p>(<bold>A</bold>) Benchmarking the simulation cost of the whole-brain network of Montbrió model, with 2.5M time step on Intel(R) Core(TM) i9-10900 CPU 2.80 GHz (in red) and NVIDIA RTX A5000 GPU (in blue). GPUs deliver substantial speedups up to 100x over multi-core CPUs. (<bold>B</bold>) Comparing MAF and NSF density estimators, MAF is typically 2-4 times faster than NSF during the training process.</p></caption>
<graphic xlink:href="633922v1_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Figure S2.</label>
<caption><title>Inference on generative parameters in the Wilson-Cowan model (<xref rid="eqn1" ref-type="disp-formula">Equation 1</xref>) of beta oscillation.</title><p>The set of inferred parameters is <italic>θ</italic> = <italic>w<sub>SG</sub></italic>, <italic>w<sub>GS</sub></italic>, <italic>w<sub>CS</sub></italic>, <italic>w<sub>SC</sub></italic>, <italic>w<sub>GG</sub></italic>, <italic>w<sub>CC</sub></italic> ∈ ℛ<sup>6</sup>. (<bold>A</bold>) The diagonal panels show the estimated posterior distributions (in red), true values (in green), and the uniform prior (in blue). The upper diagonal panels depict the joint posterior distributions between parameters, including their correlations (<italic>ρ</italic>, in the upper left corners), with true values marked by green stars. High-probability areas are color-coded in yellow, while low-probability areas are shown in black. Panels (<bold>B</bold>), (<bold>C</bold>) display the observed and predicted activity timeseries, respectively. Panels (<bold>D</bold>), (<bold>E</bold>) show the observed and predicted PSD, respectively, used as data features for training. (<bold>F</bold>) Evaluates the inference by presenting the shrinkage and z-scores of the estimated posterior distributions.</p></caption>
<graphic xlink:href="633922v1_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Figure S3.</label>
<caption><title>Inference on heterogeneous generative parameters in the whole-brain network of Jansen-Rit model (<xref rid="eqn2" ref-type="disp-formula">Equation 2</xref>).</title><p>The set of inferred parameters is <inline-formula><inline-graphic xlink:href="633922v1_inline36.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, consisting of the global scaling parameter <italic>G</italic> and the average number of synapses between neural populations <italic>C<sub>i</sub></italic> per region, with <italic>i</italic> ∈ {1, 2,…, <italic>N<sub>n</sub></italic> = 88} parcelled regions. For panels <bold>A</bold> to <bold>C</bold>, only the area under the curve of the power spectral density (PSD) in the [0,30] Hz band was used, while for panels <bold>D</bold> to <bold>F</bold>, additional statistical features of the PSD were included in the training, with a total budget of 50k simulations. (<bold>A</bold>) and (<bold>D</bold>) illustrate the observed and predicted EEG signals. (<bold>B</bold>) and (<bold>E</bold>) show the observed and predicted PSD signals. (<bold>C</bold>) and (<bold>F</bold>) display the posterior distribution of <italic>C<sub>i</sub></italic> for each region. The true values are indicated by vertical green lines, and the prior distribution is shown in blue.</p></caption>
<graphic xlink:href="633922v1_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Figure S4.</label>
<caption><title>Bayesian inference on the spatial map of epileptogenicity across brain regions in the VEP model (<xref rid="eqn4" ref-type="disp-formula">Equation 4</xref>), with slow time scale seperation, <italic>τ</italic> = 10 <italic>ms</italic>.</title><p>(<bold>A</bold>) The observed seizure envelope generated by the 2D Epileptor model given two regions as epileptogenic zones (in red) and three regions as propagation zones (in yellow), while the rest are healthy (in green). (<bold>B</bold>) The predicted seizure envelope, by training MAF density estimator on a dataset containing 10k simulations, using only the total power per region as the data features. (<bold>C</bold>) and (<bold>D</bold>) show the observed and predicted data features, respectively. (<bold>E</bold>) and (<bold>F</bold>) show the posterior distribution of heterogeneous <italic>η<sub>i</sub></italic>, and global coupling parameter <italic>G</italic>, respectively. (<bold>F</bold>) The posterior z-scores versus posterior shrinkages for estimated parameters.</p></caption>
<graphic xlink:href="633922v1_figs4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>Figure S5.</label>
<caption><title>Inference on heterogeneous generative parameters in the whole-brain network of Montbrió model (<xref rid="eqn5" ref-type="disp-formula">Equation 5</xref>) involves estimating a parameter set denoted as <inline-formula><inline-graphic xlink:href="633922v1_inline37.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</title><p>Here, <italic>G</italic> is the global scaling parameter, and <italic>η<sub>i</sub></italic> represents the excitability of each brain region, where <italic>i</italic> ∈ {1, 2,…, <italic>N<sub>n</sub></italic> = 88} corresponds to the parcelled regions. Relying on only functional data features (FC/FCD) for training proves insufficient to accurately estimate the posterior distribution of heterogeneous excitabilities, even with a budget of 500k simulations. In (<bold>A</bold>), the posterior estimates are shown in red, the true values of <italic>η<sub>i</sub></italic> in green, and the prior distribution in blue. Panels (<bold>B</bold>) and (<bold>C</bold>) show the observed and predicted FC/FCD matrices, respectively. The simulation to generate training data took approximately 24 hours, utilizing 10 GPUs concurrently. The training process lasted around 8 hours, while sampling required just a few seconds.</p></caption>
<graphic xlink:href="633922v1_figs5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs6" position="float" orientation="portrait" fig-type="figure">
<label>Figure S6.</label>
<caption><p>Evaluating the reliability and accuracy of estimation (parameter <italic>G</italic>) with respect to the number of simulation used for training the MAF/NSF density estimator by (<bold>A</bold>) posterior shrinkage, and (<bold>B</bold>) z-score versus the number of simulations.</p></caption>
<graphic xlink:href="633922v1_figs6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs7" position="float" orientation="portrait" fig-type="figure">
<label>Figure S7.</label>
<caption><p>Exemplary summary statistics from the FC/FCD matrices in the whole-brain network of Montbrió model (<xref rid="eqn5" ref-type="disp-formula">Equation 5</xref>).</p></caption>
<graphic xlink:href="633922v1_figs7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs8" position="float" orientation="portrait" fig-type="figure">
<label>Figure S8.</label>
<caption><title>Inference of the global coupling parameter <inline-formula><inline-graphic xlink:href="633922v1_inline38.gif" mime-subtype="gif" mimetype="image"/></inline-formula> in the whole-brain network of Montbrió model (<xref rid="eqn5" ref-type="disp-formula">Equation 5</xref>) using functional data features, using a budget of only 100 simulations.</title><p>(<bold>A</bold>) The uniform prior distribution of <italic>G</italic> in blue, the estimated posterior in red and the true value is shown in green. (<bold>B</bold>) and (<bold>C</bold>) The observed and predicted FC/FCD matrices, respectively.</p></caption>
<graphic xlink:href="633922v1_figs8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs9" position="float" orientation="portrait" fig-type="figure">
<label>Figure S9.</label>
<caption><title>The distribution of observed and predicted functional connectivity (FC) in panel and the functional connectivity dynamics in panel (<bold>B</bold>), which are demonstrated in <xref rid="fig8" ref-type="fig">Figure 8</xref>.</title></caption>
<graphic xlink:href="633922v1_figs9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs10" position="float" orientation="portrait" fig-type="figure">
<label>Figure S10.</label>
<caption><title>Inference of the global coupling parameter <inline-formula><inline-graphic xlink:href="633922v1_inline39.gif" mime-subtype="gif" mimetype="image"/></inline-formula> in the whole-brain model of Montbrió (<xref rid="eqn5" ref-type="disp-formula">Equation 5</xref>) using TVB simulator, using summation of FC and FCD matrix elements as low dimensional data features, constrained by a budget of only 100 simulations.</title><p>(<bold>A</bold>) The uniform prior distribution of <italic>G</italic> in blue, the estimated posterior in red and the true value is shown in green. (<bold>B</bold>) and (<bold>C</bold>) show the observed and predicted FC/FCD matrices, respectively.</p></caption>
<graphic xlink:href="633922v1_figs10.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs11" position="float" orientation="portrait" fig-type="figure">
<label>Figure S11.</label>
<caption><title>The non-identifiability in estimating <italic>G</italic> and <italic>J</italic> in the Wong-Wang model (<xref rid="eqn6" ref-type="disp-formula">Equation 6</xref>).</title><p>A total of 16k simulations and functional data features (see <xref rid="figs11" ref-type="fig">Figure S11</xref>) were used for training. The upper row illustrates the FCD variance and the sum of FC matrices plotted against the parameters <italic>G</italic> and <italic>J</italic>, respectively, for three selected observations marked by red circles. The lower panels display the parameter estimations corresponding to the selected observations. Due to structural non-identifiability in the product of <italic>G</italic> and <italic>J</italic>, the posterior distributions appear diffuse, showing a nonlinear dependency (banana shape) in the joint posterior plots.</p></caption>
<graphic xlink:href="633922v1_figs11.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs12" position="float" orientation="portrait" fig-type="figure">
<label>Figure S12.</label>
<caption><title>Exemplary summary statistics from the FC/FCD matrices in the whole-brain network of Wong-Wang model (<xref rid="eqn6" ref-type="disp-formula">Equation 6</xref>).</title></caption>
<graphic xlink:href="633922v1_figs12.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<ack>
<title>Acknowledgements</title>
<p>This research has received funding from EU’s Horizon 2020 Framework Programme for Research and Innovation under the Specific Grant Agreements No. 101147319 (EBRAINS 2.0 Project), No. 101137289 (Virtual Brain Twin Project), No. 101057429 (project environMENTAL), and government grant managed by the Agence Nationale de la Recherche reference ANR-22-PESN-0012 (France 2030 program). We acknowledge the use of Fenix Infrastructure resources, which are partially funded from the European Union’s Horizon 2020 research and innovation programme through the ICEI project under the grant agreement No. 800858. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
</ack>
<sec id="d1e3027" sec-type="additional-information">
<title>Additional information</title>
<sec id="s7">
<title>Author contributions</title>
<p>Conceptualization: V.J., and M.H. Methodology: A.Z., M.W., L.D., and M.H. Software: A.Z, M.W., L.D., and M.H. Investigation: A.Z. Visualization: A.Z., Supervision: V.J., S.P., and M.H. Funding acquisition: V.J., M.H. Writing - original draft: A.Z., and M.H. Writing - review &amp; editing: A.Z, M.W., L.D., S.P., V.J, and M.H.</p>
</sec>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>VBI</term><def><p>virtual brain inference</p></def></def-item>
<def-item><term>BOLD</term><def><p>blood-oxygen-level-dependent</p></def></def-item>
<def-item><term>fMRI</term><def><p>functional magnetic resonance imaging</p></def></def-item>
<def-item><term>EEG</term><def><p>Electroencephalography</p></def></def-item>
<def-item><term>MEG</term><def><p>Magnetoencephalography</p></def></def-item>
<def-item><term>sEEG</term><def><p>Stereoelectroencephalography</p></def></def-item>
<def-item><term>SC</term><def><p>structural connectivity</p></def></def-item>
<def-item><term>FC</term><def><p>functional connectivity</p></def></def-item>
<def-item><term>FCD</term><def><p>functional connectivity dynamic</p></def></def-item>
<def-item><term>PSD</term><def><p>power spectral density</p></def></def-item>
<def-item><term>SBI</term><def><p>simulation-based inference</p></def></def-item>
<def-item><term>MAF</term><def><p>masked autoregressive flow</p></def></def-item>
<def-item><term>NSF</term><def><p>neural spline flow</p></def></def-item>
<def-item><term>MCMC</term><def><p>Markov chain Monte Carlo</p></def></def-item>
</def-list>
</glossary>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Maria I</given-names> <surname>Falcon</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name>, and <string-name><given-names>Ana</given-names> <surname>Solodkin</surname></string-name></person-group>. <article-title>A new neuroinformatics approach to personalized medicine in neurology: The virtual brain</article-title>. <source>Current opinion in neurology</source>, <volume>29</volume>(<issue>4</issue>):<fpage>429</fpage>–<lpage>436</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Lin</given-names> <surname>Tan</surname></string-name>, <string-name><given-names>Teng</given-names> <surname>Jiang</surname></string-name>, <string-name><given-names>Lan</given-names> <surname>Tan</surname></string-name>, and <string-name><given-names>Jin-Tai</given-names> <surname>Yu</surname></string-name></person-group>. <article-title>Toward precision medicine in neurological diseases</article-title>. <source>Annals of translational medicine</source>, <volume>4</volume>(<issue>6</issue>), <year>2016</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jacob W</given-names> <surname>Vogel</surname></string-name>, <string-name><given-names>Nick</given-names> <surname>Corriveau-Lecavalier</surname></string-name>, <string-name><given-names>Nicolai</given-names> <surname>Franzmeier</surname></string-name>, <string-name><given-names>Joana B</given-names> <surname>Pereira</surname></string-name>, <string-name><given-names>Jesse A</given-names> <surname>Brown</surname></string-name>, <string-name><given-names>Anne</given-names> <surname>Maass</surname></string-name>, <string-name><given-names>Hugo</given-names> <surname>Botha</surname></string-name>, <string-name><given-names>William W</given-names> <surname>Seeley</surname></string-name>, <string-name><given-names>Dani S</given-names> <surname>Bassett</surname></string-name>, <string-name><given-names>David T</given-names> <surname>Jones</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Connectome-based modelling of neurodegenerative diseases: towards precision medicine and mechanistic insight</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>24</volume>(<issue>10</issue>):<fpage>620</fpage>–<lpage>639</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Leanne M</given-names> <surname>Williams</surname></string-name> and <string-name><given-names>Susan Whitfield</given-names> <surname>Gabrieli</surname></string-name></person-group>. <article-title>Neuroimaging for precision medicine in psychiatry</article-title>. <source>Neuropsychopharmacology, pages</source> <fpage>1</fpage>–<lpage>12</lpage>, <year>2024</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Michael</given-names> <surname>Breakspear</surname></string-name></person-group>. <article-title>Dynamic models of large-scale brain activity</article-title>. <source>Nature neuroscience</source>, <volume>20</volume>(<issue>3</issue>):<fpage>340</fpage>–<lpage>352</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Huifang E</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Marmaduke</given-names> <surname>Woodman</surname></string-name>, <string-name><given-names>Paul</given-names> <surname>Triebkorn</surname></string-name>, <string-name><given-names>Jean-Didier</given-names> <surname>Lemarechal</surname></string-name>, <string-name><given-names>Jayant</given-names> <surname>Jha</surname></string-name>, <string-name><given-names>Borana</given-names> <surname>Dollomaja</surname></string-name>, <string-name><given-names>Anirudh Nihalani</given-names> <surname>Vattikonda</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Sip</surname></string-name>, <string-name><given-names>Samuel Medina</given-names> <surname>Villalon</surname></string-name>, <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Delineating epileptogenic networks using brain imaging data and personalized modeling in drug-resistant epilepsy</article-title>. <source>Science Translational Medicine</source>, <volume>15</volume>(<issue>680</issue>):<fpage>eabp8982</fpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Lauren N</given-names> <surname>Ross</surname></string-name> and <string-name><given-names>Dani S</given-names> <surname>Bassett</surname></string-name></person-group>. <article-title>Causation in neuroscience: Keeping mechanism meaningful</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>25</volume>(<issue>2</issue>):<fpage>81</fpage>–<lpage>90</lpage>, <year>2024</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.R.</given-names> <surname>Wilson</surname></string-name> and <string-name><given-names>J.D.</given-names> <surname>Cowan</surname></string-name></person-group>. <article-title>Excitatory and inhibitory interactions in localized populations of model neurons</article-title>. <source>Biophys. J</source>., <volume>12</volume>:<fpage>1</fpage>–<lpage>24</lpage>, <year>1972</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V.K.</given-names> <surname>Jirsa</surname></string-name> and <string-name><given-names>H.</given-names> <surname>Haken</surname></string-name></person-group>. <article-title>Field theory of electromagnetic brain activity</article-title>. <source>Phys. Rev. Lett</source>., <volume>77</volume>(<issue>5</issue>):<fpage>960</fpage>–<lpage>963</lpage>, <year>1996</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Deco</surname></string-name>, <string-name><given-names>V.K.</given-names> <surname>Jirsa</surname></string-name>, <string-name><given-names>P.A.</given-names> <surname>Robinson</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Breakspear</surname></string-name>, and <string-name><given-names>K.</given-names> <surname>Friston</surname></string-name></person-group>. <article-title>The dynamic brain: from spiking neurons to neural masses and cortical fields</article-title>. <source>PloS Comp. Biol</source>., <volume>4</volume>(<issue>8</issue>), <year>2008</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Viktor K.</given-names> <surname>Jirsa</surname></string-name>, <string-name><given-names>William C.</given-names> <surname>Stacey</surname></string-name>, <string-name><given-names>Pascale P.</given-names> <surname>Quilichini</surname></string-name>, <string-name><given-names>Anton I.</given-names> <surname>Ivanov</surname></string-name>, and <string-name><given-names>Christophe</given-names> <surname>Bernard</surname></string-name></person-group>. <article-title>On the nature of seizure dynamics</article-title>. <source>Brain</source>, <volume>137</volume>(<issue>8</issue>):<fpage>2210</fpage>– <lpage>2230</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ernest</given-names> <surname>Montbrió</surname></string-name>, <string-name><given-names>Diego</given-names> <surname>Pazó</surname></string-name>, and <string-name><given-names>Alex</given-names> <surname>Roxin</surname></string-name></person-group>. <article-title>Macroscopic description for networks of spiking neurons</article-title>. <source>Physical Review X</source>, <volume>5</volume>(<issue>2</issue>):<fpage>021028</fpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Blake J</given-names> <surname>Cook</surname></string-name>, <string-name><given-names>Andre DH</given-names> <surname>Peterson</surname></string-name>, <string-name><given-names>Wessel</given-names> <surname>Woldman</surname></string-name>, and <string-name><given-names>John R</given-names> <surname>Terry</surname></string-name></person-group>. <article-title>Neural field models: A mathematical overview and unifying framework</article-title>. <source>Mathematical Neuroscience and Applications</source>, <volume>2</volume>, <year>2022</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Christopher J</given-names> <surname>Honey</surname></string-name>, <string-name><given-names>Olaf</given-names> <surname>Sporns</surname></string-name>, <string-name><given-names>Leila</given-names> <surname>Cammoun</surname></string-name>, <string-name><given-names>Xavier</given-names> <surname>Gigandet</surname></string-name>, <string-name><given-names>JeanPhilippe</given-names> <surname>Thiran</surname></string-name>, <string-name><given-names>Reto</given-names> <surname>Meuli</surname></string-name>, and <string-name><given-names>Patric</given-names> <surname>Hagmann</surname></string-name></person-group>. <article-title>Predicting human resting-state functional connectivity from structural connectivity</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>106</volume>(<issue>6</issue>):<fpage>2035</fpage>–<lpage>2040</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Olaf</given-names> <surname>Sporns</surname></string-name>, <string-name><given-names>Giulio</given-names> <surname>Tononi</surname></string-name>, and <string-name><given-names>Rolf</given-names> <surname>Kötter</surname></string-name></person-group>. <article-title>The human connectome: a structural description of the human brain</article-title>. <source>PLoS computational biology</source>, <volume>1</volume>(<issue>4</issue>):<fpage>e42</fpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Michael</given-names> <surname>Schirner</surname></string-name>, <string-name><given-names>Simon</given-names> <surname>Rothmeier</surname></string-name>, <string-name><given-names>Viktor K.</given-names> <surname>Jirsa</surname></string-name></person-group>, <article-title>Anthony Randal McIntosh, and Petra Ritter. An automated pipeline for constructing personalized virtual brains from multimodal neuroimaging data</article-title>. <source>NeuroImage</source>, <volume>117</volume>:<fpage>343</fpage> – <lpage>357</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Vincent</given-names> <surname>Bazinet</surname></string-name>, <string-name><given-names>Justine Y</given-names> <surname>Hansen</surname></string-name>, and <string-name><given-names>Bratislav</given-names> <surname>Misic</surname></string-name></person-group>. <article-title>Towards a biologically annotated brain connectome</article-title>. <source>Nature reviews neuroscience</source>, <volume>24</volume>(<issue>12</issue>):<fpage>747</fpage>–<lpage>760</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Paula</given-names> <surname>Sanz-Leon</surname></string-name>, <string-name><given-names>Stuart A.</given-names> <surname>Knock</surname></string-name>, <string-name><given-names>Andreas</given-names> <surname>Spiegler</surname></string-name>, and <string-name><given-names>Viktor K.</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Mathematical framework for large-scale brain network modeling in the virtual brain</article-title>. <source>NeuroImage</source>, <volume>111</volume>:<fpage>385</fpage> – <lpage>430</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Michael</given-names> <surname>Schirner</surname></string-name>, <string-name><given-names>Lia</given-names> <surname>Domide</surname></string-name>, <string-name><given-names>Dionysios</given-names> <surname>Perdikis</surname></string-name>, <string-name><given-names>Paul</given-names> <surname>Triebkorn</surname></string-name>, <string-name><given-names>Leon</given-names> <surname>Stefanovski</surname></string-name>, <string-name><given-names>Roopa</given-names> <surname>Pai</surname></string-name>, <string-name><given-names>Paula</given-names> <surname>Prodan</surname></string-name>, <string-name><given-names>Bogdan</given-names> <surname>Valean</surname></string-name>, <string-name><given-names>Jessica</given-names> <surname>Palmer</surname></string-name>, <string-name><given-names>Chloê</given-names> <surname>Langford</surname></string-name>, <string-name><given-names>André</given-names> <surname>Blickensdörfer</surname></string-name>, <string-name><given-names>Michiel</given-names> <surname>van der Vlag</surname></string-name>, <string-name><given-names>Sandra</given-names> <surname>Diaz-Pier</surname></string-name>, <string-name><given-names>Alexander</given-names> <surname>Peyser</surname></string-name>, <string-name><given-names>Wouter</given-names> <surname>Klijn</surname></string-name>, <string-name><given-names>Dirk</given-names> <surname>Pleiter</surname></string-name>, <string-name><given-names>Anne</given-names> <surname>Nahm</surname></string-name>, <string-name><given-names>Oliver</given-names> <surname>Schmid</surname></string-name>, <string-name><given-names>Marmaduke</given-names> <surname>Woodman</surname></string-name>, <string-name><given-names>Lyuba</given-names> <surname>Zehl</surname></string-name>, <string-name><given-names>Jan</given-names> <surname>Fousek</surname></string-name>, <string-name><given-names>Spase</given-names> <surname>Petkoski</surname></string-name>, <string-name><given-names>Lionel</given-names> <surname>Kusch</surname></string-name>, <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Daniele</given-names> <surname>Marinazzo</surname></string-name>, <string-name><given-names>Jean-François</given-names> <surname>Mangin</surname></string-name>, <string-name><given-names>Agnes</given-names> <surname>Flöel</surname></string-name>, <string-name><given-names>Simisola</given-names> <surname>Akintoye</surname></string-name>, <string-name><given-names>Bernd Carsten</given-names> <surname>Stahl</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Cepic</surname></string-name>, <string-name><given-names>Emily</given-names> <surname>Johnson</surname></string-name>, <string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name>, <string-name><given-names>Anthony R.</given-names> <surname>McIntosh</surname></string-name>, <string-name><given-names>Claus C.</given-names> <surname>Hilgetag</surname></string-name>, <string-name><given-names>Marc</given-names> <surname>Morgan</surname></string-name>, <string-name><given-names>Bernd</given-names> <surname>Schuller</surname></string-name>, <string-name><given-names>Alex</given-names> <surname>Upton</surname></string-name>, <string-name><given-names>Colin</given-names> <surname>McMurtrie</surname></string-name>, <string-name><given-names>Timo</given-names> <surname>Dickscheid</surname></string-name>, <string-name><given-names>Jan G.</given-names> <surname>Bjaalie</surname></string-name>, <string-name><given-names>Katrin</given-names> <surname>Amunts</surname></string-name>, <string-name><given-names>Jochen</given-names> <surname>Mersmann</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name>, and <string-name><given-names>Petra</given-names> <surname>Ritter</surname></string-name></person-group>. <article-title>Brain simulation as a cloud service: The virtual brain on ebrains</article-title>. <source>NeuroImage</source>, <volume>251</volume>:<issue>118973</issue>, <year>2022</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Katrin</given-names> <surname>Amunts</surname></string-name>, <string-name><given-names>Javier</given-names> <surname>DeFelipe</surname></string-name>, <string-name><given-names>Cyriel</given-names> <surname>Pennartz</surname></string-name>, <string-name><given-names>Alain</given-names> <surname>Destexhe</surname></string-name>, <string-name><given-names>Michele</given-names> <surname>Migliore</surname></string-name>, <string-name><given-names>Philippe</given-names> <surname>Ryvlin</surname></string-name>, <string-name><given-names>Steve</given-names> <surname>Furber</surname></string-name>, <string-name><given-names>Alois</given-names> <surname>Knoll</surname></string-name>, <string-name><given-names>Lise</given-names> <surname>Bitsch</surname></string-name>, <string-name><given-names>Jan G</given-names> <surname>Bjaalie</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Linking brain structure, activity, and cognitive function through computation</article-title>. <source>Eneuro</source>, <volume>9</volume>(<issue>2</issue>), <year>2022</year>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Egidio</given-names> <surname>D’Angelo</surname></string-name> and <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>The quest for multiscale brain modeling</article-title>. <source>Trends in neurosciences</source>, <volume>45</volume>(<issue>10</issue>):<fpage>777</fpage>–<lpage>790</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gustavo</given-names> <surname>Patow</surname></string-name>, <string-name><given-names>Ignacio</given-names> <surname>Martin</surname></string-name>, <string-name><given-names>Yonatan Sanz</given-names> <surname>Perl</surname></string-name>, <string-name><given-names>Morten L</given-names> <surname>Kringelbach</surname></string-name>, and <string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name></person-group>. <article-title>Whole-brain modelling: an essential tool for understanding brain dynamics</article-title>. <source>Nature Reviews Methods Primers</source>, <volume>4</volume>(<issue>1</issue>):<fpage>53</fpage>, <year>2024</year>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Damien</given-names> <surname>Depannemaecker</surname></string-name>, <string-name><given-names>Marisa</given-names> <surname>Saggio</surname></string-name>, <string-name><given-names>Paul</given-names> <surname>Triebkorn</surname></string-name>, <string-name><given-names>Giovanni</given-names> <surname>Rabuffo</surname></string-name>, <string-name><given-names>Jan</given-names> <surname>Fousek</surname></string-name>, <string-name><given-names>Abolfazl</given-names> <surname>Ziaeemehr</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Sip</surname></string-name>, <string-name><given-names>Anastasios</given-names> <surname>Athanasiadis</surname></string-name>, <string-name><given-names>Martin</given-names> <surname>Breyton</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Principles and operation of virtual brain twins</article-title>. <source>bioRxiv</source>, pages <elocation-id>2024.10.25.620245</elocation-id>, <year>2024</year>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Olaf</given-names> <surname>Sporns</surname></string-name></person-group>. <source>Networks of the Brain</source>. <publisher-name>MIT press</publisher-name>, <year>2016</year>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Danielle S</given-names> <surname>Bassett</surname></string-name> and <string-name><given-names>Olaf</given-names> <surname>Sporns</surname></string-name></person-group>. <article-title>Network neuroscience</article-title>. <source>Nature neuroscience</source>, <volume>20</volume>(<issue>3</issue>):<fpage>353</fpage>–<lpage>364</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Anandamohan</given-names> <surname>Ghosh</surname></string-name>, <string-name><given-names>Y</given-names> <surname>Rho</surname></string-name>, <string-name><given-names>Anthony Randal</given-names> <surname>McIntosh</surname></string-name>, <string-name><given-names>Rolf</given-names> <surname>Kötter</surname></string-name>, and <string-name><given-names>Viktor K</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Noise during rest enables the exploration of the brain’s dynamic repertoire</article-title>. <source>PLoS computational biology</source>, <volume>4</volume>(<issue>10</issue>):<fpage>e1000196</fpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Christopher J</given-names> <surname>Honey</surname></string-name>, <string-name><given-names>Jean-Philippe</given-names> <surname>Thivierge</surname></string-name>, and <string-name><given-names>Olaf</given-names> <surname>Sporns</surname></string-name></person-group>. <article-title>Can structure predict function in the human brain?</article-title> <source>Neuroimage</source>, <volume>52</volume>(<issue>3</issue>):<fpage>766</fpage>–<lpage>776</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Hae-Jeong</given-names> <surname>Park</surname></string-name> and <string-name><given-names>Karl</given-names> <surname>Friston</surname></string-name></person-group>. <article-title>Structural and functional brain networks: from connections to cognition</article-title>. <source>Science</source>, <volume>342</volume>(<issue>6158</issue>):<fpage>1238411</fpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Francesca</given-names> <surname>Melozzi</surname></string-name>, <string-name><given-names>Eyal</given-names> <surname>Bergmann</surname></string-name>, <string-name><given-names>Julie A.</given-names> <surname>Harris</surname></string-name>, <string-name><given-names>Itamar</given-names> <surname>Kahn</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name>, and <string-name><given-names>Christophe</given-names> <surname>Bernard</surname></string-name></person-group>. <article-title>Individual structural features constrain the mouse functional connectome</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>116</volume>(<issue>52</issue>):<fpage>26961</fpage>–<lpage>26969</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Laura E</given-names> <surname>Suárez</surname></string-name>, <string-name><given-names>Ross D</given-names> <surname>Markello</surname></string-name>, <string-name><given-names>Richard F</given-names> <surname>Betzel</surname></string-name>, and <string-name><given-names>Bratislav</given-names> <surname>Misic</surname></string-name></person-group>. <article-title>Linking structure and function in macroscale brain networks</article-title>. <source>Trends in cognitive sciences</source>, <volume>24</volume>(<issue>4</issue>):<fpage>302</fpage>–<lpage>315</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Guozheng</given-names> <surname>Feng</surname></string-name>, <string-name><given-names>Yiwen</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Weijie</given-names> <surname>Huang</surname></string-name>, <string-name><given-names>Haojie</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Jian</given-names> <surname>Cheng</surname></string-name>, and <string-name><given-names>Ni</given-names> <surname>Shu</surname></string-name></person-group>. <article-title>Spatial and temporal pattern of structure–function coupling of human brain connectome with development</article-title>. <source>eLife</source>, <volume>13</volume>:<elocation-id>RP93325</elocation-id>, <year>2024</year>. <pub-id pub-id-type="doi">10.7554/eLife.93325</pub-id></mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jacob</given-names> <surname>Tanner</surname></string-name>, <string-name><given-names>Joshua</given-names> <surname>Faskowitz</surname></string-name>, <string-name><given-names>Andreia Sofia</given-names> <surname>Teixeira</surname></string-name>, <string-name><given-names>Caio</given-names> <surname>Seguin</surname></string-name>, <string-name><given-names>Ludovico</given-names> <surname>Coletta</surname></string-name>, <string-name><given-names>Alessandro</given-names> <surname>Gozzi</surname></string-name>, <string-name><given-names>Bratislav</given-names> <surname>Mišić</surname></string-name>, and <string-name><given-names>Richard F</given-names> <surname>Betzel</surname></string-name></person-group>. <article-title>A multi-modal, asymmetric, weighted, and signed description of anatomical connectivity</article-title>. <source>Nature Communications</source>, <volume>15</volume>(<issue>1</issue>):<year>5865</year>, <fpage>2024</fpage>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Deco</surname></string-name>, <string-name><given-names>V.K.</given-names> <surname>Jirsa</surname></string-name>, and <string-name><given-names>A.R.</given-names> <surname>McIntosh</surname></string-name></person-group>. <article-title>Emerging concepts for the dynamical organization of resting-state activity in the brain</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>12</volume>(<issue>1</issue>):<fpage>43</fpage>–<lpage>56</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Peng</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Ru</given-names> <surname>Kong</surname></string-name>, <string-name><given-names>Xiaolu</given-names> <surname>Kong</surname></string-name>, <string-name><given-names>Raphaël</given-names> <surname>Liégeois</surname></string-name>, <string-name><given-names>Csaba</given-names> <surname>Orban</surname></string-name>, <string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name>, <string-name><given-names>Martijn P</given-names> <surname>Van Den Heuvel</surname></string-name>, and <string-name><given-names>BT Thomas</given-names> <surname>Yeo</surname></string-name></person-group>. <article-title>Inversion of a large-scale circuit model reveals a cortical hierarchy in the dynamic resting human brain</article-title>. <source>Science advances</source>, <volume>5</volume>(<issue>1</issue>):<fpage>eaat7854</fpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Abolfazl</given-names> <surname>Ziaeemehr</surname></string-name>, <string-name><given-names>Mina</given-names> <surname>Zarei</surname></string-name>, <string-name><given-names>Alireza</given-names> <surname>Valizadeh</surname></string-name>, and <string-name><given-names>Claudio R</given-names> <surname>Mirasso</surname></string-name></person-group>. <article-title>Frequency-dependent organization of the brain’s functional network through delayed-interactions</article-title>. <source>Neural Networks</source>, <volume>132</volume>:<fpage>155</fpage>–<lpage>165</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Xiaolu</given-names> <surname>Kong</surname></string-name>, <string-name><given-names>Ru</given-names> <surname>Kong</surname></string-name>, <string-name><given-names>Csaba</given-names> <surname>Orban</surname></string-name>, <string-name><given-names>Peng</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Shaoshi</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Kevin</given-names> <surname>Anderson</surname></string-name>, <string-name><given-names>Avram</given-names> <surname>Holmes</surname></string-name>, <string-name><given-names>John D</given-names> <surname>Murray</surname></string-name>, <string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name>, <string-name><given-names>Martijn</given-names> <surname>van den Heuvel</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Sensory-motor cortices shape functional connectivity dynamics in the human brain</article-title>. <source>Nature communications</source>, <volume>12</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>15</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mario</given-names> <surname>Lavanga</surname></string-name>, <string-name><given-names>Johanna</given-names> <surname>Stumme</surname></string-name>, <string-name><given-names>Bahar Hazal</given-names> <surname>Yalcinkaya</surname></string-name>, <string-name><given-names>Jan</given-names> <surname>Fousek</surname></string-name>, <string-name><given-names>Christiane</given-names> <surname>Jockwitz</surname></string-name>, <string-name><given-names>Hiba</given-names> <surname>Sheheitli</surname></string-name>, <string-name><given-names>Nora</given-names> <surname>Bittner</surname></string-name>, <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Spase</given-names> <surname>Petkoski</surname></string-name>, <string-name><given-names>Svenja</given-names> <surname>Caspers</surname></string-name>, <etal>et al.</etal></person-group> <article-title>The virtual aging brain: Causal inference supports inter-hemispheric dedifferentiation in healthy aging</article-title>. <source>NeuroImage</source>, <volume>283</volume>:<fpage>120403</fpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Shaoshi</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Bart</given-names> <surname>Larsen</surname></string-name>, <string-name><given-names>Valerie J</given-names> <surname>Sydnor</surname></string-name>, <string-name><given-names>Tianchu</given-names> <surname>Zeng</surname></string-name>, <string-name><given-names>Lijun</given-names> <surname>An</surname></string-name>, <string-name><given-names>Xiaoxuan</given-names> <surname>Yan</surname></string-name>, <string-name><given-names>Ru</given-names> <surname>Kong</surname></string-name>, <string-name><given-names>Xiaolu</given-names> <surname>Kong</surname></string-name>, <string-name><given-names>Ruben C</given-names> <surname>Gur</surname></string-name>, <string-name><given-names>Raquel E</given-names> <surname>Gur</surname></string-name>, <etal>et al.</etal></person-group> <article-title>In vivo whole-cortex marker of excitation-inhibition ratio indexes cortical maturation and cognitive ability in youth</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>121</volume>(<issue>23</issue>):<fpage>e2318641121</fpage>, <year>2024</year>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Pablo</given-names> <surname>Barttfeld</surname></string-name>, <string-name><given-names>Lynn</given-names> <surname>Uhrig</surname></string-name>, <string-name><given-names>Jacobo D</given-names> <surname>Sitt</surname></string-name>, <string-name><given-names>Mariano</given-names> <surname>Sigman</surname></string-name>, <string-name><given-names>Béchir</given-names> <surname>Jar-raya</surname></string-name>, and <string-name><given-names>Stanislas</given-names> <surname>Dehaene</surname></string-name></person-group>. <article-title>Signature of consciousness in the dynamics of resting-state brain activity</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>112</volume>(<issue>3</issue>):<fpage>887</fpage>–<lpage>892</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Hutt</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Darren</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Sleigh</surname></string-name></person-group>. <article-title>Anesthetic action on the transmission delay between cortex and thalamus explains the beta-buzz observed under propofol anesthesia</article-title>. <source>PLOS One</source>, <volume>12</volume>(<issue>6</issue>):<fpage>1</fpage>–<lpage>29</lpage>, 06 <year>2017</year>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Andrea I</given-names> <surname>Luppi</surname></string-name>, <string-name><given-names>Joana</given-names> <surname>Cabral</surname></string-name>, <string-name><given-names>Rodrigo</given-names> <surname>Cofre</surname></string-name>, <string-name><given-names>Pedro AM</given-names> <surname>Mediano</surname></string-name>, <string-name><given-names>Fernando E</given-names> <surname>Rosas</surname></string-name>, <string-name><given-names>Abid Y</given-names> <surname>Qureshi</surname></string-name>, <string-name><given-names>Amy</given-names> <surname>Kuceyeski</surname></string-name>, <string-name><given-names>Enzo</given-names> <surname>Tagliazucchi</surname></string-name>, <string-name><given-names>Federico</given-names> <surname>Raimondo</surname></string-name>, <string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Computational modelling in disorders of consciousness: Closing the gap towards personalised models for restoring consciousness</article-title>. <source>NeuroImage</source>, <volume>275</volume>:<issue>120162</issue>, <year>2023</year>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yonatan Sanz</given-names> <surname>Perl</surname></string-name>, <string-name><given-names>Carla</given-names> <surname>Pallavicini</surname></string-name>, <string-name><given-names>Juan</given-names> <surname>Piccinini</surname></string-name>, <string-name><given-names>Athena</given-names> <surname>Demertzi</surname></string-name>, <string-name><given-names>Vincent</given-names> <surname>Bonhomme</surname></string-name>, <string-name><given-names>Charlotte</given-names> <surname>Martial</surname></string-name>, <string-name><given-names>Rajanikant</given-names> <surname>Panda</surname></string-name>, <string-name><given-names>Naji</given-names> <surname>Alnagger</surname></string-name>, <string-name><given-names>Jitka</given-names> <surname>Annen</surname></string-name>, <string-name><given-names>Olivia</given-names> <surname>Gosseries</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Low-dimensional organization of global brain states of reduced consciousness</article-title>. <source>Cell Reports</source>, <volume>42</volume>(<issue>5</issue>), <year>2023</year>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name>, <string-name><given-names>Olaf</given-names> <surname>Sporns</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Breakspear</surname></string-name>, <string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name></person-group>, <article-title>and Anthony Randal McIntosh</article-title>. <source>Towards the virtual brain: network modeling of the intact and the damaged brain. Archives italiennes de biologie</source>, <volume>148</volume>(<issue>3</issue>):<fpage>189</fpage>–<lpage>205</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Paula Sanz</given-names> <surname>Leon</surname></string-name>, <string-name><given-names>Stuart</given-names> <surname>Knock</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Woodman</surname></string-name>, <string-name><given-names>Lia</given-names> <surname>Domide</surname></string-name>, <string-name><given-names>Jochen</given-names> <surname>Mersmann</surname></string-name>, <string-name><given-names>Anthony</given-names> <surname>McIntosh</surname></string-name>, and <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>The virtual brain: a simulator of primate brain network dynamics</article-title>. <source>Frontiers in Neuroinformatics</source>, <volume>7</volume>:<issue>10</issue>, <year>2013</year>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name>, <string-name><given-names>Huifang</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Paul</given-names> <surname>Triebkorn</surname></string-name>, <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Jayant</given-names> <surname>Jha</surname></string-name>, <string-name><given-names>Jorge</given-names> <surname>Gonzalez-Martinez</surname></string-name>, <string-name><given-names>Maxime</given-names> <surname>Guye</surname></string-name>, <string-name><given-names>Julia</given-names> <surname>Makhalova</surname></string-name>, and <string-name><given-names>Fabrice</given-names> <surname>Bartolomei</surname></string-name></person-group>. <article-title>Personalised virtual brain models in epilepsy</article-title>. <source>The Lancet Neurology</source>, <volume>22</volume>(<issue>5</issue>):<fpage>443</fpage>–<lpage>454</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Huifang E</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Paul</given-names> <surname>Triebkorn</surname></string-name>, <string-name><given-names>Martin</given-names> <surname>Breyton</surname></string-name>, <string-name><given-names>Borana</given-names> <surname>Dollomaja</surname></string-name>, <string-name><given-names>Jean-Didier</given-names> <surname>Lemarechal</surname></string-name>, <string-name><given-names>Spase</given-names> <surname>Petkoski</surname></string-name>, <string-name><given-names>Pierpaolo</given-names> <surname>Sorrentino</surname></string-name>, <string-name><given-names>Damien</given-names> <surname>Depannemaecker</surname></string-name>, <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, and <string-name><given-names>Viktor K</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Virtual brain twins: from basic neuroscience to clinical use</article-title>. <source>National Science Review</source>, <volume>11</volume>(<issue>5</issue>):<fpage>nwae079</fpage>, <year>2024</year>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V.K.</given-names> <surname>Jirsa</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Proix</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Perdikis</surname></string-name>, <string-name><given-names>M.M.</given-names> <surname>Woodman</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Gonzalez-Martinez</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Bernard</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Bénar</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Guye</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Chauvel</surname></string-name>, and <string-name><given-names>F.</given-names> <surname>Bartolomei</surname></string-name></person-group>. <article-title>The virtual epileptic patient: Individualized whole-brain models of epilepsy spread</article-title>. <source>NeuroImage</source>, <volume>145</volume>:<fpage>377</fpage> – <lpage>388</lpage>, <year>2017</year>. Individual Subject Prediction.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Timothée</given-names> <surname>Proix</surname></string-name>, <string-name><given-names>Fabrice</given-names> <surname>Bartolomei</surname></string-name>, <string-name><given-names>Maxime</given-names> <surname>Guye</surname></string-name>, and <string-name><given-names>Viktor K.</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Individual brain structure and modelling predict seizure propagation</article-title>. <source>Brain</source>, <volume>140</volume>(<issue>3</issue>):<fpage>641</fpage>–<lpage>654</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P</given-names> <surname>Sorrentino</surname></string-name>, <string-name><given-names>A</given-names> <surname>Pathak</surname></string-name>, <string-name><given-names>A</given-names> <surname>Ziaeemehr</surname></string-name>, <string-name><given-names>E</given-names> <surname>Troisi Lopez</surname></string-name>, <string-name><given-names>L</given-names> <surname>Cipriano</surname></string-name>, <string-name><given-names>A</given-names> <surname>Romano</surname></string-name>, <string-name><given-names>M</given-names> <surname>Sparaco</surname></string-name>, <string-name><given-names>M</given-names> <surname>Quarantelli</surname></string-name>, <string-name><given-names>A</given-names> <surname>Banerjee</surname></string-name>, <string-name><given-names>G</given-names> <surname>Sorrentino</surname></string-name>, <etal>et al.</etal></person-group> <article-title>The virtual multiple sclerosis patient</article-title>. <source>iScience</source>, <volume>27</volume>(<issue>7</issue>), <year>2024</year>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Camille</given-names> <surname>Mazzara</surname></string-name>, <string-name><given-names>Abolfazl</given-names> <surname>Ziaeemehr</surname></string-name>, <string-name><given-names>Emahnuel Lopez</given-names> <surname>Troisi</surname></string-name>, <string-name><surname>Lorenzo CIPRI-</surname> <given-names>ANO</given-names></string-name>, <string-name><given-names>Marianna</given-names> <surname>Angiolelli</surname></string-name>, <string-name><given-names>Maddalena</given-names> <surname>Sparaco</surname></string-name>, <string-name><given-names>Mario</given-names> <surname>Quarantelli</surname></string-name>, <string-name><given-names>Carmine</given-names> <surname>Granata</surname></string-name>, <string-name><given-names>Giuseppe</given-names> <surname>Sorrentino</surname></string-name>, <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Mapping brain lesions to conduction delays: the next step for personalized brain models in multiple sclerosis</article-title>. <source>medRxiv</source>, pages <elocation-id>2024.07.10.24310150</elocation-id>, <year>2024</year>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Bahar Hazal</given-names> <surname>Yalcinkaya</surname></string-name>, <string-name><given-names>Abolfazl</given-names> <surname>Ziaeemehr</surname></string-name>, <string-name><given-names>Jan</given-names> <surname>Fousek</surname></string-name>, <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Mario</given-names> <surname>Lavanga</surname></string-name>, <string-name><given-names>Ana</given-names> <surname>Solodkin</surname></string-name>, <string-name><given-names>Randy</given-names> <surname>McIntosh</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name>, and <string-name><given-names>Spase</given-names> <surname>Petkoski</surname></string-name></person-group>. <article-title>Personalized virtual brains of alzheimer’s disease link dynamical biomarkers of fmri with increased local excitability</article-title>. <source>medRxiv</source>, pages 2023–01, <year>2023</year>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yonatan Sanz</given-names> <surname>Perl</surname></string-name>, <string-name><given-names>Sol</given-names> <surname>Fittipaldi</surname></string-name>, <string-name><given-names>Cecilia Gonzalez</given-names> <surname>Campo</surname></string-name>, <string-name><given-names>Sebastián</given-names> <surname>Moguilner</surname></string-name>, <string-name><given-names>Josephine</given-names> <surname>Cruzat</surname></string-name>, <string-name><given-names>Matias E</given-names> <surname>Fraile-Vazquez</surname></string-name>, <string-name><given-names>Rubén</given-names> <surname>Herzog</surname></string-name>, <string-name><given-names>Morten L</given-names> <surname>Kringelbach</surname></string-name>, <string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name>, <string-name><given-names>Pavel</given-names> <surname>Prado</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Model-based whole-brain perturbational landscape of neurodegenerative diseases</article-title>. <source>eLife</source>, <volume>12</volume>:<elocation-id>e83970</elocation-id>, <year>2023</year>. <pub-id pub-id-type="doi">10.7554/eLife.83970</pub-id></mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Kyesam</given-names> <surname>Jung</surname></string-name>, <string-name><given-names>Esther</given-names> <surname>Florin</surname></string-name>, <string-name><given-names>Kaustubh R</given-names> <surname>Patil</surname></string-name>, <string-name><given-names>Julian</given-names> <surname>Caspers</surname></string-name>, <string-name><given-names>Christian</given-names> <surname>Rubbert</surname></string-name>, <string-name><given-names>Simon B</given-names> <surname>Eickhoff</surname></string-name>, and <string-name><given-names>Oleksandr V</given-names> <surname>Popovych</surname></string-name></person-group>. <article-title>Whole-brain dynamical modelling for classification of parkinson’s disease</article-title>. <source>Brain communications</source>, <volume>5</volume>(<issue>1</issue>):<fpage>fcac331</fpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Marianna</given-names> <surname>Angiolelli</surname></string-name>, <string-name><given-names>Damien</given-names> <surname>Depannemaecker</surname></string-name>, <string-name><given-names>Hasnae</given-names> <surname>Agouram</surname></string-name>, <string-name><given-names>Jean</given-names> <surname>Regis</surname></string-name>, <string-name><given-names>Romain</given-names> <surname>Carron</surname></string-name>, <string-name><given-names>Marmaduke</given-names> <surname>Woodman</surname></string-name>, <string-name><given-names>Letizia</given-names> <surname>Chiodo</surname></string-name>, <string-name><given-names>Paul</given-names> <surname>Triebkorn</surname></string-name>, <string-name><given-names>Abolfazl</given-names> <surname>Ziaeemehr</surname></string-name>, <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <etal>et al.</etal></person-group> <article-title>The virtual parkinsonian patient</article-title>. <source>medRxiv</source>, pages 2024–07, <year>2024</year>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name> and <string-name><given-names>Morten L</given-names> <surname>Kringelbach</surname></string-name></person-group>. <article-title>Great expectations: using whole-brain computational connectomics for understanding neuropsychiatric disorders</article-title>. <source>Neuron</source>, <volume>84</volume>(<issue>5</issue>):<fpage>892</fpage>–<lpage>905</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Behzad</given-names> <surname>Iravani</surname></string-name>, <string-name><given-names>Artin</given-names> <surname>Arshamian</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>Fransson</surname></string-name>, and <string-name><given-names>Neda</given-names> <surname>Kaboodvand</surname></string-name></person-group>. <article-title>Whole-brain modelling of resting state fmri differentiates adhd subtypes and facilitates stratified neuro-stimulation therapy</article-title>. <source>Neuroimage</source>, <volume>231</volume>:<issue>117844</issue>, <year>2021</year>.</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Anna Letizia</given-names> <surname>Allegra Mascaro</surname></string-name>, <string-name><given-names>Egidio</given-names> <surname>Falotico</surname></string-name>, <string-name><given-names>Spase</given-names> <surname>Petkoski</surname></string-name>, <string-name><given-names>Maria</given-names> <surname>Pasquini</surname></string-name>, <string-name><given-names>Lorenzo</given-names> <surname>Vannucci</surname></string-name>, <string-name><given-names>Núria</given-names> <surname>Tort-Colet</surname></string-name>, <string-name><given-names>Emilia</given-names> <surname>Conti</surname></string-name>, <string-name><given-names>Francesco</given-names> <surname>Resta</surname></string-name>, <string-name><given-names>Cristina</given-names> <surname>Spalletti</surname></string-name>, <string-name><given-names>Shravan Tata</given-names> <surname>Ramalingasetty</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Experimental and computational study on motor control and recovery after stroke: toward a constructive loop between experimental and virtual embodied neuroscience</article-title>. <source>Frontiers in systems neuroscience</source>, <volume>14</volume>:<fpage>31</fpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c58"><label>[58]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Sebastian</given-names> <surname>Idesis</surname></string-name>, <string-name><given-names>Chiara</given-names> <surname>Favaretto</surname></string-name>, <string-name><given-names>Nicholas V</given-names> <surname>Metcalf</surname></string-name>, <string-name><given-names>Joseph C</given-names> <surname>Griffis</surname></string-name>, <string-name><given-names>Gordon L</given-names> <surname>Shulman</surname></string-name>, <string-name><given-names>Maurizio</given-names> <surname>Corbetta</surname></string-name>, and <string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name></person-group>. <article-title>Inferring the dynamical effects of stroke lesions through whole-brain modeling</article-title>. <source>NeuroImage: Clinical</source>, <volume>36</volume>:<fpage>103233</fpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c59"><label>[59]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Giovanni</given-names> <surname>Rabuffo</surname></string-name>, <string-name><given-names>Houefa-Armelle</given-names> <surname>Lokossou</surname></string-name>, <string-name><given-names>Zengmin</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Abolfazl Ziaee-</given-names> <surname>Mehr</surname></string-name>, <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Pascale P</given-names> <surname>Quilichini</surname></string-name>, <string-name><given-names>Antoine</given-names> <surname>Ghestem</surname></string-name>, <string-name><given-names>Ouafae</given-names> <surname>Arab</surname></string-name>, <string-name><given-names>Monique</given-names> <surname>Esclapez</surname></string-name>, <string-name><given-names>Parul</given-names> <surname>Verma</surname></string-name>, <etal>et al.</etal></person-group> <article-title>On global brain reconfiguration after local manipulations</article-title>. <source>bioRxiv</source>, pages 2023–09, <year>2023</year>.</mixed-citation></ref>
<ref id="c60"><label>[60]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jin</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Min</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Wei</given-names> <surname>Lan</surname></string-name>, <string-name><given-names>Fang-Xiang</given-names> <surname>Wu</surname></string-name>, <string-name><given-names>Yi</given-names> <surname>Pan</surname></string-name>, and <string-name><given-names>Jianxin</given-names> <surname>Wang</surname></string-name></person-group>. <article-title>Classification of alzheimer’s disease using whole brain hierarchical network</article-title>. <source>IEEE/ACM transactions on computational biology and bioinformatics</source>, <volume>15</volume>(<issue>2</issue>):<fpage>624</fpage>–<lpage>632</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c61"><label>[61]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gustavo</given-names> <surname>Patow</surname></string-name>, <string-name><given-names>Leon</given-names> <surname>Stefanovski</surname></string-name>, <string-name><given-names>Petra</given-names> <surname>Ritter</surname></string-name>, <string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name>, <string-name><given-names>Xenia</given-names> <surname>Kobeleva</surname></string-name></person-group>, <article-title>and Alzheimer’s Disease Neuroimaging Initiative</article-title>. <source>Whole-brain modeling of the differential influences of amyloid-beta and tau in alzheimer’s disease. Alzheimer’s Research &amp; Therapy</source>, <volume>15</volume>(<issue>1</issue>):<fpage>210</fpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c62"><label>[62]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Timothée</given-names> <surname>Proix</surname></string-name>, <string-name><given-names>Viktor K</given-names> <surname>Jirsa</surname></string-name>, <string-name><given-names>Fabrice</given-names> <surname>Bartolomei</surname></string-name>, <string-name><given-names>Maxime</given-names> <surname>Guye</surname></string-name>, and <string-name><given-names>Wilson</given-names> <surname>Truccolo</surname></string-name></person-group>. <article-title>Predicting the spatiotemporal diversity of seizure propagation and termination in human focal epilepsy</article-title>. <source>Nature Communications</source>, <volume>9</volume>(<issue>1</issue>):<elocation-id>1088</elocation-id>, <year>2018</year>.</mixed-citation></ref>
<ref id="c63"><label>[63]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Joana</given-names> <surname>Cabral</surname></string-name>, <string-name><given-names>Francesca</given-names> <surname>Castaldo</surname></string-name>, <string-name><given-names>Jakub</given-names> <surname>Vohryzek</surname></string-name>, <string-name><given-names>Vladimir</given-names> <surname>Litvak</surname></string-name>, <string-name><given-names>Christian</given-names> <surname>Bick</surname></string-name>, <string-name><given-names>Renaud</given-names> <surname>Lambiotte</surname></string-name>, <string-name><given-names>Karl</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>Morten L</given-names> <surname>Kringelbach</surname></string-name>, and <string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name></person-group>. <article-title>Metastable oscillatory modes emerge from synchronization in the brain spacetime connectome</article-title>. <source>Communications Physics</source>, <volume>5</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>13</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c64"><label>[64]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yuanzhe</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Caio</given-names> <surname>Seguin</surname></string-name>, <string-name><given-names>Sina</given-names> <surname>Mansour</surname></string-name>, <string-name><given-names>Stuart</given-names> <surname>Oldham</surname></string-name>, <string-name><given-names>Richard</given-names> <surname>Betzel</surname></string-name>, <string-name><given-names>Maria A</given-names> <surname>Di Biase</surname></string-name>, and <string-name><given-names>Andrew</given-names> <surname>Zalesky</surname></string-name></person-group>. <article-title>Parameter estimation for connectome generative models: Accuracy, reliability, and a fast parameter fitting method</article-title>. <source>Neuroimage</source>, <volume>270</volume>:<issue>119962</issue>, <year>2023</year>.</mixed-citation></ref>
<ref id="c65"><label>[65]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Carl-Magnus</given-names> <surname>Svensson</surname></string-name>, <string-name><given-names>Stephen</given-names> <surname>Coombes</surname></string-name>, and <string-name><given-names>Jonathan Westley</given-names> <surname>Peirce</surname></string-name></person-group>. <article-title>Using Evolutionary Algorithms for Fitting High-Dimensional Models to Neuronal Data</article-title>. <source>Neuroinformatics</source>, <volume>10</volume>(<issue>2</issue>):<fpage>199</fpage>–<lpage>218</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c66"><label>[66]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Axel</given-names> <surname>Hutt</surname></string-name>, <string-name><given-names>Laure</given-names> <surname>Buhry</surname></string-name>, and <string-name><given-names>Jamie</given-names> <surname>Sleigh</surname></string-name></person-group>. <article-title>Optimal model parameter estimation from eeg power spectrum features observed during general anesthesia</article-title>. <source>Neuroinformatics</source>, <volume>16</volume>(<issue>2</issue>):<fpage>231</fpage>–<lpage>251</lpage>, <month>Apr</month> <year>2018</year>.</mixed-citation></ref>
<ref id="c67"><label>[67]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Anirudh N</given-names> <surname>Vattikonda</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Sip</surname></string-name>, <string-name><given-names>Sandra</given-names> <surname>Diaz-Pier</surname></string-name>, <string-name><given-names>Alexander</given-names> <surname>Peyser</surname></string-name>, <string-name><given-names>Huifang</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Maxime</given-names> <surname>Guye</surname></string-name>, <string-name><given-names>Fabrice</given-names> <surname>Bartolomei</surname></string-name>, <string-name><given-names>Marmaduke M</given-names> <surname>Woodman</surname></string-name>, and <string-name><given-names>Viktor K</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>On the influence of prior information evaluated by fully bayesian criteria in a personalized whole-brain model of epilepsy spread</article-title>. <source>PLoS computational biology</source>, <volume>17</volume>(<issue>7</issue>):<fpage>e1009129</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c68"><label>[68]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Anirudh N</given-names> <surname>Vattikonda</surname></string-name>, <string-name><given-names>Jayant</given-names> <surname>Jha</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Sip</surname></string-name>, <string-name><given-names>Marmaduke M</given-names> <surname>Woodman</surname></string-name>, <string-name><given-names>Fabrice</given-names> <surname>Bartolomei</surname></string-name>, and <string-name><given-names>Viktor K</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Amortized bayesian inference on generative dynamical network models of epilepsy using deep neural density estimators</article-title>. <source>Neural Networks</source>, <volume>163</volume>:<fpage>178</fpage>–<lpage>194</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c69"><label>[69]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Abolfazl</given-names> <surname>Ziaeemehr</surname></string-name>, <string-name><given-names>Marmaduke M</given-names> <surname>Woodman</surname></string-name>, <string-name><given-names>Jan</given-names> <surname>Fousek</surname></string-name>, <string-name><given-names>Spase</given-names> <surname>Petkoski</surname></string-name>, and <string-name><given-names>Viktor K</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Simulation-based inference on virtual brain models of disorders</article-title>. <source>Machine Learning: Science and Technology</source>, <volume>5</volume>(<issue>3</issue>):<issue>035019</issue>, <month>jul</month> <year>2024</year>.</mixed-citation></ref>
<ref id="c70"><label>[70]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Kyle</given-names> <surname>Cranmer</surname></string-name>, <string-name><given-names>Johann</given-names> <surname>Brehmer</surname></string-name>, and <string-name><given-names>Gilles</given-names> <surname>Louppe</surname></string-name></person-group>. <article-title>The frontier of simulation-based inference</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>117</volume>(<issue>48</issue>):<fpage>30055</fpage>–<lpage>30062</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c71"><label>[71]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Pedro J</given-names> <surname>Gonçalves</surname></string-name>, <string-name><given-names>Jan-Matthis</given-names> <surname>Lueckmann</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Deistler</surname></string-name>, <string-name><given-names>Marcel</given-names> <surname>Nonnenmacher</surname></string-name>, <string-name><given-names>Kaan</given-names> <surname>Öcal</surname></string-name>, <string-name><given-names>Giacomo</given-names> <surname>Bassetto</surname></string-name>, <string-name><given-names>Chaitanya</given-names> <surname>Chintaluri</surname></string-name>, <string-name><given-names>William F</given-names> <surname>Podlaski</surname></string-name>, <string-name><given-names>Sara A</given-names> <surname>Haddad</surname></string-name>, <string-name><given-names>Tim P</given-names> <surname>Vogels</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Training deep neural density estimators to identify mechanistic models of neural dynamics</article-title>. <source>eLife</source>, <volume>9</volume>:<elocation-id>e56261</elocation-id>, <year>2020</year>. <pub-id pub-id-type="doi">10.7554/eLife.56261</pub-id></mixed-citation></ref>
<ref id="c72"><label>[72]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Andrew</given-names> <surname>Gelman</surname></string-name>, <string-name><given-names>Christian</given-names> <surname>Robert</surname></string-name>, <string-name><given-names>Nicolas</given-names> <surname>Chopin</surname></string-name>, and <string-name><given-names>Judith</given-names> <surname>Rousseau</surname></string-name></person-group>. <source>Bayesian Data Analysis</source>. <publisher-name>CRC Press</publisher-name>, <year>1995</year>.</mixed-citation></ref>
<ref id="c73"><label>[73]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>Samuel</given-names> <surname>Gershman</surname></string-name> and <string-name><given-names>Noah</given-names> <surname>Goodman</surname></string-name></person-group>. <article-title>Amortized inference in probabilistic reasoning</article-title>. In <conf-name>Proceedings of the annual meeting of the cognitive science society</conf-name>, volume <volume>36</volume>, <year>2014</year>.</mixed-citation></ref>
<ref id="c74"><label>[74]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Betancourt</surname></string-name> and <string-name><given-names>M.</given-names> <surname>Girolami</surname></string-name></person-group>. <article-title>Hamiltonian monte carlo for hierarchical models</article-title>. <source>arXiv</source>:<elocation-id>1312.0906</elocation-id>, <year>2013</year>.</mixed-citation></ref>
<ref id="c75"><label>[75]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Betancourt</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Byrne</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Livingstone</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Girolami</surname></string-name></person-group>. <article-title>The geometric foundations of hamiltonian monte carlo</article-title>. <source>arXiv</source>:<elocation-id>1410.5110</elocation-id>, <year>2014</year>.</mixed-citation></ref>
<ref id="c76"><label>[76]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>AN</given-names> <surname>Vattikonda</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Sip</surname></string-name>, <string-name><given-names>Maxime</given-names> <surname>Guye</surname></string-name>, <string-name><given-names>Fabrice</given-names> <surname>Bartolomei</surname></string-name>, <string-name><given-names>Michael Marmaduke</given-names> <surname>Woodman</surname></string-name>, and <string-name><given-names>Viktor K</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>The Bayesian virtual epileptic patient: A probabilistic framework designed to infer the spatial map of epileptogenicity in a personalized large-scale brain model of epilepsy spread</article-title>. <source>NeuroImage</source>, <volume>217</volume>:<issue>116839</issue>, <year>2020</year>.</mixed-citation></ref>
<ref id="c77"><label>[77]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Scott A</given-names> <surname>Sisson</surname></string-name>, <string-name><given-names>Yanan</given-names> <surname>Fan</surname></string-name>, and <string-name><given-names>Mark M</given-names> <surname>Tanaka</surname></string-name></person-group>. <article-title>Sequential monte carlo without likelihoods</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>104</volume>(<issue>6</issue>):<fpage>1760</fpage>– <lpage>1765</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c78"><label>[78]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mark A</given-names> <surname>Beaumont</surname></string-name>, <string-name><given-names>Jean-Marie</given-names> <surname>Cornuet</surname></string-name>, <string-name><given-names>Jean-Michel</given-names> <surname>Marin</surname></string-name>, and <string-name><given-names>Christian P</given-names> <surname>Robert</surname></string-name></person-group>. <article-title>Adaptive approximate bayesian computation</article-title>. <source>Biometrika</source>, <volume>96</volume>(<issue>4</issue>):<fpage>983</fpage>– <lpage>990</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c79"><label>[79]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>George</given-names> <surname>Papamakarios</surname></string-name>, <string-name><given-names>Theo</given-names> <surname>Pavlakou</surname></string-name>, and <string-name><given-names>Iain</given-names> <surname>Murray</surname></string-name></person-group>. <article-title>Masked autoregressive flow for density estimation</article-title>. <source>Advances in Neural Information Processing Systems</source>, <year>2017</year>.</mixed-citation></ref>
<ref id="c80"><label>[80]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Conor</given-names> <surname>Durkan</surname></string-name>, <string-name><given-names>Artur</given-names> <surname>Bekasov</surname></string-name>, <string-name><given-names>Iain</given-names> <surname>Murray</surname></string-name>, and <string-name><given-names>George</given-names> <surname>Papamakarios</surname></string-name></person-group>. <article-title>Neural spline flows</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>32</volume>:<fpage>7511</fpage>– <lpage>7522</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c81"><label>[81]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Nina</given-names> <surname>Baldy</surname></string-name>, <string-name><given-names>Martin</given-names> <surname>Breyton</surname></string-name>, <string-name><given-names>Marmaduke M</given-names> <surname>Woodman</surname></string-name>, <string-name><given-names>Viktor K</given-names> <surname>Jirsa</surname></string-name>, and <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name></person-group>. <article-title>Inference on the macroscopic dynamics of spiking neurons</article-title>. <source>Neural Computation, pages</source> <fpage>1</fpage>–<lpage>43</lpage>, 08 <year>2024</year>.</mixed-citation></ref>
<ref id="c82"><label>[82]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.H.</given-names> <surname>Jansen</surname></string-name> and <string-name><given-names>V.G.</given-names> <surname>Rit</surname></string-name></person-group>. <article-title>Electroencephalogram and visual evoked potential generation in a mathematical model of coupled cortical columns</article-title>. <source>Biol. Cybern</source>, <volume>73</volume>:<fpage>357</fpage>–<lpage>366</lpage>, <year>1995</year>.</mixed-citation></ref>
<ref id="c83"><label>[83]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Olivier</given-names> <surname>David</surname></string-name> and <string-name><given-names>Karl J.</given-names> <surname>Friston</surname></string-name></person-group>. <article-title>A neural mass model for meg/eeg:: coupling and neuronal dynamics</article-title>. <source>NeuroImage</source>, <volume>20</volume>(<issue>3</issue>):<fpage>1743</fpage> – <lpage>1755</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c84"><label>[84]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Anton A</given-names> <surname>Selivanov</surname></string-name>, <string-name><given-names>Judith</given-names> <surname>Lehnert</surname></string-name>, <string-name><given-names>Thomas</given-names> <surname>Dahms</surname></string-name>, <string-name><given-names>Philipp</given-names> <surname>Hövel</surname></string-name>, <string-name><given-names>Alexander L</given-names> <surname>Fradkov</surname></string-name>, and <string-name><given-names>Eckehard</given-names> <surname>Schöll</surname></string-name></person-group>. <article-title>Adaptive synchronization in delay-coupled networks of stuart-landau oscillators</article-title>. <source>Physical Review E–Statistical, Nonlinear, and Soft Matter Physics</source>, <volume>85</volume>(<issue>1</issue>):<fpage>016201</fpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c85"><label>[85]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Kong-Fatt</given-names> <surname>Wong</surname></string-name> and <string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name></person-group>. <article-title>A recurrent network mechanism of time integration in perceptual decisions</article-title>. <source>Journal of Neuroscience</source>, <volume>26</volume>(<issue>4</issue>):<fpage>1314</fpage>–<lpage>1328</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c86"><label>[86]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name>, <string-name><given-names>Adrián</given-names> <surname>Ponce-Alvarez</surname></string-name>, <string-name><given-names>Dante</given-names> <surname>Mantini</surname></string-name>, <string-name><given-names>Gian Luca</given-names> <surname>Romani</surname></string-name>, <string-name><given-names>Patric</given-names> <surname>Hagmann</surname></string-name>, and <string-name><given-names>Maurizio</given-names> <surname>Corbetta</surname></string-name></person-group>. <article-title>Resting-state functional connectivity emerges from structurally and dynamically shaped slow linear fluctuations</article-title>. <source>Journal of Neuroscience</source>, <volume>33</volume>(<issue>27</issue>):<fpage>11239</fpage>–<lpage>11252</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c87"><label>[87]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Benoit</given-names> <surname>Duchet</surname></string-name>, <string-name><given-names>Filippo</given-names> <surname>Ghezzi</surname></string-name>, <string-name><given-names>Gihan</given-names> <surname>Weerasinghe</surname></string-name>, <string-name><given-names>Gerd</given-names> <surname>Tinkhauser</surname></string-name>, <string-name><given-names>Andrea A</given-names> <surname>Kühn</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>Brown</surname></string-name>, <string-name><given-names>Christian</given-names> <surname>Bick</surname></string-name>, and <string-name><given-names>Rafal</given-names> <surname>Bogacz</surname></string-name></person-group>. <article-title>Average beta burst duration profiles provide a signature of dynamical changes between the on and off medication states in parkinson’s disease</article-title>. <source>PLoS computational biology</source>, <volume>17</volume>(<issue>7</issue>):<fpage>e1009116</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c88"><label>[88]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>James J</given-names> <surname>Sermon</surname></string-name>, <string-name><given-names>Maria</given-names> <surname>Olaru</surname></string-name>, <string-name><given-names>Juan</given-names> <surname>Anso</surname></string-name>, <string-name><given-names>Stephanie</given-names> <surname>Cernera</surname></string-name>, <string-name><given-names>Simon</given-names> <surname>Little</surname></string-name>, <string-name><given-names>Maria</given-names> <surname>Shcherbakova</surname></string-name>, <string-name><given-names>Rafal</given-names> <surname>Bogacz</surname></string-name>, <string-name><given-names>Philip A</given-names> <surname>Starr</surname></string-name>, <string-name><given-names>Timothy</given-names> <surname>Denison</surname></string-name>, and <string-name><given-names>Benoit</given-names> <surname>Duchet</surname></string-name></person-group>. <article-title>Sub-harmonic entrainment of cortical gamma oscillations to deep brain stimulation in parkinson’s disease: model based predictions and validation in three human subjects</article-title>. <source>Brain Stimulation</source>, <volume>16</volume>(<issue>5</issue>):<fpage>1412</fpage>–<lpage>1424</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c89"><label>[89]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alex</given-names> <surname>Pavlides</surname></string-name>, <string-name><given-names>S</given-names> <surname>John Hogan</surname></string-name>, and <string-name><given-names>Rafal</given-names> <surname>Bogacz</surname></string-name></person-group>. <article-title>Computational models describing possible mechanisms for generation of excessive beta oscillations in parkinson’s disease</article-title>. <source>PLoS computational biology</source>, <volume>11</volume>(<issue>12</issue>):<fpage>e1004609</fpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c90"><label>[90]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Wei</given-names> <surname>Wei</surname></string-name>, <string-name><given-names>Jonathan E</given-names> <surname>Rubin</surname></string-name>, and <string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name></person-group>. <article-title>Role of the indirect pathway of the basal ganglia in perceptual decision making</article-title>. <source>Journal of Neuroscience</source>, <volume>35</volume>(<issue>9</issue>):<fpage>4052</fpage>–<lpage>4064</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c91"><label>[91]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ben H</given-names> <surname>Jansen</surname></string-name> and <string-name><given-names>Vincent G</given-names> <surname>Rit</surname></string-name></person-group>. <article-title>Electroencephalogram and visual evoked potential generation in a mathematical model of coupled cortical columns</article-title>. <source>Biological cybernetics</source>, <volume>73</volume>(<issue>4</issue>):<fpage>357</fpage>–<lpage>366</lpage>, <year>1995</year>.</mixed-citation></ref>
<ref id="c92"><label>[92]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Olivier</given-names> <surname>David</surname></string-name>, <string-name><given-names>Stefan J.</given-names> <surname>Kiebel</surname></string-name>, <string-name><given-names>Lee M.</given-names> <surname>Harrison</surname></string-name>, <string-name><given-names>Jérémie</given-names> <surname>Mattout</surname></string-name>, <string-name><given-names>James M.</given-names> <surname>Kilner</surname></string-name>, and <string-name><given-names>Karl J.</given-names> <surname>Friston</surname></string-name></person-group>. <article-title>Dynamic causal modeling of evoked responses in eeg and meg</article-title>. <source>NeuroImage</source>, <volume>30</volume>(<issue>4</issue>):<fpage>1255</fpage> – <lpage>1272</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c93"><label>[93]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.J.</given-names> <surname>Moran</surname></string-name>, <string-name><given-names>S.J.</given-names> <surname>Kiebel</surname></string-name>, <string-name><given-names>K.E.</given-names> <surname>Stephan</surname></string-name>, <string-name><given-names>R.B.</given-names> <surname>Reilly</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Daunizeau</surname></string-name>, and <string-name><given-names>K.J.</given-names> <surname>Friston</surname></string-name></person-group>. <article-title>A neural mass model of spectral responses in electrophysiology</article-title>. <source>NeuroImage</source>, <volume>37</volume>(<issue>3</issue>):<fpage>706</fpage> – <lpage>720</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c94"><label>[94]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Fabrice</given-names> <surname>Wendling</surname></string-name>, <string-name><given-names>Fabrice</given-names> <surname>Bartolomei</surname></string-name>, <string-name><given-names>Jean-Jcques</given-names> <surname>Bellanger</surname></string-name>, and <string-name><given-names>Patrick</given-names> <surname>Chauvel</surname></string-name></person-group>. <article-title>Interpretation of interdependencies in epileptic signals using a macroscopic physiological model of the eeg</article-title>. <source>Clinical neurophysiology</source>, <volume>112</volume>(<issue>7</issue>):<fpage>1201</fpage>– <lpage>1218</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c95"><label>[95]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Sheida</given-names> <surname>Kazemi</surname></string-name> and <string-name><given-names>Yousef</given-names> <surname>Jamali</surname></string-name></person-group>. <article-title>On the influence of input triggering on the dynamics of the jansen-rit oscillators network</article-title>. <source>arXiv</source>:<elocation-id>2202.06634</elocation-id>, <year>2022</year>.</mixed-citation></ref>
<ref id="c96"><label>[96]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name>, <string-name><given-names>Morten L</given-names> <surname>Kringelbach</surname></string-name>, <string-name><given-names>Viktor K</given-names> <surname>Jirsa</surname></string-name>, and <string-name><given-names>Petra</given-names> <surname>Ritter</surname></string-name></person-group>. <article-title>The dynamics of resting fluctuations in the brain: metastability and its dynamical cortical core</article-title>. <source>Scientific reports</source>, <volume>7</volume>(<issue>1</issue>):<year>3095</year>, <fpage>2017</fpage>.</mixed-citation></ref>
<ref id="c97"><label>[97]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Spase</given-names> <surname>Petkoski</surname></string-name> and <string-name><given-names>Viktor K</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Transmission time delays organize the brain network synchronization</article-title>. <source>Philosophical Transactions of the Royal Society A</source>, <volume>377</volume>(<issue>2153</issue>):<fpage>20180132</fpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c98"><label>[98]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jean-Didier</given-names> <surname>Lemaréchal</surname></string-name>, <string-name><given-names>Maciej</given-names> <surname>Jedynak</surname></string-name>, <string-name><given-names>Lena</given-names> <surname>Trebaul</surname></string-name>, <string-name><given-names>Anthony</given-names> <surname>Boyer</surname></string-name>, <string-name><given-names>François</given-names> <surname>Tadel</surname></string-name>, <string-name><given-names>Manik</given-names> <surname>Bhattacharjee</surname></string-name>, <string-name><given-names>Pierre</given-names> <surname>Deman</surname></string-name>, <string-name><given-names>Viateur</given-names> <surname>Tuyisenge</surname></string-name>, <string-name><given-names>Leila</given-names> <surname>Ayoubian</surname></string-name>, <string-name><given-names>Etienne</given-names> <surname>Hugues</surname></string-name>, <etal>et al.</etal></person-group> <article-title>A brain atlas of axonal and synaptic delays based on modelling of cortico-cortical evoked potentials</article-title>. <source>Brain</source>, <volume>145</volume>(<issue>5</issue>):<fpage>1653</fpage>– <lpage>1667</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c99"><label>[99]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Pierpaolo</given-names> <surname>Sorrentino</surname></string-name>, <string-name><given-names>Spase</given-names> <surname>Petkoski</surname></string-name>, <string-name><given-names>Maddalena</given-names> <surname>Sparaco</surname></string-name>, <string-name><given-names>E</given-names> <surname>Troisi Lopez</surname></string-name>, <string-name><given-names>Elisabetta</given-names> <surname>Signoriello</surname></string-name>, <string-name><given-names>Fabio</given-names> <surname>Baselice</surname></string-name>, <string-name><given-names>Simona</given-names> <surname>Bonavita</surname></string-name>, <string-name><given-names>Maria Agnese</given-names> <surname>Pirozzi</surname></string-name>, <string-name><given-names>Mario</given-names> <surname>Quarantelli</surname></string-name>, <string-name><given-names>Giuseppe</given-names> <surname>Sorrentino</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Whole-brain propagation delays in multiple sclerosis, a combined tractography-magnetoencephalography study</article-title>. <source>Journal of Neuroscience</source>, <volume>42</volume>(<issue>47</issue>):<fpage>8807</fpage>–<lpage>8816</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c100"><label>[100]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Agnes P</given-names> <surname>Funk</surname></string-name> and <string-name><given-names>Charles M</given-names> <surname>Epstein</surname></string-name></person-group>. <article-title>Natural rhythm: evidence for occult 40 hz gamma oscillation in resting motor cortex</article-title>. <source>Neuroscience letters</source>, <volume>371</volume>(<issue>2-3</issue>):<fpage>181</fpage>–<lpage>184</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c101"><label>[101]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>György</given-names> <surname>Buzsáki</surname></string-name> and <string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name></person-group>. <article-title>Mechanisms of gamma oscillations</article-title>. <source>Annual review of neuroscience</source>, <volume>35</volume>(<issue>1</issue>):<fpage>203</fpage>–<lpage>225</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c102"><label>[102]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alfons</given-names> <surname>Schnitzler</surname></string-name> and <string-name><given-names>Joachim</given-names> <surname>Gross</surname></string-name></person-group>. <article-title>Normal and pathological oscillatory communication in the brain</article-title>. <source>Nature reviews neuroscience</source>, <volume>6</volume>(<issue>4</issue>):<fpage>285</fpage>–<lpage>296</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c103"><label>[103]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Maria Luisa</given-names> <surname>Saggio</surname></string-name>, <string-name><given-names>Dakota</given-names> <surname>Crisp</surname></string-name>, <string-name><given-names>Jared M</given-names> <surname>Scott</surname></string-name>, <string-name><given-names>Philippa</given-names> <surname>Karoly</surname></string-name>, <string-name><given-names>Levin</given-names> <surname>Kuhlmann</surname></string-name>, <string-name><given-names>Mitsuyoshi</given-names> <surname>Nakatani</surname></string-name>, <string-name><given-names>Tomohiko</given-names> <surname>Murai</surname></string-name>, <string-name><given-names>Matthias</given-names> <surname>DÃ¼mpelmann</surname></string-name>, <string-name><given-names>Andreas</given-names> <surname>Schulze-Bonhage</surname></string-name>, <string-name><given-names>Akio</given-names> <surname>Ikeda</surname></string-name>, <string-name><given-names>Mark</given-names> <surname>Cook</surname></string-name>, <string-name><given-names>Stephen V</given-names> <surname>Gliske</surname></string-name>, <string-name><given-names>Jack</given-names> <surname>Lin</surname></string-name>, <string-name><given-names>Christophe</given-names> <surname>Bernard</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name>, and <string-name><given-names>William C</given-names> <surname>Stacey</surname></string-name></person-group>. <article-title>A taxonomy of seizure dynamotypes</article-title>. <source>eLife</source>, <volume>9</volume>:<elocation-id>e55632</elocation-id>, <month>jul</month> <year>2020</year>. <pub-id pub-id-type="doi">10.7554/eLife.55632</pub-id></mixed-citation></ref>
<ref id="c104"><label>[104]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Herman</given-names> <surname>Haken</surname></string-name></person-group>. <article-title>Synergetics</article-title>. <source>Physics Bulletin</source>, <volume>28</volume>(<issue>9</issue>):<fpage>412</fpage>, <year>1977</year>.</mixed-citation></ref>
<ref id="c105"><label>[105]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Viktor K</given-names> <surname>Jirsa</surname></string-name> and <string-name><given-names>Hermann</given-names> <surname>Haken</surname></string-name></person-group>. <article-title>A derivation of a macroscopic field theory of the brain from the quasi-microscopic neural dynamics</article-title>. <source>Physica D: Nonlinear Phenomena</source>, <volume>99</volume>(<issue>4</issue>):<fpage>503</fpage>–<lpage>526</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c106"><label>[106]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Timothée</given-names> <surname>Proix</surname></string-name>, <string-name><given-names>Fabrice</given-names> <surname>Bartolomei</surname></string-name>, <string-name><given-names>Patrick</given-names> <surname>Chauvel</surname></string-name>, <string-name><given-names>Christophe</given-names> <surname>Bernard</surname></string-name>, and <string-name><given-names>Viktor K.</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Permittivity coupling across brain regions determines seizure recruitment in partial epilepsy</article-title>. <source>Journal of Neuroscience</source>, <volume>34</volume>(<issue>45</issue>):<fpage>15009</fpage>– <lpage>15021</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c107"><label>[107]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Anthony R.</given-names> <surname>McIntosh</surname></string-name> and <string-name><given-names>Viktor K.</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>The hidden repertoire of brain dynamics and dysfunction</article-title>. <source>Network Neuroscience</source>, <volume>3</volume>(<issue>4</issue>):<fpage>994</fpage>–<lpage>1008</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c108"><label>[108]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Áine</given-names> <surname>Byrne</surname></string-name>, <string-name><given-names>Reuben D</given-names> <surname>O’Dea</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Forrester</surname></string-name>, <string-name><given-names>James</given-names> <surname>Ross</surname></string-name>, and <string-name><given-names>Stephen</given-names> <surname>Coombes</surname></string-name></person-group>. <article-title>Next-generation neural mass and field modeling</article-title>. <source>Journal of neurophysiology</source>, <volume>123</volume>(<issue>2</issue>):<fpage>726</fpage>–<lpage>742</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c109"><label>[109]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Giovanni</given-names> <surname>Rabuffo</surname></string-name>, <string-name><given-names>Jan</given-names> <surname>Fousek</surname></string-name>, <string-name><given-names>Christophe</given-names> <surname>Bernard</surname></string-name>, and <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Neuronal cascades shape whole-brain functional dynamics at rest</article-title>. <source>ENeuro</source>, <volume>8</volume>(<issue>5</issue>), <year>2021</year>.</mixed-citation></ref>
<ref id="c110"><label>[110]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Jan</given-names> <surname>Fousek</surname></string-name>, <string-name><given-names>Giovanni</given-names> <surname>Rabuffo</surname></string-name>, <string-name><given-names>Kashyap</given-names> <surname>Gudibanda</surname></string-name>, <string-name><given-names>Hiba</given-names> <surname>Sheheitli</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name>, and <string-name><given-names>Spase</given-names> <surname>Petkoski</surname></string-name></person-group>. <article-title>The structured flow on the brain’s resting state manifold</article-title>. <source>bioRxiv</source>, <year>2022</year>.</mixed-citation></ref>
<ref id="c111"><label>[111]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>M</given-names> <surname>Breyton</surname></string-name>, <string-name><given-names>J</given-names> <surname>Fousek</surname></string-name>, <string-name><given-names>G</given-names> <surname>Rabuffo</surname></string-name>, <string-name><given-names>P</given-names> <surname>Sorrentino</surname></string-name>, <string-name><given-names>L</given-names> <surname>Kusch</surname></string-name>, <string-name><given-names>M</given-names> <surname>Massimini</surname></string-name>, <string-name><given-names>S</given-names> <surname>Petkoski</surname></string-name>, and <string-name><given-names>V</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Spatiotemporal brain complexity quantifies consciousness outside of perturbation paradigms</article-title>. <source>bioRxiv</source>, pages 2023–04, <year>2023</year>.</mixed-citation></ref>
<ref id="c112"><label>[112]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jan</given-names> <surname>Fousek</surname></string-name>, <string-name><given-names>Giovanni</given-names> <surname>Rabuffo</surname></string-name>, <string-name><given-names>Kashyap</given-names> <surname>Gudibanda</surname></string-name>, <string-name><given-names>Hiba</given-names> <surname>Sheheitli</surname></string-name>, <string-name><given-names>Spase</given-names> <surname>Petkoski</surname></string-name>, and <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Symmetry breaking organizes the brain’s resting state manifold</article-title>. <source>Scientific Reports</source>, <volume>14</volume>(<issue>1</issue>):<fpage>31970</fpage>, <year>2024</year>.</mixed-citation></ref>
<ref id="c113"><label>[113]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Karl J</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>Andrea</given-names> <surname>Mechelli</surname></string-name>, <string-name><given-names>Robert</given-names> <surname>Turner</surname></string-name>, and <string-name><given-names>Cathy J</given-names> <surname>Price</surname></string-name></person-group>. <article-title>Nonlinear responses in fmri: the balloon model, volterra kernels, and other hemodynamics</article-title>. <source>NeuroImage</source>, <volume>12</volume>(<issue>4</issue>):<fpage>466</fpage>–<lpage>477</lpage>, <year>2000</year>.</mixed-citation></ref>
<ref id="c114"><label>[114]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Enrique C.A.</given-names> <surname>Hansen</surname></string-name>, <string-name><given-names>Demian</given-names> <surname>Battaglia</surname></string-name>, <string-name><given-names>Andreas</given-names> <surname>Spiegler</surname></string-name>, <string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name>, and <string-name><given-names>Viktor K.</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Functional connectivity dynamics: Modeling the switching behavior of the resting state</article-title>. <source>NeuroImage</source>, <volume>105</volume>:<fpage>525</fpage> – <lpage>535</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c115"><label>[115]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gustavo</given-names> <surname>Deco</surname></string-name>, <string-name><given-names>Morten L</given-names> <surname>Kringelbach</surname></string-name>, <string-name><given-names>Aurina</given-names> <surname>Arnatkeviciute</surname></string-name>, <string-name><given-names>Stuart</given-names> <surname>Oldham</surname></string-name>, <string-name><given-names>Kristina</given-names> <surname>Sabaroedin</surname></string-name>, <string-name><given-names>Nigel C</given-names> <surname>Rogasch</surname></string-name>, <string-name><given-names>Kevin M</given-names> <surname>Aquino</surname></string-name>, and <string-name><given-names>Alex</given-names> <surname>Fornito</surname></string-name></person-group>. <article-title>Dynamical consequences of regional heterogeneity in the brain’s transcriptional landscape</article-title>. <source>Science Advances</source>, <volume>7</volume>(<issue>29</issue>):<fpage>eabf4752</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c116"><label>[116]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Anita</given-names> <surname>Monteverdi</surname></string-name>, <string-name><given-names>Fulvia</given-names> <surname>Palesi</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Schirner</surname></string-name>, <string-name><given-names>Francesca</given-names> <surname>Argentino</surname></string-name>, <string-name><given-names>Mariateresa</given-names> <surname>Merante</surname></string-name>, <string-name><given-names>Alberto</given-names> <surname>Redolfi</surname></string-name>, <string-name><given-names>Francesca</given-names> <surname>Conca</surname></string-name>, <string-name><given-names>Laura</given-names> <surname>Mazzocchi</surname></string-name>, <string-name><given-names>Stefano F</given-names> <surname>Cappa</surname></string-name>, <string-name><given-names>Matteo Cotta</given-names> <surname>Ramusino</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Virtual brain simulations reveal network-specific parameters in neurodegenerative dementias</article-title>. <source>Frontiers in Aging Neuroscience</source>, <volume>15</volume>:<fpage>1204134</fpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c117"><label>[117]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Pedro Costa</given-names> <surname>Klein</surname></string-name>, <string-name><given-names>Ulrich</given-names> <surname>Ettinger</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Schirner</surname></string-name>, <string-name><given-names>Petra</given-names> <surname>Ritter</surname></string-name>, <string-name><given-names>Dan</given-names> <surname>Rujescu</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>Falkai</surname></string-name>, <string-name><given-names>Nikolaos</given-names> <surname>Koutsouleris</surname></string-name>, <string-name><given-names>Lana</given-names> <surname>Kambeitz-Ilankovic</surname></string-name>, and <string-name><given-names>Joseph</given-names> <surname>Kambeitz</surname></string-name></person-group>. <article-title>Brain network simulations indicate effects of neuregulin-1 genotype on excitation-inhibition balance in cortical dynamics</article-title>. <source>Cerebral Cortex</source>, <volume>31</volume>(<issue>4</issue>):<fpage>2013</fpage>–<lpage>2025</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c118"><label>[118]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Pedro Costa</given-names> <surname>Klein</surname></string-name>, <string-name><given-names>Ulrich</given-names> <surname>Ettinger</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Schirner</surname></string-name>, <string-name><given-names>Petra</given-names> <surname>Ritter</surname></string-name>, <string-name><given-names>Dan</given-names> <surname>Rujescu</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>Falkai</surname></string-name>, <string-name><given-names>Nikolaos</given-names> <surname>Koutsouleris</surname></string-name>, <string-name><given-names>Lana</given-names> <surname>Kambeitz-Ilankovic</surname></string-name>, and <string-name><given-names>Joseph</given-names> <surname>Kambeitz</surname></string-name></person-group>. <article-title>Brain network simulations indicate effects of neuregulin-1 genotype on excitation-inhibition balance in cortical dynamics</article-title>. <source>Cerebral Cortex</source>, <volume>31</volume>(<issue>4</issue>):<fpage>2013</fpage>–<lpage>2025</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c119"><label>[119]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Matthew F</given-names> <surname>Glasser</surname></string-name> and <string-name><given-names>David C</given-names> <surname>Van Essen</surname></string-name></person-group>. <article-title>Mapping human cortical areas in vivo based on myelin content as revealed by t1-and t2-weighted mri</article-title>. <source>Journal of neuroscience</source>, <volume>31</volume>(<issue>32</issue>):<fpage>11597</fpage>–<lpage>11616</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c120"><label>[120]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Klaas Enno</given-names> <surname>Stephan</surname></string-name>, <string-name><given-names>Nikolaus</given-names> <surname>Weiskopf</surname></string-name>, <string-name><given-names>Peter M</given-names> <surname>Drysdale</surname></string-name>, <string-name><given-names>Peter A</given-names> <surname>Robinson</surname></string-name>, and <string-name><given-names>Karl J</given-names> <surname>Friston</surname></string-name></person-group>. <article-title>Comparing hemodynamic models with dcm</article-title>. <source>Neuroimage</source>, <volume>38</volume>(<issue>3</issue>):<fpage>387</fpage>–<lpage>401</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c121"><label>[121]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Klaas Enno</given-names> <surname>Stephan</surname></string-name>, <string-name><given-names>Lars</given-names> <surname>Kasper</surname></string-name>, <string-name><given-names>Lee M</given-names> <surname>Harrison</surname></string-name>, <string-name><given-names>Jean</given-names> <surname>Daunizeau</surname></string-name>, <string-name><given-names>Hanneke EM</given-names> <surname>den Ouden</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Breakspear</surname></string-name>, and <string-name><given-names>Karl J</given-names> <surname>Friston</surname></string-name></person-group>. <article-title>Nonlinear dynamic causal models for fmri</article-title>. <source>Neuroimage</source>, <volume>42</volume>(<issue>2</issue>):<fpage>649</fpage>–<lpage>662</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c122"><label>[122]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Rens</given-names> <surname>van de Schoot</surname></string-name>, <string-name><given-names>Sarah</given-names> <surname>Depaoli</surname></string-name>, <string-name><given-names>Ruth</given-names> <surname>King</surname></string-name>, <string-name><given-names>Bianca</given-names> <surname>Kramer</surname></string-name>, <string-name><given-names>Kaspar</given-names> <surname>Märtens</surname></string-name>, <string-name><given-names>Mahlet G</given-names> <surname>Tadesse</surname></string-name>, <string-name><given-names>Marina</given-names> <surname>Vannucci</surname></string-name>, <string-name><given-names>Andrew</given-names> <surname>Gelman</surname></string-name>, <string-name><given-names>Duco</given-names> <surname>Veen</surname></string-name>, <string-name><given-names>Joukje</given-names> <surname>Willemsen</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Bayesian statistics and modelling</article-title>. <source>Nature Reviews Methods Primers</source>, <volume>1</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>26</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c123"><label>[123]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jayant</given-names> <surname>Jha</surname></string-name>, <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Anirudh Nihalani</given-names> <surname>Vattikonda</surname></string-name>, <string-name><given-names>Huifang</given-names> <surname>Wang</surname></string-name>, and <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Fully bayesian estimation of virtual brain parameters with self-tuning hamiltonian monte carlo</article-title>. <source>Machine Learning: Science and Technology</source>, <volume>3</volume>(<issue>3</issue>):<fpage>035016</fpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c124"><label>[124]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>George</given-names> <surname>Papamakarios</surname></string-name>, <string-name><given-names>David</given-names> <surname>Sterratt</surname></string-name>, and <string-name><given-names>Iain</given-names> <surname>Murray</surname></string-name></person-group>. <article-title>Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows</article-title>. In <conf-name>The 22nd International Conference on Artificial Intelligence and Statistics</conf-name>, pages <fpage>837</fpage>–<lpage>848</lpage>. <publisher-name>PMLR</publisher-name>, <year>2019</year>.</mixed-citation></ref>
<ref id="c125"><label>[125]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>David</given-names> <surname>Greenberg</surname></string-name>, <string-name><given-names>Marcel</given-names> <surname>Nonnenmacher</surname></string-name>, and <string-name><given-names>Jakob</given-names> <surname>Macke</surname></string-name></person-group>. <article-title>Automatic posterior transformation for likelihood-free inference</article-title>. In <conf-name>International Conference on Machine Learning</conf-name>, pages <fpage>2404</fpage>–<lpage>2414</lpage>. <publisher-name>PMLR</publisher-name>, <year>2019</year>.</mixed-citation></ref>
<ref id="c126"><label>[126]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Johann</given-names> <surname>Brehmer</surname></string-name>, <string-name><given-names>Gilles</given-names> <surname>Louppe</surname></string-name>, <string-name><given-names>Juan</given-names> <surname>Pavez</surname></string-name>, and <string-name><given-names>Kyle</given-names> <surname>Cranmer</surname></string-name></person-group>. <article-title>Mining gold from implicit models to improve likelihood-free inference</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>117</volume>(<issue>10</issue>):<fpage>5242</fpage>–<lpage>5249</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c127"><label>[127]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>Danilo</given-names> <surname>Rezende</surname></string-name> and <string-name><given-names>Shakir</given-names> <surname>Mohamed</surname></string-name></person-group>. <article-title>Variational inference with normalizing flows</article-title>. In <conf-name>International conference on machine learning (ICML)</conf-name>, pages <fpage>1530</fpage>–<lpage>1538</lpage>. <publisher-name>PMLR</publisher-name>, <year>2015</year>.</mixed-citation></ref>
<ref id="c128"><label>[128]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>George</given-names> <surname>Papamakarios</surname></string-name>, <string-name><given-names>Eric</given-names> <surname>Nalisnick</surname></string-name>, <string-name><given-names>Danilo Jimenez</given-names> <surname>Rezende</surname></string-name>, <string-name><given-names>Shakir</given-names> <surname>Mohamed</surname></string-name>, and <string-name><given-names>Balaji</given-names> <surname>Lakshminarayanan</surname></string-name></person-group>. <article-title>Normalizing flows for probabilistic modeling and inference</article-title>. <source>arXiv</source> preprint arXiv:<pub-id pub-id-type="arxiv">1912.02762</pub-id>, <year>2019</year>.</mixed-citation></ref>
<ref id="c129"><label>[129]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ivan</given-names> <surname>Kobyzev</surname></string-name>, <string-name><given-names>Simon</given-names> <surname>Prince</surname></string-name>, and <string-name><given-names>Marcus</given-names> <surname>Brubaker</surname></string-name></person-group>. <article-title>Normalizing flows: An introduction and review of current methods</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>, <year>2020</year>.</mixed-citation></ref>
<ref id="c130"><label>[130]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Caglar</given-names> <surname>Cakan</surname></string-name>, <string-name><given-names>Nikola</given-names> <surname>Jajcay</surname></string-name></person-group>, <article-title>and Klaus Obermayer. neurolib: A simulation framework for whole-brain neural mass modeling</article-title>. <source>Cognitive Computation</source>, <month>Oct</month> <year>2021</year>.</mixed-citation></ref>
<ref id="c131"><label>[131]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Marcel</given-names> <surname>Stimberg</surname></string-name>, <string-name><given-names>Romain</given-names> <surname>Brette</surname></string-name>, and <string-name><given-names>Dan FM</given-names> <surname>Goodman</surname></string-name></person-group>. <article-title>Brian 2, an intuitive and efficient neural simulator</article-title>. <source>eLife</source>, <volume>8</volume>:<elocation-id>e47314</elocation-id>, <year>2019</year>. <pub-id pub-id-type="doi">10.7554/eLife.47314</pub-id></mixed-citation></ref>
<ref id="c132"><label>[132]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Chaoming</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Tianqiu</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Xiaoyu</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Sichao</given-names> <surname>He</surname></string-name>, <string-name><given-names>Shangyang</given-names> <surname>Li</surname></string-name>, and <string-name><given-names>Si</given-names> <surname>Wu</surname></string-name></person-group>. <article-title>Brainpy, a flexible, integrative, efficient, and extensible framework for general-purpose brain dynamics programming</article-title>. <source>eLife</source>, <volume>12</volume>:<elocation-id>e86365</elocation-id>, <year>2023</year>. <pub-id pub-id-type="doi">10.7554/eLife.86365</pub-id></mixed-citation></ref>
<ref id="c133"><label>[133]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Marília</given-names> <surname>Barandas</surname></string-name>, <string-name><given-names>Duarte</given-names> <surname>Folgado</surname></string-name>, <string-name><given-names>Letícia</given-names> <surname>Fernandes</surname></string-name>, <string-name><given-names>Sara</given-names> <surname>Santos</surname></string-name>, <string-name><given-names>Mariana</given-names> <surname>Abreu</surname></string-name>, <string-name><given-names>Patrícia</given-names> <surname>Bota</surname></string-name>, <string-name><given-names>Hui</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Tanja</given-names> <surname>Schultz</surname></string-name>, and <string-name><given-names>Hugo</given-names> <surname>Gamboa</surname></string-name></person-group>. <article-title>Tsfel: Time series feature extraction library</article-title>. <source>SoftwareX</source>, <volume>11</volume>:<issue>100456</issue>, <year>2020</year>.</mixed-citation></ref>
<ref id="c134"><label>[134]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Oliver M</given-names> <surname>Cliff</surname></string-name>, <string-name><given-names>Annie G</given-names> <surname>Bryant</surname></string-name>, <string-name><given-names>Joseph T</given-names> <surname>Lizier</surname></string-name>, <string-name><given-names>Naotsugu</given-names> <surname>Tsuchiya</surname></string-name>, and <string-name><given-names>Ben D</given-names> <surname>Fulcher</surname></string-name></person-group>. <article-title>Unifying pairwise interactions in complex dynamics</article-title>. <source>Nature Computational Science</source>, <volume>3</volume>(<issue>10</issue>):<fpage>883</fpage>–<lpage>893</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c135"><label>[135]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ben D</given-names> <surname>Fulcher</surname></string-name> and <string-name><given-names>Nick S</given-names> <surname>Jones</surname></string-name></person-group>. <article-title>hctsa: A computational framework for automated time-series phenotyping using massive feature extraction</article-title>. <source>Cell systems</source>, <volume>5</volume>(<issue>5</issue>):<fpage>527</fpage>–<lpage>531</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c136"><label>[136]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F.</given-names> <surname>Pedregosa</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Varoquaux</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Gramfort</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Michel</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Thirion</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Grisel</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Blondel</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Prettenhofer</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Weiss</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Dubourg</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Vanderplas</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Passos</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Cournapeau</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Brucher</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Perrot</surname></string-name>, and <string-name><given-names>E.</given-names> <surname>Duchesnay</surname></string-name></person-group>. <article-title>Scikit-learn: Machine learning in Python</article-title>. <source>Journal of Machine Learning Research</source>, <volume>12</volume>:<fpage>2825</fpage>–<lpage>2830</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c137"><label>[137]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Carl H</given-names> <surname>Lubba</surname></string-name>, <string-name><given-names>Sarab S</given-names> <surname>Sethi</surname></string-name>, <string-name><given-names>Philip</given-names> <surname>Knaute</surname></string-name>, <string-name><given-names>Simon R</given-names> <surname>Schultz</surname></string-name>, <string-name><given-names>Ben D</given-names> <surname>Fulcher</surname></string-name>, and <string-name><given-names>Nick S</given-names> <surname>Jones</surname></string-name></person-group>. <article-title>catch22: Canonical time-series characteristics: Selected through highly comparative time-series analysis</article-title>. <source>Data Mining and Knowledge Discovery</source>, <volume>33</volume>(<issue>6</issue>):<fpage>1821</fpage>–<lpage>1852</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c138"><label>[138]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Paul</given-names> <surname>Triebkorn</surname></string-name>, <string-name><given-names>Leon</given-names> <surname>Stefanovski</surname></string-name>, <string-name><given-names>Kiret</given-names> <surname>Dhindsa</surname></string-name>, <string-name><given-names>Margarita-Arimatea Diaz-</given-names> <surname>Cortes</surname></string-name>, <string-name><given-names>Patrik</given-names> <surname>Bey</surname></string-name>, <string-name><given-names>Konstantin</given-names> <surname>Bülau</surname></string-name>, <string-name><given-names>Roopa</given-names> <surname>Pai</surname></string-name>, <string-name><given-names>Andreas</given-names> <surname>Spiegler</surname></string-name>, <string-name><given-names>Ana</given-names> <surname>Solodkin</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Brain simulation augments machine-learning– based classification of dementia</article-title>. <source>Alzheimer’s &amp; Dementia: Translational Research &amp; Clinical Interventions</source>, <volume>8</volume>(<issue>1</issue>):<fpage>e12303</fpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c139"><label>[139]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Leon</given-names> <surname>Stefanovski</surname></string-name>, <string-name><given-names>Paul</given-names> <surname>Triebkorn</surname></string-name>, <string-name><given-names>Andreas</given-names> <surname>Spiegler</surname></string-name>, <string-name><given-names>Margarita-Arimatea Diaz-</given-names> <surname>Cortes</surname></string-name>, <string-name><given-names>Ana</given-names> <surname>Solodkin</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name>, <string-name><given-names>Anthony Randal</given-names> <surname>McIntosh</surname></string-name>, <string-name><given-names>Petra</given-names> <surname>Ritter</surname></string-name></person-group>, <article-title>and Alzheimer’s Disease Neuroimaging Initiative</article-title>. <source>Linking molecular pathways and large-scale computational modeling to assess candidate disease mechanisms and pharmacodynamics in alzheimer’s disease. Frontiers in computational neuroscience</source>, <volume>13</volume>:<fpage>54</fpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c140"><label>[140]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mark A.</given-names> <surname>Beaumont</surname></string-name>, <string-name><given-names>Wenyang</given-names> <surname>Zhang</surname></string-name>, and <string-name><given-names>David J.</given-names> <surname>Balding</surname></string-name></person-group>. <article-title>Approximate bayesian computation in population genetics</article-title>. <source>Genetics</source>, <volume>162</volume>(<issue>4</issue>):<fpage>2025</fpage>–<lpage>2035</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c141"><label>[141]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mark A</given-names> <surname>Beaumont</surname></string-name></person-group>. <article-title>Approximate bayesian computation in evolution and ecology</article-title>. <source>Annual review of ecology, evolution, and systematics</source>, <volume>41</volume>:<fpage>379</fpage>–<lpage>406</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c142"><label>[142]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>S.A.</given-names> <surname>Sisson</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Fan</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Beaumont</surname></string-name></person-group>. <source>Handbook of Approximate Bayesian Computation</source>. <publisher-name>Chapman &amp; Hall/CRC handbooks of modern statistical methods. CRC Press, Taylor &amp; Francis Group</publisher-name>, <year>2018</year>.</mixed-citation></ref>
<ref id="c143"><label>[143]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Nina</given-names> <surname>Baldy</surname></string-name>, <string-name><given-names>Nicolas</given-names> <surname>Simon</surname></string-name>, <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name>, and <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name></person-group>. <article-title>Hierarchical bayesian pharmacometrics analysis of baclofen for alcohol use disorder</article-title>. <source>Machine Learning: Science and Technology</source>, <year>2023</year>.</mixed-citation></ref>
<ref id="c144"><label>[144]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>Jan-Matthis</given-names> <surname>Lueckmann</surname></string-name>, <string-name><given-names>Giacomo</given-names> <surname>Bassetto</surname></string-name>, <string-name><given-names>Theofanis</given-names> <surname>Karaletsos</surname></string-name>, and <string-name><given-names>Jakob H</given-names> <surname>Macke</surname></string-name></person-group>. <article-title>Likelihood-free inference with emulator networks</article-title>. In <conf-name>Symposium on Advances in Approximate Bayesian Inference, pages</conf-name> <fpage>32</fpage>–<lpage>53</lpage>. <publisher-name>PMLR</publisher-name>, <year>2019</year>.</mixed-citation></ref>
<ref id="c145"><label>[145]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>Conor</given-names> <surname>Durkan</surname></string-name>, <string-name><given-names>Iain</given-names> <surname>Murray</surname></string-name>, and <string-name><given-names>George</given-names> <surname>Papamakarios</surname></string-name></person-group>. <article-title>On contrastive learning for likelihood-free inference</article-title>. In <conf-name>International Conference on Machine Learning</conf-name>, pages <fpage>2771</fpage>–<lpage>2781</lpage>. <publisher-name>PMLR</publisher-name>, <year>2020</year>.</mixed-citation></ref>
<ref id="c146"><label>[146]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>Jan-Matthis</given-names> <surname>Lueckmann</surname></string-name>, <string-name><given-names>Jan</given-names> <surname>Boelts</surname></string-name>, <string-name><given-names>David</given-names> <surname>Greenberg</surname></string-name>, <string-name><given-names>Pedro</given-names> <surname>Goncalves</surname></string-name>, and <string-name><given-names>Jakob</given-names> <surname>Macke</surname></string-name></person-group>. <article-title>Benchmarking simulation-based inference</article-title>. In <conf-name>International Conference on Artificial Intelligence and Statistics</conf-name>, pages <fpage>343</fpage>–<lpage>351</lpage>. <publisher-name>PMLR</publisher-name>, <year>2021</year>.</mixed-citation></ref>
<ref id="c147"><label>[147]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W.D.</given-names> <surname>Penny</surname></string-name>, <string-name><given-names>K.E.</given-names> <surname>Stephan</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Mechelli</surname></string-name>, and <string-name><given-names>K.J.</given-names> <surname>Friston</surname></string-name></person-group>. <article-title>Comparing dynamic causal models</article-title>. <source>NeuroImage</source>, <volume>22</volume>(<issue>3</issue>):<fpage>1157</fpage> – <lpage>1172</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c148"><label>[148]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W.D.</given-names> <surname>Penny</surname></string-name></person-group>. <article-title>Comparing dynamic causal models using aic, bic and free energy</article-title>. <source>NeuroImage</source>, <volume>59</volume>(<issue>1</issue>):<fpage>319</fpage> – <lpage>330</lpage>, <year>2012</year>. Neuroergonomics: The human brain in action and at work.</mixed-citation></ref>
<ref id="c149"><label>[149]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Durk P</given-names> <surname>Kingma</surname></string-name>, <string-name><given-names>Shakir</given-names> <surname>Mohamed</surname></string-name>, <string-name><given-names>Danilo Jimenez</given-names> <surname>Rezende</surname></string-name>, and <string-name><given-names>Max</given-names> <surname>Welling</surname></string-name></person-group>. <article-title>Semi-supervised learning with deep generative models</article-title>. <source>Advances in neural information processing systems</source>, <volume>27</volume>, <year>2014</year>.</mixed-citation></ref>
<ref id="c150"><label>[150]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Carl</given-names> <surname>Doersch</surname></string-name></person-group>. <article-title>Tutorial on variational autoencoders</article-title>. <source>arXiv</source>:<elocation-id>1606.05908</elocation-id>, <year>2016</year>.</mixed-citation></ref>
<ref id="c151"><label>[151]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Viktor</given-names> <surname>Sip</surname></string-name>, <string-name><given-names>Meysam</given-names> <surname>Hashemi</surname></string-name>, <string-name><given-names>Timo</given-names> <surname>Dickscheid</surname></string-name>, <string-name><given-names>Katrin</given-names> <surname>Amunts</surname></string-name>, <string-name><given-names>Spase</given-names> <surname>Petkoski</surname></string-name>, and <string-name><given-names>Viktor</given-names> <surname>Jirsa</surname></string-name></person-group>. <article-title>Characterization of regional differences in resting-state fmri with a data-driven network model of brain dynamics</article-title>. <source>Science Advances</source>, <volume>9</volume>(<issue>11</issue>):<fpage>eabq7547</fpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c152"><label>[152]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ian</given-names> <surname>Goodfellow</surname></string-name>, <string-name><given-names>Jean</given-names> <surname>Pouget-Abadie</surname></string-name>, <string-name><given-names>Mehdi</given-names> <surname>Mirza</surname></string-name>, <string-name><given-names>Bing</given-names> <surname>Xu</surname></string-name>, <string-name><given-names>David Warde-</given-names> <surname>Farley</surname></string-name>, <string-name><given-names>Sherjil</given-names> <surname>Ozair</surname></string-name>, <string-name><given-names>Aaron</given-names> <surname>Courville</surname></string-name>, and <string-name><given-names>Yoshua</given-names> <surname>Bengio</surname></string-name></person-group>. <article-title>Generative adversarial nets</article-title>. <source>Advances in neural information processing systems</source>, <volume>27</volume>, <year>2014</year>.</mixed-citation></ref>
<ref id="c153"><label>[153]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Antonia</given-names> <surname>Creswell</surname></string-name>, <string-name><given-names>Tom</given-names> <surname>White</surname></string-name>, <string-name><given-names>Vincent</given-names> <surname>Dumoulin</surname></string-name>, <string-name><given-names>Kai</given-names> <surname>Arulkumaran</surname></string-name>, <string-name><given-names>Biswa</given-names> <surname>Sengupta</surname></string-name>, and <string-name><given-names>Anil A</given-names> <surname>Bharath</surname></string-name></person-group>. <article-title>Generative adversarial networks: An overview</article-title>. <source>IEEE signal processing magazine</source>, <volume>35</volume>(<issue>1</issue>):<fpage>53</fpage>–<lpage>65</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c154"><label>[154]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Qiao</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Jiaze</given-names> <surname>Xu</surname></string-name>, <string-name><given-names>Rui</given-names> <surname>Jiang</surname></string-name>, and <string-name><given-names>Wing Hung</given-names> <surname>Wong</surname></string-name></person-group>. <article-title>Density estimation using deep generative neural networks</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>118</volume>(<issue>15</issue>):<fpage>e2101344118</fpage>, <year>2021</year>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106194.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Fornito</surname>
<given-names>Alex</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Monash University</institution>
</institution-wrap>
<city>Clayton</city>
<country>Australia</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This paper presents a <bold>valuable</bold> software package, named &quot;Virtual Brain Inference&quot; (VBI), that enables faster and more efficient inference of parameters in dynamical system models of whole-brain activity, grounded in artificial network networks for Bayesian statistical inference. The authors have provided <bold>solid</bold> evidence, across several case studies, for the utility and validity of the methods using simulated data from several commonly used models, but more thorough benchmarking could be used to demonstrate the reliability, generalizability, and practical utility of the toolkit. This work will be of interest to computational neuroscientists interested in modelling large-scale brain dynamics.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106194.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This work provides a new Python toolkit for combining generative modeling of neural dynamics and inversion methods to infer likely model parameters that explain empirical neuroimaging data. The authors provided tests to show the toolkit's broad applicability and accuracy; hence, it will be very useful for people interested in using computational approaches to better understand the brain.</p>
<p>Strengths:</p>
<p>The work's primary strength is the tool's integrative nature, which seamlessly combines forward modelling with backward inference. This is important as available tools in the literature can only do one and not the other, which limits their accessibility to neuroscientists with limited computational expertise. Another strength of the paper is the demonstration of how the tool can be applied to a broad range of computational models popularly used in the field to interrogate diverse neuroimaging data, ensuring that the methodology is not optimal to only one model. Moreover, through extensive in-silico testing, the work provided evidence that the tool can accurately infer ground-truth parameters, which is important to ensure results from future hypothesis testing are meaningful.</p>
<p>Weaknesses:</p>
<p>Although the tool itself is the main strength of the work, the paper lacked a thorough analysis of issues concerning robustness and benchmarking relative to existing tools.</p>
<p>The first issue is the robustness to the choice of features to be included in the objective function. This choice significantly affects the training and changes the results, as the authors even acknowledged themselves multiple times (e.g., Page 17 last sentence of first paragraph or Page 19 first sentence of second paragraph). This brings the question of whether the accurate results found in the various demonstrations are due to the biased selection of features (possibly from priors on what worked in previous works). The robustness of the neural estimator and the inference method to noise was also not demonstrated. This is important as most neuroimaging measurements are inherently noisy to various degrees.</p>
<p>The second issue is on benchmarking. Because the tool developed is, in principle, only a combination of existing tools specific to modeling or Bayesian inference, the work failed to provide a more compelling demonstration of its added value. This could have been demonstrated through appropriate benchmarking relative to existing methodologies, specifically in terms of accuracy and computational efficiency.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106194.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Whole-brain network modeling is a common type of dynamical systems-based method to create individualized models of brain activity incorporating subject-specific structural connectome inferred from diffusion imaging data. This type of model has often been used to infer biophysical parameters of the individual brain that cannot be directly measured using neuroimaging but may be relevant to specific cognitive functions or diseases. Here, Ziaeemehr et al introduce a new toolkit, named &quot;Virtual Brain Inference&quot; (VBI), offering a new computational approach for estimating these parameters using Bayesian inference powered by artificial neural networks. The basic idea is to use simulated data, given known parameters, to train artificial neural networks to solve the inverse problem, namely, to infer the posterior distribution over the parameter space given data-derived features. The authors have demonstrated the utility of the toolkit using simulated data from several commonly used whole-brain network models in case studies.</p>
<p>Strengths:</p>
<p>(1) Model inversion is an important problem in whole-brain network modeling. The toolkit presents a significant methodological step up from common practices, with the potential to broadly impact how the community infers model parameters.</p>
<p>(2) Notably, the method allows the estimation of the posterior distribution of parameters instead of a point estimation, which provides information about the uncertainty of the estimation, which is generally lacking in existing methods.</p>
<p>(3) The case studies were able to demonstrate the detection of degeneracy in the parameters, which is important. Degeneracy is quite common in this type of model. If not handled mindfully, they may lead to spurious or stable parameter estimation. Thus, the toolkit can potentially be used to improve feature selection or to simply indicate the uncertainty.</p>
<p>(4) In principle, the posterior distribution can be directly computed given new data without doing any additional simulation, which could improve the efficiency of parameter inference on the artificial neural network if well-trained.</p>
<p>Weaknesses:</p>
<p>(1) While the posterior estimator was trained with a large quantity of simulated data, the testing/validation is only demonstrated with a single case study (one point in parameter space) per model. This is not sufficient to demonstrate the method's accuracy and reliability, but only its feasibility. Demonstrating the accuracy and reliability of the posterior estimation in large test sets would inspire more confidence.</p>
<p>(2) The authors have only demonstrated validation of the method using simulated data, but not features derived from actual EEG/MEG or fMRI data. So, it is unclear if the posterior estimator, when applied to real data, would produce results as sensible as using simulated data. Human data can often look quite different from the simulated data, which may be considered out of distribution. Thus, the authors should consider using simulated test data with out-of-distribution parameters to validate the method and using real human data to demonstrate, e.g., the reliability of the method across sessions.</p>
<p>(3) The z-scores used to measure prediction error are generally between 1-3, which seems quite large to me. It would give readers a better sense of the utility of the method if comparisons to simpler methods, such as k-nearest neighbor methods, are provided in terms of accuracy.</p>
<p>(4) A lot of simulations are required to train the posterior estimator, which seems much more than existing approaches. Inferring from Figure S1, at the required order of magnitudes of the number of simulations, the simulation time could range from days to years, depending on the hardware. Although once the estimator is well-trained, the parameter inverse given new data will be very fast, it is not clear to me how often such use cases would be encountered. Because the estimator is trained based on an individual connectome, it can only be used to do parameter inversion for the same subject. Typically, we only have one session of resting state data from each participant, while longitudinal resting state data where we can assume the structural connectome remains constant, is rare. Thus, the cost-efficiency and practical utility of training such a posterior estimator remains unclear.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106194.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ziaeemehr</surname>
<given-names>Abolfazl</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4696-9947</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Woodman</surname>
<given-names>Marmaduke</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8410-4581</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Domide</surname>
<given-names>Lia</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4822-2046</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Petkoski</surname>
<given-names>Spase</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4540-6293</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Jirsa</surname>
<given-names>Viktor</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8251-8860</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Hashemi</surname>
<given-names>Meysam</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5289-9837</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p><bold>Public Reviews:</bold></p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>This work provides a new Python toolkit for combining generative modeling of neural dynamics and inversion methods to infer likely model parameters that explain empirical neuroimaging data. The authors provided tests to show the toolkit's broad applicability and accuracy; hence, it will be very useful for people interested in using computational approaches to better understand the brain.</p>
<p>Strengths:</p>
<p>The work's primary strength is the tool's integrative nature, which seamlessly combines forward modelling with backward inference. This is important as available tools in the literature can only do one and not the other, which limits their accessibility to neuroscientists with limited computational expertise. Another strength of the paper is the demonstration of how the tool can be applied to a broad range of computational models popularly used in the field to interrogate diverse neuroimaging data, ensuring that the methodology is not optimal to only one model. Moreover, through extensive in-silico testing, the work provided evidence that the tool can accurately infer ground-truth parameters, which is important to ensure results from future hypothesis testing are meaningful.</p>
</disp-quote>
<p>We are happy to hear the positive feedback on our effort to provide an open-source and widely accessible tool for both fast forward simulations and flexible model inversion, applicable across popular models of large-scale brain dynamics.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>Although the tool itself is the main strength of the work, the paper lacked a thorough analysis of issues concerning robustness and benchmarking relative to existing tools.</p>
<p>The first issue is the robustness to the choice of features to be included in the objective function. This choice significantly affects the training and changes the results, as the authors even acknowledged themselves multiple times (e.g., Page 17 last sentence of first paragraph or Page 19 first sentence of second paragraph). This brings the question of whether the accurate results found in the various demonstrations are due to the biased selection of features (possibly from priors on what worked in previous works). The robustness of the neural estimator and the inference method to noise was also not demonstrated. This is important as most neuroimaging measurements are inherently noisy to various degrees.</p>
<p>The second issue is on benchmarking. Because the tool developed is, in principle, only a combination of existing tools specific to modeling or Bayesian inference, the work failed to provide a more compelling demonstration of its added value. This could have been demonstrated through appropriate benchmarking relative to existing methodologies, specifically in terms of accuracy and computational efficiency.</p>
</disp-quote>
<p>We fully agree with the reviewer that the VBI estimation heavily depends on the choice of data features, and this is the core of the inference procedure, not its weakness. We have demonstrated different scenarios showing how the informativeness of features (commonly used in the literature) results in varying uncertainty quantification. For instance, using summary statistics of functional connectivity (FC) and functional connectivity dynamics (FCD) matrices to estimate global coupling parameter leads to fast convergence; however, it is not sufficient to accurately estimate the whole-brain heterogeneous excitability parameter, which requires features such as statistical moments of time series. VBI provides a taxonomy of data features that users can employ to test their hypotheses. It is important to note that one major advantage of VBI is its ability to make estimation using a battery of data features, rather than relying on a limited set (such as only FC or FCD) as is often the case in the literature. In the revised version, we will elaborate further by presenting additional scenarios to demonstrate the robustness of the estimation. We will also evaluate the robustness of the neural density estimators to (dynamical/additive) noise.</p>
<p>More importantly, relative to benchmarking, we would like to draw attention to a key point regarding existing tools and methods. The literature often uses optimization for fitting whole-brain network models, and its limitations for reliable causal hypothesis testing have been pointed out in the Introduction/Discussion. As also noted by the reviewer under strengths, and to the best of our knowledge, there are no existing tools other than VBI that can scale and generalize to operate across whole-brain models for <italic>Bayesian model inversion</italic>. Previously, we developed Hamiltonian Monte Carlo (HMC) sampling for Epileptor model in epilepsy (Hashemi et al., 2020, Jha et al., 2022). This phenomenological model is very well-behaved in terms of numerical integration, gradient calculation, and dynamical system properties (Jirsa et al., 2014). However, this does not directly generalize to other models, particularly the Montbrió model for resting-state, which exhibits bistability with noise driving transitions between states. As shown in Baldy et al., 2024, even at the level of a single neural mass model (i.e., one brain region), gradient-based HMC failed to capture such switching behaviour, particularly when only one state variable (membrane potential) was observed while the other (firing rate) was missing. Our attempts to use other methods (e.g., the second-derivative-based Laplace approximation used in Dynamic Causal Modeling) also failed, due to divergence in gradient calculation. Nevertheless, reparameterization techniques (Baldy et al., 2024) and hybrid algorithms (Gabrié et al., 2022) could offer improvements, although this remains an open problem for these classes of computational models.</p>
<p>In sum, for oscillatory systems, it has been shown previously that SBI approach used in VBI substantially outperforms both gradient-based and gradient-free alternative methods (Gonçalves et al., 2020, Hashemi et al., 2023, Baldy et al., 2024). Importantly, for bistable systems with switching dynamics, gradient-based methods fail to converge, while gradient-free methods do not scale to the whole-brain level (Hashemi et al., 2020). Hence, the generalizability of VBI relies on the fact that neither the model nor the data features need to be differentiable. We will clarify this point in the revised version. Moreover, we will provide better explanations for some terms mentioned by the reviewer in Recommendations.</p>
<p>Hashemi, M., Vattikonda, A. N., Sip, V., Guye, M., Bartolomei, F., Woodman, M. M., &amp; Jirsa, V. K. (2020). The Bayesian Virtual Epileptic Patient: A probabilistic framework designed to infer the spatial map of epileptogenicity in a personalized large-scale brain model of epilepsy spread. NeuroImage, 217, 116839.</p>
<p>Jha, J., Hashemi, M., Vattikonda, A. N., Wang, H., &amp; Jirsa, V. (2022). Fully Bayesian estimation of virtual brain parameters with self-tuning Hamiltonian Monte Carlo. Machine Learning: Science and Technology, 3(3), 035016.</p>
<p>Jirsa, V. K., Stacey, W. C., Quilichini, P. P., Ivanov, A. I., &amp; Bernard, C. (2014). On the nature of seizure dynamics. Brain, 137(8), 2210-2230.</p>
<p>Baldy, N., Breyton, M., Woodman, M. M., Jirsa, V. K., &amp; Hashemi, M. (2024). Inference on the macroscopic dynamics of spiking neurons. Neural Computation, 36(10), 2030-2072.</p>
<p>Baldy, N., Woodman, M., Jirsa, V., &amp; Hashemi, M. (2024). Dynamic Causal Modeling in Probabilistic Programming Languages. bioRxiv, 2024-11.</p>
<p>Gabrié, M., Rotskoff, G. M., &amp; Vanden-Eijnden, E. (2022). Adaptive Monte Carlo augmented with normalizing flows. Proceedings of the National Academy of Sciences, 119(10), e2109420119.</p>
<p>Gonçalves, P. J., Lueckmann, J. M., Deistler, M., Nonnenmacher, M., Öcal, K., Bassetto, G., ... &amp; Macke, J. H. (2020). Training deep neural density estimators to identify mechanistic models of neural dynamics. eLife, 9, e56261.</p>
<p>Hashemi, M., Vattikonda, A. N., Jha, J., Sip, V., Woodman, M. M., Bartolomei, F., &amp; Jirsa, V. K. (2023). Amortized Bayesian inference on generative dynamical network models of epilepsy using deep neural density estimators. Neural Networks, 163, 178-194.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>Summary:</p>
<p>Whole-brain network modeling is a common type of dynamical systems-based method to create individualized models of brain activity incorporating subject-specific structural connectome inferred from diffusion imaging data. This type of model has often been used to infer biophysical parameters of the individual brain that cannot be directly measured using neuroimaging but may be relevant to specific cognitive functions or diseases. Here, Ziaeemehr et al introduce a new toolkit, named &quot;Virtual Brain Inference&quot; (VBI), offering a new computational approach for estimating these parameters using Bayesian inference powered by artificial neural networks. The basic idea is to use simulated data, given known parameters, to train artificial neural networks to solve the inverse problem, namely, to infer the posterior distribution over the parameter space given data-derived features. The authors have demonstrated the utility of the toolkit using simulated data from several commonly used whole-brain network models in case studies.</p>
<p>Strengths:</p>
<p>(1) Model inversion is an important problem in whole-brain network modeling. The toolkit presents a significant methodological step up from common practices, with the potential to broadly impact how the community infers model parameters.</p>
<p>(2) Notably, the method allows the estimation of the posterior distribution of parameters instead of a point estimation, which provides information about the uncertainty of the estimation, which is generally lacking in existing methods.</p>
<p>(3) The case studies were able to demonstrate the detection of degeneracy in the parameters, which is important. Degeneracy is quite common in this type of model. If not handled mindfully, they may lead to spurious or stable parameter estimation. Thus, the toolkit can potentially be used to improve feature selection or to simply indicate the uncertainty.</p>
<p>(4) In principle, the posterior distribution can be directly computed given new data without doing any additional simulation, which could improve the efficiency of parameter inference on the artificial neural network if well-trained.</p>
</disp-quote>
<p>We thank the reviewer for the careful consideration of important aspects of the VBI tool, such as uncertainty quantification, degeneracy detection, parallelization, and amortization strategy.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>(1) While the posterior estimator was trained with a large quantity of simulated data, the testing/validation is only demonstrated with a single case study (one point in parameter space) per model. This is not sufficient to demonstrate the method's accuracy and reliability, but only its feasibility. Demonstrating the accuracy and reliability of the posterior estimation in large test sets would inspire more confidence.</p>
<p>(2) The authors have only demonstrated validation of the method using simulated data, but not features derived from actual EEG/MEG or fMRI data. So, it is unclear if the posterior estimator, when applied to real data, would produce results as sensible as using simulated data. Human data can often look quite different from the simulated data, which may be considered out of distribution. Thus, the authors should consider using simulated test data with out-of-distribution parameters to validate the method and using real human data to demonstrate, e.g., the reliability of the method across sessions.</p>
<p>(3) The z-scores used to measure prediction error are generally between 1-3, which seems quite large to me. It would give readers a better sense of the utility of the method if comparisons to simpler methods, such as k-nearest neighbor methods, are provided in terms of accuracy.</p>
<p>(4) A lot of simulations are required to train the posterior estimator, which seems much more than existing approaches. Inferring from Figure S1, at the required order of magnitudes of the number of simulations, the simulation time could range from days to years, depending on the hardware. Although once the estimator is well-trained, the parameter inverse given new data will be very fast, it is not clear to me how often such use cases would be encountered. Because the estimator is trained based on an individual connectome, it can only be used to do parameter inversion for the same subject. Typically, we only have one session of resting state data from each participant, while longitudinal resting state data where we can assume the structural connectome remains constant, is rare. Thus, the cost-efficiency and practical utility of training such a posterior estimator remains unclear.</p>
</disp-quote>
<p>We agree with the reviewer that it is necessary to show results on larger synthetic test sets, and we will elaborate further by presenting additional scenarios to demonstrate the robustness of the estimation. However, there are some points raised by the reviewer that we need to clarify.</p>
<p>The validation on empirical data was beyond the scope of this study, as it relates to model validation rather than the inversion algorithms. This is also because we aimed to avoid repetition, given that we have previously demonstrated model validation on empirical data using these techniques, for invasive sEEG (Hashemi et al., 2023), MEG (Sorrentino et al., 2024), EEG (Angiolelli et al., 2025) and fMRI (Lavanga et al., 2024, Rabuffo et al., 2025). Note that if the features of the observed data are not included during training, VBI ignores them, as it requires an invertible mapping function between parameters and data features.</p>
<p>We have used z-scores and posterior shrinkage to measure prediction performance, as these are Bayesian metrics that take into account the variance of both prior and posterior rather than only the mean value or thresholding for ranking of the prediction used in k-NN or confusion matrix methods. This helps avoid biased accuracy estimation, for instance, if the mean posterior is close to the true value but there is no posterior shrinkage. Although shrinkage is bounded between 0 and 1, we agree that z-scores have no upper bound for such diagnostics.</p>
<p>Finally, the number of required simulations depends on the dimensionality of the parameter space and the informativeness of the data features. For instance, estimating a single global scaling parameter requires around 100 simulations, whereas estimating whole-brain heterogeneous parameters requires substantially more simulations. Nevertheless, we have provided fast simulations, and one key advantage of VBI is that simulations can be run in parallel (unlike MCMC sampling, which is more limited in this regard). Hence, with commonly accessible CPUs/GPUs, the fast simulations and parallelization capabilities of the VBI tool allow us to run on the order of 1 million simulations within 2–3 days on desktops, or in less than half a day on supercomputers at cohort level, rather than over several years! It has been previously shown that the SBI method used in VBI provides an order-of-magnitude faster inversion than HMC for whole-brain epilepsy spread (Hashemi et al., 2023). Moreover, after training, the amortized strategy is critical for enabling hypothesis testing within seconds to minutes. We agree that longitudinal resting-state data under the assumption of a constant structural connectome is rare; however, this strategy is essential in brain diseases such as epilepsy, where experimental hypothesis testing is prohibitive.</p>
<p>We will clarify these points and better explain some terms mentioned by the reviewer in the revised manuscript.</p>
<p>Hashemi, M., Vattikonda, A. N., Jha, J., Sip, V., Woodman, M. M., Bartolomei, F., &amp; Jirsa, V. K. (2023). Amortized Bayesian inference on generative dynamical network models of epilepsy using deep neural density estimators. Neural Networks, 163, 178-194.</p>
<p>Sorrentino, P., Pathak, A., Ziaeemehr, A., Lopez, E. T., Cipriano, L., Romano, A., ... &amp; Hashemi, M. (2024). The virtual multiple sclerosis patient. Iscience, 27(7).</p>
<p>Angiolelli, M., Depannemaecker, D., Agouram, H., Regis, J., Carron, R., Woodman, M., ... &amp; Sorrentino, P. (2025). The virtual parkinsonian patient. npj Systems Biology and Applications, 11(1), 40.</p>
<p>Lavanga, M., Stumme, J., Yalcinkaya, B. H., Fousek, J., Jockwitz, C., Sheheitli, H., ... &amp; Jirsa, V. (2023). The virtual aging brain: Causal inference supports interhemispheric dedifferentiation in healthy aging. NeuroImage, 283, 120403.</p>
<p>Rabuffo, G., Lokossou, H. A., Li, Z., Ziaee-Mehr, A., Hashemi, M., Quilichini, P. P., ... &amp; Bernard, C. (2025). Mapping global brain reconfigurations following local targeted manipulations. Proceedings of the National Academy of Sciences, 122(16), e2405706122.</p>
</body>
</sub-article>
</article>