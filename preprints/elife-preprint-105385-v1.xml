<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">105385</article-id>
<article-id pub-id-type="doi">10.7554/eLife.105385</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.105385.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>How relevant is the prior? Bayesian causal inference for dynamic perception in volatile environments</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7484-2783</contrib-id>
<name>
<surname>Meijer</surname>
<given-names>David</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>meijerdavid1@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Barumerli</surname>
<given-names>Roberto</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Baumgartner</surname>
<given-names>Robert</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03anc3s24</institution-id><institution>Acoustics Research Institute, Austrian Academy of Sciences</institution></institution-wrap>, <city>Vienna</city>, <country country="AT">Austria</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/039bp8j42</institution-id><institution>Department of Neurosciences, Biomedicine and Movement Sciences, University of Verona</institution></institution-wrap>, <city>Verona</city>, <country country="IT">Italy</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Diaconescu</surname>
<given-names>Andreea Oliviana</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country>Canada</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing Interest Statement: The authors have declared no competing interest.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-02-03">
<day>03</day>
<month>02</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP105385</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-11-30">
<day>30</day>
<month>11</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-11-22">
<day>22</day>
<month>11</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.10.29.620874"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Meijer et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Meijer et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-105385-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Interpreting sensory prediction errors can be challenging in volatile environments because they can be caused by stochastic noise or by outdated predictions. Noisy signals should be integrated with prior beliefs to improve precision, but the two should be segregated when environmental changes render prior beliefs irrelevant. Bayesian causal inference provides a statistically optimal solution to deal with uncertainty about the causes of prediction errors. However, the method quickly becomes memory intensive and computationally intractable when applied sequentially.</p><p>Here, we systematically evaluate the predictive performance of Bayesian causal inference for perceptual decisions in a spatial prediction task based on noisy audiovisual sequences with occasional changepoints. We elucidate the simplifying assumptions of a previously proposed reduced Bayesian observer model, and we compare it to an extensive set of models based on alternative simplification strategies.</p><p>Model-free analyses revealed the hallmarks of Bayesian causal inference: participants seem to have integrated sensory evidence with prior beliefs to improve accuracy when prediction errors were small, but prior influence decreased gradually as prediction errors increased, signalling probable irrelevance of the priors due to changepoints. Model comparison results indicated that participants computed probability-weighted averages over the causal options (noise or changepoint), akin to the reduced Bayesian observer model. However, participants’ reliance on prior beliefs was systematically smaller than expected, and this was best explained by individually fitting lower-than-optimal parameters for the a-priori probability of prior relevance.</p><p>We conclude that perceptual decision makers utilize priors flexibly to the extent that they are deemed relevant, though also conservatively with a lower tendency to bind than ideal observers. Simplified consecutive Bayesian causal inference predicts key characteristics of belief updating in changepoint environments and forms a suitable foundation for modelling dynamic perception in a changing world.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Perceptual decision making</kwd>
<kwd>Bayesian causal inference</kwd>
<kwd>Changepoint detection</kwd>
<kwd>Prior relevance</kwd>
<kwd>Consecutive belief updating</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The paper has been revised to emphasize a focus on Bayesian causal inference as a general principle to model perceptual decisions in changepoint environments. Major modifications have been highlighted in grey.</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/YIRG-Dynamates/priorRelevance/">https://github.com/YIRG-Dynamates/priorRelevance/</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<label>1.</label>
<title>Introduction</title>
<p>Perception is inherently uncertain. Sensory signals are disturbed by noise from external sources and our nervous system suffers from imperfect processing and transmission (<xref ref-type="bibr" rid="c11">Faisal et al., 2008</xref>). Besides, the limited information that is conveyed by the sensory signals is often insufficient by itself to obtain an unambiguous understanding of our environment. One efficient way to nevertheless form a coherent model of the world around us is to supplement and compare incoming sensory information with expectations based on our current beliefs (<xref ref-type="bibr" rid="c13">Friston, 2010</xref>; <xref ref-type="bibr" rid="c7">Clark, 2013</xref>). A mismatch between the two generates a prediction error that calls for an explanation. Prediction errors can be attributed to sensory noise or imprecise predictions, allowing the novel sensory information to be incorporated into the pre-existing beliefs to improve their accuracy. Alternatively, prediction errors can also be caused by previously unknown or new sources of the sensory signals in a changing environment, necessitating an update to the observer’s model of the world.</p>
<p>Bayesian inference is a probabilistic approach to deal with perceptual uncertainty in a manner that has the potential to be statistically optimal (<xref ref-type="bibr" rid="c25">Ma, 2012</xref>). Accordingly, it has been proposed that our brains attenuate the detrimental impact of random noise, thus improving perceptual precision, by integrating redundant information across sensory cues and prior beliefs by means of reliability-weighted averaging (<xref ref-type="bibr" rid="c19">Knill &amp; Pouget, 2004</xref>). Indeed, there is an abundance of reports that collectively demonstrate that what we perceive is often biased by our expectations and by concurrent sensory signals in accordance with Bayesian integration (<xref ref-type="bibr" rid="c8">de Lange et al., 2018</xref>, <xref ref-type="bibr" rid="c29">Meijer &amp; Noppeney, 2020</xref>) and that our brains are in principle capable of such probabilistic computations (<xref ref-type="bibr" rid="c42">Pouget et al., 2013</xref>).</p>
<p>However, one should not integrate sensory information that does not originate from the same real-world object or event (i.e., cause). Within the Bayesian inference framework, one can naturally account for the possibility of multiple sensory sources by a hierarchical extension of the prior (<xref ref-type="bibr" rid="c61">Yuille &amp; Bülthoff, 1996</xref>; <xref ref-type="bibr" rid="c49">Shams &amp; Beierholm, 2010</xref>). For example, in an audiovisual ventriloquism paradigm, an observer must entertain two competing causal structures: either the auditory and visual signals stem from the same source location, or they come from two different locations (<xref ref-type="bibr" rid="c20">Körding et al., 2007</xref>). Moderately small spatial disparities between the sensory signals could have easily been caused by noise, so an observer may falsely infer a common source and thus integrates the two sensory signals, leading to the ventriloquist illusion. Yet, the illusion does not occur for larger spatial disparities when it is more likely that the two signals originated from two different locations. Results from a multitude of psychophysics and neuroimaging studies support the claim that our brains apply such Bayesian causal inference to determine whether to integrate or segregate sensory signals (<xref ref-type="bibr" rid="c48">Shams &amp; Beierholm, 2022</xref>).</p>
<p>Another field of research in which Bayesian inference has been successful at describing human perceptual decisions is concerned with learning about changing environments (<xref ref-type="bibr" rid="c5">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c36">O’Reilly, 2013</xref>; <xref ref-type="bibr" rid="c17">Kang et al., 2024</xref>). Of specific interest to us here is the problem of changepoint detection: i.e., how does one determine whether their current model of the world has become irrelevant because of a sudden change in their surroundings? In other words, when should one integrate noisy sensory evidence with previously held beliefs to improve precision, and when should one segregate the two because the latest sensory signal stems from a novel reality? The problem is thus essentially one of causal inference (see <xref rid="fig1" ref-type="fig">Figure 1</xref>) and Bayesian probability theory prescribes the optimal approach to dynamically deal with the combined uncertainty from stochastic noise and potential changepoints in the generative process (<xref ref-type="bibr" rid="c3">Adams &amp; MacKay, 2007</xref>; <xref ref-type="bibr" rid="c12">Fearnhead and Liu, 2007</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Two competing models of the world for explaining prediction errors in a changepoint paradigm.</title> <p>A). The first causal structure assumes that the latest observation stems from the same source as the preceding observations. B). The second causal structure instead assumes that the latest observation originates from a different source. Note that the true causes that give rise to the sensory signals are unknown to observers (i.e., latent). This is illustrated on the right side by a brick wall that obscures the true source location(s) of the balls that are thrown over it (i.e., noisy observations). The inferred cause for the latest observation is mentioned in the thought clouds.</p></caption>
<graphic xlink:href="620874v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The fully Bayesian solution to the changepoint detection problem allows an agent to retrospectively evaluate evidence about changepoints that occurred several observations in the past. While such inference with hindsight leads to the most precise beliefs about the current state of the world, it also requires extensive memory and computational capacity that seems implausible for the human brain. Hence, simplified near-Bayesian changepoint models were developed that approximate the optimal solution and provide more realistic algorithms that may be implemented by the brain (<xref ref-type="bibr" rid="c34">Nassar et al., 2010</xref>, <xref rid="c33" ref-type="bibr">2012</xref>; <xref ref-type="bibr" rid="c58">Wilson et al., 2013</xref>). Indeed, available psychophysical, neuroimaging and neurophysiological work in combination with computational modelling generally support the hypothesis that the brain relies on approximately-Bayesian inference for adaptive learning in changing environments (<xref ref-type="bibr" rid="c60">Yu et al., 2021</xref>).</p>
<p>Here, our main contributions are threefold. First, we attempt to bridge a gap between the fields of learning and sensory cue integration by presenting a previously proposed reduced Bayesian observer model for changepoint detection (<xref ref-type="bibr" rid="c33">Nassar et al., 2012</xref>) in a way that is readily understandable by those familiar with the Bayesian causal inference models for sensory cue integration. In so doing, we subtly but fundamentally shift the perspective from the updating of beliefs when new information becomes available (e.g., learning rates), to the interpretation of sensory signals by latent causal inference (<xref ref-type="bibr" rid="c14">Gershman et al., 2015</xref>). While the mathematical foundation of these modelling perspectives is identical in the changepoint detection paradigm, we argue that Bayesian causal inference provides a flexible normative framework that lends itself well to model extensions and generalizations across tasks (<xref ref-type="bibr" rid="c48">Shams &amp; Beierholm, 2022</xref>). By elucidating its core components for consecutive (as opposed to concurrent) cue integration, we lay-out key predictions and introduce testable hypotheses for approximate Bayesian causal inference in the domain of dynamic belief updating.</p>
<p>Second, we evaluate the reduced Bayesian observer model’s performance in explaining spatial predictions of participants in a changepoint detection task wherein expectations had to be formed and updated during the ongoing presentation of stimulus sequences. Participants were prompted for a response at unpredictable times when the sequence suddenly stopped. This experimental design is in stark contrast to the more commonly used procedure where participants are required to make a prediction response after every stimulus (<xref ref-type="bibr" rid="c34">Nassar et al., 2010</xref>, <xref rid="c33" ref-type="bibr">2012</xref>, <xref rid="c32" ref-type="bibr">2019</xref>, <xref ref-type="bibr" rid="c28">McGuire et al., 2014</xref>). Such sequence disruptions likely affect consecutive cue integration efficacy. Instead, by using a task design that requires covert evidence accumulation rather than overt serial decision-making, we aim to examine Bayesian causal inference as a mechanism of implicit sequential perception, while also aspiring to avoid explicit choice history biases (<xref ref-type="bibr" rid="c53">Talluri et al., 2018</xref>; <xref ref-type="bibr" rid="c6">Bévalot &amp; Meyniel, 2023</xref>). We adopt the rich behavioral dataset that was previously analysed by <xref ref-type="bibr" rid="c21">Krishnamurthy, Nassar, Sarode and Gold (2017)</xref>, but we limit our analysis to the audiovisual sequences and the prediction responses, whereas their original publication focused on pupillometry recordings and localization responses about sounds that followed those predictions.</p>
<p>Third, we derive the fully Bayesian solution for this experimental paradigm and subsequently systematically introduce simplifications and alternative modelling assumptions. This allows us to build a factorial framework of near-Bayesian changepoint detection model variations with varying complexity and decisional strategies. We then fit all models to the behavioral data and perform a model comparison to evaluate which of the tested algorithmic components are most probably utilized by the brain. As such, we provide a systematic evaluation of memory and complexity reduction in sequential Bayesian causal inference models for dynamic perception in volatile environments. Please note that we restrict our analyses to modelling static sources of noisy sensory signals with sudden environmental changes. In the discussion section, we allude to possible model extensions that allow the tracking of dynamically moving sources in addition to changepoints (<xref ref-type="bibr" rid="c34">Nassar et al., 2010</xref>, <xref rid="c32" ref-type="bibr">Nassar 2019</xref>), and we compare Bayesian causal inference against alternative approaches that model environmental volatility through moving sources exclusively (i.e., hierarchical extensions of the Kalman filter; <xref ref-type="bibr" rid="c27">Mathys et al. 2011</xref>, <xref rid="c26" ref-type="bibr">2014</xref>; <xref ref-type="bibr" rid="c40">Piray &amp; Daw, 2020</xref>). Finally, we highlight possible avenues for future research that can expand sequential Bayesian causal inference models to incorporate latent causes with higher order statistical regularities (<xref ref-type="bibr" rid="c50">Skerritt-Davis &amp; Elhilali, 2018</xref>, <xref ref-type="bibr" rid="c51">2021</xref>) or for use in environments with multiple sources that are simultaneously active (<xref ref-type="bibr" rid="c14">Gershman et al., 2015</xref>; <xref ref-type="bibr" rid="c22">Larigaldie et al., 2024</xref>).</p>
</sec>
<sec id="s2">
<label>2.</label>
<title>Results</title>
<p>Twenty-nine participants performed a spatial prediction task in which they indicated the anticipated location of an upcoming stimulus by means of a mouse response on a semi-circular arc after having been presented with a sequence of audiovisual stimuli (<xref rid="fig2" ref-type="fig">Figure 2A</xref>). Responses were self-paced, and the median reaction time was 1.72 (IQR: 1.49–2.35) seconds. The sequences mostly allowed for reasonable predictions because the stimuli locations (at times <italic>t</italic>), <italic>x</italic><sub><italic>t</italic></sub>, were sampled from a normal distribution, centred on the ‘generative mean’ <italic>μ</italic><sub><italic>t</italic></sub> and with width defined by the ‘experimental noise’ σ<sub><italic>exp</italic></sub> (SD = 10° or 20° in blocked low or high noise conditions, respectively). Hence, the mean location of the preceding stimuli provides a good prediction for the location of the next stimulus. However, at every timepoint <italic>t</italic>, there was a 15% chance for a changepoint (hazard rate <italic>H</italic><sub><italic>cp</italic></sub> = 0.15), in which case the generative mean <italic>μ</italic><sub><italic>t</italic></sub> was resampled at random from within the space boundaries (uniform distribution from <italic>a</italic> = −90° to <italic>b</italic> = +90°, relative to straight ahead). Participants were instructed on the nature of the changepoint process, and they had the opportunity to learn the values of the task’s parameters (<italic>H</italic><sub><italic>cp</italic></sub>, σ<sub><italic>exp</italic></sub>) in a practice session (not analysed). See <xref ref-type="sec" rid="s4a">section 4.1</xref> for more details on the experimental procedure or consult the original publication by Krishnamurthy, <xref rid="c21" ref-type="bibr">Nassar, et al. (2017)</xref>.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>The reduced Bayesian observer model puts the causality question centre stage after every stimulus: Did the latest observation originate from the same generative mean location as the prior (with added noise), or has there been a changepoint (cp)?</title>
<p>A). Example trial in which an observer is presented with ten audiovisual stimuli. The generative mean changes twice after the start of the sequence: at <italic>t</italic>=4 and at <italic>t</italic>=6. Five consecutive stimuli are presented after the last cp (SAC 5), after which the participant responds with a prediction for the location of the upcoming stimulus. Ideally, the response location approximates the mean of the stimuli since the last cp. The sequential inference process to estimate this mean location is illustrated for three stimuli. Upon experiencing a large precision-weighted prediction error, a cp is inferred, and the prior becomes irrelevant for the current generative mean. So, the posterior (and next prior) is based on the likelihood only (<italic>t</italic>=4). Instead, small prediction errors indicate a low probability of a cp, thus likelihood and prior are integrated to improve precision of the mean estimate (<italic>t</italic>=5). But what to do when there is (causal) uncertainty about the occurrence of a cp (<italic>t</italic>=6)? The moderately sized prediction error suggests a cp, but the overlap between prior and likelihood indicates that they could have also originated from a common generative mean, i.e., <italic>μ</italic><sub>6</sub> = <italic>μ</italic><sub>5</sub>. A fully Bayesian observer computes a posterior as a weighted mixture of two posterior components (dashed lines), each conditional on a causal hypothesis (cp or not). Alternatively, the reduced Bayesian observer summarizes that mixture distribution by its mean and variance, and thus simplifies the posterior (and next prior) to a single normal distribution.</p>
<p>B-D). The prior relevance measure (<italic>Π</italic>) is key to the inference process of the reduced Bayesian observer. Panel B depicts its logit transformation (<italic>Q</italic>, i.e., the posterior log-odds of no changepoint) as a function of absolute prediction error <inline-formula><inline-graphic xlink:href="620874v2_inline94.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, for two experimental noise conditions, two levels of prior reliability (<italic>τ</italic>), and two changepoint hazard rates (<italic>H</italic><sub><italic>cp</italic></sub>). Panel C shows the resulting normalized bias towards the prior (at 1, relative to the last stimulus), which equals the product of prior relevance and prior reliability. Panel D illustrates how spatial uncertainty about the generative mean depends on the latest prediction error: it is low for small errors due to integration of prior and likelihood, it is identical to the experimental noise for large prediction errors, and highest in-between because of causal uncertainty.</p></caption>
<graphic xlink:href="620874v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<sec id="s2a">
<label>2.1</label>
<title>Reduced Bayesian observer model</title>
<p>Bayesian inference provides a statistically optimal method of dealing with the uncertainty that is caused by the combined presence of noise and changepoints in order to minimize the squared prediction errors. In <xref ref-type="sec" rid="s4c">section 4.3</xref>, we have derived the fully Bayesian solution for this task design (<xref ref-type="bibr" rid="c3">Adams &amp; MacKay, 2007</xref>). However, since that ideal observer model relies on an infinitely large memory capacity and is computationally complex, we instead consider the reduced Bayesian observer model that was introduced by <xref ref-type="bibr" rid="c33">Nassar et al. (2012)</xref>. This model presents a more plausible inference algorithm to be utilized by the brain and it has the additional benefit that it makes the causal inference process (i.e., changepoint or not) very explicit and insightful due to its simplicity.</p>
<p>Since the upcoming stimulus location <italic>x</italic><sub><italic>t</italic>+1</sub> is equal to its generative mean <italic>μ</italic><sub><italic>t</italic>+1</sub> plus some random noise, the reduced Bayesian observer makes predictions about <italic>x</italic><sub><italic>t</italic>+1</sub> based on its best prediction for <italic>μ</italic><sub><italic>t</italic>+1</sub>: i.e., <inline-formula><inline-graphic xlink:href="620874v2_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Here, the tilde indicates that these are predictions. To compute its prediction about the upcoming generative mean, the modelled agent attempts to compute the mean of the preceding stimuli since the last changepoint. If a changepoint occurred at the latest timepoint, <italic>cp</italic><sub><italic>t</italic></sub> = 1, then only the last stimulus is relevant, and the associated uncertainty is given by the learned estimate (indicated by circumflex) of the experimental noise:
<disp-formula id="eqn1">
<graphic xlink:href="620874v2_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
On the other hand, if there was no changepoint at timepoint <italic>t</italic>, then there are multiple relevant stimuli over which the agent should compute the mean. Fortunately, one does not have to remember all stimuli locations since the last changepoint. Instead, Bayesian observers compute the mean iteratively via reliability-weighted integration (which implies that they only have to remember the current mean and associated variance):
<disp-formula id="eqn2">
<graphic xlink:href="620874v2_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the weight <italic>τ</italic><sub><italic>t</italic></sub>, termed ‘prior reliability’, is computed as a relative measure of prior precision (i.e., reciprocal of variance):
<disp-formula id="eqn3">
<graphic xlink:href="620874v2_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Notice how we expressed the predicted generative mean as a sum of the last stimulus location and a bias towards the prior. The normalized bias size (between 0 and 1, for predictions at <italic>x</italic><sub><italic>t</italic></sub> and <inline-formula><inline-graphic xlink:href="620874v2_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, respectively) is equal to the prior reliability <italic>τ</italic><sub><italic>t</italic></sub>. Notice further how the spatial uncertainty about the generative mean decreases with integration because 0 ≤ <italic>τ</italic><sub><italic>t</italic></sub> &lt; 1. In the absence of changepoints, the spatial uncertainty would be reduced by a factor that is equal to the inverse of the number of observations (cf. standard error of the mean).</p>
<p>New evidence should be integrated with prior beliefs (<xref ref-type="disp-formula" rid="eqn2">Eq. 2</xref>) when the two relate to the same generative mean, and they should be segregated (<xref ref-type="disp-formula" rid="eqn1">Eq. 1</xref>) when they belong to different generative means, i.e., after a changepoint (<xref rid="fig2" ref-type="fig">Figure 2A</xref>). But how does one know whether a changepoint has occurred? A Bayesian observer infers this from the posterior probability of no changepoint, <italic>Π</italic><sub><italic>t</italic></sub>, termed ‘prior relevance’ (Krishnamurthy, Nassar, et al., 2017). Since it is a posterior measure, <italic>Π</italic><sub><italic>t</italic></sub> depends on a combination of pre-existing beliefs and an evaluation of the newest observation. To be able to separate these two contributions, we present the formula for the posterior log odds of no changepoint, <italic>Q</italic><sub><italic>t</italic></sub>, i.e., the logit transform of <italic>Π</italic><sub><italic>t</italic></sub>:
<disp-formula id="eqn4">
<graphic xlink:href="620874v2_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the unbounded quantity <italic>Q</italic><sub><italic>t</italic></sub> is back-transformed to the posterior probability, 0 ≤ <italic>Π</italic><sub><italic>t</italic></sub> ≤ 1, via the monotonic logistic function.</p>
<p>The first term (within the logarithm) represents an a-priori belief about the prior’s relevance that is independent of the last stimulus location <italic>x</italic><sub><italic>t</italic></sub>. The prior’s relevance decreases with a larger changepoint hazard rate estimate, <inline-formula><inline-graphic xlink:href="620874v2_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, it increases with a larger spatial range of the generative mean (<italic>b</italic> − <italic>a</italic>), and it decreases with more uncertainty about the location of the upcoming stimulus <inline-formula><inline-graphic xlink:href="620874v2_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, i.e., summed variance of prior on <italic>μ</italic> and experimental noise). The second term specifies by how much the (logit-transformed) prior relevance decreases as a function of the squared prediction error, i.e., after having observed <italic>x</italic><sub><italic>t</italic></sub> (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). Importantly, a particular squared prediction error reduces the prior relevance by a smaller amount when the a-priori uncertainty about the stimulus location was larger. This precision-weighted squared prediction error term can thus be intuitively interpreted as a measure of surprise about the latest stimulus location <italic>x</italic><sub><italic>t</italic></sub> that is conditional on the prior’s relative location and uncertainty (see <xref ref-type="sec" rid="s4d">section 4.4</xref>).</p>
<p>Finally, the reduced Bayesian observer computes its prediction for the generative mean as a weighted combination of the two causal structures: changepoint or not. The weights are determined by the prior relevance:
<disp-formula id="eqn5">
<graphic xlink:href="620874v2_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we have once again expressed the prediction for the generative mean as a sum of the last stimulus location and a bias towards the prior. The normalized bias size is equal to the product of prior reliability <italic>τ</italic><sub><italic>t</italic></sub> and prior relevance <italic>Π</italic><sub><italic>t</italic></sub> (<xref rid="fig2" ref-type="fig">Figure 2C</xref>; see also <xref ref-type="sec" rid="s4e">section 4.5</xref>). Note that the predicted spatial uncertainty is formed by a weighted average of the variances of the two causal structures plus a third term that indicates the additional variance due to the causal uncertainty, <italic>Π</italic><sub><italic>t</italic></sub> (1 − <italic>Π</italic><sub><italic>t</italic></sub>), which further depends on the squared prediction error and prior reliability. The contribution of this causal uncertainty term can be considerable. Because of it, the spatial uncertainty about the generative mean based on multiple stimuli can even exceed the spatial uncertainty based on a single stimulus <inline-formula><inline-graphic xlink:href="620874v2_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula> in situations where there is a high degree of causal uncertainty about whether or not a changepoint occurred (<xref rid="fig2" ref-type="fig">Figure 2D</xref>).</p>
<p>While it may seem counterintuitive to update one’s beliefs with the (weighted) average of two distinct possibilities (changepoint or not), thus placing one’s best prediction for upcoming stimuli somewhere in the middle where neither causal explanation matches particularly well, we emphasize that such concerns are unjustified. The prior relevance drops to near-zero for large prediction errors, so that the weighted average does not significantly bias one’s belief towards the prior (<xref rid="fig2" ref-type="fig">Figure 2C</xref>). Instead, the resulting prediction would be near the latest sensory evidence, in accordance with what one should expect after a noticeable changepoint. As the prediction error decreases in size, the prior relevance and resulting bias increase, and the updated belief will be exactly in the middle when <italic>Π</italic><sub><italic>t</italic></sub> <italic>τ</italic><sub><italic>t</italic></sub> = 0.5. However, as the prediction error decreases, we also effectively increase the amount of overlap between the two posterior component distributions, conditional on a changepoint or not (<xref ref-type="disp-formula" rid="eqn1">Eqs. 1</xref>-<xref ref-type="disp-formula" rid="eqn2">2</xref>; <xref rid="fig2" ref-type="fig">Figure 2A</xref>, dashed yellow lines in bottom panel). This means that the weighted average prediction <inline-formula><inline-graphic xlink:href="620874v2_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula> in such cases will actually be relatively well supported by both causal explanations.</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Qualitative evaluation</title>
<p>In this section, we compare general patterns and trends in the predictions of the reduced Bayesian observer model (<xref ref-type="disp-formula" rid="eqn3">Eqs. 3</xref>-<xref ref-type="disp-formula" rid="eqn5">5</xref>) against the behavioral responses of the participants. To gain further insights about the model and participants’ perceptual decision making, we also contrast them against predictions of two other hypothetical observers.</p>
<p>The first hypothetical observer is naïve to the generative process of the stimuli sequences or chooses to ignore it. The naïve observer bases its prediction responses on the last observed stimulus location exclusively: <inline-formula><inline-graphic xlink:href="620874v2_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Within the computational framework of the reduced Bayesian observer this behavior can be achieved by setting the estimate of the changepoint hazard rate equal to one, <inline-formula><inline-graphic xlink:href="620874v2_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which results in a constant prior relevance of zero, <italic>Π</italic><sub><italic>t</italic></sub> = 0. The naïve observer is non-Bayesian because it never integrates new evidence with prior beliefs. Hence, it is unable to decrease its prediction errors after observing multiple stimuli from the same generative mean. However, one could argue that the naïve observer opts for a cost-effective strategy in an uncertain environment: it avoids complex computations entirely in exchange for moderately larger but unbiased prediction errors (<xref ref-type="bibr" rid="c9">Eissa et al., 2022</xref>).</p>
<p>The second hypothetical observer is omniscient with regards to the changepoints. In other words, this unrealistic observer has full knowledge over when changepoints occur and thus experiences no causal uncertainty. It correctly sets the prior relevance <italic>Π</italic><sub><italic>t</italic></sub> to either zero (<italic>cp</italic><sub><italic>t</italic></sub> = 1) or to one (<italic>cp</italic><sub><italic>t</italic></sub> = 0) and it subsequently updates its beliefs about the generative mean according to <xref ref-type="disp-formula" rid="eqn3">Eqs. 3</xref> and <xref ref-type="disp-formula" rid="eqn5">5</xref>. Predictions of the omniscient observer are thus based on the mean location of all observed stimuli since the last changepoint. The omniscient observer sets a comparative benchmark for performance under conditions without causal uncertainty.</p>
<p>In a first analysis, we compare the predicted generative means of the omniscient observer against participants’ prediction responses (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). In general, they are highly correlated (Pearson’s <italic>ρ</italic> = 0.98 [0.96 – 0.99] and <italic>ρ</italic> = 0.95 [0.94 – 0.96], for the low and high noise conditions, respectively. N.b. we consistently report group-level median [Q1 – Q3]). There was only a very small bias towards the centre of space for the participants’ responses overall (regression slope = 0.96 [0.92 – 0.98] and 0.94 [0.90 – 0.98]). These minor biases are in accordance with the reduced Bayesian observer model, and they are predominantly caused by a regression to the mean due to partial integration with stimuli prior to unnoticed changepoints. Importantly, a fully Bayesian ideal observer model portrays much larger central biases, because it attempts to mitigate potentially large prediction errors in case of a changepoint at the upcoming timepoint by multiplying its estimate of the current generative mean by a factor that depends on the changepoint hazard rate (<inline-formula><inline-graphic xlink:href="620874v2_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, i.e., regression slopes &lt; 0.85; see <xref ref-type="sec" rid="s4f">section 4.6</xref>). We conclude that participants did not adjust their predictions for the possibility of an upcoming changepoint, and instead they seem to have provided responses based on their belief about the current generative mean. This has been reported previously (<xref ref-type="bibr" rid="c34">Nassar et al., 2010</xref>) and was thus implemented in the reduced Bayesian observer model (and all other model variations that were tested here, see <xref ref-type="sec" rid="s2d">section 2.4</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Participants’ prediction responses are reasonably accurate, but the reduced Bayesian observer model with default parameters performs better.</title>
<p>A). On average, participants’ responses correlate well with the omniscient observer model for the two experimental noise conditions (left and right panels). The fully Bayesian observer biases its predictions towards the centre of space to accommodate potentially upcoming changepoints. This bias is not present for participants, and it is therefore not modelled for the other observers (naïve, omniscient, and reduced Bayesian, with default parameters or with parameters that were fit to the participants’ data; see <xref ref-type="sec" rid="s2c">section 2.3</xref>).</p>
<p>B-C). The response error relative to the true generative mean (unknown) decreases with larger SAC levels due to integration of consecutive stimuli, but participants’ absolute error remains larger than the naïve observer because of additional response noise (panel B). When the errors are normalized with respect to the naïve observer’s responses (at 1), then the random response noise averages out and the relative accuracy improvement becomes visible (panel C).</p>
<p>The traces in all panels depict the group-level median of the individuals’ median response, per SAC bin (in B-C), or using a rolling kernel method (in A). Note that the rolling median results in small edge artifacts (panel A), with an apparent central bias for peripheral locations even for the naïve observer (and in addition to the integration-based bias for the other observers). The blue shaded region depicts the range between the group-level 25% (Q1) and 75% (Q3) participants.</p></caption>
<graphic xlink:href="620874v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Perhaps the most important prediction that any Bayesian observer model makes is that its accuracy should (generally) improve by integrating the newest evidence with prior beliefs. We would thus expect the average absolute error to decrease in size as more stimuli are integrated. <xref rid="fig3" ref-type="fig">Figure 3B</xref> shows that this is certainly true for the omniscient observer, whose errors relative to the true generative mean <italic>μ</italic><sub><italic>t</italic></sub> decrease as the number of stimuli after [the last] changepoint (SAC) increases. Participants also reduced their errors relative to SAC level 1, but they did not improve further when more than two stimuli were observed after the last changepoint: A 2 × 5 repeated measures ANOVA shows a main effect of low vs. high noise, <italic>F</italic>(1,28) = 397, <italic>p</italic> &lt; .001, and a main effect of SAC level, <italic>F</italic>(4,112) = 25.2, <italic>p</italic> &lt; .001; post hoc tests with Holm correction confirm the differences between SAC 1 and all other levels, <italic>p</italic> &lt; .001, but no other pairwise differences reach significance, <italic>p</italic> &gt; 0.05.</p>
<p>So, participants reduced their errors when more than one stimulus was available after a changepoint. Nevertheless, they did not outperform the naïve observer that simply predicts the next stimulus at the location of the last stimulus. This may suggest that it would have been better for participants to adopt the same naïve strategy instead of attempting to infer when changepoints occur and integrate relevant stimuli. However, we argue that participants’ worse performance can be explained by additional random noise in the response phase, i.e., following the perceptual decision (see <xref ref-type="sec" rid="s4h">section 4.8</xref>, but not included in the models for this analysis). Such response noise could, for example, arise due to imprecision of the sensorimotor system or because of a self-imposed speed-accuracy trade-off. Support for the hypothesis of additive post-decision response noise comes from the analysis of errors that were normalized with respect to the naïve observer (<xref rid="fig3" ref-type="fig">Figure 3C</xref>). Single-trial normalization was achieved by dividing the actual error (<italic>response</italic> − <italic>μ</italic><sub><italic>t</italic></sub>) by the difference between last stimulus and generative mean (<italic>x</italic><sub><italic>t</italic></sub> − <italic>μ</italic><sub><italic>t</italic></sub>), such that a response at <italic>x</italic><sub><italic>t</italic></sub> receives a normalized error of 1 (constant for the naïve observer), while a response at <italic>μ</italic><sub><italic>t</italic></sub> naturally results in a normalized error of 0 (see <xref ref-type="sec" rid="s4k">section 4.11</xref>). Contrary to the absolute errors (<xref rid="fig3" ref-type="fig">Figure 3B</xref>), this procedure enables us to average out random response noise in the normalized errors. The analysis clearly demonstrates that participants reduced their average normalized errors relative to the naïve observer as they integrated evidence over multiple stimuli (sign tests: <italic>p</italic> &lt; .005 for all SAC &gt; 1 in both noise conditions, Bonferroni corrected).</p>
<p>The reduced Bayesian observer model predicts smaller errors (both absolute and normalized) than those of the participants. However, its performance is worse than the omniscient observer, thus illustrating the effect of causal uncertainty, i.e., the ambiguity about the veracity of changepoints. Errors will be larger if a true changepoint is misinterpreted as an outlier due to random noise (SAC 1), and vice versa, errors will also be larger if a changepoint cannot be ruled out after observing an actual outlier (SAC &gt; 1). One can see that the reduced Bayesian observer struggles more with causal uncertainty in the high noise condition, as the difference with the omniscient observer’s performance is larger in the high noise condition as compared to the low noise condition, especially for low SAC levels. Note that the Bayesian observer performs worse than the naïve observer at SAC 1 (higher absolute error, <xref rid="fig3" ref-type="fig">Figure 3B</xref>), thus indicating a trade-off in adopting Bayesian causal inference: it improves performance overall, but it exacerbates errors after environmental changes. Participants, on the other hand, may have used a more conservative, risk-averse strategy in which they only moderately benefit from integration, but also attempt to avoid making large errors after changepoints.</p>
<p>Accuracy improvement with increasing SAC levels is achieved in the reduced Bayesian observer model by biasing its beliefs towards the prior, relative to the latest evidence. In <xref rid="fig4" ref-type="fig">Figure 4A</xref> we show that participants also exhibit such biases. Since it is impossible to know the covert prior beliefs of participants, we instead used the predicted prior beliefs of the omniscient observer (i.e., the mean of all stimuli since the last changepoint) to compute the normalized biases (for both participants and modelled data). This prior location is probably not precise, but it allows us to approximate the experienced prediction error for the latest observation within a reasonable margin, i.e., <inline-formula><inline-graphic xlink:href="620874v2_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. We thus computed participants’ normalized bias towards the prior as <inline-formula><inline-graphic xlink:href="620874v2_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where a response at <inline-formula><inline-graphic xlink:href="620874v2_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula> results in 1, and a response at <italic>x</italic><sub><italic>t</italic></sub> indicates no bias. Note that this normalized bias corresponds to the product of prior relevance and reliability, <italic>Π</italic><sub><italic>t</italic></sub> <italic>τ</italic><sub><italic>t</italic></sub>, in <xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref> (although for the figure we computed the modelled biases in the same way as for the participants’ responses).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Normalized bias towards the prior (at 1) for SAC 1 trials (panel A) and signed bias towards the prior (positive sign) for SAC 2 and SAC 3 trials (panel B), as a function of the experienced prediction error. The prior’s location was approximated by means of the omniscient observer.</title>
<p>The traces depict the group-level median of the individuals’ local median response, as computed via a rolling kernel method. For appropriateness of that procedure, the prediction errors were non-linearly scaled to approximate a constant density of trials over the x-axis. Note that the rolling median results in small edge artifacts which cause the signed bias to appear larger than zero for the smallest prediction errors.</p>
<p>The blue shaded region depicts the range between the group-level 25% (Q1) and 75% (Q3) participants. For the modelled observers we only depict the group-level medians (naïve, omniscient, and reduced Bayesian, with default parameters or with parameters that were fit to the participants’ data; see <xref ref-type="sec" rid="s2c">section 2.3</xref>).</p></caption>
<graphic xlink:href="620874v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In <xref rid="fig4" ref-type="fig">Figure 4A</xref>, we have limited the analysis to SAC 1 trials only in order to clearly demonstrate the effect of increasingly large prediction errors. The pattern of a gradually decreasing normalized bias is similar to what is predicted by the reduced Bayesian observer model. This suggests that participants do indeed compute a prior relevance measure (<xref ref-type="disp-formula" rid="eqn4">Eq. 4</xref>) and use it to adaptively scale their bias towards the prior (<xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref>). In doing so, they effectively computed a weighted average of the two causal structures (changepoint or not) and thus incorporated causal uncertainty into their updated belief. Furthermore, we also observe an effect of the experimental noise condition. Relative to the low noise condition, the maximal bias for the high noise condition is smaller for small prediction errors (Wilcoxon signed rank test on biases at 20° prediction error: <italic>z</italic> = -1.98, <italic>p</italic> = 0.048, low noise = 0.17 [0.10 – 0.42], high noise = 0.13 [0.06 – 0.27]), but the bias remains higher for moderately large prediction errors (Wilcoxon signed rank test on biases at 40° prediction error: <italic>z</italic> = 2.02, <italic>p</italic> = 0.043, low noise = 0.09 [0.02 – 0.13], high noise = 0.10 [0.07 – 0.14]). Both of these effects were predicted by <xref ref-type="disp-formula" rid="eqn4">Eq. 4</xref> of the reduced Bayesian observer model via the noise dependence in the denominators of the a-priori relevance (peak bias for small predictions errors) and surprise term (reduction of relevance with prediction error size).</p>
<p>Next, we looked at the biases for SAC levels 2 and 3 (<xref rid="fig4" ref-type="fig">Figure 4B</xref>). Since the effect of small misestimations of participants’ prior (i.e., <inline-formula><inline-graphic xlink:href="620874v2_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula>) leads to excessive amounts of noise in the normalized biases at small prediction errors (also observed in the intersubject variance, see shaded area in <xref rid="fig4" ref-type="fig">Figure 4A</xref>), we instead focus here on non-normalized biases (<italic>response</italic> − <italic>x</italic><sub><italic>t</italic></sub>). However, we modified the bias signs to ensure that a positive bias always points towards the predicted prior location <inline-formula><inline-graphic xlink:href="620874v2_inline14.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Importantly, we only included SAC 2 trials for this analysis if they were preceded by a large prediction error (&gt;52.7°, as determined by a median split), such that the preceding changepoint had likely been noticed. Hence, the spatial prior for these SAC 2 trials should have been based on the preceding stimulus only. Likewise, we limited the analyses of SAC 3 trials to those trials that were associated with a large changepoint prediction error (&gt;52.7°), followed by a relatively small disparity between the next stimuli (i.e., |<italic>x</italic><sub><italic>t</italic>−2</sub> − <italic>x</italic><sub><italic>t</italic>−1</sub> | had to be &lt;13.7° or &lt;27.4° for the low and high noise conditions, respectively; where the threshold values were based on excluding one third of the trials with the largest disparities). Hence, the spatial prior for these SAC 3 trials should have been based on the average of the two preceding stimuli, and the prior’s spatial uncertainty <inline-formula><inline-graphic xlink:href="620874v2_inline15.gif" mime-subtype="gif" mimetype="image"/></inline-formula> for these SAC 3 trials should thus be smaller than the prior’s uncertainty for the SAC 2 trials.</p>
<p>The general pattern of the signed biases in <xref rid="fig4" ref-type="fig">Figure 4B</xref> is similar as predicted by the reduced Bayesian observer model: the bias towards the prior increases in size with increasing prediction errors, but then starts to flatten and eventually decrease at larger prediction errors as a result of the smaller prior relevance (<italic>Π</italic><sub><italic>t</italic></sub>). The peak of participants’ signed biases is approximately reached at a prediction error that is similar to the experimental noise, 10° and 20°. For larger prediction errors, participants apparently already start to question whether a changepoint has occurred. The reduced Bayesian observer model peaks later, at approximately 29° and 26° with low noise and 53° and 47° in the high noise condition, for SAC 2 and SAC 3 trials respectively. The predicted differences between the SAC levels occur because the spatial uncertainty of the prior <inline-formula><inline-graphic xlink:href="620874v2_inline16.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is smaller for SAC 3 than SAC 2, which increases the surprise (2<sup>nd</sup> term in <xref ref-type="disp-formula" rid="eqn4">Eq. 4</xref>), thus lowering the prior relevance at smaller prediction errors. These predicted small differences are not clearly observed in the participants’ data. However, another model prediction is that the size of the biases are larger for SAC 3 than for SAC 2, independent of the prediction error, because of a difference in the prior reliability <italic>τ</italic><sub><italic>t</italic></sub> (<xref ref-type="disp-formula" rid="eqn3">Eq. 3</xref>). Participants show this effect in the high noise condition (Wilcoxon signed rank test on biases at 20° prediction error: <italic>z</italic> = 2.15, <italic>p</italic> = 0.031, SAC 2 = 2.31° [1.02° – 6.25°], SAC 3 = 5.40 [2.23 – 7.74]), but not in the low noise condition (Wilcoxon signed rank test on biases at 10° prediction error: <italic>z</italic> = 0.42, <italic>p</italic> = 0.67, SAC 2 = 2.67° [1.08° – 4.54°], SAC 3 = 2.34 [1.28 – 5.73]).</p>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Parameter optimization</title>
<p>In the above analyses we have shown that hallmarks of Bayesian causal inference are present in the response patterns of the participants. However, quantitatively, the reduced Bayesian observer model with default parameters (<inline-formula><inline-graphic xlink:href="620874v2_inline17.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="620874v2_inline18.gif" mime-subtype="gif" mimetype="image"/></inline-formula> or 20°, for low and high noise conditions, respectively) does not show a very good fit. In particular, the model severely overestimates participants’ biases towards the prior. Assuming that the principal mechanisms for Bayesian causal inference are present in the brain (Sham &amp; Beierholm, 2022), one plausible suggestion to reconcile the experimental results to the theoretical predictions is that participants were using incorrect estimates of the model’s parameters (<xref ref-type="bibr" rid="c34">Nassar et al., 2010</xref>). For example, larger changepoint hazard rate estimates, <inline-formula><inline-graphic xlink:href="620874v2_inline19.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, would have the effect of decreasing the prior relevance <italic>Π</italic><sub><italic>t</italic></sub> independent of the prediction error, thus resulting in smaller biases overall.</p>
<p>Participants were given the opportunity to learn about the changepoint hazard rate (<italic>H</italic><sub><italic>cp</italic></sub>) and the amount of experimental noise (σ<sub><italic>exp</italic></sub>) in both conditions in a practice session. However, learning these parameters by merely observing the stimuli locations is no easy task (<xref ref-type="bibr" rid="c57">Wilson et al., 2010</xref>; <xref ref-type="bibr" rid="c41">Piray &amp; Daw, 2021</xref>). A large prediction error may indicate that a changepoint occurred. If many changepoints are inferred, then the subjective hazard rate estimate should be larger. But prediction errors can alternatively be interpreted as due to random noise, in which case the subjective experimental noise estimate should be larger. Inference about the parameters of the generative process thus essentially revolves around a volatility (changepoint) vs. stochasticity (noise) trade-off, similar to the causal inference problem itself. Therefore, we would expect the two parameter estimates, <inline-formula><inline-graphic xlink:href="620874v2_inline20.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="620874v2_inline21.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, to be anticorrelated.</p>
<p>One method that the brain may apply to learn such ‘environmental parameters’ is based on an objective to minimize overall surprise (<xref ref-type="bibr" rid="c13">Friston, 2010</xref>). Without specifying how such a learning algorithm may work, we here computed the overall surprise that a reduced Bayesian observer would experience in the current experiment (i.e., summed over all stimuli) for a large number of predetermined parameter combinations (<inline-formula><inline-graphic xlink:href="620874v2_inline22.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="620874v2_inline23.gif" mime-subtype="gif" mimetype="image"/></inline-formula>) on a regular grid (see <xref ref-type="sec" rid="s4j">section 4.10</xref>). The predicted amounts of surprise are visualized as a background colour coding in <xref rid="fig5" ref-type="fig">Figure 5A</xref>. One can see that an agent with parameter estimates near the true values (<inline-formula><inline-graphic xlink:href="620874v2_inline24.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="620874v2_inline25.gif" mime-subtype="gif" mimetype="image"/></inline-formula> or 20°) minimizes the overall surprise. Some parameter combinations are predicted to lead to excessively high amounts of surprise (e.g., <inline-formula><inline-graphic xlink:href="620874v2_inline26.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="620874v2_inline27.gif" mime-subtype="gif" mimetype="image"/></inline-formula>), thus indicating that such parameter estimates would lead to a significant mismatch between the stimuli locations that are predicted and those that are experienced. However, for many parameter combinations near the true values, surprisal remains relatively low. This suggests that all such estimates are reasonably likely for near-Bayesian observers that effectively learn the statistics of their sensory environment. The expected anticorrelation between the hazard rate and experimental noise estimates is highlighted as a dashed line (indicating the value of <inline-formula><inline-graphic xlink:href="620874v2_inline28.gif" mime-subtype="gif" mimetype="image"/></inline-formula> that minimizes surprisal for a particular value of <inline-formula><inline-graphic xlink:href="620874v2_inline29.gif" mime-subtype="gif" mimetype="image"/></inline-formula>).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Fitted parameter values of the reduced Bayesian observer model.</title>
<p>Panel A. depicts the fitted changepoint hazard rate <inline-formula><inline-graphic xlink:href="620874v2_inline95.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and experimental noise <sup><inline-formula><inline-graphic xlink:href="620874v2_inline96.gif" mime-subtype="gif" mimetype="image"/></inline-formula></sup> estimates of the individual participants (separately for both experimental noise conditions, in left and right panel) on top of a modelled surface of overall (summed) surprisal levels that a reduced Bayesian observer would experience with such parameter values. Surprisal is minimized for parameter estimates that are equal to the true generative parameter values (thin dotted black lines). The dashed black lines illustrate the expected negative correlation between hazard rate and experimental noise estimates.</p>
<p>Panels B and C show the same fitted hazard rates and experimental noise estimates, but now as a comparison of the noise conditions.</p>
<p>Individuals’ colour coding depends on the model comparison results (<xref ref-type="sec" rid="s2d">section 2.4</xref> and <xref rid="fig7" ref-type="fig">Figure 7B</xref>): dark red for participants that are better fit by models with a larger memory capacity, light red for participants that are better fit by the reduced Bayesian observer model with limited memory capacity, and grey otherwise.</p></caption>
<graphic xlink:href="620874v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To obtain estimates of the parameters that participants may have used during the task we fitted the reduced Bayesian observer model to each set of responses from one individual and one experimental noise condition (by means of maximum likelihood estimation, see <xref ref-type="sec" rid="s4i">section 4.9</xref>). As expected by the relatively low biases (see <xref rid="fig4" ref-type="fig">Figure 4</xref>), we found that the fitted hazard rates for most participants were much higher than the true hazard rate (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). While there was considerable variance of the fitted hazard rates across participants, the values per participant were quite consistent across the two experimental conditions (Pearson’s correlation coefficient ρ = 0.81). Furthermore, we found that the fitted experimental noise parameters (<xref rid="fig5" ref-type="fig">Figure 5C</xref>) were reasonably accurate for most participants, though not for all, and they were smaller in the low noise condition than in the high noise condition (low noise <inline-formula><inline-graphic xlink:href="620874v2_inline30.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, high noise <inline-formula><inline-graphic xlink:href="620874v2_inline31.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, Wilcoxon signed rank test: <italic>z</italic> = -2.17, <italic>p</italic> = 0.030). Interestingly, we did not observe the predicted negative correlation between the fitted hazard rates and log-transformed experimental noise parameters (Pearson’s <italic>ρ</italic> = -0.04 and <italic>ρ</italic> = -0.02, for low and high noise condition respectively, but these correlations were not significant: <italic>p</italic> &gt; 0.8). In fact, most of the largest experimental noise parameters were for participants whose hazard rate estimates were also large (<xref rid="fig5" ref-type="fig">Figure 5A</xref>). Those participants showed overall small biases (large <inline-formula><inline-graphic xlink:href="620874v2_inline32.gif" mime-subtype="gif" mimetype="image"/></inline-formula>) that were nonetheless non-zero even at large prediction errors (large <inline-formula><inline-graphic xlink:href="620874v2_inline33.gif" mime-subtype="gif" mimetype="image"/></inline-formula>).</p>
<p>Allowing the changepoint hazard rate and experimental noise parameters to be fitted freely significantly improved the quality of the fits in terms of the coefficient of determination: R<sup>2</sup> = 0.97 [0.92 – 0.98] and R<sup>2</sup> = 0.94 [0.88 – 0.97], for low and high noise conditions, respectively. This is marginally higher (∼1% point) than the reduced Bayesian observer model with default parameter values, i.e., with <inline-formula><inline-graphic xlink:href="620874v2_inline34.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="620874v2_inline35.gif" mime-subtype="gif" mimetype="image"/></inline-formula> or <inline-formula><inline-graphic xlink:href="620874v2_inline36.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (Wilcoxon signed rank tests: <italic>z</italic> &gt; 4, p &lt; .001, for both conditions), and equally better than the naïve observer model (<italic>z</italic> &gt; 4, <italic>p</italic> &lt; .001, for both conditions). A more informative measure for the model’s improvement in quality of fit is the amount of explained variation in participants’ errors (<italic>response</italic> − <italic>μ</italic><sub><italic>t</italic></sub>, i.e., as in <xref rid="fig3" ref-type="fig">Figures 3B</xref> and <xref rid="fig3" ref-type="fig">3C</xref>). The group-level medians are R<sup>2</sup> = 0.45 vs. 0.36 vs. 0.28, and R<sup>2</sup> = 0.67 vs. 0.53 vs. 0.57, for the three models (reduced Bayesian model with fitted parameters, vs. with default parameters, vs. the naïve observer model) in the low and high noise conditions, respectively. N.b. remaining response variance was explained by the fitted reduced Bayesian observer model by means of occasional lapses (lapse rates <italic>λ</italic> = 0.017 [0.008 - 0.045] and <italic>λ</italic> = 0.043 [0.021 - 0.063], for low and high noise conditions, respectively) and by random response noise (σ<sub><italic>resp</italic></sub> = 5.64° [3.65° – 8.26°] and σ<sub><italic>resp</italic></sub> = 5.93° [3.90° – 11.0°]). Nevertheless, depicted predictions for the model with optimized parameter values in <xref rid="fig3" ref-type="fig">Figures 3</xref> and <xref rid="fig4" ref-type="fig">4</xref> (dashed lines) do not include such lapses or response noise.</p>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Model comparison</title>
<p>The reduced Bayesian observer model is a simplification of the fully Bayesian observer model. While the latter is unrealistic because of its complexity, the former is certainly not the only plausible inference algorithm. Here, we will compare the reduced Bayesian observer model against variations of itself that rely on different modelling assumptions.</p>
<p>The most striking simplification of the reduced Bayesian observer model is its limited memory requirement. The prior distribution at any timepoint is described by merely two parameters: the mean and uncertainty estimates about the generative mean (<inline-formula><inline-graphic xlink:href="620874v2_inline37.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="620874v2_inline38.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, respectively). That prior distribution approximates the weighted mixture of the two conditional prior distributions for each causal structure with regards to the preceding stimulus: changepoint or not. The fully Bayesian observer model (<xref ref-type="bibr" rid="c3">Adams &amp; MacKay, 2007</xref>) does not compute such approximate summary distributions. Instead, it remembers the conditional distributions and their associated weights (i.e., relevance). The advantage is that the weights of the conditional distributions can still be adjusted after new observations become available. For example, an agent may be uncertain about a possible changepoint at first, but this uncertainty may disappear if the next observation returns to a location that fits better with the previous prior. In that case, the spatial prediction of a fully Bayesian observer would correctly be dominated by the mean of all relevant stimuli, despite the temporary causal uncertainty that accompanied the penultimate stimulus. On the other hand, the memory-constrained reduced Bayesian observer’s prediction would generally be (slightly) less accurate (and more uncertain) because the observations are not weighted optimally: weight cannot be returned to observations whose relevance was once questioned (<xref rid="fig6" ref-type="fig">Figure 6A</xref>).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Illustration of the modelling framework with four factors: memory capacity (A), late truncation simplification (B), decision strategy (C), and pruning function (D).</title>
<p>A). The three panels depict a sequence of three stimuli (top to bottom) that illustrate the inference difference between a reduced Bayesian observer (M = 1, posterior depicted as dashed red line) and a similar Bayesian model with larger memory capacity (M ≥ 3, solid orange line with shaded area). Posterior distributions of models with extended memory consist of a weighted mixture of multiple nodes (dashed orange lines with a, b, and c letter indicators). The node’s weight indicates its relative posterior relevance for the inferred location of the generative mean. In this sequence, the second stimulus leads to high causal uncertainty (nearly equal weight for both nodes: a. latest cp at <italic>t=1</italic>, b. latest cp at <italic>t</italic>=2), but the third stimulus increases the inferred relevance of the node that codes for the hypothesis that no changepoint took place (a): i.e., it is most probable that all three stimuli stem from the same generative mean, and it is least probable that a changepoint took place at <italic>t</italic>=3 (c). The reduced Bayesian observer cannot retrospectively reassign weights to nodes and is therefore slightly less accurate (here: small bias towards penultimate stimulus) and less precise (larger spatial uncertainty) than a near-Bayesian observer with larger memory capacity.</p>
<p>B). The late truncation simplification implies that the space boundaries are ignored until a response has to be given. At that point, the observer’s best prediction is moved to within the generative mean range, only if necessary. Without the simplification, observers compute the expectation (i.e., mean) of the truncated normal distribution as their best prediction, and this will bias their response towards the centre of space. Here, the difference is illustrated for a response at <italic>t</italic>=1 (from panel A). With the simplification, the observer responds to the mean of the (non-truncated) normal distribution: subsequent movement of the intended response location to within the generative mean range is unnecessary in this example.</p>
<p>C). Whenever the posterior distribution consists of more than one node, the observer needs to decide on how to make a response (here depicted for <italic>t</italic>=2). The model averaging decision function computes the expectation of the weighted mixture distribution as its best prediction, thus essentially averaging two models of the world (i.e., nodes a and b). Instead, the model selection decision function deterministically selects the node with the highest weight (i.e., inferred relevance) as a base for its prediction response.</p>
<p>D). The node pruning function determines how an observer satisfies the memory capacity limit <italic>M</italic>. Whenever the number of posterior nodes exceeds the memory capacity, the pruning function ensures that the prior for <italic>t+1</italic> consists of no more than <italic>M</italic> nodes. Here, this is depicted for the case at <italic>t</italic>=3, with a memory capacity of M=2. The keep_<italic>WAVG</italic> pruning function merges the oldest two nodes (a and b) by computing a weighted average node (while the newest node, c, for a cp at t=3, remains in memory as well, despite its small weight). The keep_<italic>MAXP</italic> pruning function keeps the node with the highest weight of the oldest two nodes and discards the other (i.e., node a is kept, b is discarded), whereas the keep_<italic>RCNT</italic> pruning function always keeps the most recent of the two oldest nodes (i.e., node b is kept, a is discarded). The node that is kept in memory also receives the weight of the discarded node, such that it now represents the hypothesis of a cp at t ≤ 2.</p></caption>
<graphic xlink:href="620874v2_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>So, being able to juggle multiple competing hypotheses simultaneously is beneficial for task performance. Moreover, it seems intuitive that humans are able to remember the approximate locations of at least a few recent stimuli, while also maintaining uncertainty about the presence of recent changepoints. Therefore, one of the primary factors of interest in our model comparison was the model’s memory capacity. We compared models whose predictive mixture distributions consisted of up to four conditional distributions, i.e., memory capacity <italic>M</italic> ∈ {1,2,3,4}. These conditional distributions are often referred to as ‘nodes’ of the full mixture distribution (e.g., <xref ref-type="bibr" rid="c57">Wilson et al., 2010</xref>, where the terminology is based on a graphical model depiction). Here, each node is represented by three parameters: its mean, variance, and weight (see <xref ref-type="sec" rid="s4c">section 4.3</xref>).</p>
<p>The reduced Bayesian observer model limits the memory capacity to <italic>M</italic> = 1 by summarizing its two conditional distributions via a weighted average (<xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref>) after every observation. Essentially, it thus merges two nodes into one at every timepoint. We can flexibly extend the model’s memory capacity by merging progressively older nodes. The newest nodes, that are conditional on the hypothesis of a recent changepoint, and whose contributing stimuli are still fresh in memory, remain unchanged. For example, a model with a memory capacity of <italic>M</italic> = 4 would summarize its oldest two nodes such that the merged node is associated with the hypothesis that the last changepoint occurred four <italic>or more</italic> stimuli ago, while the latest three nodes are also kept in memory (see <xref ref-type="sec" rid="s4e">section 4.5</xref>).</p>
<p>Besides merging nodes via a <italic>weighted average</italic> (i.e., keep_<italic>WAVG</italic> node), one can also constrain the memory requirements via different rules (<xref rid="fig6" ref-type="fig">Figure 6D</xref>). For example, it has been suggested that humans may simply forget the oldest node once memory capacity has been exceeded (<xref ref-type="bibr" rid="c50">Skerritt-Davis &amp; Elhilali, 2018</xref>). In that case an agent would only remember evidence that is associated with the hypotheses of a changepoint at any of the <italic>recent</italic> timepoints (keep<italic>_RCNT</italic>). A third option that was proposed previously (<xref ref-type="bibr" rid="c3">Adams &amp; MacKay, 2007</xref>) is to discard nodes based on their inferred relevance (i.e., the nodes’ weights). In our implementation here, we keep either of the two oldest nodes, whichever has a <italic>larger probability</italic> of being relevant (keep_<italic>MAXP</italic>). We refer to these three procedures as node pruning functions (<xref ref-type="bibr" rid="c57">Wilson et al., 2010</xref>). Note that a model with the keep_<italic>RCNT</italic> pruning function and with minimal memory capacity, <italic>M</italic> = 1, is identical to the naïve observer model that we introduced in <xref ref-type="sec" rid="s2b">section 2.2</xref>.</p>
<p>Whenever the prior distribution consists of more than one node at the end of a trial (<italic>M</italic> &gt; 1), the observer needs to decide on how to form a single prediction response out of the mixture distribution (see <xref ref-type="sec" rid="s4f">section 4.6</xref>). A Bayesian observer that attempts to minimize its squared errors computes a weighted average of the nodes’ means as its best prediction for the generative mean. Since each node is associated with a particular model of the world (i.e., causal structure), specifying when the last changepoint occurred, this decision strategy is known as ‘model averaging’ (<xref ref-type="bibr" rid="c59">Wozny et al., 2010</xref>). The consequence of model averaging is that an agent accepts to be somewhat wrong about the state of the world most of the time, but it avoids occasionally making excessively large errors. However, different strategies are also possible (<xref rid="fig6" ref-type="fig">Figure 6C</xref>). For example, under the ‘model selection’ decision strategy, an agent would instead attempt to maximize its accuracy most of the time, while occasionally accepting a large error. This agent selects the mean of the node with the largest weight (i.e., relevance) as its best prediction for the location of the generative mean.</p>
<p>A final factor that we consider in our model comparison is related to the computational complexity that arises as a result of the finite spatial interval of the generative mean <italic>μ</italic><sub><italic>t</italic></sub> (i.e., here between -90° and 90°). Bayesian observers account for the interval when they update the weights of the nodes by means of a complex computation that depends on the distance of the stimulus location to the interval’s boundaries (<xref ref-type="sec" rid="s4c">section 4.3</xref>) and again in the response decision phase when they compute the spatial expectations of the nodes (<xref ref-type="sec" rid="s4f">section 4.6</xref>). However, these complex computations can be omitted at the cost of a limited accuracy loss by only considering the interval constraint at the very end of the decision-making process. Under the late truncation simplification hypothesis (<xref rid="fig6" ref-type="fig">Figure 6B</xref>) spatial predictions are initially formed using simplified computations which do not account for the locations of the stimuli relative to the spatial boundaries, but the final prediction is moved to the nearest boundary if it would otherwise be outside of the generative mean interval (<xref ref-type="sec" rid="s4g">section 4.7</xref>). Note that the reduced Bayesian observer model makes use of the late truncation simplification.</p>
<p>In the above, we have described a framework of near-Bayesian models in which we combine the following factors: 1) memory capacity, 2) node pruning function, 3) decision strategy, and 4) late truncation simplification. In total, we fitted 42 model variations. There were 6 models with a minimal memory capacity (<italic>M</italic> = 1), one for each of the three pruning functions (keep_<italic>WAVG</italic>, keep_<italic>MAXP</italic>, and keep_<italic>RCNT</italic>) with and without the late truncation simplification. The other 36 model versions with larger memory capacity were organized factorially for <italic>M</italic> ∈ {2, 3, 4}, the three pruning functions, two decision strategies, and with and without truncation simplification. Since we fitted each model separately to the responses of both experimental noise conditions (to be able to compare the fitted parameters independently, see <xref rid="fig5" ref-type="fig">Figure 5</xref>), there were 84 model fits per subject. The models’ abilities to predict participants responses were compared by means of the log model evidence (<italic>lme</italic>; higher values indicate better fits), which is based on a sum of the maximized log likelihoods of the two conditions (see <xref ref-type="sec" rid="s4i">section 4.9</xref>).</p>
<p><xref rid="fig7" ref-type="fig">Figure 7A</xref> depicts the group-level results for a fixed effects analysis (i.e., summed <italic>lme</italic> over participants). That analysis serves as a useful overview of the relative differences in predictive performance of all the models. However, we will draw conclusions from a selection of family-wise random effects analyses that are more robust to outlier subjects by allowing for group-level heterogeneity (<xref ref-type="bibr" rid="c52">Stephan et al., 2009</xref>; <xref ref-type="bibr" rid="c46">Rigoux et al., 2014</xref>; <xref ref-type="bibr" rid="c1">Acerbi et al., 2018</xref>). First, we focus on a comparison of the six models with <italic>M</italic> = 1. A 3 × 2 factorial analysis revealed a strong preference for the keep_<italic>WAVG</italic> pruning function (protected exceedance probability <italic>pxp</italic> = 1.00 for keep_<italic>WAVG vs. 0</italic>.<italic>00</italic> for both keep_<italic>MAXP</italic> and keep_<italic>RCNT</italic>) and a moderate preference for the late truncation simplification (<italic>pxp</italic> = 0.73 vs. 0.27). Next, we examined the 36 larger memory capacity models in a 3 × 3 × 2 × 2 factorial analysis. The result confirmed the preferences for the keep_<italic>WAVG</italic> pruning function and the late truncation simplification (<italic>pxp</italic> = 0.93 for keep_<italic>WAVG</italic> vs. 0.04 for keep_<italic>MAXP</italic> vs. 0.03 for keep_<italic>RCNT</italic>; and <italic>pxp</italic> = 0.96 vs. 0.04 in favour of the simplification). Moreover, the model averaging decision strategy seems to be crucial for larger memory models to fit participants’ responses well (<italic>pxp</italic> = 0.97 for model averaging vs. 0.03 for model selection). The fixed effects analysis, as depicted in <xref rid="fig7" ref-type="fig">Figure 7A</xref>, demonstrates that the choice of pruning function loses importance as the model’s memory capacity increases, while the model-averaging decision strategy becomes increasingly decisive as more nodes are available for a response decision.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Model Comparison Results.</title><p>Panel A shows the fixed effects model comparison for the 42 models. The y-axis denotes the log model evidence (<italic>lme</italic>) of each model, summed across participants, relative to the reduced Bayesian observer model (memory capacity <italic>M</italic> = 1, keep_<italic>WAVG</italic> pruning function, model averaging decision strategy, and with late truncation simplification). The <italic>lme</italic> difference is dominated by the pruning function (colour coding) at low memory capacity (x-axis), while it is dominated by the decision strategy (light vs. dark) at larger memory capacities. Models with the model averaging decision strategy fit participants’ data better with the late truncation simplification, while models with the selection decision strategy generally fit better without the simplification. Panel B zooms in on the individual results of the memory capacity factor (x-axis), for models with keep_<italic>WAVG</italic> pruning function, model averaging decision strategy, and with late truncation simplification. Each line depicts the <italic>lme</italic> differences for one participant. The colour coding separates participants that were better fit by models with larger memory capacity (dark red), and participants who responded more like reduced Bayesian observers (light red), from participants without a clear preference (grey).</p></caption>
<graphic xlink:href="620874v2_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To be able to fairly compare all four memory capacity settings against each other, we selected the four models that incorporated the late truncation simplification, the keep_<italic>WAVG</italic> pruning function, and the model averaging decision strategy (i.e., the preferred settings based on the previous analyses). The comparison was inconclusive, with an almost equal preference for each memory capacity (<italic>pxp</italic> = 0.25 vs. 0.24 vs. 0.25 vs. 0.26, for M from 1 to 4, respectively). The ambiguous result can be explained by a combination of two reasons that become clear when we plot the log model evidence of these four models for each individual (<xref rid="fig7" ref-type="fig">Figure 7B</xref>). First, most participants don’t seem to show a significant preference for any of the memory capacity settings (<italic>lme</italic> differences &lt; 1, i.e., corresponding Bayes Factors &lt; 3). Second, there is some heterogeneity in the population with six participants that are better fit by the larger memory capacity models, whereas the reduced Bayesian observer model (<italic>M</italic> = 1) is the best-fitting model for four other participants. <xref rid="fig7" ref-type="fig">Figure 7B</xref> also demonstrates that there are only minimal differences in the goodness-of-fit between the three larger memory capacity models. This is because these models make very similar predictions. So, while a memory extension to <italic>M</italic> = 2 is preferred to <italic>M</italic> = 1 by some participants (but not by others; a direct comparison is non-decisive: <italic>pxp</italic> = 0.31 vs. 0.69 in favour of <italic>M</italic> = 2), adding more model complexity through further memory extensions (<italic>M</italic> &gt; 2) is not warranted by these results.</p>
<p>Finally, we note that there were only minimal differences between the fitted parameter values of the reduced Bayesian observer model (<italic>M</italic> = 1) and its model variation with larger memory (<italic>M</italic> = 2). The Pearson correlation coefficients, across participants, were <italic>ρ</italic> = 0.989 and <italic>ρ</italic> = 0.988 for (log-) experimental noise parameters, and <italic>ρ</italic> = 0.997 and <italic>ρ</italic> = 0.998 for the hazard rates (low and high noise conditions, respectively). Interestingly, we noticed a trend in the fitted parameter values of the four participants with a preference for the <italic>M</italic> = 1 memory setting: they all had relatively low hazard rates (&lt;0.55, for both conditions; <xref rid="fig5" ref-type="fig">Figure 5B</xref>). This may potentially be indicative of individual differences in decision strategies. However, we are cautious about any such conclusion given the low number of participants with a clear model preference.</p>
</sec>
</sec>
<sec id="s3">
<label>3.</label>
<title>Discussion</title>
<p>In the current paper we have analysed the problem of changepoint detection in noisy environments from a perspective of Bayesian causal inference (<xref ref-type="bibr" rid="c48">Shams &amp; Beierholm, 2022</xref>). The fundamental question that observers face is whether novel sensory signals should be integrated with prior beliefs to improve precision, or whether an environmental change has occurred that has rendered the prior irrelevant. The reduced Bayesian observer model (<xref ref-type="bibr" rid="c33">Nassar et al., 2012</xref>) puts this causality question centre stage after every new observation (<xref ref-type="disp-formula" rid="eqn4">Eq. 4</xref>) and then summarizes the probabilistic result to keep complexity at a minimum (<xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref>). As such, it provides an elegantly simple algorithm for iterative Bayesian causal inference that can be utilized to estimate latent sources of consecutive sensory signals in volatile environments.</p>
<p>We tested the model’s performance in explaining human perceptual decisions on a behavioral dataset wherein participants made prediction responses after having been presented a sequence of noisy observations from static sources with occasional changepoints (Krishnamurthy, Nassar, et al., 2017). Our analyses brought forth three main findings: 1. The reduced Bayesian observer model predicted the response patterns qualitatively well. 2. It required freely fitting the model’s parameters to also quantitatively fit well. 3. Model comparison favoured the reduced Bayesian observer model over many model variations, but it was inconclusive with regards to the model’s memory capacity. In what follows, we shall discuss these three findings one by one and relate them to relevant literature in general and previous reports of learning in volatile environments in particular.</p>
<sec id="s3a">
<label>3.1.</label>
<title>Hallmarks of Bayesian causal inference</title>
<p>We have shown that observers were partially able to average out noise from sequential observations during ongoing stimulus streams and thereby improved the accuracy of their predictions when more than one stimulus was available to base their decision on. In line with findings from cue integration experiments, they achieved this by weighing new sensory evidence versus existing beliefs according to their relative reliabilities (<xref ref-type="disp-formula" rid="eqn3">Eq. 3</xref>; prior attraction is larger for SAC 3 than for SAC 2 in the high noise condition). However, reliability is not the only factor that determines integration weights (<xref ref-type="bibr" rid="c30">Meijer et al., 2019</xref>; <xref ref-type="bibr" rid="c44">Rahnev &amp; Denison, 2018</xref>). Since observers found themselves in a volatile environment, wherein prior information was not always relevant for their predictions, they dynamically reduced the prior’s weight in accordance with its inferred relevance.</p>
<p>According to the reduced Bayesian observer model, the weight of the prior is determined by the product of prior reliability and prior relevance (<xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref>). The latter depends on an a-priori belief about the prior’s relevance as well as a surprise-based posterior evaluation (<xref ref-type="disp-formula" rid="eqn4">Eq. 4</xref>). In agreement with the model’s predictions, we found that reliance on the prior was larger in the low experimental noise condition than in the high experimental noise condition, at least for relatively small spatial disparities between the prior’s prediction and the latest observation. As the prediction error grew larger, the prior’s inferred relevance declined, and so we saw a gradual decrease of the normalized bias towards the prior (i.e., a measure of the prior’s weight). Moreover, the biases decreased faster in the low noise condition, because moderate prediction errors result in a larger surprise when the prior’s predictive precision is larger. Vice versa, the experimental condition with more stochastic noise led to flatter curves, thus less modulation of the prior’s weight as a function of the prediction error.</p>
<p>Smooth transitions from a large bias towards highly relevant priors, to near-zero biases for irrelevant priors, as we observed here, are modelled via a weighted average between two causal structures (i.e., models of the world that explain the causes of sensory signals; see <xref rid="fig1" ref-type="fig">Figure 1</xref>). In the reduced Bayesian observer model with limited memory (M=1) weighted averaging is established via the keep_<italic>WAVG</italic> pruning function, while for models with larger memory capacities this occurs primarily via the model averaging decision strategy. Regardless, models that compute a weighted average over the causal structures explained participants’ responses significantly better than models that did not (e.g., model selection decision strategy). By computing a weighted average, an observer essentially accounts for the uncertainty about the inferred causal structure. In the case of the reduced Bayesian observer model, the causal uncertainty is also literally incorporated into the updated belief about the source location via an additive term for the spatial uncertainty (<xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref>; <xref rid="fig2" ref-type="fig">Figure 2D</xref>). This effectively ensures that appropriately low reliability is attributed to the updated prior at the next timestep if there was considerable uncertainty about the occurrence of a changepoint at the current timestep.</p>
<p>In the learning literature there has been a long-standing debate about the use of the prior relevance measure as a flexible moderator for the extent to which beliefs should be updated after a new observation. In that field it is common to speak of learning rates (taking perspective from the current belief) instead of biases towards the prior (from the perspective of the latest sensory signal), but in the current changepoint paradigm they are mathematically interchangeable: the momentary learning rate (<italic>α</italic><sub><italic>t</italic></sub>) is equal to one minus the normalized bias (i.e., <italic>α</italic><sub><italic>t</italic></sub> = 1 − <italic>Π</italic><sub><italic>t</italic></sub> <italic>τ</italic><sub><italic>t</italic></sub>). In the seminal delta rule model by <xref ref-type="bibr" rid="c45">Rescorla &amp; Wagner (1972)</xref> learning rates <bold>were assumed to be constant. However, later models, e.g</bold>., <bold>by </bold><xref ref-type="bibr" rid="c38">Pearce &amp; Hall (1980)</xref><bold>, allowed</bold> learning rates to adjust flexibly to the size of the prediction error (<xref ref-type="bibr" rid="c23">Lee et al., 2020</xref>). As discussed, our results indicate that learning rates are indeed flexibly adjusted by the interaction of prior reliability and prior relevance (<xref rid="fig4" ref-type="fig">Figure 4</xref>).</p>
<p>Nevertheless, there are other recent studies that report a preference for a simpler heuristic with a constant learning rate (e.g., exponential decay or leaky accumulator models; <xref ref-type="bibr" rid="c47">Ryali et al., 2018</xref>; <xref ref-type="bibr" rid="c35">Norton et al., 2019</xref>). We believe that many such contradictory findings can be explained by the experimental task design which may not provide sufficient variety in the surprise term of the prior relevance, such that the learning rates only vary insignificantly even if an optimal adaptive strategy is applied (i.e., observations are information-poor; <xref ref-type="bibr" rid="c47">Ryali et al., 2018</xref>). For example, this may be the case in tasks that require observers to estimate a probability or to weigh two alternatives probabilistically. In such tasks, a single observation cannot be decisive evidence for a changepoint (or not), so the prior relevance does not take extreme values near zero (or one). This will also be the case for experiments with relatively large amounts of stochastic noise (e.g., experimentally induced, but potentially also due to sensory noise). As explained above, the prior relevance curve of an ideal observer in more noisy conditions will be relatively flat (as a function of prediction error). Under such high noise conditions, it may be difficult to conclude whether observers employ causal inference because the measured biases will appear very similar to a learner with a fixed learning rate (see also <xref ref-type="bibr" rid="c16">Heilbron &amp; Meyniel, 2019</xref>). Moreover, we cannot exclude the possibility that humans choose to use a simpler cost-effective heuristic in a high uncertainty environment in which more complex solutions do not substantially improve accuracy (<xref ref-type="bibr" rid="c54">Tavoni et al., 2022</xref>; <xref ref-type="bibr" rid="c56">Verbeke &amp; Verguts, 2024</xref>). Nonetheless, it is worth emphasizing that our results strongly suggest that changepoint designs with a moderately large range to noise ratio, such as the task that was used here (<xref rid="c21" ref-type="bibr">Krishnamurthy, Nassar, et al., 2017</xref>), introduce highly dynamic learning where observers adapt their use of the prior in accordance with its inferred relevance, thus confirming the key principle of Bayesian causal inference.</p>
</sec>
<sec id="s3b">
<label>3.2.</label>
<title>Reduced reliance on prior</title>
<p>We found that the reduced Bayesian observer model generally overestimated the biases towards the prior when its parameters were set to the correct values, i.e., the experimental noise and changepoint hazard rate that were used to generate the stimuli sequences. In other words, we reproduced previous reports that humans systematically used higher learning rates than an ideal observer would have done (<xref ref-type="bibr" rid="c34">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="c23">Lee et al., 2020</xref>, <xref ref-type="bibr" rid="c4">Bakst &amp; McGuire, 2023</xref>). One may hypothesize that lower-than-ideal bias sizes can be explained by misestimation of the changepoint hazard rate. Specifically, if observers expect there to be more changepoints, then this would reduce the a-priori relevance of their priors. However, if participants did indeed overestimate the changepoint hazard rate, then we hypothesized that their experimental noise estimates should also be smaller than the true value. This is because of the expected trade-off between noise and changepoint inference rates for relatively large prediction errors (<xref ref-type="bibr" rid="c37">Payzan-LeNestour &amp; Bossaerts, 2011</xref>; <xref ref-type="bibr" rid="c41">Piray &amp; Daw, 2021</xref>).</p>
<p>We proceeded by fitting the reduced Bayesian observer model to the response data. The optimized hazard rate parameters were indeed (much) larger than the true changepoint rate, although there were considerable individual differences. Larger hazard rates reduced the modelled prior relevance, and therefore the biases, thus resulting in improved model fits to the response data. However, the optimized noise parameters were reasonably accurate; they were certainly not smaller than the true values, as would be expected from the presumed trade-off between experienced volatility and stochasticity. We interpret the lack of a trade-off as an indication that the fitted hazard rate parameters are not illustrative for the rate with which participants experienced changepoints. Instead, we believe that the optimized parameter values signify a reduced a-priori trust in the relevance of the prior, or a strategic choice to not rely on the prior as much as the reduced Bayesian observer. In other words, the probability <inline-formula><inline-graphic xlink:href="620874v2_inline39.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (or the non-negative quantity <inline-formula><inline-graphic xlink:href="620874v2_inline40.gif" mime-subtype="gif" mimetype="image"/></inline-formula> in <xref ref-type="disp-formula" rid="eqn4">Eq. 4</xref>) should rather be viewed as an individual’s tendency to bind novel sensory signals with existing beliefs. Similar binding tendencies, their plasticity and individual differences are an active area of research in the field of sensory cue integration (<xref ref-type="bibr" rid="c43">Quintero et al., 2022</xref>).</p>
<p>The lower-than-ideal binding tendencies for consecutive cues are in curious contradiction with the fact that human observers are often biased towards preceding stimuli and responses, also in experiments when there is no consistent relationship between successive stimuli or trials (thus when there is no benefit of such a bias). One explanation for these so-called serial dependence biases is that observers have learned that the world is generally stable, thus prior beliefs persist to stabilise perception even when objectively irrational within a rapidly changing experimental context (<xref ref-type="bibr" rid="c18">Kiyonaga et al., 2017</xref>). So, why would observers not make full use of prior information in experiments where it is actually useful to do so (like here)?</p>
<p>One plausible reason may be specific to the artificially volatile environment in changepoint paradigms. This may prompt participants to explicitly focus on the causality question (changepoint or not), thus making them overly attentive for deviations from stability. Relatedly, multisensory cue integration experiments have demonstrated that tasks that require explicit causal decisions result in more segregated percepts as compared to implicit causal inference tasks (<xref ref-type="bibr" rid="c1">Acerbi et al., 2018</xref>). Hence, being very aware of the constant potential for a changepoint could markedly reduce the extent to which one integrates consecutive sensory signals, independent of the actual hazard rate. By focusing on not missing any of the changepoints, participants may have adopted a suboptimal strategy for dealing with the changepoint versus noise trade-off. Bayesian ideal observers occasionally falsely infer ‘no changepoint’ (on SAC 1 trials), and so they bias their responses towards an irrelevant prior. In exchange, they more often than not correctly integrate successive stimuli (SAC &gt; 1) and thus gain accuracy overall. Instead, it seems that participants opted for a more conservative strategy that avoids making relatively large errors by incorrectly biasing their responses towards irrelevant priors after changepoints, and in exchange they accept a moderate precision reduction overall, i.e., increased response variance but less bias. The choice of strategy can thus be seen as an instance of the bias-variance trade-off, which has previously been proposed to underly individual differences in learning rates (<xref ref-type="bibr" rid="c15">Glaze et al., 2018</xref>; <xref ref-type="bibr" rid="c9">Eissa et al., 2022</xref>). Additionally, participants’ behavior is in line with the Ellsberg paradox (<xref ref-type="bibr" rid="c10">Ellsberg, 1961</xref>; <xref ref-type="bibr" rid="c55">Trimmer et al., 2011</xref>; <xref ref-type="bibr" rid="c37">Payzan-LeNestour &amp; Bossaerts, 2011</xref>), according to which humans prefer quantifiable risk (i.e., errors with sizes defined by the experimental noise) over ambiguity (unpredictable and potentially large errors on changepoint trials).</p>
<p>Another factor that may have contributed to adopting a conservative strategy is the fact that observers were likely facing more uncertainty than we have included into the Bayesian models. For example, they may have been unsure about the structure of the generative process for the spatial locations of the stimuli sequences (e.g., they may have assumed that the generative means <italic>μ</italic><sub><italic>t</italic></sub> slowly drift through space in addition to the sudden changepoints), and they were probably not certain about the precise values of their estimates for changepoint rate and experimental noise (<xref ref-type="bibr" rid="c37">Payzan-LeNestour &amp; Bossaerts, 2011</xref>). Such additional (out-of-model) uncertainty makes a conservative heuristic algorithm more attractive because the performance improvement that is gained via complex inference may only be realised when the assumed generative model is accurate (<xref ref-type="bibr" rid="c54">Tavoni et al., 2022</xref>). Besides merely experiencing uncertainty about the generative process, participants may have actually had a different generative model in mind than the one we used for the Bayesian model (<xref ref-type="sec" rid="s4b">section 4.2</xref>). For example, participants may have falsely incorporated the idea of a drifting generative mean (<xref ref-type="bibr" rid="c34">Nassar et al., 2010</xref>, <xref rid="c32" ref-type="bibr">2019</xref>), or they may have accounted for disturbances to their prior beliefs, e.g., from memory decay (<xref rid="c21" ref-type="bibr">Krishnamurthy, Nassar, et al., 2017</xref>). Both examples would lead observers to undervalue the prior’s reliability and reduce their biases towards it, in accordance with the experimental data.</p>
<p>Lastly, diverse psychophysiological processes may have also affected the tendency to bind sensory signals with prior beliefs. For example, the arousal system has been implicated in adjusting the extent to which novel sensory information affects current beliefs (<xref ref-type="bibr" rid="c33">Nassar et al., 2012</xref>), as well as the extent to which prior beliefs bias perception of the sensory signals (<xref rid="c21" ref-type="bibr">Krishnamurthy, Nassar, et al., 2017</xref>). It has been suggested that laboratory experiments bring participants in an aroused (or sleepy) state, which therefore leads to higher (or lower) learning rates (<xref ref-type="bibr" rid="c23">Lee et al., 2020</xref>). In support of the hypothesis that cognitive states influence perceptual inference, it was found that a trial’s reward value, although otherwise irrelevant to task accuracy, nonetheless affected observers’ learning rates (<xref ref-type="bibr" rid="c28">McGuire et al., 2014</xref>).</p>
<p>So, there are various non-exclusive explanations for the low binding tendencies that we and others have observed. Here, we have modelled them by reducing the a-priori relevance of the priors, but there are many other modelling options that may achieve similar, or even better, fits to the empirical data. Inclusion of some of these factors into the here presented basic causal inference model should be fairly straightforward (although issues may arise with parameter identifiability), but this falls outside the scope of this study. The experimental design of the current study (Krishnamurthy, Nassar, et al., 2017) is not ideally suited to test which of the hypotheses are correct explanations for the low binding tendencies. To answer that research question, it would be useful to obtain stimulus-by-stimulus prediction responses, together with subjective judgments of uncertainty about participants’ priors, and potentially also pupillometry or neuroimaging data. However, experimental designs with overt serial decision-making risk introducing diverse cognitive biases in the response data (<xref ref-type="bibr" rid="c53">Talluri et al., 2018</xref>; <xref ref-type="bibr" rid="c6">Bévalot &amp; Meyniel, 2023</xref>). Instead, our analysis here demonstrated the extent to which observers adhere to the core principle of Bayesian causal inference during uninterrupted sequential perception in a volatile environment.</p>
</sec>
<sec id="s3c">
<label>3.3.</label>
<title>Alternative models</title>
<p>We have derived the reduced Bayesian observer model (<xref ref-type="bibr" rid="c33">Nassar et al., 2012</xref>) from the fully Bayesian solution for the generative model of this changepoint task design (<xref ref-type="bibr" rid="c3">Adams &amp; MacKay, 2007</xref>). In doing so, we clarified the assumptions and simplifications that underly the reduced model, and it begs the question whether different modelling choices would have led to better fits of the data.</p>
<p>A first consideration is that the reduced Bayesian observer model, contrary to an ideal Bayesian observer that attempts to minimize its squared errors, makes predictions about the upcoming stimulus location based on the latest posterior belief about the current generative mean. This model assumption was found to be true, as participants did not adjust their prediction responses with a bias towards the centre of space to account for the possibility of an upcoming changepoint. This finding was very clear and has been reported before (<xref ref-type="bibr" rid="c34">Nassar et al., 2010</xref>), so we did not consider the central bias in any of our model comparisons. But we do note that this is another indication that the fitted hazard rate parameters should not be interpreted as the expected probability of an upcoming changepoint. After all, if some participants would predict a 90% chance of a changepoint for every upcoming stimulus, then why would they not just respond near the centre of space all the time?</p>
<p>Second, the reduced Bayesian observer model neglects the spatial boundaries of the generative mean while it iteratively updates its beliefs. Unlike the fully Bayesian observer, it does not induce small central biases for beliefs that are near those bounds. Our model comparison analysis clearly demonstrated that incorporating the complex space truncation computations from the fully Bayesian solution made the model fits worse. This result suggests that the spatial boundaries were only accounted for when preparing to make a mouse response on the finite semicircular arc on the screen, and that the preceding computations for evidence accumulation and causal inference take place in an apparently unbounded internal representation of space. We remind the reader of the other parts of the experimental task (not analysed here) where participants had to localize a subsequently presented sound without a concurrent visual signal (Krishnamurthy, Nassar, et al., 2017). Hence, it made sense to pay particular attention to the auditory components of the stimuli, and only map the result to the visual arc on the screen when it was necessary to do so for a response. Moreover, ignoring space truncation significantly simplifies the computations at a minimal loss of accuracy, and therefore presents a logical option for an agent with limited resources (<xref ref-type="bibr" rid="c54">Tavoni et al., 2022</xref>; <xref ref-type="bibr" rid="c39">Piasini et al., 2023</xref>).</p>
<p>Third, we found that extending the memory capacity of the reduced Bayesian observer model did not significantly improve the fits for most of the participants. The memory limit is probably the most striking simplification in the reduced model because it deviates so much from the infinite memory requirement of a fully Bayesian observer. Yet, our analyses suggest that there is hardly any difference in the predictions of the models with various memory capacity settings as long as the weighted average pruning function (keep_<italic>WAVG</italic>) is used to reduce the memory load (<xref ref-type="bibr" rid="c33">Nassar et al., 2012</xref>). The two other pruning functions that we tested (keep_<italic>MAXP</italic> and keep_<italic>RCNT</italic>) performed objectively worse in terms of accuracy, because they explicitly discard (i.e., forget) potentially useful information (<xref ref-type="bibr" rid="c3">Adams &amp; MacKay, 2007</xref>; <xref ref-type="bibr" rid="c50">Skerritt-Davis &amp; Elhilali, 2018</xref>). More importantly, they also reduced the quality of the fits to participants’ responses. These results suggest that near-optimal Bayesian causal inference can be achieved with limited memory requirements by efficiently summarizing the retained prior information, and that human observers are likely to use a very similar strategy (although not nearly achieving optimality because of reasons that we discussed in the previous section).</p>
<p>We have chosen to restrict our analysis here to a factorial model comparison that included 42 variations of the reduced Bayesian observer model. However, naturally, other changepoint detection models have been described in the literature. For example, <xref ref-type="bibr" rid="c58">Wilson et al., (2013)</xref> proposed an interesting model variant for changepoint detection tasks that eludes the need for a pruning function to reduce memory load by instead attributing weights to a fixed number of nodes with predefined learning rates. Processing of sensory evidence leads to an update of the nodes’ location estimates via independent delta rules and a redistribution of the nodes’ weights via approximate causal inference. The eventual predictions are computed as a weighted average across the nodes. Because of the model’s ability to adaptively adjust the effective learning rate via the weights, its predictions will be qualitatively similar to the reduced Bayesian observer that we evaluated here. Furthermore, probabilistically weighing multiple nodes allows one to retain uncertainty about the occurrence of a changepoint, and so it resembles the behaviour of our models with memory capacities greater than one (<italic>M</italic> ≥ 2). However, it remains unclear how the predefined learning rates have to be determined and how they limit the model’s flexibility to fit to participants’ responses.</p>
<p>Remarkably, alternative modelling approaches that do not explicitly include changepoints in their generative models have also frequently been used to examine learning in changepoint environments. Notable examples are the Hierarchical Gaussian Filter (HGF; <xref ref-type="bibr" rid="c27">Mathys et al. 2011</xref>, <xref rid="c26" ref-type="bibr">2014</xref>) and the Volatile Kalman Filter (VKF; <xref ref-type="bibr" rid="c40">Piray &amp; Daw, 2020</xref>). In their generative models, volatility is implemented by allowing the latent cause of the stochastic observations to take random walks (i.e., drift) through space. Within the context of this paper, this would assume that a new generative mean is sampled from a normal distribution that is centred on the previous generative mean: <inline-formula><inline-graphic xlink:href="620874v2_inline41.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Crucially, the drift rate (i.e., variance of the random walk) is hierarchically regulated and fluctuates in time, thus producing volatile stimuli sequences. The amount of volatility over time (i.e., changes of the drift rate) is determined by a higher order parameter (similar to the hazard rate parameter in our changepoint models). During inference, the modelled observers obtain momentary estimates of the latent cause (mean and variance) and its volatility (current drift rate). Upon experiencing a changepoint, they infer a sudden jump in volatility, which leads to an increase of the learning rate for the next observation. As such, the modelled agents adapt to changepoints reasonably quickly.</p>
<p>However, critically, modelled predictions immediately following a changepoint (i.e., SAC 1 responses) will not be very accurate for HGF and VKF observers, because the current learning rate depends on the inferred volatility over the preceding observations, but not on the current prediction error (Eq. 51 in <xref ref-type="bibr" rid="c27">Mathys et al., 2011</xref>; Eqs. 9-10 in <xref ref-type="bibr" rid="c40">Piray &amp; Daw, 2020</xref>). Hence, we would see a straight horizontal line when we plot these agents’ normalized biases towards the prior as a function of the latest prediction error (the line’s height would depend on the inferred volatility over preceding stimuli [averaged over multiple trials]). This model prediction is clearly at odds with the adaptive curves of the empirical data that we presented in <xref rid="fig4" ref-type="fig">Figure 4A</xref>. This is a fundamental difference with the method of Bayesian causal inference that we advocate for in this paper, and it is a direct consequence of the fact that the generative model of the HGF and VKF do not account for changepoints. The models adjust the prior’s reliability for the expected drift rate (i.e., our <xref ref-type="disp-formula" rid="eqn3">Eq. 3</xref> is modified), but the prior’s relevance is never questioned (belief updates essentially follow <xref ref-type="disp-formula" rid="eqn2">Eq. 2</xref>). One possible reason for the fact that these models have nevertheless been seemingly successful at describing human decisions in changepoint environments is one that we have already put forward for fixed learning rate models: if observations are information-poor (<xref ref-type="bibr" rid="c47">Ryali et al., 2018</xref>), then a changepoint cannot be inferred based on a single observation (e.g., when estimating probabilities based on binary outcome variables). Only in such changepoint environments will agents that model volatility based on Gaussian random walks behave similarly to agents that account for volatility via causal inference.</p>
</sec>
<sec id="s3d">
<label>3.4.</label>
<title>Concluding remarks and future directions</title>
<p>We have shown that the reduced Bayesian observer model (<xref ref-type="bibr" rid="c33">Nassar et al., 2012</xref>) determines prior relevance via probabilistic causal inference and implements model averaging via its pruning function, which efficiently keeps model complexity to a minimum by retaining only a single best estimate for the source of every observation, together with a measure of uncertainty. After adjusting for individual prior binding tendencies, this simple algorithm described human predictions well in the environment for which it was designed: sequential noisy observations from static latent sources that occasionally suddenly switch location. The model would probably perform worse in a different environment that does not correspond with its generative model. However, Bayesian causal inference as a general principle is useful in any environment where there are multiple competing prior beliefs about the possible causes of observations. Accordingly, our brains seem to have adopted the method for a diverse set of tasks across the domains of perception and learning (<xref ref-type="bibr" rid="c60">Yu et al., 2021</xref>, <xref ref-type="bibr" rid="c48">Shams &amp; Beierholm, 2022</xref>).</p>
<p>We have laid out the core components of Bayesian causal inference for this particular changepoint experiment (<xref rid="fig2" ref-type="fig">Figure 2</xref>). While we believe that the insights that we presented hold true for other changepoint tasks, the model equations will likely have to be modified to account for different environmental statistics. Specifically, we envision that the reduced Bayesian observer model forms a useful basis for modelling perceptual decisions in volatile environments that include dynamically moving sources in addition to changepoints (see also <xref ref-type="bibr" rid="c34">Nassar et al., 2010</xref>, <xref rid="c32" ref-type="bibr">2019</xref>). It will be particularly interesting to depart from the assumption of a Gaussian random walk and instead assume that latent regular patterns underly the noisy observations. The Dynamic Regularity Extraction (DREX) model, developed by <xref ref-type="bibr" rid="c50">Skerritt-Davis &amp; Elhilali (2018</xref>, <xref ref-type="bibr" rid="c51">2021</xref>), is an excellent example in this direction. We took inspiration from that model for the variable memory capacity, but their arguably most intriguing contribution is that the DREX model tracks the covariance of successive observations in addition to their mean. This enables it to learn temporal dependencies in the stimuli sequences, and thus to detect deviations thereof that may indicate environmental changepoints. A drawback of the DREX model is that it is memory intensive and computationally expensive, especially when used to track covariance over time. It would be worth investigating whether the number of competing causal hypotheses (i.e., possible patterns) can be reduced by implementing some sort of weighted average pruning function, similar to the one in the reduced Bayesian observer model.</p>
<p>Another interesting research direction for which Bayesian causal inference lends itself naturally (more so than the classical view on belief updating expressed in terms of learning rates) is one that increases the number of active latent causes. In the changepoint paradigm, agents can simply forget their previous beliefs after a new source has been inferred for the latest observation, because the previous latent cause will not become relevant again. The opposite is true in an oddball paradigm. There, outlier observations may be caused by secondary sources that are occasionally active, but those oddball causes should be ignored, and agents are supposed to track the primary source only (<xref ref-type="bibr" rid="c32">Nassar et al., 2019</xref>, <xref ref-type="bibr" rid="c4">Bakst &amp; McGuire, 2023</xref>). Hence, outlier signals should not be integrated with prior beliefs, but those beliefs should persist despite their irrelevance for the latest sensory input (n.b. low bias to prior <italic>and</italic> low learning rate!). This is akin to real world situations in which multiple objects coexist, even if temporarily obscured or silent. One can extend this line of thinking to more realistic experiments wherein causal inference is required to correctly discover latent causes of sensory signals from among multiple known objects or assign a new cause after a potential environmental change (<xref ref-type="bibr" rid="c14">Gershman et al., 2015</xref>). For example, a multi-source Bayesian causal inference model that is based on perceptual clustering via the Chinese Restaurant Process was recently successfully applied to explain several phenomena in auditory stream segregation (<xref ref-type="bibr" rid="c22">Larigaldie et al., 2024</xref>). While there is considerable psychophysical and neurophysiological evidence that supports the view that our brains use Bayesian causal inference to organize the plethora of sensory inputs according to their latent causes (<xref ref-type="bibr" rid="c60">Yu et al., 2021</xref>), many open questions also still remain.</p>
</sec>
</sec>
<sec id="s4">
<label>4.</label>
<title>Methods</title>
<p>The methods section is structured as follows. First, we provide details on the experimental task (<xref ref-type="sec" rid="s4a">section 4.1</xref>) and how the trial generation process can be translated to a generative model (<xref ref-type="sec" rid="s4b">section 4.2</xref>). We then derive the fully Bayesian inference solution (<xref ref-type="sec" rid="s4c">section 4.3</xref>), with a special emphasis on the prior relevance (<xref ref-type="sec" rid="s4d">section 4.4</xref>). Second, we provide details on the implementation of model variations via the pruning function (<xref ref-type="sec" rid="s4e">section 4.5</xref>), decision strategy (<xref ref-type="sec" rid="s4f">section 4.6</xref>), and late truncation simplification (<xref ref-type="sec" rid="s4g">section 4.7</xref>). Third, we describe the construction of a response distribution based on the inferred prediction (<xref ref-type="sec" rid="s4h">section 4.8</xref>), which is subsequently used to fit model parameters to participants’ responses, for various models, whose predictive performance we can then compare (<xref ref-type="sec" rid="s4i">section 4.9</xref>). The final two sections elaborate on the methodology that was used to compute an a-priori likelihood surface for the model parameters (<xref ref-type="sec" rid="s4j">section 4.10</xref>) and on specifics of the qualitative analysis for response accuracy and biases (<xref ref-type="sec" rid="s4k">section 4.11</xref>).</p>
<p>All analyses were run in Matlab 2019b (The MathWorks, Inc.) and JASP 0.19.1 (<ext-link ext-link-type="uri" xlink:href="https://jasp-stats.org/">https://jasp-stats.org/</ext-link>). The analysis code and behavioral data are available on: <ext-link ext-link-type="uri" xlink:href="https://github.com/YIRG-Dynamates/priorRelevance/">https://github.com/YIRG-Dynamates/priorRelevance/</ext-link>.</p>
<sec id="s4a">
<label>4.1</label>
<title>Task and data</title>
<p>The current study is a novel analysis of the experimental data that was acquired and published by <xref ref-type="bibr" rid="c21">Krishnamurthy, Nassar, Sarode &amp; Gold (2017)</xref>. They made the data available to us upon request and they gave permission for us to share the relevant data for this publication in the public repository that is mentioned above.</p>
<p>The dataset that we received consisted of data from twenty-nine subjects who participated in between three and six experimental sessions on different days. Each session was subdivided into four main task blocks. Within each block, participants were presented with a sequence of six hundred audiovisual stimuli whose angular locations were modulated (frontal azimuth between -90° and +90°; elevation was kept constant at 0°). The sequences were paused at pseudorandom times about thirty times per block, but always after at least eight consecutive stimuli had been presented. During the pauses, participants were asked to make a prediction response about the angular location of a single sound stimulus that would be presented shortly thereafter. Participants’ pupil size was recorded in a 2.5 second delay period following the sound, after which participants made an estimation response about the sound’s location and a binary confidence judgement about that estimate. This marked the end of the pause, and the audiovisual sequence would then continue. Here, we treat each partial sequence up to the end of a pause as a separate trial, and we limit our analysis to the audiovisual stimuli and the subsequent prediction responses only, i.e., we henceforth ignore the single sound presentations and their associated pupillometry measurements, estimation responses and confidence judgments. So, for our analysis purposes, there were approximately thirty trials per main task block, each consisting of an audiovisual stimulus sequence followed by a prediction response.</p>
<p>The auditory and visual signals were presented in synchrony with a duration of 300 milliseconds (ms) and the interstimulus interval was 150 ms. The visual signals consisted of spatial markers on a semicircular arc that was continuously present on an isoluminant visual display in front of the participants. Responses were made on that same arc by moving a mouse cursor to the predicted location of the next stimulus. The auditory signals consisted of five 50 ms white noise pulses (incl. 5 ms on- and offset cosine ramps) that were separated by 10 ms silence. The sounds were spatialized by convolution with a head-related transfer function (HRTF), and they were presented through headphones. Each individual underwent a short test at the beginning of the first session to select an HRTF from the IRCAM database (<ext-link ext-link-type="uri" xlink:href="http://recherche.ircam.fr/equipes/salles/listen/download.html">http://recherche.ircam.fr/equipes/salles/listen/download.html</ext-link>) that gave the best circular experience for a sound sequence that moved through the horizontal plane in regular steps.</p>
<p>The spatial locations of the stimuli were sampled according to the pseudorandom generative process that is described in the next <xref ref-type="sec" rid="s4b">section (4.2)</xref>. However, small modifications were implemented to assure that stimuli locations did not exceed the range between -90° and 90° (noise was resampled if this occurred). Furthermore, while the probability for a changepoint was in principle equal for all stimuli and the number of stimuli per trial was unpredictable, care was taken such that the last stimulus in each trial occurred equally often between 1 and 5 stimuli after the last changepoint. In other words, there was an approximately equal number of trials for stimulus-after-changepoint (SAC) levels 1 to 5. Moreover, the number of stimuli in each trial was controlled such that the average trial length (roughly twenty stimuli) was approximately equal across those five SAC levels. These mechanisms operated on a per-block basis, such that they also ensured a balanced design for two conditions with high and low levels of experimental noise that were fixed within- and alternated across blocks. The data of the first session of each participant was not analysed, i.e., the first two blocks of both noise conditions were ignored, because we assumed that participants needed this time to familiarize themselves with the task, learn about the generative structure, and estimate the changepoint probability and the amount of stochasticity in the noise conditions. Hence, between 120 and 300 trials per participant for each noise condition were included in the analyses.</p>
</sec>
<sec id="s4b">
<label>4.2</label>
<title>Generative model</title>
<p>The pseudorandom generative process is graphically depicted in <xref rid="fig8" ref-type="fig">Figure 8</xref>. For each timepoint <italic>t</italic> a random draw from a Bernoulli distribution (<italic>B</italic>) determines whether or not a changepoint occurs, <italic>cp</italic><sub><italic>t</italic></sub> = 1 or <italic>cp</italic><sub><italic>t</italic></sub> = 0. The beginning of each trial always starts with a changepoint. At all other timepoints there is a constant hazard rate that determines the probability of a changepoint, <italic>H</italic><sub><italic>cp</italic></sub> = 0.15. Hence, <italic>H</italic><sub>1</sub> = 1 and <italic>H</italic><sub><italic>t</italic></sub> = <italic>H</italic><sub><italic>cp</italic></sub> for all <italic>t</italic> &gt; 1. On a changepoint, the generative mean <italic>μ</italic><sub><italic>t</italic></sub> is drawn at random from a uniform distribution on the interval [<italic>a</italic> = −90°, <italic>b</italic> = 90°]. If no changepoint occurs, then the generative mean remains the same as on the previous timepoint, <italic>μ</italic><sub><italic>t</italic></sub> = <italic>μ</italic><sub><italic>t</italic>−1</sub>. Finally, stimulus location <italic>x</italic><sub><italic>t</italic></sub> is drawn at random from a normal distribution with mean <italic>μ</italic><sub><italic>t</italic></sub> and variance <inline-formula><inline-graphic xlink:href="620874v2_inline42.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which depends on the experimental condition: <italic>σ</italic><sub><italic>exp</italic></sub> = 10° and <italic>σ</italic><sub><italic>exp</italic></sub> = 20° for the low and high noise conditions, respectively.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><title>The generative model describes the process that gives rise to sensory signals.</title> <p>For every stimulus, a random draw from a Bernoulli distribution determines whether or not a changepoint occurs. For a changepoint (right panel), the generative mean is drawn at random from a uniform distribution, whereas it remains the same as before for no changepoints (left panel). Finally, in both cases, the stimulus location is drawn at random from a normal distribution that is centred on the generative mean. See text in <xref ref-type="sec" rid="s4b">section 4.2</xref> for details and generative parameter settings.</p></caption>
<graphic xlink:href="620874v2_fig8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s4c">
<label>4.3</label>
<title>Bayesian inference</title>
<p>The task is to predict the location of the next (sound) stimulus, <italic>x</italic><sub><italic>t</italic>+1</sub>, whenever the sequence stops. In order to do so accurately, an observer would be wise to continuously estimate the unknown generative mean <italic>μ</italic><sub><italic>t</italic></sub>, because the next stimulus is likely to be sampled at random from a normal distribution that is centred on <italic>μ</italic><sub><italic>t</italic></sub>. Hence, we will describe an algorithm that infers the location of the unknown <italic>μ</italic><sub><italic>t</italic></sub> from the observations <italic>x</italic><sub>1:<italic>t</italic></sub>.</p>
<p>While algorithms have been developed to simultaneously estimate the hazard rate, <italic>H</italic><sub><italic>cp</italic></sub>, and experimental noise, <italic>σ</italic><sub><italic>exp</italic></sub>, from the observations during ongoing sequence presentations (<xref ref-type="bibr" rid="c57">Wilson et al., 2010</xref>; <xref ref-type="bibr" rid="c41">Piray &amp; Daw, 2021</xref>), we here assume that participants have learned the values for these parameters and we treat their estimates as stable constants that we denote as <inline-formula><inline-graphic xlink:href="620874v2_inline43.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="620874v2_inline44.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p>
<p>Bayesian inference for changepoint problems of the like that we face here was described by <xref ref-type="bibr" rid="c3">Adams &amp; MacKay, 2007</xref> (also see <xref ref-type="bibr" rid="c12">Fearnhead and Liu, 2007</xref>). The optimal solution requires an agent to have extensive memory and computational capacity because its posterior distribution at any timepoint <italic>t</italic> is a weighted mixture distribution that consists of <italic>t</italic> nodes (i.e., mixture components): a new node is added with every new observation. Since this would quickly exhaust human working memory limits and become computationally intractable for longer sequences, we will introduce a maximum memory capacity (<italic>M</italic>) for the number of nodes that can be memorized and subsequently utilized. In our implementation here, this means that the posterior belief about the former generative mean, <italic>μ</italic><sub><italic>t</italic>−1</sub>, based on all preceding stimuli, <italic>x</italic><sub>1:(<italic>t</italic>−1)</sub>, is first simplified to comply with the memory constraint via the function <italic>fMC</italic> (which will be discussed in more detail in <xref ref-type="sec" rid="s4e">section 4.5</xref>), before it is used as a prior distribution for the upcoming generative mean, <italic>μ</italic><sub><italic>t</italic></sub>, conditional on the assumption of no-changepoint (i.e., <italic>μ</italic><sub><italic>t</italic></sub> = <italic>μ</italic><sub><italic>t</italic>−1</sub>). The memory constraint function <italic>f</italic><sub><italic>MC</italic></sub> ensures that the simplified conditional prior distribution consists of a weighted mixture distribution of maximally <italic>M</italic> nodes:
<disp-formula id="ueqn1">
<graphic xlink:href="620874v2_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Please note that we will consistently refer to the agent’s subjective prior probabilities, distributions and parameters by means of a tilde, while we use a double overbar for subjective posterior probabilities, distributions and parameters. These are likely to be approximations of the priors and posteriors of an ideal observer because of simplifications and estimations. We will index the prior nodes at timepoint <italic>t</italic> with <italic>n</italic> = 1: <italic>N</italic><sub><italic>t</italic></sub>, where <italic>N</italic><sub><italic>t</italic></sub> is defined by the sequence length (<italic>t</italic>) or by <italic>M</italic> + 1, whichever is smaller: <italic>N</italic><sub><italic>t</italic></sub> = min (<italic>t, M</italic> + 1). Node indices are superscripted within parentheses. The first prior node is reserved for the assumption of an upcoming changepoint: <inline-formula><inline-graphic xlink:href="620874v2_inline45.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Note that given a changepoint, <italic>μ</italic><sub><italic>t</italic></sub> is conditionally independent of <italic>x</italic><sub>1:(<italic>t</italic>−1)</sub>. The full prior distribution for <italic>μ</italic><sub><italic>t</italic></sub> is described as a weighted sum of the two options, either there was a changepoint or there was not:
<disp-formula id="ueqn2">
<graphic xlink:href="620874v2_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the estimate of the hazard rate <inline-formula><inline-graphic xlink:href="620874v2_inline46.gif" mime-subtype="gif" mimetype="image"/></inline-formula> for <italic>t</italic> = 1, and <inline-formula><inline-graphic xlink:href="620874v2_inline47.gif" mime-subtype="gif" mimetype="image"/></inline-formula> otherwise.</p>
<p>Upon observing <italic>x</italic><sub><italic>t</italic></sub>, the posterior distribution for <italic>μ</italic><sub><italic>t</italic></sub> is computed via Bayes’ rule by multiplication of the prior with the subjective likelihood function, <inline-formula><inline-graphic xlink:href="620874v2_inline48.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which is equal to <inline-formula><inline-graphic xlink:href="620874v2_inline49.gif" mime-subtype="gif" mimetype="image"/></inline-formula> due to conditional independence, and by division with a normalization constant, <italic>c</italic>(<italic>x</italic><sub><italic>t</italic></sub>):
<disp-formula id="ueqn3">
<graphic xlink:href="620874v2_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We thus find that the posterior is a weighted mixture distribution, where each of the posterior nodes is computed by multiplication of the likelihood function with the respective prior node, followed by normalization:
<disp-formula id="ueqn4">
<graphic xlink:href="620874v2_ueqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the node-specific normalization constants <italic>c</italic>(<italic>x</italic><sub><italic>t</italic></sub>)<sup>(<italic>n</italic>)</sup> ensure that the posterior nodes are themselves proper probability distributions:
<disp-formula id="ueqn5">
<graphic xlink:href="620874v2_ueqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Furthermore, we have seen that the posterior weights depend on the prior weights as:
<disp-formula id="ueqn6">
<graphic xlink:href="620874v2_ueqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we note that the overall normalization constant <italic>c</italic>(<italic>x</italic><sub><italic>t</italic></sub>) is a weighted sum of the node-specific normalization constants:
<disp-formula id="ueqn7">
<graphic xlink:href="620874v2_ueqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Now, we will make this general approach for Bayesian inference more concrete by showing that it can be implemented via simple updating equations for the summary statistics (i.e., parameters) of each node’s distribution.</p>
<p>We will start with a single observation, <italic>x</italic><sub><italic>t</italic></sub>. Since the agent has learned that the stimulus was sampled from a normal distribution that is centred at <italic>μ</italic><sub><italic>t</italic></sub> with variance <inline-formula><inline-graphic xlink:href="620874v2_inline50.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, it is straightforward to construct the subjective likelihood function for <italic>μ</italic><sub><italic>t</italic></sub> using the symmetry of the normal distribution:
<disp-formula id="ueqn8">
<graphic xlink:href="620874v2_ueqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>φ</italic> represents the standard normal distribution.</p>
<p>In the case of a changepoint, <italic>μ</italic><sub><italic>t</italic></sub> is sampled from a uniform distribution on the interval [a, b]. Hence, the first node of the prior distribution equals:
<disp-formula id="ueqn9">
<graphic xlink:href="620874v2_ueqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we have used the Iverson bracket notation.</p>
<p>It follows that the first posterior node is a truncated normal distribution:
<disp-formula id="ueqn10">
<graphic xlink:href="620874v2_ueqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
characterized by the following parameters (together with constants <italic>a</italic> and <italic>b</italic>):
<disp-formula id="ueqn11">
<graphic xlink:href="620874v2_ueqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>Φ</italic> represents the cumulative distribution function of the standard normal distribution.</p>
<p>Since the first posterior node becomes the second prior node (see <xref ref-type="sec" rid="s4e">section 4.5</xref> for details), the second posterior node will also be a truncated normal distribution. In fact, this is the case for each posterior node with index <italic>n</italic> &gt; 1:
<disp-formula id="ueqn12">
<graphic xlink:href="620874v2_ueqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the posterior parameters result from the product of the two normal distributions in the numerator, which itself is a scaled normal distribution. The posterior parameters can be computed efficiently with the following update equations:
<disp-formula id="ueqn13">
<graphic xlink:href="620874v2_ueqn13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the “prior reliability” <italic>τ</italic><sub><italic>t</italic></sub> <sup>(<italic>n</italic>)</sup> represents a normalized measure of precision (i.e., reciprocal of variance) of the untruncated prior node relative to the precision of a single observation with regards to the measure of interest <italic>μ</italic><sub><italic>t</italic></sub>:
<disp-formula id="ueqn14">
<graphic xlink:href="620874v2_ueqn14.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Computation of the posterior node via the normalized product of likelihood and prior node can thus be viewed as an example of precision-weighted integration.</p>
<p>Finally, we still need to define the nodes’ normalization constants, <italic>c</italic>(<italic>x</italic><sub><italic>t</italic></sub>)<sup>(<italic>n</italic>)</sup>, which are required to compute the posterior weights <inline-formula><inline-graphic xlink:href="620874v2_inline51.gif" mime-subtype="gif" mimetype="image"/></inline-formula>:
<disp-formula id="ueqn15">
<graphic xlink:href="620874v2_ueqn15.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Likewise, we also integrate out the unknown <italic>μ</italic><sub><italic>t</italic></sub> for the nodes’ constants with indices <italic>n</italic> &gt; 1:
<disp-formula id="ueqn16">
<graphic xlink:href="620874v2_ueqn16.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We note that these normalization constants, <italic>c</italic>(<italic>x</italic><sub><italic>t</italic></sub>)<sup>(<italic>n</italic>)</sup>, can be interpreted as the likelihood of a particular node, given the latest observation <italic>x</italic><sub><italic>t</italic></sub>. The likelihood of the first node is essentially a scalar that depends on the spatial range of <italic>μ</italic><sub><italic>t</italic></sub>, multiplied by a term that depends on how near the observation was to the space boundaries (a and b). The likelihood of all other nodes is given by the probability density of the normal distribution that is centred on the node’s prior location parameter <inline-formula><inline-graphic xlink:href="620874v2_inline52.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and with variance equal to the summed variances of prior and experimental noise, multiplied by another complex term that depends on the proximity of observation <italic>x</italic><sub><italic>t</italic></sub> and prior mean <inline-formula><inline-graphic xlink:href="620874v2_inline53.gif" mime-subtype="gif" mimetype="image"/></inline-formula> to the space boundaries.</p>
</sec>
<sec id="s4d">
<label>4.4</label>
<title>Prior relevance</title>
<p>Since updating from prior to posterior happens on a per-node basis, and since the posterior weights, <inline-formula><inline-graphic xlink:href="620874v2_inline54.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, collectively form a posterior probability distribution over the nodes, we can also view these weights as a quantification of the adequacy of the respective prior nodes in terms of having provided information about the latest generative mean <italic>μ</italic><sub><italic>t</italic></sub>. In other words, <inline-formula><inline-graphic xlink:href="620874v2_inline55.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a posterior measure for the relevance of the n<sup>th</sup> prior node with regards to the latest observation <italic>x</italic><sub><italic>t</italic></sub>, and relative to the other prior nodes.</p>
<p>Although the first prior node also exists, <inline-formula><inline-graphic xlink:href="620874v2_inline56.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, we may prefer to think of “the prior” as the collection of nodes that are based on the posterior over the previous observations, conditional on no changepoint: <inline-formula><inline-graphic xlink:href="620874v2_inline57.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. As such, we define “prior relevance” <italic>Π</italic><sub><italic>t</italic></sub> as the sum of the posterior weights with indices <italic>n</italic> &gt; 1 (Krishnamurthy, Nassar, et al., 2017):
<disp-formula id="ueqn17">
<graphic xlink:href="620874v2_ueqn17.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and the posterior probability of a changepoint at timepoint <italic>t</italic> is <inline-formula><inline-graphic xlink:href="620874v2_inline58.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p>
<p>Next, we will show that a logit transformation of the prior relevance, the unbounded quantity <italic>Q</italic><sub><italic>t</italic></sub>, can be intuitively computed via the information-theoretic measure of surprisal:
<disp-formula id="ueqn18">
<graphic xlink:href="620874v2_ueqn18.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we have defined surprisal conditional on the changepoint assumption:
<disp-formula id="ueqn19">
<graphic xlink:href="620874v2_ueqn19.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In other words, the posterior log-odds for the no changepoint hypothesis is equal to its prior log-odds plus the difference in conditional surprisal (see also <xref ref-type="bibr" rid="c24">Liakoni et al., 2021</xref>; <xref ref-type="bibr" rid="c31">Modirshanechi et al., 2022</xref>). N.b. this unbounded quantity can be transformed to a probability via the logistic function: <italic>Π</italic><sub><italic>t</italic></sub> = <italic>logistic</italic>(<italic>Q</italic><sub><italic>t</italic></sub>) = (1 + <italic>e</italic><sup>−<italic>Qt</italic></sup>)<sup>−1</sup>.</p>
<p>Note that surprisal under the assumption of a changepoint is approximately constant, especially when the stimulus <italic>x</italic><sub><italic>t</italic></sub> is located in the middle of space and far away from the boundaries (a and b). Furthermore, when the prior conditional on no changepoint, <inline-formula><inline-graphic xlink:href="620874v2_inline59.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, consists of only one node (<italic>N</italic><sub><italic>t</italic></sub> = 2, e.g., when <italic>M</italic> = 1), then we find that the associated conditional surprisal is dominated by the precision-weighted prediction error, i.e., the ratio of the observed squared prediction error, <inline-formula><inline-graphic xlink:href="620874v2_inline60.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, to the expected squared prediction error, <inline-formula><inline-graphic xlink:href="620874v2_inline61.gif" mime-subtype="gif" mimetype="image"/></inline-formula>:
<disp-formula id="ueqn20">
<graphic xlink:href="620874v2_ueqn20.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Hence, for the limited memory model with <italic>M</italic> = 1, the transformed prior relevance <italic>Q</italic><sub><italic>t</italic></sub> is equal to:
<disp-formula id="ueqn21">
<graphic xlink:href="620874v2_ueqn21.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="ueqn22">
<graphic xlink:href="620874v2_ueqn22.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
So, under the minimal memory assumption (<italic>M</italic> = 1), we find that the prior relevance is larger when 1) the a-priori probability for a changepoint is lower and when 2) the spatial range for the generative mean is larger. Furthermore, 3) the prior relevance decreases a-priori when the prior’s uncertainty about the upcoming stimulus location <italic>x</italic><sub><italic>t</italic></sub> is larger, either due to a less reliable prior on <italic>μ</italic><sub><italic>t</italic></sub> or due to larger experimental noise. Importantly, 4) the prior relevance decreases a-posteriori when the squared prediction error is larger, and this dependence on prediction error is stronger when the prior is more reliable and when there is less experimental noise. Finally, 5) the prior relevance increases a-priori when the prior’s location parameter is nearer to or even outside the spatial boundary for the generative mean, and 6) it increases a-posteriori when the observation <italic>x</italic><sub><italic>t</italic></sub> is more peripheral than the posterior’s location parameter. In other words, the prior is considered more relevant a-posteriori when it biases the percept towards the centre of space, especially when the new observation is near or outside the spatial boundaries for the generative mean.</p>
</sec>
<sec id="s4e">
<label>4.5</label>
<title>Pruning function</title>
<p>In the above-described recursive Bayesian inference algorithm (<xref ref-type="sec" rid="s4c">section 4.3</xref>) we have mentioned that the preceding posterior distribution becomes the next prior distribution, conditional on no changepoint, and constrained by limited memory via the function <italic>f</italic><sub><italic>MC</italic></sub>, for all <italic>t</italic> &gt; 1:
<disp-formula id="ueqn23">
<graphic xlink:href="620874v2_ueqn23.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the total number of nodes (including the first changepoint node) is: <italic>N</italic><sub><italic>t</italic></sub> = min (<italic>t, M</italic> + 1).</p>
<p>A fully-Bayesian ideal observer would have no memory restrictions (<italic>M</italic> = ∞), such that the number of nodes always increases by 1 per timestep: <italic>N</italic><sub><italic>t</italic></sub> = <italic>N</italic><sub><italic>t</italic>−1</sub> + 1. However, this is unrealistic for human working memory. So, we investigated modifications of the statistically optimal algorithm.</p>
<p>To comply with memory constraints, it has been proposed to reduce the number of posterior nodes that carry over into the subsequent prior. This has been termed “node pruning”. Roughly speaking, it can be done in two ways: 1) one can discard posterior nodes entirely or 2) one can merge posterior nodes before prior formation. For example, 1a) <xref ref-type="bibr" rid="c3">Adams &amp; MacKay, 2007</xref> suggested to discard posterior nodes when their inferred relevance, <inline-formula><inline-graphic xlink:href="620874v2_inline62.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, is smaller than some threshold. Instead, 1b) <xref ref-type="bibr" rid="c50">Skerritt-Davis &amp; Elhilali, 2018</xref> suggested to discard the oldest node, i.e., the one with the highest node index, whenever memory capacity is exceeded, because humans likely first forget the contribution of stimuli that were presented the longest time ago. Besides, those old stimuli are a-priori less likely to be informative for estimating the current generative mean <italic>μ</italic><sub><italic>t</italic></sub> in an environment with changepoints. On the other hand, 2a) <xref ref-type="bibr" rid="c57">Wilson et al., 2010</xref> suggested to merge nodes based on their similarity in terms of mean and variance. Their key insight was that nodes with similar run lengths represent similar belief distributions. In our description of the Bayesian algorithm, this translates to merging nodes that have adjacent node indices. Finally, 2b) a rather extreme form of node merging was first suggested by <xref ref-type="bibr" rid="c34">Nassar et al., 2010</xref>, in which they reduced the posterior to one node (<italic>M</italic> = 1) with weighted average mean and variance, where the weights were naturally given by the nodes’ relevance, <inline-formula><inline-graphic xlink:href="620874v2_inline63.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. This algorithm was later refined by <xref ref-type="bibr" rid="c33">Nassar et al., 2012</xref>, such that the variance of the merged node was computed based on the full variance of the weighted mixture distribution, which incorporates additional uncertainty due to disparity between the means of the nodes.</p>
<p>Here, we incorporate some of the above insights and test which of three competitive ideas for node pruning best fits the behavioral data for various settings of the memory capacity parameter <italic>M</italic>: ranging from 1 to 4. In all three of the pruning methods, we make use of the insights that the oldest two nodes are often most similar, and that the memory of the oldest contributing stimuli may become hazy. So, we either merge the oldest two posterior nodes or we simply discard one of them, but we always sum their weights, so that the oldest remaining node, i.e., with the highest prior node index (<italic>N</italic><sub><italic>t</italic></sub>) represents the belief that a changepoint occurred at least <italic>N</italic><sub><italic>t</italic></sub> − 1 timepoints ago. The pruning rule thus only affects the oldest pair of posterior nodes, whenever the number of posterior nodes exceeds the memory capacity, <italic>N</italic><sub><italic>t</italic>−1</sub> &gt; <italic>M</italic>. Hence, all other prior nodes are simply identical to the preceding posterior node with one index lower:</p>
<p>For all three <italic>f</italic><sub><italic>MC</italic></sub> and all prior nodes with indices 2 ≤ <italic>n</italic> ≤ <italic>M</italic>, and for prior node <italic>n</italic> = <italic>N</italic><sub><italic>t</italic></sub> if <italic>N</italic><sub><italic>t</italic>−1</sub> ≤ <italic>M</italic>:
<disp-formula id="ueqn24">
<graphic xlink:href="620874v2_ueqn24.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In the first pruning method we discard the oldest posterior node once the memory capacity is exceeded, in accordance with the idea of simply forgetting stimuli that were presented a long time ago (<xref ref-type="bibr" rid="c50">Skerritt-Davis &amp; Elhilali, 2018</xref>). Since, we keep the most recent of the two oldest nodes, we refer to this pruning method as <italic>keep_RCNT</italic>:</p>
<p>For <italic>f</italic><sub><italic>MC</italic>_<italic>RCNT</italic></sub> and prior node <italic>n</italic> = <italic>N</italic><sub><italic>t</italic></sub> if <italic>N</italic><sub><italic>t</italic>−1</sub> &gt; <italic>M</italic>:
<disp-formula id="ueqn25">
<graphic xlink:href="620874v2_ueqn25.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<italic>f</italic><sub><italic>MC</italic>_<italic>RCNT</italic></sub> effectively puts a limit on the number of stimuli that can get integrated, even if there are no changepoints for a long time. Hence, the variance parameter of the last prior node is bound to a minimum: <inline-formula><inline-graphic xlink:href="620874v2_inline64.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and its prior reliability is bound to a maximum: <inline-formula><inline-graphic xlink:href="620874v2_inline65.gif" mime-subtype="gif" mimetype="image"/></inline-formula></p>
<p>Furthermore, if the memory capacity is set to a minimum of one node, <italic>M</italic> = 1, this observer would only remember the location of the latest stimulus, <italic>x</italic><sub><italic>t</italic></sub>. In this special case, <italic>f</italic><sub><italic>MC</italic>_<italic>RCNT</italic></sub> does not allow for any integration of evidence over multiple stimuli. The prior belief about <italic>μ</italic><sub><italic>t</italic></sub>, conditional on no changepoint, <inline-formula><inline-graphic xlink:href="620874v2_inline66.gif" mime-subtype="gif" mimetype="image"/></inline-formula> would be described by a single truncated normal distribution, <inline-formula><inline-graphic xlink:href="620874v2_inline67.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, with parameters equal to: <inline-formula><inline-graphic xlink:href="620874v2_inline68.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p>
<p>In the second pruning method we instead discard the least relevant of the two oldest posterior nodes, i.e., we keep the node with the maximum posterior probability, <italic>keep_MAXP</italic>:</p>
<p>For <italic>f</italic><sub><italic>MC</italic>_<italic>MAXP</italic></sub> and prior node <italic>n</italic> = <italic>N</italic><sub><italic>t</italic></sub> if <italic>N</italic><sub><italic>t</italic>−1</sub> &gt; <italic>M</italic>:
<disp-formula id="ueqn26">
<graphic xlink:href="620874v2_ueqn26.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Potentially keeping the oldest but more relevant node allows one to make full use of evidence integration over many relevant stimuli (i.e., more than <italic>M</italic> stimuli can be integrated). In the special case with <italic>M</italic> = 1, an observer with the <italic>f</italic><sub><italic>MC</italic>_<italic>MAXP</italic></sub> pruning function would determine whether or not a changepoint has occurred after every stimulus (based on whether the prior relevance <italic>Π</italic><sub><italic>t</italic></sub> is smaller than 0.5). This observer would then keep the node that is associated with the inferred event (changepoint or not) and discard the other.</p>
<p>The third pruning function does not deterministically select one or the other node, but instead attempts to summarize the information from both nodes into a single one by computing a weighted average, <italic>keep_WAVG</italic>.</p>
<p>For <italic>f</italic><sub><italic>MC</italic>_<italic>WAVG</italic></sub> and prior node <italic>n</italic> = <italic>N</italic><sub><italic>t</italic></sub> if <italic>N</italic><sub><italic>t</italic>−1</sub> &gt; <italic>M</italic>:
<disp-formula id="ueqn27">
<graphic xlink:href="620874v2_ueqn27.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the weight is fined as:
<disp-formula id="ueqn28">
<graphic xlink:href="620874v2_ueqn28.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The location parameter of the new prior node is thus a weighted average of the two posterior location parameters. The squared scale parameter of the prior node is formed by a weighted average of the posterior squared scale parameters, plus a term that depends on the squared distance between the nodes’ mean parameters multiplied by a scalar that indicates the uncertainty about which of the two nodes is more relevant, <italic>ω</italic><sub><italic>t</italic></sub> <sup>(<italic>n</italic>)</sup>(1 − <italic>ω</italic><sub><italic>t</italic></sub> <sup>(<italic>n</italic>)</sup>), i.e., the variance of a Bernoulli distribution with parameter <italic>ω</italic><sub><italic>t</italic></sub> <sup>(<italic>n</italic>)</sup>.</p>
<p>In the special case where <italic>M</italic> = 1, the <italic>f</italic><sub><italic>MC</italic>_<italic>WAVG</italic></sub> pruning function forms the core belief updating algorithm of the reduced Bayesian inference model that was described by <xref ref-type="bibr" rid="c33">Nassar et al., 2012</xref>. Under those minimal memory conditions, the new prior node’s parameters can be computed directly from the preceding prior node parameters and the latest observation <italic>x</italic><sub><italic>t</italic>−1</sub> (without explicitly computing the posterior parameters):
<disp-formula id="ueqn29">
<graphic xlink:href="620874v2_ueqn29.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We thus find that the new prior’s location parameter is based on the latest observation plus a bias towards the preceding prior’s location parameter. The product of prior relevance and prior reliability, <italic>Π</italic><sub><italic>t</italic>−1</sub> <italic>τ</italic><sub><italic>t</italic>−1</sub>, here serves as a normalized bias measure from the latest stimulus location (<italic>x</italic><sub><italic>t</italic>−1</sub> at 0 in normalized space) to the prior’s location parameter (<inline-formula><inline-graphic xlink:href="620874v2_inline69.gif" mime-subtype="gif" mimetype="image"/></inline-formula> at 1 in normalized space).</p>
</sec>
<sec id="s4f">
<label>4.6</label>
<title>Decision strategy</title>
<p>So far, we have shown how an observer can update beliefs about the generative mean <italic>μ</italic><sub><italic>t</italic></sub> after observing a new stimulus and how to reduce memory load by restrictive formation of a new prior. This prior distribution can then be used to predict the location of the upcoming stimulus when the observer is prompted to do so. It is straightforward to construct a predictive distribution for the unobserved stimulus <italic>x</italic><sub><italic>t</italic></sub> based on the prior on <italic>μ</italic><sub><italic>t</italic></sub> by additionally accounting for the experimental noise, <inline-formula><inline-graphic xlink:href="620874v2_inline70.gif" mime-subtype="gif" mimetype="image"/></inline-formula>:
<disp-formula id="ueqn30">
<graphic xlink:href="620874v2_ueqn30.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
One may recognize that we have already evaluated these integrals for a particular value of <italic>x</italic><sub><italic>t</italic></sub> when we computed the normalization constants of the posterior nodes, <italic>c</italic>(<italic>x</italic><sub><italic>t</italic></sub>)<sup>(1)</sup> and <italic>c</italic>(<italic>x</italic><sub><italic>t</italic></sub>)<sup>(<italic>n</italic>&gt;1)</sup>. Fortunately, it is not necessary to evaluate the integrals for all possible values of the unknown upcoming observation <italic>x</italic><sub><italic>t</italic></sub>. Instead, in order to make the best possible prediction, an observer only needs to compute the expected values of the predictive distribution’s nodes:
<disp-formula id="ueqn31">
<graphic xlink:href="620874v2_ueqn31.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we have used the fact that the additional experimental noise, which is sampled at random from a normal distribution, does not change the expected values of the predictive distribution’s components. These expected values are:
<disp-formula id="ueqn32">
<graphic xlink:href="620874v2_ueqn32.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Note that the latter expectation is given by the location parameter of the prior node plus a truncation-dependent term that biases the expectation towards the centre of space, especially when the node’s location parameter <inline-formula><inline-graphic xlink:href="620874v2_inline71.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is near or outside the space boundaries for <italic>μ</italic><sub><italic>t</italic></sub> (a and b).</p>
<p>So, the statistically optimal prediction for the location of the upcoming stimulus, <inline-formula><inline-graphic xlink:href="620874v2_inline72.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, i.e., one that minimizes the squared error <inline-formula><inline-graphic xlink:href="620874v2_inline73.gif" mime-subtype="gif" mimetype="image"/></inline-formula> across many such predictions, is given by a weighted average of the prior nodes’ distribution expectations. Such a strategy is called model averaging (<xref ref-type="bibr" rid="c59">Wozny et al., 2010</xref>); where the nodes here represent competing models of the world, i.e., hypotheses about the occurrence of the latest changepoint. Since the expectation of the first prior node, conditional on an upcoming changepoint, is equal to 0.5(<italic>a</italic> + <italic>b</italic>), the ideal Bayesian observer would bias all of their responses towards the centre of space with a weight equal to <inline-formula><inline-graphic xlink:href="620874v2_inline74.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. However, in accordance with <xref ref-type="bibr" rid="c34">Nassar et al., 2010</xref>, we did not observe such central biases in the current dataset (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). Therefore, we assume that participants made their predictions conditional on the assumption that there will not be a changepoint. Under the “model averaging” decision strategy this amounts to:
<disp-formula id="ueqn33">
<graphic xlink:href="620874v2_ueqn33.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
While the model averaging decision strategy is the one that a Bayesian observer would use under a squared error loss function, it is possible that participants relied on one of many other loss functions. For example, in multiple-choice tasks, the optimal strategy is to select the option with the maximum a-posteriori probability (MAP). Participants could have post-hoc applied this common strategy to determine which of the prior nodes contains the most relevant information about the generative mean <italic>μ</italic><sub><italic>t</italic></sub>. Under the so-called “model selection” decision strategy, participants would then single out the prior node with the highest weight <inline-formula><inline-graphic xlink:href="620874v2_inline75.gif" mime-subtype="gif" mimetype="image"/></inline-formula> as the basis for their prediction:
<disp-formula id="ueqn34">
<graphic xlink:href="620874v2_ueqn34.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Note that both decision strategies lead to the same prediction, <inline-formula><inline-graphic xlink:href="620874v2_inline76.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, if the memory capacity is set to <italic>M</italic> = 1.</p>
</sec>
<sec id="s4g">
<label>4.7</label>
<title>Late truncation simplification</title>
<p>The above near-Bayesian model computations can be simplified by ignoring the complex space truncation terms until a prediction response has to be made. In other words, during sequence presentation, sensory evidence may be accumulated (or not, in case of inferred changepoints) without considering the space boundaries for the generative mean. Under this assumption, the normalization constants (i.e., the likelihoods of the nodes) are approximated by:
<disp-formula id="ueqn35">
<graphic xlink:href="620874v2_ueqn35.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and
<disp-formula id="ueqn36">
<graphic xlink:href="620874v2_ueqn36.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The simplification implies that any new observation <italic>x</italic><sub><italic>t</italic></sub> is not immediately compared against the spatial boundaries for the generative mean (a, b) when computing the prior relevance <italic>Π</italic><sub><italic>t</italic></sub>. The spatial range merely plays a role as an a-priori offset for the transformed prior relevance <italic>Q</italic><sub><italic>t</italic></sub>.</p>
<p>Nevertheless, we do assume that participants are aware of the spatial boundaries for the generative mean and that they take these into account when they make predictions for the upcoming stimulus. However, instead of computing the complex bias term for the expectation of the posterior truncated normal distributions, the prediction itself is simply truncated unto the interval of the generative mean. Hence, the predictions are first approximated:
<disp-formula id="ueqn37">
<graphic xlink:href="620874v2_ueqn37.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and subsequently truncated:
<disp-formula id="ueqn38">
<graphic xlink:href="620874v2_ueqn38.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s4h">
<label>4.8</label>
<title>Response distribution</title>
<p>We assume that a participant intends to direct the response to the location of their best guess for the upcoming stimulus, <inline-formula><inline-graphic xlink:href="620874v2_inline77.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, but that the response itself is inaccurate to some extent. Hence, we assume that the actual response is disturbed by random response noise according to:
<disp-formula id="ueqn39">
<graphic xlink:href="620874v2_ueqn39.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Furthermore, subjects’ attention may occasionally lapse, or they may blink during the last stimulus presentation, such that they have no idea where the next stimulus is going to be presented. On such lapses (Λ = 1), we assume that their intended response location is randomly chosen from the uniform distribution of the generative mean, <inline-formula><inline-graphic xlink:href="620874v2_inline78.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The predicted response distribution is a weighted sum of the conditional response distributions for a lapse and no lapse:
<disp-formula id="ueqn40">
<graphic xlink:href="620874v2_ueqn40.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>λ</italic> is the lapse rate.</p>
<p>Since responses are bound to the response interval [<italic>c</italic> = −90°, <italic>d</italic> = 90°], we define the predicted response distribution, conditional on no lapse as a truncated normal distribution, where the location parameter is given by the model’s prediction <inline-formula><inline-graphic xlink:href="620874v2_inline79.gif" mime-subtype="gif" mimetype="image"/></inline-formula>:
<disp-formula id="ueqn41">
<graphic xlink:href="620874v2_ueqn41.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The predicted response distribution conditional on a lapse is defined by the following convolution of a uniform and normal distribution, <inline-formula><inline-graphic xlink:href="620874v2_inline80.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, truncated to the response interval [<italic>c, d</italic>]:
<disp-formula id="ueqn42">
<graphic xlink:href="620874v2_ueqn42.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the integrals in the denominator can be computed analytically as:
<disp-formula id="ueqn43">
<graphic xlink:href="620874v2_ueqn43.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and we note that the denominator is approximately equal to <italic>d</italic> − <italic>c</italic>, such that the probability, conditional on a lapse, for any response that is well away from and in-between the space boundaries, <italic>a</italic> ≪ <italic>r</italic> ≪ <italic>b</italic>, is approximately constant: <italic>p</italic>(<italic>r</italic>|Λ = 1) ≈ (<italic>d</italic> − <italic>c</italic>)<sup>−1</sup>.</p>
</sec>
<sec id="s4i">
<label>4.9</label>
<title>Model fitting and model comparison</title>
<p>We utilize the method of maximum likelihood estimation to optimize the parameter values of a model, <italic>θ</italic><sub><italic>m</italic></sub>, to best predict the spatial prediction responses <italic>r</italic><sub><italic>k</italic></sub> of a participant, across all relevant trials <italic>k</italic> = 1: <italic>N</italic><sub><italic>k</italic></sub>.
<disp-formula id="ueqn44">
<graphic xlink:href="620874v2_ueqn44.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the likelihood across trials <italic>L</italic>(<italic>θ</italic><sub><italic>m</italic></sub>) for a particular set of parameter values is computed as a product of the likelihoods for each trial, and the likelihood for a single trial response is given as the probability density of the model-predicted response distribution, <italic>p</italic>(<italic>r</italic>|<italic>x</italic><sub>1:(<italic>t</italic>−1)</sub>, <italic>θ</italic><sub><italic>m</italic></sub>), evaluated at the participant’s response location, <italic>r</italic><sub><italic>k</italic></sub>.</p>
<p>We fitted the models separately for both experimental noise conditions. For each fit, we optimized the following four parameters: subjective estimate of the changepoint hazard rate <inline-formula><inline-graphic xlink:href="620874v2_inline81.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, subjective estimate of the experimental noise standard deviation <inline-formula><inline-graphic xlink:href="620874v2_inline82.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, the standard deviation of the response noise (0° &lt; σ<sub><italic>resp</italic></sub> &lt; 200°), and the lapse rate (0 &lt; <italic>λ</italic> &lt; 1):
<disp-formula id="ueqn45">
<graphic xlink:href="620874v2_ueqn45.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The only exceptions to this were the models with limited memory capacity, <italic>M</italic> = 1, and the <italic>f</italic><sub><italic>MC</italic>_<italic>LAST</italic></sub> pruning method. These models essentially base their predicted response distributions on the last stimulus location only, and they do not make use of the hazard rate estimate <inline-formula><inline-graphic xlink:href="620874v2_inline83.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Under the late truncation simplification assumption, the experimental noise estimate <inline-formula><inline-graphic xlink:href="620874v2_inline84.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is also not used (without the simplification assumption it is used to bias the prediction <inline-formula><inline-graphic xlink:href="620874v2_inline85.gif" mime-subtype="gif" mimetype="image"/></inline-formula> towards the centre of space via the expectation of the truncated normal). So, for these models we optimized either three <inline-formula><inline-graphic xlink:href="620874v2_inline86.gif" mime-subtype="gif" mimetype="image"/></inline-formula> or two parameters (σ<sub><italic>resp</italic></sub>, <italic>λ</italic>) only.</p>
<p>To find the parameter values that maximize the likelihood we used the Bayesian Adaptive Direct Search optimization algorithm (BADS; <xref ref-type="bibr" rid="c2">Acerbi &amp; Ma, 2017</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/acerbilab/bads">https://github.com/acerbilab/bads</ext-link>). For each model and dataset (responses from one participant for one experimental noise condition) we ran BADS four times, each from a different starting point, <italic>θ</italic><sub><italic>m</italic>,0</sub>. To obtain promising starting points for each dataset, we first selected 1000 sets of parameter values <italic>θ</italic><sub><italic>m</italic></sub> at random from within the following plausible bounds: <inline-formula><inline-graphic xlink:href="620874v2_inline87.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, σ<sub><italic>resp</italic></sub>: 1° - 50°, and <italic>λ</italic>: 0.001 - 0.25. For each of the parameter sets we computed the likelihood <italic>L</italic>(<italic>θ</italic><sub><italic>m</italic></sub>), and we subsequently selected the four parameter sets with the highest likelihood as starting points for BADS.</p>
<p>Non-extensive parameter recovery analyses indicated good identifiability of the true model parameters. Each of the model variations was tested several times with various parameter combinations. Responses were generated for a hypothetical observer using the experimental trials (i.e., stimuli location sequences) of a random participant from the current study as model input. Model parameters were then fitted to the generated response data using the above-described method. Approximate correspondence of the fitted parameters with the parameter values that were used during generation was checked subjectively. Although minor differences existed (as expected due to random noise generation and limited number of trials), none of the parameter recovery results gave rise to doubt identifiability.</p>
<p>For comparison of the models’ quality of fit to participants’ data, we computed the Bayesian information criterion (<italic>BIC</italic>) for each fit and then obtained an estimate of the log model evidence (<italic>lme</italic>) per participant for each model by summing over the two experimental noise conditions according to:
<disp-formula id="ueqn46">
<graphic xlink:href="620874v2_ueqn46.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where #(<italic>θ</italic><sub><italic>m</italic></sub>) represents the number of fitted parameters for model <italic>m</italic>.</p>
<p>The log model evidence <italic>lme</italic> is used to compare the models’ performances in predicting participants’ responses. We make use of two different comparison methods. First, we assume that all subjects make prediction responses according to the same underlying inference mechanism. The most likely mechanism, out of the ones tested here, is represented by the model where the summed <italic>lme</italic> across subjects is largest. This is known as a fixed effects model comparison. We used bootstrapping to obtain robust estimates of the summed <italic>lme</italic> differences between models, and their confidence intervals (<xref ref-type="bibr" rid="c1">Acerbi et al., 2018</xref>). Precisely, we repeatedly (N = 10,000) sampled 29 subjects with replacement and computed the summed <italic>lme</italic> differences for each sample, for all models relative to one reference model. Subsequently, we selected the 0.05, 0.5, and 0.95 quantiles for each model from the bootstrapped summed differences.</p>
<p>The second model comparison method we employed is based on the random effects method (<xref ref-type="bibr" rid="c52">Stephan et al., 2009</xref>). In general, this analysis accounts for heterogeneity within the subject population and estimates a probability distribution across models to indicate the likelihood of any one model to have generated the responses of a randomly selected subject. We here used the random effects method in a factorial model comparison, where probability distributions were estimated across competing model components based on the summed <italic>lme</italic> per subject over all models that incorporated that component (<xref ref-type="bibr" rid="c1">Acerbi et al., 2018</xref>): e.g., the factor ‘pruning function’ had three components: keep_<italic>RCNT</italic>, keep_<italic>MAXP</italic>, and keep_<italic>WAVG</italic>. For each factor, we could then compare the components’ predictive performance relative to each other via the protected exceedance probability measure (<xref ref-type="bibr" rid="c46">Rigoux et al., 2014</xref>).</p>
</sec>
<sec id="s4j">
<label>4.10</label>
<title>Experimental noise and changepoint hazard rate inference</title>
<p>In the previous section we have described how we fit the model’s parameters to participants’ responses, but how did participants obtain their estimates of the parameters of the generative model? A Bayesian observer would construct a joint distribution over the parameters and update it iteratively as evidence comes in. This evidence comes in the form of a likelihood, that expresses the probability of observing a certain stimulus location <italic>x</italic><sub><italic>t</italic></sub> given a particular set of parameter values, and conditional on all previous observations (and the model itself). Under a non-informative prior over the joint parameter space, the parameter combination that maximizes the likelihood product across all observations forms the best estimate of the parameters. This fully Bayesian inference process is rather complex, likely computationally intractable for human brains, and falls outside of the scope of this study (for related discussions and algorithms see <xref ref-type="bibr" rid="c57">Wilson et al., 2010</xref> and <xref ref-type="bibr" rid="c41">Piray &amp; Daw, 2021</xref>). However, we utilized the general idea of computing likelihoods for particular combinations of parameter values to obtain an insight into which parameter combinations are more or less probable to have given rise to the given stimuli locations. Hence, we can compare the fitted parameter estimates of the participants to these likelihoods, in an attempt to quantify the errors that participants made in estimating the parameter combinations.</p>
<p>An equivalent algorithm to maximizing the likelihood product is minimizing the summed surprisal (<xref ref-type="bibr" rid="c13">Friston, 2010</xref>), across all stimuli in the experimental condition (i.e., across all stimuli in all trials with the same experimental noise). Surprisal for a single stimulus is computed as:
<disp-formula id="ueqn47">
<graphic xlink:href="620874v2_ueqn47.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In the limited memory model (<italic>M</italic> = 1) with late truncation simplification, single stimulus surprisal is approximated with:
<disp-formula id="ueqn48">
<graphic xlink:href="620874v2_ueqn48.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
To compute the coloured background plane of <xref rid="fig5" ref-type="fig">Figure 5A</xref>, we computed the approximate surprisal summed across all stimuli of each experimental condition (all trials and all subjects were aggregated), for a grid of 625 parameter combinations: 25 values of <inline-formula><inline-graphic xlink:href="620874v2_inline88.gif" mime-subtype="gif" mimetype="image"/></inline-formula> between 2.5° and 250° (logarithmically spaced) x 25 values of <inline-formula><inline-graphic xlink:href="620874v2_inline89.gif" mime-subtype="gif" mimetype="image"/></inline-formula> between 0.02 and 0.98 (linearly spaced). The summed surprisal values were subsequently scaled to the interval between 0 (the minimum surprisal) and 1 (surprisal for the largest <inline-formula><inline-graphic xlink:href="620874v2_inline90.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="620874v2_inline91.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, i.e., top right corner in the plot), and larger surprisal values (bottom left corner) were capped to a maximum of 1.5. Linear interpolation was used during plotting to create a smooth surface.</p>
</sec>
<sec id="s4k">
<label>4.11</label>
<title>Qualitative data analysis</title>
<p>The data shown in <xref rid="fig3" ref-type="fig">Figures 3</xref> and <xref rid="fig4" ref-type="fig">4</xref> is the group median (Q1 – Q3 in shaded area, i.e., 25% and 75% quantiles at the group level) of the median at the individual level, per grid-point on the x-axis. This robust visualization controlled for outlier responses at the individual level (e.g., lapses), and for possible outlier participants at the group level. Likewise, we employed non-parametric rank-based statistics (sign tests and Wilcoxon signed rank tests) that are robust to outliers and non-normality of the response data (which contained much intersubject variability).</p>
<p>In <xref rid="fig3" ref-type="fig">Figures 3B</xref> and <xref rid="fig3" ref-type="fig">3C</xref> the trials were first discretized per SAC level (stimuli after changepoint) and the medians were computed for each bin. In <xref rid="fig3" ref-type="fig">Figures 3A</xref>, <xref rid="fig4" ref-type="fig">4A</xref> and <xref rid="fig4" ref-type="fig">4B</xref> the x-axis represented continuous variables (omniscient mean or absolute prediction error), so we instead computed rolling weighted medians for each grid point on the x-axis, where the weights were assigned to the individual’s responses by a Gaussian kernel that was centred on the grid-point (SD = 5° in <xref rid="fig3" ref-type="fig">Figure 3A</xref>, SD = 0.1 in <xref rid="fig4" ref-type="fig">Figure 4A</xref>, and SD = 0.2 in <xref rid="fig4" ref-type="fig">Figure 4B</xref>, see below for further explanations). To improve smoothness of the curves in the figures, the group-level medians (and Q1s, Q3s) were computed via bootstrapping (N = 100 random samples of 29 subjects, with replacement): the depicted values are the means across the bootstrapped group-level medians (and Q1s, Q3s).</p>
<p>The normalized errors (<xref rid="fig3" ref-type="fig">Figure 3C</xref>) were computed for each trial as the ratio of the participant’s error (numerator) and the error of the naïve observer (denominator), with respect to the true generative mean <italic>μ</italic><sub><italic>t</italic></sub>:
<disp-formula id="ueqn49">
<graphic xlink:href="620874v2_ueqn49.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
As explained in the previous paragraph, these normalized errors were discretized per SAC level and the individual’s median was then computed for each bin. The group-level medians (Q1s, Q3s) were subsequently computed via bootstrapping.</p>
<p>The normalized bias (<xref rid="fig4" ref-type="fig">Figure 4A</xref>) for each trial was computed as the ratio of the participant’s bias (numerator) and the prediction error of the omniscient observer (denominator):
<disp-formula id="ueqn50">
<graphic xlink:href="620874v2_ueqn50.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The signed bias (<xref rid="fig4" ref-type="fig">Figure 4B</xref>) of a trial was computed as:
<disp-formula id="ueqn51">
<graphic xlink:href="620874v2_ueqn51.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the ‘sgn(y)’ function is -1 if y&lt;0, and 1 otherwise.</p>
<p>To obtain unbiased estimates of an individual’s average trace as a function of a continuous variable (<xref rid="fig3" ref-type="fig">Figures 3A</xref>, <xref rid="fig4" ref-type="fig">4A, 4B</xref>) via the rolling median method it is essential that the trial density across the x-axis is approximately equal. This was naturally the case for the generative mean <italic>μ</italic><sub><italic>t</italic></sub>, because it was sampled from a uniform distribution between -90° and 90°, and so it was also approximately true for the omniscient observer’s estimate of the generative mean (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). However, to achieve a relatively constant density of trials over the (omniscient observer’s) prediction errors for the normalized and signed bias plots (<xref rid="fig4" ref-type="fig">Figure 4</xref>), we used a non-linear transformation of the prediction errors when we computed the rolling medians. These transforms were based on the expected cumulative probability distributions of the prediction errors, as is explained in the following paragraphs.</p>
<p>The absolute distances between the generative means from before and after a changepoint are approximately distributed as a triangular distribution (across many trials):
<disp-formula id="ueqn52">
<graphic xlink:href="620874v2_ueqn52.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
By extension, the absolute prediction errors of the omniscient observer for SAC 1 (<xref rid="fig4" ref-type="fig">Figure 4A</xref>) have nearly the same distribution. Hence, their cumulative distribution function (cdf) can be approximated as:
<disp-formula id="ueqn53">
<graphic xlink:href="620874v2_ueqn53.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
for absolute prediction errors <italic>ε</italic> ∈ [0°, 180°].</p>
<p>The cdf allowed us to assign a cumulative probability to every trial based on the omniscient observer’s prediction errors. By definition, the trials of an individual now had a constant density over these cumulative probabilities. We could thus compute an individual’s rolling median normalized bias over a grid of cumulative probabilities using a Gaussian weights kernel in the cdf-transformed space. The group-level medians (Q1s, Q3s) were subsequently obtained for each grid point via bootstrapping. Each of the grid points corresponds to a particular prediction error (of the omniscient observer), which we computed via the inverse cdf and utilized as x-axis labels in <xref rid="fig4" ref-type="fig">Figure 4A</xref>.</p>
<p>We used a similar cdf-based transformation for the prediction errors of the omniscient observer on no-changepoint stimuli (i.e., SAC 2 and SAC 3 in <xref rid="fig4" ref-type="fig">Figure 4B</xref>). The directional prediction errors are roughly distributed as a normal distribution:
<disp-formula id="ueqn54">
<graphic xlink:href="620874v2_ueqn54.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Since the omniscient observer is fully aware of the changepoints, the a-priori uncertainty about the generative mean, <inline-formula><inline-graphic xlink:href="620874v2_inline92.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, is equal to the experimental noise variance divided by the number of stimuli that were observed since the last changepoint, e.g., N = 1 for SAC 2 and N = 2 for SAC 3. Hence, the cdf for the absolute prediction errors can be written as:
<disp-formula id="ueqn55">
<graphic xlink:href="620874v2_ueqn55.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For <italic>ε</italic> ≥ 0, where <italic>N</italic> is defined by the SAC level, and <italic>Φ</italic> denotes the cdf of the standard normal distribution.</p>
<p>As before, the cdf was used to assign cumulative probabilities to trials (separately for bot noise conditions in SAC 2 and SAC 3), which were then used as a basis to compute individuals’ rolling weighted median biases on a regular grid in cdf-space. Subsequently, group-level medians (Q1s, Q3s) were computed via bootstrapping, and the corresponding absolute prediction errors of the grid points were computed via inverse cdfs. Finally, we plotted the curves of the two SAC levels on a common axis, where the axis-spacing was obtained via a cdf transformation with N = 1.5 (i.e., an average spacing for both SAC levels).</p>
<p>N.b. the depicted curves of the modelled observers were computed in the same way as for the human observers: i.e., we simulated their intended response locations (<inline-formula><inline-graphic xlink:href="620874v2_inline93.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, without response noise or lapses) for each individual’s set of trials and we used them to compute rolling medians at the individual level (via the cdf-transformation method, if necessary) and group-level medians via bootstrapping, with the same methodological settings as for the human observers.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We thank Kamesh Krishnamurthy, Matthew Nassar, Shilpa Sarode, and Joshua Gold for making their experimental data available and for kindly answering our questions. We also thank Günther Koliander for helpful feedback on an earlier version of the methods section. This work was supported by the Austrian Science Fund (FWF; doi.org/10.55776/ZK66, Dynamates).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Acerbi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Dokka</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Angelaki</surname>, <given-names>D. E.</given-names></string-name>, &amp; <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Bayesian comparison of explicit and implicit causal inference strategies in multisensory heading perception</article-title>. <source>PLOS Computational Biology</source>, <volume>14</volume>(<issue>7</issue>), <fpage>e1006110</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006110</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Acerbi</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>30</volume>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Adams</surname>, <given-names>R. P.</given-names></string-name>, &amp; <string-name><surname>MacKay</surname>, <given-names>D. J. C.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Bayesian Online Changepoint Detection (No</article-title>. <pub-id pub-id-type="arxiv">0710.3742</pub-id>). <source>arXiv</source>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/0710.3742">http://arxiv.org/abs/0710.3742</ext-link></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bakst</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>McGuire</surname>, <given-names>J. T.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Experience-driven recalibration of learning from surprising events</article-title>. <source>Cognition</source>, <volume>232</volume>, <fpage>105343</fpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2022.105343</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Walton</surname>, <given-names>M. E.</given-names></string-name>, &amp; <string-name><surname>Rushworth</surname>, <given-names>M. F. S.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nature Neuroscience</source>, <volume>10</volume>(<issue>9</issue>), <fpage>1214</fpage>–<lpage>1221</lpage>. <pub-id pub-id-type="doi">10.1038/nn1954</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Bévalot</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Meyniel</surname>, <given-names>F.</given-names></string-name></person-group> (<year>2023</year>). <article-title>A dissociation between the use of implicit and explicit priors in perceptual inference</article-title>. <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2023.08.18.553834</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clark</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Whatever next? Predictive brains, situated agents, and the future of cognitive science</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>36</volume>(<issue>3</issue>), <fpage>181</fpage>–<lpage>204</lpage>. <pub-id pub-id-type="doi">10.1017/S0140525X12000477</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>De Lange</surname>, <given-names>F. P.</given-names></string-name>, <string-name><surname>Heilbron</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Kok</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2018</year>). <article-title>How Do Expectations Shape Perception?</article-title> <source>Trends in Cognitive Sciences</source>, <volume>22</volume>(<issue>9</issue>), <fpage>764</fpage>–<lpage>779</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2018.06.002</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eissa</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name>, <string-name><surname>Josić</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Kilpatrick</surname>, <given-names>Z. P.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Suboptimal human inference can invert the bias-variance trade-off for decisions with asymmetric evidence</article-title>. <source>PLOS Computational Biology</source>, <volume>18</volume>(<issue>7</issue>), <fpage>e1010323</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1010323</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ellsberg</surname>, <given-names>D.</given-names></string-name></person-group> (<year>1961</year>). <article-title>Risk, Ambiguity, and the Savage Axioms</article-title>. <source>The Quarterly Journal of Economics</source>, <volume>75</volume>(<issue>4</issue>), <fpage>643</fpage>–<lpage>669</lpage>. <pub-id pub-id-type="doi">10.2307/1884324</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Faisal</surname>, <given-names>A. A.</given-names></string-name>, <string-name><surname>Selen</surname>, <given-names>L. P. J.</given-names></string-name>, &amp; <string-name><surname>Wolpert</surname>, <given-names>D. M.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Noise in the nervous system</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>9</volume>(<issue>4</issue>), <fpage>292</fpage>–<lpage>303</lpage>. <pub-id pub-id-type="doi">10.1038/nrn2258</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fearnhead</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Liu</surname>, <given-names>Z.</given-names></string-name></person-group> (<year>2007</year>). <article-title>On-Line Inference for Multiple Changepoint Problems</article-title>. <source>Journal of the Royal Statistical Society Series B: Statistical Methodology</source>, <volume>69</volume>(<issue>4</issue>), <fpage>589</fpage>–<lpage>605</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9868.2007.00601.x</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friston</surname>, <given-names>K.</given-names></string-name></person-group> (<year>2010</year>). <article-title>The free-energy principle: A unified brain theory?</article-title> <source>Nature Reviews Neuroscience</source>, <volume>11</volume>(<issue>2</issue>), <fpage>127</fpage>–<lpage>138</lpage>. <pub-id pub-id-type="doi">10.1038/nrn2787</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Norman</surname>, <given-names>K. A.</given-names></string-name>, &amp; <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Discovering latent causes in reinforcement learning</article-title>. <source>Current Opinion in Behavioral Sciences</source>, <volume>5</volume>, <fpage>43</fpage>–<lpage>50</lpage>. <pub-id pub-id-type="doi">10.1016/j.cobeha.2015.07.007</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glaze</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Filipowicz</surname>, <given-names>A. L. S.</given-names></string-name>, <string-name><surname>Kable</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2018</year>). <article-title>A bias– variance trade-off governs individual differences in on-line learning in an unpredictable environment</article-title>. <source>Nature Human Behaviour</source>, <volume>2</volume>(<issue>3</issue>), <fpage>213</fpage>–<lpage>224</lpage>. <pub-id pub-id-type="doi">10.1038/s41562-018-0297-4</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heilbron</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Meyniel</surname>, <given-names>F.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Confidence resets reveal hierarchical adaptive learning in humans</article-title>. <source>PLOS Computational Biology</source>, <volume>15</volume>(<issue>4</issue>), <fpage>e1006972</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006972</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kang</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Tobler</surname>, <given-names>P. N.</given-names></string-name>, &amp; <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Bayesian reinforcement learning: A basic overview</article-title>. <source>Neurobiology of Learning and Memory</source>, <volume>211</volume>, <fpage>107924</fpage>. <pub-id pub-id-type="doi">10.1016/j.nlm.2024.107924</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kiyonaga</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Scimeca</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Bliss</surname>, <given-names>D. P.</given-names></string-name>, &amp; <string-name><surname>Whitney</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Serial Dependence across Perception, Attention, and Memory</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>21</volume>(<issue>7</issue>), <fpage>493</fpage>–<lpage>497</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2017.04.011</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Knill</surname>, <given-names>D. C.</given-names></string-name>, &amp; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2004</year>). <article-title>The Bayesian brain: The role of uncertainty in neural coding and computation</article-title>. <source>Trends in Neurosciences</source>, <volume>27</volume>(<issue>12</issue>), <fpage>712</fpage>–<lpage>719</lpage>. <pub-id pub-id-type="doi">10.1016/j.tins.2004.10.007</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Körding</surname>, <given-names>K. P.</given-names></string-name>, <string-name><surname>Beierholm</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Quartz</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name>, &amp; <string-name><surname>Shams</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Causal Inference in Multisensory Perception</article-title>. <source>PLOS One</source>, <volume>2</volume>(<issue>9</issue>), <fpage>e943</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0000943</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krishnamurthy</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Sarode</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Arousal-related adjustments of perceptual biases optimize perception in dynamic environments</article-title>. <source>Nature Human Behaviour</source>, <volume>1</volume>(<issue>6</issue>), <fpage>0107</fpage>. <pub-id pub-id-type="doi">10.1038/s41562-017-0107</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Larigaldie</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Yates</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Beierholm</surname>, <given-names>U. R.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Perceptual clustering in auditory streaming</article-title>. <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2021.05.27.446050</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name>, &amp; <string-name><surname>Kable</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2020</year>). <article-title>The human as delta-rule learner</article-title>. <source>Decision</source>, <volume>7</volume>(<issue>1</issue>), <fpage>55</fpage>–<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1037/dec0000112</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liakoni</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Modirshanechi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Brea</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Learning in Volatile Environments With the Bayes Factor Surprise</article-title>. <source>Neural Computation</source>, <volume>33</volume>(<issue>2</issue>), <fpage>269</fpage>–<lpage>340</lpage>. <pub-id pub-id-type="doi">10.1162/neco_a_01352</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Organizing probabilistic models of perception</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>16</volume>(<issue>10</issue>), <fpage>511</fpage>–<lpage>518</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2012.08.010</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mathys</surname>, <given-names>C. D.</given-names></string-name>, <string-name><surname>Lomakina</surname>, <given-names>E. I.</given-names></string-name>, <string-name><surname>Daunizeau</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Iglesias</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Brodersen</surname>, <given-names>K. H.</given-names></string-name>, <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name>, &amp; <string-name><surname>Stephan</surname>, <given-names>K. E.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Uncertainty in perception and the Hierarchical Gaussian Filter</article-title>. <source>Frontiers in Human Neuroscience</source>, <volume>8</volume>. <pub-id pub-id-type="doi">10.3389/fnhum.2014.00825</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mathys</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Daunizeau</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name>, &amp; <string-name><surname>Stephan</surname>, <given-names>K. E.</given-names></string-name></person-group> (<year>2011</year>). <article-title>A Bayesian foundation for individual learning under uncertainty</article-title>. <source>Frontiers in Human Neuroscience</source>, <volume>5</volume>. <pub-id pub-id-type="doi">10.3389/fnhum.2011.00039</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McGuire</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name>, &amp; <string-name><surname>Kable</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Functionally Dissociable Influences on Learning Rate in a Dynamic Environment</article-title>. <source>Neuron</source>, <volume>84</volume>(<issue>4</issue>), <fpage>870</fpage>–<lpage>881</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.013</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Meijer</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Noppeney</surname>, <given-names>U.</given-names></string-name></person-group> (<year>2020</year>). <chapter-title>Chapter 5—Computational models of multisensory integration</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>K.</given-names> <surname>Sathian</surname></string-name> &amp; <string-name><given-names>V. S.</given-names> <surname>Ramachandran</surname></string-name></person-group> (Eds.), <source>Multisensory Perception</source> (pp. <fpage>113</fpage>–<lpage>133</lpage>). <publisher-name>Academic Press</publisher-name>. <pub-id pub-id-type="doi">10.1016/B978-0-12-812492-5.00005-X</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meijer</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Veselic</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Calafiore</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Noppeney</surname>, <given-names>U.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Integration of audiovisual spatial signals is not consistent with maximum likelihood estimation</article-title>. <source>Cortex</source>, <volume>119</volume>, <fpage>74</fpage>–<lpage>88</lpage>. <pub-id pub-id-type="doi">10.1016/j.cortex.2019.03.026</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Modirshanechi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brea</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2022</year>). <article-title>A taxonomy of surprise definitions</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>110</volume>, <fpage>102712</fpage>. <pub-id pub-id-type="doi">10.1016/j.jmp.2022.102712</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Bruckner</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Statistical context dictates the relationship between feedback-related EEG signals and learning</article-title>. <source>eLife</source>, <volume>8</volume>, <elocation-id>e46975</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.46975</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Rumsey</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Parikh</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Heasly</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title>. <source>Nature Neuroscience</source>, <volume>15</volume>(<issue>7</issue>), <fpage>1040</fpage>–<lpage>1046</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3130</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Heasly</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2010</year>). <article-title>An Approximately Bayesian Delta-Rule Model Explains the Dynamics of Belief Updating in a Changing Environment</article-title>. <source>The Journal of Neuroscience</source>, <volume>30</volume>(<issue>37</issue>), <fpage>12366</fpage>–<lpage>12378</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Norton</surname>, <given-names>E. H.</given-names></string-name>, <string-name><surname>Acerbi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, &amp; <string-name><surname>Landy</surname>, <given-names>M. S.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Human online adaptation to changes in prior probability</article-title>. <source>PLOS Computational Biology</source>, <volume>15</volume>(<issue>7</issue>), <fpage>e1006681</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006681</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Reilly</surname>, <given-names>J. X.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Making predictions in a changing world—Inference, uncertainty, and learning</article-title>. <source>Frontiers in Neuroscience</source>, <volume>7</volume>. <pub-id pub-id-type="doi">10.3389/fnins.2013.00105</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Payzan-LeNestour</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Bossaerts</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Risk, Unexpected Uncertainty, and Estimation Uncertainty: Bayesian Learning in Unstable Settings</article-title>. <source>PLoS Computational Biology</source>, <volume>7</volume>(<issue>1</issue>), <fpage>e1001048</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1001048</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pearce</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name><surname>Hall</surname>, <given-names>G.</given-names></string-name></person-group> (<year>1980</year>). <article-title>A model for Pavlovian learning: Variations in the effectiveness of conditioned but not of unconditioned stimuli</article-title>. <source>Psychological Review</source>, <volume>87</volume>(<issue>6</issue>), <fpage>532</fpage>–<lpage>552</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295X.87.6.532</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Piasini</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Chaudhari</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2023</year>). <article-title>How Occam’s razor guides human decision-making</article-title>. <source>bioRxiv</source> <pub-id pub-id-type="doi">10.1101/2023.01.10.523479</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Piray</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name></person-group> (<year>2020</year>). <article-title>A simple model for learning in volatile environments</article-title>. <source>PLOS Computational Biology</source>, <volume>16</volume>(<issue>7</issue>), <fpage>e1007963</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1007963</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Piray</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name></person-group> (<year>2021</year>). <article-title>A model for learning based on the joint estimation of stochasticity and volatility</article-title>. <source>Nature Communications</source>, <volume>12</volume>(<issue>1</issue>), <fpage>6587</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-021-26731-9</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Beck</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, &amp; <string-name><surname>Latham</surname>, <given-names>P. E.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Probabilistic brains: Knowns and unknowns</article-title>. <source>Nature Neuroscience</source>, <volume>16</volume>(<issue>9</issue>), <fpage>1170</fpage>–<lpage>1178</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3495</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quintero</surname>, <given-names>S. I.</given-names></string-name>, <string-name><surname>Shams</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Kamal</surname>, <given-names>K.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Changing the Tendency to Integrate the Senses</article-title>. <source>Brain Sciences</source>, <volume>12</volume>(<issue>10</issue>), <fpage>1384</fpage>. <pub-id pub-id-type="doi">10.3390/brainsci12101384</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rahnev</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Denison</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Suboptimality in Perceptual Decision Making</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>41</volume>, <fpage>1</fpage>–<lpage>107</lpage>. <pub-id pub-id-type="doi">10.1017/S0140525X18000936</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Rescorla</surname>, <given-names>R. A.</given-names></string-name>, &amp; <string-name><surname>Wagner</surname>, <given-names>A. R.</given-names></string-name></person-group> (<year>1972</year>). <chapter-title>A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>A.H.</given-names> <surname>Black</surname></string-name> &amp; <string-name><given-names>W. F.</given-names> <surname>Prokasy</surname></string-name></person-group> (Eds.), <source>Classical conditioning II: Current research and theory</source>. <publisher-name>Appleton-Century-Crofts</publisher-name>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rigoux</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Stephan</surname>, <given-names>K. E.</given-names></string-name>, <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name>, &amp; <string-name><surname>Daunizeau</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Bayesian model selection for group studies—Revisited</article-title>. <source>NeuroImage</source>, <volume>84</volume>, <fpage>971</fpage>–<lpage>985</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.065</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ryali</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Reddy</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Yu</surname>, <given-names>A. J.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Demystifying excessively volatile human learning: A Bayesian persistent prior and a neural approximation</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>31</volume>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shams</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Beierholm</surname>, <given-names>U.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Bayesian causal inference: A unifying neuroscience theory</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source>, <volume>137</volume>, <fpage>104619</fpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2022.104619</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shams</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Beierholm</surname>, <given-names>U. R.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Causal inference in perception</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>14</volume>(<issue>9</issue>), <fpage>425</fpage>–<lpage>432</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2010.07.001</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Skerritt-Davis</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Elhilali</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Detecting change in stochastic sound sequences</article-title>. <source>PLOS Computational Biology</source>, <volume>14</volume>(<issue>5</issue>), <fpage>e1006162</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006162</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Skerritt-Davis</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Elhilali</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Computational framework for investigating predictive processing in auditory perception</article-title>. <source>Journal of Neuroscience Methods</source>, <volume>360</volume>, <fpage>109177</fpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2021.109177</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stephan</surname>, <given-names>K. E.</given-names></string-name>, <string-name><surname>Penny</surname>, <given-names>W. D.</given-names></string-name>, <string-name><surname>Daunizeau</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Moran</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Bayesian model selection for group studies</article-title>. <source>NeuroImage</source>, <volume>46</volume>(<issue>4</issue>), <fpage>1004</fpage>–<lpage>1017</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.03.025</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Talluri</surname>, <given-names>B. C.</given-names></string-name>, <string-name><surname>Urai</surname>, <given-names>A. E.</given-names></string-name>, <string-name><surname>Tsetsos</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Usher</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Donner</surname>, <given-names>T. H.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Confirmation Bias through Selective Overweighting of Choice-Consistent Evidence</article-title>. <source>Current Biology</source>, <volume>28</volume>(<issue>19</issue>), <fpage>3128</fpage>-<lpage>3135.e8</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2018.07.052</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tavoni</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Doi</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Pizzica</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Human inference reflects a normative balance of complexity and accuracy</article-title>. <source>Nature Human Behaviour</source>, <volume>6</volume>(<issue>8</issue>), <fpage>1153</fpage>– <lpage>1168</lpage>. <pub-id pub-id-type="doi">10.1038/s41562-022-01357-z</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trimmer</surname>, <given-names>P. C.</given-names></string-name>, <string-name><surname>Houston</surname>, <given-names>A. I.</given-names></string-name>, <string-name><surname>Marshall</surname>, <given-names>J. A. R.</given-names></string-name>, <string-name><surname>Mendl</surname>, <given-names>M. T.</given-names></string-name>, <string-name><surname>Paul</surname>, <given-names>E. S.</given-names></string-name>, &amp; <string-name><surname>McNamara</surname>, <given-names>J. M.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Decision-making under uncertainty: Biases and Bayesians</article-title>. <source>Animal Cognition</source>, <volume>14</volume>(<issue>4</issue>), <fpage>465</fpage>–<lpage>476</lpage>. <pub-id pub-id-type="doi">10.1007/s10071-011-0387-4</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Verbeke</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Verguts</surname>, <given-names>T.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Humans adaptively select different computational strategies in different learning environments</article-title>. <source>Psychological Review</source>. <pub-id pub-id-type="doi">10.1037/rev0000474</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Bayesian Online Learning of the Hazard Rate in Change-Point Problems</article-title>. <source>Neural Computation</source>, <volume>22</volume>(<issue>9</issue>), <fpage>2452</fpage>–<lpage>2476</lpage>. <pub-id pub-id-type="doi">10.1162/NECO_a_00007</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2013</year>). <article-title>A Mixture of Delta-Rules Approximation to Bayesian Inference in Change-Point Problems</article-title>. <source>PLoS Computational Biology</source>, <volume>9</volume>(<issue>7</issue>), <fpage>e1003150</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003150</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wozny</surname>, <given-names>D. R.</given-names></string-name>, <string-name><surname>Beierholm</surname>, <given-names>U. R.</given-names></string-name>, &amp; <string-name><surname>Shams</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Probability Matching as a Computational Strategy Used in Perception</article-title>. <source>PLoS Computational Biology</source>, <volume>6</volume>(<issue>8</issue>), <fpage>e1000871</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1000871</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>L. Q.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, &amp; <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Adaptive learning is structure learning in time</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source>, <volume>128</volume>, <fpage>270</fpage>–<lpage>281</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2021.06.024</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Yuille</surname>, <given-names>A. L.</given-names></string-name>, &amp; <string-name><surname>Bülthoff</surname>, <given-names>H. H.</given-names></string-name></person-group> (<year>1996</year>). <chapter-title>Bayesian decision theory and psychophysics</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>D. C.</given-names> <surname>Knill</surname></string-name></person-group> (Ed.), <source>Perception as Bayesian Inference</source>. <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105385.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Diaconescu</surname>
<given-names>Andreea Oliviana</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country>Canada</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study makes a <bold>valuable</bold> contribution to understanding Bayesian inference in dynamic environments by demonstrating how humans integrate prior beliefs with sensory evidence, revealing an overestimation of environmental volatility while accurately tracking noise. The evidence is <bold>solid</bold>, supported by robust model fitting and principled factorial model set analyses, though limitations in sample size and inconclusive findings on memory capacity tradeoffs reduce the overall impact. Future work should expand validation across datasets, enhance model comparisons, and explore the generalizability of reduced Bayesian frameworks to strengthen the conclusions and broader relevance of the study.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105385.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary</p>
<p>Behavioural adjustments to different sources of uncertainty remain a hot topic in many fields including reinforcement learning. The authors present valuable findings suggesting that human participants integrate prior beliefs with sensory evidence to improve their predictions in dynamically changing environments involving perceptual decision-making, pinpointing to hallmarks of Bayesian inference. Fitting of a reduced Bayesian model to participant choice behaviour reveals that decision-makers overestimate environmental volatility, but were reasonably accurate in terms of tracking environmental noise.</p>
<p>Strengths</p>
<p>Using a perceptual decision-making task in which participants were presented with sequences of noisy observation in environments with constant volatility and variable noise, the authors demonstrate solid evidence in favour of reduced Bayesian models that can account for participant choice behaviour when its generative parameters are fitted freely. The work nicely complements recent work demonstrating the fitting of a full Bayesian model to human reinforcement learning. The authors' approach to the fitting of the model in a principled/factorial manner that is exhaustive performs the model comparison and highlights the need for further work in evaluating the model's performance in environments outside of its generative parameters. Overall the work further highlights the utility of using perceptual decision-making for Bayesian inference questions.</p>
<p>Weaknesses</p>
<p>Although data sharing and reanalysis of data are extremely welcome, particularly considering their utility for open science, the small sample size (N= 29) of the original dataset somewhat restricts the authors' ability to show more conclusive findings when it comes to deciphering the optimal memory capacity of the fitted models. It is likely that the relatively small sample size also contributes to certain key hypotheses not being confirmed intuitively, for example, the expected negative relationship between hazard rates and log (noise). The notion that the participants rely on priors to a greater extent in low noise environments relative to high noise may also indicate that they might misattribute noise as volatility, as higher noise in the environment usually obscures the information content of outcomes, and in the case of pure random/noisy sequences, it should increase reliance to priors as new sensory evidence becomes unreliable.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105385.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Meijer et al reanalyze behavioral data from a task in which people made predictions about the next in a sequence of localized sounds with the goal of understanding the computations through which people combine sensory experiences into a prior used for perception. The authors combine basic analyses of experimental data with model simulations and development and fitting of a factorial model set that includes a prominent model of change-point detection that has previously been shown to approximate Bayesian inference at a reduced computational cost and provide a good match to human prediction data (reduced Bayesian model). The authors present a number of findings, including a demonstration of key qualitative markers for Bayesian change-point detection, a tendency in humans to over-rely on recent observations, a lack of an inverse relationship between fit values of hazard rate and fit values of noise, support for a number of assumptions in the reduced Bayesian model, and a lack of evidence for reliance on memory systems beyond the extremely minimal requirements of that model.</p>
<p>Strengths:</p>
<p>The paper asks an important question and takes a number of useful steps toward answering it. In particular, the factorial model set constructed to examine a number of explicit assumptions in the models typically fit to change-point predictive inference task data was a very useful innovation, and in some cases showed clearly that assumptions in the model are necessary or at least better than the proposed alternatives. In particular, the paper develops a notion of memory capacity that allows for a continuum of models differing in their tradeoffs between computational cost and predictive precision. Another strength of the paper is that it relies on data that avoids sequential biases that can contaminate reported beliefs in more standard predictive inference tasks.</p>
<p>Weaknesses:</p>
<p>The primary weakness of the paper is that most of the definitive findings reported within it have already been reported elsewhere. That humans increase the influence of surprising outcomes indicative of change points, or to say this another way, decrease their reliance on prior information in such cases, has been fairly well established, as has the discovery that humans tend to overuse recent outcomes when making predictions. The most novel aspect of the paper, the exploration of reductions of the Bayesian ideal observer that rely on differing memory capacities, yielded results that are somewhat difficult to interpret, particularly because it is not clear that the task analyzed is diagnostic of the memory capacity term in the model, or if so, what the qualitative hallmarks of a high/low memory capacity model reduction might be.</p>
</body>
</sub-article>
</article>