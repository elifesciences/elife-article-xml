<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">106506</article-id>
<article-id pub-id-type="doi">10.7554/eLife.106506</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106506.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Modeling flexible behavior with remapping-based hippocampal sequence learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Ito</surname>
<given-names>Yoshiki</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
<xref ref-type="aff" rid="A2">2</xref>
<xref ref-type="aff" rid="A3">3</xref>
<email>yito@nips.ac.jp</email>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Toyoizumi</surname>
<given-names>Taro</given-names>
</name>
<xref ref-type="aff" rid="A2">2</xref>
<xref ref-type="aff" rid="A4">4</xref>
<email>taro.toyoizumi@riken.jp</email>
</contrib>
<aff id="A1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/057zh3y96</institution-id><institution>Department of Neuroscience, Graduate School of Medicine, the University of Tokyo</institution></institution-wrap>, <city>Tokyo</city>, <country country="JP">Japan</country></aff>
<aff id="A2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04j1n1c04</institution-id><institution>RIKEN Center for Brain Science</institution></institution-wrap>, <city>Saitama</city>, <country country="JP">Japan</country></aff>
<aff id="A3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/048v13307</institution-id><institution>Division of Visual Information Processing, National Institute for Physiological Sciences</institution></institution-wrap>, <city>Okazaki</city>, <country country="JP">Japan</country></aff>
<aff id="A4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/057zh3y96</institution-id><institution>Department of Mathematical Informatics, Graduate School of Information Science and Technology, the University of Tokyo</institution></institution-wrap>, <city>Tokyo</city>, <country country="JP">Japan</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Bhalla</surname>
<given-names>Upinder S</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Centre for Biological Sciences</institution>
</institution-wrap>
<city>Bangalore</city>
<country>India</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="FN1" fn-type="coi-statement"><p>Competing interests: The authors declare that they have no competing interests.</p></fn>
</author-notes>
<pub-date pub-type="epub">
<day>16</day>
<month>02</month>
<year>2025</year>
</pub-date>
<pub-date date-type="original-publication" iso-8601-date="2025-06-06">
<day>06</day>
<month>06</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP106506</elocation-id>
<history><date date-type="sent-for-review" iso-8601-date="2025-02-28">
<day>28</day>
<month>02</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-02-16">
<day>16</day>
<month>02</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.48550/arXiv.2407.14708"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Ito &amp; Toyoizumi</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Ito &amp; Toyoizumi</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-106506-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Animals flexibly change their behavior depending on context. It is reported that the hippocampus is one of the most prominent regions for contextual behaviors, and its sequential activity shows context dependency. However, how such context-dependent sequential activity is established through reorganization of neuronal activity (remapping) is unclear. To better understand the formation of hippocampal activity and its contribution to context-dependent flexible behavior, we present a novel biologically plausible reinforcement learning model. In this model, a context-selection module promotes the formation of context-dependent sequential activity and allows for flexible switching of behavior in multiple contexts. This model reproduces a variety of findings from neural activity, optogenetic inactivation, human fMRI, and clinical research. Furthermore, our model predicts that imbalances in the ratio between sensory and contextual inputs in the context-selection module account for schizophrenia (SZ) and autism spectrum disorder (ASD)-like behaviors.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="s1" sec-type="intro">
<title>Introduction</title>
<p>Humans exhibit highly flexible behavior. However, a major challenge in solving various tasks with one neural network is that the same external stimulus can have different meanings depending on the context. For example, the word “mouse” can mean either an animal or a PC device, depending on the context (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Therefore, for correct word recognition, the biological neural computation should not be based only on the word “mouse” alone, but also on the context it appears in. In experiments, it is reported that the hippocampus is one of the most important regions for contextual behavior. Hippocampal neurons show sequential activity (<xref ref-type="bibr" rid="c8">Buzsáki and Tingley, 2018</xref>) related to episodic memory (<xref ref-type="bibr" rid="c7">Burgess et al., 2002</xref>), the amount of reward (<xref ref-type="bibr" rid="c2">Ambrose et al., 2016</xref>), planning (<xref ref-type="bibr" rid="c35">Ólafsdóttir et al., 2018</xref>), and recall (<xref ref-type="bibr" rid="c9">Carr et al., 2011</xref>), and their representation depends on the context (<xref ref-type="bibr" rid="c20">Hasselmo and Eichenbaum, 2005</xref>). Additionally, hippocampal neurons exhibit reorganized neural activity called remapping, which does not purely reflect the change in the external stimuli but task structure (<xref ref-type="bibr" rid="c24">Jeffery et al., 2003</xref>), and subjective context (<xref ref-type="bibr" rid="c40">Sanders et al., 2020</xref>). However, how context-dependent sequential activity in the hippocampus is established through remapping and how it contributes to flexible behavior remain to be understood.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1</label>
<caption><title>Schematic representation of our model.</title>
<p><bold>A</bold>, An example of context-dependent cognition. Humans can understand the meaning of “mouse” (an animal or a computer input device) depending on the context. <bold>B</bold>, Our model involves two modules: the context selection module (<italic>X</italic>) and the hippocampal sequential module (<italic>H</italic>). chooses a context depending on the external stimuli and the input from <italic>H</italic>, and activates a sequence in <italic>H</italic>. This sequence is used for reward prediction. In addition, <italic>H</italic> sends predictive feedback about external stimuli to <italic>X</italic>. <bold>C</bold>, <italic>X</italic> compares the predictive input from <italic>H</italic> to the external stimuli. In case of a prediction error (a green cross mark), remapping occurs: the context representation in <italic>X</italic> is either switched or newly created and a different sequence in <italic>H</italic> is activated. <bold>D</bold>, Episodic segments represented in <italic>H</italic> are combined depending on rewards (purple arrows) and concatenated into task-dependent sequences. The sequences support action planning and enable predictions of future external stimuli and rewards. <bold>E</bold>, Mechanism of remapping in our model. Blue squares represent contextual states in the context selection module, and orange squares represent those in the sequential module and gray circles represent visible environmental states. Reward-independent synaptic connections are indicated by black arrows and reward-dependent synaptic connections are indicated by purple arrows. Here we consider a situation where an agent has experienced the environmental states S1 and S2, and the corresponding contextual states are already established in <italic>X</italic> and <italic>H</italic>. If the agent assumes it is in a contextual state associated with S1 that predicts external stimuli other than S2 but experiences S2, a prediction error arises (a green cross mark) and triggers remapping: a new contextual state associated with S2 indexed by <italic>β</italic> (green squares) is created, and the synaptic connections are potentiated between <italic>X</italic> and <italic>H</italic> (green arrows).</p></caption>
<graphic xlink:href="2407.14708v2_fig1.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>Several theoretical models have been proposed to explain how hippocampal activity depends on context. The first approach uses the structure of the environment. The Tolman-Eichenbaum Machine (<xref ref-type="bibr" rid="c47">Whittington et al., 2020</xref>) and the Clone Structured Cognitive Graph (<xref ref-type="bibr" rid="c19">George et al., 2021</xref>) account for context-dependent neural activities, such as splitter cells (<xref ref-type="bibr" rid="c15">Dudchenko and Wood, 2014</xref>) and lap cells (<xref ref-type="bibr" rid="c44">Sun et al., 2020</xref>), by introducing graphical structure stored within the network. However, these models entail optimization procedures like backpropagation or the expectation-maximization (EM) algorism, which are not considered biologically plausible. The second approach uses eligibility trace to explain how past experiences, i.e., temporal context, are integrated into hippocampal activity (<xref ref-type="bibr" rid="c11">Cone and Clopath, 2024</xref>). In this framework, the length of the temporal context is constrained by the time constant of the eligibility trace. Nevertheless, animals can flexibly estimate the current context using history of various lengths (<xref ref-type="bibr" rid="c5">Barnett et al., 2014</xref>), suggesting that hippocampal activity may not be bound by a fixed eligibility window. The third approach trains recurrent neural networks (RNNs) to replicate the dynamics of hippocampal activity. While previous works have explored hippocampal sequential activity for planning (<xref ref-type="bibr" rid="c25">Jensen et al., 2024</xref>; <xref ref-type="bibr" rid="c36">Pettersen et al., 2024</xref>) and hippocampal remapping for contextual inference (<xref ref-type="bibr" rid="c33">Low et al., 2023</xref>) separately, they have yet to elucidate how these two aspects jointly enable flexible behavior. A comprehensive model that can explain the formation of context-dependent hippocampal sequences of various lengths through remapping, while relying on a biologically plausible learning process, would thus provide valuable insights into the mechanisms underpinning flexible behavior.</p>
<p>We aim to understand how context-dependent hippocampal sequences can emerge from hippocampal remapping driven by prediction errors. Our key idea is as follows. When the external environment deviates from the expectations of the current subjective context, prediction errors arise and trigger remapping. This process recruits distinct subsets of neurons to encode the novel experience, thereby establishing separate contextual memories and enabling flexible goal-oriented behavior in response to sudden environmental changes. To demonstrate the capability of this idea, we constructed a computational model comprising two modules: a context-selection module that selects the appropriate context based on prediction errors, and a hippocampal sequence module that learns to generate neural activity sequences predicting future events by concatenating context-dependent episodic segments according to reward. Our model implements simple model-based reinforcement learning in ambiguous contexts, yielding flexible behavior using a biologically plausible synaptic plasticity rule. We show that it reproduces a range of context-dependent hippocampal activities as well as the impairments associated with specific brain lesion studies.</p>
<p>Finally, our model predicts a relationship between deficits in model-based behavior and sensory processing. Clinical research has reported that patients with schizophrenia (SZ) or autism spectrum disorder (ASD) often exhibit problems with both behavioral flexibility and sensory processing, including hyper- and hyposensitivity (<xref ref-type="bibr" rid="c23">Javitt and Freedman, 2015</xref>; <xref ref-type="bibr" rid="c46">Watts et al., 2016</xref>). These symptoms frequently co-occur, but the underlying reason remains unclear. Our model shows that the relative sizes of the neural populations in the sensory-processing region and the context-processing region within the context-selection module are important for contextual inference, suggesting that treatments targeting sensory processing could improve cognitive flexibility in some psychoses.</p>
</sec>
<sec id="s2" sec-type="results">
<title>Results</title>
<p>As illustrated in <xref ref-type="fig" rid="fig1">Figure 1B-D</xref>, our model consists of two components: a context-selection module (X), which selects appropriate contexts, and a hippocampal sequence module (H), which generates neural activity sequences that predict future events. We use the Amari-Hopfield network (<xref ref-type="bibr" rid="c1">Amari, 1972</xref>; <xref ref-type="bibr" rid="c21">Hopfield, 1982</xref>) with Hebbian plasticity for X. X has two domains: a stimulus domain that represents external stimuli, and a contextual domain that represents subjective contextual information. This contextual domain allows the representation of multiple contextual states for a given external stimulus, such as different interpretations or associations of the stimulus. X can stably store multiple contextual states by creating attractors. When agents are at a starting point (i.e., a landmark), X initializes the neural activity of the contextual domain based on the external stimulus (see Materials and methods). When agents move to other locations, X receives predictive input from H and compares the predicted outcome with the actual external stimulus (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). When the prediction error is small, X performs error correction via attractor dynamics. When a significant prediction error occurs, remapping is triggered, and X’s activity either shifts to another contextual state or generates a new one, thereby adding a new context (<xref ref-type="fig" rid="fig1">Figure 1E</xref>, see Materials and methods). Once X’s activity is set, it transmits the resulting output to H, which then activates an initial segment of H’s episodic sequence. H produces an episodic sequence corresponding to hippocampal replay (<xref ref-type="bibr" rid="c14">Davidson et al., 2009</xref>) or planning (<xref ref-type="bibr" rid="c35">Ólafsdóttir et al., 2018</xref>) based on its connectivity. For simplicity, we use a binary recurrent neural network for H, whose connectivity is updated by a three-factor Hebbian plasticity rule that depends on reward (see Materials and methods). Each replayed sequence is associated with actions and two predictive outcomes: expected reward value and predicted future external stimuli. At the beginning of learning, there are only short sequences that generate immediate actions and yield short-term predictions. As learning continues, the three-factor Hebbian plasticity rule concatenates these memory fragments, thereby creating longer sequences that reflect the task structure (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Thus, H learns to generate extended sequences that outline a course of actions and predict both reward and subsequent changes in the environment, forming a simple transition model for model-based reinforcement learning (<xref ref-type="bibr" rid="c12">Coulom, 2007</xref>). If a significant reward prediction error arises from a sequence, the agent explores a random action not specified by that sequence (see Materials and methods).</p>
<sec id="s2-1">
<sec id="s2-1-1">
<title>Splitter cells</title>
<p>Our model reproduces a range of hippocampal activity patterns that align with empirical data. First, we confirmed that our model reproduces the splitter cells reported in the hippocampus (<xref ref-type="bibr" rid="c15">Dudchenko and Wood, 2014</xref>). Splitter cells are a subset of hippocampal neurons that fire differentially on an overlapping segment of trajectories depending on where the animal came from, and/or where it is going. It is known that they do so based on information that is not present in sensory or motor patterns at the time of the splitting effect, but rather appear to reflect the recent past, upcoming future, and/or inferences about the state of the environment (<xref ref-type="bibr" rid="c16">Duvelle et al., 2023</xref>).</p>
<p>Experimentally, splitter cells are most often observed in an alternation task in a modified T-maze. Here, we simplified this task by using an environment with five discrete states, i.e. five discrete external stimuli (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). In this environment, agents successfully solve this task by remapping, which creates different contextual states C2α and C2p at a task state S2 based on where the agents came from, and thereby enabling context-specific exploration of which state to go (S3 or S4) (<xref ref-type="fig" rid="fig2">Figure 2B</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2</label>
<caption><title>Our model replicates the emergence of splitter cells.</title>
<p><bold>A</bold>, Simplified alteration task diagram. <bold>B</bold>, A successful context map of our model. The state S2 is split into 2 different contextual states, C2α and C2β. <bold>C</bold>, The correct rate of our model. The error bar indicates the standard error of the mean (N = 40). <bold>D</bold>, The maximum number of states ahead that the agents planned (planning length) gradually increases over learning. Black lines indicate the planning length of each agent, and the red line is their average. <bold>e</bold>, Emergence of splitter cells in the hippocampus in the modified T-maze modification task (<xref ref-type="bibr" rid="c48">Wood et al., 2000</xref>)(<xref ref-type="bibr" rid="c48">Wood et al., 2000</xref>). <bold>F</bold>, Our model replicates the emergence of splitter cells in S2.</p></caption>
<graphic xlink:href="2407.14708v2_fig2.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>In our model, most agents can solve this task (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). As learning progresses, the length of episodic memories increases, and eventually planning of the transition from one reward state to the next is possible (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). Our model can be compared to the neural activity of the rats’ splitter cells in the hippocampus during the modified T-maze task. Our model successfully replicates the result describing splitter cells in <xref ref-type="bibr" rid="c48">Wood et al. (2000)</xref>(<xref ref-type="bibr" rid="c48">Wood et al., 2000</xref>) (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), and contextdependent neural activity is reproduced at S2 (<xref ref-type="fig" rid="fig2">Figure 2F</xref>).</p>
</sec>
<sec id="s2-1-2">
<title>Lap cells</title>
<p>The emergence of splitter cells explored above has also been studied in previous work (<xref ref-type="bibr" rid="c16">Duvelle et al., 2023</xref>; <xref ref-type="bibr" rid="c20">Hasselmo and Eichenbaum, 2005</xref>; <xref ref-type="bibr" rid="c29">Katz et al., 2007</xref>). However, preparing a temporal context in advance is generally challenging for tasks where the number of required histories is unknown or changes dynamically, because preparing too few histories results in failing to solve the tasks, while preparing too many slows down the search for a solution. Instead of preparing temporal context of fixed length in advance, our model uses remapping that adds new contextual states whenever a prediction error arises. This approach enables on-demand creation of contextual states and accelerates solution-finding in dynamically changing tasks.</p>
<p>To show the advantage of our model, we demonstrate that our model replicates the emergence of lap cells (<xref ref-type="bibr" rid="c44">Sun et al., 2020</xref>). We set up a simplified discrete environment with a loop structure where the number of laps required to receive a reward varies (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Agents are initially rewarded for the shortest transitions through environmental states S1-S2-S4. After 20 trials, the environment changes, and the agents are rewarded for one lap transition, i.e., S1-S2-S3-S2-S4. It causes remapping that splits contextual states. For example, task state S2 is discriminated into C2α and C2β based on the lap, and contextual state transitions C1-C2α-C3α-C2β-C4β emerges. After another 15 trials, the environment changes again and the agents are rewarded for two laps, i.e., S1-S2-S3-S2-S3-S2-S4, or more. This reward rule cannot be represented by the existing shortest transition, C1-C2α-C4α, or the one lap transition, C1-C2α-C3α-C2β-C4β, requiring the addition of new contextual states. Again, remapping occurs, the contextual states for the second lap are prepared, and the rewarded transition of contextual states, i.e., C1-C2α-C3α-C2β-C3β-C2γ-C4γ, is reinforced (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3</label>
<caption><title>Our model replicates the emergence of lap cells.</title>
<p><bold>A</bold>, Simplified 2-lap task diagram. Agents are rewarded for the shortest path (S1→S2→S4) for the initial 15 trials, for the 1-lap path (S1→S2→S3→S2→S4) for the next 15 trials, and for the 2 or more laps (S1→S2→S3→S2→S3→S2→S4, etc.) for the next 30 trials. <bold>B</bold>, A successful context map of our model. The state S2 and S4 are split into three contextual states, while S3 is split into two contextual states. <bold>C</bold>, The correct rate of our model. The error bar indicates the standard error of the mean (N = 40). <bold>D</bold>, The planning length gradually increases during learning, depending on the task demand. The black lines indicate the planning length of each agent, and the red line is their average. <bold>E</bold>, The comparison of lap cells in the hippocampus in the 4-lap task (<xref ref-type="bibr" rid="c44">Sun et al., 2020</xref>)(<xref ref-type="bibr" rid="c44">Sun et al., 2020</xref>) and our replicated results. <bold>F</bold>, The inhibition experiment of medial entorhinal cortex axons at CA1. ESR cells show a weak lap-specific correlation (ESR correlation) between light-on trials and light-off trials, while they show a strong spatial correlation between light-on trials and light-off trials (Left). Our model replicates the result qualitatively with the inhibition on and off (Right).</p></caption>
<graphic xlink:href="2407.14708v2_fig3.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>In our model, most agents can solve this task (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). The episodic memory used for planning changes successfully depending on the environment (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). This task is comparable with the 4- lap task for rats (<xref ref-type="bibr" rid="c44">Sun et al., 2020</xref>). In an environment where rats are rewarded for every four laps of a circuit, different hippocampal neurons fire for each lap. Our model replicates this result with the different hippocampal cells firing for different laps (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). It is also reported that the inhibition of medial entorhinal cortex axons at CA1 attenuates the lap-specific activity (i.e., event-specific rate remapping (ESR)) without much affecting spatial encoding. Our model replicates this result by blocking the synaptic transmission from most ofneurons in the context domain of X to H (<xref ref-type="fig" rid="fig3">Figure 3F</xref>).</p>
<p>This task can also be solved by simply preparing temporal contexts with three histories, which is the minimal number to solve this task. However, it takes much longer to find the correct transition for solving the 1-lap task than our model because it involves an excessive number of states (<xref ref-type="fig" rid="fig7">Figure S1</xref>).</p>
<p>This result indicates that our model, which creates contextual states on demand, can perform better than the model with a fixed-length history.</p>
</sec>
<sec id="s2-1-3">
<title>Planning in stimulus-cued dynamic environment</title>
<p>In the real world, external stimuli dynamically change, and animals make plans and derive appropriate behavior by using the external stimulus as a clue. Here, we demonstrate that our model replicates key features of stimulus-related contextual behavior and its neural activity reported in experimental studies using remapping.</p>
<p>We consider the simplified environment of <xref ref-type="bibr" rid="c17">Ekman et al. (2022)</xref> (<xref ref-type="bibr" rid="c17">Ekman et al., 2022</xref>) shown in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. In initial environment I, agents start from S0 and go to a state where one of two different external stimuli S2 or S3 is presented with different probability (p=0.8, 0.2 respectively). When it is S2, agents can get a reward at S4, whereas when it is S3, they can get a reward at S5. After 30 trials, the environment changes to II and the initial stimulus is switched to S1, not S0. In this environment, agents are rewarded at S5 and S4 when the external stimulus is S2 and S3, respectively (i.e., Reversal).</p>
<p>In such a stochastic environment, the agents need to switch transition rules according to the external stimuli after the first transition. For instance, in environment I, two rewarded transitions exist: a more likely one (C0-C2α-C4α) and a less likely one (C0-C3α-C5β) (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). When external stimuli indicate that the less likely transition has occurred, remapping in the hippocampus enables replanning of an appropriate action. As a result, the correct transition models are created for both environment I and environment II (<xref ref-type="fig" rid="fig4">Figure 4B</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4</label>
<caption><title>Our model replicates key features of human neural activity in dynamic environments.</title>
<p><bold>A</bold>, Simplified task diagram of <xref ref-type="bibr" rid="c17">Ekman et al. 2022</xref>. In environment I, agents start at S0 and move to S2 or S3 randomly (S2 for p = 0.8 and S3 for p = 0.2) and receive a reward in S4 when they come from S2 and in S5 otherwise. In environment II, agents start at S1 and move to S2 or S3 randomly (S2 for p = 0.2 and S3 for p = 0.8) and receive a reward in S5 when they come from S2 and in S4 otherwise. The environment switches between the two every 30 trials. <bold>B</bold>, A successful context map of this task. S2 and S3 are split into two contextual states, and S4 and S5 are split into four contextual states. The hippocampal connections are built for rewarded conditions only. <bold>C</bold>, The probability of choosing S4. The red/blue line shows its mean when S2/S3 is presented. The error bar indicates the standard error of the mean (N = 40). <bold>D</bold>, The planning length gradually increases over learning and converges to 3. The black lines indicate each agent’s planning length, and the red line is their average. <bold>E</bold>, The probability of generating a specific planning sequence at S0 or S1. The expected states (S2 or S3) are modulated according to the environment. <bold>F</bold>, Our model behavior is similar to the human fMRI result of <xref ref-type="bibr" rid="c17">Ekman et al. (2022)</xref>(<xref ref-type="bibr" rid="c17">Ekman et al., 2022</xref>). <bold>G</bold>, Simplified task diagram of <xref ref-type="bibr" rid="c27">Julian &amp; Doeller (2021)</xref>(<xref ref-type="bibr" rid="c27">Julian and Doeller, 2021</xref>). The training phase is the same as <bold>A</bold>, but the contextual stimuli of Square (Sq) or Circle (Ci) are initially presented and the probability of S2 and S3 is equal. In the test phase, either one of Sq, Ci or the mixture stimuli of Sq and Ci (Squircle: SC) are presented, and the agent transfers following their faith. Reward feedback is not given in the test phase. <bold>H</bold>, The transition probability under Sq context (Left) and Ci context (Right). <bold>I</bold>, The transition probability under SC context of the human patients in <xref ref-type="bibr" rid="c27">Julian &amp; Doeller (2021)</xref>(<xref ref-type="bibr" rid="c27">Julian and Doeller, 2021</xref>) (Left) and our model (Right). <bold>J</bold>, Comparison of behavioral decoding accuracy from hippocampal fMRI activity of <xref ref-type="bibr" rid="c27">Julian &amp; Doeller (2021)</xref>(<xref ref-type="bibr" rid="c27">Julian and Doeller, 2021</xref>) (Left) and hippocampal neural activity of our model (Right). Our model replicates the worse decoding accuracy in SC context (Bottom) than Sq or Ci context (Top).</p></caption>
<graphic xlink:href="2407.14708v2_fig4.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>In our model, most agents can learn to make appropriate transitions depending on the external stimuli. Importantly, they show a one-shot switch when the agents experience the same environment for the second time (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). The length of the planning sequence used in the actual transition converges to between 2 and 3 because agents reselect the correct planning sequence in case of unexpected external stimuli (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). The probability of predicted external stimuli matches well with the actual probability (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). This result replicates that of <xref ref-type="bibr" rid="c17">Ekman et al. (2022)</xref> (<xref ref-type="bibr" rid="c17">Ekman et al., 2022</xref>), who showed that the sequence generation in the human hippocampus reflects the probability of the external stimuli (<xref ref-type="fig" rid="fig4">Figure 4F</xref>).</p>
<p><xref ref-type="bibr" rid="c27">Julian and Doeller (2021)</xref> (<xref ref-type="bibr" rid="c27">Julian and Doeller, 2021</xref>) studied a similar task structure that we model here. In the training phase, external stimuli associated with the Square (Sq) or Circle (Ci) arena are presented first. Then, one of two target objects is randomly specified by S2 or S3 with equal probability. Depending on the arena type, the agents decide to transit to S4 or S5 to find it. This state transition structure is the same as <xref ref-type="fig" rid="fig4">Figure 4A</xref>. In the test phase, Sq, Ci, or their morphed version, Squircle (SC) arena, is presented. The agents transit depending on the subjective context of either Sq or Ci. Reward feedback is not given in the test phase (<xref ref-type="fig" rid="fig4">Figure 4G</xref>).</p>
<p>Our model successfully learns the context-dependent behaviors of Sq and Ci (<xref ref-type="fig" rid="fig4">Figure 4H</xref>). Additionally, our model replicates the experimental results of the mixed Sq- or Ci-like behaviors under SC (<xref ref-type="fig" rid="fig4">Figure 4I</xref>). Under SC, three reconstruction cases are observed in X: Sq context reconstruction, Ci context reconstruction, and a new contextual state generation due to X’s failure to convergence (see Materials and methods). In the last case, the agents make a random transition by recruiting new hippocampal neurons. Therefore, behavioral decoding based on hippocampal neural activity is lower than that under the Sq and Ci conditions (<xref ref-type="fig" rid="fig4">Figure 4J</xref>). This result is consistent with the findings of <xref ref-type="bibr" rid="c27">Julian and Doeller (2021)</xref>.</p>
</sec>
<sec id="s2-1-4">
<title>Prediction related to sensory processing and flexible behavior</title>
<p>Our model does not only replicate a variety of experimental results, but also make predictions. In clinical research, it has been reported that issues related to behavioral flexibility and sensory processing often co-occur in certain psychiatric conditions, including schizophrenia (SZ) (<xref ref-type="bibr" rid="c23">Javitt and Freedman, 2015</xref>) and autism spectrum disorder (ASD) (<xref ref-type="bibr" rid="c46">Watts et al., 2016</xref>). Many studies have reported that both symptoms are linked to the dysfunction of the prefrontal cortex (PFC) (<xref ref-type="bibr" rid="c28">Kaplan et al., 2016</xref>; <xref ref-type="bibr" rid="c45">Watanabe et al., 2012</xref>); however, the reasons for their cooccurrence are not yet fully understood.</p>
<p>We assume that this dysfunction corresponds to hypo-/hyper-representation of context information in X. To investigate this hypothesis, we altered the ratio of neurons in the context domain and sensory domain in X in our model. We used the same task described in <xref ref-type="fig" rid="fig4">Figure 4A</xref> with equal probability transitions to S2 and S3 (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). The agents with the standard context-stimulus ratio successfully solve this task by identifying the correct episodic sequence, whereas those with altered contextstimulus ratios fail (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). When the stimulus domain is relatively underrepresented, the correct context cannot be inferred from the given stimuli, resulting in inaccurate distinctions of different external stimuli (hallucination-like behavior) and an inability to switch back to the appropriate behavior rapidly. Associated prediction errors often generate excessive contextual states. Occasionally, multiple of them are assigned to the same hippocampal neurons, leading to ambiguity (see Materials and methods). In contrast, when the context domain is relatively underrepresented, the capacity of the Amari-Hopfield network to store distinct contexts is reduced, causing frequent failure to reconstruct the appropriate contextual state and persistent behavior under the default contextual state. Thus, our model predicts a relationship between sensory processing and behavioral flexibility.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5</label>
<caption><title>Model prediction about the relationship between sensory processing and flexible behavior.</title>
<p><bold>A</bold>, Task diagram. The structure is the same as <xref ref-type="fig" rid="fig4">Figure 4</xref>, but the probability of S2 and S3 is equal. <bold>B</bold>, The result of perturbation about the neuron ratio of stimulus domain in the cortex. (Left) We tested three stimulus neuron ratios; 2.5% for SZ, 16.7% for control and 50% for ASD. (Middle) The probability of choosing S4 is plotted for the task performance. SZ model fails to show one-shot switch for the second experience of the environment I and II, while ASD model shows an impaired task performance mainly to the environment II. (Right) The result of context calculation is plotted. The total number of context calculations is plotted in black, the number of wrong stimulus context reconstruction (hallucination-like) is plotted in green, the number of reconstruction fail (default network usage) is plotted in red, and the number of new context preparation is plotted in yellow.</p></caption>
<graphic xlink:href="2407.14708v2_fig5.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
</sec>
</sec>
<sec id="s3" sec-type="discussion">
<title>Discussion</title>
<p>In this study, we proposed a simple, model-based reinforcement learning model equipped with two functional modules: a hippocampal sequence module and a context-selection module. We introduced prediction error-based remapping as a key for generating context-dependent sequential activity in hippocampus and enabling flexible behavior. This mechanism is biologically plausible, as it is observed in the hippocampus (<xref ref-type="bibr" rid="c6">Bostock et al., 1991</xref>) and in some cortical regions (<xref ref-type="bibr" rid="c10">Castegnetti et al., 2021</xref>). Our model could simulate a variety of context-dependent sequential representations in hippocampus such as splitter cells (<xref ref-type="bibr" rid="c48">Wood et al., 2000</xref>), lap cells (<xref ref-type="bibr" rid="c44">Sun et al., 2020</xref>), probabilistic model selection (<xref ref-type="bibr" rid="c17">Ekman et al., 2022</xref>), and contextual inference (<xref ref-type="bibr" rid="c27">Julian and Doeller, 2021</xref>), without taskdependent parameter tuning. Furthermore, our model predicted a mechanistic explanation for the cooccurrence of deficits in sensory processing and flexible behavior. This result supported clinical reports that psychosis can change the attractor dynamics in the hippocampus (34) and treatments for sensory processing helped restore flexible behavior in some psychoses (<xref ref-type="bibr" rid="c3">Andelin et al., 2021</xref>; <xref ref-type="bibr" rid="c23">Javitt and Freedman, 2015</xref>; <xref ref-type="bibr" rid="c37">Pfeiffer et al., 2011</xref>). To the best of our knowledge, this is the first model that describes the formation of context-dependent hippocampal activity through remapping and its contribution to flexible behavior.</p>
<p>Although remapping is a widely known phenomenon, its mechanism remains under debate. We used the Amari-Hopfield network as the context-selection module to distinguish multiple contextual states that share the same external stimuli, and to reconstruct them via attractor dynamics from partial observations. We propose two advantages of this associative memory model. First, it can represent different contexts under the same external stimuli depending on the feedback from H to implement rapid behavioral switching without requiring synaptic changes. The second advantage is its ability to infer a contextual state using the associative memory mechanism. This property might occasionally yield a non-trivial contextual state based on past experiences. Expanding upon our model with more sophisticated associative memory search mechanisms could enable creative behavior.</p>
<p>We speculate that the context-selection module is implemented across multiple brain regions with varying degrees of resolution, including a part of the hippocampus and certain cortical regions. First, CA1 receives inputs from both CA3, which exhibits attractor dynamics reflecting sensory input, and the entorhinal cortex, which represents context information. Consequently, CA1 might calculate prediction errors between them (<xref ref-type="bibr" rid="c50">Zhao et al., 2022</xref>). Second, PFC has been reported to retain contextdependent attractors, which reflect working memory (<xref ref-type="bibr" rid="c13">D’Ardenne et al., 2012</xref>), attention (<xref ref-type="bibr" rid="c42">Siegel et al., 2015</xref>), and confidence (<xref ref-type="bibr" rid="c49">Wynn and Nyhus, 2022</xref>), and to send inputs to the hippocampus via the nucleus reuniens. In addition, the PFC computes prediction errors that might trigger remapping. Specifically, reward-related prediction errors are computed in the orbitofrontal cortex (OFC) (<xref ref-type="bibr" rid="c18">Garvert et al., 2023</xref>; <xref ref-type="bibr" rid="c43">Stalnaker et al., 2014</xref>), anterior cingulate cortex (ACC) (<xref ref-type="bibr" rid="c41">Seo and Lee, 2007</xref>) and ventromedial PFC (<xref ref-type="bibr" rid="c39">Rehbein et al., 2023</xref>), whereas stimulus-related prediction errors are calculated in the ACC (<xref ref-type="bibr" rid="c22">Ide et al., 2013</xref>) and dorsolateral PFC (<xref ref-type="bibr" rid="c34">Masina et al., 2018</xref>; <xref ref-type="bibr" rid="c51">Zmigrod et al., 2014</xref>). These neural circuits likely coordinate to estimate the current context and select the appropriate representation in the hippocampus via remapping. Our modeling of the context-selection module captures this core functionality in a simplified manner. Incorporating more elaborate features, such as multiple hierarchies (<xref ref-type="bibr" rid="c38">Rao, 2024</xref>), in future studies might help explain a broader range of experimental results.</p>
<p>To validate our model, we propose three experiments. First, our model posits that an error about the context triggers remapping. The OFC is known to be active when reward-related prediction error occurs (<xref ref-type="bibr" rid="c4">Banerjee et al., 2020</xref>), and hippocampal remapping is suggested to be induced by the entorhinal cortex, especially its lateral part (<xref ref-type="bibr" rid="c32">Latuske et al., 2017</xref>). Because a direct projection exists from the OFC to the lateral entorhinal cortex (<xref ref-type="bibr" rid="c30">Kondo and Witter, 2014</xref>), this input might critically influence hippocampal remapping. Second, our model suggests that the prediction error about the environment would induce a shift from place-cell encoding to lap-cell encoding in the hippocampus (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Third, our model proposes two types of prediction error; one is the conventional prediction error that updates the synaptic weights within the context, and the other is the prediction error about the context that triggers remapping in the cortex and the hippocampus. How these two different prediction errors are represented in neural circuits will deepen our understanding of the neural basis of flexible behavior.</p>
<p>Our model also has limitations. First, there are context-dependent tasks that our model cannot solve. Although our model learns to separate contextual states, it does not combine them; consequently, we did not consider simulating the environment in which the number of hidden states decreases over time. Greater flexibility might be achieved by integrating both sensory and contextual information within certain neurons (e.g., <xref ref-type="fig" rid="fig8">Figure S2</xref>). Second, the resolution at which our model should distinguish different contextual states is hand-tuned in this work. However, this resolution must be adjusted autonomously. Introducing hierarchical representations with multiple levels of resolution might help facilitate such adjustments. Third, our model assumed that only the hippocampus projects to the midbrain for reward prediction of sequential plans. However, there are projections from other brain regions, including the cortex, to the midbrain that are also involved in reward prediction (<xref ref-type="bibr" rid="c26">Jo and Mizumori, 2016</xref>). How these additional projections influence model-based behavior, especially in the case of hippocampal lesions, remains beyond the scope of this work. Finally, explicitly modeling the input from grid cells that encode geometric task structure (<xref ref-type="bibr" rid="c31">Krupic et al., 2015</xref>) might enable more sophisticated planning (e.g., discovering the shortest path).</p>
</sec>
<sec id="s4" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="s4-1">
<title>Simulation environment</title>
<p>We conducted all simulations and post-hoc analysis using a custom-made Python code. The source code is provided in Supplementary data.</p>
</sec>
<sec id="s4-2">
<title>Model description</title>
<sec id="s4-2-1">
<title>Overview</title>
<p>Below, we introduce a model that describes the acquisition of model-based reasoning. Our model consists of two components: the context-selection module (X) and the sequence module (H). For simplicity, agents move through discrete environmental states characterized by distinct external stimuli. The agents execute actions specified by a hippocampal sequence. To generate a sequence, the agents perform state estimation by the context-selection module and activate a corresponding hippocampal neuron. Then, this hippocampal neuron initiates sequential activity based on hippocampal synaptic connectivity. Each hippocampal sequence represents a planned course of action and is used to predict a series of external stimuli. The agents follow the plan unless remapping (see Remapping section) or exploration (see Exploration section). The hippocampal sequence from which actions are generated is updated upon a reward. As the agents become familiar with the environment, hippocampal sequences that enable future predictions to become longer, and state estimation by the context-selection module becomes less frequent. The algorithmic flow chart of our model is described in <xref ref-type="fig" rid="fig6">Figure 6</xref>.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6</label>
<caption><title>The algorithmic flow chart of the model.</title>
<p>Square boxes show the manipulation explained in Method, while the gray circles show if bifurcation with yes for ochre arrows and no for blue arrows. Synaptic weight update is indicated in the pink boxes.</p></caption>
<graphic xlink:href="2407.14708v2_fig6.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s4-2-2">
<title>Context-selection module</title>
<p>We model the context-selection module as Amari-Hopfield network (<xref ref-type="bibr" rid="c1">Amari, 1972</xref>; <xref ref-type="bibr" rid="c21">Hopfield, 1982</xref>) of <italic>N =</italic> 1200 binary neurons, whose activity is described by vector <italic>X</italic>. <italic>X</italic> consists of two domains: stimulus domain <italic>X</italic><sup>stim</sup> and context domain <italic>X</italic><sup>cont</sup>. The neuron ratio in the stimulus domain over the whole neurons dim(<italic>X</italic><sup>stim</sup>)/N is 16.7% for the control condition, 2.5% for the SZ condition, and 50% for the ASD condition. Note that dim describes the dimensions of a vector.</p>
<p>When the agents visit a task state for the first time, the <italic>X</italic>’s activity is set to
<disp-formula id="FD1">
<alternatives>
<mml:math display="block" id="M1"><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mtext>stim</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mtext>cont</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>ξ</mml:mi><mml:mrow><mml:mtext>stim</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>ξ</mml:mi><mml:mrow><mml:mtext>stim</mml:mtext></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2407.14708v2_eqn1.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.1)</label>
</disp-formula>
</p>
<p>where converter function <italic>f</italic>(<italic>ξ</italic><sup>stim</sup>) = binary(<italic>Aξ</italic><sup>stim</sup> &gt; <italic>a</italic>) returns a binary vector computed from dim (<italic>X</italic><sup>cont</sup>) by dim (<italic>X</italic><sup>stim</sup>) matrix <italic>A</italic> with independently and identically distributed unit Gaussian entries and scalar threshold a chosen so that <italic>f</italic>(<italic>ξ</italic><sup>stim</sup>) consists of half 1 and half 0 elements. This contextual state is set as a default pattern, and used in case associative memory dynamics fail to converge, as we explain below.</p>
<p>From the second visit of each task state after completing actions according to a hippocampal sequence, the contextual state is determined by associative memory dynamics of the Amari-Hopfield network to produce a hippocampal sequence. We adopt two ways of initialization: history-based and landmark based. We use the former calculation when the synaptic weights from the recently activated hippocampal neuron to have already been learned. We use the latter calculation when these weights have not been learned and the agents are at the landmark (at the initial state of the task environment in this manuscript). When these weights have not been learned and the agents are not at the landmark, which often happens after remapping (see Remapping section), a new contextual state is prepared and stored in the Amari-Hopfield network without running the associative memory dynamics (see below). The landmark-based calculation starts from the initial state of the Amari-Hopfield network
<disp-formula id="FD2">
<alternatives>
<mml:math display="block" id="M2"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mtext>init</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>ξ</mml:mi><mml:mrow><mml:mtext>stim</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtext>random</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2407.14708v2_eqn2.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.2)</label>
</disp-formula>
</p>
<p>where random indicates a random binary vector consisting of half 0 and half 1 elements. This randomness in the initial condition helps in learning a tree structure with multiple branches from the same state upon remapping. The history-based calculation starts from the initial state of the Amari-Hopfield network
<disp-formula id="FD3">
<alternatives>
<mml:math display="block" id="M3"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mtext>init</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>binary</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup><mml:mi>H</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2407.14708v2_eqn3.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.3)</label>
</disp-formula>
</p>
<p>where binary represents the indicator function that takes 1 if the argument is true and 0 otherwise, <italic>H</italic> is the binary vector of hippocampal neural activity in the previous state, and dim(<italic>X</italic>) by dim (<italic>H</italic>) matrix <italic>W<sup>XH</sup></italic> represents the synaptic weights from <italic>H</italic> to <italic>X</italic> (see Synaptic weight update section for how W<sup>XH</sup> changes).</p>
<p>Then, the contextual state is updated according to the associative memory dynamics:
<disp-formula id="FD4">
<alternatives>
<mml:math display="block" id="M4"><mml:mi>X</mml:mi><mml:mo>←</mml:mo><mml:mtext>binary</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2407.14708v2_eqn4.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.4)</label>
</disp-formula>
</p>
<p>where <italic>θ</italic> = 0.5 , <italic>X</italic><sup>0</sup> = 0.5 , and dim(<italic>X</italic>) by dim(<italic>X</italic>) matrix <italic>W<sup>XX</sup></italic> represents synaptic weights of context-selection module (see Synaptic weight update section for how <italic>W<sup>XX</sup></italic> changes). These dynamics end up either as a successful or failed recall. A recall is defined as successful if <italic>X</italic> converges within 50 iterations, and its stimulus domain <italic>X</italic><sup>stim</sup> becomes identical to <italic>ξ</italic><sup>stim</sup>. If X fails to converge within 50 iterations, the contextual state is set to the default state defined in (<xref ref-type="disp-formula" rid="FD1">eq. 1</xref>). If <italic>X</italic> converges within 50 iterations but the stimulus domain <italic>X</italic><sup>stim</sup> of the converged <italic>X</italic> is different from <italic>ξ</italic><sup>stim</sup>, agents consider the external stimuli as new stimuli, and new contextual state is prepared and stored in the Amari-Hopfield network, i.e. <italic>X</italic> is set to be a new contextual pattern <italic>X</italic> = (<italic>ξ</italic><sup>stim</sup>, random)<sup><italic>T</italic></sup> and the synaptic weights <italic>W<sup>XX</sup></italic> are updated (see Synaptic weight update section).</p>
<p>After <italic>X</italic> is set, the agents randomly generate a hippocampal sequence reflecting it (see Hippocampus section). The agents evaluate this sequence that encodes a course of actions and act according to it (see Sequence selection). This randomness in the sequence generation facilitates the exploration behavior of the agents, which is important for reinforcement learning, but also adds noise to the input from the sequence module to the context-selection module in the history-based computation. The associative memory dynamics help retrieve more appropriate contextual states both in the sensory and context domains. In addition, a successful or failed recall facilitates the production of a new context and the reuse of the default context, respectively. This difference becomes critical in explaining the SZ and ASD phenotypes.</p>
</sec>
<sec id="s4-2-3">
<title>Hippocampus</title>
<p>The hippocampus produces sequential activity probabilistically based on the contextual state computed above. Starting from the seed hippocampal neuron directly activated by the contextual state, the next hippocampal neuron is iteratively activated with a probability proportional to the synaptic weights from the previously activated hippocampal neuron. Therefore, the same contextual state could generate diverse sequences.</p>
<p>Hippocampal neurons initially receive input vector <italic>W<sup>HX</sup>X<sub>k</sub></italic>, where <italic>W<sup>HX</sup></italic> is the synaptic weight matrix from <italic>X</italic> to the hippocampus, and <italic>X<sub>k</sub></italic> is the contextual state at time step <italic>k</italic>. Only the neuron that receives the strongest input is activated, whose index is described as
<disp-formula id="FD5">
<alternatives>
<mml:math display="block" id="M5"><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext>arg max</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2407.14708v2_eqn5.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.5)</label>
</disp-formula>
</p>
<p>(see Synaptic weight update section for how <italic>W<sup>HX</sup></italic> changes), where the tilde mark indicates a neuron index.</p>
<p>Our model has two types of hippocampal neurons: state-coding and transition-coding types. The indices of neurons belonging to these types are denoted as <inline-formula id="ID1">
<alternatives>
<mml:math display="inline" id="I1"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq1.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> and <inline-formula id="ID2">
<alternatives>
<mml:math display="inline" id="I2"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq2.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, respectively. The statecoding neurons receive input from <italic>X</italic> and represent the current state, while the transition-coding neurons send output to <italic>X</italic> and indicate the next state the agents can transition. When the agents experience this contextual state <italic>X<sub>k</sub></italic> for the first time, <inline-formula id="ID3">
<alternatives>
<mml:math display="inline" id="I3"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq3.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> is randomly chosen and the synaptic weight from <inline-formula id="ID4">
<alternatives>
<mml:math display="inline" id="I4"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq4.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> to <inline-formula id="ID5">
<alternatives>
<mml:math display="inline" id="I5"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq5.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> is set to 1. From the second experience of the contextual state <italic>X<sub>k</sub></italic>, the corresponding hippocampal neuron <inline-formula id="ID6">
<alternatives>
<mml:math display="inline" id="I6"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq6.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> initiates a sequence <inline-formula id="ID7">
<alternatives>
<mml:math display="inline" id="I7"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mtext>…</mml:mtext><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq7.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> of hippocampal activity with a non-negative integer <italic>τ</italic>, where the next neuron is recursively chosen with a probability vector proportional to
<disp-formula id="FD6">
<alternatives>
<mml:math display="block" id="M6"><mml:mfrac><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msub><mml:mo>.</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msub><mml:mo>.</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0.01</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2407.14708v2_eqn6.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.6)</label>
</disp-formula>
</p>
<p>where <inline-formula id="ID8">
<alternatives>
<mml:math display="inline" id="I8"><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq8.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> describes a vector of intra-hippocampal synaptic weights from neuron <inline-formula id="ID9">
<alternatives>
<mml:math display="inline" id="I9"><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq9.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> and <italic>w</italic><sub>0</sub> = 0.3 is the effective threshold. The sequential activity can stop at a transition-coding neuron <inline-formula id="ID10">
<alternatives>
<mml:math display="inline" id="I10"><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq10.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> according to two conditions: when all the synaptic weights <inline-formula id="ID11">
<alternatives>
<mml:math display="inline" id="I11"><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>⋅</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq11.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> are equal to or below 0.01 or when the reward value function of the lastly activated transition-coding neuron <inline-formula id="ID12">
<alternatives>
<mml:math display="inline" id="I12"><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq12.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> becomes positive (see Reward prediction section).</p>
<p>Because the input source for the state-coding neuron and the transition coding neuron differ (the former is selected from <italic>X</italic>, while the latter is selected from <italic>H</italic>), the same hippocampal neuron could occasionally be used for both state-coding and transition-coding across different contextual states. This is evident when an excessive number of contextual states are prepared especially in the SZ condition. This phenomenon degrades state estimation at X (<xref ref-type="disp-formula" rid="FD3">eq.3</xref>).</p>
<p>The synaptic connection from a state-coding neuron to a transition-coding neuron is formed in a reward-independent manner as described above, whereas the connection from a transition-coding neuron to a state-coding neuron is established in a reward-dependent manner (see Synaptic Weight Update section). Consequently, when animals receive few rewards during the initial exploration phase, minimal sequences with <italic>τ</italic> = 0 are constructed. As animals discover rewarding behaviors, these minimal sequences join, and eventually, agents anticipate the rewarding transition ahead.</p>
</sec>
<sec id="s4-2-4">
<title>Reward prediction</title>
<p>Each hippocampal sequence <italic>H</italic> is associated with rewards, perhaps via the operation of the midbrain. Reward value function <inline-formula id="ID13">
<alternatives>
<mml:math display="inline" id="I13"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq13.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> which depends on the lastly activated transition-coding hippocampal neuron <inline-formula id="ID14">
<alternatives>
<mml:math display="inline" id="I14"><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq14.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> of the sequence, is updated every time the agents receive reward <italic>R</italic> &gt; 0 according to
<disp-formula id="FD7">
<alternatives>
<mml:math display="block" id="M7"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2407.14708v2_eqn7.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.7)</label>
</disp-formula>
</p>
<p>with learning rate <italic>α</italic> = 0.15. The sequence value <inline-formula id="ID15">
<alternatives>
<mml:math display="inline" id="I15"><mml:mi>S</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq15.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> associated with <inline-formula id="ID16">
<alternatives>
<mml:math display="inline" id="I16"><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq16.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> mirrors <inline-formula id="ID17">
<alternatives>
<mml:math display="inline" id="I17"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq17.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> except when it is suppressed by this neuron’s <italic>no-good</italic> indicator <inline-formula id="ID18">
<alternatives>
<mml:math display="inline" id="I18"><mml:mi>N</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq18.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> (cross marks in <xref ref-type="fig" rid="fig1">Figure 1C</xref>), namely,
<disp-formula id="FD8">
<alternatives>
<mml:math display="block" id="M8"><mml:mi>S</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>N</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mtext>binary</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2407.14708v2_eqn8.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.8)</label>
</disp-formula>
</p>
<p>where suppression threshold <italic>θ<sub>NG</sub></italic> is set to 0.7. When the <italic>no-good</italic> indicator is active, i.e., <inline-formula id="ID19">
<alternatives>
<mml:math display="inline" id="I19"><mml:mi>N</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq19.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> ≥ <italic>θ<sub>NG</sub></italic> the sequence value becomes transiently negative.</p>
<p>These neurons’ <italic>no-good</italic> indicators change when a reward is presented. The <italic>no-good</italic> indicator of the lastly activated hippocampal neuron <inline-formula id="ID20">
<alternatives>
<mml:math display="inline" id="I20"><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq20.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> instantaneously drops to 0 when the reward is greater than the reward value function, i.e., <italic>R</italic> &gt; <inline-formula id="ID21">
<alternatives>
<mml:math display="inline" id="I21"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq21.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> but instantaneously increases by 1 otherwise. In addition, the <italic>no-good</italic> indicators of all hippocampal neurons gradually decay according to
<disp-formula id="FD9">
<alternatives>
<mml:math display="block" id="M9"><mml:mi>N</mml:mi><mml:mi>G</mml:mi><mml:mo>←</mml:mo><mml:mi>γ</mml:mi><mml:mi>N</mml:mi><mml:mi>G</mml:mi></mml:math>
<graphic xlink:href="2407.14708v2_eqn9.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.9)</label>
</disp-formula>
</p>
<p>with multiplication factor <italic>γ</italic> = 0.7 when the reward is less than the reward value function, i.e., <italic>R</italic> &lt; <inline-formula id="ID22">
<alternatives>
<mml:math display="inline" id="I22"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq22.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>.</p>
</sec>
<sec id="s4-2-5">
<title>Sequence selection</title>
<p>The agents generate a contextual state and, based on it, generate a random hippocampal sequence <italic>ℌ</italic>. The transition-coding hippocampal neurons [<inline-formula id="ID23">
<alternatives>
<mml:math display="inline" id="I23"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq23.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, …, <inline-formula id="ID24">
<alternatives>
<mml:math display="inline" id="I24"><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq24.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>] in the sequence specify the series of states the agents plan to move to in the next <italic>τ</italic> steps in its task environment, unless remapping happens. Below, we describe how the agents generate multiple hippocampal sequences and choose the one to follow. The last hippocampal neuron <inline-formula id="ID25">
<alternatives>
<mml:math display="inline" id="I25"><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq25.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> of the sequence <italic>ℌ</italic> informs its sequence value <inline-formula id="ID26">
<alternatives>
<mml:math display="inline" id="I26"><mml:mi>S</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq26.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> (see Reward prediction section). When <inline-formula id="ID27">
<alternatives>
<mml:math display="inline" id="I27"><mml:mi>S</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq27.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> is positive or to test a new context, the agents execute actions according to this sequence. Otherwise, the agents reject this hippocampal sequence. In case of rejection, the agents repeat generating another hippocampal sequence (using a different random seed for the landmark-based initialization) for up to nine attempts. If none of the nine sequences have positive <inline-formula id="ID28">
<alternatives>
<mml:math display="inline" id="I28"><mml:mi>S</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq28.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, one is selected randomly, excluding that with the lowest sequence value. The agents continue a course of actions following the accepted sequence till its end unless remapping happens, and the sequence is interrupted (see Remapping section). After completing the final action specified by the sequence, the agents repeat the whole procedure in a new environmental state.</p>
</sec>
<sec id="s4-2-6">
<title>Remapping</title>
<p>Remapping can occur while the agents execute a course of actions following a hippocampal sequence. We refer to remapping as the shift of <italic>X</italic>’s activity to another contextual state or generate a new one under the same external stimuli. Upon the course of actions following hippocampal sequence <italic>ℌ</italic>, the stimulus domain ofthe input binaiy(<italic>W<sup>XH</sup>H</italic> &gt; 0) predicts the next external stimulus (without running associative memory dynamics), which may differ from the actual one, <italic>ξ</italic><sup>stim</sup>. When this happens at time <italic>k</italic> + 1, remapping occurs, and the synaptic weights from a transition-coding hippocampal neuron to state-coding hippocampal neurons are modified following the steps below.</p>
<list list-type="order">
<list-item><p>The hippocampal sequence is interrupted between the transition <inline-formula id="ID29">
<alternatives>
<mml:math display="inline" id="I29"><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>→</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq29.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, and the corresponding synaptic weight is weakened (see Synaptic weight update section).</p></list-item>
<list-item><p>If the transition-coding neuron <inline-formula id="ID30">
<alternatives>
<mml:math display="inline" id="I30"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq30.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> projects to state-coding neurons other than <inline-formula id="ID31">
<alternatives>
<mml:math display="inline" id="I31"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq31.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> these state-coding neurons’ predictions about external stimuli are examined. If there exists one that predicts the actual external stimuli with an error less than the remapping threshold of <italic>θ<sub>remap</sub></italic> = 5 <italic>bit</italic>, this neuron is activated, and the contextual state <italic>X</italic> is set based on its input (see Context-selection module section). If there is no such state-coding neuron, a new contextual state is set as <italic>X</italic> = (<italic>ξ</italic><sup>stim</sup>, random)<sup>T</sup> with the synaptic weights <italic>W<sup>XX</sup></italic> updated (see Synaptic weight update section).</p></list-item>
<list-item><p>A hippocampal neuron is activated based on the new <italic>X</italic> following (<xref ref-type="disp-formula" rid="FD5"><italic>eq.</italic> 5</xref>), and the synaptic weight is strengthened between the interrupted transition-coding hippocampal neuron <inline-formula id="ID32">
<alternatives>
<mml:math display="inline" id="I32"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq32.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> and the newly activated state-coding hippocampal neuron (see Synaptic weight update section).</p></list-item>
</list>
</sec>
<sec id="s4-2-7">
<title>Exploration</title>
<p>To gain information on the environment, the agents perform exploration. We refer to exploration as a random action not specified by the selected sequence. Exploration can occur with exploration probability <italic>p</italic> whenever the agents enter an environmental state with the number of transition candidates greater than the number of stored sequences initiating from the corresponding state-coding hippocampal neuron. The exploration probability is generally <italic>p</italic> = 0.3 but increases to certainty (<italic>p</italic> = 1) if the agents are taking actions following a sequence with a negative sequence value, which happens when its <italic>no-good</italic> indicator is active. In case of this exploration, one of the unconnected transitioncoding hippocampal neurons is randomly activated, and the agents take a random transition. Then, synaptic weights of <italic>H</italic> and <italic>X</italic> are updated (see Synaptic weight update section).</p>
</sec>
<sec id="s4-2-8">
<title>Synaptic weight update</title>
<p>We used a Hebbian learning rule to update the synaptic weight matrix <italic>W<sup>XX</sup></italic> only for the first time contextual state <italic>X</italic> is settled:
<disp-formula id="FD10">
<alternatives>
<mml:math display="block" id="M10"><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msup><mml:mo>←</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:math>
<graphic xlink:href="2407.14708v2_eqn10.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.10)</label>
</disp-formula>
</p>
<p>We also used a basic Hebbian learning rule for updating synaptic weights between <italic>X</italic> and <italic>H</italic>. Again, only for the first time a hippocampal neuron is activated according to (<italic>eq</italic>. 5) in response to contextual state <italic>X<sub>k</sub></italic>, synaptic weights are updated as
<disp-formula id="FD11">
<alternatives>
<mml:math display="block" id="M11"><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msup><mml:mo>←</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:math>
<graphic xlink:href="2407.14708v2_eqn11.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.11)</label>
</disp-formula>
<disp-formula id="FD12">
<alternatives>
<mml:math display="block" id="M12"><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup><mml:mo>←</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:math>
<graphic xlink:href="2407.14708v2_eqn12.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.12)</label>
</disp-formula>
<disp-formula id="FD13">
<alternatives>
<mml:math display="block" id="M13"><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup><mml:mo>←</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:math>
<graphic xlink:href="2407.14708v2_eqn13.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.13)</label>
</disp-formula>
</p>
<p>where <italic>H<sup>(s)</sup></italic> and <italic>H<sup>(T)</sup></italic> are the state-coding and transition-coding hippocampal activity vectors, respectively, whose elements take 1 for the activated neuron of the corresponding type and 0 for the others. Similarly, <inline-formula id="ID33">
<alternatives>
<mml:math display="inline" id="I33"><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq33.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> is the transition-coding hippocampal activity vector of the previous hippocampal sequence, where the element corresponding to the last transition-coding neuron takes 1, and others take 0. Learning rate <italic>η</italic> = (<italic>N</italic> + 1)/2 and offset <italic>X</italic><sup>1</sup> = <italic>N</italic>/(<italic>N</italic> + 1) are chosen to achieve good association dynamics in the context-selection module. These synaptic weights change within the bound <italic>W<sup>XH</sup></italic>, <italic>W<sup>HX</sup></italic> ≤ 1/2.</p>
<p>We used different learning rules for the intra-hippocampal synaptic weights depending on the coding types. The initial synaptic weights are all <italic>w</italic><sub>0</sub>, and these weights change within the bound 0 ≤ <italic>W<sup>HH</sup></italic> ≤ 1. State-coding to transition-coding synapses are constantly updated when <inline-formula id="ID34">
<alternatives>
<mml:math display="inline" id="I34"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq34.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> and <inline-formula id="ID35">
<alternatives>
<mml:math display="inline" id="I35"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq35.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> are activated as
<disp-formula id="FD14">
<alternatives>
<mml:math display="block" id="M14"><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup><mml:mo>←</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>H</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn><mml:mi>α</mml:mi><mml:msubsup><mml:mi>H</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>H</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mtext>binary</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2407.14708v2_eqn14.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.14)</label>
</disp-formula>
</p>
<p>The second term describes Hebbian potentiation, and the third term describes hetero-synaptic depression between non-active presynaptic neurons and the active postsynaptic neuron. Note that we assume hetero-synaptic depression only upon the initial establishment of the synaptic connection between the two hippocampal neurons. Transition-coding to state-coding synapses involved in <italic>ℌ</italic> are constantly updated when the agents receive reward (<italic>R</italic> &gt; 0) and <inline-formula id="ID36">
<alternatives>
<mml:math display="inline" id="I36"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq36.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> and <inline-formula id="ID37">
<alternatives>
<mml:math display="inline" id="I37"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq37.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> are involved in <italic>ℌ</italic> according to
<disp-formula id="FD15">
<alternatives>
<mml:math display="block" id="M15"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup><mml:mo>←</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn><mml:mi>α</mml:mi><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>H</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>binary</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2407.14708v2_eqn15.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.15)</label>
</disp-formula>
</p>
<p>The second term describes Hebbian potentiation that modifies the weight <inline-formula id="ID38">
<alternatives>
<mml:math display="inline" id="I38"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msub></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq38.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> toward <italic>R</italic> − <italic>w</italic><sub>0</sub>, and the third term describes hetero-synaptic depression.</p>
<p>In addition, if remapping happens at the sequence location between <inline-formula id="ID39">
<alternatives>
<mml:math display="inline" id="I39"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq39.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> and <inline-formula id="ID40">
<alternatives>
<mml:math display="inline" id="I40"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq40.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, the synaptic weight from <inline-formula id="ID41">
<alternatives>
<mml:math display="inline" id="I41"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq41.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> to <inline-formula id="ID42">
<alternatives>
<mml:math display="inline" id="I42"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq42.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> is weakened by −<italic>α</italic><inline-formula id="ID43">
<alternatives>
<mml:math display="inline" id="I43"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msub></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq43.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, while that from <inline-formula id="ID44">
<alternatives>
<mml:math display="inline" id="I44"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq44.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> to the activated state-coding hippocampal neurons <inline-formula id="ID45">
<alternatives>
<mml:math display="inline" id="I45"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq45.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> is strengthened by <italic>α</italic>(0.65 − <inline-formula id="ID46">
<alternatives>
<mml:math display="inline" id="I46"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msub></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq46.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>) binary(<inline-formula id="ID47">
<alternatives>
<mml:math display="inline" id="I47"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msub></mml:mrow></mml:math>
<inline-graphic xlink:href="2407.14708v2_ieq47.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> &lt; 0.65).</p>
<p>Considering the memory capacity ofthe Amari-Hopfield Network with correlated patterns, the number of memorizable contextual states sharing the same external stimulus is below 8. If this condition is violated, to prevent overloading the Amari-Hopfield network, the contextual state <italic>X</italic> that has never produced hippocampal sequences with a sequence value more than 0.7 induces a forgetting process as
<disp-formula id="FD16">
<alternatives>
<mml:math display="block" id="M16"><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msup><mml:mo>←</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:math>
<graphic xlink:href="2407.14708v2_eqn16.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.16)</label>
</disp-formula>
</p>
<p>This process represents forgetting of reward-unrelated episodic memory.</p>
</sec>
<sec id="s4-2-9">
<title>Model-free learning with temporal contexts</title>
<p>To highlight the advantage of our model, we compared it to the Q-learning with temporal contexts, namely, the state is defined by the recent transition history of task state. The number of histories is changed from 0 to 3. In the Q-learning, the action value for a temporal state <italic>s<sub>t</sub></italic> to the next <italic>s<sub>t+1</sub></italic> is updated as
<disp-formula id="FD17">
<alternatives>
<mml:math display="block" id="M17"><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:munder><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2407.14708v2_eqn17.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.17)</label>
</disp-formula>
</p>
<p>where the initial Q value is 0, learning rate <italic>α</italic> = 0.4 , the discount factor <italic>γ</italic> = 0.6 and the taskdependent reward function <italic>R</italic> = 100 for the rewarded transition and <italic>R</italic> = 1 for else. Next state selection policy <italic>π</italic> is set to be proportional to Q value as
<disp-formula id="FD18">
<alternatives>
<mml:math display="block" id="M18"><mml:mi>π</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>∞</mml:mi><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2407.14708v2_eqn18.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(eq.18)</label>
</disp-formula>
</p>
</sec>
<sec id="s4-2-10">
<title>Inhibition experiment</title>
<p>To replicate the inhibition experiment of medial entorhinal cortex axons at CA1, we inhibit 98.5% of the input from the context domain of <italic>X</italic> to <italic>H</italic>. After the 2-lap task in <xref ref-type="fig" rid="fig3">Figure 3</xref>, we observed the hippocampal activity responding to each contextual state with or without this inhibition. ESR correlation is calculated based on the hippocampal activity of each lap, while the spatial correlation is calculated based on that of space. To avoid nan value when calculating correlations, we assumed that the activity of hippocampal cells without firing would have a random spontaneous activity between 0 and 0.1. Note that this operation does not significantly affect the result.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure S1</label>
<caption><title>Simplified 2-lap task with model-free learning with temporal contextual states.</title>
<p>The contextual states are defined by the composition of the current state and n back states. It requires at least 3 back states to complete this task, but the correct rate of 3 back states is worse than our model.</p></caption>
<graphic xlink:href="2407.14708v2_fig7.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure S2</label>
<caption><title>Reward-dependent plasticity when sensory and contextual encoding neurons coexist in hippocampus.</title>
<p><bold>A</bold>, Schematic figure of how sensory and contextual encoding neurons can coexist in the hippocampus. Hippocampal neurons that receive synaptic input mainly from the stimulus-encoding region have sensory encoding, while those from the context-encoding region have contextual encoding. <bold>B</bold>, How the hippocampal network evolves when sensory and contextual encoding neurons coexist in the 1- round task. This task requires contextual encoding, otherwise agents cannot distinguish between the first and second visit of S2. After 100 trials of random exploration in this area, the network between sensory encoding hippocampal neurons (indicated by the orange square) does not increase synaptic weights, while that between relevant context-encoding hippocampal neurons increases synaptic weights. <bold>c</bold>, How the hippocampal network evolves when sensory and contextual encoding neurons coexist in the ignore task. In this task, contextual encoding is not necessary because agents receive a reward at S4 independent of past states or latent variables. In contrast to the 1-round task, the network between sensory encoding hippocampal neurons (indicated by the orange square) increases the synaptic weights as well as that between context encoding hippocampal neurons.</p></caption>
<graphic xlink:href="2407.14708v2_fig8.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
</sec>
</sec>
</body>
<back>
<sec id="s5" sec-type="data-availability">
<title>Data and materials availability:</title>
<p>All data needed to evaluate the conclusions in the paper are present in the paper and/or the Supplementary Materials. All source code is provided in <ext-link ext-link-type="uri" xlink:href="https://github.com/toppo365/flexiblemodel.git">https://github.com/toppo365/flexiblemodel.git</ext-link>.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p><bold>Funding:</bold> The study was supported by RIKEN Center for Brain Science, the JST CREST program JPMJCR23N2, and RIKEN TRIP initiative (RIKEN Quantum).</p>
</ack>
<sec id="nt1">
<title>Note</title>
<p>This reviewed preprint has been updated to add details for a corresponding author.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Amari</surname> <given-names>S</given-names></string-name></person-group>. <year>1972</year>. <article-title>Learning patterns and pattern sequences by self-organizing nets of threshold elements</article-title>. <source>IEEE Trans Comput</source> <volume>C-21</volume>:<fpage>1197</fpage>–<lpage>1206</lpage>. doi:<pub-id pub-id-type="doi">10.1109/T-C.1972.223477</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ambrose</surname> <given-names>RE</given-names></string-name>, <string-name><surname>Pfeiffer</surname> <given-names>BE</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>DJ</given-names></string-name></person-group>. <year>2016</year>. <article-title>Reverse replay of hippocampal place cells is uniquely modulated by changing reward</article-title>. <source>Neuron</source> <volume>91</volume>:<fpage>1124</fpage>–<lpage>1136</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2016.07.047</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Andelin</surname> <given-names>L</given-names></string-name>, <string-name><surname>Reynolds</surname> <given-names>S</given-names></string-name>, <string-name><surname>Schoen</surname> <given-names>S</given-names></string-name></person-group>. <year>2021</year>. <article-title>Effectiveness of Occupational Therapy Using a Sensory Integration Approach: A Multiple-Baseline Design Study</article-title>. <source>Am J Occup Ther</source> <volume>75</volume>. doi:<pub-id pub-id-type="doi">10.5014/ajot.2021.044917</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Banerjee</surname> <given-names>A</given-names></string-name>, <string-name><surname>Parente</surname> <given-names>G</given-names></string-name>, <string-name><surname>Teutsch</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lewis</surname> <given-names>C</given-names></string-name>, <string-name><surname>Voigt</surname> <given-names>FF</given-names></string-name>, <string-name><surname>Helmchen</surname> <given-names>F</given-names></string-name></person-group>. <year>2020</year>. <article-title>Value-guided remapping of sensory cortex by lateral orbitofrontal cortex</article-title>. <source>Nature</source> <volume>585</volume>:<fpage>245</fpage>–<lpage>250</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41586-020-2704-z</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barnett</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>O’Neil</surname> <given-names>EB</given-names></string-name>, <string-name><surname>Watson</surname> <given-names>HC</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>ACH</given-names></string-name></person-group>. <year>2014</year>. <article-title>The human hippocampus is sensitive to the durations of events and intervals within a sequence</article-title>. <source>Neuropsychologia</source> <volume>64</volume>:<fpage>1</fpage>–<lpage>12</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2014.09.011</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bostock</surname> <given-names>E</given-names></string-name>, <string-name><surname>Muller</surname> <given-names>RU</given-names></string-name>, <string-name><surname>Kubie</surname> <given-names>JL</given-names></string-name></person-group>. <year>1991</year>. <article-title>Experience-dependent modifications of hippocampal place cell firing</article-title>. <source>Hippocampus</source> <volume>1</volume>:<fpage>193</fpage>–<lpage>205</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hipo.450010207</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burgess</surname> <given-names>N</given-names></string-name>, <string-name><surname>Maguire</surname> <given-names>EA</given-names></string-name>, <string-name><surname>O’Keefe</surname> <given-names>J</given-names></string-name></person-group>. <year>2002</year>. <article-title>The human hippocampus and spatial and episodic memory</article-title>. <source>Neuron</source> <volume>35</volume>:<fpage>625</fpage>–<lpage>641</lpage>. doi:<pub-id pub-id-type="doi">10.1016/s0896-6273(02)00830-9</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buzsáki</surname> <given-names>G</given-names></string-name>, <string-name><surname>Tingley</surname> <given-names>D</given-names></string-name></person-group>. <year>2018</year>. <article-title>Space and Time: The Hippocampus as a Sequence Generator</article-title>. <source>Trends Cogn Sci</source> <volume>22</volume>:<fpage>853</fpage>–<lpage>869</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2018.07.006</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carr</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Jadhav</surname> <given-names>SP</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>L</given-names></string-name></person-group>. <year>2011</year>. <article-title>Hippocampal replay in the awake state: a potential substrate for memory consolidation and retrieval</article-title>. <source>Nat Neurosci</source> <volume>14</volume>:<fpage>147</fpage>–<lpage>153</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2732</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Castegnetti</surname> <given-names>G</given-names></string-name>, <string-name><surname>Zurita</surname> <given-names>M</given-names></string-name>, <string-name><surname>De Martino</surname> <given-names>B</given-names></string-name></person-group>. <year>2021</year>. <article-title>How usefulness shapes neural representations during goal-directed behavior</article-title>. <source>Sci Adv</source> <volume>7</volume>. doi:<pub-id pub-id-type="doi">10.1126/sciadv.abd5363</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cone</surname> <given-names>I</given-names></string-name>, <string-name><surname>Clopath</surname> <given-names>C</given-names></string-name></person-group>. <year>2024</year>. <article-title>Latent representations in hippocampal network model co-evolve with behavioral exploration of task structure</article-title>. <source>Nat Commun</source> <volume>15</volume>:<fpage>687</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-024-44871-6</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Coulom</surname> <given-names>R</given-names></string-name></person-group>. <year>2007</year>. <source>Efficient selectivity and backup operators in Monte-Carlo tree searchComputers and Games, Lecture Notes in Computer Science</source>. <publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer Berlin Heidelberg</publisher-name>. pp. <fpage>72</fpage>–<lpage>83</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-540-75538-8_7</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>D’Ardenne</surname> <given-names>K</given-names></string-name>, <string-name><surname>Eshel</surname> <given-names>N</given-names></string-name>, <string-name><surname>Luka</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lenartowicz</surname> <given-names>A</given-names></string-name>, <string-name><surname>Nystrom</surname> <given-names>LE</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>JD</given-names></string-name></person-group>. <year>2012</year>. <article-title>Role of prefrontal cortex and the midbrain dopamine system in working memory updating</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>109</volume>:<fpage>19900</fpage>–<lpage>19909</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1116727109</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Davidson</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Kloosterman</surname> <given-names>F</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name></person-group>. <year>2009</year>. <article-title>Hippocampal replay of extended experience</article-title>. <source>Neuron</source> <volume>63</volume>:<fpage>497</fpage>–<lpage>507</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.027</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Dudchenko</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Wood</surname> <given-names>ER</given-names></string-name></person-group>. <year>2014</year>. <chapter-title>Splitter Cells: Hippocampal Place Cells Whose Firing Is Modulated by Where the Animal Is Going or Where It Has Been</chapter-title> In: <person-group person-group-type="editor"><string-name><surname>Derdikman</surname> <given-names>D</given-names></string-name>, <string-name><surname>Knierim</surname> <given-names>JJ</given-names></string-name></person-group>. <source>Space,Time and Memory in the Hippocampal Formation</source>. <publisher-loc>Vienna</publisher-loc>: <publisher-name>Springer Vienna</publisher-name>. pp. <fpage>253</fpage>–<lpage>272</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-7091-1292-2_10</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Duvelle</surname> <given-names>É</given-names></string-name>, <string-name><surname>Grieves</surname> <given-names>RM</given-names></string-name>, <string-name><surname>van der Meer</surname> <given-names>MAA</given-names></string-name></person-group>. <year>2023</year>. <article-title>Temporal context and latent state inference in the hippocampal splitter signal</article-title>. <source>eLife</source> <volume>12</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.82357</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Ekman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gennari</surname> <given-names>G</given-names></string-name>, <string-name><surname>de Lange</surname> <given-names>FP</given-names></string-name></person-group>. <year>2022</year>. <article-title>Probabilistic forward replay of anticipated stimulus sequences in human primary visual cortex and hippocampus</article-title>. <source>bioRxiv</source>. doi:<pub-id pub-id-type="doi">10.1101/2022.01.26.477907</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garvert</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Saanum</surname> <given-names>T</given-names></string-name>, <string-name><surname>Schulz</surname> <given-names>E</given-names></string-name>, <string-name><surname>Schuck</surname> <given-names>NW</given-names></string-name>, <string-name><surname>Doeller</surname> <given-names>CF</given-names></string-name></person-group>. <year>2023</year>. <article-title>Hippocampal spatio-predictive cognitive maps adaptively guide reward generalization</article-title>. <source>Nat Neurosci</source> <volume>26</volume>:<fpage>615</fpage>–<lpage>626</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-023-01283-x</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>George</surname> <given-names>D</given-names></string-name>, <string-name><surname>Rikhye</surname> <given-names>RV</given-names></string-name>, <string-name><surname>Gothoskar</surname> <given-names>N</given-names></string-name>, <string-name><surname>Guntupalli</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Dedieu</surname> <given-names>A</given-names></string-name>, <string-name><surname>Lázaro-Gredilla</surname> <given-names>M</given-names></string-name></person-group>. <year>2021</year>. <article-title>Clonestructured graph representations enable flexible learning and vicarious evaluation of cognitive maps</article-title>. <source>Nat Commun</source> <volume>12</volume>:<fpage>2392</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-021-22559-5</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hasselmo</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Eichenbaum</surname> <given-names>H</given-names></string-name></person-group>. <year>2005</year>. <article-title>Hippocampal mechanisms for the context-dependent retrieval of episodes</article-title>. <source>Neural Netw</source> <volume>18</volume>:<fpage>1172</fpage>–<lpage>1190</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neunet.2005.08.007</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hopfield</surname> <given-names>JJ</given-names></string-name></person-group>. <year>1982</year>. <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>79</volume>:<fpage>2554</fpage>–<lpage>2558</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.79.8.2554</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ide</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>P</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Li</surname> <given-names>C-SR</given-names></string-name></person-group>. <year>2013</year>. <article-title>Bayesian prediction and evaluation in the anterior cingulate cortex</article-title>. <source>J Neurosci</source> <volume>33</volume>:<fpage>2039</fpage>–<lpage>2047</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2201-12.2013</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Javitt</surname> <given-names>DC</given-names></string-name>, <string-name><surname>Freedman</surname> <given-names>R</given-names></string-name></person-group>. <year>2015</year>. <article-title>Sensory processing dysfunction in the personal experience and neuronal machinery of schizophrenia</article-title>. <source>Am J Psychiatry</source> <volume>172</volume>:<fpage>17</fpage>–<lpage>31</lpage>. doi:<pub-id pub-id-type="doi">10.1176/appi.ajp.2014.13121691</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jeffery</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Gilbert</surname> <given-names>A</given-names></string-name>, <string-name><surname>Burton</surname> <given-names>S</given-names></string-name>, <string-name><surname>Strudwick</surname> <given-names>A</given-names></string-name></person-group>. <year>2003</year>. <article-title>Preserved performance in a hippocampal-dependent spatial task despite complete place cell remapping</article-title>. <source>Hippocampus</source> <volume>13</volume>:<fpage>175</fpage>–<lpage>189</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hipo.10047</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jensen</surname> <given-names>KT</given-names></string-name>, <string-name><surname>Hennequin</surname> <given-names>G</given-names></string-name>, <string-name><surname>Mattar</surname> <given-names>M</given-names></string-name></person-group>. <year>2024</year>. <article-title>A recurrent network model of planning explains hippocampal replay and human behavior</article-title>. <source>Nature Neuroscience</source> <volume>27</volume>:<fpage>1340</fpage>–<lpage>1348</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-024-01675-7</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jo</surname> <given-names>YS</given-names></string-name>, <string-name><surname>Mizumori</surname> <given-names>SJY</given-names></string-name></person-group>. <year>2016</year>. <article-title>Prefrontal Regulation of Neuronal Activity in the Ventral Tegmental Area</article-title>. <source>Cereb Cortex</source> <volume>26</volume>:<fpage>4057</fpage>–<lpage>4068</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhv215</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Julian</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Doeller</surname> <given-names>CF</given-names></string-name></person-group>. <year>2021</year>. <article-title>Remapping and realignment in the human hippocampal formation predict context-dependent spatial behavior</article-title>. <source>Nat Neurosci</source> <volume>24</volume>:<fpage>863</fpage>–<lpage>872</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-021-00835-3</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kaplan</surname> <given-names>CM</given-names></string-name>, <string-name><surname>Saha</surname> <given-names>D</given-names></string-name>, <string-name><surname>Molina</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Hockeimer</surname> <given-names>WD</given-names></string-name>, <string-name><surname>Postell</surname> <given-names>EM</given-names></string-name>, <string-name><surname>Apud</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Weinberger</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Tan</surname> <given-names>HY</given-names></string-name></person-group>. <year>2016</year>. <article-title>Estimating changing contexts in schizophrenia</article-title>. <source>Brain</source> <volume>139</volume>:<fpage>2082</fpage>–<lpage>2095</lpage>. doi:<pub-id pub-id-type="doi">10.1093/brain/aww095</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katz</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Kath</surname> <given-names>WL</given-names></string-name>, <string-name><surname>Spruston</surname> <given-names>N</given-names></string-name>, <string-name><surname>Hasselmo</surname> <given-names>ME</given-names></string-name></person-group>. <year>2007</year>. <article-title>Coincidence detection of place and temporal context in a network model of spiking hippocampal neurons</article-title>. <source>PLoS Comput Biol</source> <volume>3</volume>:<elocation-id>e234</elocation-id>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.0030234</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kondo</surname> <given-names>H</given-names></string-name>, <string-name><surname>Witter</surname> <given-names>MP</given-names></string-name></person-group>. <year>2014</year>. <article-title>Topographic organization of orbitofrontal projections to the parahippocampal region in rats</article-title>. <source>J Comp Neurol</source> <volume>522</volume>:<fpage>772</fpage>–<lpage>793</lpage>. doi:<pub-id pub-id-type="doi">10.1002/cne.23442</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krupic</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bauza</surname> <given-names>M</given-names></string-name>, <string-name><surname>Burton</surname> <given-names>S</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name>, <string-name><surname>O’Keefe</surname> <given-names>J</given-names></string-name></person-group>. <year>2015</year>. <article-title>Grid cell symmetry is shaped by environmental geometry</article-title>. <source>Nature</source> <volume>518</volume>:<fpage>232</fpage>–<lpage>235</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature14153</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Latuske</surname> <given-names>P</given-names></string-name>, <string-name><surname>Kornienko</surname> <given-names>O</given-names></string-name>, <string-name><surname>Kohler</surname> <given-names>L</given-names></string-name>, <string-name><surname>Allen</surname> <given-names>K</given-names></string-name></person-group>. <year>2017</year>. <article-title>Hippocampal Remapping and Its Entorhinal Origin</article-title>. <source>Front Behav Neurosci</source> <volume>11</volume>:<fpage>253</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnbeh.2017.00253</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Low</surname> <given-names>IIC</given-names></string-name>, <string-name><surname>Giocomo</surname> <given-names>LM</given-names></string-name>, <string-name><surname>Williams</surname> <given-names>AH</given-names></string-name></person-group>. <year>2023</year>. <article-title>Remapping in a recurrent neural network model of navigation and context inference</article-title>. <source>eLife</source> <volume>12</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.86943</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masina</surname> <given-names>F</given-names></string-name>, <string-name><surname>Vallesi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Di Rosa</surname> <given-names>E</given-names></string-name>, <string-name><surname>Semenzato</surname> <given-names>L</given-names></string-name>, <string-name><surname>Mapelli</surname> <given-names>D</given-names></string-name></person-group>. <year>2018</year>. <article-title>Possible Role of Dorsolateral Prefrontal Cortex in Error Awareness: Single-Pulse TMS Evidence</article-title>. <source>Front Neurosci</source> <volume>12</volume>:<fpage>179</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnins.2018.00179</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ólafsdóttir</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Bush</surname> <given-names>D</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name></person-group>. <year>2018</year>. <article-title>The Role of Hippocampal Replay in Memory and Planning</article-title>. <source>Curr Biol</source> <volume>28</volume>:<fpage>R37</fpage>–<lpage>R50</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2017.10.073</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pettersen</surname> <given-names>M</given-names></string-name>, <string-name><surname>Rogge</surname> <given-names>F</given-names></string-name>, <string-name><surname>Lepperød</surname> <given-names>M</given-names></string-name></person-group>. <year>2024</year>. <article-title>Learning place cell representations and context-dependent remapping</article-title>. <source>Neural Inf Process Syst</source>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pfeiffer</surname> <given-names>BA</given-names></string-name>, <string-name><surname>Koenig</surname> <given-names>K</given-names></string-name>, <string-name><surname>Kinnealey</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sheppard</surname> <given-names>M</given-names></string-name>, <string-name><surname>Henderson</surname> <given-names>L</given-names></string-name></person-group>. <year>2011</year>. <article-title>Effectiveness of sensory integration interventions in children with autism spectrum disorders: a pilot study</article-title>. <source>Am J Occup Ther</source> <volume>65</volume>:<fpage>76</fpage>–<lpage>85</lpage>. doi:<pub-id pub-id-type="doi">10.5014/ajot.2011.09205</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname> <given-names>RPN</given-names></string-name></person-group>. <year>2024</year>. <article-title>A sensory-motor theory of the neocortex</article-title>. <source>Nat Neurosci</source>. doi:<pub-id pub-id-type="doi">10.1038/s41593-024-01673-9</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rehbein</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Kroker</surname> <given-names>T</given-names></string-name>, <string-name><surname>Winker</surname> <given-names>C</given-names></string-name>, <string-name><surname>Ziehfreund</surname> <given-names>L</given-names></string-name>, <string-name><surname>Reschke</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bölte</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wyczesany</surname> <given-names>M</given-names></string-name>, <string-name><surname>Roesmann</surname> <given-names>K</given-names></string-name>, <string-name><surname>Wessing</surname> <given-names>I</given-names></string-name>, <string-name><surname>Junghöfer</surname> <given-names>M</given-names></string-name></person-group>. <year>2023</year>. <article-title>Non-invasive stimulation reveals ventromedial prefrontal cortex function in reward prediction and reward processing</article-title>. <source>Front Neurosci</source> <volume>17</volume>:<fpage>1219029</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnins.2023.1219029</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sanders</surname> <given-names>H</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Gershman</surname> <given-names>SJ</given-names></string-name></person-group>. <year>2020</year>. <article-title>Hippocampal remapping as hidden state inference</article-title>. <source>eLife</source> <volume>9</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.51140</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seo</surname> <given-names>H</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>D</given-names></string-name></person-group>. <year>2007</year>. <article-title>Temporal filtering of reward signals in the dorsal anterior cingulate cortex during a mixed-strategy game</article-title>. <source>J Neurosci</source> <volume>27</volume>:<fpage>8366</fpage>–<lpage>8377</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2369-07.2007</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Siegel</surname> <given-names>M</given-names></string-name>, <string-name><surname>Buschman</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>EK</given-names></string-name></person-group>. <year>2015</year>. <article-title>Cortical information flow during flexible sensorimotor decisions</article-title>. <source>Science</source> <volume>348</volume>:<fpage>1352</fpage>–<lpage>1355</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.aab0551</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stalnaker</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Cooch</surname> <given-names>NK</given-names></string-name>, <string-name><surname>McDannald</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>T-L</given-names></string-name>, <string-name><surname>Wied</surname> <given-names>H</given-names></string-name>, <string-name><surname>Schoenbaum</surname> <given-names>G</given-names></string-name></person-group>. <year>2014</year>. <article-title>Orbitofrontal neurons infer the value and identity of predicted outcomes</article-title>. <source>Nat Commun</source> <volume>5</volume>:<fpage>3926</fpage>. doi:<pub-id pub-id-type="doi">10.1038/ncomms4926</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname> <given-names>C</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>W</given-names></string-name>, <string-name><surname>Martin</surname> <given-names>J</given-names></string-name>, <string-name><surname>Tonegawa</surname> <given-names>S</given-names></string-name></person-group>. <year>2020</year>. <article-title>Hippocampal neurons represent events as transferable units of experience</article-title>. <source>Nat Neurosci</source> <volume>23</volume>:<fpage>651</fpage>–<lpage>663</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-020-0614-x</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Watanabe</surname> <given-names>T</given-names></string-name>, <string-name><surname>Yahata</surname> <given-names>N</given-names></string-name>, <string-name><surname>Abe</surname> <given-names>O</given-names></string-name>, <string-name><surname>Kuwabara</surname> <given-names>H</given-names></string-name>, <string-name><surname>Inoue</surname> <given-names>H</given-names></string-name>, <string-name><surname>Takano</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Iwashiro</surname> <given-names>N</given-names></string-name>, <string-name><surname>Natsubori</surname> <given-names>T</given-names></string-name>, <string-name><surname>Aoki</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Takao</surname> <given-names>H</given-names></string-name>, <string-name><surname>Sasaki</surname> <given-names>H</given-names></string-name>, <string-name><surname>Gonoi</surname> <given-names>W</given-names></string-name>, <string-name><surname>Murakami</surname> <given-names>M</given-names></string-name>, <string-name><surname>Katsura</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kunimatsu</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kawakubo</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Matsuzaki</surname> <given-names>H</given-names></string-name>, <string-name><surname>Tsuchiya</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Kato</surname> <given-names>N</given-names></string-name>, <string-name><surname>Kano</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Miyashita</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Kasai</surname> <given-names>K</given-names></string-name>, <string-name><surname>Yamasue</surname> <given-names>H</given-names></string-name></person-group>. <year>2012</year>. <article-title>Diminished medial prefrontal activity behind autistic social judgments of incongruent information</article-title>. <source>PLoS One</source> <volume>7</volume>:<elocation-id>e39561</elocation-id>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0039561</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Watts</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Rodgers</surname> <given-names>J</given-names></string-name>, <string-name><surname>Riby</surname> <given-names>D</given-names></string-name></person-group>. <year>2016</year>. <article-title>A Systematic Review of the Evidence for Hyporesponsivity in ASD</article-title>. <source>Review Journal of Autism and Developmental Disorders</source> <volume>3</volume>:<fpage>286</fpage>–<lpage>301</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s40489-016-0084-y</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Whittington</surname> <given-names>JCR</given-names></string-name>, <string-name><surname>Muller</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Mark</surname> <given-names>S</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>G</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name>, <string-name><surname>Burgess</surname> <given-names>N</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name></person-group>. <year>2020</year>. <article-title>The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation</article-title>. <source>Cell</source> <volume>183</volume>:<fpage>1249</fpage>–<lpage>1263</lpage>.<elocation-id>e23</elocation-id>. doi:<pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wood</surname> <given-names>ER</given-names></string-name>, <string-name><surname>Dudchenko</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Robitsek</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Eichenbaum</surname> <given-names>H</given-names></string-name></person-group>. <year>2000</year>. <article-title>Hippocampal neurons encode information about different types of memory episodes occurring in the same location</article-title>. <source>Neuron</source> <volume>27</volume>:<fpage>623</fpage>–<lpage>633</lpage>. doi:<pub-id pub-id-type="doi">10.1016/s0896-6273(00)00071-4</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wynn</surname> <given-names>SC</given-names></string-name>, <string-name><surname>Nyhus</surname> <given-names>E</given-names></string-name></person-group>. <year>2022</year>. <article-title>Brain activity patterns underlying memory confidence</article-title>. <source>Eur J Neurosci</source> <volume>55</volume>:<fpage>1774</fpage>–<lpage>1797</lpage>. doi:<pub-id pub-id-type="doi">10.1111/ejn.15649</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname> <given-names>X</given-names></string-name>, <string-name><surname>Hsu</surname> <given-names>C-L</given-names></string-name>, <string-name><surname>Spruston</surname> <given-names>N</given-names></string-name></person-group>. <year>2022</year>. <article-title>Rapid synaptic plasticity contributes to a learned conjunctive code of position and choice-related information in the hippocampus</article-title>. <source>Neuron</source> <volume>110</volume>:<fpage>96</fpage>–<lpage>108</lpage>.<elocation-id>e4</elocation-id>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2021.10.003</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zmigrod</surname> <given-names>S</given-names></string-name>, <string-name><surname>Colzato</surname> <given-names>LS</given-names></string-name>, <string-name><surname>Hommel</surname> <given-names>B</given-names></string-name></person-group>. <year>2014</year>. <article-title>Evidence for a role of the right dorsolateral prefrontal cortex in controlling stimulus-response integration: a transcranial direct current stimulation (tDCS) study</article-title>. <source>Brain Stimul</source> <volume>7</volume>:<fpage>516</fpage>–<lpage>520</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.brs.2014.03.004</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106506.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Bhalla</surname>
<given-names>Upinder S</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Centre for Biological Sciences</institution>
</institution-wrap>
<city>Bangalore</city>
<country>India</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This is a potentially <bold>valuable</bold> modeling study on sequence generation in the hippocampus in a variety of behavioral contexts. While the scope of the model is ambitious, its presentation is <bold>incomplete</bold> and would benefit from substantially more methodological clarity and better biological justification. The work will interest the broad community of researchers studying cortical-hippocampal interactions and sequences.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106506.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The manuscript by Ito and Toyozumi proposes a new model for biologically plausible learning of context-dependent sequence generation, which aims to overcome the predefined contextual time horizon of previous proposals. The model includes two interacting models: an Amari-Hopfield network that infers context based on sensory cues, with new contexts stored whenever sensory predictions (generated by a second hippocampal module) deviate substantially from actual sensory experience, which then leads to hippocampal remapping. The hippocampal predictions themselves are context-dependent and sequential, relying on two functionally distinct neural subpopulations. On top of this state representation, a simple Rescola-Wagner-type rule is used to generate predictions for expected reward and to guide actions. A collection of different Hebbian learning rules at different synaptic subsets of this circuit (some reward-modulated, some purely associative, with occasional additional homeostatic competitive heterosynaptic plasticity) enables this circuit to learn state representations in a set of simple tasks known to elicit context-dependent effects.</p>
<p>Strengths:</p>
<p>The idea of developing a circuit-level model of model-based reinforcement learning, even if only for simple scenarios, is definitely of interest to the community. The model is novel and aims to explain a range of context-dependent effects in the remapping of hippocampal activity.</p>
<p>Weaknesses:</p>
<p>The link to model-based RL is formally imprecise, and the circuit-level description of the process is too algorithmic (and sometimes discrepant with known properties of hippocampus responses), so the model ends up falling in between in a way that does not fully satisfy either the computational or the biological promise. Some of the problems stem from the lack of detail and biological justification in the writing, but the loose link to biology is likely not fully addressable within the scope of the current results. The attempt at linking poor functioning of the context circuit to disease is particularly tenuous.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106506.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Ito and Toyoizumi present a computational model of context-dependent action selection. They propose a &quot;hippocampus&quot; network that learns sequences based on which the agent chooses actions. The hippocampus network receives both stimulus and context information from an attractor network that learns new contexts based on experience. The model is consistent with a variety of experiments, both from the rodent and the human literature, such as splitter cells, lap cells, and the dependence of sequence expression on behavioral statistics. Moreover, the authors suggest that psychiatric disorders can be interpreted in terms of over-/under-representation of context information.</p>
<p>Strengths:</p>
<p>This ambitious work links diverse physiological and behavioral findings into a self-organizing neural network framework. All functional aspects of the network arise from plastic synaptic connections: Sequences, contexts, and action selection. The model also nicely links ideas from reinforcement learning to neuronally interpretable mechanisms, e.g., learning a value function from hippocampal activity.</p>
<p>Weaknesses:</p>
<p>The presentation, particularly of the methodological aspects, needs to be majorly improved. Judgment of generality and plausibility of the results is hampered, but is essential, particularly for the conclusions related to psychiatric disorders. In its present form, it is unclear whether the claims and conclusions made are justified. Also, the lack of clarity strongly reduces the impact of the work in the larger field.</p>
<p>More specifically:</p>
<p>(1) The methods section is impenetrable. The specific adaptations of the model to the individual use cases of the model, as well as the posthoc analyses of the simulations, did not become clear. Important concepts are only defined in passing and used before they are introduced. The authors may consider a more rigorous mathematical reporting style. They also may consider making the methods part self-contained and moving it in front of the results part.</p>
<p>(2) The description of results in the main text remains on a very abstract level. The authors may consider showing more simulated neural activity. It remains vague how the different stimuli and contexts are represented in the network. Particularly, the simulations and related statistical analyses underlying the paradigms in Figure 4 are incompletely described.</p>
<p>(3) The literature review can be improved (laid out in the specific recommendations).</p>
<p>(4) Given the large range of experimental phenomenology addressed by the manuscript, it would be helpful to add a Discussion paragraph on how much the results from mice and humans can be integrated, particularly regarding the nature of the context selection network.</p>
<p>(5) As a minor point, the hippocampus is pretty much treated as a premotor network. Also, a Discussion paragraph would be helpful.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106506.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper develops a model to account for flexible and context-dependent behaviors, such as where the same input must generate different responses or representations depending on context. The approach is anchored in the hippocampal place cell literature. The model consists of a module X, which represents context, and a module H (hippocampus), which generates &quot;sequences&quot;. X is a binary attractor RNN, and H appears to be a discrete binary network, which is called recurrent but seems to operate primarily in a feedforward mode. H has two types of units (those that are directly activated by context, and transition/sequence units). An input from X drives a winner-take-all activation of a single unit H_context unit, which can trigger a sequence in the H_transition units. When a new/unpredicted context arises, a new stable context in X is generated, which in turn can trigger a new sequence in H. The authors use this model to account for some experimental findings, and on a more speculative note, propose to capture key aspects of contextual processing associated with schizophrenia and autism.</p>
<p>Strengths:</p>
<p>Context-dependency is an important problem. And for this reason, there are many papers that address context-dependency - some of this work is cited. To the best of my knowledge, the approach of using an attractor network to represent and detect changes in context is novel and potentially valuable.</p>
<p>Weaknesses:</p>
<p>The paper would be stronger, however, if it were implemented in a more biologically plausible manner - e.g., in continuous rather than discrete time. Additionally, not enough information is provided to properly evaluate the paper, and most of the time, the network is treated as a black box, and we are not shown how the computations are actually being performed.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106506.1.sa0</article-id>
<title-group>
<article-title>Author Response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ito</surname>
<given-names>Yoshiki</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Toyoizumi</surname>
<given-names>Taro</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>We appreciate the reviewers’ thoughtful assessments and constructive feedback on our manuscript. The central goal of our study was to propose a simple and biologically inspired model-based reinforcement learning (MBRL) framework that draws on mechanisms observed in episodic memory systems. Unlike model-free approaches that require processing at each state transition, our model uses sequential activity (= transition model) to predict environmental changes in the long term by leveraging episode-like representations.</p>
<p>While many prior studies have focused on optimizing task performance in MBRL, our primary aim is to explore how flexible, context-dependent behavior—reminiscent of that observed in biological systems—can be instantiated using simple, neurally plausible mechanisms. In particular, we emphasize the use of an Amari-Hopfield network for the context selection module. This network, governed by Hebbian learning, forms attractors that can correct for sensory noise and facilitate associative recall, allowing dynamic separation of prediction errors due to sensory noise versus those due to contextual mismatches. However, we acknowledge that our explanation of these mechanisms, especially in relation to sensory noise, was not sufficiently developed in the current manuscript. We plan to revise the text to clarify this limitation and to expand on the implications of these mechanisms in the context of psychiatric disorder-like behaviors, as illustrated in Figure 5.
Several reviewers raised concerns about the clarity of our model. Our implementation is intentionally algorithmic rather than formal, designed to provide an accessible proof-of-concept model. We will revise the manuscript to better describe the core logic of the model—namely, the bidirectional interaction between the Hopfield network (X) and the hippocampal sequence module (H), where X sends the information on estimated current context to H, and H returns a future prediction based on the episode to X. This interaction forms a loop enabling the current context estimation and its reselection.</p>
<p>The key advantage of this architecture is its ability to flexibly adjust the temporal span of episodes used for inference and control, providing a potential solution to the challenge of credit assignment over variable time scales in MBRL. Because our model forms and stores the variable length of episodes depending on the context, it can handle both short-horizon and long-horizon tasks simultaneously. Moreover, because each episode is organized by context, reselecting contexts enables rapid switching between these variable timescales. This flexibility addresses a challenge in MBRL—the assignment of credit across variable time scales—without requiring explicit optimization. To better illustrate this important feature, we plan to include additional experiments in the revised manuscript that demonstrate how context-dependent modulation of episode length enhances behavioral flexibility and task performance.</p>
<p>Finally, we will address the comments on the presentation and the biological grounding of our model. To improve clarity and biological relevance, we will revise the Methods section to explicitly describe how the model is grounded in mechanisms observed in real neural systems. Also, we will clarify which parts of our figures represent computational results versus schematic illustrations and more clearly explain how each model component relates to known neural mechanisms. These revisions aim to improve both clarity and accessibility for a broad audience, while reinforcing the biological relevance of our approach.</p>
<p>We thank the reviewers again for their insightful comments, which will help us substantially improve the manuscript. We look forward to submitting a revised version that more clearly conveys the contributions and implications of our work.</p>
</body>
</sub-article>
</article>