<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">98415</article-id>
<article-id pub-id-type="doi">10.7554/eLife.98415</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.98415.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Nonlinear sensitivity to acoustic context is a stable feature of neuronal responses to complex sounds in auditory cortex of awake mice</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Akritas</surname>
<given-names>Marios</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Armstrong</surname>
<given-names>Alex G</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lebert</surname>
<given-names>Jules M</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0468-3369</contrib-id>
<name>
<surname>Meyer</surname>
<given-names>Arne F</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5560-3341</contrib-id>
<name>
<surname>Sahani</surname>
<given-names>Maneesh</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2210-1374</contrib-id>
<name>
<surname>Linden</surname>
<given-names>Jennifer F</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Ear Institute, University College London</institution>, London, <country>U.K</country></aff>
<aff id="a2"><label>2</label><institution>Sainsbury Wellcome Centre, University College London</institution>, London, <country>U.K</country></aff>
<aff id="a3"><label>3</label><institution>Gatsby Computational Neuroscience Unit, University College London</institution>, London, <country>U.K</country></aff>
<aff id="a4"><label>4</label><institution>Department of Neuroscience, Physiology &amp; Pharmacology, University College London</institution>, London, <country>U.K</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label><bold>For correspondence:</bold> <email>j.linden@ucl.ac.uk</email> (JFL)</corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-07-15">
<day>15</day>
<month>07</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP98415</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-04-12">
<day>12</day>
<month>04</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-04-01">
<day>01</day>
<month>04</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.04.22.537782"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Akritas et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Akritas et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-98415-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>The perceptual salience of a sound depends on the acoustic context in which it appears, and can vary on a timescale of milliseconds. At the level of single neurons in the auditory cortex, spectrotemporal tuning for particular sounds is shaped by a similarly fast and systematic nonlinear sensitivity to acoustic context. Does this neuronal context sensitivity “drift” over time in awake animals, or is it a stable feature of sound representation in the auditory cortex? We used chronically implanted tetrode arrays in awake mice to measure the electrophysiological responses of auditory cortical neurons to spectrotemporally complex, rapidly varying sounds across many days. For each neuron in each recording session, we applied the nonlinear-linear “context model” to estimate both a principal (spectrotemporal) receptive ﬁeld and a “contextual gain ﬁeld” describing the neuron’s nonlinear sensitivity to acoustic context. We then quantiﬁed the stability of these ﬁelds within and across days, using spike waveforms to match neurons recorded in multiple sessions. Contextual gain ﬁelds of auditory cortical neurons in awake mice were remarkably stable across many days of recording, and comparable in stability to principal receptive ﬁelds. Interestingly, there were small but signiﬁcant effects of changes in locomotion or pupil size on the ability of the context model to ﬁt temporal fluctuations in the neuronal response.</p><p>We conclude that both spectrotemporal tuning and nonlinear sensitivity to acoustic context are stable features of neuronal sound representation in the awake auditory cortex, which can be modulated by behavioral state.</p>
</abstract>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Title and abstract revised; introduction revised and updated; Figure 6 revised; figure legends updated; discussion expanded; acknowledgements updated.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Are sensory receptive fields of neurons in auditory cortex of adult animals fundamentally stable properties? Decades of research has shown that auditory cortical receptive fields in adult animals can be altered by behavioral training or by shifts in auditory attention (for reviews see <xref ref-type="bibr" rid="c42">Weinberger, 2007</xref>; <xref ref-type="bibr" rid="c16">Fritz et al., 2007</xref>; <xref ref-type="bibr" rid="c19">Irvine, 2018</xref>). However, the long-term baseline stability of auditory cortical receptive-field structure in adult animals is less well studied — especially for nonlinear features of the receptive fields, such as sound combination sensitivity and other forms of modulation by acoustic context. Here we analyze the long-term stability of nonlinear context sensitivity as well as spectrotemporal tuning in auditory cortical receptive fields of awake mice, using chronic electro-physiological recording and nonlinear stimulus-response function estimation.</p>
<p>The stability of sensory cortical response properties in awake animals has recently become a hot topic in debates about the nature of “representational drift” (<xref ref-type="bibr" rid="c8">Clopath et al., 2017</xref>; <xref ref-type="bibr" rid="c12">Driscoll et al., 2022</xref>; <xref ref-type="bibr" rid="c23">Marks and Goard, 2021</xref>). In the auditory cortex, long-term two-photon calcium imaging studies in awake mice have reported “representational drift” in population responses to sound stimuli (<xref ref-type="bibr" rid="c20">Kato et al., 2015</xref>; <xref ref-type="bibr" rid="c7">Chambers et al., 2022</xref>; <xref ref-type="bibr" rid="c3">Aschauer et al., 2022</xref>). Notably, this “drift” appears to arise primarily from changes in whether individual neurons respond to their preferred stimuli, rather than changes in their stimulus preferences when responsive (see for instance Supplementary Figure 5 in <xref ref-type="bibr" rid="c7">Chambers et al., 2022</xref>). However, the slowness of the calcium signal makes it difficult to reconstruct details of auditory cortical receptive fields, and therefore difficult to determine the extent to which spectrotemporal tuning and combination sensitivity might remain consistently stable in individual neurons when they are responsive. Sound patterns that evoke the same response from a neuron on the slow timescale of calcium signalling could evoke different responses measured at the fast timescale of neuronal spiking. Thus, previous calcium imaging studies in auditory cortex have not resolved questions about whether auditory cortical receptive fields in adult animals remain stable across days when measured with the millisecond temporal resolution most relevant to auditory perception.</p>
<p>Previous electrophysiological studies have reported that spectrotemporal tuning of auditory cortical neurons can remain stable for many hours — but to the best of our knowledge, no studies have investigated the long-term stability of nonlinear sensitivity to acoustic context. <xref ref-type="bibr" rid="c13">Elhilali et al. (2007</xref>) used reverse-correlation techniques to obtain repeated estimates of linear spectrotemporal receptive fields (STRFs) from neuronal responses to complex sounds in awake, passively listening ferrets, and found that STRF structure of individual neurons remained relatively stable across many hours of recording. Similarly, <xref ref-type="bibr" rid="c17">Grana et al. (2009</xref>) reported that STRFs recorded from neurons in field L (avian auditory cortex) were stable for hours in awake, passively listening songbirds. Other electrophysiological studies focusing on more basic measures of spectrotemporal selectivity, such as frequency tuning and spike timing statistics, have suggested that neuronal response properties might be stable for days or weeks in awake animals implanted with electrode arrays (<xref ref-type="bibr" rid="c44">Williams et al., 1999</xref>; <xref ref-type="bibr" rid="c47">Witte et al., 1999</xref>). How stable are spectrotemporal receptive fields of auditory cortical neurons in awake animals across days or weeks? And how stable are nonlinear features of auditory cortical receptive fields, such as sound combination sensitivity and modulation by acoustic context? To address these questions, we analyzed the stability of auditory cortical receptive-field structure in awake, passively listening mice across days of chronic electrophysiological recording, using the nonlinear-linear “context model” (<xref ref-type="bibr" rid="c45">Williamson et al., 2016</xref>) to estimate both spectrotemporal tuning and contextual sensitivity of auditory cortical neurons from their spiking responses to complex sounds. Unlike the STRF and commonly used linear-nonlinear models of auditory cortical responses (reviewed in <xref ref-type="bibr" rid="c26">Meyer et al., 2017</xref>), the context model allows for nonlinear integration of spectrotemporal elements within a complex stimulus (for example, nonlinear forward suppression or two-tone interactions). The context model includes both an STRF-like principal receptive field (PRF), with dimensions of sound frequency and time preceding the neuronal response, and a contextual gain field (CGF), with dimensions of frequency offset and time offset for sound combinations that modulate input gain. The PRF represents the spectrotemporal tuning of the neuron, while the CGF represents its contextual sensitivity — i.e., how the responsiveness of a neuron to a tonal element within a complex sound is affected by the acoustic context in which that element appears. Hence, the CGF captures suppressive or facilitatory effects of sound combinations, which modulate the gain of the neuron’s response to each sound element falling within the PRF. Estimation of PRF and CGF parameters from neuronal responses to a complex sound is an experimentally efficient and relatively stimulus-agnostic means of determining both spectrotemporal tuning and nonlinear sensitivity to acoustic context (<xref ref-type="bibr" rid="c45">Williamson et al., 2016</xref>; <xref ref-type="bibr" rid="c26">Meyer et al., 2017</xref>).</p>
<p>We report that neuron-specific patterns of nonlinear contextual sensitivity as well as spectrotemporal tuning remain stable across multiple days in awake, passively listening mice. We also observe significant but very small effects of changes in locomotion or pupil size on the ability of the context model to fit temporal fluctuations in auditory cortical responses. These results suggest that auditory cortical neurons can maintain consistent receptive fields for many days, despite some modulation by spontaneous behavioral state. Moreover, the findings indicate that nonlinear tuning to acoustic context is a robust and remarkably stable feature of the neural code in the awake auditory cortex.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>We chronically implanted male CBA/Ca mice with multi-tetrode arrays, using a tangential approach to the auditory cortex. We used the tetrodes to record extracellularly from auditory cortical neurons in awake, head-fixed mice, while also measuring running behavior and pupil diameter, while the animals listened passively to noise bursts, tone pips and dynamic random chord (DRC) stimuli (<xref rid="fig1" ref-type="fig">Figure 1</xref>). Two DRC stimuli, each consisting of 15 continuous repetitions of a 45-s-long DRC trial, were presented within each recording session. We conducted multiple recording sessions at each recording site, repeating exactly the same stimulation and recording protocol on different days. In 4 mice we obtained high-quality auditory cortical recordings from multiple recording sites across at least 5 days for each site, which could be used to assess stability of neuronal responses over time.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Experimental setup, auditory stimuli, recording strategy, and stability assessment.</title>
<p><bold>A</bold>. Illustration of experimental setup. Single-unit and multi-unit recordings were obtained from the auditory cortex of awake mice using a chronically implanted 8-tetrode array. Mice were head-fixed but were able to run on a rotating cylinder. Simultaneous neuronal recordings and measurements of running speed and pupil diameter were obtained during repeated presentations of noise bursts, tone pips, and dynamic random chord (DRC) stimuli. Responses to noise bursts and tone pips were used to identify core auditory cortical areas. Responses to DRC stimuli were used to estimate contextual gain fields (CGFs) and principal receptive fields (PRFs) using the context model. <bold>B</bold>. Schematic illustrations of noise bursts (top), tones (middle), and DRC excerpt (bottom). A full DRC stimulus lasted 675 s, and consisted of 15 continuous repetitions of a 45-s-long sequence of 20-ms random chords. <bold>C</bold>. Schematic representation of the experimental design. Recordings were obtained from the same site for multiple days before tetrodes were advanced to sample new sites. Note the repetition of the full sequence of stimulus presentations (1 segment) within each session. <bold>D</bold>. Conceptual illustration of methodology used for assessing stability of the context model fits. On each day of recording, the full DRC stimulus was played twice, once in each segment (upper left). CGF or PRF estimates from different days and/or different segments (field<sub><italic>j,k</italic></sub>, where <italic>j</italic>=day and <italic>k</italic>=segment) were compared both within and between sessions to obtain a similarity matrix (right). Within-session similarities are on the diagonal (in green and yellow) and the average estimates of the across-session similarities (lower left) are on the off-diagonals (in brown).</p></caption>
<graphic xlink:href="537782v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Recordings were spike-sorted to distinguish single units from likely multi-units (see Materials and Methods). Recording sites in core auditory areas were then identified as those producing unit recordings with significant and short-latency (≤ 20 ms) responses to tone pips (<xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref>). The core auditory dataset (314 single units, 199 multi-units) included units that either directly fulfilled these criteria or were recorded on the same tetrode at the same time (and hence at the same location) as another unit that fulfilled the criteria.</p>
<p>We matched neuronal recordings obtained over multiple different days by analyzing spike wave-form similarity in tetrode recordings. To do so we customized a waveform-matching technique introduced by <xref ref-type="bibr" rid="c41">Tolias et al. (2007</xref>), which quantifies the difference between two sets of spike wave-forms using two metrics, <italic>d</italic><sub>1</sub> and <italic>d</italic><sub>2</sub>. The former measures differences in shape between spike wave-forms and the latter measures differences in scale. We improved upon the original approach by establishing a null distribution (in dimensions of <italic>d</italic><sub>1</sub> and <italic>d</italic><sub>2</sub>) reflecting differences between definitively non-matched units, recorded using the same tetrode but from sites spaced at least 250 microns apart (<xref rid="fig2" ref-type="fig">Figure 2A</xref>). We used parameters of this null distribution to distinguish likely from unlikely matched pairs in the experimental dataset, which consisted of spike waveforms recorded using the same tetrode on different days at the same recording site (<xref rid="fig2" ref-type="fig">Figure 2B–C</xref>; see also Materials and Methods).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Spike waveforms matched across multiple days using pairwise waveform distances.</title>
<p>See text for explanation of waveform distance metrics <italic>d</italic><sub>1</sub> and <italic>d</italic><sub>2</sub>. <bold>A</bold>. Null distribution. Scatterplot shows (<italic>d</italic><sub>2</sub>, <italic>d</italic><sub>1</sub>) spike waveform distances for pairwise comparisons (n=6574) between spike waveforms for unit recordings known to be non-matched (obtained using the same tetrode but from sites located at least 250 microns apart). The ellipse represents the 99% confidence interval (CI) for the null distribution, estimated by fitting a 2D Gaussian to the data. Marginal distributions were obtained using kernel density estimation. <bold>B</bold>. Experimental distribution. Scatterplot shows (<italic>d</italic><sub>2</sub>, <italic>d</italic><sub>1</sub>) spike waveform distances for pairwise comparisons (n=5594) between spike waveforms for unit recordings obtained using the same tetrode on different recording days at the same recording site. A Gaussian mixture model was fitted to the experimental data using the Expectation-Maximization (EM) algorithm with two clusters. One of the clusters was fixed to the null distribution estimated in A. Ellipses show the 99% CIs for the null (blue) and the experimental (red) distributions. We conservatively defined a waveform pair to be “matched” (i.e., likely to be coming from the same unit) if the waveform distance fell within the experimental but outside the null 99% CI. Colored dots correspond to the example matched and non-matched waveform pairs shown in C. <bold>C</bold>. Examples of spike waveform pairs. The pairs in the first two columns were identified as matches, whereas those in the latter two columns were not. <bold>D</bold>. Number of matches as a function of the temporal separation between the two recordings. Dotted gray line shows percentage of total comparisons which were matches. Note that the number of waveform pairs identified as matches was highest for recordings occurring 1–4 days apart, but this was primarily because the number of pairwise waveform comparisons was highest for recordings occurring a small number of days apart. The <italic>percentage</italic> of waveform comparisons producing a match could be just as high for recordings made weeks apart as days apart, indicating that prolonged tetrode recordings from the same site could be stable.</p></caption>
<graphic xlink:href="537782v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We obtained 637 matches, some made between units recorded as long as 3 weeks apart. As expected, most waveform matches were made across 1–4 elapsed days (<xref rid="fig2" ref-type="fig">Figure 2D</xref>, histogram), because most recordings from the same site were obtained across 5 consecutive days. However, some of the intervals between recordings at the same site were much longer, and we saw no evidence for an overall decline in the fraction of waveform matches at longer intervals. For recordings separated by weeks, the percentage of waveform comparisons producing matches could be as high as for recordings separated by 1–4 days (<xref rid="fig2" ref-type="fig">Figure 2D</xref>, dotted line).</p>
<sec id="s2a">
<title>Neuronal sensitivity to acoustic context in awake mice conserves main features seen in anesthetized mice</title>
<p>For consistency with a previous study of neuronal CGF structure in anesthetized animals (<xref ref-type="bibr" rid="c45">Williamson et al., 2016</xref>), we included in the context model analysis all units in the core auditory dataset for which the signal power in the neuronal response to the DRC stimulus was at least one standard error greater than zero (a total of 142 single units and 127 multi-units). Signal power is the stimulus-dependent power in the neural response — i.e., the portion of the temporal variability in the response that is preserved from trial to trial, and that is at least in principle predictable from a stimulus-response function model. As in previous work (<xref ref-type="bibr" rid="c37">Sahani and Linden, 2002b</xref>; <xref ref-type="bibr" rid="c1">Ahrens et al., 2008</xref><bold><italic>; </italic></bold><xref ref-type="bibr" rid="c45">Williamson et al., 2016</xref>), we defined noise power as the remaining, stimulus-independent part of the response, encompassing any variability that is not repeatable across identical trials. Context model parameters can be estimated effectively for any neuronal response with significantly non-zero signal power, regardless of noise power. Nevertheless, the signal-to-noise power ratio (SNR) provides a useful quantitative index of selectivity for the DRC stimulus in the recorded population. <xref rid="fig3" ref-type="fig">Figure 3A</xref> shows the SNR values for all units in the dataset, and <xref rid="fig3" ref-type="fig">Figure 3B–F</xref> provides examples of DRC responses for units with different SNRs. Note that both single-unit and multiunit recordings yielded DRC responses with SNRs spanning the entire SNR range observed in the population.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Neuronal responses to the DRC stimulus used to estimate PRF and CGF structure in awake mice.</title>
<p><bold>A</bold>. Signal power normalized by noise power (SNR) for neuronal responses to the DRC stimulus, for all units that qualified for further analysis given our selection criteria (see text). Units are sorted in order of ascending SNR. Single units are shown in red, multi-units in blue. <bold>B</bold>. Spectrographic reresentation of the final 1.5 s of the 45-s-long DRC stimulus used. Each shaded rectangle represents a 20-ms tone pulse, with darker shades corresponding to louder tone pips (see colorbar). <bold>C-F</bold>. Trial-by-trial spike rasters (top) and histograms of spiking rate (bottom), describing the responses of four example units to the DRC excerpt in B. Histogram bins are aligned with the 20-ms chords of the DRC. Units were taken from a point in the distribution in A indicated by the arrows. Time is shown relative to the beginning of the stimulus for the trial. <bold>G</bold>. Example PRFs (left) and CGFs (right) for three different units (each row is one unit). Yellow and cyan areas in the PRFs represent excitatory and inhibitory regions of the time-frequency receptive field respectively. In the CGFs, axes are time offset and frequency offset relative to a “target” tone represented by the notch at <italic>τ</italic>=0 and <italic>ϕ</italic>=0, which can be any tonal element in the DRC stimulus. Red and blue areas in the CGF indicate amplifying or dampening effects (respectively) of acoustic energy at that relative position on the gain of the neuron’s response to a target tone. In other words, the CGF depicts modulation of neuronal responsiveness by sound combinations, as a function of time and frequency differences between the tonal elements in the combinations. <bold>H</bold>. Average CGF across all units and animals (center). For units recorded across multiple days, we included in this average a single CGF estimated from all the available data for the unit. Line plots along margins show: (left) gain profile as a function of frequency offset between tone pips, averaged across time offsets; (bottom) gain profile as a function of time offset between tone pips, averaged across frequency offsets; and (right) gain profile as a function of frequency offset for the 0–20-ms time-bin alone (i.e., for near-simultaneous tone pips). Error bars indicate standard error of the estimated population means.</p></caption>
<graphic xlink:href="537782v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To examine features of contextual sensitivity in auditory cortical neurons of awake mice, we first fit a single context model for each unit, pooling all the DRC responses recorded from that unit across multiple days of recording in the awake animal. Procedures for estimating the PRF and CGF parameters in the context model are described in Materials and Methods. <xref rid="fig3" ref-type="fig">Figure 3G</xref> depicts example PRFs and CGFs from three units, and <xref rid="fig3" ref-type="fig">Figure 3H</xref> shows the average CGF across all units and animals. This average CGF illustrates the most common features of contextual sensitivity in auditory cortical neurons of awake, passively listening mice, and it is consistent with that previously reported by <xref rid="c46" ref-type="bibr">Williamson and Polley (2019</xref>) specifically for neurons in layers 5 and 6 of awake mouse auditory cortex.</p>
<p>Notably, contextual sensitivities of auditory cortical neurons in awake passively listening mice were also qualitatively similar to those previously described in anesthetized mice (<xref ref-type="bibr" rid="c45">Williamson et al., 2016</xref>). Like the average CGF for anesthetized mice shown in that reference, the average CGF for awake mice (<xref rid="fig3" ref-type="fig">Figure 3H</xref>) exhibited (i) narrowband delayed suppression (blue region centred on zero frequency offset and extending over negative time offsets) and (ii) near-simultaneous broadband facilitation (red areas at zero time offset and large frequency offsets on either side of the target tone). However, the narrowband delayed suppression observed previously in anesthetized mice peaked at and extended to longer time offsets than was observed in awake mice here (and by <xref ref-type="bibr" rid="c46">Williamson and Polley, 2019</xref>).</p>
</sec>
<sec id="s2b">
<title>Neuronal sensitivity to acoustic context is stable across days of recording in awake mice</title>
<p>We next examined whether both spectrotemporal tuning and contextual sensitivity of auditory cortical neurons were stable over time in awake mice. To do so, we compared different estimates of PRFs or CGFs obtained from the same unit within and across recording sessions, using the spike-waveform-matching technique described previously to track units across multiple days of recording at the same recording site. Within-session comparisons of repeated PRF or CGF estimates provided a measure of short-term test-retest reliability, while across-session comparisons allowed us to measure long-term stability of spectrotemporal tuning and contextual sensitivity.</p>
<p>As demonstrated by the examples in <xref rid="fig4" ref-type="fig">Figure 4A-C</xref>, the structure of both PRFs and CGFs was often remarkably consistent across recording days. We calculated the normalized dot product (field correlation) between repeated PRF or CGF estimates obtained for the same unit to assess consistency of neuron-specific structure. Correlation between repeated PRF or CGF estimates for the same unit could be nearly as high across days as within recording sessions (<xref rid="fig4" ref-type="fig">Figure 4D-F</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Examples of quantification of PRF and CGF stability across recording days.</title>
<p><bold>A-C</bold>. Example PRF (top row) and CGF (bottom row) pairs for neurons matched across recording sessions. The within-session repetition of the 675-s-long DRC run allowed us to estimate two PRFs and two CGFs for each session. For each example, PRFs are identically scaled to the maximum change in firing rate shown in the PRF colorbar. CGF weights at each value of (<italic>ϕ, τ</italic>) represent the change in gain induced in the response to a sound at the (0,0) notch point if one of the loudest tones of the DRC were to fall at the corresponding (<italic>ϕ, τ</italic>) location (colors correspond to gain change shown on the CGF colorbar). Like PRFs, CGFs are identically scaled within and across sessions for each example. Time runs from left to right and is in recording sessions conducted on separate but not necessarily consecutive days; numerals across the top of panel A indicate number of recording sessions following the initial session. Note the remarkable consistency of both CGF and PRF structure, which is nearly as high across days as within sessions. <bold>D-F</bold>. Heatmaps showing the normalized dot product (i.e., field correlation) between the PRFs (orange) or between the CGFs (green) shown in A-C, respectively. Diagonals indicate the within-session comparisons, off-diagonals the across-session (i.e., across-day) comparisons. Higher values indicate higher correlation in structure. The correlation color scale was set to 0.70–1.00 (rather than 0.00–1.00) to maximize visibility of small differences in the generally high correlation values.</p></caption>
<graphic xlink:href="537782v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Population data on stability of PRFs and CGFs: normalized field alignment indices.</title>
<p><bold>A-B</bold>. Stability of PRFs (A) and CGFs (B) quantified using a normalized field alignment index, where 1.0 indicates similarity equivalent to the field correlation observed for within-session comparisons for each unit, and 0.0 indicates baseline field correlation expected for comparisons between PRFs or CGFs obtained from different units (see text for details). Data points on day 0 represent the within-session comparison; subsequent points represent comparisons across different numbers of days. Each colored line represents a unit; the solid black line is the median across units. Insets show zoomed-in views of the bulk of the data, between days 0 and 5. Normalized field alignment remained close to 1.0 across sessions for most PRFs and CGFs, indicating that neuron-specific PRF and CGF structure was preserved for many days in most neurons.</p></caption>
<graphic xlink:href="537782v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To examine stability of PRFs and CGFs across the neuronal population, we first quantified similarity using a normalized <italic>field alignment index</italic>, where 1.0 indicates across-session similarity equivalent to that observed for within-session comparisons for each unit, and 0.0 indicates similarity no higher than the expected baseline for the population (i.e., the similarity that would be expected for comparisons between fields from different units). The field alignment index was calculated as <inline-formula><inline-graphic xlink:href="537782v2_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,with terms defined as follows for CGFs (and equivalently for PRFs). For each unit, we defined the <italic>within-session similarity α</italic> to be the average correlation between CGFs estimated within the same recording session (i.e., the average across central diagonal values in matrices shown in <xref rid="fig4" ref-type="fig">Figure 4D-E</xref>). Likewise, we defined the unit’s <italic>across-session similarity β</italic> for sessions <italic>n</italic> days apart to be the average of the correlation values for all CGF estimates from recordings made <italic>n</italic> days apart (i.e., the average across values in an offset diagonal in matrices shown in <xref rid="fig4" ref-type="fig">Figure 4D-E</xref>). Finally, we estimated <italic>baseline similarity γ</italic> by comparing the CGF for the unit to CGFs from other units recorded from the same animal.</p>
<p>Analysis of field alignment indices for the recorded population revealed that most PRFs and CGFs were as stable across days of recording as they were within a single recording session (<xref rid="fig5" ref-type="fig">Figure 5</xref>). Indeed, as shown by the extended, nearly horizontal trajectories of some of the colored lines in <xref rid="fig5" ref-type="fig">Figure 5</xref>, some units maintained within-session levels of stability in neuron-specific PRF and CGF structure across recording sessions as long as three weeks apart.</p>
<p>Similar stability was evident in analysis of the raw correlation values (i.e., <italic>α</italic> for 0 days between recordings, <italic>β</italic>(<italic>n</italic>) for recordings <italic>n</italic> days apart). For reasons explained in Materials and Methods, we used the raw correlation values rather than the normalized field alignment indices for population analysis of PRF and CGF stability. For both PRFs and CGFs, correlation between fields estimated from the same unit’s responses recorded on different days were typically 0.8-1.0, even when recordings were separated by weeks (<xref rid="fig6" ref-type="fig">Figure 6A-B</xref>). To illustrate the dominant trends, <xref rid="fig6" ref-type="fig">Figure 6C</xref> and <xref rid="fig6" ref-type="fig">D</xref> show the lines of best fit to the field correlation values for each unit’s PRF or CGF respectively, computed as a function of days between recordings using weighted regression. Note that a slope of -0.2 for this best-fit line would correspond to loss of field correlation across 5 days, which was the most common time range over which our repeated recordings were made. As demonstrated in <xref rid="fig6" ref-type="fig">Figure 6E</xref> and <xref rid="fig6" ref-type="fig">F</xref>, the best-fit line slopes were significantly higher than -0.2 for almost all units (68/69 PRFs, 64/69 CGFs with slope estimates at least 2 standard errors greater than -0.2). Moreover, for both PRFs and CGFs, the slopes were often statistically indistinguishable from zero (29/69 PRFs, 49/69 CGFs with slope estimates within 2 standard errors of 0). Thus, most PRFs and CGFs were stable on a timescale that substantially exceeded the range of our measurements.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Population data on stability of PRFs and CGFs: raw correlation values.</title>
<p><bold>A-B</bold>. Stability of PRFs (A) and CGFs (B) quantified using raw correlation values, where 1.0 indicates perfect alignment of fields estimated from recordings made on two different days (see <xref rid="fig4" ref-type="fig">Figure 4</xref> for examples). As in <xref rid="fig5" ref-type="fig">Figure 5</xref>, data points on day 0 represent within-session comparisons; subsequent points represent comparisons across different numbers of days. Each colored line represents a unit, and lines are transparent so that shading darkens as multiple lines superimpose. Note that most units display high PRF (A) or CGF (B) correlation values that are stable across days or weeks. <bold>C-D</bold>. Lines of best fit to the within-session and across-session field correlation values for each unit, for PRFs (A) and CGFs (B). Each best-fit line was estimated using weighted regression, taking into account the number of within-session (0 days between recordings) and across-session (<italic>n</italic> days between recordings) comparisons available for the unit. <bold>E-F</bold>. Slope (x-axis) for each colored line in A or B respectively; units (y-axis) are ordered by increasing slope. Error bars indicate ±1 standard error of the estimated slope. For both PRFs (C) and CGFs (D), the slopes of the best-fit lines were often statistically indistinguishable from zero and rarely more negative than -0.2 (the value corresponding to loss of field correlation across 5 days).</p></caption>
<graphic xlink:href="537782v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Further analysis confirmed the conclusion that PRFs and CGFs were both remarkably stable properties of neuronal responses. For example, using the slope of the line of best fit to the field correlation values across recording intervals (<xref rid="fig6" ref-type="fig">Figure 6</xref>) as a measure of stability, we found that the distribution of unit-by-unit differences in PRF and CGF stability was strongly peaked at zero (<xref rid="fig7" ref-type="fig">Figure 7A</xref>). We also analyzed relationships between the slope measure of PRF and CGF stability and properties of the neuronal response to the DRC stimulus. There was no significant correlation between PRF or CGF stability and either the mean evoked firing rate or the signal-to-noise power ratio of the neuronal response to the DRC stimuli. There was a weak positive correlation between PRF stability and the normalized predictive power of the context model (Spearman’s <italic>rho</italic> = 0.3, <italic>p</italic> = 0.014), but no significant relationship for CGF stability. Thus, PRF and CGF structure appeared to be similarly stable within units and relatively robust to across-unit variation in neuronal response properties or model fits.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Further analysis of PRF and CGF stability.</title>
<p><bold>A</bold>. Histogram of unit-by-unit differences between the PRF and CGF slope estimates from the correlation-based stability analysis shown in <xref rid="fig6" ref-type="fig">Figure 6</xref>. Note clustering of values near zero (dotted line). <bold>B-D</bold>. Slopes of best-fit lines from correlation-based stability analysis for PRFs (orange) and CGFs (green), plotted versus: mean firing rate evoked by the DRC stimulus (B); signal-to-noise power ratio in the neuronal response (C); and normalized predictive power of the context model fit (D). There was no apparent relationship between PRF/CGF stability and firing rate or signal-to-noise power ratio. The stability of PRFs showed a weak positive correlation with normalized predictive power (Spearman’s <italic>rho</italic> = 0.3, <italic>p</italic> = 0.014), whereas that of CGFs did not.</p></caption>
<graphic xlink:href="537782v2_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2c">
<title>Changes in locomotion or pupil size have significant but small effects on context model fits to neuronal responses</title>
<p>Given that neuron-specific CGF and PRF structure tended to be stable for days in awake mice, we wondered if there was any effect of the animal’s behavioral state on the context model fits, and by extension, on the spectrotemporal tuning and contextual sensitivities of the neurons. Previous studies have found that excitability of auditory cortical neurons decreases during locomotion (<xref ref-type="bibr" rid="c39">Schneider et al., 2014</xref>) and either increases with pupil dilation or exhibits non-monotonic dependence on pupil size (<xref ref-type="bibr" rid="c25">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="c40">Schwartz et al., 2020</xref>). These changes in neuronal excitability with behavioral state are known to modulate the gain and variability of auditory cortical responses to sound, but do not necessarily affect stimulus selectivity (<xref ref-type="bibr" rid="c40">Schwartz et al., 2020</xref>). We therefore asked whether context model fits might be robust to changes in locomotion and pupil size in awake mice.</p>
<p>We recorded locomotor activity and pupil size along with auditory cortical activity in the vast majority of our experiments (<xref rid="fig1" ref-type="fig">Figure 1</xref>), and observed behavioral associations and changes in neuronal excitability consistent with previous reports. For example, in line with previous work (e.g.: <xref ref-type="bibr" rid="c35">Reimer et al., 2014</xref>; <xref ref-type="bibr" rid="c39">Schneider et al., 2014</xref>), we found that locomotor activity was associated with pupil dilation in mice, and evoked firing rates tended to be smaller when the mouse was moving than when it was still (data not shown).</p>
<p>To investigate how changes in locomotor activity and pupil size affected context model fits, we compared the residuals from model predictions between different behavioral states. Neuronal responses to multiple repetitions of a 45-s-long DRC trial were required to fit each context model, and behavioral variables like locomotion and pupil size varied on a much faster timescale than the DRC trial length (<xref rid="fig8" ref-type="fig">Figure 8A</xref>). Hence, it was not feasible to fit different context models to entire DRC trials when the mouse was still versus moving or when the pupil was small versus large. Instead, we analyzed how the moment-by-moment error in context model predictions depended on the animal’s behavioral state. For each unit, we fit a context model to all DRC responses recorded from the cell; calculated the difference between the observed neuronal response and context model prediction for each 20-ms time bin in all DRC recordings; and then compared the interquartile range (IQR) and median of these residuals for time bins when the animal was still versus moving or when the pupil was small versus large (see Materials and Methods for further details).</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Small but significant effects of locomotor activity and pupil dilation on context model fits.</title>
<p><bold>A</bold>. Observed spiking activity of a single unit (top, black) overlaid with the context model prediction (top, red). Underneath is a trace showing the difference between the two (i.e., the residual, shown in grey, measured in spikes). Dotted black line indicates zero residual. Further below is the pupil diameter (measured as a proportion relative to eye width), and below it a trace of the animal’s running activity over the same period of time. <bold>B</bold>. Interquartile range (IQR) of the residuals for individual units recorded when the mice were still versus moving (i.e., timebins when running cylinder rotation speed was zero versus non-zero). Dotted black line indicates diagonal where the IQRs are equal. Note that more data points fall below than above the line, but that most data points are very close to the diagonal. <bold>C</bold>. Residual IQRs for units recorded when the pupil size was small versus large (i.e., pupil diameter less than or greater than the median pupil diameter for the relevant recording sessions). Conventions and observations as in B.</p></caption>
<graphic xlink:href="537782v2_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Analysis of the residual IQRs showed that the ability of the context model to predict temporal variation in auditory cortical responses was significantly, but minimally, affected by changes in locomotor activity and pupil size (<xref rid="fig8" ref-type="fig">Figure 8, B</xref> and <xref rid="fig8" ref-type="fig">C</xref> respectively). An increase in residual IQR implies poorer prediction of fluctuations in firing rate driven by the DRC stimulus. Comparisons between behavioral states revealed that residual IQRs were significantly higher when the animal was moving or the pupil was large (Wilcoxon sign-rank tests, <italic>p</italic> = 1.5<italic>x</italic>10<sup>−26</sup> for the locomotion data, <italic>p</italic> = 2.7<italic>x</italic>10<sup>−13</sup> for the pupil data). However, effect sizes were extremely small in both cases (Cohen’s <italic>d</italic>, 0.09 for the locomotion data and 0.07 for the pupil data). Moreover, the balance of the residual IQRs between the behavioral states improved when the dataset was restricted to single-unit recordings (e.g., proportion of units above the diagonal rose from 0.31 to 0.34 for the locomotion data and from 0.35 to 0.40 for the pupil data). We therefore conclude that behavioral state had significant but very small effects on the ability of the context model to predict temporal fluctuations in auditory cortical responses to the DRC stimulus. In <xref rid="figS2" ref-type="fig">Supplementary Figure 2</xref>, we also report small but significant effects of behavioral state on the median residuals from context model predictions; however these results are more difficult to relate to PRF/CGF structure because unlike residual IQRs, median residuals depend not only on the PRF/CGF structure but also on a constant offset term in the model related to prediction of overall mean firing rate.</p>
<p>In sum, these analyses indicate that context model fits were significantly influenced by changes in locomotor activity or pupil size in awake mice, but that effect sizes were small. More detailed analyses of the influence of behavioral state on CGF/PRF structure will require further experiments in which animals are trained or motivated to maintain particular behavioral states for prolonged periods, so that separate context models can be estimated for each state.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Our results indicate that auditory cortical neurons in awake mice maintain remarkably stable patterns of nonlinear sensitivity to combinations of sound input. Individual neurons recorded across many days displayed consistent nonlinear contextual sensitivity (CGF structure) which was stable across many days and comparable in stability to spectrotemporal tuning (PRF structure). In fact, for most auditory cortical neurons, the projected timescale for stability of neuron-specific CGF (and PRF) structure was well beyond the timeframe of the repeated measurements performed here. Average CGF structure in awake mice was qualitatively similar to that observed previously in anesthetized mice (<xref ref-type="bibr" rid="c45">Williamson et al., 2016</xref>). Notably, however, the ability of the CGF/PRF model to fit temporal fluctuations in the neuronal response was significantly modulated by behavioral state in awake mice, although effect sizes were very small. These observations support the conclusion that both spectrotemporal tuning and nonlinear sensitivity to acoustic context are stable features of auditory cortical receptive fields, which can be at least partially modified by behavioral state. Interestingly, recent two-photon imaging studies in the visual cortex have drawn similar conclusions regarding the stability of orientation tuning, size tuning and surround suppression (<xref ref-type="bibr" rid="c23">Marks and Goard, 2021</xref>; <xref ref-type="bibr" rid="c34">Ranson, 2017</xref>), at least in the highly responsive neurons that would be preferentially sampled with electrophysiological recording techniques. Thus, nonlinear sound-combination sensitivity may well be as stable a feature of auditory cortical receptive fields as orientation selectivity, size tuning and surround suppression are in visual cortical receptive fields.</p>
<p>These results may at first appear in conflict with reports of “representational drift” in the auditory cortex; however, they are not. Recent two-photon calcium imaging studies of auditory cortex in awake mice have concluded that “representational drift” in the auditory cortex arises primarily from fluctuations in the responsiveness of individual neurons, not from changes in the stimulus selectivities of those neurons when they are responsive (<xref ref-type="bibr" rid="c7">Chambers et al., 2022</xref>; <xref ref-type="bibr" rid="c3">Aschauer et al., 2022</xref>). Two-photon calcium imaging allows individual neurons to be tracked over time more definitively than is possible with spike-waveform matching from electrophysiological recording, and it is therefore a better technology to use to address questions about whether individual neurons “drop in” and “drop out” of population activity over time. However, two-photon calcium imaging provides an indirect measure of spiking activity with temporal resolution too low for detailed mapping of receptive fields; therefore, it is limited in its ability to address questions about stability of stimulus selectivity over time. Conversely, while extracellular electrophysiological recording can only be used to track neurons when they are responsive, it allows measurement of spiking activity with the sub-millisecond temporal resolution required for mapping auditory cortical receptive fields. Thus, results of the present electrophysiological study complement and extend the conclusions of previous two-photon imaging studies in auditory cortex, by showing that spectrotemporal receptive fields and sound combination sensitivities of responsive auditory cortical neurons are remarkably stable over time.</p>
<p>To the best of our knowledge, these data also provide the first demonstration that nonlinear sensitivity to acoustic context is a stable, robust feature of receptive fields in the awake auditory cortex. Previous electrophysiological studies of stability in auditory cortical responses to complex sounds have examined consistency of linear spectrotemporal tuning, not nonlinear combination sensitivity, over a timescale of minutes to hours, not days. These studies have reported that spectrotemporal receptive fields (analogous to PRFs, not CGFs) are stable over minutes to hours of recording in awake passively listening animals (<xref ref-type="bibr" rid="c13">Elhilali et al., 2007</xref>; <xref ref-type="bibr" rid="c17">Grana et al., 2009</xref>) and are substantially modified by engagement in behavior (e.g., <xref ref-type="bibr" rid="c15">Fritz et al., 2005</xref>; <xref ref-type="bibr" rid="c9">David et al., 2012</xref>). Other electrophysiological studies have described input nonlinearities analogous to CGF structure (<xref ref-type="bibr" rid="c1">Ahrens et al., 2008</xref>; <xref ref-type="bibr" rid="c10">David et al., 2009</xref>; <xref ref-type="bibr" rid="c29">Pienkowski and Eggermont, 2010</xref>; <xref ref-type="bibr" rid="c45">Williamson et al., 2016</xref>; <xref ref-type="bibr" rid="c18">Harper et al., 2016</xref>; <xref ref-type="bibr" rid="c46">Williamson and Polley, 2019</xref>), but none have examined whether these nonlinearities remain stable over days in individual auditory cortical neurons. We found that both CGFs and PRFs were remarkably stable, with neuron-specific structure that was nearly as consistent between recording sessions conducted on different days as between repeated recordings conducted within the same session on the same day.</p>
<p>These findings have three important implications: physiological, computational, and conceptual. First: physiologically, our results imply that nonlinear sensitivity to acoustic context in the auditory cortex is driven by neural mechanisms that are as stable as those underlying spectrotemporal tuning — at least for sound conjunctions within the &lt;300 ms, ±1 octave range captured by the CGF. Nonlinear contextual sensitivity is sometimes assumed to be a more labile, emergent property of auditory cortex than spectrotemporal tuning, which is largely inherited from strongly stimulus-driven subcortical inputs. However, neurons throughout the subcortical auditory system are known to respond nonlinearly to combinations of sound input. Even within the cochlea, adaptation at the hair-cell synapse generates nonlinear forward suppression in auditory nerve fibres over a ∼50ms timescale, and cochlear mechanics generate nonlinear two-tone interactions spanning many octaves (<xref ref-type="bibr" rid="c49">Zhang et al., 2001</xref>; <xref ref-type="bibr" rid="c50">Zilany et al., 2009</xref>). Other examples of nonlinear combination sensitivity have been documented throughout the auditory brainstem and midbrain, for example in the dorsal cochlear nucleus (<xref ref-type="bibr" rid="c28">Nelken et al., 1997</xref>; <xref ref-type="bibr" rid="c48">Yu and Young, 2000</xref>), the medial nucleus of the trapezoid body (<xref ref-type="bibr" rid="c14">Englitz et al., 2010</xref>), the nucleus of the lateral lemniscus (<xref ref-type="bibr" rid="c32">Portfors and Wenstrup, 2001</xref>), and the inferior colliculus (<xref ref-type="bibr" rid="c31">Portfors and Wenstrup, 1999</xref>; <xref ref-type="bibr" rid="c30">Portfors and Felix, 2005</xref>; <xref ref-type="bibr" rid="c6">Brimijoin and O’Neill, 2010</xref>; <xref ref-type="bibr" rid="c43">Wenstrup et al., 2012</xref>). Finally, previous work has already shown that CGF structure in the auditory thalamus is similar to that observed in the auditory cortex, with small differences in the temporal extent of delayed suppression (<xref ref-type="bibr" rid="c45">Williamson et al., 2016</xref>). Cortical sensitivity to acoustic context could therefore be predominantly inherited from strongly stimulus-driven, sound-combination-sensitive subcortical inputs — a scenario consistent with both the stability of CGF structure over time and the small effect sizes observed for variation in model fits with spontaneous changes in behavioral state.</p>
<p>Second: computationally, our results call into question common assumptions about sound representation in the auditory cortex — which are implicit in all studies that have used linear spectrotemporal receptive field (STRF) models or linear-nonlinear (LN) models to describe cortical responses to complex sounds (e.g., <xref ref-type="bibr" rid="c21">Linden et al., 2003</xref>; <xref ref-type="bibr" rid="c11">Depireux et al., 2001</xref>; <xref ref-type="bibr" rid="c33">Rabinowitz et al., 2011</xref>; <xref ref-type="bibr" rid="c4">Atencio et al., 2008</xref>, and many others). Contrary to the assumptions of STRF and LN models, neurons in the auditory cortex do not linearly combine sound information across points in spectrotemporal space, applying any nonlinear transformations only after the linear combination of sound inputs. Rather, sound inputs are integrated <italic>nonlinearly</italic> across spectrotemporal space, as demonstrated by the robustness and stability of CGF structure. These input nonlinearities cannot be captured by either STRF or LN models. Of course, the nonlinear-linear (NL) CGF/PRF context model also has limitations; for example, it assumes that the same pattern of combination sensitivity applies to all regions of spectrotemporal space (see <xref ref-type="bibr" rid="c45">Williamson et al., 2016</xref>, for evidence supporting this assumption), and it does not currently incorporate known output nonlinearities such as variable spiking thresholds. Alternative approaches using nonlinear-linear frameworks have made different assumptions, but reached similar conclusions regarding the relevance of input nonlinearities to complex sound encoding in the auditory cortex (<xref ref-type="bibr" rid="c10">David et al., 2009</xref>; <xref ref-type="bibr" rid="c29">Pienkowski and Eggermont, 2010</xref>; <xref ref-type="bibr" rid="c18">Harper et al., 2016</xref>; <xref ref-type="bibr" rid="c22">Lopez Espejo et al., 2019</xref>). As famously noted by Box, all models are approximations and therefore wrong, but some are useful (<xref ref-type="bibr" rid="c5">Box, 1979</xref>). The CGF/PRF model is useful because it reveals that nonlinear combination sensitivity is a robust and stable feature of the neural code for complex sounds in auditory cortical neurons.</p>
<p>Finally, the third and most fundamental implication of our results is that the traditional concept of a sensory “receptive field” is misleading, at least for auditory cortical neurons. A sensory receptive field is typically defined as encompassing the region of sensory space where stimuli evoke changes in the spiking activity of a neuron. Early discoveries in visual neuroscience led to an expansion of this definition to include the concepts of a “classical” (driving) and surrounding “non-classical” (modulatory) receptive field (for a recent review, see <xref ref-type="bibr" rid="c2">Angelucci et al., 2017</xref>). However, even this expanded definition of a receptive field is inadequate for describing the robust and pervasive nonlinear sensitivity to sound combinations revealed in the CGFs. Auditory cortical receptive fields are better defined as nonlinear (and therefore context-dependent) filters with stable sensitivities both to individual sensory inputs and to particular combinations of those inputs within a region of sensory space. This alternative conceptualization of a sensory receptive field may be more accurate not only for auditory cortical neurons but also for neurons in other brain areas and sensory systems.</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Animals</title>
<p>A total of 8 male CBA/Ca mice were initially implanted for experiments, and 4 provided sufficient amounts of well-targeted auditory cortex data over months of recording for this study. We used CBA/Ca mice because this strain maintains excellent hearing in adulthood and is therefore a commonly used strain for studies of normal auditory brain function. Following the implantation surgery at 8–12 weeks of age, the mice were singly housed in standard mouse housing rooms, in specially designed cages for mice with implants. Mice were put on a 12-hour reversed light-dark cycle and were provided with food and water ad libitum. Recordings were conducted in each mouse for 3–5 months. All surgical, recording, and housing procedures were performed under a licence approved by the UK Home Office in accordance with the United Kingdom Animals (Scientific Procedures) Act of 1986.</p>
</sec>
<sec id="s4b">
<title>Chronic tetrode implants</title>
<p>Chronic tetrode implants were custom-made using a microdrive (Axona; UK). A connector (OMNET-ICS; USA) with 34 pins was attached using dental cement. Eight tetrodes each made of 4 strands of 17μm thick platinum 10% iridium wire (California Fine Wire Company; USA) were attached to the connector, with the two remaining pins used for grounding. Tetrodes were plated with platinum to an impedance of 150 kΩ before implantation, and advanced together into the brain using the microdrive.</p>
</sec>
<sec id="s4c">
<title>Surgery</title>
<p>Mice were chronically implanted with both the tetrode microdrive and a head fixation ring at 8 to 12 weeks of age. The animals were anesthetized with 1.0–3.0% isofluorane and received perioperative and post-operative analgesia (carprofen 5 mg/kg) and post-operative hydration with 0.1 ml warmed saline. A bone screw was inserted in an anterolateral position relative to bregma for a grounding wire. Then, a small craniotomy for the tetrode implant was made over the left hemisphere 2.9 mm lateral and 2.6 mm posterior to bregma. The tetrode bundle was inserted into the brain at an angle of 24<sup>º</sup>to vertical to allow for a roughly tangential microdrive trajectory through the auditory cortex. The initial depth of tetrode bundle insertion along this trajectory was no more than 3.5 mm relative to to the skull surface at bregma; tetrodes were subsequently advanced fully into core auditory cortex using the microdrive after the animal recovered from the surgery. The microdrive, bone screw, and a head fixation ring were secured to the skull using Superbond (C&amp;B Sun Medical; Japan) and dental cement. The grounding wire attached to the bone screw was then soldered to the ground pin on the implant. Following surgery, mice were allowed 2 weeks to recover and acclimatize to head fixation before the commencement of experiments.</p>
</sec>
<sec id="s4d">
<title>Calibration</title>
<p>As shown in <xref rid="fig1" ref-type="fig">Figure 1</xref>, the speaker was directed at the animal’s right ear during experiments, and auditory cortical recordings were made from the left hemisphere. Approximately every month, acoustic stimuli were calibrated with a G.R.A.S. 1/4” microphone positioned where the opening of the animal’s right ear would be during experiments. Calibrations were performed with a G.R.A.S. microphone amplifier and preamplifier (Models 12AA and 26AC). Typically, the calibration ensured that the frequency response of the sound system was flat to within ±2 dB over at least a 5–40 kHz range (more typically, 2–80 kHz). The microphone response was periodically calibrated using a Svantek sound level calibrator emitting a 1 kHz tone at 94 or 114 dB SPL.</p>
</sec>
<sec id="s4e">
<title>Stimuli</title>
<p>A typical neuronal recording session involved presentation of two identically repeated series of stimuli (called here a “segment”). Each segment consisted of 3 different stimuli separated from each other by 5 seconds of silence. The stimuli were:</p>
<list list-type="bullet">
<list-item><p>Noise bursts of varying duration and inter-onset timing (used primarily for a separate study and not discussed further here).</p></list-item>
<list-item><p>Tone sequences: 10 trials per frequency/intensity combination; tone length 100 ms with 5-ms cosine ramp rise/fall; 20 frequencies equally spaced between 5 kHz and 40 kHz; intensities 40, 50, 60 or 70 dB SPL each with an equal chance; tones of different frequency/intensity combinations presented in a random order.</p></list-item>
<list-item><p>Dynamic Random Chord (DRC) stimulus: 15 continuous repetitions of a 45-s-long DRC trial; chords composed of 20-ms tone pips with 5-ms cosine ramp rise/fall; tone pip frequencies 5–40 kHz in 1/12-octave increments; tone pip intensities 25–70 dB SPL in 5 dB increments; average density 6 tones per chord, or 2 tone pips/octave.</p></list-item>
</list>
<p>See <xref rid="fig1" ref-type="fig">Figure 1</xref> for illustrations of the stimuli and the recording set-up.</p>
</sec>
<sec id="s4f">
<title>Experimental set-up</title>
<p>Recordings were performed in a sound-attenuating box. Stimuli were generated in Python and converted to analog signals with a sound card (HDSPe AIO; RME; Germany), amplified using a power amplifier (RB-971; ROTEL; Japan) and passed through an attenuator (PA5; Tucker-Davis Technologies; USA) for presentation via a loudspeaker (XT25TG30-04; Peerless Vifa; USA) located approximately 12 cm to the right of the animal’s right ear.</p>
<p>Neural activity was recorded using a 32-channel Intan RHD 2132 amplifier board (hardware bandpass filtering between 1.1 and 7603.8 Hz; Intan Technologies; California, USA), connected to an Open Ephys acquisition board (available from <ext-link ext-link-type="uri" xlink:href="http://www.open-ephys.org">www.open-ephys.org</ext-link>) via an ultra-thin, serial peripheral interface (SPI) cable (RHD2000; Intan Technologies; California, USA). Tetrode recordings were sampled at 30 kHz. The Open Ephys GUI was used to visualize the local field potential and the raw signal was recorded after passing through a bandpass filter of 6-6000 Hz.</p>
<p>A camera was used to record a close-up around the right eye of the mouse, and a second camera recorded the a profile view of the mouse from the right side. Cameras had a sampling frequency of 30 frames/s. Infrared light was added as well as dim visible light in order to keep the pupil diameter at an appropriate level for tracing light-independent changes in pupil size.</p>
<p>The mouse was allowed to run on a custom styrofoam cylinder (20 cm in diameter; 11.5 cm in width; ball-bearing mounted axis) while head-fixed throughout the experiment. A rotary encoder (1024 steps per rotation; Kubler; Germany) was fitted onto the axis of the polystyrene wheel to allow for measurement of the running speed of the mouse during the experiment. Rotation steps were extracted using a microcontroller (Arduino Uno; Farnell; UK) and the running signal was synchronized to neuronal recordings by connecting the microcontroller output onto the Open Ephys data acquisition board.</p>
</sec>
<sec id="s4g">
<title>Experimental procedures</title>
<p>Mice were accustomed to handling for 2–3 days, acclimatized to the set-up for a further 2–3 days, and finally habituated to increasingly longer periods of head-fixation (from 5 to 30–60 minutes with a daily addition of 5 minutes) in the recording booth. To assess stability of spectrotemporal tuning and contextual sensitivity in auditory cortical neurons across many days, we designed a long experiment where we recorded the neural signal from the same site in the auditory cortex on at least five different (not necessarily consecutive) days, and then advanced the tetrode by 62.5 microns to a new recording site in order to repeat the process (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). Locomotor activity and pupil size were continuously recorded along with auditory cortical activity. We recorded from up to 10 recording sites in each mouse. From initial tetrode implantation to the end of recordings, experiments were 3-5 months long for each mouse.</p>
</sec>
<sec id="s4h">
<title>Data pre-processing</title>
<p>Signals collected from the auditory cortical recordings were spike-sorted using software written in MATLAB (<xref ref-type="bibr" rid="c36">Sahani, 1999</xref>). The spike-sorting procedure was conducted as follows. First, during the automatic phase, the software would use thresholding to identify potential spikes, then whitened Principal Component Analysis to reduce dimensionality of the data and identify the 4 dimensions which accounted for most of the variance in the waveform shapes. A mixture-of-Gaussians model was then fit to the spike data in the space defined by the 4 principal components. Then, in a later manual phase, the user evaluated the automatically identified clusters to confirm classification as a single unit, multi-unit, or noise, taking into account the following metrics provided by the software.</p>
<list list-type="bullet">
<list-item><p>The false positive rate and the false negative rate (i.e., the predictions from the mixture-of-Gaussians model for misclassification of spike waveforms inside and outside each cluster). We required that both these rates were below 0.05; otherwise the cluster would be labelled noise.</p></list-item>
<list-item><p>Graphical representations of the clusters. Each cluster was represented in 10 different plots (because of the 10 possible combinations between the 4 principal components calculated). If the clusters were not well separated from the noise cluster they were labelled noise. If two or more clusters were superimposed onto each other in all plots, then they were merged.</p></list-item>
<list-item><p>The waveform shapes for the spikes of each cluster. In rare cases the user would re-classify as noise an automatically identified “unit” cluster for which the waveform shape seemed biologically implausible. For example, if the waveform shape had qualities reminiscent of electrical noise or if it seemed inconsistent between spikes, or if it looked exactly the same across the four channels, then the user would take this into account in deciding how to label the cluster.</p></list-item>
<list-item><p>Auto-correlograms and cross-correlograms comparing the firing of any two clusters. Cross-correlograms were helpful in identifying clusters that required merging with one another. Auto-correlograms allowed us to decided whether clusters representing genuine neural activity were in fact single units or multi-unit activity. Clusters were labelled as single units when the autocorrelogram showed no firing in the first 2-ms bin after the cluster had just fired. Otherwise, the cluster would be labelled as multi-unit activity.</p></list-item>
</list>
</sec>
<sec id="s4i">
<title>Identifying core auditory areas</title>
<p>Following conventions used previously in other studies of mouse auditory cortex (including <xref ref-type="bibr" rid="c45">Williamson et al., 2016</xref>), we imposed two physiological criteria in order identify recording sites in “core” auditory areas (i.e., primary auditory cortex and anterior auditory field):</p>
<list list-type="order">
<list-item><p>A significantly altered firing rate in the first 50 ms following a tone presentation, based on a Wilcoxon test conducted between the firing rates of the unit in interest in the 50 ms before and after stimulus onset in each trial presented. Only cases with significant differences (<italic>p</italic> &lt; 0.01) were deemed core auditory cells.</p></list-item>
<list-item><p>A response latency smaller than 20 ms. The latency was marked as the first 2-ms bin where the response of the cell deviated from the mean spontaneous firing rate (as estimated from the 50 ms before stimulus presentation) by 3 or more times the standard deviation of the spontaneous firing rate.</p></list-item></list>
<p>Units recorded from the same tetrode and same location at the same time as as another unit which directly met these criteria were also designated as core auditory. Therefore, consistent with the approach used in most studies of auditory cortex, the core auditory dataset included both units that met the classic physiological criteria themselves, and neighbouring units that did not.</p>
</sec>
<sec id="s4j">
<title>Spike-waveform matching</title>
<p>We used a spike-waveform-matching technique previously described in <xref ref-type="bibr" rid="c41">Tolias et al. (2007</xref>) to match units found in discontinuous recordings from the same sites. We compared each unit to all units identified on the same tetrode and at the same depth.</p>
<p>Let us consider two example tetrode waveforms to be compared to each other: <italic>X</italic> and <italic>Y</italic> . <italic>X</italic> was first scaled by a factor <italic>α</italic> so as to minimize the sum of squared differences between the two waveforms. Two different metrics were then computed (here referred to as <italic>d</italic><sub>1</sub> and <italic>d</italic><sub>2</sub>). <italic>d</italic><sub>1</sub> is the normalized Euclidean distance between the scaled waveforms which therefore represents a metric of the difference in shape that exists between the two waveforms:
<disp-formula id="ueqn1">
<graphic xlink:href="537782v2_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>α</italic>(<italic>x, y</italic>) = <italic>arg</italic><sub><italic>α</italic></sub><italic>min</italic> ‖ <italic>αx</italic> − <italic>y</italic>‖<sup>2</sup>, and where the sum is over the four channels of the tetrode. <italic>d</italic><sub>2</sub> is defined as:
<disp-formula id="ueqn2">
<graphic xlink:href="537782v2_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
and it captures the difference in the amplitudes across the four channels. As in <xref ref-type="bibr" rid="c41">Tolias et al. (2007</xref>), in order to make these measures symmetric we used <italic>d</italic><sub>1</sub>(<italic>X, Y</italic>) + <italic>d</italic><sub>1</sub>(<italic>Y, X</italic>) for the shape factor and <italic>d</italic><sub>2</sub>(<italic>X, Y</italic>) + <italic>d</italic><sub>2</sub>(<italic>Y, X</italic>) for the scaling factor.</p>
<p>We established a null distribution which consisted of comparisons between units identified on the same tetrode but which were recorded from locations at least 250 μm apart from each other (i.e.: units which were definitely not matches). To compare the two distributions in one dimension we fitted a mixture of two Gaussians model (m) to the experimental data:
<disp-formula id="ueqn3">
<graphic xlink:href="537782v2_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where μ<sub><italic>i</italic></sub> and <italic>Q</italic><sub><italic>i</italic></sub> represent the mean and covariance matrix of the <italic>i</italic><sup>th</sup> component which is normally distributed.</p>
<p>The parameters of one of the two Gaussians in the model were fixed to those which described the null distribution obtained earlier, and the others were learnt using an Expectation-Maximization algorithm. This second Gaussian therefore describes the distribution of possible matches. We then took as confirmed matches the waveform comparisons which fell within the 99% confidence interval of the distribution of possible matches and outside the 99% confidence interval of the null distribution. Using these stringent criteria we aimed to minimize the false positives, and maximise the chances that matched recordings truly originated from the same unit.</p>
</sec>
<sec id="s4k">
<title>Context model fitting</title>
<p>For context model analysis, we required that core auditory units met three additional physiological criteria related specifically to their responses to the DRC stimulus.</p>
<list list-type="bullet">
<list-item><p>Each unit’s DRC responses had to have signal power at least one standard error greater than zero. Context models can be fit effectively only to units which show stimulus-dependent variation in their responses to the DRC stimulus (i.e., non-zero signal power).</p></list-item>
<list-item><p>Firing rate over all trials had to be greater than or equal to 5 spikes/s. When neurons fire very infrequently this leads to highly sparse matrices which create issues with the fitting of the model.</p></list-item>
<list-item><p>Normalized noise power had to be below below 40. This was a criterion put in place to remove outliers with excessive noise power.</p></list-item>
</list>
<p>Mathematically, the context model generates predictions for the response (<italic>r</italic>) of a neuron to a given sound (<italic>s</italic>) with spectrotemporal energy at time t in frequency channel f, as follows:
<disp-formula id="ueqn4">
<graphic xlink:href="537782v2_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where the constant <italic>c</italic> sets a baseline firing rate, <italic>w</italic><sup><bold>tf</bold></sup> is the PRF field with summation limits over time shifts (t) and frequency (f), and <italic>w</italic><sup><italic>τϕ</italic></sup> is the CGF field and the summation limits are over relative time shift (<italic>τ</italic>) and relative frequency (<italic>ϕ</italic>). The CGF weight corresponding to zero time-frequency offset was fixed to 0; therefore no weight contributed to its own context, resulting in a linear STRF model prediction for presentations of isolated tones. For more details on the model and validation of its performance, see <xref ref-type="bibr" rid="c45">Williamson et al. (2016</xref>).</p>
    <p>The context model was fitted for each unit to the neuronal responses recorded during DRC segments. Typically we had 2 DRC stimuli of 15 trials each, per recording session, for each unit. The first DRC trial from each segment was discarded to minimize effects of level adaptation on context model fits. The fitting was done using Alternate Least Squares (ALS) as there were two fields whose parameters needed to be optimized (the PRF and the CGF). We used Automatic Smoothness Determination (ASD) (<xref ref-type="bibr" rid="c37">Sahani and Linden, 2002a</xref>) to find the best smoothing parameters for the PRFs. We then fixed those smoothing parameters for the PRF and then used a grid search method to find the best smoothing parameters for the CGF, because the ASD method did not reliably converge when both PRF and CGF smoothing were simultaneously optimized.</p>
<p>The grid search method involved running multiple fittings of the model with the PRF smoothing parameters fixed and each time changing the combination of the three smoothing parameters for the CGF. At the end we proceeded with the CGF smoothing parameters that provided the greatest cross-validation predictive power. The parameters we tried during the grid search method were the following: scaling parameter: (3, 6 and 9); spectral smoothing parameter: (2, 4, 6, 8, 10, 12) and temporal smoothing parameter: (1.5, 3.5, 5.5, 7.5, 9.5). These values were chosen for the grid search to try and cover as much parameter space as possible, but were centered around the parameter values that were most commonly observed in CGFs.</p>
<p>To ensure that differences in smoothing parameters did not confound assessments of field stability for each unit, we estimated optimal smoothing parameters for the context model for each unit using all the data available for the unit (i.e., all DRC recordings made across days). These optimal smoothing parameters for the unit were then applied to all context model fits based on individual DRC segments.</p>
</sec>
<sec id="s4l">
<title>Stability assessment</title>
<p>To evaluate similarity between fields (PRFs or CGFs) estimated in different DRC segments, we calculated the normalized dot product (i.e., zero-shift two-dimensional cross-correlation) between the fields, without subtraction of the mean matrix. The within-session field correlation was simply the correlation between the two fields estimated from the first and second DRC segment of a session respectively. The across-session field correlation was the average correlation across all four possible comparisons between the two DRC segments in each of the two recording sessions. We then constructed a similarity matrix for each unit which shows on the central diagonal the within-day, within-session field correlations and on the offset diagonals the across-day field correlations. The method is illustrated graphically in <xref rid="fig1" ref-type="fig">Figure 1D</xref> and for example neurons in <xref rid="fig4" ref-type="fig">Figure 4D-F</xref>.</p>
<p>For each unit, we then defined the within-session field similarity <italic>α</italic> to be the average withinsession field correlation for CGF (or PRF) estimates from all the unit’s recording sessions. Likewise, the across-session similarity <italic>β</italic> for sessions <italic>n</italic> days apart was defined as the average of all the unit’s across-session field correlation values for CGF (or PRF) estimates obtained from recordings made <italic>n</italic> days apart. We plotted these within-session and across-session field similarity values versus the number of days between recording sessions, and estimated the best-fit line to the data using weighted linear regression (taking into account the number of comparisons contributing to the averages <italic>α</italic> and <italic>β</italic>(<italic>n</italic>)). We used the slope of this best-fit line as our measure of the unit’s CGF (or PRF) stability for population analysis. This slope represents the average rate of change in CGF (or PRF) correlation as a function of time between recording sessions, but does not necessarily imply a gradual rate of change across chronological days of recording. It should be noted that similar slopes could be obtained from a gradual decline in field correlation over time and from a more abrupt drop on a particular day during the recording period for a unit.</p>
<p>We also examined CGF (and PRF) stability using a normalized field alignment index, where 1.0 represents within-session similarity for the unit and 0.0 indicates baseline similarity expected for comparisons with CGF (or PRF) estimates from other units. For each unit’s CGF (or PRF), we defined the field alignment index as <inline-formula><inline-graphic xlink:href="537782v2_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where <italic>α</italic> and <italic>β</italic> were calculated as above, and <italic>γ</italic> was a baseline field correlation measure obtained by comparing the CGF (or PRF) for the unit to those from other units recorded from the same animal. This normalized field alignment index was useful for comparing across-session to within-session stability and assessing persistence of neuron-specific CGF (or PRF) structure (<xref rid="fig5" ref-type="fig">Figure 5</xref>). However, unlike the raw field correlation values and field similarity measures <italic>α</italic> and <italic>β</italic>, the values of the normalized field alignment index were potentially unbounded and very noisy in units with poor within-session stability. For this reason, we used the field similarity measures rather than the normalized field alignment indices to derive the slope estimates used for population analyses of CGF and PRF stability (<xref rid="fig6" ref-type="fig">Figure 6</xref> and <xref rid="fig7" ref-type="fig">Figure 7</xref>).</p>
</sec>
<sec id="s4m">
<title>Pupil diameter extraction</title>
<p>For pupil tracking we used DeepLabCut (version 2) (<xref ref-type="bibr" rid="c24">Mathis et al., 2018</xref>; <xref ref-type="bibr" rid="c27">Nath et al., 2019</xref>), which leverages a ResNet-50-based convolutional neural network for predicting the location of a desired bodypart across frames. We labeled 80 frames taken from 4 videos (one from each animal), then used 95% of the video data for training. We trained for 1,030,000 iterations, validated with 1 shuffle and we report a test error of 3.38 pixels and a train error of 1.03 pixels (image size was 416 by 252). We then used a p-cutoff of 0.99 to condition the predicted coordinates, which served to exclude predictions for which the network was not certain, hence making our data more reliable. We used this network to analyze videos collected under very similar experimental conditions. During labelling, we marked 8 specific points: 6 points delineating the edges of the pupil and 2 at the left and right edges of the mouse’s eye.</p>
<p>We fit an ellipse on the pupil in each frame. We asserted that there had to be at least 5 out of 6 points in a frame in order for us to attempt to fit the ellipse. The major axis of the ellipse (in pixels) fitted to the pupil in that frame was then taken as the diameter of the pupil. Some videos were excluded after manual inspection due to poor quality of tracking.</p>
<p>We estimated the width of the eye opening during a recording as the median distance between the points marking the right and the left edge of the eye, which the network was also trained to detect. Finally, in our analyses we used the frame-wise pupil diameter, obtained as explained above and normalized by the median length of the eye in each recording, meaning that our measurements are not influenced by small perturbations in the positioning and angling of the camera relative to the animal’s eye from day to day of experimentation.</p>
</sec>
<sec id="s4n">
<title>Analysis of effects of locomotor activity and pupil dilation</title>
<p>To assess the effects of locomotor activity and pupil dilation on context model performance we divided the timebin-by-timebin data for each unit into categories of still versus moving, or small versus large pupil. More specifically, for the locomotor activity analysis, we divided all the 20-ms timebins from each recording with locomotor activity data into two categories: (i) timebins when the mouse was still (speed = 0.0; 36.0% for the average unit, standard deviation 15.1%), or (ii) timebins when the speed of the mouse was non-zero (62.7% of timebins for the average unit, standard deviation 16.3%). Results of the residuals analysis were similar when we used a higher speed threshold for the still/moving categorization (e.g., with threshold 0.5 cm/s, 83.3% timebins categorized as still, 15.3% as moving, standard deviation 12.5% and 11.6% respectively). For the pupil size analysis, we divided all the timebins into two categories: (i) timebins when the pupil was more dilated than the median pupil size for all sessions for the unit, or (ii) timebins when the pupil was smaller than the median. Since this categorization was performed relative to the median pupil size, equal percentages of timebins fell into the two categories.</p>
<p>We then calculated the residual from the context model prediction of the firing rate in each timebin (observed minus predicted firing rate), and computed the interquartile range and median of the residual distributions for the different timebin categories for each unit. The IQRs and medians for the residual distributions with and without locomotor activity or pupil dilation were then compared across units in population analysis (<xref rid="fig8" ref-type="fig">Figure 8</xref> and <xref rid="figS2" ref-type="fig">Supplementary Figure 2</xref>). Note that we used the actual signed residual rather than the absolute residual, in order to distinguish cases in which the observed firing rates were either higher or lower than predicted. Further interpretation of these measures is provided in the main text.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>This work was supported by the Biotechnology and Biological Sciences Research Council (BB/P007201/1, JFL); the London Interdisciplinary Doctoral Programme (MA); the Simons Foundation (SCGB543039, MS); and the Gatsby Charitable Foundation (MS). We would also like to thank Simon Rumpel for constructive discussions which helped us to improve this manuscript. These discussions were enabled by a workshop supported by grant NSF PHY-1748958 to the Kavli Institute for Theoretical Physics (KITP).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Ahrens</surname> <given-names>MB</given-names></string-name>, <string-name><surname>Linden</surname> <given-names>JF</given-names></string-name>, <string-name><surname>Sahani</surname> <given-names>M.</given-names></string-name> <article-title>Nonlinearities and contextual influences in auditory cortical responses modeled with multilinear spectrotemporal methods</article-title>. <source>Journal of Neuroscience</source>. <year>2008</year> <month>Feb</month>; <volume>28</volume>(<issue>8</issue>):<fpage>1929</fpage>–<lpage>1942</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Angelucci</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bijanzadeh</surname> <given-names>M</given-names></string-name>, <string-name><surname>Nurminen</surname> <given-names>L</given-names></string-name>, <string-name><surname>Federer</surname> <given-names>F</given-names></string-name>, <string-name><surname>Merlin</surname> <given-names>S</given-names></string-name>, <string-name><surname>Bressloff</surname> <given-names>PC</given-names></string-name>. <article-title>Circuits and mechanisms for surround modulation in visual cortex</article-title>. <source>Annual Review of Neuroscience</source>. <year>2017</year> <month>Jul</month>; <volume>40</volume>:<fpage>425</fpage>–<lpage>451</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Aschauer</surname> <given-names>DF</given-names></string-name>, <string-name><surname>Eppler</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Ewig</surname> <given-names>L</given-names></string-name>, <string-name><surname>Chambers</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Pokorny</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kaschube</surname> <given-names>M</given-names></string-name>, <string-name><surname>Rumpel</surname> <given-names>S.</given-names></string-name> <article-title>Learning-induced biases in the ongoing dynamics of sensory representations predict stimulus generalization</article-title>. <source>Cell Reports</source>. <year>2022</year> <month>Feb</month>; <volume>38</volume>(<issue>6</issue>):<fpage>110340</fpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Atencio</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Sharpee</surname> <given-names>TO</given-names></string-name>, <string-name><surname>Schreiner</surname> <given-names>CE</given-names></string-name>. <article-title>Cooperative nonlinearities in auditory cortical neurons</article-title>. <source>Neuron</source>. <year>2008</year> <month>Jun</month>; <volume>58</volume>(<issue>6</issue>):<fpage>956</fpage>–<lpage>966</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="book"><string-name><surname>Box</surname> <given-names>GEP</given-names></string-name>. <chapter-title>Robustness in the Strategy of Scientific Model Building</chapter-title>. <source>In: Robustness in Statistics Elsevier</source>; <year>1979</year>. p. <fpage>201</fpage>–<lpage>236</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Brimijoin</surname> <given-names>WO</given-names></string-name>, <string-name><surname>O’Neill</surname> <given-names>WE</given-names></string-name>. <article-title>Patterned tone sequences reveal non-linear interactions in auditory spectrotemporal receptive fields in the inferior colliculus</article-title>. <source>Hearing Research</source>. <year>2010</year> <month>Aug</month>; <volume>267</volume>(<issue>1-2</issue>):<fpage>96</fpage>–<lpage>110</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Chambers</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Aschauer</surname> <given-names>DF</given-names></string-name>, <string-name><surname>Eppler</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Kaschube</surname> <given-names>M</given-names></string-name>, <string-name><surname>Rumpel</surname> <given-names>S.</given-names></string-name> <article-title>A stable sensory map emerges from a dynamic equilibrium of neurons with unstable tuning properties</article-title>. <source>Cerebral Cortex</source>. <year>2022</year> <month>Nov</month>; <volume>33</volume>(<issue>9</issue>):<fpage>5597</fpage>–<lpage>562</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Clopath</surname> <given-names>C</given-names></string-name>, <string-name><surname>Bonhoeffer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Hübener</surname> <given-names>M</given-names></string-name>, <string-name><surname>Rose</surname> <given-names>T.</given-names></string-name> <article-title>Variance and invariance of neuronal long-term representations</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>. <year>2017</year> <month>Mar</month>; <volume>372</volume>(<issue>1715</issue>):<fpage>20160161</fpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>David</surname> <given-names>SV</given-names></string-name>, <string-name><surname>Fritz</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>. <article-title>Task reward structure shapes rapid receptive field plasticity in auditory cortex</article-title>. <source>Proceedings of the National Academy of Sciences U S A</source>. <year>2012</year> <month>Feb</month>; <volume>109</volume>(<issue>6</issue>):<fpage>2144</fpage>–<lpage>2149</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>David</surname> <given-names>SV</given-names></string-name>, <string-name><surname>Mesgarani</surname> <given-names>N</given-names></string-name>, <string-name><surname>Fritz</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>. <article-title>Rapid synaptic depression explains nonlinear modulation of spectro-temporal tuning in primary auditory cortex by natural stimuli</article-title>. <source>Journal of Neuroscience</source>. <year>2009</year> <month>Mar</month>; <volume>29</volume>(<issue>11</issue>):<fpage>3374</fpage>–<lpage>3386</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Depireux</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Simon</surname> <given-names>JZ</given-names></string-name>, <string-name><surname>Klein</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>. <article-title>Spectro-temporal response field characterization with dynamic ripples in ferret primary auditory cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2001</year> <month>Mar</month>; <volume>85</volume>(<issue>3</issue>):<fpage>1220</fpage>–<lpage>1234</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Driscoll</surname> <given-names>LN</given-names></string-name>, <string-name><surname>Duncker</surname> <given-names>L</given-names></string-name>, <string-name><surname>Harvey</surname> <given-names>CD</given-names></string-name>. <article-title>Representational drift: emerging theories for continual learning and experimental future directions</article-title>. <source>Current Opinion in Neurobiology</source>. <year>2022</year> <month>Oct</month>; <volume>76</volume>(<issue>102609</issue>):<fpage>102609</fpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Elhilali</surname> <given-names>M</given-names></string-name>, <string-name><surname>Fritz</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Chi</surname> <given-names>TS</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>. <article-title>Auditory cortical receptive fields: stable entities with plastic abilities</article-title>. <source>Journal of Neuroscience</source>. <year>2007</year> <month>Sep</month>; <volume>27</volume>(<issue>39</issue>):<fpage>10372</fpage>–<lpage>10382</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Englitz</surname> <given-names>B</given-names></string-name>, <string-name><surname>Ahrens</surname> <given-names>M</given-names></string-name>, <string-name><surname>Tolnai</surname> <given-names>S</given-names></string-name>, <string-name><surname>bsamen</surname> <given-names>R</given-names></string-name>, <string-name><surname>Sahani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jost</surname> <given-names>J.</given-names></string-name> <article-title>Multilinear models of single cell responses in the medial nucleus of the trapezoid body</article-title>. <source>Network</source>. <year>2010</year>; <volume>21</volume>(<issue>1-2</issue>):<fpage>91</fpage>–<lpage>124</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Fritz</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Elhilali</surname> <given-names>M</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>. <article-title>Differential dynamic plasticity of A1 receptive fields during multiple spectral tasks</article-title>. <source>Journal of Neuroscience</source>. <year>2005</year> <month>Aug</month>; <volume>25</volume>(<issue>33</issue>):<fpage>7623</fpage>–<lpage>7635</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Fritz</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Elhilali</surname> <given-names>M</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>. <article-title>Auditory attention—focusing the searchlight on sound</article-title>. <source>Current Opinion in Neurobiology</source>. <year>2007</year> <month>Aug</month>; <volume>17</volume>(<issue>4</issue>):<fpage>437</fpage>–<lpage>455</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Grana</surname> <given-names>GD</given-names></string-name>, <string-name><surname>Billimoria</surname> <given-names>CP</given-names></string-name>, <string-name><surname>Sen</surname> <given-names>K.</given-names></string-name> <article-title>Analyzing variability in neural responses to complex natural sounds in the awake songbird</article-title>. <source>Journal of Neurobiology</source>. <year>2009</year> <month>Jun</month>; <volume>101</volume>(<issue>6</issue>):<fpage>3147</fpage>–<lpage>3157</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Harper</surname> <given-names>NS</given-names></string-name>, <string-name><surname>Schoppe</surname> <given-names>O</given-names></string-name>, <string-name><surname>Willmore</surname> <given-names>BD</given-names></string-name>, <string-name><surname>Cui</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Schnupp</surname> <given-names>JW</given-names></string-name>, <string-name><surname>King</surname> <given-names>AJ</given-names></string-name>. <article-title>Network receptive field modeling reveals extensive integration and multi-feature selectivity in auditory cortical neurons</article-title>. <source>PLoS Computational Biology</source>. <year>2016</year> <month>Nov</month>; <volume>12</volume>(<issue>11</issue>):<fpage>e1005113</fpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Irvine</surname> <given-names>DRF</given-names></string-name>. <article-title>Plasticity in the auditory system</article-title>. <source>Hearing Research</source>. <year>2018</year> <month>May</month>; <volume>362</volume>:<fpage>61</fpage>–<lpage>73</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Kato</surname> <given-names>H</given-names></string-name>, <string-name><surname>Gillet</surname> <given-names>S</given-names></string-name>, <string-name><surname>Isaacson</surname> <given-names>J.</given-names></string-name> <article-title>Flexible sensory representations in auditory cortex driven by behavioral relevance</article-title>. <source>Neuron</source>. <year>2015</year> <month>Dec</month>; <volume>88</volume>(<issue>5</issue>):<fpage>1027</fpage>–<lpage>1039</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Linden</surname> <given-names>JF</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Sahani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schreiner</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Merzenich</surname> <given-names>MM</given-names></string-name>. <article-title>Spectrotemporal structure of receptive fields in areas AI and AAF of mouse auditory cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2003</year> <month>Oct</month>; <volume>90</volume>(<issue>4</issue>):<fpage>2660</fpage>–<lpage>2675</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Lopez Espejo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schwartz</surname> <given-names>ZP</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>. <article-title>Spectral tuning of adaptation supports coding of sensory context in auditory cortex</article-title>. <source>PLoS Computational Biology</source>. <year>2019</year> <month>Oct</month>; <volume>15</volume>(<issue>10</issue>):<fpage>e1007430</fpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Marks</surname> <given-names>TD</given-names></string-name>, <string-name><surname>Goard</surname> <given-names>MJ</given-names></string-name>. <article-title>Stimulus-dependent representational drift in primary visual cortex</article-title>. <source>Nat Commun</source>. <year>2021</year> <month>Aug</month>; <volume>12</volume>(<issue>1</issue>):<fpage>5169</fpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Mathis</surname> <given-names>A</given-names></string-name>, <string-name><surname>Mamidanna</surname> <given-names>P</given-names></string-name>, <string-name><surname>Cury</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Abe</surname> <given-names>T</given-names></string-name>, <string-name><surname>Murthy</surname> <given-names>VN</given-names></string-name>, <string-name><surname>Mathis</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Bethge</surname> <given-names>M.</given-names></string-name> <article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title>. <source>Nature Neuroscience</source>. <year>2018</year> <month>Sep</month>; <volume>21</volume>(<issue>9</issue>):<fpage>1281</fpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>McGinley</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>, <string-name><surname>McCormick</surname> <given-names>DA</given-names></string-name>. <article-title>Cortical membrane potential signature of optimal states for sensory signal detection</article-title>. <source>Neuron</source>. <year>2015</year> <month>Jul</month>; <volume>87</volume>(<issue>1</issue>):<fpage>179</fpage>–<lpage>192</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Meyer</surname> <given-names>AF</given-names></string-name>, <string-name><surname>Williamson</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Linden</surname> <given-names>JF</given-names></string-name>, <string-name><surname>Sahani</surname> <given-names>M.</given-names></string-name> <article-title>Models of neuronal stimulus-response functions: elaboration, estimation, and evaluation</article-title>. <source>Frontiers in Systems Neuroscience</source>. <year>2017</year>; <volume>10</volume>:<fpage>109</fpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Nath</surname> <given-names>T</given-names></string-name>, <string-name><surname>Mathis</surname> <given-names>A</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Patel</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bethge</surname> <given-names>M</given-names></string-name>, <string-name><surname>Mathis</surname> <given-names>MW</given-names></string-name>. <article-title>Using DeepLabCut for 3D markerless pose estimation across species and behaviors</article-title>. <source>Nature Protocols</source>. <year>2019</year> <month>Jul</month>; <volume>14</volume>(<issue>7</issue>):<fpage>2152</fpage>–<lpage>2176</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Nelken</surname> <given-names>I</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Young</surname> <given-names>ED.</given-names></string-name> <article-title>Linear and nonlinear spectral integration in type IV neurons of the dorsal cochlear nucleus</article-title>. <source>II. Predicting responses with the use of nonlinear models. Journal of Neurophysiology</source>. <year>1997</year> <month>Aug</month>; <volume>78</volume>(<issue>2</issue>):<fpage>800</fpage>–<lpage>811</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Pienkowski</surname> <given-names>M</given-names></string-name>, <string-name><surname>Eggermont</surname> <given-names>JJ</given-names></string-name>. <article-title>Nonlinear cross-frequency interactions in primary auditory cortex spectrotemporal receptive fields: a Wiener-Volterra analysis</article-title>. <source>Journal of Computational Neuroscience</source>. <year>2010</year> <month>Apr</month>; <volume>28</volume>(<issue>2</issue>):<fpage>285</fpage>–<lpage>303</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Portfors</surname> <given-names>CV</given-names></string-name>, <string-name><surname>Felix</surname> <given-names>RA</given-names></string-name>. <article-title>Spectral integration in the inferior colliculus of the CBA/CaJ mouse</article-title>. <source>Neuroscience</source>. <year>2005</year>; <volume>136</volume>(<issue>4</issue>):<fpage>1159</fpage>–<lpage>1170</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Portfors</surname> <given-names>CV</given-names></string-name>, <string-name><surname>Wenstrup</surname> <given-names>JJ</given-names></string-name>. <article-title>Delay-tuned neurons in the inferior colliculus of the mustached bat: implications for analyses of target distance</article-title>. <source>Journal of Neurophysiology</source>. <year>1999</year> <month>Sep</month>; <volume>82</volume>(<issue>3</issue>):<fpage>1326</fpage>–<lpage>1338</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Portfors</surname> <given-names>CV</given-names></string-name>, <string-name><surname>Wenstrup</surname> <given-names>JJ</given-names></string-name>. <article-title>Responses to combinations of tones in the nuclei of the lateral lemniscus</article-title>. <source>Journal of the Association for Research in Otolaryngology</source>. <year>2001</year> <month>Jun</month>; <volume>2</volume>(<issue>2</issue>):<fpage>104</fpage>–<lpage>117</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Rabinowitz</surname> <given-names>N</given-names></string-name>, <string-name><surname>Willmore</surname> <given-names>BB</given-names></string-name>, <string-name><surname>Schnupp</surname> <given-names>JH</given-names></string-name>, <string-name><surname>King</surname> <given-names>A.</given-names></string-name> <article-title>Contrast gain control in auditory cortex</article-title>. <source>Neuron</source>. <year>2011</year> <month>Jun</month>; <volume>70</volume>(<issue>6</issue>):<fpage>1178</fpage>–<lpage>1191</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Ranson</surname> <given-names>A.</given-names></string-name> <article-title>Stability and Plasticity of Contextual Modulation in the Mouse Visual Cortex</article-title>. <source>Cell Rep</source>. <year>2017</year> <month>Jan</month>; <volume>18</volume>(<issue>4</issue>):<fpage>840</fpage>–<lpage>848</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Reimer</surname> <given-names>J</given-names></string-name>, <string-name><surname>Froudarakis</surname> <given-names>E</given-names></string-name>, <string-name><surname>Cadwell</surname> <given-names>CR</given-names></string-name>, <string-name><surname>Yatsenko</surname> <given-names>D</given-names></string-name>, <string-name><surname>Denfield</surname> <given-names>GH</given-names></string-name>, <string-name><surname>Tolias</surname> <given-names>AS</given-names></string-name>. <article-title>Pupil fluctuations track fast switching of cortical states during quiet wakefulness</article-title>. <source>Neuron</source>. <year>2014</year> <month>Oct</month>; <volume>84</volume>(<issue>2</issue>):<fpage>355</fpage>–<lpage>362</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="book"><string-name><surname>Sahani</surname> <given-names>M.</given-names></string-name> <article-title>Latent Variable Models for Neural Data Analysis</article-title>. <source>Caltech</source>. <year>1999</year>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="book"><string-name><surname>Sahani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Linden</surname> <given-names>J.</given-names></string-name> <chapter-title>Evidence optimization techniques for estimating stimulus-response functions</chapter-title>. <source>In: Advances in Neural Information Processing Systems</source>, vol. <volume>15</volume> <publisher-name>MIT Press</publisher-name>; <year>2002a</year>. p. <fpage>301</fpage>–<lpage>308</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="book"><string-name><surname>Sahani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Linden</surname> <given-names>J.</given-names></string-name> <chapter-title>How linear are auditory cortical responses?</chapter-title> <source>In: Advances in Neural Information Processing Systems</source>, vol. <volume>15</volume> <publisher-name>MIT Press</publisher-name>; <year>2002b</year>. p. <fpage>109</fpage>–<lpage>116</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Schneider</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Nelson</surname> <given-names>A</given-names></string-name>, <string-name><surname>Mooney</surname> <given-names>R.</given-names></string-name> <article-title>A synaptic and circuit basis for corollary discharge in the auditory cortex</article-title>. <source>Nature</source>. <year>2014</year> <month>Sep</month>; <volume>513</volume>(<issue>7517</issue>):<fpage>189</fpage>–<lpage>194</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Schwartz</surname> <given-names>ZP</given-names></string-name>, <string-name><surname>Buran</surname> <given-names>BN</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>. <article-title>Pupil-associated states modulate excitability but not stimulus selectivity in primary auditory cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2020</year> <month>Jan</month>; <volume>123</volume>(<issue>1</issue>):<fpage>191</fpage>–<lpage>208</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Tolias</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Ecker</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Siapas</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Hoenselaar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Keliris</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Logothetis</surname> <given-names>NK</given-names></string-name>. <article-title>Recording chronically from the same neurons in awake, behaving primates</article-title>. <source>Journal of Neurophysiology</source>. <year>2007</year> <month>Dec</month>; <volume>98</volume>(<issue>6</issue>):<fpage>3780</fpage>–<lpage>3790</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Weinberger</surname> <given-names>NM</given-names></string-name>. <article-title>Associative representational plasticity in the auditory cortex: A synthesis of two disciplines</article-title>. <source>Learning &amp; Memory</source>. <year>2007</year> <month>Jan</month>; <volume>14</volume>(<issue>1-2</issue>):<fpage>1</fpage>–<lpage>16</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Wenstrup</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Nataraj</surname> <given-names>K</given-names></string-name>, <string-name><surname>Sanchez</surname> <given-names>JT</given-names></string-name>. <article-title>Mechanisms of spectral and temporal integration in the mustached bat inferior colliculus</article-title>. <source>Frontiers in Neural Circuits</source>. <year>2012</year>; <volume>6</volume>:<fpage>75</fpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Williams</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Rennaker</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Kipke</surname> <given-names>DR</given-names></string-name>. <article-title>Stability of chronic multichannel neural recordings: Implications for a long-term neural interface</article-title>. <source>Neurocomputing</source>. <year>1999</year> <month>Jun</month>; <volume>26-27</volume>:<fpage>1069</fpage>–<lpage>1076</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Williamson</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Ahrens</surname> <given-names>MB</given-names></string-name>, <string-name><surname>Linden</surname> <given-names>JF</given-names></string-name>, <string-name><surname>Sahani</surname> <given-names>M.</given-names></string-name> <article-title>Input-specific gain modulation by local sensory context shapes cortical and thalamic responses to complex sounds</article-title>. <source>Neuron</source>. <year>2016</year> <month>Jul</month>; <volume>91</volume>(<issue>2</issue>):<fpage>467</fpage>–<lpage>481</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Williamson</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Polley</surname> <given-names>DB</given-names></string-name>. <article-title>Parallel pathways for sound processing and functional connectivity among layer 5 and 6 auditory corticofugal neurons</article-title>. <source>eLife</source>. <year>2019</year> <month>Feb</month>; <volume>8</volume>:<fpage>e42974</fpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Witte</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Otto</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Williams</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Kipke</surname> <given-names>DR</given-names></string-name>. <article-title>Pursuing dynamic reorganization in auditory cortex using chronic, multichannel unit recordings in awake, behaving cats</article-title>. <source>Neurocomputing</source>. <year>1999</year> <month>Jun</month>; <volume>26-27</volume>:<fpage>593</fpage>–<lpage>600</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Yu</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Young</surname> <given-names>ED.</given-names></string-name> <article-title>Linear and nonlinear pathways of spectral information transmission in the cochlear nucleus</article-title>. <source>Proceedings of the National Academy of Sciences U S A</source>. <year>2000</year> <month>Oct</month>; <volume>97</volume>(<issue>22</issue>):<fpage>11780</fpage>–<lpage>11786</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname> <given-names>X</given-names></string-name>, <string-name><surname>Heinz</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Bruce</surname> <given-names>IC</given-names></string-name>, <string-name><surname>Carney</surname> <given-names>LH</given-names></string-name>. <article-title>A phenomenological model for the responses of auditory-nerve fibers: I</article-title>. <source>Nonlinear tuning with compression and suppression. Journal of the Acoustical Society of America</source>. <year>2001</year> <month>Feb</month>; <volume>109</volume>(<issue>2</issue>):<fpage>648</fpage>–<lpage>670</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Zilany</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Bruce</surname> <given-names>IC</given-names></string-name>, <string-name><surname>Nelson</surname> <given-names>PC</given-names></string-name>, <string-name><surname>Carney</surname> <given-names>LH</given-names></string-name>. <article-title>A phenomenological model of the synapse between the inner hair cell and auditory nerve: long-term adaptation with power-law dynamics</article-title>. <source>Journal of the Acoustical Society of America</source>. <year>2009</year> <month>Nov</month>; <volume>126</volume>(<issue>5</issue>):<fpage>2390</fpage>–<lpage>2412</lpage>.</mixed-citation></ref>
</ref-list>
<sec id="s5">
<title>Supplementary Figures</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><title>Core auditory cortical recording sites identified using physiological criteria.</title>
<p><bold>A-C</bold>. Three example units recorded from one animal. Left: raw waveform on each of the four tetrode channels. Middle: PSTH of the response of each unit to 100-ms pure tones, pooled across tone frequencies and intensities. Blue shading indicates time of tone presentation. All three units met the two criteria for classification as “core” auditory cortex: (1) robust responses to tone pips (significant difference in firing rate across trials between the 50 ms before and 50 ms after tone onset; Wilcoxon rank-sum test, <italic>p</italic> &lt; 0.01), and (2) response latency &lt;20 ms. Latency is indicated here with a red vertical line and was defined as the first time bin after tone onset where the firing rate fell outside the mean (dotted black line) ±3 standard deviations (grey shaded area) of the bin-by-bin firing rates in the 50 ms before tone onset. Right: Frequency-Response Areas (FRA). Top of each panel: frequency tuning profile averaged over all tone intensities. The grey and black lines indicate estimates of the frequency tuning profile obtained from two different runs of the tone-pip sequence separated by more than 20 minutes. The overlap of these two lines illustrates the consistency of frequency tuning estimates in units with the robust, short-latency responses typical of “core” auditory cortex.</p></caption>
<graphic xlink:href="537782v2_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Supplementary Figure 2.</label>
<caption><title>Effects of locomotor activity and pupil dilation on context model residual distributions and median residuals.</title>
<p><bold>A</bold>. 2D histograms of the context model residuals plotted against the model predictions when mice had: (i) non-zero speeds (leftmost plot); (ii) zero speed (still: middle left); (iii) a pupil diameter above the median diameter for the unit recordings (middle right); and (iv) a pupil diameter below the median diameter (rightmost plot). Pupil median diameters were calculated for each unit based on all data available from the relevant recording sessions. Plots show pooled data from all suitable timepoints in recordings from all mice. <bold>B-C</bold>. Scatter plots showing the median of the residuals when the mice were still versus moving (B) or when the pupil size was small versus large (C). Dotted black line indicates equal values. Note that median residuals were typically slightly negative, indicating that the context model tended to over-predict firing rates. Note also that median residuals were significantly more positive (i.e., in most cases, less negative) whenthe animal was moving or the pupil was large (Wilcoxon sign-rank tests: locomotion data, <italic>p</italic> = 1.8<italic>x</italic>10<sup>−24</sup>; pupil data, <italic>p</italic> = 3.7<italic>x</italic>10<sup>−14</sup>). Effect sizes were relatively small (Cohen’s <italic>d</italic>: locomotion data 0.23; pupil data 0.29), but not as tiny as for residual IQRs.</p></caption>
<graphic xlink:href="537782v2_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98415.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study provides <bold>important</bold> findings regarding the stability over time of the response properties of neurons in the auditory cortex, including their nonlinear sensitivity to sound context. The data obtained from chronic recordings combined with nonlinear stimulus-response estimation provide <bold>convincing</bold> evidence that auditory cortical representations are stable over a period of days to weeks. While this study should be of widespread interest to sensory neuroscientists, the paper would be strengthened by a more thorough assessment and discussion of the effects of context and of the stability of the responses, as well as by the inclusion of more information about the location and types of neurons that were sampled.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98415.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Recent studies have used optical or electrophysiological techniques to chronically measure receptive field properties of sensory cortical neurons over long time periods, i.e. days to weeks, to ask whether sensory receptive fields are stable properties. Akritas et al expand on prior studies by investigating whether nonlinear contextual sensitivity, a property not previously investigated in the context of so-called 'representational drift,' remains stable over days or weeks of recording. They performed chronic tetrode recordings of auditory cortical neurons over at least five recording days while also performing daily measurements of both the linear spectro-temporal receptive field (principal receptive field, PRF) and non-linear 'contextual gain field' (CGF), which captures the neuron's sensitivity to acoustic context. They found that spike waveforms could be reliably matched even when recorded weeks apart. In well-matched units, by comparing the correlation between tuning within one day's session to sessions across days, both PRFs and CGFs showed remarkable stability over time. This was the case even when recordings were performed over weeks. Meanwhile, behavioral and brain state, measured with locomotion and pupil diameter, respectively, resulted in small but significant shifts in the ability of the PRF/CGF model to predict fluctuations in the neuronal response over time.</p>
<p>Strengths:</p>
<p>The study addresses a fundamental question, which is whether the neural underpinnings of sensory perception, which encompasses both sensory events and their context, are stable across relevant timescales over which our experiences must be stable, despite biological turnover. Although two-photon calcium imaging is ideal for identifying neurons stably regardless of their activity levels and tuning, it lacks temporal precision and is therefore limited in its ability to capture the complexity of sensory responses. Akritas et al performed painstaking chronic extracellular recordings in the auditory cortex with the temporal resolution to investigate complex receptive field properties, such as neural sensitivities to acoustic context. Prior studies, particularly in the auditory cortex, focused on basic tuning properties or sensory responsivity, but Akritas et al expand on this work by showing that even the nonlinear, contextual elements of sensory neurons' responses can remain stable, providing a mechanism for the stability of our complex perception. This work is both novel and broadly applicable to those investigating cortical stability across sensory modalities.</p>
<p>Weaknesses:</p>
<p>Apart from some aspects such as single-unit versus multi-unit, the study largely treats their dataset as a monolith rather than showing how factors such as firing rate, depth, and cell type could define more or less stable subpopulations. It is likely that their methodology did not enable an even sampling over these qualities, and the authors should discuss these biases to put their findings more in context with related studies.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98415.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This study explores the fundamental neuroscience question of the stability of neuronal representation. The concept of 'representational-drift' has been put forward after observations made using 2-photon imaging of neuronal activity over many days revealed that neurons contribute in a time-limited manner to population representation of stimuli or experiences. The authors contribute to the still contested concept of 'drifts' by measuring representation across days using electrophysiology and thus with sufficient temporal resolution to characterize the receptive fields of neurons in timescales relevant to the stimuli used. The data obtained from chronic recordings over days combined with nonlinear stimulus-response estimation allows the authors to conclude that both the spectrotemporal receptive fields as well as contextual gain fields dependent on combination sensitivity to complex stimuli were stable over time. This suggests that when a neuron is responsive to experimental parameters across long periods of time (days), its sensory receptive field is stable.</p>
<p>Strengths:</p>
<p>The strength of this study lies in the capacity to draw novel conclusions on auditory cortex representation based on the experimentally difficult combination of stable recordings of neuronal activity, behavior, and pupil over days and state-of-the-art analysis of receptive fields.</p>
<p>Weaknesses:</p>
<p>It would have been desirable, but too ambitious in the current setting, to be able to assess what proportion if any of the neurons drop out or in to draw a closer parallel with the 2-photon studies.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98415.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In their study on &quot;Nonlinear sensitivity to acoustic context is a stable feature of neuronal responses to complex sounds in auditory cortex of awake mice&quot;, Akritas et al. investigate the stability of the response properties of neurons in the auditory cortex of mice. They estimate a model with restricted non-linearities for individual neurons and compare the model properties between recordings on the same day and subsequent days. They find that both the linear and nonlinear components of the model stay rather constant over this period and conclude that on the level of the tuning properties, there is no evidence for representational drift on this time scale.</p>
<p>Strengths:</p>
<p>- The study has a clear analytical approach that goes beyond linear models and investigates this in a rigorous way, in particular comparing across-day variability to within-day variability.</p>
<p>
- The use of tetrodes is a rather reliable way in electrophysiological recordings to assess neuron identity over multiple days.</p>
<p>
- The comparison with pupil and motion activity was useful and insightful.</p>
<p>
- The presentation of the study is very logical and pretty much flawless on the writing level.</p>
<p>Weaknesses:</p>
<p>- The stability results across cells show a good amount of variability, which is only partially addressed.</p>
<p>
- In particular, no attempt is made to localize the cells in space, in order to check whether these differences could be layer or area-dependent.</p>
<p>
- The full context model also includes the possibility to estimate the input non-linearity, which was not done here, but could have been insightful.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98415.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Akritas</surname>
<given-names>Marios</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Armstrong</surname>
<given-names>Alex G</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lebert</surname>
<given-names>Jules M</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Meyer</surname>
<given-names>Arne F</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0468-3369</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Sahani</surname>
<given-names>Maneesh</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5560-3341</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Linden</surname>
<given-names>Jennifer F</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2210-1374</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Summary:</p>
<p>Recent studies have used optical or electrophysiological techniques to chronically measure receptive field properties of sensory cortical neurons over long time periods, i.e. days to weeks, to ask whether sensory receptive fields are stable properties. Akritas et al expand on prior studies by investigating whether nonlinear contextual sensitivity, a property not previously investigated in the context of so-called 'representational drift,' remains stable over days or weeks of recording. They performed chronic tetrode recordings of auditory cortical neurons over at least five recording days while also performing daily measurements of both the linear spectro-temporal receptive field (principal receptive field, PRF) and non-linear 'contextual gain field' (CGF), which captures the neuron's sensitivity to acoustic context. They found that spike waveforms could be reliably matched even when recorded weeks apart. In well-matched units, by comparing the correlation between tuning within one day's session to sessions across days, both PRFs and CGFs showed remarkable stability over time. This was the case even when recordings were performed over weeks. Meanwhile, behavioral and brain state, measured with locomotion and pupil diameter, respectively, resulted in small but significant shifts in the ability of the PRF/CGF model to predict fluctuations in the neuronal response over time.</p>
<p>Strengths:</p>
<p>The study addresses a fundamental question, which is whether the neural underpinnings of sensory perception, which encompasses both sensory events and their context, are stable across relevant timescales over which our experiences must be stable, despite biological turnover. Although two-photon calcium imaging is ideal for identifying neurons stably regardless of their activity levels and tuning, it lacks temporal precision and is therefore limited in its ability to capture the complexity of sensory responses. Akritas et al performed painstaking chronic extracellular recordings in the auditory cortex with the temporal resolution to investigate complex receptive field properties, such as neural sensitivities to acoustic context. Prior studies, particularly in the auditory cortex, focused on basic tuning properties or sensory responsivity, but Akritas et al expand on this work by showing that even the nonlinear, contextual elements of sensory neurons' responses can remain stable, providing a mechanism for the stability of our complex perception. This work is both novel and broadly applicable to those investigating cortical stability across sensory modalities.</p>
<p>Weaknesses:</p>
<p>Apart from some aspects such as single-unit versus multi-unit, the study largely treats their dataset as a monolith rather than showing how factors such as firing rate, depth, and cell type could define more or less stable subpopulations. It is likely that their methodology did not enable an even sampling over these qualities, and the authors should discuss these biases to put their findings more in context with related studies.</p>
</disp-quote>
<p>We did, in fact, investigate whether firing rate and other physiological response properties of units might differentiate subpopulations with different stability. This analysis is shown in Figure 7B-D. There was no apparent relationship between stability of nonlinear contextual gain fields and physiological properties such as mean evoked firing rate, signal-to-noise ratio for evoked firing, or predictive power of the context model (a measure of model goodness-of-fit).</p>
<p>The reviewer is correct, however, that we did not address possible differences between units recorded at different cortical depths or of different cell types, due to limitations of our methodology and sampling.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Summary:</p>
<p>This study explores the fundamental neuroscience question of the stability of neuronal representation. The concept of 'representational-drift' has been put forward after observations made using 2-photon imaging of neuronal activity over many days revealed that neurons contribute in a time-limited manner to population representation of stimuli or experiences. The authors contribute to the still contested concept of 'drifts' by measuring representation across days using electrophysiology and thus with sufficient temporal resolution to characterize the receptive fields of neurons in timescales relevant to the stimuli used. The data obtained from chronic recordings over days combined with nonlinear stimulus-response estimation allows the authors to conclude that both the spectrotemporal receptive fields as well as contextual gain fields dependent on combination sensitivity to complex stimuli were stable over time. This suggests that when a neuron is responsive to experimental parameters across long periods of time (days), its sensory receptive field is stable.</p>
<p>Strengths:</p>
<p>The strength of this study lies in the capacity to draw novel conclusions on auditory cortex representation based on the experimentally difficult combination of stable recordings of neuronal activity, behavior, and pupil over days and state-of-the-art analysis of receptive fields.</p>
<p>Weaknesses:</p>
<p>It would have been desirable, but too ambitious in the current setting, to be able to assess what proportion if any of the neurons drop out or in to draw a closer parallel with the 2-photon studies.</p>
</disp-quote>
<p>We certainly agree that this comparison would have been desirable in principle. In practice, however, it was technically infeasible and would have been likely to produce misleading results. Our criteria for spike waveform matching across days were extremely conservative, to minimise the potential for a false positive match (which could artifactually decrease apparent stability of unit responses). Therefore, we were likely to have missed some neurons that did in fact remain active over days, due to small changes in extracellular waveform or just noise (which could artifactually decrease apparent stability of population representations). Two-photon imaging is more appropriate for analysing population stability, because cell identity is determined by spatial location. However, as we mention in the paper, electrophysiology is more appropriate for analysing receptive-field stability, because the temporal resolution is sufficient to resolve structure at the millisecond timescales relevant to auditory perception.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public Review):</bold></p>
<p>Summary:</p>
<p>In their study on &quot;Nonlinear sensitivity to acoustic context is a stable feature of neuronal responses to complex sounds in auditory cortex of awake mice&quot;, Akritas et al. investigate the stability of the response properties of neurons in the auditory cortex of mice. They estimate a model with restricted non-linearities for individual neurons and compare the model properties between recordings on the same day and subsequent days. They find that both the linear and nonlinear components of the model stay rather constant over this period and conclude that on the level of the tuning properties, there is no evidence for representational drift on this time scale.</p>
<p>Strengths:</p>
<p>- The study has a clear analytical approach that goes beyond linear models and investigates this in a rigorous way, in particular comparing across-day variability to within-day variability.</p>
<p>- The use of tetrodes is a rather reliable way in electrophysiological recordings to assess neuron identity over multiple days.</p>
<p>- The comparison with pupil and motion activity was useful and insightful.</p>
<p>- The presentation of the study is very logical and pretty much flawless on the writing level.</p>
<p>Weaknesses:</p>
<p>- The stability results across cells show a good amount of variability, which is only partially addressed.</p>
<p>- In particular, no attempt is made to localize the cells in space, in order to check whether these differences could be layer or area-dependent.</p>
<p>- The full context model also includes the possibility to estimate the input non-linearity, which was not done here, but could have been insightful.</p>
</disp-quote>
<p>We agree with these comments and acknowledge these limitations, which arise from technological constraints. In particular, the tangential trajectory of our chronic tetrode implant, used to maximise stability of chronic recordings, limited our ability to sample cells from different cortical layers/areas and to explore how these factors might relate to variability in stability across units. Estimating input nonlinearities would have been valuable but also would have increased the number of parameters in the model and the data required to obtain reliable, predictive model fits.</p>
</body>
</sub-article>
</article>