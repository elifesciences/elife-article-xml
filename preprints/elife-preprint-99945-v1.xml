<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">99945</article-id>
<article-id pub-id-type="doi">10.7554/eLife.99945</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.99945.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Accelerated spike-triggered non-negative matrix factorization reveals coordinated ganglion cell subunit mosaics in the primate retina</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0836-1663</contrib-id>
<name>
<surname>Zapp</surname>
<given-names>Sören J</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3123-7054</contrib-id>
<name>
<surname>Khani</surname>
<given-names>Mohammad H</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">§</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schreyer</surname>
<given-names>Helene M</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">§</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8837-8555</contrib-id>
<name>
<surname>Sridhar</surname>
<given-names>Shashwat</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0002-1369-2600</contrib-id>
<name>
<surname>Ramakrishna</surname>
<given-names>Varsha</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2773-6785</contrib-id>
<name>
<surname>Krüppel</surname>
<given-names>Steffen</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3520-5394</contrib-id>
<name>
<surname>Mietsch</surname>
<given-names>Matthias</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2554-6419</contrib-id>
<name>
<surname>Protti</surname>
<given-names>Dario A</given-names>
</name>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9469-5020</contrib-id>
<name>
<surname>Karamanlis</surname>
<given-names>Dimokratis</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n2">%</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3998-533X</contrib-id>
<name>
<surname>Gollisch</surname>
<given-names>Tim</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>University Medical Center Göttingen, Department of Ophthalmology</institution>, Göttingen, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>Bernstein Center for Computational Neuroscience</institution>, Göttingen, <country>Germany</country></aff>
<aff id="a3"><label>3</label><institution>International Max Planck Research School for Neurosciences</institution>, Göttingen, <country>Germany</country></aff>
<aff id="a4"><label>4</label><institution>Cluster of Excellence “Multiscale Bioimaging: from Molecular Machines to Networks of Excitable Cells” (MBExC), University of Göttingen</institution>, Göttingen, <country>Germany</country></aff>
<aff id="a5"><label>5</label><institution>German Primate Center, Laboratory Animal Science Unit</institution>, Göttingen, <country>Germany</country></aff>
<aff id="a6"><label>6</label><institution>German Center for Cardiovascular Research</institution>, Partner Site Göttingen, Göttingen, <country>Germany</country></aff>
<aff id="a7"><label>7</label><institution>The University of Sydney, School of Medical Sciences (Neuroscience)</institution>, Sydney, NSW, <country>Australia</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Rieke</surname>
<given-names>Fred</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Washington</institution>
</institution-wrap>
<city>Seattle</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label><email>tim.gollisch@med.uni-goettingen.de</email></corresp>
<fn id="n1" fn-type="present-address"><label>§</label><p>Institute of Molecular and Clinical Ophthalmology Basel, Basel, Switzerland</p></fn>
<fn id="n2" fn-type="present-address"><label>%</label><p>University of Geneva, Department of Basic Neurosciences, Geneva, Switzerland</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-08-20">
<day>20</day>
<month>08</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP99945</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-06-06">
<day>06</day>
<month>06</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-06-07">
<day>07</day>
<month>06</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.04.22.590506"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Zapp et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Zapp et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-99945-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>A standard circuit motif in sensory systems is the pooling of sensory information from an upstream neuronal layer. A downstream neuron thereby collects signals across different locations in stimulus space, which together compose the neuron’s receptive field. In addition, nonlinear transformations in the signal transfer between the layers give rise to functional subunits inside the receptive field. For ganglion cells in the vertebrate retina, for example, receptive field subunits are thought to correspond to presynaptic bipolar cells. Identifying the number and locations of subunits from the stimulus–response relationship of a recorded ganglion cell has been an ongoing challenge in order to characterize the retina’s functional circuitry and to build computational models that capture nonlinear signal pooling. Here we present a novel version of spike-triggered non-negative matrix factorization (STNMF), which can extract localized subunits in ganglion-cell receptive fields from recorded spiking responses under spatiotemporal white-noise stimulation. The method provides a more than 100-fold speed increase compared to a previous implementation, which can be harnessed for systematic screening of hyperparameters, such as sparsity regularization. We demonstrate the power and flexibility of this approach by analyzing populations of ganglion cells from salamander and primate retina. We find that subunits of midget as well as parasol ganglion cells in the marmoset retina form separate mosaics that tile visual space. Moreover, subunit mosaics show alignment with each other for ON and OFF midget as well as for ON and OFF parasol cells, indicating a spatial coordination of ON and OFF signals at the bipolar-cell level. Thus, STNMF can reveal organizational principles of signal transmission between successive neural layers, which are not easily accessible by other means.</p>
</abstract>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>slight edits regarding references and regarding discussion of subunit alignment</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/gollischlab/STNMF_with_AFHALS">https://github.com/gollischlab/STNMF_with_AFHALS</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://doi.gin.g-node.org/10.12751/g-node.zpj6rc/">https://doi.gin.g-node.org/10.12751/g-node.zpj6rc/</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://doi.gin.g-node.org/10.12751/g-node.62b65b/">https://doi.gin.g-node.org/10.12751/g-node.62b65b/</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>In sensory pathways, neuronal signals typically carry spatiotemporal information about the outside world. The information is transmitted by an array of neurons, each encoding a constrained region of the stimulus space, defining its receptive field. A postsynaptic neuron can pool signals across multiple neurons in this array, constituting a receptive field that is larger than in the presynaptic layer. Owing to synaptic rectification or other signal transformations in the signal transmission, the integration of presynaptic signals is often nonlinear, which gives rise to substructure within the receptive field, for example, in the form of functional subunits that together compose the receptive field (<xref ref-type="bibr" rid="c122">Zapp et al. 2022</xref>). Nonlinear integration of subunit signals then sets the stage for complex computations. For example, in the retina, the neural network where vertebrate visual processing starts, subunits convey sensitivity of ganglion cells to spatial contrast or to different types of motion stimuli (<xref ref-type="bibr" rid="c34">Demb and Singer 2015</xref>; <xref ref-type="bibr" rid="c54">Gollisch and Meister 2010</xref>; <xref ref-type="bibr" rid="c72">Kerschensteiner 2022</xref>).</p>
<p>For retinal ganglion cells, receptive field subunits are thought to correspond to presynaptic bipolar cells (<xref ref-type="bibr" rid="c10">Borghuis et al. 2013</xref>; <xref ref-type="bibr" rid="c35">Demb et al. 2001</xref>; <xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>). Their excitatory signals may be integrated nonlinearly by the ganglion cells (<xref ref-type="bibr" rid="c10">Borghuis et al. 2013</xref>; <xref ref-type="bibr" rid="c35">Demb et al. 2001</xref>), which plays a substantial role in sensitivity to high spatial frequency (<xref ref-type="bibr" rid="c42">Enroth-Cugell and Robson 1966</xref>; <xref ref-type="bibr" rid="c108">Schwartz et al. 2012</xref>; <xref ref-type="bibr" rid="c116">Victor and Shapley 1979</xref>) as well as in local dynamics like contrast adaptation (<xref ref-type="bibr" rid="c67">Jarsky et al. 2011</xref>; <xref ref-type="bibr" rid="c88">Manookin and Demb 2006</xref>; <xref ref-type="bibr" rid="c104">Rieke 2001</xref>). Understanding how subunits compose the receptive field and how their signals are integrated can thus, on the one hand, provide essential information about the functional connectivity and the propagation of information in sensory networks, like how ganglion cells pool signals over an array of bipolar cells. These insights may then aid in explaining how ganglion cell receptive fields implement specific neural computations. On the other hand, identifying the layouts of subunits for different neuronal cell types can complement morphological findings by identifying differences in connectivity patterns and shared connections. In particular, the subunits of ganglion cells of a single type may be expected to form a mosaic-like arrangement, as is commonly observed for receptive fields of retinal cells of a given type. This has been reported across species for photoreceptors (<xref ref-type="bibr" rid="c90">Marc and Sperling 1977</xref>), bipolar cells (<xref ref-type="bibr" rid="c25">Cohen and Sterling 1990a</xref>, <xref ref-type="bibr" rid="c26">1990b</xref>; <xref ref-type="bibr" rid="c112">Sterling et al. 1988</xref>), and ganglion cells (<xref ref-type="bibr" rid="c3">Anishchenko et al. 2010</xref>; <xref ref-type="bibr" rid="c37">DeVries and Baylor 1997</xref>; <xref ref-type="bibr" rid="c49">Gauthier et al. 2009</xref>).</p>
<p>The retina subjected to light stimulation has proved to be a suitable model for investigating the functional connectivity in sensory systems. Nevertheless, direct experimental investigations of the neuronal connections that constitute the subunits, for example by simultaneously stimulating and recording pre- and postsynaptic neuronal layers, remain challenging. In light of the experimental limitations, several methods have been proposed to infer subunits computationally from recorded ganglion cell responses to visual stimuli. The methods include data-driven fitting of cascade networks that model subunits as linear filters with a nonlinear transfer function converging onto a ganglion cell (<xref ref-type="bibr" rid="c45">Freeman et al. 2015</xref>; <xref ref-type="bibr" rid="c86">Maheswaranathan et al. 2018</xref>; <xref ref-type="bibr" rid="c93">McFarland et al. 2013</xref>; <xref ref-type="bibr" rid="c111">Shi et al. 2019</xref>). Similarly, convolutional neural networks, which offer a comparable model of signal convergence with potentially deeper layering have been used to capture how local processing inside the receptive field of a ganglion cell shapes the cell’s visual responses (<xref ref-type="bibr" rid="c87">Maheswaranathan et al. 2023</xref>; <xref ref-type="bibr" rid="c94">McIntosh et al. 2016</xref>; <xref ref-type="bibr" rid="c113">Tanaka et al. 2019</xref>). On the other side of the spectrum, there are statistical analyses of a cell’s stimulus-response relationship, such as spike-triggered clustering (<xref ref-type="bibr" rid="c110">Shah et al. 2020</xref>) and spike-triggered non-negative matrix factorization (STNMF; <xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>).</p>
<p>For example, STNMF relies on visual stimulation with spatial or spatiotemporal white-noise patterns and on analyzing correlations in the set of those stimulus patterns that elicited spikes (spike-triggered stimulus ensemble), while placing a non-negativity and a sparsity constraint on the extracted structures. Subunits identified with STNMF from salamander ganglion cells have been shown to match receptive fields of simultaneously recorded bipolar cells (<xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>). However, the proposed implementation is computationally expensive, requiring on the order of several hours of analysis time per ganglion cell on a standard desktop computer. This has limited the control over the effects of hyperparameters, such as the strength of sparsity regularization, which needs to be adjusted to the right range for obtaining spatially localized subunits.</p>
<p>Here, we develop a new version of STNMF that addresses the shortcomings of previous implementations. We introduce a novel combination of state-of-the-art algorithms of non-negative matrix factorization (NMF) and complement it with guided initialization procedures to improve speed and reliability. The resulting method allows subunit recovery for a cell in a matter of seconds on a standard desktop computer. We demonstrate how clustering consensus methods can be applied for hyperparameter selection and offer tools that reliably provide suitable values for sparsity regularization. This makes STNMF more versatile across cells of different functional classes and across datasets of different species. In this work, we firstly demonstrate the superior speed of the new STNMF algorithm and its flexibility in analyses of ganglion cell populations in both salamander and primate retina. Secondly, we show that the versatile implementation of STNMF with hyperparameter tuning allows matching subunit properties to anatomical characteristics of parasol and midget ganglion cells in the primate retina. Thirdly, we use STNMF to investigate subunit mosaic arrangements of ON- and OFF-type pathways, demonstrating that these are spatially aligned between ON- and OFF-pathways, in contrast to the anti-alignment of ganglion cell receptive field mosaics (<xref ref-type="bibr" rid="c105">Roy et al. 2021</xref>).</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>STNMF is a type of spike-triggered analysis that aims at extracting spatial subunits from the structure of spike-eliciting stimulus segments under white-noise stimulation. Spike-triggered analyses have long been used for assessing receptive fields via computation of the spike-triggered average (STA; <xref ref-type="bibr" rid="c15">Bryant and Segundo 1976</xref>; <xref ref-type="bibr" rid="c20">Chichilnisky 2001</xref>; <xref ref-type="bibr" rid="c33">De Boer and Kuyper 1968</xref>) as well as for obtaining multiple (typically temporal) stimulus filters via spike-triggered covariance (STC) analysis (<xref ref-type="bibr" rid="c18">Cantrell et al. 2010</xref>; <xref ref-type="bibr" rid="c44">Fairhall et al. 2006</xref>; <xref ref-type="bibr" rid="c53">Gollisch and Meister 2008</xref>; <xref ref-type="bibr" rid="c106">Samengo and Gollisch 2013</xref>; <xref ref-type="bibr" rid="c109">Schwartz et al. 2006</xref>). As an extension of these approaches, STNMF can identify localized subunits, based on the statistical structure (e.g. correlations) of spike-triggered stimuli, leading to a parts-based (<xref ref-type="bibr" rid="c81">Lee and Seung 1999</xref>) decomposition of the receptive field. For detecting the relevant structure evoked by the subunits, STNMF requires a spatiotemporally uncorrelated stimulus (white noise) with a spatial resolution finer than the expected subunit size.</p>
<p>The analysis starts with recording spikes of a neuron under white-noise stimulation, for example, a checkerboard layout with light intensities of the checkerboard squares flickering randomly and independently in the case of visual stimulation. From the recorded data, one then extracts the spike-triggered stimuli, that is, the stimulus sequences preceding a spike over a time window given by the temporal sensitivity of the neuron. Since subunits of a given cell typically share the same temporal dynamics (<xref ref-type="bibr" rid="c86">Maheswaranathan et al. 2018</xref>), focusing on the spatial profile by integrating out time has been a viable option to reduce input dimensions (<xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>; <xref ref-type="bibr" rid="c110">Shah et al. 2020</xref>). To do so, the temporal component of the spike-triggered stimuli, obtained from the STA, is used to compress each spike-triggered stimulus into a single effective spike-triggered spatial pattern (<xref ref-type="bibr" rid="c71">Kaardal et al. 2013</xref>; <xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>). Concretely, for each spike-triggered stimulus sequence, we take the average of the stimulus frames weighted with the temporal component. Furthermore, to focus the analysis on the relevant region in space, the time-averaged spike-triggered stimuli are cropped to roughly the region of a cell’s receptive field, here done by selecting the smallest rectangle containing the three-standard-deviation ellipse of a Gaussian function fitted to the spatial component of the STA.</p>
<p>The collection of these time-averaged, cropped spike-triggered stimulus patterns gives us the effective spike-triggered stimulus ensemble (STE) for a given cell. We arrange the STE into a pixel-by-spikes matrix (<xref rid="fig1" ref-type="fig">Figure 1A</xref>), where each column collects all the pixel values of the effective spike-triggered stimulus for a given spike. We then perform semi-non-negative matrix factorization (semi-NMF; <xref ref-type="bibr" rid="c38">Ding et al. 2010</xref>) on this STE matrix. The use of semi-NMF, rather than a full NMF with non-negativity constraints on all matrices, enforces non-negativity only on one of the two matrices in the factorization. This accommodates the negative contrast values contained in our STE matrix.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Conceptual sketch of spike-triggered non-negative matrix factorization.</title>
<p>(<bold>A</bold>) The stimulus ensemble (top) is a matrix of pixels by spikes. Each column is the effective spike-triggered stimulus of a given spike (bottom). The stimulus ensemble serves as the input to the matrix factorization (dimensions not to scale). (<bold>B</bold>) Using semi-NMF, the stimulus ensemble is decomposed into two smaller matrices, the non-negative spatial modules and their corresponding weights. Together, these represent a lower-dimensional approximation of the stimulus ensemble. (<bold>C</bold>) The models can be reshaped into two-dimensional spatial layouts. Some modules exhibit localized structure and are identified via their spatial autocorrelation as subunits, whereas others (here displayed with reduced saturation) capture noise.</p></caption>
<graphic xlink:href="590506v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The semi-NMF decomposes the STE matrix into two smaller matrices, which contain the spatial modules and their corresponding weights for each spike (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). Any stimulus that led to a spike is approximated by a linear combination of the modules, with weights specific to that spike. The non-negativity constraint is here applied to the module matrix. Thus, there are no negative pixel values in the modules, which could cancel out with positive values in the linear combination. As a result, the modules emerge as purely additive building blocks. By limiting the number of modules, these building blocks must be shared between the different spike-triggered stimuli and therefore reflect the prevailing structure (the pixel correlations) in the STE. Along with a sparsity constraint on the module matrix, STNMF extracts spatially localized modules that capture the spatial patterns behind the spiking response. These are taken as the estimated subunits within the receptive field of the ganglion cell (<xref rid="fig1" ref-type="fig">Figure 1C</xref>).</p>
<p>The optimal number of modules is not known a priori, and its selection poses a common hurdle in the field of NMF and of subunit recovery. Much like for clustering algorithms, the obtained modules might merge separate structures or oversplit if their number is not chosen well. For identifying the localized subunits, however, STNMF is relatively robust to changing the number of modules as long as it is somewhat larger than the number of (expected) subunits (<xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>). The reason for this is that the excess modules beyond the ones that capture the actual subunits turn into non-localized, noise-like modules. Allowing for more modules then increases the number of noise-like modules, whereas the number of localized subunit-like modules remains largely unaffected. The noise-like modules are typically dominated by pixels outside the receptive field, which do not contribute to activating the cell and are thus not particularly correlated with pixels that compose the localized subunits. The noise-like subunits therefore capture spurious correlations within the STE, essentially reflecting noise in the STE from finite sampling. For the detection of subunits, these noise-like modules can then be ignored, making the identification of localized subunits robust to varying the number of modules. As previously suggested (<xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>), we find 20 modules to be a good number for our application on retinal ganglion cells in the datasets analyzed here. The recovered modules of interest are visibly distinguishable from the noisy excess modules by their spatially localized structure. We automate this differentiation by defining those modules as recovered subunits that have a sufficiently high spatial autocorrelation (<xref rid="fig1" ref-type="fig">Figure 1C</xref>; see Methods).</p>
<sec id="s2a">
<title>Accelerated fast hierarchical alternating least squares speeds up subunit recovery</title>
<p>We investigated different NMF algorithms to provide the most suitable implementation in context of subunit recovery. Due to its non-negativity constraint, NMF is NP-hard (<xref ref-type="bibr" rid="c115">Vavasis 2010</xref>). To obtain a good decomposition, NMF is generally performed by iterative improvements. Various algorithms facilitate these iterations under the non-negativity constraint. Many of them are accurate but computationally costly algorithms (<xref ref-type="bibr" rid="c76">Kim and Park 2011</xref>), as they often seek exact solutions at each iteration when updating either the modules or the weights and because they consider all data at once. As an alternative, hierarchical alternating least squares (HALS; <xref ref-type="bibr" rid="c23">Cichocki et al. 2007</xref>; <xref ref-type="bibr" rid="c59">Ho 2008</xref>; <xref ref-type="bibr" rid="c84">Li and Zhang 2009</xref>) has gained popularity in recent years. HALS replaces accurate with approximated solutions at each iteration of NMF, but exploits the thereby gained iteration speed. Over more but faster iterations, it outperforms previous methods in many applications of NMF (<xref ref-type="bibr" rid="c23">Cichocki et al. 2007</xref>; <xref ref-type="bibr" rid="c22">Cichocki and Phan 2009</xref>; <xref ref-type="bibr" rid="c51">Gillis and Glineur 2012</xref>) while ensuring convergence (<xref ref-type="bibr" rid="c50">Gillis and Glineur 2008</xref>). Instead of inferring all modules from their weights at once, HALS updates the modules sequentially. This breaks down large matrix multiplications into smaller, more efficient vector operations. The speed of this approach compensates for this approximation because more iterations are possible in shorter time. Various modifications of the HALS algorithm have been proposed recently to further increase its speed or its accuracy.</p>
<p>Here, we combine two HALS algorithms into what we call Accelerated Fast HALS (AF-HALS). Fast HALS (<xref ref-type="bibr" rid="c22">Cichocki and Phan 2009</xref>) achieves a speed-up through computational simplification by employing vector normalization to cancel out terms in the update equation. Accelerated HALS (<xref ref-type="bibr" rid="c51">Gillis and Glineur 2012</xref>) improves factorization accuracy per iteration by performing multiple consecutive HALS updates as long as the number of floating point operations stays below that of the heavy matrix operations preceding the next iteration. With Fast HALS, each iteration in NMF becomes less complex, requiring less computation time. With Accelerated HALS, each iteration becomes more accurate, requiring fewer iterations.</p>
<p>To demonstrate a direct comparison in speed and accuracy in the context of STNMF, we selected the popular active-set method (<xref ref-type="bibr" rid="c79">Lawson and Hanson 1974</xref>) as an alternative to AF-HALS. It is representative for current state-of-the-art NMF algorithms (<xref ref-type="bibr" rid="c76">Kim and Park 2011</xref>; <xref ref-type="bibr" rid="c123">Zhang et al. 2014</xref>) as it prevails for its high accuracy at each iteration. A previous implementation of STNMF was based on the active-set method (<xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>). We demonstrate the differences exemplarily on a retinal ganglion cell from the salamander retina, which had been recorded under white-noise stimulation as part of a previous study of subunit recovery with STNMF (<xref ref-type="bibr" rid="c52">Gollisch and Liu 2018</xref>; <xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>). We find that, using the same data, number of modules, and initial conditions, AF-HALS converges on localized modules both faster and within fewer iterations (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Not only are the individual NMF iterations considerably faster with AF-HALS, reaching 10 iterations within a fraction of a second rather than the several seconds required by the active-set implementation, but the achieved error and the quality of the identified subunit structure is comparable or even slightly better for AF-HALS, despite the approximation at each iteration.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>STNMF with Accelerated Fast HALS (AF-HALS) converges faster than the previous implementation of STNMF.</title>
<p>Reconstruction error of STNMF implemented with AF-HALS (black) and STNMF based on the active-set method used in <xref ref-type="bibr" rid="c85">Liu et al. (2017</xref>; gray) for a sample salamander ganglion cell. Arrows denote the number of iterations. Insets allow visual inspection of the recovered modules at different states during the iterations. Although the active-set method calculates more accurately at each step, the reconstruction process is similar after ten iterations in both methods (blue and red insets). The active-set method does not reach the low error that AF-HALS accomplishes within a few seconds. The visualized subunits of the active-set method after 45 minutes (purple inset) arrive at the state that AF-HALS reached within five seconds (green inset). Top right: Distributions of iteration speeds (measured as inverse of each iteration duration) of the active-set method (gray) and of AF-HALS (black) for the sample cell.</p></caption>
<graphic xlink:href="590506v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Thus, a clear subunit decomposition already emerges within the first few hundred iterations, taking only a few seconds, with a remaining error that is smaller than what is reached by the active-set implementation even after several tens of minutes of runtime (<xref rid="fig2" ref-type="fig">Figure 2</xref>). In the end, both methods arrive at similar subunit estimates, but convergence for AF-HALS is reached much sooner by orders of magnitude in absolute computation time.</p>
</sec>
<sec id="s2b">
<title>Guided initialization can replace repeated runs</title>
<p>As NMF is a non-convex optimization problem (<xref ref-type="bibr" rid="c115">Vavasis 2010</xref>), there are no guarantees for any given method to arrive at the globally optimal solution. In typical iterative implementations, solutions correspond to local optima and therefore depend on the starting point of the iterative search (<xref ref-type="bibr" rid="c81">Lee and Seung 1999</xref>), that is, the initial values of the modules. A popular way to compensate for the dependence on the starting point is to perform multiple repetitions of NMF starting from different random initializations of the modules and select the best of the obtained decompositions, the one with minimal residual reconstruction error (<xref ref-type="bibr" rid="c8">Berry et al. 2007</xref>; <xref ref-type="bibr" rid="c24">Cichocki et al. 2009</xref>).</p>
<p>However, random initialization generally does not offer a strong starting point for efficient convergence of the iterative procedures (<xref ref-type="bibr" rid="c121">Wild et al. 2004</xref>), and relying on many repetitions with different initializations poses a high demand on computational time. Furthermore, the selection of the best solution may depend on the particular measure of comparison. To circumvent these obstacles, we substitute the time-consuming repeated runs by implementing a guided initialization, based on singular value decomposition (SVD; <xref ref-type="bibr" rid="c11">Boutsidis and Gallopoulos 2008</xref>). Applying SVD to the matrix of the STE already yields structured components, akin to modules after several iterations of randomly initialized NMF, albeit with both positive and negative entries. Furthermore, SVD-based initialization has been shown to yield earlier convergence and smaller residual errors of NMF (<xref ref-type="bibr" rid="c102">Qiao 2015</xref>). To accommodate for the non-negativity constraint of NMF, methods of SVD-based initialization typically set negative values in the SVD components to zero before supplying these as initial conditions to the NMF algorithm.</p>
<p>As a further improvement, one can take advantages of the sign ambiguity of SVD and duplicate selected components with opposite sign before setting the negative values in all components to zero, as is done in non-negative singular value decomposition with low-rank correction (NNSVD-LRC; <xref ref-type="bibr" rid="c5">Atif et al. 2019</xref>). This offers potentially twice the amount of information from the selected SVD components. Furthermore, the procedure produces initial modules with around half of their values at zero, offering around 50% sparsity before even starting NMF. NNSVD-LRC subsequently uses the low-rank approximation of the input matrix constructed from the selected components to perform a few NMF iterations. The low-rank factorization reduces the computational complexity of the matrix multiplications involved, providing a computationally cheap head start for the full NMF. We modified NNSVD-LRC to be suitable for semi-NMF and improved its numerical stability (see Methods). This includes keeping the previously skipped duplicate of the component with the highest singular value and replacing the elements of columns whose entries are all zeros with a small non-zero constant to avoid convergence issues in HALS-based NMF.</p>
<p>We find that a single run of STNMF initialized with NNSVD-LRC can typically recover all recurring subunits that had been identified via 100 repetitions of randomly initialized STNMF. To show this, we compared STNMF results for an available dataset of salamander retinal ganglion cells (<xref ref-type="bibr" rid="c52">Gollisch and Liu 2018</xref>). For this comparison, we aimed at determining those spatially localized subunits that were robustly identified across multiple randomly initialized STNMF runs. We defined them as subunits that could be repeatedly identified across a majority of runs by their high spatial overlap (see Methods). We found that those robustly identified subunits matched the subunits recovered with NNSVD-LRC-based STNMF quite closely (<xref rid="fig3" ref-type="fig">Figure 3</xref>). This demonstrates the viability of the NNSVD-LRC initialization and supports the possibility of an additional 100-fold speed increase by omitting the repeated runs with random initialization, in addition to the already manifold speed increase obtained from applying AF-HALS.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>A single run of NNSVD-LRC-initialized STNMF yields subunits consistent with recurring subunits from 100 different, randomly initialized runs.</title>
<p>(<bold>A</bold>) Contour outlines of subunits of 100 randomly initialized STNMF runs for two sample cells (fast-OFF type) from salamander retina. Subunits of different runs are regarded as identical if they exhibit substantial spatial overlap (Jaccard index &gt; 0.5; see Methods). Subunits that emerged in more than half of the runs are colored, with saturation corresponding to the level of recurrence (see colorbar) and marked with a percentage of recurrence. (<bold>B</bold>) Comparison of subunit layouts recovered with NNSVD-LRC (gray) and with randomly initialized runs and a 50%-recurrence-criterion (yellow). Each yellow outline is the contour of the mean of the recurring subunits in (<bold>A</bold>). For the two sample cells, a single NNSVD-LRC-based STNMF run found all recurring subunits of the randomly initialized runs. (<bold>C</bold>) Distributions over 40 analyzed fast-OFF cells of the fraction of recurring subunits recovered by a single run with NNSVD-LRC (dark gray) or by 100 runs with random (light gray) initialization. Recovered subunits are determined via the Jaccard index (see above and Methods). NNSVD-LRC-based STNMF reliably finds more of the recurring subunits than the individual randomly initialized runs (averaged over 100 runs for each cell).</p></caption>
<graphic xlink:href="590506v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2c">
<title>Effects of sparsity regularization on subunit layout</title>
<p>In contrast to regular NMF, where the non-negativity constraint is placed on all matrices, semi-NMF only forces one matrix to be non-negative, in our case the modules, not the weights. Due to the loosened constraint, semi-NMF typically fails to retain additive, parts-based solutions without additional constraints (<xref ref-type="bibr" rid="c38">Ding et al. 2010</xref>). This crucial aspect of NMF can be recovered in semi-NMF through sparsity regularization on one of the factor matrices (<xref ref-type="bibr" rid="c60">Hoyer 2002</xref>, <xref ref-type="bibr" rid="c61">2004</xref>; <xref ref-type="bibr" rid="c74">Kim and Park 2007</xref>, <xref ref-type="bibr" rid="c75">2008</xref>). Unlike other methods of subunit recovery or machine learning in general, where regularization serves as an optional step to counteract overfitting or to alleviate the lack of sufficient data, sparsity regularization in STNMF based on semi-NMF is therefore an essential part of its functionality when parts-based decompositions are desired. To obtain localized subunits, we enforce the modules to be both non-negative and sparse. We achieve this by ℓ1-norm-based regularization, including a term in the objective function that penalizes large numbers of non-zero-pixel values in the modules.</p>
<p>As is customary, the strength of regularization is controlled via a regularization parameter. Increasing the value of the regularization parameter drives more pixel values in the modules to zero. Once regularization becomes too strong, subunits are forced to shrink in size or will be split into multiple smaller subunits until they eventually vanish. The optimal amount of sparsity depends on the dimensionality of the data. Accessible properties, like the number of pixels and number of spikes, as well as unknown characteristics prior to subunit recovery, like the true number of subunits and their sizes, play a role. Consequently, the regularization is difficult to control and may have to be individually adjusted for cells that differ in their properties. On the other hand, for cells that share characteristics, similar strengths of regularization should be suitable.</p>
<p>We examined the impact of sparsity regularization on the subunit decomposition for data recorded from ganglion cells of a salamander retina (<xref ref-type="bibr" rid="c52">Gollisch and Liu 2018</xref>). We ran STNMF initialized with NNSVD-LRC on the data of selected cells at varying sparsity regularization. Without sparsity regularization, we obtained modules that span the entire receptive field with strong overlap (example cell in <xref rid="fig4" ref-type="fig">Figure 4C</xref><bold> insets</bold>). As regularization strength increases, these modules first break up into large subunits that subsequently split into multiple smaller subunits. For a certain range, the subunit layout becomes more stable, with variations in smaller subunits further away from the receptive field center. Although prominent subunits are fairly robust to changes in sparsity, good control to provide the right amount of sparsity regularization is beneficial to extract a subunit layout that is most likely to represent the underlying structure of the receptive field.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Consensus analysis for determining the suitable weight of sparsity regularization.</title>
<p>(<bold>A</bold>) Module sparsity (fraction of zeros in the modules) of the decomposition with increasing sparsity regularization for a sample salamander cell. The first step in the analysis is finding the window (dotted frame) in which regularization starts to dominate the decomposition, that is, module sparsity approaches unity. Within that range, the consensus of decompositions is probed. (<bold>B</bold>) Reordered consensus matrix showing the pairwise agreement between spike pairs across 30 decompositions. High consensus is indicated by the ten clusters on the diagonal corresponding to ten reliably recovered subunits as visualized in the second subunit layout inset of (<bold>C</bold>). (<bold>C</bold>) Stability curve for the same cell as obtained from consensus matrices at different regularization strength. The diagonal clustering structure in (<bold>B</bold>) is measured with a scalar value, the cophenetic correlation coefficient (CPCC). The correlation increases with increasing sparsity regularization, supported by refined subunit outlines (first and second inset). After a peak in stability, subunits become too sparse (third inset) until they eventually vanish when regularization becomes too strong. (<bold>D</bold>) The stability curves for a wide range of regularization parameters of a subset of cells (dark) compared to the curves of all 40 fast-OFF cells (yellow) from a salamander retina. Dotted frame indicates the range of interest as specified in (<bold>C</bold>).</p></caption>
<graphic xlink:href="590506v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2d">
<title>Consensus analyses aid in selection of regularization parameter</title>
<p>The regularization requires the choice of a hyperparameter value to control the amount of sparsity. With our tractable implementation of STNMF, we here provide a method to do so in reasonable computation time. A common approach to finding the most suitable weight for regularization is through cross-validation. However, techniques that rely on held-out data are problematic in applications of unsupervised learning like NMF (<xref ref-type="bibr" rid="c13">Bro et al. 2008</xref>; <xref ref-type="bibr" rid="c100">Owen and Perry 2009</xref>). The weight matrix in STNMF is highly dependent on the spikes from the specific input and cannot be used to compare training and test data sets, but would have to be recomputed for the test data. Relatedly, the reconstruction error of the factorization does not pose a suitable metric in the context of sparsity regularization as it increases monotonically with regularization (see Methods). Adjusted cross-validation-like procedures for matrix factorization have been proposed (<xref ref-type="bibr" rid="c46">Fu and Perry 2017</xref>; <xref ref-type="bibr" rid="c100">Owen and Perry 2009</xref>) based on selectively leaving out data entries across both rows and columns of the input matrix (pixels and spikes) and keeping these randomly scattered matrix elements as test data. However, using missing or masked entries in the input matrix does not generalize well to accelerated NMF algorithms like Accelerated HALS. This is due to optimizations regarding vectorized calculations and matrix multiplications that are factored out of the column-wise updates.</p>
<p>Instead of cross-validation, we therefore turn to the solution of a similar parameter-selection problem. A common hurdle for clustering techniques is the choice of the optimal number of clusters. This problem also translates to NMF and may be addressed by using so-called consensus methods (<xref ref-type="bibr" rid="c96">Monti et al. 2003</xref>). To explore this approach to find a suitable regularization parameter for sparsity, we temporarily neglect the aforementioned SVD-based initialization and revert to repeated runs of NMF with different random initializations. The variability in the solutions across runs is then exploited to find the most consistent decomposition among the sets of solutions. The more appropriate the choice of the sparsity regularization parameter, the more the subunit structure becomes similar across solutions, that is, the more the different solutions consent regarding which spikes relate to the same subunits (<xref ref-type="bibr" rid="c14">Brunet et al. 2004</xref>).</p>
<p>In clustering, the consensus is typically analyzed via the consensus matrix, which contains for each pair of samples the fraction of times that the two samples were clustered together. In STNMF, the spikes take the role of the samples, and the weight factor matrix denotes their affiliation with the different modules, analogous to different clusters. This, however, is not a hard cluster assignment, but a soft weighting of how much each module contributes to reconstructing a given spike-triggered stimulus. Thus, to build the consensus across repeated runs, we determine the module most strongly affiliated with each spike as the module with the maximum weight for the spike. For our purposes, we further slightly modify the calculation of the consensus matrix by only allowing localized, subunit-like modules to contribute positively to the consensus. That is, if a pair of spikes is affiliated with the same non-localized module for a given STNMF run, this is treated like a case where affiliations do not match. We found that this adjustment reduced noise in the consensus analysis that likely comes from spurious coincidences of spikes with noise-like modules.</p>
<p>The consensus matrix then contains, for all pairs of spikes, the fraction of randomly initialized STNMF runs for which the pair is affiliated with the same localized subunit (<xref rid="fig4" ref-type="fig">Figure 4B</xref>). As proposed previously (<xref ref-type="bibr" rid="c14">Brunet et al. 2004</xref>), we quantify the dispersion of values in the consensus matrix by its cophenetic correlation coefficient (CPCC). The cophenetic correlation measures the degree of clustering in the consensus matrix in a hierarchical clustering distance manner. This provides a scalar metric between zero and unity, with higher values indicating increased stability of the decomposition.</p>
<p>For a given sparsity parameter, we run STNMF repeatedly with different random initializations. The consensus analysis reflects how robust the parameter is to the initializations and describes the stability of the subunit decomposition, which can then be compared via the CPCC across different sparsity parameter values (<xref rid="fig4" ref-type="fig">Figure 4C</xref>). We find that stability first increases with stronger sparsity regularization, as it increasingly constrains the solution and decreases variability among the decompositions, and then plateaus or declines again when regularization becomes too strong. Beyond this, a high coefficient can eventually also arise at the extreme end of strong regularization when very few or even only a single localized subunit emerges, causing near perfect consensus. In particular, this occurs as our computation of the consensus matrix only considers localized subunits. In practice, however, this extreme region can easily be avoided by observing the corresponding subunit structures.</p>
<p>The most important feature of the stability curve is that it exhibits a distinctive bend after the initial sharp increase before it plateaus or decreases. The location of the bend indicates a suited strength of sparsity regularization, providing a solution that is as stable as possible while affecting its structure as little as possible. Different techniques can be used to extract a specific regularization parameter value from the location of the bend, such as via a coefficient obtained from a fitted saturation curve. Here, we simply selected a parameter value by visual inspection. After determining a suitable regularization parameter, we run STNMF in that configuration initialized with NNSVD-LRC to obtain the final set of localized subunits.</p>
</sec>
<sec id="s2e">
<title>Suitable regularization parameters can be inferred from a subset of cells</title>
<p>We applied the consensus analysis to the salamander data of retinal ganglion cell recordings. To obtain a suitable sparsity regularization parameter for subsequently recovering the subunits for all cells, we proceeded as follows. Among the cells belonging to the same functional type, we selected a representative subset that resides near the population average for properties like receptive field diameter, number of spikes, and amount of noise in the STA by visual inspection. Here, with our computationally fast implementation of STNMF at hand, we were able to probe the effect of sparsity regularization quickly as a first step to narrow down the range of interest. We ran STNMF with NNSVD-LRC with increasing sparsity regularization to find an upper bound after which all values in the modules approached zero (<xref rid="fig4" ref-type="fig">Figure 4A</xref>). As our AF-HALS implementation of STNMF imposes sparsity at multiple sub-steps per full iteration, we found 200 iterations to give a sufficient estimate of the sparsity, measured as the fraction of zero values in the modules. Within the determined range, we investigated the solution stability for a coarse selection of regularization parameter values using the consensus across repeated STNMF runs of random initialization (<xref rid="fig4" ref-type="fig">Figure 4C</xref>). As this merely serves to further narrow down suitable bounds of regularization, we only performed five repetitions at each sparsity value to save time. For cells with nonlinear receptive fields that do in fact exhibit subunits, the stability curve rises sharply and shows one initial peak before plateauing or decreasing (<xref rid="fig4" ref-type="fig">Figure 4C</xref>), as expected. The area around the peak is the range of interest as it captures both ends of the impact of sparsity regularization. Within this window, we then performed the full consensus analysis at high resolution of regularization coefficients on the subset of cells (<xref rid="fig4" ref-type="fig">Figure 4D</xref> gray frame). We propose to perform between 20 to 30 repetitions for each regularization parameter value with 1000 STNMF iterations or until convergence to obtain a reasonable estimate of stability. Finally, we extract the suitable sparsity regularization parameter from the bend in the average of the stability curves by visual inspection. Beyond the subset of cells used for tuning the regularization, we then applied that regularization parameter to NNSVD-LRC-based STNMF to the entire population of cells of that type to identify the final subunit layouts for all of them. The process was repeated for each cell type.</p>
<p>By applying consensus analysis to the full population over a wide range of sparsity regularization, we verified that parameters inferred from a subset of cells can be extrapolated to the entire population effectively. For the sake of thoroughness, we analyzed a range of 44 sparsity parameter values between zero and ten, using a comparatively large number of repetitions (50) for each of them (<xref rid="fig4" ref-type="fig">Figure 4D</xref> bright curves). Note, that this extensive analysis takes substantially more time than the procedure described in the paragraph above and was performed here for comparison purposes only. Occasionally, the stability curve can abruptly decrease and approach low values, as seen in <xref rid="fig4" ref-type="fig">Figure 4D</xref> for one example. This occurs due to excessive regularization strengths beyond the appropriate level, breaking subunits arbitrarily into smaller structures and thereby preventing consensus across repeated decompositions. Otherwise, the stability curves are generally well in agreement with each other so that an arbitrary subset of cells is representative of the population here (<xref rid="fig4" ref-type="fig">Figure 4D</xref>).</p>
</sec>
<sec id="s2f">
<title>Subunits match previous analyses of bipolar cell receptive fields</title>
<p>We recovered subunits of the fast-OFF ganglion cells in the salamander data given the procedure described above. To estimate the subunits of all cells, STNMF took a total of five minutes on a conventional office computer averaging at around 9 seconds per ganglion cell. This is well beyond a 100-fold reduction in computation time compared to the earlier implementation based on the active-set method. Yet, the obtained subunits match the results from that previous analysis (<xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>). We observe a close resemblance in the set of subunits of individual cells (<xref rid="fig5" ref-type="fig">Figure 5A</xref>) and find the subunit outlines to align for the cell population (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). Furthermore, we were able to reproduce previously reported overlaps between subunits across cell pairs (<xref rid="fig5" ref-type="fig">Figure 5C</xref>). For some of the receptive fields, we recovered additional subunits to the otherwise matching subunit layout that had not been detected before. The differences we observe typically concern subunits with relatively small average weights in the STNMF decomposition. One possible explanation for these unmatched subunits may be the differing procedures to determine the final subunit layout. In the present work, the subunits correspond to the localized modules from STNMF without further curation. In the previous analysis (<xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>), the final subunits were obtained from the average of reoccurring subunits over multiple repetitions. Lower-weight subunits that occurred less frequently across the repetitions might have been more likely to be excluded by the previous method.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Subunits of AF-HALS-based STNMF match previous findings and bipolar cell receptive fields.</title>
<p>Subunit layouts of salamander cells (yellow) are compared to <xref ref-type="bibr" rid="c85">Liu et al. (2017</xref>; gray). Subunits are represented as 1.5-sigma ellipses of Gaussian fits in gray, and as yellow contour lines (see Methods). (<bold>A</bold>) Decomposition for two example cell receptive fields. Receptive field outlines are 1.5-sigma ellipses of Gaussian fits. The subunit layouts resemble the previously estimated subunits. (<bold>B</bold>) Comparison of subunit mosaics of a population of fast-OFF cells, colors like in (<bold>A</bold>). Most of the previously identified subunits as well as some additional ones are recovered. (<bold>C</bold>) Examples of subunit layouts for adjacent fast-OFF ganglion cells with overlapping (shared) subunit, as obtained with both methods. (<bold>D</bold>) Comparison of recovered subunits with receptive field of a simultaneously recorded bipolar cell. One of the subunits (yellow outlines) matches the bipolar cell receptive field (red outline). Panels (<bold>A</bold> gray), (<bold>B</bold> left), (<bold>C</bold> left), and (<bold>D</bold> rightmost) are adapted from <xref ref-type="bibr" rid="c85">Liu et al. (2017)</xref> licensed under CC BY 4.0.</p></caption>
<graphic xlink:href="590506v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Experiments combining multi-electrode recordings of ganglion cells with single-cell recordings of bipolar cells had been performed previously in salamander retinas to investigate the relationship between computationally inferred subunits and measured bipolar cell receptive fields (<xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>). Here, we confirm the results using the data of the respective ganglion cells. We find similar overlaps between subunits and bipolar cell receptive fields (<xref rid="fig5" ref-type="fig">Figure 5D</xref>). These findings suggest that our implementation can reveal bipolar cell receptive fields as subunits.</p>
</sec>
<sec id="s2g">
<title>STNMF recovers subunit mosaics for all of the four major cell types in the primate retina</title>
<p>With the new, fast implementation of STNMF in place, we next aimed at performing subunit analyses of ganglion cell populations in the primate retina in order to demonstrate how STNMF can provide insight into the subunit organization of different ganglion cell types. To this end, we recorded spiking activity from ganglion cells in isolated marmoset retina under white-noise stimulation. We identified the four major cell types of the primate retina, ON and OFF parasol as well as midget cells, according to their receptive field sizes and temporal filters (see Methods). STNMF was able to identify subunits from the spiking data of individual cells for each of the four cell types (<xref rid="fig6" ref-type="fig">Figure 6A</xref>). Furthermore, the separation of the cells into four distinct types with at least partial tiling of receptive fields (<xref rid="fig6" ref-type="fig">Figure 6B</xref>) allowed us to identify the layout of subunits on a cell-type-specific population level (<xref rid="fig6" ref-type="fig">Figure 6C</xref>). By doing so, we found that subunits associated with cells of the same functional type also tile the retina in a mosaic-like fashion. Subunit layouts from different ganglion cells of the same type intertwine nearly seamlessly so that it is not easily visible where the boundaries between ganglion cell receptive fields are.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>STNMF recovers subunits in all four major cell types of the marmoset retina.</title>
<p>Data is shown from ON and OFF parasol cells (one retina; mid-periphery) and ON and OFF midget cells (one retina; periphery). Note that the scale bars differ between the four sample cells. (<bold>A</bold>) Receptive fields, STNMF modules, and subunit layouts of sample ON and OFF parasol cells and ON and OFF midget cells. Modules identified as localized subunits by their autocorrelation (see Methods) are marked by colored frames and depicted together in a colored subunit layout of contours superimposed on the receptive field contour (gray; top right). The outlines are numbered in descending order according to the mean STNMF weight. (<bold>B</bold>) Receptive field mosaic of the four main cell populations (colored). Gray outlines correspond to the receptive fields of the corresponding type with reversed polarity of preferred contrast. The temporal dynamics of the receptive fields are depicted by the temporal filters of the spike-triggered average (insets; scale bar 200 ms). The sample cells of (<bold>A</bold>) are marked in red. (<bold>C</bold>) Subunit mosaics corresponding to (<bold>B</bold>). Sample cells marked in red. For some cells, in particular several OFF midget cells, no subunits could be reliably identified. Scale bars (300 µm) correspond to both (<bold>B</bold>) and (<bold>C</bold>).</p></caption>
<graphic xlink:href="590506v2_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The availability of four distinct cell-type populations also allowed us to investigate the generality of the consensus analysis and to probe whether optimal sparsity regularization is cell-type-specific. As cells of the same functional type share properties like receptive field size and firing rate more so than cells of different types, the required sparsity may differ across cell types.</p>
<p>To analyze whether this is reflected in the optimal sparsity regularization parameter, we examined the regularization-dependent consensus and compared the resulting stability curves for a wide range of regularization parameter values. For each of the four types, we found stability curves as expected, with a bend that indicates the optimal regularization strength (<xref rid="fig7" ref-type="fig">Figure 7A</xref>). Within each type, the shapes of the stability curves exhibit similarities, but this does not hold across types.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Stability curves align well among cells of same functional type.</title>
<p>(<bold>A</bold>) Stability defined by the cophenetic correlation coefficient (CPCC) for different sparsity regularization strength for ON and OFF parasol cells (one retina) and ON and OFF midget cells (one retina). Consensus for cells without nonlinear integration in their receptive fields may be undefined as indicated by incomplete stability curves. The dark curves represent the medians (excluding not defined values) of the corresponding population. Stability curves show the expected increase and plateau. (<bold>B</bold>-<bold>D</bold>) Consensus comparison of ON and OFF midget cells. (<bold>B</bold>) Superimposed stability curves of the different cell types, showing slight but systematic differences. (<bold>C</bold>) Stability curves projected onto the first two principal components of all curves from the two populations. (<bold>D</bold>) Inter- and across-type Euclidean distances in the two-dimensional PCA space, showing significant differences of distances across versus within cell types. Central line and box represent the median and the interquartile range (IQR; 1st to 3rd quartile), respectively. Whiskers extend to most extreme values within 1.5 IQR, and dots indicate outliers.</p></caption>
<graphic xlink:href="590506v2_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Comparing, for example, the stability curves for ON versus OFF midget cells reveals slight, but systematic differences (<xref rid="fig7" ref-type="fig">Figure 7B</xref>). The slope of the stability curves for OFF midget cells tends to be somewhat shallower around the bend than for ON midget cells. The difference can be illustrated by analyzing the family of curves with principal component analysis and comparing the shapes of the curves according to the projections on the first two principal components (<xref rid="fig7" ref-type="fig">Figure 7C</xref>). This shows that curves of cells for the same type tend to group together but diverge across types, despite some overlap of the two populations. It is likely that differences in the levels of noise and in the subunit nonlinearities contribute to these cell-type differences of regularization effects.</p>
<p>More quantitatively, we find that the distances between pairs of curves are significantly larger across cell types than for curves of the same type (<xref rid="fig7" ref-type="fig">Figure 7D</xref>; two-tailed Wilcoxon rank-sum test, p &lt; 10<sup>−6</sup> for both ON and OFF cells versus across types). This indicates that the stability analysis is similar for cells within a type, but can differ across types, suggesting, along with the tight alignment of the stability curves observed in the salamander dataset (<xref rid="fig4" ref-type="fig">Figure 4D</xref>), that a suited sparsity regularization parameter can be inferred from a representative subset of cells for each functional cell type, but that different types may require different levels of regularization. The subunit populations in <xref rid="fig6" ref-type="fig">Figure 6C</xref> are based on cell-type specific regularization parameters.</p>
</sec>
<sec id="s2h">
<title>Subunits reflect anatomical differences between parasol and midget cell circuits</title>
<p>The sizes of subunits are fairly homogeneous within functional types, but differ between parasol and midget cells (<xref rid="fig8" ref-type="fig">Figure 8A</xref>; subunit diameters mean ± standard deviation: 60.5±16.7 µm for ON parasol cells, 56.3±10.9 µm for OFF parasol cells, 44.6±12.2 µm for ON midget cells, 38.1±12.9 µm for OFF midget cells, p &lt; 10<sup>−6</sup> for both ON parasol versus ON midget and OFF parasol versus OFF midget, two-tailed Wilcoxon rank-sum test, data from three marmoset retinas), suggesting distinct presynaptic inputs. Parasol cells in primates receive excitatory inputs from diffuse bipolar cells (<xref ref-type="bibr" rid="c16">Calkins and Sterling 2007</xref>; <xref ref-type="bibr" rid="c65">Jacoby et al. 2000</xref>; <xref ref-type="bibr" rid="c118">Wässle 1999</xref>), whereas midget cells are primarily connected to midget bipolar cells (<xref ref-type="bibr" rid="c69">Jusuf et al. 2006a</xref>, <xref ref-type="bibr" rid="c70">2006b</xref>; <xref ref-type="bibr" rid="c78">Kolb and Dekorver 1991</xref>). We found the average midget subunit diameter of around 42 µm to match the receptive field size of midget bipolar cells (31–51 µm) as measured in the peripheral macaque retina (<xref ref-type="bibr" rid="c32">Dacey et al. 2000</xref>). The average parasol subunit diameter of around 58 µm lies between reported anatomical dendritic tree sizes (30–50 µm) (<xref ref-type="bibr" rid="c12">Boycott and Wässle 1991</xref>) and measured receptive field sizes (74–114 µm) (<xref ref-type="bibr" rid="c32">Dacey et al. 2000</xref>) of diffuse bipolar cells in the peripheral macaque retina.</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Subunits match anatomical properties of bipolar cells.</title>
<p>(<bold>A</bold>) Subunit diameters of the four major cell types collected from three marmoset retinas. (Box plots like in <xref rid="fig7" ref-type="fig">Figure 7D</xref>.) Parasol and midget subunits are comparable in size to diffuse bipolar and midget bipolar cells, respectively. Bipolar cell sizes were previously reported in the macaque retina according to physiological measurements (<xref ref-type="bibr" rid="c32">Dacey et al. 2000</xref>) and to calculations based on cone inputs (<xref ref-type="bibr" rid="c12">Boycott and Wässle 1991</xref>). (<bold>B</bold>-<bold>C</bold>) Examples of the subunits of adjacent parasol (<bold>B</bold>) and midget (<bold>C</bold>) cells. Markers represent centers of mass. While the parasol subunits can display substantial overlap from adjacent cells, the midget cell subunit layouts are typically distinct with no or few overlapping subunits. (<bold>D</bold>) Histograms of subunit pair overlap. Overlap between subunit pairs within ON (top), OFF (middle), and across ON and OFF (bottom) parasol and midget cells is measured with the Jaccard index. Only overlap pairs with an index greater than zero are visualized. The dashed line indicates the lower bound of what we consider here as substantial overlap, suggesting shared bipolar cell inputs. Consistent with the examples in (<bold>C</bold>), we observed few overlapping pairs for midget cells, but a considerable amount (<bold>B</bold>) for OFF parasol cells.</p></caption>
<graphic xlink:href="590506v2_fig8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Even though these values and our subunit analyses come from different primate species, the matching sizes, in particular the relative differences between parasol and midget inputs, suggest a correspondence between subunits and bipolar cell inputs.</p>
<p>Midget cells in our analysis yielded on average 5.7±2.3 subunits and parasol cells had 6.3±2.7 subunits (mean ± standard deviation). Furthermore, to analyze how the subunits of different cells relate to each other, we identified all pairs of subunits from different individual ganglion cells that displayed an overlap and quantified the relative overlap by the Jaccard index. The maximum value of this index is unity, which would indicate identical, fully overlapping subunits, whereas values near zero correspond to minimal overlap. Particularly high relative overlap of pairs of subunits occurred mostly for OFF parasol cells, as illustrated in an example of subunits from two cells in <xref rid="fig8" ref-type="fig">Figure 8B</xref>. Midget ganglion cells, on the other hand, showed far fewer near identical subunits obtained from two neighboring ganglion cells of the same type. Rather, subunit layouts of neighboring cells complemented each other, jointly tiling space with little overlap (see example in <xref rid="fig8" ref-type="fig">Figure 8C</xref>). Consistent with anatomical evidence, we find a higher degree of subunit sharing among parasol cells compared to midget cells. Dendritic trees of midget ganglion cells do not overlap independent of eccentricity, while parasol cells do show overlap in the periphery primate retina (<xref ref-type="bibr" rid="c31">Dacey 1993</xref>; <xref ref-type="bibr" rid="c80">Lee et al. 2010</xref>), suggesting the possibility of systematically shared input.</p>
</sec>
<sec id="s2i">
<title>Different ganglion cell types display distinct subunit mosaics</title>
<p>Our results indicate that subunits of ganglion cells belonging to the same functional type arrange in a tiling pattern across the retinal space (<xref rid="fig6" ref-type="fig">Figure 6C</xref>). Within functional types, we thus expect pairwise overlap of subunits to typically remain small. To test this, we computed the relative overlap for each pair of subunits for parasol cells (<xref rid="fig8" ref-type="fig">Figure 8D</xref> left) and for midget cells (<xref rid="fig8" ref-type="fig">Figure 8D</xref> right). Within subunit pairs of ganglion cells from the same type, we observe only few cases of relative overlap beyond 50% of overlap, indicating that violations of subunit tiling are rare. However, some subunit pairs display particularly strong overlap, especially for pairs obtained from OFF parasol cells. These may indicate shared subunits, as would be expected from joint input to the two cells from the same bipolar cells. Unlike within types, subunits do not arrange regularly across ganglion cell types. For parasol versus midget cells, this is already indicated by differences in subunit size (<xref rid="fig8" ref-type="fig">Figure 8A</xref>). For ON versus OFF parasol cells as well as for ON versus OFF midget cells, we observe a continuum of overlap values with many violations of tiling (overlap larger than about 50%) in subunit pairs of one ON- and one OFF-type ganglion cell (<xref rid="fig8" ref-type="fig">Figure 8D</xref> bottom). As the violations occur substantially more often across than within ON and OFF types, they suggest the existence of distinct ON and OFF subunit mosaics.</p>
</sec>
<sec id="s2j">
<title>ON- and OFF-type subunit mosaics are aligned</title>
<p>Having characterized large-scale subunit mosaics of ON- as well as OFF-type ganglion cells of corresponding types, we next asked whether these mosaic pairs display any type of spatial coordination with each other. For example, the layouts of subunits from ON and OFF parasol cells might be aligned with each other, with approximately matching subunit locations between the two mosaics. Alternatively, the mosaics might be anti-aligned with subunit locations of one population lying preferentially in between several subunits of the other population. Or the two mosaics might be independent of each other, displaying no specific coordination. On the level of receptive fields of ganglion cells, a recent study had demonstrated that the mosaics of ON and OFF cells of corresponding types (parasol ganglion cells in macaque) tend to be anti-aligned, following a prediction from efficient coding theory (<xref ref-type="bibr" rid="c105">Roy et al. 2021</xref>). We thus asked whether a corresponding coordination can be observed at the preceding processing layer, as the subunits reflect the organization of the inputs coming to the ganglion cells, which stem from their presynaptic bipolar cells.</p>
<p>For both parasol and midget cells, we selected a recording with particularly dense coverage of receptive fields in order to investigate alignment between ON- and OFF-type mosaics within regions with good coverage of identified subunits (<xref rid="fig9" ref-type="fig">Figure 9A</xref>). To quantify the level of alignment, we followed the procedure proposed by <xref ref-type="bibr" rid="c105">Roy et al. (2021)</xref>. We reduced the contour of each receptive field to a single coordinate point, defined by its center-of-mass. We then computed the inter-mosaic coordination energy (IMCE), which describes the pairwise spacing between centroids across mosaics of different cell types (<xref ref-type="bibr" rid="c105">Roy et al. 2021</xref>). In this analysis, each heterotypic pair of centroids contributes energy to the IMCE depending on the distance between the two centroids, with smaller distances corresponding to higher energies. Thus, higher values of the IMCE indicate stronger alignment between the mosaics.</p>
<fig id="fig9" position="float" orientation="portrait" fig-type="figure">
<label>Figure 9.</label>
<caption><title>ON- and OFF-type subunit mosaics are aligned, while receptive field mosaics show anti-alignment.</title>
<p>(<bold>A</bold>) Contour mosaics of ON- and OFF-type parasol (top) and ON- and OFF-type midget (bottom) ganglion cell receptive fields, each from one retina, mid-periphery and periphery, respectively. Centers of mass (black markers) inside the region of interest (ROI, shaded area) are considered for analysis (colored markers inside black frame, right). One center-of-mass mosaic is shifted relative to the other, as schematically indicated (right); n = numbers of enclosed subunits. (<bold>B</bold>) Topographical map visualizing the inter-mosaic coordination energy (IMCE) at different mosaic shifts around the original position in the center. (<bold>C</bold>) Dependence of the IMCE on radial distance by averaging across angles in (<bold>B</bold>), displaying mean (black) and standard deviation (shaded gray). IMCE topographical map and radial average curves are z-scored, and the shift distance <italic>r</italic> is normalized to the median homotypic nearest-neighbor distance of the ON-type mosaic. (<bold>D</bold>-<bold>F</bold>) Same as (<bold>A</bold>-<bold>C</bold>), but for the subunit mosaics of the cell populations analyzed in (<bold>A</bold>-<bold>C</bold>). The red rectangles in (<bold>D</bold>) correspond to the red rectangles of the corresponding cell populations in (<bold>A</bold>). The decreasing IMCE curves in (<bold>F</bold>) indicate that corresponding ON and OFF subunit mosaics tend to be aligned.</p></caption>
<graphic xlink:href="590506v2_fig9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The analysis consists of observing how the IMCE changes as one mosaic is shifted vertically and horizontally relative to the other (<xref rid="fig9" ref-type="fig">Figure 9A</xref> right). For aligned mosaics, paired centroids are close to one another and the energy is initially high and decreases with shifting. For anti-aligned mosaics, the energy rises, as centroids shift closer to each other. Finally, for independent mosaics, there is no distinct increase or decrease. We visualize the IMCE for different mosaic offsets as a topographic map (<xref rid="fig9" ref-type="fig">Figure 9B</xref>). To start, we consider the alignment of ganglion cell receptive fields themselves. For both parasol and midget receptive field mosaics, the energy increases with the relative shift between the ON and OFF populations, as evident in the radial average of the topographic map (<xref rid="fig9" ref-type="fig">Figure 9C</xref>). This indicates that the ON- and OFF-type receptive field mosaics are anti-aligned, as previously reported for parasol cells in the macaque retina (<xref ref-type="bibr" rid="c105">Roy et al. 2021</xref>).</p>
<p>We then applied the procedure also to the corresponding subunit mosaics (<xref rid="fig9" ref-type="fig">Figure 9D</xref>) of the same parasol and midget cell populations. Unlike for the receptive fields, the IMCE of the subunit mosaics was found to be largest for zero shift, and a decrease with mosaic shift is apparent for both parasol and midget subunit mosaics (<xref rid="fig9" ref-type="fig">Figure 9E-F</xref>). This indicates that, in contrast to receptive field mosaics, subunit mosaics of corresponding ON and OFF cells are aligned. Note that mechanistically, such a switch from aligned subunits to anti-aligned receptive fields at the next layer of neuronal processing is not contradictory; ON and OFF ganglion cells may simply pool their signals from (aligned) subunits over distinct, anti-aligned spatial regions.</p>
<p>Note further that the mosaics are partially depleted due to missing receptive fields of non-recorded cells. Although the procedure is robust to subsampling to a certain extent (<xref ref-type="bibr" rid="c105">Roy et al. 2021</xref>), we had manually chosen regions of interest for both parasol and midget populations, in which we find few gaps in the tiling for both ON- and OFF-type mosaics (<xref rid="fig9" ref-type="fig">Figure 9D</xref> right). The tested portion of the mosaic pairs include around 20–50 subunits each. Also with larger regions of interest defined by the convex hull of centroid pairs excluding outliers, as proposed (<xref ref-type="bibr" rid="c105">Roy et al. 2021</xref>), the IMCE remained sharply decreasing with relative shifts of the subunit mosaics, corroborating the alignment of the ON- and OFF-type subunits.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We propose a method for subunit identification based on spike-triggered non-negative matrix factorization (STNMF), which finds subunits within a receptive field from recorded spike-train data in a matter of seconds of computation time. The approach enables, for example, large-scale analyses of the primate retina, recovering the nonlinear subunits of the four major ganglion cell types: ON and OFF parasol, and ON and OFF midget cells. This allows in-depth cell-type-specific analyses of subunits on a cell population level, comparison to type-specific anatomical properties, and new insights about the spatial coordination of ON- and OFF-pathway signal transmission.</p>
<sec id="s3a">
<title>Recovered subunits resemble bipolar cell receptive fields in the primate retina</title>
<p>We applied the method to recorded spike trains from marmoset retinas and analyzed their subunit properties. The disparities we reported on the subunits of parasol versus midget ganglion cells align with existing anatomical data. Parasol cells exhibited larger subunits and a higher degree of overlap among neighboring cells compared to midget cells, reflecting their overlapping dendritic trees and shared presynaptic inputs (<xref ref-type="bibr" rid="c31">Dacey 1993</xref>; <xref ref-type="bibr" rid="c80">Lee et al. 2010</xref>).</p>
<p>There are suggestions that functional subunits of primate parasol cell receptive fields correspond to diffuse bipolar cell inputs (<xref ref-type="bibr" rid="c28">Crook et al. 2008</xref>, <xref ref-type="bibr" rid="c27">2014</xref>). Since our subunits from marmoset do not exceed receptive field and dendritic tree size estimates of macaque diffuse bipolar cells (<xref ref-type="bibr" rid="c12">Boycott and Wässle 1991</xref>; <xref ref-type="bibr" rid="c32">Dacey et al. 2000</xref>), it is unlikely that the subunits are composed of combinations of multiple bipolar cell inputs. To the extent of our comparison of midget and parasol cells, the retina of marmoset and macaque are reported to be functionally equivalent (<xref ref-type="bibr" rid="c80">Lee et al. 2010</xref>), though absolute comparisons of subunit and dendritic tree sizes should be taken with caution. Yet, the matching relative sizes of larger subunits and larger presynaptic bipolar cells for parasol compared to midget cells resonate with the idea of subunits reflecting bipolar cell input. Together, our findings concerning subunit density, uniform tiling, and potential sharing of subunits between pairs of parasol cells support the notion that the parasol subunits may correspond to individual bipolar cell inputs. Note, though, that these bipolar cell inputs do not occur in isolation, but are likely shaped and modulated by interactions with amacrine cells (<xref ref-type="bibr" rid="c66">Jacoby et al. 1996</xref>; <xref ref-type="bibr" rid="c78">Kolb and Dekorver 1991</xref>) and gap junctions between individual bipolar cells (<xref ref-type="bibr" rid="c4">Appleby and Manookin 2020</xref>; <xref ref-type="bibr" rid="c65">Jacoby et al. 2000</xref>; <xref ref-type="bibr" rid="c89">Manookin et al. 2018</xref>).</p>
<p>For midget cell subunits, the correspondence to bipolar cell input may seem more difficult. On average, midget ganglion cells appear to receive input from around eight (mid-periphery) up to 13 midget bipolar cells (periphery) in the marmoset retina (<xref ref-type="bibr" rid="c70">Jusuf et al. 2006b</xref>). We typically found fewer subunits per midget ganglion cell. Yet, these subunits of midget cells form a mosaic at the population level and subunit sizes seem consistent with what one might expect for receptive fields of individual bipolar cells. It is possible that the discrepancy in the numbers of subunits and connected bipolar cells reflects that some subunits do not correspond to individual bipolar cells or that some subunits remain undetected. Alternatively, some anatomically connected bipolar cells might not have a strong functional connection to the postsynaptic midget cell under the applied spatiotemporal white-noise stimulus.</p>
</sec>
<sec id="s3b">
<title>Subunits arrange in a uniform mosaic by cell type</title>
<p>Our subunit analysis with STNMF revealed distinct mosaics of subunits for ON and OFF parasol, and ON and OFF midget cells in the marmoset retina. The distinct subunit mosaics are in line with ganglion cell types stratifying in different levels of the inner plexiform layer (<xref ref-type="bibr" rid="c120">Watanabe and Rodieck 1989</xref>) and receiving input from distinct bipolar cell types (<xref ref-type="bibr" rid="c91">Masland 2001</xref>; <xref ref-type="bibr" rid="c119">Wässle 2004</xref>). The observed uniformity of the subunit mosaics matches reports of bipolar cell input density to be independent of the size of the dendritic tree of the ganglion cell in the marmoset retina (<xref ref-type="bibr" rid="c43">Eriköz et al. 2008</xref>).</p>
<p>There is recent evidence that the mosaics of ON and OFF parasol ganglion cell receptive fields in the macaque retina are spatially anti-aligned (<xref ref-type="bibr" rid="c105">Roy et al. 2021</xref>). Models of efficient coding indicate that anti-alignment is the optimal arrangement between populations of ON and OFF cells in a high-noise/high-threshold coding regime, in which ganglion cells likely operate, as it allows nearby ON and OFF cells to encode non-redundant information (<xref ref-type="bibr" rid="c68">Jun et al. 2021</xref>). Increased resolution is an additional benefit of anti-alignment, and it may have advantages for down-stream convergence (<xref ref-type="bibr" rid="c105">Roy et al. 2021</xref>). Our present analysis confirmed the anti-alignment of ganglion cell receptive fields. By contrast, the same analysis applied to the identified subunit mosaics indicated alignment rather than anti-alignment between ON- and OFF-type subunit mosaics for midget as well as for parasol cells. Thus, there seems to be a switch from aligned to anti-aligned spatial coordination when going from the bipolar cell layer to the ganglion cell layer.</p>
<p>A reason for this switch could be that the conditions that make anti-alignment efficient for ganglion cell receptive fields do not hold at the level of bipolar cells. Due to the finer mosaics of bipolar cells, anti-alignment may offer little additional benefit in spatial resolution. Furthermore, the accumulated noise at the bipolar cell level, where signals are carried by graded potentials rather than stochastic spikes, is likely lower than after spike generation in ganglion cells (<xref ref-type="bibr" rid="c7">Berry et al. 1997</xref>), and – in contrast to the high-noise scenario – alignment is thought to be optimal for efficient coding in the low-noise regime (<xref ref-type="bibr" rid="c68">Jun et al. 2021</xref>). Mechanistically, the alignment of ON and OFF subunits might be aided by or even arise from the fact that ON and OFF bipolar cells receive their input from the same presynaptic cells, the cone photoreceptors under our photopic light conditions. In the peripheral primate retina, cones are sparse and comparatively large, which may bias ON and OFF subunits towards similar positions. Moreover, subunits of midget ganglion cells may contain just a single cone location, as has been shown for OFF midget cells in the macaque retina (<xref ref-type="bibr" rid="c45">Freeman et al. 2015</xref>), which may lead to naturally aligned subunits if the same cone forms the basis of a subunit for both an OFF and an ON midget cell.</p>
</sec>
<sec id="s3c">
<title>Accelerated Fast HALS as a fast and versatile method for STNMF</title>
<p>The large-scale analyses were made possible by the improved methodology of different aspects in the STNMF approach. Through purpose-built initialization, the method is steered towards a suitable solution, and by means of a tailored NMF algorithm, it is scalable to large-scale population recordings. Furthermore, by adjusting consensus methods to our needs, we demonstrated a viable method for hyperparameter selection. Our findings suggest that the selection of the sparsity regularization parameter based on a subset of neuronal cells is transferable to cells of the same functional type. Subsequent analyses for cells of the same type reduce to a parameter-free procedure that can be applied in a plug- and-play fashion.</p>
<p>Solving a non-negative least squares problem (NNLS) sits at the core of NMF. To solve it accurately, typically, costly algorithms are employed iteratively (<xref ref-type="bibr" rid="c76">Kim and Park 2011</xref>). These include multiplicative updates (<xref ref-type="bibr" rid="c81">Lee &amp; Seung, 1999</xref>), the projected quasi-Newton method (D. Kim et al., 2007), the projected gradient method (Lin, 2007), non-negative quadratic programming (Zdunek &amp; Cichocki, 2008), and the active-set method (<xref ref-type="bibr" rid="c79">Lawson &amp; Hanson, 1974</xref>). The algorithms strive to provide exact solutions at each iteration by taking into account all data at once. Here, we avoid the high computational demand with hierarchical alternating least squares (HALS) by solving smaller, non-restricted least squares problems followed by setting all negative values to zero (<xref ref-type="bibr" rid="c23">Cichocki et al. 2007</xref>; <xref ref-type="bibr" rid="c59">Ho 2008</xref>; <xref ref-type="bibr" rid="c84">Li and Zhang 2009</xref>). While Fast HALS (<xref ref-type="bibr" rid="c22">Cichocki and Phan 2009</xref>) simplifies computational operations for speed, A-HALS (<xref ref-type="bibr" rid="c51">Gillis and Glineur 2012</xref>) refines the coarse approximations of HALS by performing multiple cycles of updates within one NMF iteration. The intended purpose of A-HALS is to accelerate the convergence by reducing the number of necessary iterations, which lends it its name. However, by incorporating sparsity regularization, we make use of another advantage of this procedure. Additional constraints like sparsity regularization are typically integrated into the equations of the iterative update (<xref ref-type="bibr" rid="c74">Kim and Park 2007</xref>; <xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>). As we instead perform it multiple times, that is, at each A-HALS cycle within one NMF iteration, the continuously applied sparsity constraint refines the subsequent repetitions by giving more weight to prominent structures and progressively suppressing the effect of uncorrelated noise. Consequently, the result after one full iteration offers relatively high accuracy and sparsity. Our AF-HALS method with sparsity regularization may prove to be a valuable tool not only for the estimation of subunits, but also for other applications of NMF.</p>
</sec>
<sec id="s3d">
<title>Sparsity regularization as a crucial ingredient of STNMF</title>
<p>In the field of machine learning, sparsity regularization has become an important tool to combat overfitting and has earned the role of an enhancement strategy to allow generalization when data is limited. In many applications of signal processing and learning representations, however, sparsity has proved to be an even more essential and critical player (<xref ref-type="bibr" rid="c17">Candès et al. 2006</xref>; <xref ref-type="bibr" rid="c30">d’Aspremont et al. 2007</xref>; <xref ref-type="bibr" rid="c40">Donoho 2006</xref>; <xref ref-type="bibr" rid="c61">Hoyer 2004</xref>). Sparsity in NMF offers interpretable solutions (<xref ref-type="bibr" rid="c30">d’Aspremont et al. 2007</xref>) and even inherently reduces the impact of noise by decreasing the effects of uncorrelated patterns in inputs (<xref ref-type="bibr" rid="c39">Donoho 1995</xref>; <xref ref-type="bibr" rid="c41">Elad 2006</xref>; <xref ref-type="bibr" rid="c63">Hyvärinen 1999</xref>). Aside from these benefits, sparsity is an integral part of STNMF. It replaces the dropped non-negativity constraint of one factor matrix in semi-NMF (<xref ref-type="bibr" rid="c60">Hoyer 2002</xref>, <xref ref-type="bibr" rid="c61">2004</xref>; <xref ref-type="bibr" rid="c74">Kim and Park 2007</xref>, <xref ref-type="bibr" rid="c75">2008</xref>), as otherwise the parts-based reconstruction can collapse (<xref ref-type="bibr" rid="c38">Ding et al. 2010</xref>). In the context of STNMF, sparsity is thus a vital component for producing localized subunits.</p>
<p>Beyond simple ℓ1-norm-based sparsity, there have been other efforts towards regularization techniques that favor localized solutions in the fields of NMF and clustering such as decomposing widefield calcium imaging signals into localized functional brain regions (<xref ref-type="bibr" rid="c107">Saxena et al. 2020</xref>). The prior definition of the localized regions based on a brain atlas in this previous study, however, does not easily translate to our problem of identifying subunits of unknown number, locations, and shapes. A different approach to enforce localized solutions is to apply a locally normalized ℓ1-regularization, which was introduced with spike-triggered clustering (<xref ref-type="bibr" rid="c110">Shah et al. 2020</xref>) to instill spatial information into the ℓ1-regularization in subunit estimation. The penalty of sparsity regularization at a given location of a subunit was adjusted based on the spatially neighboring values. For our application, the forced locality is not directly applicable, as it makes a module either contain a localized pattern or collapse to no non-zero values. Noise in the input cannot easily escape to excess modules, and the number of included modules would have to be precisely determined instead of using an upper bound on the number of expected subunits as is done here. An alternative approach to regularization with localized structures comes from using basis functions to parameterize stimulus filters. For example, using spline-based parametrizations can help estimate receptive fields and has also been combined with subunit-based model fits (<xref ref-type="bibr" rid="c62">Huang et al. 2021</xref>).</p>
</sec>
<sec id="s3e">
<title>Parameter selection by consensus analysis</title>
<p>To find a suitable amount of sparsity regularization, we investigated how robust the decomposition is with respect to varying initialization. To measure how stable the decomposition is, we here adjust the consensus procedure proposed by <xref ref-type="bibr" rid="c14">Brunet et al. (2004)</xref> to be applied to the problem of identifying regularization parameters. An alternative to using consensus analysis is L-curve fitting. The L-curve technique (<xref ref-type="bibr" rid="c56">Hansen 1999a</xref>, <xref ref-type="bibr" rid="c57">1999b</xref>) aids in determining a suitable parameter for a regularized least squares problem. The method inspects the relation between two norms, the fitted data and the regularization term. With too much regularization, the data will not be properly accounted for, and with too little regularization, the fit will be good but dominated by undesired effects. Both terms are visualized against each other for a range of regularization values, exhibiting a curve shaped like the letter “L”. Determining a corner point can then be used to obtain a suitable trade-off between the two terms for the least squares optimization and the regularization penalty. An advantage over our proposed consensus analysis is the conceptual simplicity and that it does not require multiple repetitions of NMF. It has been applied to regularized NMF with HALS previously, although for a different type of regularization (<xref ref-type="bibr" rid="c22">Cichocki and Phan 2009</xref>). Nevertheless, when applied to STNMF, we did not find a sharp corner with the data available, and also the dedicated method of L-corner fitting (<xref ref-type="bibr" rid="c55">Hansen 1994</xref>) did not succeed. We therefore turned towards the more involved consensus analysis, which we found to provide a good alternative.</p>
</sec>
<sec id="s3f">
<title>NNSVD-LRC offers reliable initialization</title>
<p>We demonstrate that a single run of STNMF with SVD-based initialization can replace the selection of the most suitable solution among 100 randomly initialized runs. Specifically, NNSVD-LRC is advantageous, as it converges faster to a stationary point due to low error and increased sparsity in the initialization (<xref ref-type="bibr" rid="c5">Atif et al. 2019</xref>). Notably, on the one hand, techniques based on SVD do not guarantee NMF to find the global optimum (<xref ref-type="bibr" rid="c5">Atif et al. 2019</xref>). On the other hand, however, seeking the global optimum in network structures bears the risk of overfitting (<xref ref-type="bibr" rid="c21">Choromanska et al. 2015</xref>). Furthermore, the alternative of selecting a most suitable among many randomly initialized solutions raises challenges because a measure of suitability is not easily defined and a manual selection of a best solution or a particular criterion is subject to human bias. To alleviate these problems, an adapted consensus clustering procedure (<xref ref-type="bibr" rid="c124">Zhou et al. 2020</xref>) poses a viable alternative for initialization. Instead of choosing the best decompositions among 100 randomly initialized NMF runs, the resulting modules are concatenated to serve as the input to another NMF run that yields a final set of modules. We found that decompositions initialized with NNSVD-LRC are comparable with solutions of that approach while requiring only one run of NMF.</p>
</sec>
<sec id="s3g">
<title>Limitations</title>
<p>We identify three primary limitations of the proposed method. Firstly, the method poses strict constraints on the stimulus with which the spiking data is obtained. To infer subunits from pixel correlations in the spiking response, a white-noise stimulus with uncorrelated pixel contrast across space is necessary. This demands to allocate time to a specific stimulus during the experimental recording. Here, we were able to recover subunits successfully from less than one hour of recording time. Another caveat is the pixel size of the stimulus. Although STNMF makes few assumptions on the data, the stimulus design must provide stimulus pixels of suitable size to fit bipolar cell receptive fields, whose spatial scales can vary with species and with location on the retina. To aid stimulus design, estimates of dendritic-tree size or measured receptive fields in the literature can be consulted, or relevant spatial scales of nonlinear integration can be estimated from responses to standard reversing-grating stimuli at varying spatial frequency. The third drawback is the inability to produce subunits with both positive and negative components. Although the unconstrained sign of the STNMF weights allows the recovery of subunits that have either purely positive or purely negative entries, mixed structures, such as subunits with an antagonistic surround, are not consistent with the non-negativity constraint. One might speculate that antagonistic structures could be recovered as separate, additional subunits if their effects are strong enough, but we have not observed such cases in our datasets.</p>
</sec>
<sec id="s3h">
<title>Comparison to other methods of subunit inference</title>
<p>Popular computational methods of subunit inference in recent years have been linear-nonlinear cascade models (<xref ref-type="bibr" rid="c86">Maheswaranathan et al. 2018</xref>; <xref ref-type="bibr" rid="c103">Real et al. 2017</xref>), approaches of convolutional neural network models (<xref ref-type="bibr" rid="c87">Maheswaranathan et al. 2023</xref>; <xref ref-type="bibr" rid="c94">McIntosh et al. 2016</xref>; <xref ref-type="bibr" rid="c113">Tanaka et al. 2019</xref>), and methods of statistical inference (<xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>; <xref ref-type="bibr" rid="c110">Shah et al. 2020</xref>). Linear-nonlinear-linear-nonlinear (LNLN) models consist of a layer of linear filters of the spatial or spatiotemporal subunits with nonlinear transfer functions that additively converge into another nonlinear transfer function to produce a firing rate or spiking probability. Recent work has demonstrated how the filters and nonlinearities can be trained in a supervised manner on the stimulus input and spiking response (<xref ref-type="bibr" rid="c86">Maheswaranathan et al. 2018</xref>). This approach directly yields a generative model for predicting responses to novel stimuli. It was successfully applied to data from retinal ganglion cells of salamanders. To combat complexity, sparsity regularization was applied as well as restricting the stimulus to one spatial dimension. Training may struggle here when going to two spatial dimensions, as the dimensionality of the optimization task will be strongly increased.</p>
<p>Convolutional neural networks are similarly trained end-to-end. The models are often optimized on data from a population of neurons and provide convolutional filters of subunit types rather than individual subunits for each neuron. Training can be done with natural images instead of artificial stimuli like white noise or flickering bars. For models trained with ganglion cell data from the salamander retina, the obtained convolutional filters shared properties with actual bipolar and amacrine cells (<xref ref-type="bibr" rid="c87">Maheswaranathan et al. 2023</xref>; <xref ref-type="bibr" rid="c113">Tanaka et al. 2019</xref>), although it remains unclear to what extent the model architecture resembles the actual neural circuitry. Spike-triggered clustering (<xref ref-type="bibr" rid="c110">Shah et al. 2020</xref>), on the other hand, recovers subunits on stimulus correlations much like STNMF. Subunit number and regularization are here determined through cross-validation, and the obtained models were demonstrated to be capable of predicting spiking responses to natural scenes for primate retinal ganglion cells.</p>
<p>A common trait of the state-of-the-art subunit inference techniques is their high demand on computational power and time. The training of parameters of a convolutional neural network requires powerful GPUs and hours of training. Extensive cross-validation to find the most suitable number of subunits is a reoccurring obstacle as it is time-consuming and often has to be performed for every neuron as the number of subunits may vary. In comparison, our implementation of STNMF offers an analysis of only a few seconds on a conventional office CPU and provides the number of subunits automatically. Hyperparameter search is reduced to a subset of neurons for each cell type making a subunit population analysis considerably faster than previously available.</p>
</sec>
<sec id="s3i">
<title>Beyond retinal subunits</title>
<p>Nonlinear signal integration is a ubiquitous feature of neural systems and of sensory signal processing in particular. Analyses based on receptive field subunits are thus applicable to many other sensory areas and have been applied in visual cortex (<xref ref-type="bibr" rid="c2">Almasi et al. 2020</xref>; <xref ref-type="bibr" rid="c6">Bartsch et al. 2022</xref>; <xref ref-type="bibr" rid="c82">Lehky et al. 1992</xref>; <xref ref-type="bibr" rid="c117">Vintch et al. 2015</xref>), in medial superior temporal visual cortex (<xref ref-type="bibr" rid="c9">Beyeler et al. 2016</xref>; <xref ref-type="bibr" rid="c95">Mineault et al. 2012</xref>), and in the auditory system (<xref ref-type="bibr" rid="c1">Ahrens et al. 2008</xref>; <xref ref-type="bibr" rid="c58">Harper et al. 2016</xref>; <xref ref-type="bibr" rid="c73">Keshishian et al. 2020</xref>; <xref ref-type="bibr" rid="c93">McFarland et al. 2013</xref>). The methodology presented in the present work is directly applicable to these systems, given sufficiently long recordings with white-noise-like stimuli. In the case of the auditory system, for example, subunits might then correspond to filters in spectro-temporal space, whereas subunits in higher, motion-sensitive visual cortical areas may be partly defined by their direction and speed tuning. Applying STNMF in these systems should aid in developing nonlinear stimulus–response models that link the functional circuitry to the performed neural computations.</p>
<p>In addition to sensory systems, the implementation of NMF developed here together with the presented techniques for controlling hyperparameters and initialization should be of interest for analyzing neuronal population activity. Uncovering hidden structure and dynamics in the joint activity of large ensembles of neurons is seen as an important part of understanding neural computations and information flow in the brain, and a common approach is to identify latent variables of the population activity via dimensional-reduction techniques (<xref ref-type="bibr" rid="c29">Cunningham and Yu 2014</xref>; <xref ref-type="bibr" rid="c47">Gallego et al. 2017</xref>; <xref ref-type="bibr" rid="c48">Gao and Ganguli 2015</xref>; <xref ref-type="bibr" rid="c77">Koh et al. 2022</xref>). NMF provides an appealing approach to this challenge, as one may hope that the non-negativity constraint helps infer latent variables—the equivalent of the subunits of the ganglion cell receptive fields—with interpretable structure (<xref ref-type="bibr" rid="c19">Carbonero et al. 2023</xref>; <xref ref-type="bibr" rid="c36">Devarajan 2008</xref>; <xref ref-type="bibr" rid="c98">Nagayama et al. 2022</xref>; <xref ref-type="bibr" rid="c99">Onken et al. 2016</xref>). The computational speed achieved by the combination of fast and accelerated HALS as demonstrated in this work should be advantageous for applications of NMF to neural population data, in particular in order to control regularization and other hyperparameters.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>This work was supported by the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement number 724822) and by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – project numbers 432680300 (SFB 1456, project B05) and 515774656.</p>
</ack>
<sec id="s4">
<title>Author contributions</title>
<p>SJZ developed and implemented the AF-HALS-based STNMF method, collected and curated the marmoset retina data, analyzed the data, and prepared figures and the initial draft of the manuscript. DK, MHK, HMS, SS, VR, SK, MM, and DAP all contributed to experiments and data collection. SJZ, DK, MHK, HMS, and TG supplied methodology. TG supervised the project and contributed to writing the manuscript. All authors helped revise the manuscript.</p>
</sec>
<sec id="s5">
<title>Disclosure statement</title>
<p>The authors declare no competing interests.</p>
</sec>
<sec id="s6">
<title>Data and software availability</title>
<p>The salamander spike trains analyzed in this work come from a publicly accessible repository (<ext-link ext-link-type="uri" xlink:href="https://gin.g-node.org/gollischlab/Liu_etal_2017_RGC_spiketrains_for_STNMF">https://gin.g-node.org/gollischlab/Liu_etal_2017_RGC_spiketrains_for_STNMF</ext-link>; DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.12751/g-node.62b65b">10.12751/g-node.62b65b</ext-link>). We have made the marmoset spike trains from the present study publicly available in this repository: <ext-link ext-link-type="uri" xlink:href="https://gin.g-node.org/gollischlab/Zapp_Gollisch_2023_Marmoset_RGC_spiketrains_under_spatiotemporal_white_noise">https://gin.g-node.org/gollischlab/Zapp_Gollisch_2023_Marmoset_RGC_spiketrains_under_spatiotemporal_white_noise</ext-link> (DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.12751/g-node.zpj6rc">10.12751/g-node.zpj6rc</ext-link>). The implemented software for STNMF analysis is provided as a Python package. It includes the NMF algorithm and initialization procedures optimized with NumPy for multi-threaded CPU computation. Tools for visualization are also available as well as routines for the consensus analysis and custom extensions via callback functions. The software, along with an extensive documentation and example code for running the analysis, is available in a GitHub repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/gollischlab/STNMF_with_AFHALS">https://github.com/gollischlab/STNMF_with_AFHALS</ext-link>.</p>
</sec>
<sec id="s7">
<title>Methods</title>
<sec id="s7a">
<title>Ethics statement</title>
<p>All experimental procedures were performed in strict accordance with national and institutional guidelines. Recordings from marmoset retinas were performed on tissue obtained from animals used by other researchers, as approved by the institutional animal care committee of the German Primate Center and by the responsible regional government office (Niedersächsisches Landesamt für Verbraucherschutz und Lebensmittelsicherheit, permit number 33.19-42502-04-17/2496).</p>
</sec>
<sec id="s7b">
<title>Electrophysiology</title>
<p>The salamander data stem from a publicly available repository (<xref ref-type="bibr" rid="c52">Gollisch and Liu 2018</xref>) and had been described and analyzed in a previous publication (<xref ref-type="bibr" rid="c85">Liu et al. 2017</xref>). Here, we analyzed spike trains of the first retina recording in the repository (“cell_data_01_NC.mat”). The spike trains had been recorded from ganglion cells in isolated axolotl salamander (<italic>Ambystoma mexicanum</italic>) retinas, mounted on 252-channel planar multi-electrode arrays (MEAs) and provided with oxygenated Ringer’s solution at a constant temperature of around 22°C.</p>
<p>Data from common marmoset (<italic>Callithrix jacchus</italic>) were recorded from retinas of three animals of different sex and age (female 2.3 years, male 18.1 years, and male 13.2 years). The eyes were removed between three and twelve minutes after time of death. Left and right eye were labeled and dark-adapted for at least one hour. The retina was isolated and cut into pieces, classified at time of dissection by their quadrant (nasal, superior, and dorsal) and eccentricity (central, mid-periphery, and periphery). The temporal quadrant was not considered due to the optic disc and the high density of cell bodies and axons at the fovea. Dissection was performed under infrared illumination on a stereo-microscope equipped with night-vision goggles. Individual retina pieces were removed carefully from the sclera and choroid and placed on MEAs (MultiChannel Systems, Reutlingen, Germany). Pieces not recorded immediately were stored in darkness in oxygenated (95% O2 and 5% CO2) Ames’ solution, supplemented with 6 mM D-glucose, and buffered with 22 mM NaHCO3 to maintain a pH of 7.4. The data analyzed in this work were recorded from three pieces (one mid-periphery, two periphery), using either a conventional 60-channel MEA (10 µm electrode diameter, 100 µm electrode distance; one recording) or a 60-channel perforated MEA (30 µm electrode diameter, 100 µm electrode distance; two recordings), containing holes between the electrodes in order to keep the retina piece in place by slight suction from below. On the conventional MEA, the piece was held in place by coating the MEA with poly-D-lysine (Millipore, 1 mg/mL), applied to the array for one to two hours and then rinsed off prior to mounting.</p>
<p>During recording, the retina pieces were perfused with oxygenated Ames’ solution and kept at a constant temperature of around 32–34°C, using an in-line heater and, in the case of the conventional MEA, additionally a heating plate below the array. Bandpass-filtered (300 Hz to 5 kHz) voltage signals from each electrode were sampled at 25 kHz. Spikes were extracted using Kilosort (<xref ref-type="bibr" rid="c101">Pachitariu et al. 2016</xref>) adjusted to accommodate for MEA data (<ext-link ext-link-type="uri" xlink:href="https://github.com/dimokaramanlis/KiloSortMEA">https://github.com/dimokaramanlis/KiloSortMEA</ext-link>). The automated extraction was followed by visual inspection and curation using Phy2 (<ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/phy">https://github.com/cortex-lab/phy</ext-link>). Clusters that displayed good separation from other clusters as well as a uniform spike waveform and a clear refractory period were considered as representing individual ganglion cells.</p>
</sec>
<sec id="s7c">
<title>Visual stimulation</title>
<p>Spiking activity was recorded in response to visual stimulation. Stimuli were projected onto the photoreceptor side of the retina using a gamma-corrected white-light OLED projector (eMagin, USA) at 800 × 600 square pixels with a refresh rate of 60 Hz (salamander and two marmoset experiments) or 85 Hz (one marmoset experiment). The pixel size (width and height) translated to 2.5 µm or 7.5 µm on the retina, depending on the configuration. The projector was controlled by a custom-built software based on C++ and OpenGL to generate the stimulus frames. The spatiotemporal white-noise stimulus was presented with a pixel size of 15 µm on the retina (30 µm for salamander) and temporally updated at 30 Hz (salamander), 20 Hz, or 21.25 Hz (marmoset). The light intensity of each stimulus pixel was drawn independently from a binary distribution with 100% contrast and a mean light level of about 2.5 mW/m<sup>2</sup> (salamander), 3.33 mW/m<sup>2</sup>, or 4.89 mW/m<sup>2</sup> (marmoset). For analysis, the stimulus was described by its contrast values of +1 (bright) or –1 (dark) for each stimulus pixel. The white-noise stimulus was presented in (non-repeating) sections of 50–180 seconds (depending on the experiment), which were periodically interleaved with a presentation of the same, fixed white-noise sequence (10–31 seconds), intended as held-out data for model validation. The data from the fixed white-noise sequence were not considered in this work. The recording durations of the marmoset experiments ranged between 43 minutes and three and a half hours of non-repeated stimuli (3:28, 0:43, and 1:42 hours).</p>
</sec>
<sec id="s7d">
<title>Receptive field analysis</title>
<p>The receptive field of a given ganglion cell was estimated using reverse correlation to obtain the spike-triggered average (STA; <xref ref-type="bibr" rid="c20">Chichilnisky 2001</xref>). The stimulus frames within the 700 ms time window preceding a spike were collected and averaged across all spikes. The STA summarizes the spatiotemporal dynamics of the receptive field. To describe the temporal filter of the STA, we selected the pixel that exhibits the maximum absolute value across all STA frames. We defined the temporal filter as the value of that pixel across time, normalized to unit Euclidean norm. The spatial profile was defined as the stimulus frame of the STA that contained the highest absolute pixel value.</p>
<p>The receptive field diameter was estimated by fitting a two-dimensional Gaussian function to the spatial profile of the STA. The effective receptive field diameter <italic>d</italic> = √<italic>ab</italic> was obtained from the major axis <italic>a</italic> and minor axis <italic>b</italic> of the ellipse at two standard deviations.</p>
<p>For inspection of subunit shape and tiling, contour outlines of the receptive field and subunits were produced. First, the image of each spatial filter was up-scaled by a factor of eight with nearest neighbor sampling and then smoothed with a circular Gaussian filter with a standard deviation appropriate to the spatial size (1.2 original stimulus pixels for receptive fields and 0.5 stimulus pixels for subunits). The contour was determined with the function “find_contours” of the Python module “skimage.measure” at 47.5% of the maximum value of the smoothed filter, equivalent to the 1.22-sigma contour of a circular Gaussian fit. To counter possible expansion effects by the Gaussian smoothing, two-dimensional Gaussians were fit to the smooth and non-smooth filter image. The ratio in their effective diameters was then used to correct and rescale the contour by scaling the contour-level sigma. Contour islands and holes were excluded by selecting the positive closed contour of largest area. Contours were used for visualization of the subunit layouts and mosaics, as well as for determining the relative overlap of two subunits.</p>
</sec>
<sec id="s7e">
<title>Functional cell-type classification</title>
<p>Ganglion cells from marmoset recordings were classified based on their temporal filters and effective receptive field diameters. For each cell, the filter and diameter values were concatenated into a vector and then standardized to zero mean and unit variance across all cells. The vectors’ first few principal components that explained 0.9 of the variance were clustered using K-means clustering. The cells grouped by the cluster labels were checked by visual inspection, and occasional non-matching cells that violated receptive field tiling and temporal filter shape were removed from the cell cluster. The clusters were manually labeled as ON and OFF parasol and ON and OFF midget cells based on the sign and shape of the temporal filter and the diameter of the receptive field. Cells in an additional fifth cluster were considered unclassified and excluded from the analysis (excluded cells for each of the three recordings: 12 out of 109 cells total, 32 out of 127, and 39 out of 103).</p>
</sec>
<sec id="s7f">
<title>Spike-triggered stimulus ensemble</title>
<p>The spatial region of the stimulus relevant to a given ganglion cell’s response was defined as the smallest rectangular window, <italic>x</italic> × <italic>y</italic>, that encloses the three-sigma outline of the Gaussian fit of the receptive field (see above). The set of stimulus sequences that lie within this spatial window and within the 700 ms time window preceding a spike compose the spike-triggered stimulus ensemble. Frames in each spike-triggered stimulus were weighted by the temporal filter of the STA and then summed to one effective stimulus frame per spike. For multiple spikes occurring in one time bin, the identical effective stimulus was repeated accordingly. The effective stimuli of all spikes compose the effective spike-triggered stimulus ensemble (STE). The stimulus frames of the STE with <italic>n</italic> = <italic>x</italic> × <italic>y</italic> pixels were flattened into column vectors to form the STE matrix with dimensions <italic>n</italic> × <italic>y</italic>, corresponding to <italic>n</italic> pixels by <italic>y</italic> spikes.</p>
</sec>
<sec id="s7g">
<title>Sparse semi-non-negative matrix factorization</title>
<p>Semi-non-negative matrix factorization (semi-NMF) decomposes a matrix <bold>V</bold> ∈ ℝ<sup><italic>n</italic>×<italic>y</italic></sup> into two factor matrices <bold>W</bold> ∈ ℝ<sup><italic>n</italic>×<italic>m</italic></sup> and <bold>H</bold> ∈ ℝ<sup><italic>m</italic>×<italic>y</italic></sup> with <italic>m</italic> &lt; <italic>y</italic>, <italic>n</italic>, such that</p>
<disp-formula>
<graphic xlink:href="590506v2_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<p>These variable names are common to NMF terminology and are related to STNMF in the following way: <bold>V</bold> is the STE, where each column <italic>v<sub>i</sub></italic> ∈ ℝ<sup><italic>n</italic></sup> is the effective stimulus frame of spike <italic>i</italic> ∈ 1, … , <italic>y</italic>. The columns of <bold>W</bold>, <italic>w<sub>k</sub></italic> ∈ ℝ<sup><italic>n</italic></sup>, are the <italic>k</italic> ∈ 1, … , <italic>m</italic> spatial modules, and each column of <bold>H,</bold> ℎ<sub><italic>i</italic></sub> ∈ ℝ<sup><italic>m</italic></sup>, contains the corresponding <italic>r</italic> weights for each spike <italic>i</italic> ∈ 1, … , <italic>y</italic>. The stimulus <italic>v<sub>i</sub></italic> that corresponds to spike <italic>i</italic> is approximated by the linear combination of the modules <bold>W</bold>, as basis vectors, and the corresponding weights, ℎ<sub><italic>i</italic></sub> , as coefficients or encodings. The product of <bold>W</bold> and <bold>H</bold> forms a lower-dimensional representation of <bold>V</bold> based on recurring structures within <bold>V</bold>. This gives rise to the basis spatial modules <bold>W,</bold> among which we find the resulting subunits.</p>
<p>Semi-NMF is an NMF variant that relaxes the non-negativity constraint on <bold>V</bold> and <bold>H</bold>, while <bold>W</bold> remains non-negative. To retain parts-based factorizations in semi-NMF, the loosened non-negativity constraint has to be replaced (<xref ref-type="bibr" rid="c38">Ding et al. 2010</xref>). Typically this is achieved by sparsity regularization on <bold>W</bold> (<xref ref-type="bibr" rid="c60">Hoyer 2002</xref>, <xref ref-type="bibr" rid="c61">2004</xref>; <xref ref-type="bibr" rid="c74">Kim and Park 2007</xref>, <xref ref-type="bibr" rid="c75">2008</xref>). Here, this resulted in the use of sparse semi-NMF.</p>
<p>NMF implementations generally improve the approximation <bold>WH</bold> iteratively by minimizing an objective function. As is common for NMF, we chose the Euclidean distance between <bold>V</bold> and the reconstruction <bold>WH</bold>, because it is simple to differentiate (<xref ref-type="bibr" rid="c81">Lee and Seung 1999</xref>). Sparsity was implemented with an ℓ1-norm penalty on the modules as an additional term in the objective function, weighted by a regularization parameter λ</p>
<disp-formula>
<graphic xlink:href="590506v2_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<p>where <italic>w<sub>jk</sub></italic> for <italic>j</italic> = 1, … , <italic>n</italic> and <italic>k</italic> = 1, … , <italic>m</italic> are the elements of <bold>W</bold>, ‖·‖<sup>2</sup> is the squared Frobenius norm and ‖·‖<sub>1</sub> is the ℓ1-norm.</p>
<p>To distinguish the localized subunits from noisy modules in <bold>W</bold>, the spatial autocorrelation was calculated using Moran’s I (<xref ref-type="bibr" rid="c83">Li et al. 2007</xref>; <xref ref-type="bibr" rid="c97">Moran 1950</xref>). Given module w<sub><italic>k</italic></sub> for <italic>k</italic> = 1, … , <italic>m</italic> as the vector <italic>s</italic> ∈ ℝ<sup><italic>n</italic></sup>, the autocorrelation was computed with</p>
<disp-formula>
<graphic xlink:href="590506v2_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<p>where <italic>a</italic>, <italic>b</italic> = 1, … , <italic>n</italic> are pairs of pixel indices, <inline-formula><inline-graphic xlink:href="590506v2_inline1a.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the mean of vector <italic>s</italic>, and <italic><bold>L</bold></italic> ∈ ℝ<sup><italic>n</italic>×<italic>n</italic></sup> is the neighbor matrix with <italic>l<sub>a,b</sub></italic> equal to unity if <italic>a</italic> and <italic>b</italic> correspond to spatially adjacent pixels in the layout <italic>n</italic> = <italic>x</italic> × <italic>y</italic> and zero otherwise. The scalar <italic>I</italic> ranges from negative to positive unity with higher positive values denoting denser localization in space. We chose an autocorrelation threshold of <italic>I</italic> = 0.25 to distinguish localized subunits from noise modules. Additionally, one can consult the mean spike weight of a given module <italic>k</italic> by averaging the <italic>k</italic>th row of <bold>H</bold> to exclude candidate subunits from among the modules when their contribution to the spike generation is small, e.g., smaller than that of non-localized modules. We encountered such low-weight localized modules only rarely and excluded them from the final set of displayed subunits in a few cases based on this criterion.</p>
</sec>
<sec id="s7h">
<title>Accelerated fast hierarchical alternating least squares</title>
<p>The objective function was minimized by alternating optimization of the two factor matrices. Given a prior initialization of <bold>W</bold>, <bold>H</bold> was updated while <bold>W</bold> was held fixed, and <bold>W</bold> was subsequently updated while the newly computed <bold>H</bold> was held fixed. This process is generally repeated until a termination criterion is reached. We here chose a fixed number of 1000 iterations (5000 for selected checks) as most cells showed convergence much earlier. The iterations concluded with a final update of <bold>H</bold> to provide the appropriate weights for the final set of modules. As the update of <bold>H</bold> is unconstrained, unlike the update of <bold>W</bold>, this also helps in obtaining an accurate assessment of the achieved reconstructions error.</p>
<p>The alternating updates of <bold>W</bold> and <bold>H</bold> split the optimization into two sub-problems. In the context of semi-NMF, <bold>H</bold> is not constrained to be non-negative. Given the Euclidean distance objective function, the update of <bold>H</bold> reduces to a least squares problem (<xref ref-type="bibr" rid="c38">Ding et al. 2010</xref>) and can be solved accurately using the Moore-Penrose inverse or pseudoinverse (·)<sup>†</sup></p>
<disp-formula>
<graphic xlink:href="590506v2_ueqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<p>Subsequently, we applied an ℓ2-normalization of the rows of <bold>H</bold>. This normalization step is generally performed in Euclidean-distance-based NMF to counteract non-uniqueness of solutions (since a scaling of a row in <bold>H</bold> can be compensated by an opposite scaling of the corresponding column in <bold>W</bold> without affecting the reconstruction) and to prevent exploding coefficients during the alternating updates of <bold>W</bold> and <bold>H</bold> (<xref ref-type="bibr" rid="c59">Ho 2008</xref>). The update of the non-negative matrix <bold>W</bold>, on the other hand, poses a non-negative least squares (NNLS) problem, in fact a regularized NNLS in the case of sparse semi-NMF. HALS algorithms (<xref ref-type="bibr" rid="c23">Cichocki et al. 2007</xref>) approximate it by updating the modules sequentially. We incorporated our sparsity constraint into Fast HALS (<xref ref-type="bibr" rid="c22">Cichocki and Phan 2009</xref>) with the local update for <italic>w<sub>k</sub></italic> for <italic>k</italic> ∈ 1, … , <italic>m</italic></p>
<disp-formula>
<graphic xlink:href="590506v2_ueqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<p>where <italic>w<sub>k</sub></italic> and (·)<sub><italic>k</italic></sub> are the <italic>k</italic>th column of <bold>W</bold> and of the result of the matrix multiplication in parentheses, respectively, <bold>1</bold><sub><italic>n</italic></sub> ∈ ℝ<sup><italic>n</italic></sup> is a column vector of length <italic>n</italic> containing all ones, and [·]<sub>+</sub> = max{·, 0} is the elementwise maximum with zero of a vector. The terms <bold>VH</bold><sup>⊤</sup> and <bold>HH</bold><sup>⊤</sup> remain fixed, whereas <bold>W</bold> is updated in-between the column updates. This update rule is based on Fast HALS with additional sparsity regularization. Fast HALS simplifies the update equation of HALS and results in a significant speed up (<xref ref-type="bibr" rid="c22">Cichocki and Phan 2009</xref>). It allows terms to be dropped from the HALS equation facilitated by the rows of <bold>H</bold> being ℓ2-normalized prior to the update. Fast HALS takes advantage of this normalization step.</p>
<p>While Fast HALS improves the local update rule on the scale of one module, A-HALS (<xref ref-type="bibr" rid="c51">Gillis and Glineur 2012</xref>) optimizes the computational cost on the scale of all modules in <bold>W</bold>. While <bold>W</bold> is updated continuously, A-HALS exploits the fact that the terms <bold>VH</bold><sup>⊤</sup> and <bold>HH</bold><sup>⊤</sup> in the local update remain unchanged over the course of iterating over the modules. These matrix multiplications outweigh the other terms of the local update rule in the number of floating-point operations, making the update of <bold>W</bold> costly compared to the outcome. A-HALS wraps an outer loop around the local updates of each column of <bold>W</bold>, effectively updating <bold>W</bold> multiple times per one NMF iteration, in order to tradeoff the floating-point operations in the pre-computed matrix multiplications and in the local updates. This increases the approximation at comparably little additional cost and improves the accuracy of a single update of <bold>W</bold>.</p>
<p>To determine the number of outer loop cycles, we found the previously suggested parameters to be suitable (<xref ref-type="bibr" rid="c51">Gillis and Glineur 2012</xref>). The maximum number of outer loop cycles is determined by <italic>α</italic> × <italic>ρ</italic><sub><bold>W</bold></sub>, where <inline-formula><inline-graphic xlink:href="590506v2_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the number of floating-point operations in the update and <italic>α</italic> = 0.5 is a scaling factor. An additional dynamic stopping criterion checks whether the last improvement of <bold>W</bold> is smaller than 10% of the first improvement, that is, in the first cycle of the outer loop. The improvement of <bold>W</bold> is measured as the Frobenius norm of the difference to the previous cycle of the outer loop, <inline-formula><inline-graphic xlink:href="590506v2_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Aside from the acceleration by performing multiple update cycles, A-HALS improves numerical stability by ensuring no zero-columns in <bold>W</bold> to avoid convergence issues of HALS (<xref ref-type="bibr" rid="c50">Gillis and Glineur 2008</xref>; <xref ref-type="bibr" rid="c59">Ho 2008</xref>). Columns of all zeros are replaced by columns whose entries all take a small positive constant (here 10<sup>−16</sup>). In the context of semi-NMF, we observed this to benefit the convergence of an SVD-based pseudoinverse <bold>W</bold><sup>†</sup> for the subsequent update of <bold>H</bold>. We combined Fast HALS and A-HALS by replacing the local update in A-HALS with the equations from Fast HALS and complementing this with sparsity regularization. All analyses were carried out on computers with an Intel Xeon CPU E3-1270 v5 @ 3.60 GHz.</p>
</sec>
<sec id="s7i">
<title>Non-negative singular value decomposition with low-rank correction</title>
<p>The aforementioned alternating optimization starts with an update of the weights <bold>H</bold> inferred from the STE <bold>V</bold> and an initialization of <bold>W</bold>. We initialized the modules <bold>W</bold> using a slightly modified non-negative singular value decomposition with low-rank correction (NNSVD-LRC), which was introduced for NMF (<xref ref-type="bibr" rid="c5">Atif et al. 2019</xref>). Here, we describe a modified version for semi-NMF with slight optimizations. Given <italic>r</italic> modules, we extracted half that number of components from a truncated SVD of <bold>V</bold>. Specifically, we used <inline-formula><inline-graphic xlink:href="590506v2_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> components from the decomposition <bold>V</bold> ≈ <bold>UΣA</bold> with the matrices <bold>U</bold> ∈ ℝ<sup><italic>n</italic>×<italic>p</italic></sup> and <bold>A</bold> ∈ ℝ<sup><italic>p</italic>×<italic>y</italic></sup> and the diagonal matrix <bold>Σ</bold> ∈ ℝ<sup><italic>p</italic>×<italic>p</italic></sup>. To obtain a two-factor form as in NMF, the singular values were integrated into the left and right singular vectors with their element-wise square root to provide <inline-formula><inline-graphic xlink:href="590506v2_inline1b.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="590506v2_inline1c.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, respectively, so that <bold>V</bold> ≈ <bold>UA</bold> with the modified <bold>U</bold> and <bold>A</bold>. Unlike the original NNSVD-LRC, we only initialized <bold>W</bold> (via <bold>U</bold>) and thus discarded <bold>A</bold>. The components of <bold>U</bold> sorted by decreasing singular values served as the columns of <bold>W</bold>. In doing so, each component was used twice, with and without a sign-flip, ordered so that the one with the largest positive element came before its sign-inverted counterpart to ensure reproducible component ordering. (In case of an odd <italic>r</italic>, the component with the lowest singular value was only added once.) In the end, all negative entries were set to zero to make the initialization of <bold>W</bold> non-negative. This resulted in the initialization <bold>W</bold> = [<italic>u</italic><sub>1</sub>, −<italic>u</italic><sub>1</sub>, <italic>u</italic><sub>2</sub>, −<italic>u</italic><sub>2</sub>, … , <italic>u</italic><sub><italic>p</italic></sub>, −<italic>u</italic><sub><italic>p</italic></sub>]<sub>+</sub>. Inspired by A-HALS, we implemented an additional step to avoid numerical instability (<xref ref-type="bibr" rid="c51">Gillis and Glineur 2012</xref>). Any columns of <bold>W</bold> that contained only zeros were set to a small positive value (10<sup>−16</sup>). Any zeros residing in nonzero columns remained to accelerate matrix multiplications and to allow sparsity to emerge.</p>
<p>The solution can be improved further at low computational cost by a few NMF iterations on the low-rank approximation <bold>V</bold><sup>(<italic>p</italic>)</sup> ≈ <bold>UA</bold> . As <bold>V</bold><sup>(<italic>p</italic>)</sup> has a factorization with low-rank matrices, the matrix multiplications for the NMF iterations become less complex, and NMF iterations reduce from a complexity of 𝒪(<italic>nym</italic>) to 𝒪((<italic>n</italic> + <italic>y</italic>)<italic>m</italic><sup>2</sup>) (<xref ref-type="bibr" rid="c5">Atif et al. 2019</xref>; <xref ref-type="bibr" rid="c51">Gillis and Glineur 2012</xref>). In the original NNSVD-LRC, the low-rank NMF was performed using A-HALS until the difference in relative reconstruction error ‖<bold>V</bold><sup>(<italic>p</italic>)</sup> − <bold>WH</bold>‖<sub><italic>F</italic></sub>/‖<bold>V</bold><sup>(<italic>p</italic>)</sup>‖<sub><italic>F</italic></sub> to the previous iteration fell below 5% of the initial error, which typically occurred within ten iterations (<xref ref-type="bibr" rid="c5">Atif et al. 2019</xref>). Here, since we used sparse semi-NMF instead, we observed that the proposed termination criterion was always reached within one AF-HALS update in the case of STNMF. We thus fixed the number of iterations with <bold>V</bold><sup>(<italic>p</italic>)</sup>at one and omitted the termination criterion. Without the need for computing reconstruction errors, it suffices to initialize <bold>W</bold> from the SVD components, leaving <bold>H</bold> to be subsequently computed from the initialization of <bold>W</bold>. This further reduces computational cost and provides a fast initialization procedure.</p>
<p>For comparison and for consensus methods, we applied random initialization of <bold>W</bold> by sampling its values independently from a uniform distribution between zero and unity. We used the Mersenne Twister (MT19937) pseudorandom number generator (<xref ref-type="bibr" rid="c92">Matsumoto and Nishimura 1998</xref>) for potential compatibility across Python, R, and MATLAB. For reproducibility, we applied a specified set of seeds, here ranging from 0 to 49 for the 50 repetitions of the consensus analysis.</p>
</sec>
<sec id="s7j">
<title>Consensus analysis</title>
<p>We used consensus analyses (<xref ref-type="bibr" rid="c14">Brunet et al. 2004</xref>; <xref ref-type="bibr" rid="c96">Monti et al. 2003</xref>) to determine the best tradeoff between solution stability and sparsity. Consensus methods allow judging the robustness of the parameter when there is a lack of measurable error. A typical proxy for goodness of decomposition in the field of NMF is the reconstruction error, or residual, as it is non-increasing over the NMF iterations (<xref ref-type="bibr" rid="c23">Cichocki et al. 2007</xref>). However, with additional constraints like sparsity regularization, the residual does not correspond to the used objective function. Furthermore, in the context of STNMF, the noisy excess modules may influence the residual, but neglecting them instead, favors solutions that exhibit more localized modules over those with fewer. Consequently, decompositions based on different parameters cannot be compared easily by their residual. This is one of the reasons, why cross-validation is not suitable for STNMF.</p>
<p>For applying consensus methods, we performed 30 randomly initialized repetitions of sparse semi-NMF (50 repetitions for the detailed comparative analysis) for a range of parameters. The parameters correspond to different sparsity regularization strengths. Semi-NMF was run for 1000 iterations, which we found to typically be enough to reach convergence. Similarity between solutions was assessed by treating the encodings in <bold>H</bold> as cluster labels and comparing them across solutions. We define cluster labels as the index of the module with the highest absolute weight for a given spike. Although a spike may be elicited by a combination of subunit activations, considering the maximum associated module suffices for sake of comparison. Because the ordering of the emerging modules is arbitrary, the cluster labels cannot be compared across solutions directly. To remove this ambiguity, pairwise comparisons of cluster labels among the spikes within each solution are computed in a connectivity matrix <bold>G</bold>. Each entry <bold>G</bold><sub><italic>ij</italic></sub> in the square matrix is unity, if spikes <italic>i</italic> and <italic>j</italic> share the cluster label and zero otherwise. As the number of unique pairs grows according to <italic>y</italic>(<italic>y</italic> − 1)/2 for increasing number of spikes <italic>m</italic>, we limited ourselves to 25000 spikes selected at random with a persistent selection across the analysis. That amounts to more than one gigabyte of memory at 32-bit floating-point precision for one decomposition. The number may be increased with more memory available or with memory-efficient implementations. Nevertheless, we found that this subsample provides a sufficient representation of the resulting cluster memberships. The elementwise average of the connectivity matrices of all 30 (or 50) solutions expresses the consensus across solutions. This consensus matrix contains values between zero and unity, describing the fraction of agreement between the encodings across the 30 (or 50) runs. We calculated the cophenetic correlation using the function “linkage” to perform hierarchical clustering and “cophenet” to calculate the cophenetic distances within the clustering from the Python module “scipy.cluster.hierarchy”. The coefficient is a real value between zero and unity, with unity denoting perfect consensus and identical solutions (<xref ref-type="bibr" rid="c14">Brunet et al. 2004</xref>).</p>
<p>STNMF reserves excess modules to capture noise in the data. These modules are not considered localized subunits and are not representative of the solution. As uncorrelated noise is distributed arbitrarily across the excess modules, they are likely to vary across solutions. Thereby they skew the described metric. Consequently, we only considered modules containing localized subunits as valid cluster labels. Connectivity pairs involving non-localized modules were set to zero in the connectivity matrices. These entries do not reach consensus across solutions. This causes a lower dispersion in the consensus matrix, quenching the cophenetic correlation coefficients. The metric becomes more sensitive to differences in detected subunits. In the case of no localized subunits in the decomposition, we did not compute the cophenetic correlation. This results in gaps in the stability curve (see <xref rid="fig7" ref-type="fig">Figure 7A</xref> for an example).</p>
<p>The cophenetic correlation coefficient corresponds to the similarity of the recovered subunits across the repeated decompositions. It represents the stability of the solutions, and we used it to compare the different sparsity regularization parameters. The optimal trade-off between high stability and little regularization was found at the bend of the curve of regularization strength versus stability (<xref rid="fig4" ref-type="fig">Figure 4C</xref>). Here, we determined the inflection point by visual inspection and defined it as the most suitable sparsity parameter. To identify it systematically instead, we propose that one could describe the curve as a piecewise linear function with two or three components and select the intersection of the functions.</p>
</sec>
<sec id="s7k">
<title>Subunit comparison</title>
<p>To compare recovered subunits on a geometrical basis, we computed their relative spatial overlap. Given the contour outlines (described above) of two subunits <italic>i</italic> and <italic>j</italic>, we calculated their relative overlap <italic>o<sub>ij</sub></italic> with the Jaccard index (<xref ref-type="bibr" rid="c64">Jaccard 1912</xref>), which is defined as the ratio of the intersection by the union of their areas <italic>a<sub>i</sub></italic> and <italic>b<sub>j</sub></italic>:
<disp-formula>
<graphic xlink:href="590506v2_ueqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>We considered subunit pairs with <italic>o<sub>ij</sub></italic> &gt; 0.5 , that is, more than 50% area overlap, to be strongly overlapping and thus candidates of identical subunits.</p>
<p>For the purpose of determining prevalent subunits across multiple randomly initialized runs of STNMF (<xref rid="fig3" ref-type="fig">Figure 3</xref>), the relative overlap was compared across decompositions. A subunit that showed overlap with <italic>o<sub>ij</sub></italic> &gt; 0.5 across more than 50% of the runs (colored outlines in <xref rid="fig3" ref-type="fig">Figure 3</xref>) was considered a robustly recovered subunit.</p>
</sec>
<sec id="s7l">
<title>Inter-mosaic coordination</title>
<p>The spatial coordination of ON- and OFF-type subunit mosaics was determined using the inter-mosaic coordination energy (IMCE) as proposed previously (<xref ref-type="bibr" rid="c105">Roy et al. 2021</xref>). In brief, contour mosaics were reduced to subunit centroids by their center of mass. Within a region of interest, one of the mosaics (center of mass points) was shifted in horizontal and vertical position relative to the other. The squared inverse distance between each heterotypic pair of centroids <italic>m</italic><sub><italic>ij</italic></sub> was measured with
<disp-formula>
<graphic xlink:href="590506v2_ueqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>m</italic><sub><italic>yin</italic></sub> is a minimum distance set to 0.2 times the median heterotypic nearest-neighbor distance. The values of <italic>e<sub>ij</sub></italic> were averaged across all pairs to obtain the IMCE. The IMCE was computed for different offsets of the OFF-type mosaic relative to the ON-type mosaic on a 50-by-50 Cartesian grid before being z-scored. The shift distances were normalized to the median homotypic nearest neighbor distance of the ON-type (frozen) mosaic. The generated topographic map of IMCE values was radially averaged to examine whether the IMCE increased or decreased with radial shift distance. We selected the analyzed region of interest in two ways. First, we manually chose a region where the density of subunits was approximately homogeneous on both mosaics to minimize effects of gaps. We then confirmed the determined IMCE by following the proposed implementation of finding a suitable convex hull that maximized the number of enclosed heterotypic pairs while excluding outliers (<xref ref-type="bibr" rid="c105">Roy et al. 2021</xref>).</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahrens</surname>, <given-names>M. B.</given-names></string-name>, <string-name><surname>Linden</surname>, <given-names>J. F.</given-names></string-name>, and <string-name><surname>Sahani</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Nonlinearities and Contextual Influences in Auditory Cortical Responses Modeled with Multilinear Spectrotemporal Methods</article-title>. <source>Journal of Neuroscience</source>, <volume>28</volume>(<issue>8</issue>), <fpage>1929</fpage>–<lpage>1942</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Almasi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Meffin</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Cloherty</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Wong</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Yunzab</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Ibbotson</surname>, <given-names>M. R</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Mechanisms of Feature Selectivity and Invariance in Primary Visual Cortex</article-title>. <source>Cerebral Cortex</source>, <volume>30</volume>(<issue>9</issue>), <fpage>5067</fpage>–<lpage>5087</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anishchenko</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Greschner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Elstrott</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Sher</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Litke</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Feller</surname>, <given-names>M. B.</given-names></string-name>, and <string-name><surname>Chichilnisky</surname>, <given-names>E. J</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Receptive field mosaics of retinal ganglion cells are established without visual experience</article-title>. <source>Journal of Neurophysiology</source>, <volume>103</volume>(<issue>4</issue>), <fpage>1856</fpage>–<lpage>1864</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Appleby</surname>, <given-names>T. R.</given-names></string-name>, and <string-name><surname>Manookin</surname>, <given-names>M. B</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Selectivity to approaching motion in retinal inputs to the dorsal visual pathway</article-title>. <source>ELife</source>, <volume>9</volume>, <fpage>e51144</fpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Atif</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Qazi</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Gillis</surname>, <given-names>N</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Improved SVD-based initialization for nonnegative matrix factorization using low-rank correction</article-title>. <source>Pattern Recognition Letters</source>, <volume>122</volume>, <fpage>53</fpage>–<lpage>59</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bartsch</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Cumming</surname>, <given-names>B. G.</given-names></string-name>, and <string-name><surname>Butts</surname>, <given-names>D. A</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Model-based characterization of the selectivity of neurons in primary visual cortex</article-title>. <source>Journal of Neurophysiology</source>, <volume>128</volume>(<issue>2</issue>), <fpage>350</fpage>–<lpage>363</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berry</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Warland</surname>, <given-names>D. K.</given-names></string-name>, and <string-name><surname>Meister</surname>, <given-names>M</given-names></string-name></person-group>. (<year>1997</year>). <article-title>The structure and precision of retinal spike trains</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>94</volume>(<issue>10</issue>), <fpage>5411</fpage>–<lpage>5416</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berry</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Browne</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Langville</surname>, <given-names>A. N.</given-names></string-name>, <string-name><surname>Pauca</surname>, <given-names>V. P.</given-names></string-name>, and <string-name><surname>Plemmons</surname>, <given-names>R. J</given-names></string-name></person-group>. (<year>2007</year>). <article-title>Algorithms and applications for approximate nonnegative matrix factorization</article-title>. <source>Computational Statistics and Data Analysis</source>, <volume>52</volume>(<issue>1</issue>), <fpage>155</fpage>–<lpage>173</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Beyeler</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dutt</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Krichmar</surname>, <given-names>J. L</given-names></string-name></person-group>. (<year>2016</year>). <article-title>3D Visual Response Properties of MSTd Emerge from an Efficient, Sparse Population Code</article-title>. <source>Journal of Neuroscience</source>, <volume>36</volume>(<issue>32</issue>), <fpage>8399</fpage>–<lpage>8415</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Borghuis</surname>, <given-names>B. G.</given-names></string-name>, <string-name><surname>Marvin</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Looger</surname>, <given-names>L. L.</given-names></string-name>, and <string-name><surname>Demb</surname>, <given-names>J. B</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Two-Photon Imaging of Nonlinear Glutamate Release Dynamics at Bipolar Cell Synapses in the Mouse Retina</article-title>. <source>Journal of Neuroscience</source>, <volume>33</volume>(<issue>27</issue>), <fpage>10972</fpage>–<lpage>10985</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boutsidis</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Gallopoulos</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2008</year>). <article-title>SVD based initialization: A head start for nonnegative matrix factorization</article-title>. <source>Pattern Recognition</source>, <volume>41</volume>(<issue>4</issue>), <fpage>1350</fpage>–<lpage>1362</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boycott</surname>, <given-names>B. B.</given-names></string-name>, and <string-name><surname>Wässle</surname>, <given-names>H</given-names></string-name></person-group>. (<year>1991</year>). <article-title>Morphological Classification of Bipolar Cells of the Primate Retina</article-title>. <source>European Journal of Neuroscience</source>, <volume>3</volume>(<issue>11</issue>), <fpage>1069</fpage>–<lpage>1088</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bro</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kjeldahl</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Smilde</surname>, <given-names>A. K.</given-names></string-name>, and <string-name><surname>Kiers</surname>, <given-names>H. A. L</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Cross-validation of component models: A critical look at current methods</article-title>. <source>Analytical and Bioanalytical Chemistry</source>, <volume>390</volume>(<issue>5</issue>), <fpage>1241</fpage>–<lpage>1251</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brunet</surname>, <given-names>J.-P.</given-names></string-name>, <string-name><surname>Tamayo</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Golub</surname>, <given-names>T. R.</given-names></string-name>, and <string-name><surname>Mesirov</surname>, <given-names>J. P</given-names></string-name></person-group>. (<year>2004</year>). <article-title>Metagenes and molecular pattern discovery using matrix factorization</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>101</volume>(<issue>12</issue>), <fpage>4164</fpage>–<lpage>4169</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bryant</surname>, <given-names>H. L.</given-names></string-name>, and <string-name><surname>Segundo</surname>, <given-names>J. P</given-names></string-name></person-group>. (<year>1976</year>). <article-title>Spike initiation by transmembrane current: a white-noise analysis</article-title>. <source>The Journal of Physiology</source>, <volume>260</volume>(<issue>2</issue>), <fpage>279</fpage>–<lpage>314</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Calkins</surname>, <given-names>D. J.</given-names></string-name>, and <string-name><surname>Sterling</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2007</year>). <article-title>Microcircuitry for Two Types of Achromatic Ganglion Cell in Primate Fovea</article-title>. <source>Journal of Neuroscience</source>, <volume>27</volume>(<issue>10</issue>), <fpage>2646</fpage>–<lpage>2653</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Candès</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Romberg</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Tao</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information</article-title>. <source>IEEE Transactions on Information Theory</source>, <volume>52</volume>(<issue>2</issue>), <fpage>489</fpage>–<lpage>509</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cantrell</surname>, <given-names>D. R.</given-names></string-name>, <string-name><surname>Cang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Troy</surname>, <given-names>J. B.</given-names></string-name>, and <string-name><surname>Liu</surname>, <given-names>X</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Non-Centered Spike-Triggered Covariance Analysis Reveals Neurotrophin-3 as a Developmental Regulator of Receptive Field Properties of ON-OFF Retinal Ganglion Cells</article-title>. <source>PLoS Computational Biology</source>, <volume>6</volume>(<issue>10</issue>), <fpage>e1000967</fpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carbonero</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Noueihed</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Kramer</surname>, <given-names>M. A.</given-names></string-name>, and <string-name><surname>White</surname>, <given-names>J. A</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Non-Negative Matrix Factorization for Analyzing State Dependent Neuronal Network Dynamics in Calcium Recordings</article-title>. <source>BioRxiv</source>, <fpage>561797v3</fpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chichilnisky</surname>, <given-names>E. J</given-names></string-name></person-group>. (<year>2001</year>). <article-title>A simple white noise analysis of neuronal light responses</article-title>. <source>Network: Computation in Neural Systems</source>, <volume>12</volume>(<issue>2</issue>), <fpage>199</fpage>–<lpage>213</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Choromanska</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Henaff</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Mathieu</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Arous</surname>, <given-names>G. Ben</given-names></string-name>, and <string-name><surname>LeCun</surname>, <given-names>Y.</given-names></string-name> (). . In <string-name><given-names>G.</given-names> <surname>Lebanon</surname></string-name>, &amp; <string-name><given-names>S. V. N.</given-names> <surname>Vishwanathan</surname></string-name></person-group><year>2015</year>). <chapter-title>The Loss Surfaces of Multilayer Networks</chapter-title>. In , &amp;  (Eds.), <source>Proceedings of Machine Learning Research</source> (Vol. <volume>38</volume>, pp. <fpage>192</fpage>–<lpage>204</lpage>). <publisher-name>PMLR</publisher-name>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cichocki</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Phan</surname>, <given-names>A. H</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Fast local algorithms for large scale nonnegative matrix and tensor factorizations</article-title>. <source>IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences</source>, <volume>E92-A</volume>(<issue>3</issue>), <fpage>708</fpage>–<lpage>721</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Cichocki</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Zdunek</surname>, <given-names>R.</given-names></string-name>, and <string-name><surname>Amari</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2007</year>). <chapter-title>Hierarchical ALS Algorithms for Nonnegative Matrix and 3D Tensor Factorization</chapter-title>. In <source>Independent Component Analysis and Signal Separation</source> (pp. <fpage>169</fpage>–<lpage>176</lpage>). <publisher-name>Springer Berlin Heidelberg</publisher-name>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Cichocki</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Zdunek</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Phan</surname>, <given-names>A. H.</given-names></string-name>, and <string-name><surname>Amari</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2009</year>). <source>Nonnegative Matrix and Tensor Factorizations</source> (<edition>1</edition>st ed.). <publisher-name>Wiley</publisher-name>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cohen</surname>, <given-names>E.</given-names></string-name>, and <string-name><surname>Sterling</surname>, <given-names>P</given-names></string-name></person-group>. (<year>1990a</year>). <article-title>Convergence and divergence of cones onto bipolar cells in the central area of cat retina</article-title>. <source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source>, <volume>330</volume>(<issue>1258</issue>), <fpage>323</fpage>–<lpage>328</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cohen</surname>, <given-names>E.</given-names></string-name>, and <string-name><surname>Sterling</surname>, <given-names>P</given-names></string-name></person-group>. (<year>1990b</year>). <article-title>Demonstration of cell types among cone bipolar neurons of cat retina</article-title>. <source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source>, <volume>330</volume>(<issue>1258</issue>), <fpage>305</fpage>–<lpage>321</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crook</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Packer</surname>, <given-names>O. S.</given-names></string-name>, and <string-name><surname>Dacey</surname>, <given-names>D. M</given-names></string-name></person-group>. (<year>2014</year>). <article-title>A synaptic signature for ON- and OFF-center parasol ganglion cells of the primate retina</article-title>. <source>Visual Neuroscience</source>, <volume>31</volume>(<issue>1</issue>), <fpage>57</fpage>–<lpage>84</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crook</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Peterson</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Packer</surname>, <given-names>O. S.</given-names></string-name>, <string-name><surname>Robinson</surname>, <given-names>F. R.</given-names></string-name>, <string-name><surname>Troy</surname>, <given-names>J. B.</given-names></string-name>, and <string-name><surname>Dacey</surname>, <given-names>D. M</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Y-Cell Receptive Field and Collicular Projection of Parasol Ganglion Cells in Macaque Monkey Retina</article-title>. <source>Journal of Neuroscience</source>, <volume>28</volume>(<issue>44</issue>), <fpage>11277</fpage>–<lpage>11291</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cunningham</surname>, <given-names>J. P.</given-names></string-name>, and <string-name><surname>Yu</surname>, <given-names>B. M</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Dimensionality reduction for large-scale neural recordings</article-title>. <source>Nature Neuroscience</source>, <volume>17</volume>(<issue>11</issue>), <fpage>1500</fpage>–<lpage>1509</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>d’Aspremont</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>El Ghaoui</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Jordan</surname>, <given-names>M. I.</given-names></string-name>, and <string-name><surname>Lanckriet</surname>, <given-names>G. R. G.</given-names></string-name></person-group> (<year>2007</year>). <article-title>A Direct Formulation for Sparse PCA Using Semidefinite Programming</article-title>. <source>SIAM Review</source>, <volume>49</volume>(<issue>3</issue>), <fpage>434</fpage>–<lpage>448</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dacey</surname>, <given-names>D. M</given-names></string-name></person-group>. (<year>1993</year>). <article-title>The mosaic of midget ganglion cells in the human retina</article-title>. <source>Journal of Neuroscience</source>, <volume>13</volume>(<issue>12</issue>), <fpage>5334</fpage>–<lpage>5355</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dacey</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Packer</surname>, <given-names>O. S.</given-names></string-name>, <string-name><surname>Diller</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Brainard</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Peterson</surname>, <given-names>B.</given-names></string-name>, and <string-name><surname>Lee</surname>, <given-names>B</given-names></string-name></person-group>. (<year>2000</year>). <article-title>Center surround receptive field structure of cone bipolar cells in primate retina</article-title>. <source>Vision Research</source>, <volume>40</volume>(<issue>14</issue>), <fpage>1801</fpage>– <lpage>1811</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>De Boer</surname>, <given-names>E.</given-names></string-name>, and <string-name><surname>Kuyper</surname>, <given-names>P.</given-names></string-name></person-group> (<year>1968</year>). <article-title>Triggered Correlation</article-title>. <source>IEEE Transactions on Biomedical Engineering</source>, <volume>15</volume>(<issue>3</issue>), <fpage>169</fpage>–<lpage>179</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Demb</surname>, <given-names>J. B.</given-names></string-name>, and <string-name><surname>Singer</surname>, <given-names>J. H</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Functional Circuitry of the Retina</article-title>. <source>Annual Review of Vision Science</source>, <volume>1</volume>(<issue>1</issue>), <fpage>263</fpage>–<lpage>289</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Demb</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Zaghloul</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Haarsma</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Sterling</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Bipolar Cells Contribute to Nonlinear Spatial Summation in the Brisk-Transient (Y) Ganglion Cell in Mammalian Retina</article-title>. <source>Journal of Neuroscience</source>, <volume>21</volume>(<issue>19</issue>), <fpage>7447</fpage>–<lpage>7454</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Devarajan</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Nonnegative Matrix Factorization: An Analytical and Interpretive Tool in Computational Biology</article-title>. <source>PLoS Computational Biology</source>, <volume>4</volume>(<issue>7</issue>), <fpage>e1000029</fpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>DeVries</surname>, <given-names>S. H.</given-names></string-name>, and <string-name><surname>Baylor</surname>, <given-names>D. A</given-names></string-name></person-group>. (<year>1997</year>). <article-title>Mosaic arrangement of ganglion cell receptive fields in rabbit retina</article-title>. <source>Journal of Neurophysiology</source>, <volume>78</volume>(<issue>4</issue>), <fpage>2048</fpage>–<lpage>2060</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ding</surname>, <given-names>C.</given-names></string-name>, <string-name><given-names>Tao</given-names> <surname>Li</surname></string-name>, and <string-name><surname>Jordan</surname>, <given-names>M. I</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Convex and Semi-Nonnegative Matrix Factorizations</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>, <volume>32</volume>(<issue>1</issue>), <fpage>45</fpage>–<lpage>55</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Donoho</surname>, <given-names>D. L</given-names></string-name></person-group>. (<year>1995</year>). <article-title>De-noising by soft-thresholding</article-title>. <source>IEEE Transactions on Information Theory</source>, <volume>41</volume>(<issue>3</issue>), <fpage>613</fpage>–<lpage>627</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Donoho</surname>, <given-names>D. L</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Compressed sensing</article-title>. <source>IEEE Transactions on Information Theory</source>, <volume>52</volume>(<issue>4</issue>), <fpage>1289</fpage>– <lpage>1306</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Elad</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Why Simple Shrinkage Is Still Relevant for Redundant Representations?</article-title> <source>IEEE Transactions on Information Theory</source>, <volume>52</volume>(<issue>12</issue>), <fpage>5559</fpage>–<lpage>5569</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Enroth-Cugell</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Robson</surname>, <given-names>J. G</given-names></string-name></person-group>. (<year>1966</year>). <article-title>The contrast sensitivity of retinal ganglion cells of the cat</article-title>. <source>The Journal of Physiology</source>, <volume>187</volume>(<issue>3</issue>), <fpage>517</fpage>–<lpage>552</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eriköz</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Jusuf</surname>, <given-names>P. R.</given-names></string-name>, <string-name><surname>Percival</surname>, <given-names>K. A.</given-names></string-name>, and <string-name><surname>Grünert</surname>, <given-names>U</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Distribution of bipolar input to midget and parasol ganglion cells in marmoset retina</article-title>. <source>Visual Neuroscience</source>, <volume>25</volume>(<issue>1</issue>), <fpage>67</fpage>–<lpage>76</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fairhall</surname>, <given-names>A. L.</given-names></string-name>, <string-name><surname>Burlingame</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Narasimhan</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Harris</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Puchalla</surname>, <given-names>J. L.</given-names></string-name>, and <string-name><surname>Berry</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Selectivity for Multiple Stimulus Features in Retinal Ganglion Cells</article-title>. <source>Journal of Neurophysiology</source>, <volume>96</volume>(<issue>5</issue>), <fpage>2724</fpage>–<lpage>2738</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freeman</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Field</surname>, <given-names>G. D.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>P. H.</given-names></string-name>, <string-name><surname>Greschner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Gunning</surname>, <given-names>D. E.</given-names></string-name>, <string-name><surname>Mathieson</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Sher</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Litke</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, and <string-name><surname>Chichilnisky</surname>, <given-names>E. J</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Mapping nonlinear receptive field structure in primate retina at single cone resolution</article-title>. <source>ELife</source>, <volume>4</volume>, <fpage>e05241</fpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fu</surname>, <given-names>W.</given-names></string-name>, and <string-name><surname>Perry</surname>, <given-names>P. O</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Estimating the number of clusters using cross-validation</article-title>. <source>Journal of Computational and Graphical Statistics</source>, <volume>29</volume>(<issue>1</issue>), <fpage>162</fpage>–<lpage>173</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gallego</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Perich</surname>, <given-names>M. G.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>L. E.</given-names></string-name>, and <string-name><surname>Solla</surname>, <given-names>S. A</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Neural Manifolds for the Control of Movement</article-title>. <source>Neuron</source>, <volume>94</volume>(<issue>5</issue>), <fpage>978</fpage>–<lpage>984</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gao</surname>, <given-names>P.</given-names></string-name>, and <string-name><surname>Ganguli</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2015</year>). <article-title>On simplicity and complexity in the brave new world of large-scale neuroscience</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>32</volume>, <fpage>148</fpage>–<lpage>155</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gauthier</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Field</surname>, <given-names>G. D.</given-names></string-name>, <string-name><surname>Sher</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Greschner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Shlens</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Litke</surname>, <given-names>A. M.</given-names></string-name>, and <string-name><surname>Chichilnisky</surname>, <given-names>E. J</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Receptive Fields in Primate Retina Are Coordinated to Sample Visual Space More Uniformly</article-title>. <source>PLoS Biology</source>, <volume>7</volume>(<issue>4</issue>), <fpage>e1000063</fpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gillis</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Glineur</surname>, <given-names>F</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Nonnegative Factorization and The Maximum Edge Biclique Problem</article-title>. <source>ArXiv</source>, <volume>0810</volume>.<issue>4225v</issue><fpage>1</fpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gillis</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Glineur</surname>, <given-names>F</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Accelerated Multiplicative Updates and Hierarchical ALS Algorithms for Nonnegative Matrix Factorization</article-title>. <source>Neural Computation</source>, <volume>24</volume>(<issue>4</issue>), <fpage>1085</fpage>–<lpage>1105</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gollisch</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Liu</surname>, <given-names>J. K</given-names></string-name></person-group>. (<year>2018</year>). <article-title><italic>Data: Salamander retinal ganglion cells under finely structured spatio-temporal white noise</italic> [Dataset]</article-title>. <source>G-Node</source>. <pub-id pub-id-type="doi">10.12751/g-node.62b65b</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gollisch</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Meister</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Modeling convergent ON and OFF pathways in the early visual system</article-title>. <source>Biological Cybernetics</source>, <volume>99</volume>(<issue>4–5</issue>), <fpage>263</fpage>–<lpage>278</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gollisch</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Meister</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Eye Smarter than Scientists Believed: Neural Computations in Circuits of the Retina</article-title>. <source>Neuron</source>, <volume>65</volume>(<issue>2</issue>), <fpage>150</fpage>–<lpage>164</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hansen</surname>, <given-names>P. C</given-names></string-name></person-group>. (<year>1994</year>). <article-title>Regularization tools: A Matlab package for analysis and solution of discrete ill-posed problems</article-title>. <source>Numerical Algorithms</source>, <volume>6</volume>, <fpage>1</fpage>–<lpage>35</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hansen</surname>, <given-names>P. C</given-names></string-name></person-group>. (<year>1999a</year>). <article-title>Regularization Tools Version 3.0 for Matlab 5.2</article-title>. <source>Numerical Algorithms</source>, <volume>20</volume>, <fpage>195</fpage>–<lpage>196</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hansen</surname>, <given-names>P. C</given-names></string-name></person-group>. (<year>1999b</year>). <source>The L-curve and its use in the numerical treatment of inverse problems: Vol. 1999:15. IMM, Department of Mathematical Modelling</source>, <publisher-name>Technical University of Denmark</publisher-name>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harper</surname>, <given-names>N. S.</given-names></string-name>, <string-name><surname>Schoppe</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Willmore</surname>, <given-names>B. D. B.</given-names></string-name>, <string-name><surname>Cui</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Schnupp</surname>, <given-names>J. W. H.</given-names></string-name>, and <string-name><surname>King</surname>, <given-names>A. J</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Network Receptive Field Modeling Reveals Extensive Integration and Multi-feature Selectivity in Auditory Cortical Neurons</article-title>. <source>PLOS Computational Biology</source>, <volume>12</volume>(<issue>11</issue>), <fpage>e1005113</fpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="thesis"><person-group person-group-type="author"><string-name><surname>Ho</surname>, <given-names>N.-D.</given-names></string-name></person-group> (<year>2008</year>). <source>Nonnegative matrix factorization algorithms and applications</source> [Diss. PhD thesis]. <publisher-name>Université catholique de Louvain</publisher-name>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hoyer</surname>, <given-names>P. O</given-names></string-name></person-group>. (<year>2002</year>). <article-title>Non-negative sparse coding</article-title>. <source>Proceedings of the 12th IEEE Workshop on Neural Networks for Signal Processing</source>, <fpage>557</fpage>–<lpage>565</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hoyer</surname>, <given-names>P. O</given-names></string-name></person-group>. (<year>2004</year>). <article-title>Non-negative matrix factorization with sparseness constraints</article-title>. <source>Journal of Machine Learning Research</source>, <volume>5</volume>, <fpage>1457</fpage>–<lpage>1469</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Ran</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Oesterle</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Euler</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Berens</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Estimating smooth and sparse neural receptive fields with a flexible spline basis</article-title>. <source>Neurons, Behavior, Data Analysis, and Theory</source>, <volume>5</volume>(<issue>3</issue>), <fpage>1</fpage>–<lpage>30</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hyvärinen</surname>, <given-names>A</given-names></string-name></person-group>. (<year>1999</year>). <article-title>Sparse Code Shrinkage: Denoising of Nongaussian Data by Maximum Likelihood Estimation</article-title>. <source>Neural Computation</source>, <volume>11</volume>(<issue>7</issue>), <fpage>1739</fpage>–<lpage>1768</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jaccard</surname>, <given-names>P</given-names></string-name></person-group>. (<year>1912</year>). <article-title>The Distribution of the Flora in the Alpine Zone</article-title>. <source>New Phytologist</source>, <volume>11</volume>(<issue>2</issue>), <fpage>37</fpage>–<lpage>50</lpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jacoby</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Wiechmann</surname>, <given-names>A. F.</given-names></string-name>, <string-name><surname>Amara</surname>, <given-names>S. G.</given-names></string-name>, <string-name><surname>Leighton</surname>, <given-names>B. H.</given-names></string-name>, and <string-name><surname>Marshak</surname>, <given-names>D. W</given-names></string-name></person-group>. (<year>2000</year>). <article-title>Diffuse bipolar cells provide input to OFF parasol ganglion cells in the macaque retina</article-title>. <source>The Journal of Comparative Neurology</source>, <volume>416</volume>(<issue>1</issue>), <fpage>6</fpage>–<lpage>18</lpage>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jacoby</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Stafford</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kouyama</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Marshak</surname>, <given-names>D</given-names></string-name></person-group>. (<year>1996</year>). <article-title>Synaptic inputs to ON parasol ganglion cells in the primate retina</article-title>. <source>Journal of Neuroscience</source>, <volume>16</volume>(<issue>24</issue>), <fpage>8041</fpage>–<lpage>8056</lpage>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jarsky</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Cembrowski</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Logan</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Kath</surname>, <given-names>W. L.</given-names></string-name>, <string-name><surname>Riecke</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Demb</surname>, <given-names>J. B.</given-names></string-name>, and <string-name><surname>Singer</surname>, <given-names>J. H</given-names></string-name></person-group>. (<year>2011</year>). <article-title>A synaptic mechanism for retinal adaptation to luminance and contrast</article-title>. <source>Journal of Neuroscience</source>, <volume>31</volume>(<issue>30</issue>), <fpage>11003</fpage>–<lpage>11015</lpage>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jun</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Field</surname>, <given-names>G. D.</given-names></string-name>, and <string-name><surname>Pearson</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Scene statistics and noise determine the relative arrangement of receptive field mosaics</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>118</volume>(<issue>39</issue>), <fpage>e2105115118</fpage>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jusuf</surname>, <given-names>P. R.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>P. R.</given-names></string-name>, and <string-name><surname>Grünert</surname>, <given-names>U</given-names></string-name></person-group>. (<year>2006a</year>). <article-title>Synaptic connectivity in the midget-parvocellular pathway of primate central retina</article-title>. <source>The Journal of Comparative Neurology</source>, <volume>494</volume>(<issue>2</issue>), <fpage>260</fpage>–<lpage>274</lpage>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jusuf</surname>, <given-names>P. R.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>P. R.</given-names></string-name>, and <string-name><surname>Grünert</surname>, <given-names>U</given-names></string-name></person-group>. (<year>2006b</year>). <article-title>Random wiring in the midget pathway of primate retina</article-title>. <source>Journal of Neuroscience</source>, <volume>26</volume>(<issue>15</issue>), <fpage>3908</fpage>–<lpage>3917</lpage>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kaardal</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Fitzgerald</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Berry</surname>, <given-names>M. J.</given-names></string-name>, and <string-name><surname>Sharpee</surname>, <given-names>T. O</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Identifying Functional Bases for Multidimensional Neural Computations</article-title>. <source>Neural Computation</source>, <volume>25</volume>(<issue>7</issue>), <fpage>1870</fpage>–<lpage>1890</lpage>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kerschensteiner</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Feature Detection by Retinal Ganglion Cells</article-title>. <source>Annual Review of Vision Science</source>, <volume>8</volume>(<issue>1</issue>), <fpage>135</fpage>–<lpage>169</lpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keshishian</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Akbari</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Khalighinejad</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Herrero</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Mehta</surname>, <given-names>A. D.</given-names></string-name>, and <string-name><surname>Mesgarani</surname>, <given-names>N</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Estimating and interpreting nonlinear receptive field of sensory neural responses with deep neural network models</article-title>. <source>ELife</source>, <volume>9</volume>, <fpage>e53445</fpage>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname>, <given-names>H.</given-names></string-name>, and <string-name><surname>Park</surname>, <given-names>H</given-names></string-name></person-group>. (<year>2007</year>). <article-title>Sparse non-negative matrix factorizations via alternating non-negativity-constrained least squares for microarray data analysis</article-title>. <source>Bioinformatics</source>, <volume>23</volume>(<issue>12</issue>), <fpage>1495</fpage>– <lpage>1502</lpage>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Park</surname>, <given-names>H</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Sparse Nonnegative Matrix Factorization for Clustering</article-title>. <source>Georgia Institute of Technology, Tech. Rep</source>. <fpage>GT-CSE-08</fpage>–<lpage>01</lpage>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Park</surname>, <given-names>H</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Fast Nonnegative Matrix Factorization: An Active-Set-Like Method and Comparisons</article-title>. <source>SIAM Journal on Scientific Computing</source>, <volume>33</volume>(<issue>6</issue>), <fpage>3261</fpage>–<lpage>3281</lpage>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Koh</surname>, <given-names>T. H.</given-names></string-name>, <string-name><surname>Bishop</surname>, <given-names>W. E.</given-names></string-name>, <string-name><surname>Kawashima</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Jeon</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Srinivasan</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Mu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Wei</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Kuhlman</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Ahrens</surname>, <given-names>M. B.</given-names></string-name>, <string-name><surname>Chase</surname>, <given-names>S. M.</given-names></string-name>, and <string-name><surname>Yu</surname>, <given-names>B. M</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Dimensionality reduction of calcium-imaged neuronal population activity</article-title>. <source>Nature Computational Science</source>, <volume>3</volume>(<issue>1</issue>), <fpage>71</fpage>–<lpage>85</lpage>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kolb</surname>, <given-names>H.</given-names></string-name>, and <string-name><surname>Dekorver</surname>, <given-names>L</given-names></string-name></person-group>. (<year>1991</year>). <article-title>Midget ganglion cells of the parafovea of the human retina: A study by electron microscopy and serial section reconstructions</article-title>. <source>The Journal of Comparative Neurology</source>, <volume>303</volume>(<issue>4</issue>), <fpage>617</fpage>–<lpage>636</lpage>.</mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lawson</surname>, <given-names>C. L.</given-names></string-name>, and <string-name><surname>Hanson</surname>, <given-names>R. J</given-names></string-name></person-group>. (<year>1974</year>). <source>Solving Least Squares Problems</source>. <publisher-name>Prentice-Hall</publisher-name>.</mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>P. R.</given-names></string-name>, and <string-name><surname>Grünert</surname>, <given-names>U</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Retinal connectivity and primate vision</article-title>. <source>Progress in Retinal and Eye Research</source>, <volume>29</volume>(<issue>6</issue>), <fpage>622</fpage>–<lpage>639</lpage>.</mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname>, <given-names>D. D.</given-names></string-name>, and <string-name><surname>Seung</surname>, <given-names>H. S</given-names></string-name></person-group>. (<year>1999</year>). <article-title>Learning the parts of objects by non-negative matrix factorization</article-title>. <source>Nature</source>, <volume>401</volume>(<issue>6755</issue>), <fpage>788</fpage>–<lpage>791</lpage>.</mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lehky</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Sejnowski</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Desimone</surname>, <given-names>R</given-names></string-name></person-group>. (<year>1992</year>). <article-title>Predicting responses of nonlinear neurons in monkey striate cortex to complex patterns</article-title>. <source>The Journal of Neuroscience</source>, <volume>12</volume>(<issue>9</issue>), <fpage>3568</fpage>–<lpage>3581</lpage>.</mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Calder</surname>, <given-names>C. A.</given-names></string-name>, and <string-name><surname>Cressie</surname>, <given-names>N</given-names></string-name></person-group>. (<year>2007</year>). <article-title>Beyond Moran’s I: Testing for Spatial Dependence Based on the Spatial Autoregressive Model</article-title>. <source>Geographical Analysis</source>, <volume>39</volume>(<issue>4</issue>), <fpage>357</fpage>–<lpage>375</lpage>.</mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Zhang</surname>, <given-names>Y.-J</given-names></string-name></person-group>. (<year>2009</year>). <article-title>FastNMF: highly efficient monotonic fixed-point nonnegative matrix factorization algorithm with good applicability</article-title>. <source>Journal of Electronic Imaging</source>, <volume>18</volume>(<issue>3</issue>), <fpage>033004</fpage>.</mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>J. K.</given-names></string-name>, <string-name><surname>Schreyer</surname>, <given-names>H. M.</given-names></string-name>, <string-name><surname>Onken</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Rozenblit</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Khani</surname>, <given-names>M. H.</given-names></string-name>, <string-name><surname>Krishnamoorthy</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Panzeri</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Gollisch</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Inference of neuronal functional circuitry with spike-triggered non-negative matrix factorization</article-title>. <source>Nature Communications</source>, <volume>8</volume>(<issue>1</issue>), <fpage>149</fpage>.</mixed-citation></ref>
<ref id="c86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maheswaranathan</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Kastner</surname>, <given-names>D. B.</given-names></string-name>, <string-name><surname>Baccus</surname>, <given-names>S. A.</given-names></string-name>, and <string-name><surname>Ganguli</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Inferring hidden structure in multilayered neural circuits</article-title>. <source>PLOS Computational Biology</source>, <volume>14</volume>(<issue>8</issue>), <fpage>e1006291</fpage>.</mixed-citation></ref>
<ref id="c87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maheswaranathan</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>McIntosh</surname>, <given-names>L. T.</given-names></string-name>, <string-name><surname>Tanaka</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Grant</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Kastner</surname>, <given-names>D. B.</given-names></string-name>, <string-name><surname>Melander</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Nayebi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brezovec</surname>, <given-names>L. E.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>J. H.</given-names></string-name>, <string-name><surname>Ganguli</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Baccus</surname>, <given-names>S. A</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Interpreting the retinal neural code for natural scenes: From computations to neurons</article-title>. <source>Neuron</source>, <volume>111</volume>(<issue>17</issue>), <fpage>2742</fpage>–<lpage>2755</lpage>.</mixed-citation></ref>
<ref id="c88"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manookin</surname>, <given-names>M. B.</given-names></string-name>, and <string-name><surname>Demb</surname>, <given-names>J. B</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Presynaptic Mechanism for Slow Contrast Adaptation in Mammalian Retinal Ganglion Cells</article-title>. <source>Neuron</source>, <volume>50</volume>(<issue>3</issue>), <fpage>453</fpage>–<lpage>464</lpage>.</mixed-citation></ref>
<ref id="c89"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manookin</surname>, <given-names>M. B.</given-names></string-name>, <string-name><surname>Patterson</surname>, <given-names>S. S.</given-names></string-name>, and <string-name><surname>Linehan</surname>, <given-names>C. M</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Neural Mechanisms Mediating Motion Sensitivity in Parasol Ganglion Cells of the Primate Retina</article-title>. <source>Neuron</source>, <volume>97</volume>(<issue>6</issue>), <fpage>1327</fpage>–<lpage>1340</lpage>.</mixed-citation></ref>
<ref id="c90"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marc</surname>, <given-names>R. E.</given-names></string-name>, and <string-name><surname>Sperling</surname>, <given-names>H. G</given-names></string-name></person-group>. (<year>1977</year>). <article-title>Chromatic organization of primate cones</article-title>. <source>Science</source>, <volume>4288</volume>(<issue>196</issue>), <fpage>454</fpage>–<lpage>456</lpage>.</mixed-citation></ref>
<ref id="c91"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masland</surname>, <given-names>R. H</given-names></string-name></person-group>. (<year>2001</year>). <article-title>The fundamental plan of the retina</article-title>. <source>Nature Neuroscience</source>, <volume>4</volume>(<issue>9</issue>), <fpage>877</fpage>–<lpage>886</lpage>.</mixed-citation></ref>
<ref id="c92"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Matsumoto</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Nishimura</surname>, <given-names>T.</given-names></string-name></person-group> (<year>1998</year>). <article-title>Mersenne twister</article-title>. <source>ACM Transactions on Modeling and Computer Simulation</source>, <volume>8</volume>(<issue>1</issue>), <fpage>3</fpage>–<lpage>30</lpage>.</mixed-citation></ref>
<ref id="c93"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McFarland</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Cui</surname>, <given-names>Y.</given-names></string-name>, and <string-name><surname>Butts</surname>, <given-names>D. A</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Inferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs</article-title>. <source>PLoS Computational Biology</source>, <volume>9</volume>(<issue>7</issue>), <fpage>e1003143</fpage>.</mixed-citation></ref>
<ref id="c94"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>McIntosh</surname>, <given-names>L. T.</given-names></string-name>, <string-name><surname>Maheswaranathan</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Nayebi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ganguli</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Baccus</surname>, <given-names>S. A</given-names></string-name></person-group>. (<year>2016</year>). <chapter-title>Deep Learning Models of the Retinal Response to Natural Scenes</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>D.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Sugiyama</surname></string-name>, <string-name><given-names>U.</given-names> <surname>Luxburg</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Guyon</surname></string-name> &amp; <string-name><given-names>R.</given-names> <surname>Garnett</surname></string-name></person-group> (Eds.), <source>Advances in Neural Information Processing Systems</source> (Vol. <fpage>29</fpage>). <publisher-name>Curran Associates, Inc</publisher-name>.</mixed-citation></ref>
<ref id="c95"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mineault</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Khawaja</surname>, <given-names>F. A.</given-names></string-name>, <string-name><surname>Butts</surname>, <given-names>D. A.</given-names></string-name>, and <string-name><surname>Pack</surname>, <given-names>C. C</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Hierarchical processing of complex motion along the primate dorsal visual pathway</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>109</volume>(<issue>16</issue>), <fpage>E972</fpage>–<lpage>E980</lpage>.</mixed-citation></ref>
<ref id="c96"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Monti</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Tamayo</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Mesirov</surname>, <given-names>J. P.</given-names></string-name>, and <string-name><surname>Golub</surname>, <given-names>T. R</given-names></string-name></person-group>. (<year>2003</year>). <article-title>Consensus clustering: A resampling-based method for class discovery and visualization of gene expression microarray data</article-title>. <source>Machine Learning</source>, <volume>52</volume>(<issue>1</issue>), <fpage>91</fpage>–<lpage>118</lpage>.</mixed-citation></ref>
<ref id="c97"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moran</surname>, <given-names>P. A. P</given-names></string-name></person-group>. (<year>1950</year>). <article-title>Notes on Continuous Stochastic Phenomena</article-title>. <source>Biometrika</source>, <volume>37</volume>(<issue>1–2</issue>), <fpage>17</fpage>–<lpage>23</lpage>.</mixed-citation></ref>
<ref id="c98"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nagayama</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Aritake</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Hino</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Kanda</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Miyazaki</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Yanagisawa</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Akaho</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Murata</surname>, <given-names>N</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Detecting cell assemblies by NMF-based clustering from calcium imaging data</article-title>. <source>Neural Networks</source>, <volume>149</volume>, <fpage>29</fpage>–<lpage>39</lpage>.</mixed-citation></ref>
<ref id="c99"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Onken</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>J. K.</given-names></string-name>, <string-name><surname>Karunasekara</surname>, <given-names>P. P. C. R.</given-names></string-name>, <string-name><surname>Delis</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Gollisch</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Panzeri</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Using Matrix and Tensor Factorizations for the Single-Trial Analysis of Population Spike Trains</article-title>. <source>PLOS Computational Biology</source>, <volume>12</volume>(<issue>11</issue>), <fpage>e1005189</fpage>.</mixed-citation></ref>
<ref id="c100"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Owen</surname>, <given-names>A. B.</given-names></string-name>, and <string-name><surname>Perry</surname>, <given-names>P. O</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Bi-cross-validation of the SVD and the nonnegative matrix factorization</article-title>. <source>Annals of Applied Statistics</source>, <volume>3</volume>(<issue>2</issue>), <fpage>564</fpage>–<lpage>594</lpage>.</mixed-citation></ref>
<ref id="c101"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Pachitariu</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Steinmetz</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Kadir</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Harris</surname>, <given-names>K. D</given-names></string-name></person-group>. (<year>2016</year>). <chapter-title>Fast and accurate spike sorting of high-channel count probes with KiloSort</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>D. D.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Sugiyama</surname></string-name>, <string-name><given-names>U. V.</given-names> <surname>Luxburg</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Guyon</surname></string-name> &amp; <string-name><given-names>R.</given-names> <surname>Garnett</surname></string-name></person-group> (Eds.), <source>Advances in Neural Information Processing Systems</source> (Vol. <fpage>29</fpage>). <publisher-name>Curran Associates, Inc</publisher-name>.</mixed-citation></ref>
<ref id="c102"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qiao</surname>, <given-names>H</given-names></string-name></person-group>. (<year>2015</year>). <article-title>New SVD based initialization strategy for non-negative matrix factorization</article-title>. <source>Pattern Recognition Letters</source>, <volume>63</volume>, <fpage>71</fpage>–<lpage>77</lpage>.</mixed-citation></ref>
<ref id="c103"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Real</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Asari</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Gollisch</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Meister</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Neural Circuit Inference from Function to Structure</article-title>. <source>Current Biology</source>, <volume>27</volume>(<issue>2</issue>), <fpage>189</fpage>–<lpage>198</lpage>.</mixed-citation></ref>
<ref id="c104"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rieke</surname>, <given-names>F</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Temporal Contrast Adaptation in Salamander Bipolar Cells</article-title>. <source>Journal of Neuroscience</source>, <volume>21</volume>(<issue>23</issue>), <fpage>9445</fpage>–<lpage>9454</lpage>.</mixed-citation></ref>
<ref id="c105"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roy</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Jun</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Davis</surname>, <given-names>E. L.</given-names></string-name>, <string-name><surname>Pearson</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Field</surname>, <given-names>G. D</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Inter-mosaic coordination of retinal receptive fields</article-title>. <source>Nature</source>, <volume>592</volume>(<issue>7854</issue>), <fpage>409</fpage>–<lpage>413</lpage>.</mixed-citation></ref>
<ref id="c106"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Samengo</surname>, <given-names>I.</given-names></string-name>, and <string-name><surname>Gollisch</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Spike-triggered covariance: geometric proof, symmetry properties, and extension beyond Gaussian stimuli</article-title>. <source>Journal of Computational Neuroscience</source>, <volume>34</volume>(<issue>1</issue>), <fpage>137</fpage>–<lpage>161</lpage>.</mixed-citation></ref>
<ref id="c107"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Saxena</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Kinsella</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Musall</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>S. H.</given-names></string-name>, <string-name><surname>Meszaros</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Thibodeaux</surname>, <given-names>D. N.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Cunningham</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Hillman</surname>, <given-names>E. M. C.</given-names></string-name>, <string-name><surname>Churchland</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Paninski</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Localized semi-nonnegative matrix factorization (LocaNMF) of widefield calcium imaging data</article-title>. <source>PLOS Computational Biology</source>, <volume>16</volume>(<issue>4</issue>), <fpage>e1007791</fpage>.</mixed-citation></ref>
<ref id="c108"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schwartz</surname>, <given-names>G. W.</given-names></string-name>, <string-name><surname>Okawa</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Dunn</surname>, <given-names>F. A.</given-names></string-name>, <string-name><surname>Morgan</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Kerschensteiner</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Wong</surname>, <given-names>R. O.</given-names></string-name>, and <string-name><surname>Rieke</surname>, <given-names>F</given-names></string-name></person-group>. (<year>2012</year>). <article-title>The spatial structure of a nonlinear receptive field</article-title>. <source>Nature Neuroscience</source>, <volume>15</volume>(<issue>11</issue>), <fpage>1572</fpage>–<lpage>1580</lpage>.</mixed-citation></ref>
<ref id="c109"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schwartz</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Rust</surname>, <given-names>N. C.</given-names></string-name>, and <string-name><surname>Simoncelli</surname>, <given-names>E. P</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Spike-triggered neural characterization</article-title>. <source>Journal of Vision</source>, <volume>6</volume>(<issue>4</issue>), <fpage>484</fpage>–<lpage>507</lpage>.</mixed-citation></ref>
<ref id="c110"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shah</surname>, <given-names>N. P.</given-names></string-name>, <string-name><surname>Brackbill</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Rhoades</surname>, <given-names>C. E.</given-names></string-name>, <string-name><surname>Kling</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Goetz</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Litke</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Sher</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, and <string-name><surname>Chichilnisky</surname>, <given-names>E. J</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Inference of nonlinear receptive field subunits with spike-triggered clustering</article-title>. <source>ELife</source>, <volume>9</volume>, <fpage>e45743</fpage>.</mixed-citation></ref>
<ref id="c111"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shi</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Gupta</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Boukhvalova</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Singer</surname>, <given-names>J. H.</given-names></string-name>, and <string-name><surname>Butts</surname>, <given-names>D. A</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Functional characterization of retinal ganglion cells using tailored nonlinear modeling</article-title>. <source>Scientific Reports</source>, <volume>9</volume>(<issue>1</issue>), <fpage>8713</fpage>.</mixed-citation></ref>
<ref id="c112"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sterling</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Freed</surname>, <given-names>M. A.</given-names></string-name>, and <string-name><surname>Smith</surname>, <given-names>R. G</given-names></string-name></person-group>. (<year>1988</year>). <article-title>Architecture of rod and cone circuits to the on-beta ganglion cell</article-title>. <source>Journal of Neuroscience</source>, <volume>8</volume>(<issue>2</issue>), <fpage>623</fpage>–<lpage>642</lpage>.</mixed-citation></ref>
<ref id="c113"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Tanaka</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Nayebi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Maheswaranathan</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>McIntosh</surname>, <given-names>L. T.</given-names></string-name>, <string-name><surname>Baccus</surname>, <given-names>S. A.</given-names></string-name>, and <string-name><surname>Ganguli</surname>, <given-names>S.</given-names></string-name> (). . In <string-name><given-names>H.</given-names> <surname>Wallach</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Larochelle</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Beygelzimer</surname></string-name>, <string-name><given-names>F.</given-names> <surname>D’Alché-Buc</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Fox</surname></string-name> &amp; <string-name><given-names>R.</given-names> <surname>Garnett</surname></string-name></person-group><year>2019</year>). <chapter-title>From deep learning to mechanistic understanding in neuroscience: the structure of retinal prediction</chapter-title>. In , , , ,  &amp;  (Eds.), <source>Advances in Neural Information Processing Systems</source> (Vol. <volume>32</volume>). <publisher-name>Curran Associates, Inc</publisher-name>.</mixed-citation></ref>
<ref id="c115"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vavasis</surname>, <given-names>S. A</given-names></string-name></person-group>. (<year>2010</year>). <article-title>On the Complexity of Nonnegative Matrix Factorization</article-title>. <source>SIAM Journal on Optimization</source>, <volume>20</volume>(<issue>3</issue>), <fpage>1364</fpage>–<lpage>1377</lpage>.</mixed-citation></ref>
<ref id="c116"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Victor</surname>, <given-names>J. D.</given-names></string-name>, and <string-name><surname>Shapley</surname>, <given-names>R. M</given-names></string-name></person-group>. (<year>1979</year>). <article-title>The nonlinear pathway of Y ganglion cells in the cat retina</article-title>. <source>Journal of General Physiology</source>, <volume>74</volume>(<issue>6</issue>), <fpage>671</fpage>–<lpage>689</lpage>.</mixed-citation></ref>
<ref id="c117"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vintch</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name>, and <string-name><surname>Simoncelli</surname>, <given-names>E. P</given-names></string-name></person-group>. (<year>2015</year>). <article-title>A Convolutional Subunit Model for Neuronal Responses in Macaque V1</article-title>. <source>Journal of Neuroscience</source>, <volume>35</volume>(<issue>44</issue>), <fpage>14829</fpage>–<lpage>14841</lpage>.</mixed-citation></ref>
<ref id="c118"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wässle</surname>, <given-names>H</given-names></string-name></person-group>. (<year>1999</year>). <chapter-title>Parallel pathways from the outer to the inner retina in primates</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>K. R.</given-names> <surname>Gegenfurtner</surname></string-name>, &amp; <string-name><given-names>L. T.</given-names> <surname>Sharpe</surname></string-name></person-group> (Eds.), <source>Color Vision: From Genes to Perception</source> (pp. <fpage>145</fpage>–<lpage>162</lpage>). <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref>
<ref id="c119"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wässle</surname>, <given-names>H</given-names></string-name></person-group>. (<year>2004</year>). <article-title>Parallel processing in the mammalian retina</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>5</volume>(<issue>10</issue>), <fpage>747</fpage>–<lpage>757</lpage>.</mixed-citation></ref>
<ref id="c120"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Watanabe</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Rodieck</surname>, <given-names>R. W</given-names></string-name></person-group>. (<year>1989</year>). <article-title>Parasol and midget ganglion cells of the primate retina</article-title>. <source>The Journal of Comparative Neurology</source>, <volume>289</volume>(<issue>3</issue>), <fpage>434</fpage>–<lpage>454</lpage>.</mixed-citation></ref>
<ref id="c121"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wild</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Curry</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Dougherty</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2004</year>). <article-title>Improving non-negative matrix factorizations through structured initialization</article-title>. <source>Pattern Recognition</source>, <volume>37</volume>(<issue>11</issue>), <fpage>2217</fpage>–<lpage>2232</lpage>.</mixed-citation></ref>
<ref id="c122"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zapp</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Nitsche</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Gollisch</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Retinal receptive-field substructure: scaffolding for coding and computation</article-title>. <source>Trends in Neurosciences</source>, <volume>45</volume>(<issue>6</issue>), <fpage>430</fpage>–<lpage>445</lpage>.</mixed-citation></ref>
<ref id="c123"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Jing</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Xiu</surname>, <given-names>N</given-names></string-name></person-group>. (<year>2014</year>). <article-title>A New Active Set Method For Nonnegative Matrix Factorization</article-title>. <source>SIAM Journal on Scientific Computing</source>, <volume>36</volume>(<issue>6</issue>), <fpage>A2633</fpage>–<lpage>A2653</lpage>.</mixed-citation></ref>
<ref id="c124"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Cong</surname>, <given-names>F.</given-names></string-name>, and <string-name><surname>Li</surname>, <given-names>D. X</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Early childhood developmental functional connectivity of autistic brains with non-negative matrix factorization</article-title>. <source>NeuroImage: Clinical</source>, <volume>26</volume>, <fpage>102251</fpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99945.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Rieke</surname>
<given-names>Fred</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Washington</institution>
</institution-wrap>
<city>Seattle</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This paper introduces an efficient approach to identify subunits in the receptive fields of retinal ganglion cells. The general approach has been used in this application previously and this limits the conceptual advance of the paper. The improved speed is <bold>valuable</bold>, as it allows a more thorough exploration of the control parameters in this analysis and facilitates application to larger populations of cells. Validation of the approach is <bold>convincing</bold>. The paper would benefit from a more thorough exploration of the method and its limitations, or an extension of the new results about subunit populations.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99945.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper introduces an efficient approach to infer properties of receptive-field subunits from the ensemble of spike-triggered stimuli. This is an important general problem in sensory coding. The results introduced in the paper make a solid contribution to both how subunits can be identified and how subunits of different types are coordinated in space.</p>
<p>Strengths:</p>
<p>A primary strength of the paper is the development of approaches that substantially speed non-negative matrix factorization and by doing so create an opportunity for a more systematic exploration of how the procedure depends on various control parameters. The improved procedure is well documented and the direct comparisons with previous procedures are helpful. The improved efficiency enabled several improvements in the procedure - notably tests of good procedures for initializing NNMF and tests of the dependence of the results on the sparsity regularization parameter.</p>
<p>A second strength of the paper is the exploration of the spatial relationship between different subunits. This, to my knowledge, is new and is an interesting direction. There are some concerns about this analysis (see weaknesses below), but if this analysis can be strengthened it will provide new information that will be important both functionally and developmentally.</p>
<p>Weaknesses:</p>
<p>A primary concern is that choices made about parameters for several aspects of the analysis appear to be made subjectively. Much of this centers around how much of the structure in the extracted subunits is imposed by the procedure itself, and how much reflects the underlying neural circuitry. Some specific issues related to this concern are:</p>
<p>- Sparsity: the use of the autocorrelation function to differentiate real vs spurious subunits should be documented and validated. For example, can the authors split data in half and show that the real subunits are stable?</p>
<p>- Choice of regularization: the impact of the regularization parameter on subunit properties is nicely documented. However, the choice of an appropriate regularization parameter seems somewhat arbitrary. Line 253-256 is an example of this problem: this sentence sounds circular - as if the sparsity factor was turned up until the authors obtained what they expected to obtain. Could the choice of this parameter significantly impact the properties of the extracted subunits? How sensitive are the subunit properties to that parameter? Some additional control analyses are needed to validate the parameter choice (see the crossvalidation comment below).</p>
<p>- Crossvalidation was not used to identify the regularization constraint value because the weight matrix from NNMF does not generalize beyond the data it was fit to. Could the authors instead hold the components matrix fixed and recompute the weight matrix, and use that approach for cross-validation (especially since it is really the components matrix that needs validating)?</p>
<p>The paper would benefit from a more complete comparison with known anatomy. For example, can the authors estimate the number of cones within each subunit? This is well-constrained both anatomically (at least in macaque) and, especially for midget ganglion cell subunits, functionally. In macaque, most midget bipolar cells get input from single cones, so the number of extracted subunits should be close to the number of cones. This would be a useful point of comparison for the current work.</p>
<p>Is the analysis of the spatial relationship between different subunit mosaics robust to the incompleteness of those mosaics? The argument on lines 496-503 should be backed up by more analysis. For example, if subunits are removed from regions where the mosaic is pretty complete, do the authors change the spatial dependence? Alternatively, could they use synthetic mosaics with properties like those measured to check the sensitivity to missing cells?</p>
<p>NNMF relies on accounting for each spike-triggered stimulus with a linear combination of components. Would nonlinearities - e.g. those in the bipolar cell outputs - substantially change the results?</p>
<p>Does the approach work for cells that receive input from multiple bipolar types? Some ganglion cells, e.g. in mice, receive input from multiple bipolar types, each accounting for a sizable percentage of the total input. There is similar anatomical work indicating that parasol cells may receive input from multiple diffuse bipolar types. It is not clear whether the current approach works in cases where the subunits of a single ganglion cell overlap. Some discussion of this would be useful.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99945.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Identifying spatial subunits within the receptive field of retinal ganglion cells can help study spatial nonlinearities and upstream computations performed by the bipolar cells. The authors significantly accelerate the implementation of the previously proposed Spike Triggered semi-non-negative Matrix Factorization (STNMF) method to identify the subunits. The authors also propose a few method improvements - better initialization; new stability-based criteria for selecting the regularization strength, and hyperparameter selection across cell types.</p>
<p>The authors then apply this new method to RGC populations in both the salamander retina and the macaque (marmoset) retina. The authors document the subunit sizes, numbers, and overlap across cell types. The neuroscience finding describes the anti-coordination of ON and OFF parasol receptive fields, but not for the corresponding subunits.</p>
<p>Overall, the authors claim that a faster and more accurate method makes scale-up to large neuronal populations feasible.</p>
<p>Strengths:</p>
<p>- The paper is well-written, easy to read and the figures are clear. The limitations are also made clear.</p>
<p>- The scientific findings are novel and seem to be well supported.</p>
<p>- The claimed speed-up of the method is potentially important for practical applications to large populations. Each innovation of the method is well-supported.</p>
<p>- This is a serious effort to improve the method and document the subunits in primate retina.</p>
<p>Weaknesses:</p>
<p>- The description of the method is confusing. Currently, the new method is described in the context of changes from existing methods. As someone who is not familiar with previous methods, it is very confusing to follow the details.</p>
<p>- I think it will help a lot with clarity to have a concise flowchart/pseudocode to summarize the algorithm and separate it from a description of the main changes from previous methods.</p>
<p>- Separate pseudocodes can be provided for the main method, initialization, regularization parameter selection using consensus, and identifying the regularization parameter across cell types.</p>
<p>- While the new method clearly shows a drastic improvement compared to the previous method on a laptop, would it be possible to get the same improvement on the previous method if it was implemented with GPU (as is standard for most AI/ML algorithms)?</p>
<p>- For the calculation of subunits across multiple cells, can you run multiple parallel jobs on the same computer? This may make some innovations unnecessary (like setting the same regularization strength across multiple cells).</p>
<p>- There are two main innovations in this paper: the fast and approximate method, and analysis of subunit mosaics for primate RGCs. It would be helpful to include an analysis of the primate RGC subunits using the older, slower, but more exact method and show that the major scientific results can be reproduced. This would validate the new method in an end-to-end manner. While this may take a while to run, it may be helpful in the supplement.</p>
<p>- It would be important to understand the data-efficiency of the method. The approximate method may deviate more from the exact method when the amount of data is limited.</p>
<p>- Would it be possible to have a few steps of the exact method at the end to ensure that the solution truly optimizes the objective function?</p>
<p>- Does the number of estimated subunits change with the number of observed spikes? If so, the estimates of subunit number/size must be interpreted with caution.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99945.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work addresses the problem of determining the subunit composition of receptive fields of retinal ganglion cells (RGCs). RGCs process stimuli through non-linear transforms that largely (although not entirely) reflect the individual contributions of their input bipolar cells, which themselves process visual stimuli nonlinearly. Thus, using the correct system identification methods might correctly model the RGC cells, while revealing details of the underlying circuit, including the function of the presynaptic components. It is now well established that a model of the form of an LNLN cascade can potentially capture this bipolar-RGC circuit, although the devil is in the details. The authors present an improved method of non-negative matrix factorization (NMF) - which is one approach to this system identification problem - that can speed things up by a factor of 100, and in doing so infer plausible mosaics of the bipolar cell types supporting the identified RGC types that are recorded from.</p>
<p>As written, the focus of this paper seems almost entirely methodological, supporting the sped-up version of NMF, called STNMF. The &gt;100x speedup potentially makes a lot more measurements available, since it enables much more comprehensive scans across model meta-parameters, although has its own complications that must also be methodologically addressed. The results presented are largely a demonstration and validation of the potential power of this approach using example recordings in the peripheral marmoset retina. I do not think the results themselves are meant to be evaluated as definitive, since they are often based on examples and are largely confirmatory of what is already known.</p>
<p>Strengths:</p>
<p>I have very few concerns about the paper methodologically: these methods are well laid out and demonstrated (at least up to the level of my expertise and interest), including validation with established literature.</p>
<p>I am also enthusiastic about some of the potential results in the retina outlined (but not fully fleshed out) in the later sections of the paper.</p>
<p>Weaknesses:</p>
<p>My main critique is to question the conceptual advance in this paper: what did we learn, and what is the targeted audience of interest? Establishing this is particularly dire for this manuscript since NMF has already been established and expounded on as a useful approach in this context (including by the author most recently in 2017) so any of the scientific results is already achievable with enough computer power using existing approaches. As currently cast, the conceptual advances here are purely methodological and relate to the utility of speeding up the approach. Also, they do not appear to generalize to other problems outside of the narrow range that it is currently applied.</p>
<p>Thus, two paths to improving the manuscript would be either:</p>
<p>
(1) target readers interested in the retina by fully fleshing out the current results and add more to make this into a paper about the retina rather than about the STNMF method, or</p>
<p>
(2) demonstrate that the methods might be useful outside of the very narrow set of conditions specific to identifying nonlinear bipolar cell subunits in peripheral retina under white noise stimulation.</p>
<p>In its current state, the Discussion addressing limitations and generality seems to suggest applicability past this narrow condition, which I do not think is the case: but would be happy to be convinced otherwise.</p>
<p>For fleshing out scientific results, in the current manuscript, they are currently presented to validate the approach and are largely confirmatory for what we already know about the retina (which allows for this validation). Also, much of the results are measurements based on examples, and not accumulated past a single recording in some cases. Finally, it is not clear to the extent that these results depend on the specific recordings in the peripheral marmoset retina: what about more central in the retina, or in other species?</p>
<p>For demonstrating the utility of the methodology: here are some of the main limitations to generalizing past this specific case:</p>
<p>
(1) the necessity of linear or near-linear processing in previous layers;</p>
<p>
(2) lack of any negative components;</p>
<p>
(3) lack of ability to account for other influences on spiking than the positive contributions of LN subunits;</p>
<p>
(4) necessity of white noise stimulation that is specifically sized for a uniform subunit size.</p>
<p>Together, I believe this precludes potential applications to other areas in the brain: further back in the visual system will require non-linear transforms as well as the convergence of positive and negative inputs. Other sensory systems like the auditory system are even more non-linear well before getting to even mid-level pre-cortical structures and also combine positive and negative influences. Given the importance of inhibition in the retina (including what is thought to be an important role of amacrine cells in shaping RGC responses), it is not clear how general this approach is in the retina, although the specific results shown are believable. How could this approach generalize, realistically? Could applications to other types of data be demonstrated, and/or plausibly get by these fundamental limitations? How?</p>
</body>
</sub-article>
</article>