<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">102823</article-id>
<article-id pub-id-type="doi">10.7554/eLife.102823</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.102823.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Increased listening effort and cochlear neural degeneration underlie behavioral deficits in speech perception in noise in normal hearing middle-aged adults</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Zink</surname>
<given-names>Maggie E</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n2">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Zhen</surname>
<given-names>Leslie</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n2">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1148-4018</contrib-id>
<name>
<surname>McHaney</surname>
<given-names>Jacie R</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n2">*</xref><xref ref-type="author-notes" rid="n1">+</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Klara</surname>
<given-names>Jennifer</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Yurasits</surname>
<given-names>Kimberly</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cancel</surname>
<given-names>Victoria</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Flemm</surname>
<given-names>Olivia</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mitchell</surname>
<given-names>Claire</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Datta</surname>
<given-names>Jyotishka</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chandrasekaran</surname>
<given-names>Bharath</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">+</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4573-8004</contrib-id>
<name>
<surname>Parthasarathy</surname>
<given-names>Aravindakshan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<email>Aravind_Partha@pitt.edu</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Communication Science and Disorders, School of Health and Rehabilitation Sciences, University of Pittsburgh</institution></institution-wrap>, <city>Pittsburgh</city>, <country>United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02smfhw86</institution-id><institution>Department of Statistics, Virginia Polytechnic Institute and State University</institution></institution-wrap>, <city>Blacksburg</city>, <country>United States</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Bioengineering, Swanson School of Engineering, University of Pittsburgh</institution></institution-wrap>, <city>Pittsburgh</city>, <country>United States</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Otolaryngology, School of Medicine, University of Pittsburgh</institution></institution-wrap>, <city>Pittsburgh</city>, <country>United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Obleser</surname>
<given-names>Jonas</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Lübeck</institution>
</institution-wrap>
<city>Lübeck</city>
<country>Germany</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="present-address"><label>+</label><p>Present address: Department of Communication Sciences and Disorders, Northwestern University, Evanston, Unites States</p></fn>
<fn id="n2" fn-type="equal"><label>*</label><p>Equal contributions</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-11-14">
<day>14</day>
<month>11</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP102823</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-09-03">
<day>03</day>
<month>09</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-10-16">
<day>16</day>
<month>10</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.08.01.606213"/>
</event>
</pub-history>
<permissions>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">
<ali:license_ref>https://creativecommons.org/publicdomain/zero/1.0/</ali:license_ref>
<license-p>This is an open-access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">Creative Commons CC0 public domain dedication</ext-link>.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-102823-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Middle-age is a critical period of rapid changes in brain function that presents an opportunity for early diagnostics and intervention for neurodegenerative conditions later in life. Hearing loss is one such early indicator linked to many comorbidities later in life. However, current clinical tests fail to capture hearing difficulties for ∼10% of middle-aged adults seeking help at hearing clinics. Cochlear neural degeneration (CND) could play a role in these hearing deficits, but our current understanding is limited by the lack of objective diagnostics and uncertainty regarding its perceptual consequences. Here, using a cross-species approach, we measured envelope following responses (EFRs) – neural ensemble responses to sound originating from the peripheral auditory pathway – in young and middle-aged adults with normal audiometric thresholds, and compared these responses to young and middle-aged Mongolian gerbils, where CND was histologically confirmed. We observed near identical changes in EFRs across species that were associated with CND. Perceptual effects measured as behavioral readouts showed deficits in the most challenging listening conditions and were associated with CND. Additionally, pupil-indexed listening effort increased even at moderate task difficulties where behavioral outcomes were matched. Our results reveal perceptual deficits in middle-aged adults driven by CND and increases in listening effort, which may result in increased listening fatigue and conversational disengagement.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The original submission was missing the reference list. This reference list is now appended to the end of the manuscript.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Age-related hearing loss, defined as declines in hearing sensitivity, is exceedingly common; according to some estimates, ∼45 million adults in the United States over 50 years of age have age-related hearing loss that is significant enough to interfere with communication (<xref ref-type="bibr" rid="c1">1</xref>). Untreated hearing loss decreases quality of life and is thought to be the single-largest modifiable risk factor in middle-age for other age-related comorbidities such as cognitive impairment and dementia (<xref ref-type="bibr" rid="c2">2</xref>). However, current measures of hearing sensitivity fail to capture critical aspects of real-world hearing difficulties in this population (<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>). Hearing difficulties experienced by up to 10% of adults seeking help in the hearing clinic are ‘hidden’ to current diagnostic procedures (<xref ref-type="bibr" rid="c3">3</xref>–<xref ref-type="bibr" rid="c6">6</xref>). Peripheral deafferentation caused by cochlear neural degeneration (CND) may underlie many of these perceptual difficulties (<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c8">8</xref>). Anatomical evidence for progressive CND with aging is clear – postmortem studies using human temporal bones estimate a 40% deafferentation caused by CND by the fifth decade of life (<xref ref-type="bibr" rid="c9">9</xref>–<xref ref-type="bibr" rid="c11">11</xref>). CND causes neural coding deficits in the peripheral auditory pathway, affecting the faithful representation of spectrotemporally complex auditory stimuli (<xref ref-type="bibr" rid="c12">12</xref>–<xref ref-type="bibr" rid="c14">14</xref>). But the evidence linking CND with perceptual deficits is mixed - current assessments of perceptual deficits associated with CND primarily focus on behavioral measures of speech in noise, with mixed evidence of deficits in individuals with putative CND (<xref ref-type="bibr" rid="c15">15</xref>–<xref ref-type="bibr" rid="c18">18</xref>).</p>
<p>Two challenges impede our understanding of the perceptual consequences of CND. First, while many non- invasive markers of CND have been proposed and validated in animal models (<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c20">20</xref>), non-invasive estimates of putative CND in humans cannot be confirmed with histological assessment of synapses in the same participants. Cross-species comparative studies and computational modeling provide promising avenues for overcoming this gap (<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c22">22</xref>). Secondly, behavioral readouts of perceptual difficulties in humans show mixed results with putative CND depending on the specific test used and degree of spectrotemporal and contextual information provided in that test (<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c24">24</xref>). The most promising tests for CND are ones with no linguistic context and short spectrotemporal processing windows (<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref>). However, these behavioral readouts may minimize subliminal changes in perception that are reflected in listening effort but <italic>not</italic> in accuracies (<xref ref-type="bibr" rid="c26">26</xref>–<xref ref-type="bibr" rid="c28">28</xref>). Here, we used a cross-species approach, combined with simultaneous measurements of behavior and listening effort, to show that CND is associated with decreased neural coding fidelity and increased listening effort in middle-aged adults with normal audiometric thresholds. We measured putative CND using the envelope following response (EFR) to rapid (∼1000Hz) modulation frequencies – a suggested marker for CND (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c14">14</xref>). Cross-species comparisons with identical recordings in a low-frequency hearing animal model, the Mongolian gerbil, confirmed that decreases in EFRs were selective only for responses with generators in the auditory nerve. These EFRs were also associated with histologically-confirmed CND. In the human model, we simultaneously measured pupil-indexed listening effort in participants as they performed a speech-in-noise task and show that increased listening effort was present despite matched behavioral accuracies. These results point to hitherto underexplored aspects of auditory perceptual difficulties associated with listening effort and CND.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>“Normal” hearing middle-aged adults show evidence of peripheral neural coding deficits that are associated with CND Middle-aged (MA, 40-55 years) listeners were recruited to participate in this study, and their responses were compared to that of young adult (YA, 18-25 years) listeners (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). All participants had clinically normal hearing thresholds and spoke fluent American English. Participants had normal otoscopy by visual examination and air conduction thresholds below 25dB HL for octave frequencies between 250Hz to 8 kHz (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>, <xref rid="tbl1" ref-type="table">Table 1</xref>), consistent with WHO guidelines for normal hearing (<xref ref-type="bibr" rid="c29">29</xref>). Threshold differences were exaggerated in MAs at extended high frequencies (&gt;8kHz) that are seldom clinically measured but may be a marker for accumulated lifetime noise damage ((<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c30">30</xref>–<xref ref-type="bibr" rid="c32">32</xref>), <xref rid="fig1" ref-type="fig">Fig. 1B</xref>, <xref rid="tbl2" ref-type="table">Table 2</xref>). Outer hair cell function, assessed using distortion product otoacoustic emissions (DPOAEs), were comparable between young adult and middle-aged listeners up to 4 kHz, the frequency regions that contains most of the spectral information in speech (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>, <xref rid="tbl3" ref-type="table">Table 3</xref>). Participants also had no severe symptoms of tinnitus (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>) assessed using the Tinnitus Handicap Inventory (THI; (<xref ref-type="bibr" rid="c33">33</xref>)) and Loudness Discomfort Levels (LDLs; (<xref ref-type="bibr" rid="c32">32</xref>)) above 80 dB SPL for frequencies up to 3 kHz (<xref rid="fig1" ref-type="fig">Fig. 1E</xref>, <xref rid="tbl4" ref-type="table">Table 4</xref>). Self-reported noise exposure using the Noise</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Age-related CND occurs prior to overt changes in hearing thresholds and can be assessed non-invasively by measuring phase-locked neural envelope following responses.</title>
<p><bold>(A)</bold> Thirty middle-aged (MA, 40-55 yrs, mean = 46.1±4.6 yrs) and 36 young adults (YA, 18-25 years, mean = 21.17± 1.8yrs) participated in this study. <bold>(B)</bold> All participants had clinically normal hearing thresholds with some evidence of threshold losses at extended high frequencies above 8 kHz typically not tested in the clinic. Hearing thresholds in dB HL are shown on the Y axis and frequency in kHz is plotted on the X axis. <bold>(C)</bold> Outer hair cell function assessed using DPOAEs is comparable between YA and MA up to 4kHz and showed age-related decreases at higher frequencies. Both cohorts show no evidence of self-reported tinnitus <bold>(D)</bold> or hyperacusis measured as LDLs <bold>(E)</bold>, have comparable self-reported noise exposure levels <bold>(F)</bold>, and comparable working memory scores assessed using OSPAN <bold>(G)</bold>. <bold>(H)</bold> EFRs to modulation frequencies of 1024Hz can be reliably recorded in young and middle-aged adults using ‘tiptrodes’. The panel shows grand-averaged FFT traces for YA and MA. <bold>(I)</bold> Middle-aged adults showed significant declines in EFR amplitudes at 1024Hz AM, with putative neural generators in the auditory nerve. <bold>(J)</bold> Signal-to-noise ratios were 8dB on average for YA and 4dB for MA. (K) Statistically significant decreases in EFR amplitudes were selective for 1024Hz AM, the modulation frequency with putative generators in the auditory nerve. All panels: Error bars and shading represent standard error of the mean (SEM). Asterisks represent p&lt;0.05, ANOVA.</p></caption>
<graphic xlink:href="606213v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Comparison of air conduction thresholds using a 3-way ANOVA (MA = 37, YA = 35)</title></caption>
<graphic xlink:href="606213v2_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title>Comparison of extended high frequencies using 3-way ANOVA (MA = 37, YA = 35)</title></caption>
<graphic xlink:href="606213v2_tbl2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><title>Comparison of right ear distortion product otoacoustic emissions using a 2-way ANOVA (MA = 34, YA = 31)</title></caption>
<graphic xlink:href="606213v2_tbl3.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4.</label>
<caption><title>Comparisons using 1-way ANOVAs</title></caption>
<graphic xlink:href="606213v2_tbl4.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>Exposure Questionnaire (NEQ; (<xref ref-type="bibr" rid="c35">35</xref>)) was not significantly different between age groups (<xref rid="fig1" ref-type="fig">Fig. 1F</xref>, <xref rid="tbl4" ref-type="table">Table 4</xref>). Participants also had normal cognitive function indexed by the Montreal Cognitive Assessment (MoCA ≥ 25; (<xref ref-type="bibr" rid="c36">36</xref>)) and comparable working memory scores assessed using the operation span task (OSPAN) ((<xref ref-type="bibr" rid="c37">37</xref>), <xref rid="fig1" ref-type="fig">Fig. 1G</xref>, <xref rid="tbl4" ref-type="table">Table 4</xref>). Hence, the middle-aged adults recruited for this study were all “normal” by currently administered behavioral and audiological assessments in the hearing clinic, while exhibiting some sub- clinical outer hair cell dysfunction, especially at frequencies above 4kHz.</p>
<p>We then measured putative CND using neural ensemble responses from the auditory periphery phase-locked to the stimulus amplitude envelope (Envelope following response, EFR). EFRs can be used to emphasize neural generators in the auditory periphery by exploiting divergent phase-locking abilities along the ascending auditory pathway. EFRs, especially at rapid amplitude modulation (AM) frequencies above 600Hz, have been shown to relate to underlying CND in animal models (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c14">14</xref>) and in humans (<xref ref-type="bibr" rid="c25">25</xref>). Here, we measured EFRs to AM frequencies that have putative neural generators in the central auditory pathway such as the cortex (40Hz AM; (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c38">38</xref>), as well as faster modulation rates (110Hz, 512Hz, and 1024Hz AM) that emphasize progressively peripheral auditory regions (<xref ref-type="bibr" rid="c12">12</xref>). We were able to reliably record EFRs, even to modulation frequencies up to 1024Hz, by using gold-foil tipped electrodes (‘tiptrodes’) placed in the ear canal, closer to the presumptive neural generators in the auditory nerve (<xref rid="fig1" ref-type="fig">Fig. 1H</xref>). EFR peaks analyzed in the spectral domain were above noise floor, with average signal to noise ratios (SNRs) of 8dB in YA and 4dB in MA (Fig. I, J). Statistically significant decreases in EFR amplitudes were only present for EFRs to the 1024Hz AM rate, with putative generators in the auditory nerve (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c14">14</xref>) and were not present for slower AM rates with generators in the midbrain or cortex (<xref rid="fig1" ref-type="fig">Fig. 1K</xref>, <xref rid="tbl5" ref-type="table">Table 5</xref>).</p>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5.</label>
<caption><title>Comparison of EFRs using 2-way ANOVAs (MA = 29, YA = 28)</title></caption>
<graphic xlink:href="606213v2_tbl5.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>To confirm that the EFR parameters used here were indeed sensitive to CND, we measured EFRs using identical stimuli, acquisition, and analysis parameters in young (18wk) and middle-aged (80wk) Mongolian gerbils (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>). Gerbils share the same hearing frequency range as humans, making them an ideal animal model for direct comparison in cross-species studies. Middle-aged gerbils showed no loss of hearing thresholds, similar to middle-aged humans (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). Remarkably, gerbils also exhibited a selective decrease in EFR amplitudes for AM rates at 1024Hz, similar to middle-aged adults (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>, <xref rid="tbl6" ref-type="table">Table 6</xref>). CND was assessed using immunohistological analysis of cochlear whole mounts, where the cell bodies, presynaptic ribbon terminals and the post-synaptic glutamate receptor patches were immunostained, visualized using confocal microscopy, and quantified from 3D reconstructed images (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>). Significant decreases in afferent synapse counts were present in middle-aged gerbils, reaching up to 20% losses compared to the young gerbils (<xref rid="fig2" ref-type="fig">Fig. 2E</xref>, <xref rid="tbl7" ref-type="table">Table 7</xref>). Further, EFR amplitudes were significantly correlated to the number of remaining cochlear synapses (<xref rid="fig2" ref-type="fig">Fig. 2F</xref>), thus confirming that our EFRs were a sensitive metric of CND.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Cross-species experiments in a rodent model show that EFRs are a sensitive biomarker for histologically confirmed CND.</title>
<p><bold>(A)</bold> Cross-species comparisons were made with young (22± 0.86 weeks, n = 14) and middle-aged (80± 0.76 weeks, n = 13) Mongolian gerbils, with identical stimuli, recording, and analysis parameters. <bold>(B)</bold> Middle-aged gerbils did not show any age-related decreases in hearing thresholds. <bold>(C)</bold> Age-related decreases in EFR amplitudes were isolated to the 1024Hz modulation frequency, similar to middle-aged humans in Fig1K. <bold>(D)</bold> CND was quantified for a subset of these gerbils (n = 10 young and 10 middle-aged) using immunostained organ of Corti whole mounts, where afferent excitatory synapses were quantified using 3D reconstructed images. <bold>(E)</bold> Cochlear synapse counts at the 3kHz cochlear region corresponding to the carrier frequency for the EFRs was significantly decreased in middle-aged gerbils, despite matched auditory thresholds. <bold>(F)</bold> EFR amplitudes at 1024Hz AM were significantly correlated with the number of remaining cochlear synapses, suggesting that these EFRs are a sensitive metric for CND with age. All panels: Error bars and shading represent standard error of the mean (SEM). Asterisks represent p&lt;0.05, ANOVA.</p></caption>
<graphic xlink:href="606213v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<table-wrap id="tbl6" orientation="portrait" position="float">
<label>Table 6.</label>
<caption><title>Comparison of 22 week-old gerbil (n= 14) and 80 week-old gerbil (n = 12) EFRs using 2-way ANOVAs</title></caption>
<graphic xlink:href="606213v2_tbl6.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbl7" orientation="portrait" position="float">
<label>Table 7.</label>
<caption><title>Comparison of synapse counts at 3000 Hz in 19 and 74 week-old gerbils using 1-way ANOVA</title></caption>
<graphic xlink:href="606213v2_tbl7.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<sec id="s2a">
<title>Perceptual deficits manifest as increased listening effort prior to behavioral deficits in middle-aged adults</title>
<p>Do middle-aged adults with putative CND experience challenges with hearing in noise despite having clinically normal hearing thresholds? We measured speech perception in noise using the Quick Speech-in- Noise (QuickSIN; (<xref ref-type="bibr" rid="c39">39</xref>)) task, to assess hearing in noise changes that were closer to real-world listening scenarios. QuickSIN tests suprathreshold hearing of medium context sentences presented in varying levels of four-talker background babble (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>). Further, QuickSIN is a clinically relevant test that we recently identified as being sensitive to detect perceptual deficits in adult populations with normal audiograms (<xref ref-type="bibr" rid="c5">5</xref>). Participants are scored on the ability to identify and repeat five key words in each target sentence as the SNR is decreased in 5 dB steps from 25 dB SNR to 0 dB SNR. Clinically, QuickSIN is scored as dB SNR loss, i.e., an estimate of the SNR required to correctly identify key words in noise correctly half the time. No significant age-related decreases were observed in clinically scored QuickSIN measures (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>, <xref rid="tbl4" ref-type="table">Table 4</xref>). When analyzing performance at each SNR, accuracy was at near-ceiling from 25 dB SNR to 10 dB SNR, but dropped from 5dB SNR in both young and middle-aged adults. Statistically significant behavioral deficits with age were observed on QuickSIN only in the most challenging SNR of 0 dB (<xref rid="fig3" ref-type="fig">Fig. 3C</xref>, <xref rid="tbl8" ref-type="table">Table 8</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Increased listening effort precedes behavioral deficits in speech in noise perception in middle-aged adults.</title>
<p><bold>(A)</bold> Speech perception in noise was assessed using the QuickSIN test, which presents moderate context sentences in varying levels of multi-talker babble. Pupillary measures were analyzed in two time-windows – 1. during stimulus presentation, and 2. after target sentence offset and prior to response initiation <bold>(B)</bold> No significant age-related differences were observed in clinical QuickSIN scores presented as dB SNR loss. <bold>(C)</bold> QuickSIN performance is matched between MA and YA until the most difficult noise condition (SNR 0). The x-axis shows the SNR condition that the target sentences were presented in, with 25dB being the easiest noise condition, and 0dB being the most difficult noise condition. The y-axis shows participant accuracy in repeating key words from the target sentences as percent correct. <bold>(D)</bold> Grand-averaged pupillary responses measured during task listening as an index of effort exhibit modulation with task difficulty, with greater pupillary dilations observed in harder conditions for both groups. <bold>(E)</bold> Middle-aged adults show consistently higher pupillary responses during performance on the QuickSIN task and at SNR levels prior to when overt behavioral deficits are observed. <bold>(F)</bold> Grand-averaged pupillary responses measured after target sentence offset as an index of effort exhibit greater modulation with task difficulty, compared to changes in the listening window. <bold>(G)</bold> Trends seen in the listening window were amplified in this integration window, with middle-aged adults showing even greater effort, especially at moderate SNRs where behavior was matched.</p></caption>
<graphic xlink:href="606213v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<table-wrap id="tbl8" orientation="portrait" position="float">
<label>Table 8.</label>
<caption><title>Comparison of QuickSIN performance using a 2-way ANOVA (MA = 34, YA = 31)</title></caption>
<graphic xlink:href="606213v2_tbl8.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>Are there perceptual deficits experienced by middle-aged adults that are not captured by traditional behavioral readouts? We addressed this question by measuring isoluminous task-related changes in pupil diameter as an index of listening effort (<xref ref-type="bibr" rid="c40">40</xref>–<xref ref-type="bibr" rid="c42">42</xref>) while participants performed the QuickSIN task (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>). Pupillary changes were analyzed using growth curve analysis (GCA, (<xref ref-type="bibr" rid="c43">43</xref>)). GCAs provide a statistical approach to modeling changes over time in the timing and shape of the pupillary response and has several advantages to analyzing pupillary response over traditional approaches. First, GCA does not require time-binned samples, thus removing the trade-off between temporal resolution and statistical power, and secondly, GCA can account of individual variability. Two second-order GCAs were fit to different time-windows (<xref rid="tbl9" ref-type="table">Table 9</xref>-10, see methods). One time window from the onset of the masker and covering the first 2.8s of the target sentence (listening window), and second, from the end of the target sentence prior to behavioral response (integration window). These two time-windows are hypothesized to represent effort associated with differing sensory and cognitive processes. The listening window reflects linguistic and semantic processing of ongoing speech stimuli and is a physiological response to auditory processing (<xref ref-type="bibr" rid="c44">44</xref>). The integration window reflects error correction, working memory and comparisons with predictive internal models (<xref ref-type="bibr" rid="c45">45</xref>). (<xref ref-type="bibr" rid="c46">46</xref>). The linear term from the GCA was further analyzed as a marker for the slope of pupillary change over time.</p>
<table-wrap id="tbl9" orientation="portrait" position="float">
<label>Table 9.</label>
<caption><title>Fixed-effect estimates for model of pupillary responses from 0 to 5.8 seconds time-locked to babble masker onset to examine the effect of SNR and age group (observations = 96,612, groups: participant x SNR = 332, participant = 63)</title></caption>
<graphic xlink:href="606213v2_tbl9.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>Pupil-indexed listening effort measured during listening was modulated by task difficulty, with pupil diameters showing a larger growth at challenging SNRs (<xref rid="fig3" ref-type="fig">Fig. 3D</xref>). Both YA and MA showed increases in pupil-indexed effort prior to overt changes in behavioral performance (<xref rid="fig3" ref-type="fig">Fig. 3E</xref>). While MAs exhibited larger increases in listening effort compared to YAs, this change was not statistically significant (<xref rid="fig3" ref-type="fig">Fig. 3E</xref>, Supp. <xref rid="tbl9" ref-type="table">Table 9</xref>). Trends seen in the pupillary responses for the listening window were further amplified in the integration window. Pupillary responses were modulated by task difficulty (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>). Pupillary slopes obtained from the GCA increased with task difficulty in both YA and MA. However, MA showed a steady increase in listening effort with decreasing SNRs that was higher than YA, reaching a statistically significant increase at 10dB SNR, even though behavioral performance was matched (<xref rid="fig3" ref-type="fig">Figure 3G</xref>, Supp. <xref rid="tbl10" ref-type="table">Table 10</xref>). These results suggest that middle-aged adults may maintain comparable performance to younger listeners at moderate task difficulty but at the cost of greater listening effort.</p>
<table-wrap id="tbl10" orientation="portrait" position="float">
<label>Table 10.</label>
<caption><title>Fixed-effect estimates for model of pupillary responses from 0 to 3 seconds time-locked to QuickSIN target sentence offset to examine the effect of SNR and age group (observations = 63,184, groups: participant x SNR = 359, participant = 63)</title></caption>
<graphic xlink:href="606213v2_tbl10.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s2b">
<title>Pupil-indexed listening effort and CND provide synergistic contributions to speech in noise intelligibility</title>
<p>We sought to understand the relationships between CND, listening effort and speech-in-noise intelligibility in normal-hearing middle-aged adults. Behavioral performance in QuickSIN at 0dB SNR, where there was a group effect of age, was significantly correlated with CND assessed using EFRs at 1024 Hz (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>), suggesting that peripheral deafferentation manifests as overt behavioral deficits under the most challenging listening conditions. Pupil-indexed listening effort was also greater in the integration window in middle-aged adults at 10dB SNR (<xref rid="fig3" ref-type="fig">Fig. 3G</xref>), even though behavioral performance was near ceiling in both young and middle-aged adults. Pupillary slopes at 10dB SNR in the integration window were correlated with behavioral deficits at 0 dB SNR (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>). These results add to the emerging evidence suggesting that pupil-indexed effort to maintain behavioral performance at moderate task difficulties is predictive of behavioral performance at more challenging listening conditions (<xref ref-type="bibr" rid="c47">47</xref>). There were significant correlations between pupillary slopes in the listening window as well, even though there were no group level differences with age (<xref rid="fig4" ref-type="fig">Fig. 4C</xref>). These data suggest that CND and increased listening effort both associated with listening challenges in middle-aged adults.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Listening effort and CND provide complementary contributions to speech in noise intelligibility.</title>
<p><bold>(A)</bold> Behavioral performance at the most challenging SNR was significantly correlated with the EFR measures of CND, with lower EFR amplitudes being associated with poorer behavioral performance. <bold>(B)</bold> Pupillary responses at 10 dB SNR from the integration window were significantly correlated with behavioral performance at 0dB SNR, <bold>(B)</bold> These correlations between pupillary responses at 10 dB SNR and behavioral performance at 0dB SNR was also found in the listening window, even though there were no group differences in age, further strengthening the link between listening effort at moderate SNRs and behavioral performance at challenging SNRs. <bold>(D)</bold> an elastic net regression model with 10-fold cross validation (cv) was fit to the QuickSIN scores at 0dB SNR. The tuning parameter Lambda controls the extent to which coefficients contributing least to predictive accuracy are suppressed. <bold>(E)</bold> A lollipop plot displaying the coefficients (β) contributing to explaining variance on QuickSIN performance suggests that CND, listening effort and subclinical changes in hearing thresholds all contribute to QuickSIN performance. <bold>(F)</bold> QuickSIN scores predicted by the elastic net regression are corelated with actual participant QuickSIN scores.</p></caption>
<graphic xlink:href="606213v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Is increase in listening effort synergistic with for CND? To understand the multifactorial contributions of sensory and top-down factors that may affect speech perception in noise, we performed a penalized regression with elastic net penalty (<xref ref-type="bibr" rid="c48">48</xref>), with QuickSIN performance at 0dB SNR (scaled to 0-100) as the outcome variable and all other measured variables as the input variables. The elastic net penalized regression framework is a robust method that blends of Lasso’s ability to perform variable selection and Ridge’s ability to handle multicollinearity and grouped covariates. The fitted elastic net regression model shows an R<sup>2</sup> value of 0.5981, and five significant predictors – hearing thresholds averaged across 500Hz to 4kHz (PTA4k), EFR amplitudes at 1024Hz AM, pupillary slopes at 10dB SNR and 0 dB SNR in the listening window, and pupillary slopes at 10dB SNR in the integration window (<xref rid="fig4" ref-type="fig">Fig. 4D-E</xref>). This model was significantly related to QuickSIN performance and predicted the observed QuickSIN scores across YA and MA (r = 0.64/(pseudo-)R<sup>2</sup> = 0.41, <xref rid="fig4" ref-type="fig">Fig. 4F</xref>). Hence, the output of the elastic net regression suggests that CND and pupil-indexed listening, in addition to subclinical changes in hearing thresholds all provided complementary contributions to speech perception in noise.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Middle-age, typically defined as the fifth and sixth decade of life, has been historically understudied compared to older age ranges (<xref ref-type="bibr" rid="c49">49</xref>). Yet increasing evidence suggests that middle-age is critical as a period of rapid changes in brain function (<xref ref-type="bibr" rid="c50">50</xref>, <xref ref-type="bibr" rid="c51">51</xref>). The resilience of the brain in keeping with degenerative processes that begin to occur in middle-age predicts further age-related degeneration in older ages and presents a critical opportunity for early intervention (<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c52">52</xref>–<xref ref-type="bibr" rid="c54">54</xref>). Hearing loss has been recently identified as the single most modifiable risk factor in middle-age associated with dementia and Alzheimer’s disease later in life (<xref ref-type="bibr" rid="c2">2</xref>). However, the number of middle-aged patients who seek help for hearing difficulties but have no abnormal clinical indicators suggests the need for the development of sensitive biomarkers for hearing challenges experienced by this population (<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c55">55</xref>).</p>
<p>Anatomical evidence from human temporal bones suggests a 40% deafferentation of cochlear synapses in middle-aged adults, even without a substantial noise exposure history (<xref ref-type="bibr" rid="c9">9</xref>–<xref ref-type="bibr" rid="c11">11</xref>). Peripheral deafferentation triggers compensatory mechanisms across sensory, language, and attentional systems (<xref ref-type="bibr" rid="c56">56</xref>–<xref ref-type="bibr" rid="c59">59</xref>). But our understanding of the perceptual consequences of cochlear deafferentation are limited by the lack of consensus on sensitive biomarkers for CND (<xref ref-type="bibr" rid="c60">60</xref>). Recent studies have identified multiple promising biomarkers for CND in animal models and human populations (<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c61">61</xref>). Here, we used one such marker to identify CND in middle-aged adults with normal audiometric thresholds. EFRs measure peripheral neural coding and central auditory activity by exploiting the divergent phase-locking abilities of the ascending auditory pathway (<xref ref-type="bibr" rid="c62">62</xref>). Here, we found decreases in EFRs at modulation rates that are selective for the auditory periphery, while responses from the central auditory structures do not differ with age (<xref rid="fig1" ref-type="fig">Fig. 1K</xref>). These data suggest a decrease in peripheral neural coding, with a concomitant increase in central auditory activity or ‘gain’. The perceptual consequences of this gain are unclear, but emerging evidence suggests selective deficits in speech-in-noise abilities (<xref ref-type="bibr" rid="c58">58</xref>, <xref ref-type="bibr" rid="c63">63</xref>).</p>
<p>The Mongolian gerbil provides a robust model for cross-species comparisons with aging humans, with their overlapping hearing frequency ranges and experimentally tractable lifespans. Here, using young and middle-aged gerbils, we showed similar EFR decreases as seen in human listeners (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>), which are also associated with confirmed CND (<xref rid="fig2" ref-type="fig">Fig. 2F</xref>). The gerbils used in this study also do not have any changes in hearing thresholds (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). Hence, they are unlikely to have known strial degenerations that occur in older gerbils and affect auditory thresholds. The synapse loss patterns and EFR amplitude changes seen here in gerbils are in agreement with earlier studies using alternate rodent models (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c64">64</xref>), further confirming that age-related cochlear synapse loss is a pervasive mammalian phenomenon that can be captured using EFRs to modulation frequencies at 1000Hz AM.</p>
<p>Strong evidence links CND with altered neural coding of sounds in multiple ascending auditory stations (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c58">58</xref>). However, the perceptual consequences of CND are still unclear (<xref ref-type="bibr" rid="c60">60</xref>). Evidence of overt behavioral deficits are mixed and may depend on the specific type of task used for assessment (<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c23">23</xref>). Here, we used QuickSIN, a clinically relevant test that we recently identified as being sensitive to changes in adult normal hearing populations with perceived hearing deficits (<xref ref-type="bibr" rid="c5">5</xref>). However, tests that are further challenging in spectrotemporal complexity, such as the addition of time compression or reverberation, may tease apart these differences even more (<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c25">25</xref>). Behavioral deficits here began to emerge only at the most challenging SNRs (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). However, perceptual deficits in terms of listening effort began to appear well before these behavioral deficits.</p>
<p>Listening effort is an umbrella term that may assess multiple forms of executive function such as cognitive resource allocation, working memory, and attention, and can be assessed by measuring isoluminous task-linked changes in pupil diameter (<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c40">40</xref>–<xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c65">65</xref>). The mechanisms underlying these pupillary changes are still under study (<xref ref-type="bibr" rid="c66">66</xref>, <xref ref-type="bibr" rid="c67">67</xref>) but are hypothesized to involve the Locus Coeruleus – Norepinephrine (LC-NE) system (<xref ref-type="bibr" rid="c68">68</xref>, <xref ref-type="bibr" rid="c69">69</xref>). Here, we observed that pupil-indexed listening effort increased in middle-aged adults, even when behavioral performance is matched (<xref rid="fig3" ref-type="fig">Fig. 3E, F</xref>). This suggests that middle-aged adults expend more effort to maintain behavioral performance, which may lead to more listening fatigue or disengagement from conversations (<xref ref-type="bibr" rid="c26">26</xref>, <xref ref-type="bibr" rid="c70">70</xref>, <xref ref-type="bibr" rid="c71">71</xref>). Potentially confounding factors impacting pupil measurement such as the decrease of pupil dynamic range with aging (<xref ref-type="bibr" rid="c72">72</xref>, <xref ref-type="bibr" rid="c73">73</xref>), participant fatigue, or task habituation (<xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c65">65</xref>, <xref ref-type="bibr" rid="c74">74</xref>) can vary between individuals for a multitude of reasons (<xref ref-type="bibr" rid="c75">75</xref>). Here, the effects of these factors were minimized by applying trial-by-trial baseline corrections prior to analysis to match the magnitude of response between young and middle-aged adults.</p>
<p>Interestingly, pupil-indexed listening effort at a moderate SNR was a better predictor of behavioral performance at a more challenging SNR using two independent methods – a Pearsons’s correlation and the elastic net regression model (<xref rid="fig4" ref-type="fig">Fig. 4B-D</xref>). We have also previously demonstrated similar results in a different test group of young adult participants (<xref ref-type="bibr" rid="c47">47</xref>). Perhaps akin to predicting a person’s ability to run five miles based on assessing their effort required to run one, these results suggest that the amount of effort required to maintain ceiling performance at moderate SNRs are predictive of behavioral performance at harder task difficulties. Pupillary indices at the harder task conditions may be rolling over into hyperexcitability (<xref ref-type="bibr" rid="c66">66</xref>, <xref ref-type="bibr" rid="c67">67</xref>) and thus being a poorer predictor of concomitant behavioral performance.</p>
<p>We used a linear model with an elastic net penalization/regularization (<xref ref-type="bibr" rid="c48">48</xref>) to simultaneously estimate the underlying contributions of the various predictor variables measured in our studies, and perform model selection. This approach has been previously validated for model selection using multidimensional data related to hearing pathologies like tinnitus and hyperacusis (<xref ref-type="bibr" rid="c76">76</xref>). Elastic net is a regularized regression method that minimizes the negative log-likelihood with a penalty on the parameters that combines the l<sub>1</sub> (LASSO) and l<sub>2</sub> (Ridge) penalty, i.e. the elastic net penalty on the regression parameters β can be written as <inline-formula><inline-graphic xlink:href="606213v2_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The relative strength of selection and shrinkage is controlled by the hyper-parameters λ and α: a higher λ implies more stringent penalization pushing towards the null model and 0 ≤ α ≤ 1 controls the degree of convexity and hence the amount of sparsity with α = 0 implying a Ridge regression with no variable selection. An elastic net regularization and has several advantages over both of LASSO or Ridge as well as a simple linear model. The l<sub>1</sub>part of the elastic net (‖β‖<sub>1</sub>) leads to a sparse model where some of the coefficients are shrunk to exact zeroes, thereby performing an automatic model selection without the combinatorial computational complexities of a best- subset selection approach. Further, the quadratic l<sub>2</sub> part <inline-formula><inline-graphic xlink:href="606213v2_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula> encourages grouped variable selection and removes the limitation of number of selected variables unlike LASSO while stablizing the selection path. Our elastic net regression model suggests that CND and listening effort provided complementary contributions to explaining variance on the QuickSIN task.</p>
<p>Even though both young and middle-aged adults had clinically normal hearing thresholds, subtle changes within this normal range affected speech-in-noise performance (<xref rid="fig4" ref-type="fig">Fig. 4D</xref>), lending support to studies suggesting that the definition of clinical ‘normal’ may itself need revision (<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c77">77</xref>). Future studies will directly test this link between cochlear and peripheral neural deficits and listening effort, and explore further contributions of other top-down mechanisms that may influence listening effort such as selective attention or semantic load (<xref ref-type="bibr" rid="c78">78</xref>, <xref ref-type="bibr" rid="c79">79</xref>).</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Humans</title>
<sec id="s4a1">
<title>Participants</title>
<sec id="s4a1a">
<title>Recruitment</title>
<p>Young (<italic>n</italic> = 38; 18-25 years old, male = 10) and middle-aged (<italic>n</italic> = 45; 40-55 years old, male = 16) adult participants were recruited from the University of Pittsburgh Pitt + Me research participant registry, the University of Pittsburgh Department of Communication Science and Disorders research participant pool, and the broader community under a protocol approved by the University of Pittsburgh Institutional Review Board (IRB#21040125). Participants were compensated for their time, travel, and given an additional monetary incentive for completing all study sessions.</p>
</sec>
</sec>
<sec id="s4a2">
<title>Eligibility</title>
<p>Participant eligibility was determined during the first session of the study. Eligible participants had normal cognition determined by the Montreal Cognitive Assessment (MoCA ≥ 25; Nasreddine et al., 2005), normal hearing thresholds (≤ 25 dB HL 250-8000 Hz), no severe tinnitus self- reported via the Tinnitus Handicap Inventory (THI; (<xref ref-type="bibr" rid="c33">33</xref>), and Loudness Discomfort Levels (LDLs) ≥ 80dB HL at .5, 1, and 3kHz (<xref ref-type="bibr" rid="c34">34</xref>). Participants self-reported American English fluency. Thirty-six young (18-25 years old, male = 10) and 30 middle-aged participants (40-55 years old, male = 10) met these eligibility criteria and were tested further using the battery described below. The Beck’s depression Inventory (BDI (<xref ref-type="bibr" rid="c80">80</xref>)) was administered and participants were excluded if they reported thoughts of self-harm, determined by any response to survey item nine greater than 0.</p>
</sec>
</sec>
<sec id="s4b">
<title>Audiological assessment</title>
<sec id="s4b1">
<title>Otoscopy</title>
<p>An otoscopic examination was conducted using a Welch Allyn otoscope to examine the patient’s external auditory canal, tympanic membrane, and middle ear space for excess cerumen, ear drainage, and other abnormalities. The presence of any such abnormality resulted in exclusion from the study, as these may lead to a conductive hearing loss.</p>
</sec>
<sec id="s4b2">
<title>Audiogram</title>
<p>Hearing thresholds were collected inside a sound attenuating booth using a MADSEN Astera<sup>2</sup> audiometer, Otometrics transducers [Natus Medical, Inc. Middleton, WI], and foam insert eartips sized to the participants’ ear canal width. Tones were presented using a pulsed beat and participants were instructed to press a response plunger if they believed that they perceived a tone being played, even if they were unsure. Extended high frequency hearing thresholds (EHFs) were collected at frequencies 8, 12.5, and 16kHz using Sennheiser circumaural headphones and Sennheiser HDA 300 transducers using the same response instructions.</p>
</sec>
<sec id="s4b3">
<title>Loudness Discomfort Levels (LDLs)</title>
<p>LDLs were collected binaurally using Otometrics transducer [Natus Medical, Inc., Middleton, WI] and foam tip ear inserts. Warble tones were presented, and participants were instructed to rate the loudness on a scale of one to seven, with seven being so loud that they would leave the room.</p>
</sec>
<sec id="s4b4">
<title>Distortion Product Otoacoustic Emissions (DPOAEs)</title>
<p>Outer hair cell function was assessed using DPOAEs. DPOAEs were collected from both the right and left ear individually with a starting frequency of 500Hz and an ending frequency of 16kHz. The stimulus had an L1 of 75dB SPL and an L2 of 65dB SPL and was presented in 8 blocks of 24 sweeps with alternating polarity. Responses were collected using rubber ear inserts sized to participants’ ear canal width and ER-10D DPOAE Probe transducer [Etymotic Research Inc., Elk Grove, IL].</p>
</sec>
<sec id="s4b5">
<title>Noise Exposure History</title>
<p>Participants completed the Noise Exposure Questionnaire (NEQ; (<xref ref-type="bibr" rid="c35">35</xref>)) as a self-reported assay of annual noise exposure accounting for both occupational and non-occupational sources. Annual noise exposure was expressed using L<sub>Aeq8760h</sub>, representing the annual hourly duration of noise exposure presented in sound pressure level in dB. Calculation of the L<sub>Aeq8760h</sub> followed the original article (<xref ref-type="bibr" rid="c35">35</xref>).</p>
</sec>
<sec id="s4b6">
<title>OSPAN</title>
<p>Participants also completed the automated version of the OSPAN task(<xref ref-type="bibr" rid="c81">81</xref>), which measures working memory (<xref ref-type="bibr" rid="c37">37</xref>). Participants were shown simple arithmetic problems and asked to decide whether presented solutions to the problems were correct or incorrect. A letter was displayed on the screen after each problem. Participants were required to recall the letters that were displayed in the order that they appeared following a series of arithmetic problems. The task consisted of 15 letter sequences that spanned three to seven letters (three repetitions of each span). If a participant correctly recalled all letters from a sequence, the span length was added to their score. The maximum possible score on the OSPAN task was 75. Each participant’s OSPAN score was used as a measure of working memory.</p>
</sec>
</sec>
<sec id="s4c">
<title>Speech perception in noise</title>
<sec id="s4c1">
<title>Sentence-level speech perception in noise</title>
<p>Speech perception in noise was indexed using moderate-predictability sentences masked in multitalker babble at six different signal-to-noise ratios (SNR) from the Quick Speech in Noise test (QuickSIN; Killion et al., 2004). QuickSIN is a standardized measure of speech perception in noise that is commonly used in audiology clinics and is representative of a naturalistic listening environment (<xref ref-type="bibr" rid="c82">82</xref>). QuickSIN provides a measure of SNR loss. Each QuickSIN test list consisted of six sentences masked in four-talker babble at the following SNR levels: 25, 20, 15, 10, 5, and 0dB. All participants completed four test lists. Participants were instructed to fixate on a point on the screen during listening (to facilitate pupillometry recordings, described below) and to repeat the target sentence to the best of their ability. Each target sentence contained five keywords for identification. The number of key words identified per sentence were recorded. Then, the proportion of keywords correctly identified for each SNR across all four test lists (20 total key words per SNR) was calculated for each participant. In addition to the clinical scoring protocol, participants’ performance as the proportion of correctly identified words (i.e., perception accuracy) was also quantified (<xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c83">83</xref>).</p>
</sec>
</sec>
<sec id="s4d">
<title>Pupillometry</title>
<sec id="s4d1">
<title>Acquisition</title>
<p>Pupillary responses were recorded while participants completed the QuickSIN task. Participants were seated in a testing room with consistent, moderate ambient lighting facing a monitor and an EyeLink 1000 Plus Desktop Mount camera (SR Research). During the pupillometry tasks, participants rested their chins on a head-mount and wore Sennheiser circumaural headphones. The masker was presented at 60dB SPL. The sound level of the target sentences was varied to obtain the required signal to noise ratio. The EyeLink 1000 Plus system recorded monocular left eye pupil size in arbitrary units at a 1000 Hz sampling rate. Nine-point eye-tracker calibration was performed prior to the start of the experiment. Participants were required to fixate on a cross on the screen at the start of each trial for a minimum of 500 ms to trigger the start of the QuickSIN stimulus. This fixation criterion was applied to control for the effects of saccades, which can alter pupil diameter and to minimize pupil foreshortening errors (<xref ref-type="bibr" rid="c84">84</xref>–<xref ref-type="bibr" rid="c86">86</xref>). After meeting the fixation criteria, a 100 ms 1000 Hz beep was presented to alert the participant to the start of the trial. There was two second delay after the beep before the QuickSIN stimulus was presented. The background masker began three seconds before the target sentence and continued for two seconds after the target sentence. Following the end of the stimulus, there was another two second delay and a 100 ms 1000 Hz beep to signal the start of the verbal response period. Manual drift correction was performed at the end of each trial by the experimenter to ensure high quality tracking of the pupil.</p>
</sec>
<sec id="s4d2">
<title>Preprocessing</title>
<p>Raw pupillary data recorded while participants listened to QuickSIN sentences were processed in R (<xref ref-type="bibr" rid="c87">87</xref>) using the <italic>eyelinker</italic> package (<xref ref-type="bibr" rid="c88">88</xref>) and custom written scripts. Pupillary responses were analyzed in two windows of interest: 1) listening window, from multi-talker babble onset through 5800 ms, and 2) integration window, from target sentence offset to 1000 ms prior to behavioral response period. Separately for each window of interest, data were first processed to remove noise from blinks and saccades. Any trial with more than fifteen percent of the samples detected as saccades or blinks were removed. For the remaining trials, blinks were linearly interpolated from 60 ms before to 160ms after the detected blinks. Saccades were linearly interpolated from 60 ms before to 60 ms after any detected saccade. The de-blinked data were then down sampled to a 50 Hz sampling rate. Pupillary responses were baseline corrected and normalized on a trial-by-trial basis to account for a downward drift in baseline that can occur across a task and for individual differences in pupil dynamic range (<xref ref-type="bibr" rid="c85">85</xref>). Baseline pupil size was defined as the average pupil size in the 1000 ms period prior to the start of the window of interest (<inline-formula><inline-graphic xlink:href="606213v2_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula>). The pupillary response was then averaged across all four test lists for each SNR per participant in each window of interest. The outcome reported is percent change in pupil size from baseline.</p>
<p>A growth curve analysis (GCA; Mirman, 2014) was used to obtain a measure of the slope of the pupillary response during listening. GCA uses orthogonal polynomial time terms to model distinct functional forms of the pupillary response over time. A GCA was fit using a second-order orthogonal polynomial to model the interaction of age group with SNR level. This second-order model provides three parameters to explain the pupillary response. The first is the intercept, which refers to the overall change in the pupillary response over the time-window of interest. The second is the linear term (ot1), which represents the slope of the pupillary response over time, or the rate of dilation. The third is the quadratic term (ot2), representing curvature of the pupil response, or the change in rate of the pupillary response over time. GCA were conducted in R (R Core Team, 2022) using the <italic>lme4</italic> package (<xref ref-type="bibr" rid="c89">89</xref>) and <italic>p</italic>-values were estimated using the <italic>lmerTest</italic> package (<xref ref-type="bibr" rid="c90">90</xref>).</p>
<p>For the listening window, the best-fit GCA model included fixed effects of each time term (ot1, ot2), SNR (reference = 25), Group (reference = YA), and all 2- and 3-way interactions between SNR, Group, and time terms. The random effect structure consisted of a random slope of each time term per participant that removed the correlation between random effects, and a random slope of each time term per the interaction of participant and SNR level.
<disp-formula>
<graphic xlink:href="606213v2_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For the integration window, the best-fit GCA model included fixed effects of each time term (ot1, ot2), SNR (reference = 25), Group (reference = YA), and all 2- and 3-way interactions between SNR, Group, and time terms. The random effect structure consisted of a random slope of each time term per participant, and a random slope of each time term per the interaction of participant and SNR level.
<disp-formula>
<graphic xlink:href="606213v2_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
</sec>
<sec id="s4e">
<title>Electrophysiology</title>
<sec id="s4e1">
<title>Envelope Following Responses (EFRs)</title>
<p>EFRs were collected in a sound attenuating booth using a 64-channel EEG system (BioSemi ActiveTwo) with stimuli presented using ER-3C transducers [Etymotic Research Inc., Elk Grove, IL]. Gold-foil tiptrodes were positioned in participants’ ear canals to deliver sound stimuli and record additional channels of evoked potentials from the ear canal. EFRs were recorded to 85dB SPL tones with a carrier frequency of 3000Hz, amplitude modulated (AM) at 40, 110, 512, and 1024Hz. Stimuli were presented in alternating polarity, with 500 repetitions in each polarity. Stimulus duration was 250ms, and each AM token was presented at 3.1 repetitions/second, for a period of 322ms. Stimuli were presented to the right ear. During electrophysiology recordings, participants were sat in a comfortable recliner chair in a low-lit room and watched a silent, subtitled streaming show or movie of their choice and were instructed to avoid falling asleep. Researchers checked in periodically between recordings to ensure that participants were awake. Averaged responses were collected and analyzed further using custom-written scripts in MATLAB.</p>
</sec>
<sec id="s4e2">
<title>Preprocessing</title>
<p>EFRs from the Fz to the ipsilateral (right) tiptrode were further analyzed. EFRs were processed using a fourth-order Butterworth filter with a lowpass filter of 3000Hz. The highpass filter cutoffs used were 5Hz, 80Hz, 200Hz, 300Hz for 40Hz, 110Hz, 512Hz, and 1024Hz AM stimuli, respectively. Fast Fourier transforms (FFTs) were performed on the averaged time domain waveforms for each participant at each AM rate starting 10ms after stimulus onset to exclude ABRs and ending 10ms after stimulus offset using MATLAB v. 2022a (MathWorks Inc., Natick, Massachusetts). The maximum amplitude of the FFT peak at one of three adjacent bins (∼3Hz) around the modulation frequency of the AM rate is reported as the EFR amplitude.</p>
</sec>
</sec>
<sec id="s4f">
<title>Animals</title>
<sec id="s4f1">
<title>Subjects</title>
<p>Fourteen young adult Mongolian gerbils aged 18-27 weeks (male = 9) and thirteen middle-aged Mongolian gerbils aged 75-82 weeks (male = 6) were used in this study. All animals are born and raised in our animal care facility from breeders obtained from Charles River. The acoustic environment within the holding facility has been characterized by noise-level data logging and is periodically monitored. Data logging revealed an average noise level of 56 dB, with transients not exceeding 74 dB during regular housing conditions and transients of 88dB once a week during cage changes. All animal procedures are approved by the Institutional Animal Care and Use Committee of the University of Pittsburgh (Protocol #21046600).</p>
</sec>
</sec>
<sec id="s4g">
<title>Experimental Setup</title>
<p>Experiments were performed in a double walled acoustic chamber. Animals were placed on a water circulated warming blanket set to 37 °C with the pump placed outside the recording chamber to eliminate audio and electrical interferences. Gerbils were initially anesthetized with isoflurane gas anesthesia (4%) in an induction chamber. The animals were transferred post induction to a manifold and maintained at 1%–1.5% isoflurane. The electrodes were then positioned, and the animals were then injected with dexmedetomidine (Dexdomitor, 0.3 mg/kg subdermal) and taken off the isoflurane. The usual duration of isoflurane anesthesia during this setup process was approximately 10 min. Recordings were commenced 15 min after cessation of isoflurane, with the time window for the effects of isoflurane to wear off determined empirically as 9 min, based on ABRs waveforms and latencies as well as the response to foot pinch stimuli. Dexmedetomidine is an alpha-adrenergic agonist which acts as a sedative and an analgesic, and which is known to decrease motivation but preserve behavioral as well as neural responses in rodents (<xref ref-type="bibr" rid="c91">91</xref>, <xref ref-type="bibr" rid="c92">92</xref>). This helps to maintain animals in an un-anesthetized state, where they still respond to pain stimuli like a foot pinch but are otherwise compliant to recordings for a period of about 3 h. Subdermal electrodes (Ambu) were placed on the animals’ scalps for the recordings. A positive electrode was placed along the vertex. The negative electrode was placed under the ipsilateral ear, along the mastoid, while the ground electrode was placed in the base of the tail. Impedances from the electrodes were always less than 1 kHz as tested using the head-stage (RA4LI, Tucker Davis technologies, or TDT).</p>
</sec>
<sec id="s4h">
<title>Stimulus presentation, acquisition, and analysis</title>
<p>The stimulus was presented to the right ear of the animal using insert earphones (ER3C, Etymotic) similar to humans. Signal presentation and acquisition was done by a custom program for gerbils (LabView). The output from the insert earphones was calibrated using a Bruel Kjaer microphone and was found to be within ±6 dB for the frequency range tested. Digitized waveforms were recorded with a multichannel recording and stimulation system (RZ-6, TDT) and analyzed with custom written programs in MATLAB (Mathworks).</p>
<p>Hearing thresholds were obtained using auditory brainstem responses presented to tone stimuli that were 5 ms long, with a 2.5 ms on and off ramp, at 27.1 repetitions per second. ABRs were filtered from 300Hz to 30000Hz, and thresholds were determined as the minimum sound level that produced a response as assessed using visual inspection by two blinded, trained observers.</p>
<p>EFRs were elicited to sinusoidally amplitude modulated (sAM) tones (5ms rise/fall, 250ms duration, 3.1 repetitions/s, alternating polarity) at a 3KHz carrier frequency presented 30dB above auditory thresholds obtained using ABRs at 3kHz. The modulation frequency was systematically varied from 16Hz to 1024Hz AM. Responses were amplified (×10,000; TDT Medusa 4z amplifier) and filtered (0.1–3 kHz). Trials in which the response amplitude exceeded 200μV were rejected; 250 artifact-free trials of each polarity were averaged to compute the EFR waveform. Fast Fourier transforms were performed on the averaged time– domain waveforms starting 10ms after stimulus onset to exclude ABRs and ending at stimulus offset using custom-written programs in MATLAB (MathWorks). The maximum amplitude of the FFT peak at 1 of 3 frequency bins (∼3 Hz each) around the modulation frequency gave the peak FFT amplitude. This FFT amplitude at the modulation frequency of the AM frequency is reported as the EFR amplitude. The noise floor was calculated as the average of 5 frequency bins (∼3 Hz each) above and below the central three bins. A response was deemed as significantly above noise if the FFT amplitude was at least 6 dB above the noise floor.</p>
</sec>
<sec id="s4i">
<title>Immunohistology</title>
<p>Animals were transcardially perfused using a 4% paraformaldehyde solution (Sigma-Aldrich, 441244) for approximately five minutes before decapitation and isolation of the right and left cochlea. Following intra- labyrinthine perfusion with 4% paraformaldehyde, cochleas were stored in paraformaldehyde for one hour. Cochleae were decalcified in EDTA (Fisher Scientific, BP120500) for 3 to 5 days, followed by cryoprotection with sucrose (Fisher Scientific, D16500) and flash freezing. All chemicals were of reagent grade. Cochlea were thawed prior to dissection and dissected in PBS solution. Immunostaining was accomplished by incubation with the following primary antibodies: 1) mouse anti-CtBP2 (BD Biosciences) at 1:200, 2) mouse anti-GluA2 (Millipore) at 1:2000, 3) rabbit anti-myosin VIIa (Proteus Biosciences) at 1:200; followed by incubation with secondary antibodies coupled to AlexaFluors in the red, green, and blue channels. Piece lengths were measured and converted to cochlear frequency using established cochlear maps (<xref ref-type="bibr" rid="c93">93</xref>) and custom plugins in ImageJ. Cochlear stacks were obtained at the target frequency (3kHz) spanning the cuticular plate to the synaptic pole of ∼10 hair cells (in 0.25 μm z-steps). Images were collected in a 1024 × 1024 raster using a high-resolution, oil-immersion objective (x60) and 1.59x digital zoom using a Nikon A1 confocal microscope. Images were denoised in NIS elements and loaded into an image-processing software platform (Imaris; Oxford Instruments), where IHCs were quantified based on their Myosin VIIa-stained cell bodies and CtBP2-stained nuclei. Presynaptic ribbons and postsynaptic glutamate receptor patches were counted using 3D representations of each confocal z-stack. Juxtaposed ribbons and receptor puncta constitute a synapse, and these synaptic associations were determined using IMARIS workflows that calculated and displayed the x–y projection of the voxel space (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c94">94</xref>).</p>
</sec>
<sec id="s4j">
<title>Statistical analysis</title>
<sec id="s4j1">
<title>Analysis of Variance (ANOVA)</title>
<p>Normality was first checked visually using Q-Q plots and statistically using Shapiro-Wilks test with alpha = 0.05. Homogeneity of variance was assessed using Levene’s test. N-way ANOVAs were completed using R 2022.07.1 for each measure to determine statistically significant differences between groups (<xref ref-type="bibr" rid="c95">95</xref>). The package employed, aov(), uses treatment contrasts in which the first baseline level is compared to each of the following levels. The number of factors was determined based on the conditions tested in each measure. Bonferroni corrections were used to control familywise error rate due to multiple comparisons.</p>
</sec>
<sec id="s4j2">
<title>Correlations</title>
<p>Any outliers were detected using Tukey’s Fence with a boundary distance of k = 1.5 and removed. Correlations were computed using Pearson’s correlations. Degrees of freedom, r, and p values are reported.</p>
</sec>
<sec id="s4j3">
<title>Elastic Net Regression</title>
<p>We used an linear model with an elastic net penalization/regularization (<xref ref-type="bibr" rid="c48">48</xref>) to simultaneously estimate the underlying contributions of the various predictor variables measured in our studies, and perform model selection. The relative strength of selection and shrinkage is controlled by the hyper-parameters λ and α: a higher λ implies more stringent penalization pushing towards the null model and 0 ≤ α ≤ 1 controls the degree of convexity and hence the amount of sparsity with α = 0 implying a Ridge regression with no variable selection. To choose the tuning parameters λ and α, we used a 10-fold cross-validation that minimizes the out-of-sample root mean-squared error (RMSE). We used the R packages <italic>glmnet</italic> (<xref ref-type="bibr" rid="c96">96</xref>)and <italic>caret</italic> (<xref ref-type="bibr" rid="c97">97</xref>) for training the elastic net regularizer.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>This work was supported by the National Institute on Deafness and Other Communication Disorders-National Institutes of Health Grants R21DC018882 to A.P, T32DC011499 to K. Kandler and B. yates (Trainee: M.E.Z) and F31DC020085 to J.R.M., and the PNC-Trees Charitable Trust (PNC to B.C. and A.P.). We thank Dr. Carl Snyderman for collaboration on the PNC-Trees grant, and Megan Hallihan, Kathryn Bergstrom, Sarah Anthony, and Shaina Wasileski for their assistance with participant recruitment and data collection. Chandrasekaran). Thanks also to The Center for Biological Imaging at the University of Pittsburgh Dr. Simon Watkins, Katherine Helfrich and Mike Calderon (1S10RR028478 01, PI Watkins) for collaboration on confocal imaging and analysis.</p>
</ack>
<sec id="s5">
<title>Additional information</title>
<sec id="s5a">
<title>Conflict of Interest</title>
<p>The authors declare no competing financial interests.</p>
</sec>
<sec id="s6">
<title>Author Contributions</title>
<p>Conceptualization: AP; Methodology: AP, BC, JM, JD; Data collection: MEZ, JK, KY, VC, OF, CM; Data analysis: MEZ, LZ, JRM, KY, VC, OF, CM; Statistical analysis: JRM, MEZ, LZ, JD; Writing: MEZ, JRM; Editing: AP, JD, BC; Supervision, Project administration: AP, BC; Funding acquisition: AP, BC</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F. R.</given-names> <surname>Lin</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Thorpe</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Gordon-Salant</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Ferrucci</surname></string-name></person-group>, <article-title>Hearing Loss Prevalence and Risk Factors Among Older Adults in the United States</article-title>. <source>J. Gerontol. Ser. -Biol. Sci. Med. Sci</source>. <volume>66</volume>, <fpage>582</fpage>–<lpage>590</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Livingston</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Dementia prevention, intervention, and care</article-title>. <source>The Lancet</source> <volume>390</volume>, <fpage>2673</fpage>–<lpage>2734</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. E.</given-names> <surname>Hind</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Prevalence of clinical referrals having hearing thresholds within normal limits</article-title>. <source>Int. J. Audiol</source>. <volume>50</volume>, <fpage>708</fpage>–<lpage>716</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. L.</given-names> <surname>Tremblay</surname></string-name>, <etal>et al.</etal>, . <collab>. 36,</collab></person-group><article-title>Self-Reported Hearing Difficulties Among Adults With Normal Audiograms: The Beaver Dam Offspring Study</article-title>. <source>Ear Hear</source> <fpage>E290</fpage>–<lpage>E299</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V. E.</given-names> <surname>Cancel</surname></string-name>, <string-name><given-names>J. R.</given-names> <surname>McHaney</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Milne</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Palmer</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name></person-group>, <article-title>A data-driven approach to identify a rapid screener for auditory processing disorder testing referrals in adults</article-title>. <source>Sci. Rep</source>. <volume>13</volume>, <issue>13636</issue> (<year>2023</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name>, <string-name><given-names>K. E.</given-names> <surname>Hancock</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Bennett</surname></string-name>, <string-name><given-names>V.</given-names> <surname>DeGruttola</surname></string-name>, <string-name><given-names>D. B.</given-names> <surname>Polley</surname></string-name></person-group>, <article-title>Bottom-up and top-down neural signatures of disordered multi-talker speech perception in adults with normal hearing</article-title>. <source>eLife</source> <volume>9</volume>, <fpage>e51419</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. G.</given-names> <surname>Kujawa</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Adding Insult to Injury: Cochlear Nerve Degeneration after “Temporary” Noise-Induced Hearing Loss</article-title>. <source>J. Neurosci</source>. <volume>29</volume>, <fpage>14077</fpage>–<lpage>14085</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Schaette</surname></string-name>, <string-name><given-names>D.</given-names> <surname>McAlpine</surname></string-name></person-group>, <article-title>Tinnitus with a Normal Audiogram: Physiological Evidence for Hidden Hearing Loss and Computational Model</article-title>. <source>J. Neurosci</source>. <volume>31</volume>, <fpage>13452</fpage>–<lpage>13457</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P. Z.</given-names> <surname>Wu</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Primary Neural Degeneration in the Human Cochlea: Evidence for Hidden Hearing Loss in the Aging Ear</article-title>. <source>Neuroscience</source> (<year>2018</year>). <pub-id pub-id-type="doi">10.1016/j.neuroscience.2018.07.053</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P.</given-names> <surname>Wu</surname></string-name>, <string-name><given-names>J. T.</given-names> <surname>O’Malley</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Neural Degeneration in Normal-Aging Human Cochleas: Machine-Learning Counts and 3D Mapping in Archival Sections</article-title>. <source>J. Assoc. Res. Otolaryngol</source>. (<year>2023</year>). <pub-id pub-id-type="doi">10.1007/s10162-023-00909-y</pub-id>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P.-Z.</given-names> <surname>Wu</surname></string-name>, <string-name><given-names>J. T.</given-names> <surname>O’Malley</surname></string-name>, <string-name><given-names>V.</given-names> <surname>de Gruttola</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Age-Related Hearing Loss Is Dominated by Damage to Inner Ear Sensory Cells</article-title>, <source>Not the Cellular Battery That Powers Them. J. Neurosci. Off. J. Soc. Neurosci</source>. <volume>40</volume>, <fpage>6357</fpage>–<lpage>6366</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name>, <string-name><given-names>S. G.</given-names> <surname>Kujawa</surname></string-name></person-group>, <article-title>Synaptopathy in the Aging Cochlea: Characterizing Early-Neural Deficits in Auditory Temporal Envelope Processing</article-title>. <source>J. Neurosci. Off. J. Soc. Neurosci</source>. <volume>38</volume>, <fpage>7108</fpage>–<lpage>7119</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. M.</given-names> <surname>Mepani</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Envelope following responses predict speech-in-noise performance in normal-hearing listeners</article-title>. <source>J. Neurophysiol</source>. <volume>125</volume>, <fpage>1213</fpage>–<lpage>1222</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. A.</given-names> <surname>Shaheen</surname></string-name>, <string-name><given-names>M. D.</given-names> <surname>Valero</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Towards a Diagnosis of Cochlear Neuropathy with Envelope Following Responses</article-title>. <source>J Assoc Res Otolaryngol</source> (<year>2015</year>). <pub-id pub-id-type="doi">10.1007/s10162-015-0539-3</pub-id>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Prendergast</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Effects of noise exposure on young adults with normal audiograms I: Electrophysiology</article-title>. <source>Hear. Res</source>. <volume>344</volume>, <fpage>68</fpage>–<lpage>81</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Guest</surname></string-name>, <string-name><given-names>K. J.</given-names> <surname>Munro</surname></string-name>, <string-name><given-names>C. J.</given-names> <surname>Plack</surname></string-name></person-group>, <article-title>Tinnitus with a normal audiogram: Role of high-frequency sensitivity and reanalysis of brainstem-response measures to avoid audiometric over-matching</article-title>. <source>Hear. Res</source>. <volume>356</volume>, <fpage>116</fpage>–<lpage>117</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. J.</given-names> <surname>Grant</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Electrophysiological markers of cochlear function correlate with hearing-in-noise performance among audiometrically normal subjects</article-title>. <source>J. Neurophysiol</source>. <volume>124</volume>, <fpage>418</fpage>–<lpage>431</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. J.</given-names> <surname>Grant</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Predicting neural deficits in sensorineural hearing loss from word recognition scores</article-title>. <source>Sci. Rep</source>. <volume>12</volume>, 8929 (<year>2022</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. D.</given-names> <surname>Valero</surname></string-name>, <string-name><given-names>K. E.</given-names> <surname>Hancock</surname></string-name>, <string-name><given-names>S. F.</given-names> <surname>Maison</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Effects of cochlear synaptopathy on middle-ear muscle reflexes in unanesthetized mice</article-title>. <source>Hear. Res</source>. <volume>363</volume>, <fpage>109</fpage>–<lpage>118</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Mehraei</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Auditory Brainstem Response Latency in Noise as a Marker of Cochlear Synaptopathy</article-title>. <source>J. Neurosci</source>. <volume>36</volume>, <fpage>3755</fpage>–<lpage>3764</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H. M.</given-names> <surname>Bharadwaj</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Cross-species experiments reveal widespread cochlear neural damage in normal hearing. <italic>Commun</italic></article-title>. <source>Biol</source>. <volume>5</volume>, <fpage>1</fpage>–<lpage>10</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. N.</given-names> <surname>Buran</surname></string-name>, <string-name><given-names>G. P.</given-names> <surname>McMillan</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Keshishzadeh</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Verhulst</surname></string-name>, <string-name><given-names>N. F.</given-names> <surname>Bramhall</surname></string-name></person-group>, <article-title>Predicting synapse counts in living humans by combining computational models with auditory physiology</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>151</volume>, <issue>561</issue> (<year>2022</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Prendergast</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Effects of noise exposure on young adults with normal audiograms II: Behavioral measures</article-title>. <source>Hear. Res</source>. <volume>356</volume>, <fpage>74</fpage>–<lpage>86</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. M.</given-names> <surname>Mepani</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Middle Ear Muscle Reflex and Word Recognition in “Normal-Hearing” Adults: Evidence for Cochlear Synaptopathy?</article-title> <source>Ear Hear</source>. (<year>2019</year>). <pub-id pub-id-type="doi">10.1097/AUD.0000000000000804</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. M.</given-names> <surname>Mepani</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Envelope following responses predict speech-in-noise performance in normal-hearing listeners</article-title>. <source>J. Neurophysiol</source>. <volume>125</volume>, <fpage>1213</fpage>–<lpage>1222</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. K.</given-names> <surname>Pichora-Fuller</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Hearing Impairment and Cognitive Energy: The Framework for Understanding Effortful Listening (FUEL)</article-title>. <source>Ear Hear</source>. <volume>37</volume>, <fpage>5S</fpage>–<lpage>27S</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. E.</given-names> <surname>Peelle</surname></string-name></person-group>, <article-title>Listening Effort: How the Cognitive Consequences of Acoustic Challenge Are Reflected in Brain and Behavior</article-title>. <source>Ear Hear</source>. <volume>39</volume>, <fpage>204</fpage>–<lpage>214</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. A.</given-names> <surname>Zekveld</surname></string-name>, <string-name><given-names>S. E.</given-names> <surname>Kramer</surname></string-name>, <string-name><given-names>J. M.</given-names> <surname>Festen</surname></string-name></person-group>, <article-title>Cognitive Load During Speech Perception in Noise: The Influence of Age, Hearing Loss, and Cognition on the Pupil Response</article-title>. <source>Ear Hear</source>. <volume>32</volume>, <fpage>498</fpage>–<lpage>510</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="web"><article-title>International Classification of Functioning, Disability and Health (ICF)</article-title>. Available at: <ext-link ext-link-type="uri" xlink:href="https://www.who.int/standards/classifications/international-classification-of-functioning-disability-and-health">https://www.who.int/standards/classifications/international-classification-of-functioning-disability-and-health</ext-link> [Accessed 4 April 2024]. <year>no date</year></mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Škerková</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Extended high-frequency audiometry: hearing thresholds in adults</article-title>. <source>Eur. Arch. Otorhinolaryngol</source>. <volume>280</volume>, <fpage>565</fpage>–<lpage>572</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. K.</given-names> <surname>Mishra</surname></string-name>, <string-name><given-names>U.</given-names> <surname>Saxena</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Rodrigo</surname></string-name></person-group>, <article-title>Extended High-frequency Hearing Impairment Despite a Normal Audiogram: Relation to Early Aging, Speech-in-noise Perception, Cochlear Function, and Routine Earphone Use</article-title>. <source>Ear Hear</source>. <volume>43</volume>, <fpage>822</fpage>–<lpage>835</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Lough</surname></string-name>, <string-name><given-names>C. J.</given-names> <surname>Plack</surname></string-name></person-group>, <article-title>Extended high-frequency audiometry in research and clinical practice</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>151</volume>, 1944 (<year>2022</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>C. W.</given-names> <surname>Newman</surname></string-name>, <string-name><given-names>G. P.</given-names> <surname>Jacobson</surname></string-name>, <string-name><given-names>J. B.</given-names> <surname>Spitzer</surname></string-name></person-group>, <article-title>Development of the Tinnitus Handicap Inventory</article-title>. <source>Arch. Otolaryngol. Head Neck Surg</source>. <volume>122</volume>, <fpage>143</fpage>–<lpage>148</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. P.</given-names> <surname>Sherlock</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Formby</surname></string-name></person-group>, <article-title>Estimates of loudness, loudness discomfort, and the auditory dynamic range: normative estimates, comparison of procedures, and test-retest reliability</article-title>. <source>J. Am. Acad. Audiol</source>. <volume>16</volume>, <fpage>85</fpage>–<lpage>100</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T. A.</given-names> <surname>Johnson</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Cooper</surname></string-name>, <string-name><given-names>G. C.</given-names> <surname>Stamper</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Chertoff</surname></string-name></person-group>, <article-title>Noise Exposure Questionnaire (NEQ): A Tool for Quantifying Annual Noise Exposure</article-title>. <source>J. Am. Acad. Audiol</source>. <volume>28</volume>, <fpage>14</fpage>–<lpage>35</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Z. S.</given-names> <surname>Nasreddine</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>The Montreal Cognitive Assessment, MoCA: a brief screening tool for mild cognitive impairment</article-title>. <source>J. Am. Geriatr. Soc</source>. 53, <fpage>695</fpage>–<lpage>699</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. L.</given-names> <surname>Turner</surname></string-name>, <string-name><given-names>R. W.</given-names> <surname>Engle</surname></string-name></person-group>, <article-title>Is working memory capacity task dependent?</article-title> <source>J. Mem. Lang</source>. <volume>28</volume>, <fpage>127</fpage>–<lpage>154</lpage> (<year>1989</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Bartlett</surname></string-name></person-group>, <article-title>Two-channel recording of auditory-evoked potentials to detect age- related deficits in temporal processing</article-title>. <source>Hear. Res</source>. <volume>289</volume>, <fpage>52</fpage>–<lpage>62</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. C.</given-names> <surname>Killion</surname></string-name>, <string-name><given-names>P. A.</given-names> <surname>Niquette</surname></string-name>, <string-name><given-names>G. I.</given-names> <surname>Gudmundsen</surname></string-name>, <string-name><given-names>L. J.</given-names> <surname>Revit</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Banerjee</surname></string-name></person-group>, <article-title>Development of a quick speech-in-noise test for measuring signal-to-noise ratio loss in normal-hearing and hearing-impaired listeners</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>116</volume>, <fpage>2395</fpage>–<lpage>2405</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Beatty</surname></string-name></person-group>, <article-title>PHASIC NOT TONIC PUPILLARY RESPONSES VARY WITH AUDITORY VIGILANCE PERFORMANCE</article-title>. <source>Psychophysiology</source> <volume>19</volume>, <fpage>167</fpage>–<lpage>172</lpage> (<year>1982</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. B.</given-names> <surname>Winn</surname></string-name>, <string-name><given-names>J. R.</given-names> <surname>Edwards</surname></string-name>, <string-name><given-names>R. Y.</given-names> <surname>Litovsky</surname></string-name></person-group>, <article-title>The Impact of Auditory Spectral Resolution on Listening Effort Revealed by Pupil Dilation</article-title>. <source>Ear Hear</source>. <volume>36</volume>, <fpage>e153</fpage>–<lpage>e165</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. E.</given-names> <surname>Kuchinsky</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Pupil size varies with word listening and response selection difficulty in older adults with hearing loss</article-title>. <source>Psychophysiology</source> <volume>50</volume>, <fpage>23</fpage>–<lpage>34</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Mirman</surname></string-name></person-group>, <source>Growth Curve Analysis and Visualization Using R</source> (<publisher-name>Chapman and Hall/CRC</publisher-name>, <year>2014</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. R.</given-names> <surname>McHaney</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Tessmer</surname></string-name>, <string-name><given-names>C. L.</given-names> <surname>Roark</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Chandrasekaran</surname></string-name></person-group>, <article-title>Working memory relates to individual differences in speech category learning: Insights from computational modeling and pupillometry</article-title>. <source>Brain Lang</source>. <volume>222</volume>, <issue>105010</issue> (<year>2021</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. B.</given-names> <surname>Winn</surname></string-name></person-group>, <article-title>Time Scales and Moments of Listening Effort Revealed in Pupillometry</article-title>. <source>Semin. Hear</source>. <volume>44</volume>, <fpage>106</fpage>–<lpage>123</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. E.</given-names> <surname>Kuchinsky</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Speech-perception training for older adults with hearing loss impacts word recognition and effort</article-title>. <source>Psychophysiology</source> <volume>51</volume>, <fpage>1046</fpage>–<lpage>1057</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><given-names>J. R.</given-names> <surname>McHaney</surname></string-name>, <string-name><given-names>K. E.</given-names> <surname>Hancock</surname></string-name>, <string-name><given-names>D. B.</given-names> <surname>Polley</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name>, <collab>. [Preprint]</collab></person-group><article-title>Sensory representations and pupil-indexed listening effort provide complementary contributions to multi-talker speech intelligibility</article-title> (<year>2023</year>). Available at: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2023.08.13.553131v1">https://www.biorxiv.org/content/10.1101/2023.08.13.553131v1</ext-link> [Accessed 24 August 2023].</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Zou</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Hastie</surname></string-name></person-group>, <article-title>Regularization and Variable Selection Via the Elastic Net</article-title>. <source>J. R. Stat. Soc. Ser. B Stat. Methodol</source>. <volume>67</volume>, <fpage>301</fpage>–<lpage>320</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Dohm-Hansen</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>The “middle-aging” brain</article-title>. <source>Trends Neurosci</source>. <volume>0</volume> (<year>2024</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Schaum</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Ageing hallmarks exhibit organ-specific temporal signatures</article-title>. <source>Nature</source> <volume>583</volume>, <fpage>596</fpage>– <lpage>602</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T. A.</given-names> <surname>Salthouse</surname></string-name></person-group>, <article-title>Trajectories of normal cognitive aging</article-title>. <source>Psychol. Aging</source> <volume>34</volume>, <fpage>17</fpage>–<lpage>24</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. L.</given-names> <surname>Elliott</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Brain-age in midlife is associated with accelerated biological aging and cognitive decline in a longitudinal birth cohort</article-title>. <source>Mol. Psychiatry</source> <volume>26</volume>, <fpage>3829</fpage>–<lpage>3838</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. L.</given-names> <surname>Elliott</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Disparities in the pace of biological aging among midlife adults of the same chronological age have implications for future frailty risk and policy. <italic>Nat</italic></article-title>. <source>Aging</source> <volume>1</volume>, <fpage>295</fpage>–<lpage>308</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. L.</given-names> <surname>Hughes</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Agrigoroaei</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Jeon</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Bruzzese</surname></string-name>, <string-name><given-names>M. E.</given-names> <surname>Lachman</surname></string-name></person-group>, <article-title>Change in Cognitive Performance From Midlife Into Old Age: Findings from the Midlife in the United States (MIDUS) Study</article-title>. <source>J. Int. Neuropsychol. Soc</source>. <volume>24</volume>, <fpage>805</fpage>–<lpage>820</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. P.</given-names> <surname>Spehar</surname></string-name>, <string-name><given-names>J. T.</given-names> <surname>Lichtenhan</surname></string-name></person-group>, <article-title>Patients With Normal Hearing Thresholds but Difficulty Hearing in Noisy Environments: A Study on the Willingness to Try Auditory Training</article-title>. <source>Otol. Neurotol. Off. Publ. Am. Otol. Soc. Am. Neurotol. Soc. Eur. Acad. Otol. Neurotol</source>. <volume>39</volume>, <fpage>950</fpage>–<lpage>956</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. D.</given-names> <surname>Auerbach</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Radziwon</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Salvi</surname></string-name></person-group>, <article-title>Testing the Central Gain Model: Loudness Growth Correlates with Central Auditory Gain Enhancement in a Rodent Model of Hyperacusis</article-title>. <source>Neuroscience</source> <volume>407</volume>, <fpage>93</fpage>– <lpage>107</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. R.</given-names> <surname>Chambers</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Central Gain Restores Auditory Processing following Near-Complete Cochlear Denervation</article-title>. <source>Neuron</source> <volume>89</volume>, <fpage>867</fpage>–<lpage>879</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Resnik</surname></string-name>, <string-name><given-names>D. B.</given-names> <surname>Polley</surname></string-name></person-group>, <article-title>Cochlear neural degeneration disrupts hearing in background noise by increasing auditory cortex internal noise</article-title>. <source>Neuron</source> <volume>109</volume>, <fpage>984</fpage>–<lpage>996.e4</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H. M.</given-names> <surname>Bharadwaj</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Masud</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Mehraei</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Verhulst</surname></string-name>, <string-name><given-names>B. G.</given-names> <surname>Shinn-Cunningham</surname></string-name></person-group>, <article-title>Individual Differences Reveal Correlates of Hidden Hearing Deficits</article-title>. <source>J. Neurosci</source>. <volume>35</volume>, <fpage>2161</fpage>–<lpage>2172</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Bramhall</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>The search for noise-induced cochlear synaptopathy in humans: Mission impossible?</article-title> <source>Hear. Res</source>. <volume>377</volume>, <fpage>88</fpage>–<lpage>103</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Bharadwaj M</surname></string-name>., <etal>et al.</etal></person-group>, <article-title>Non-Invasive Assays of Cochlear Synaptopathy - Candidates and Considerations</article-title>. <source>Neuroscience</source> <volume>407</volume>, <fpage>53</fpage>–<lpage>66</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P. X.</given-names> <surname>Joris</surname></string-name>, <string-name><given-names>C. E.</given-names> <surname>Schreiner</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Rees</surname></string-name></person-group>, <article-title>Neural processing of amplitude-modulated sounds</article-title>. <source>Physiol. Rev</source>. <volume>84</volume>, <fpage>541</fpage>–<lpage>577</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Dougherty</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Hustedt-Mai</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Hagedorn</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Bharadwaj</surname></string-name></person-group>, <article-title>Central gain in aging, tinnitus, and temporary hearing loss</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>150</volume>, <fpage>A341</fpage>–<lpage>A341</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name>, <string-name><given-names>E. L.</given-names> <surname>Bartlett</surname></string-name></person-group>, <article-title>Age-related Auditory Deficits in Temporal Processing in F-344 Rats</article-title>. <source>Neuroscience</source> <volume>192</volume>, <fpage>619</fpage>–<lpage>630</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V. A.</given-names> <surname>Brown</surname></string-name>, <string-name><given-names>D. J.</given-names> <surname>McLaughlin</surname></string-name>, <string-name><given-names>J. F.</given-names> <surname>Strand</surname></string-name>, <string-name><given-names>K. J.</given-names> <surname>Van Engen</surname></string-name></person-group>, <article-title>Rapid adaptation to fully intelligible nonnative-accented speech reduces listening effort</article-title>. <source>Q. J. Exp. Psychol</source>. 2006 <volume>73</volume>, <fpage>1431</fpage>–<lpage>1443</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. J.</given-names> <surname>McGinley</surname></string-name>, <string-name><given-names>S. V.</given-names> <surname>David</surname></string-name>, <string-name><given-names>D. A.</given-names> <surname>McCormick</surname></string-name></person-group>, <article-title>Cortical Membrane Potential Signature of Optimal States for Sensory Signal Detection</article-title>. <source>Neuron</source> <volume>87</volume>, <fpage>179</fpage>–<lpage>192</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. W.</given-names> <surname>de Gee</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Pupil-linked phasic arousal predicts a reduction of choice bias across species and decision domains</article-title>. <source>eLife</source> <volume>9</volume>, <fpage>e54014</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Joshi</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Kalwani</surname></string-name>, <string-name><given-names>J. I.</given-names> <surname>Gold</surname></string-name></person-group>, <article-title>Relationships between Pupil Diameter and Neuronal Activity in the Locus Coeruleus, Colliculi, and Cingulate Cortex</article-title>. <source>Neuron</source> <volume>89</volume>, <fpage>221</fpage>–<lpage>234</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Reimer</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title>. <source>Nat. Commun</source>. <volume>7</volume>, <issue>13289</issue> (<year>2016</year>).</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. W. Y.</given-names> <surname>Hornsby</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Naylor</surname></string-name>, <string-name><given-names>F. H.</given-names> <surname>Bess</surname></string-name></person-group>, <article-title>A Taxonomy of Fatigue Concepts and Their Relation to Hearing Loss</article-title>. <source>Ear Hear</source>. <volume>37</volume>, <fpage>136S</fpage>–<lpage>144S</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. W. Y.</given-names> <surname>Hornsby</surname></string-name></person-group>, <article-title>The effects of hearing aid use on listening effort and mental fatigue associated with sustained speech processing demands</article-title>. <source>Ear Hear</source>. <volume>34</volume>, <fpage>523</fpage>–<lpage>534</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H. H.</given-names> <surname>Telek</surname></string-name></person-group>, <article-title>The Effects of Age Pupil Diameters at Different Light Amplitudes</article-title>. <source>Beyoglu Eye J</source>. (<year>2018</year>). <pub-id pub-id-type="doi">10.14744/bej.2018.43534</pub-id>.</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names> <surname>Piquado</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Isaacowitz</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Wingfield</surname></string-name></person-group>, <article-title>Pupillometry as a measure of cognitive effort in younger and older adults</article-title>. <source>Psychophysiology</source> <volume>47</volume>, <fpage>560</fpage>–<lpage>569</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W. W.</given-names> <surname>Tryon</surname></string-name></person-group>, <article-title>Pupillometry: A Survey of Sources of Variation</article-title>. <source>Psychophysiology</source> <volume>12</volume>, <fpage>90</fpage>–<lpage>93</lpage> (<year>1975</year>).</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. S.</given-names> <surname>Ansari</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Vehof</surname></string-name>, <string-name><given-names>C. J.</given-names> <surname>Hammond</surname></string-name>, <string-name><given-names>F. D.</given-names> <surname>Bremner</surname></string-name>, <string-name><given-names>K. M.</given-names> <surname>Williams</surname></string-name></person-group>, <article-title>Evidence That Pupil Size and Reactivity Are Determined More by Your Parents Than by Your Environment</article-title>. <source>Front. Neurol</source>. <volume>12</volume> (<year>2021</year>).</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><given-names>S. S.</given-names> <surname>Smith</surname></string-name>, <string-name><given-names>K. N.</given-names> <surname>Jahn</surname></string-name>, <string-name><given-names>J. A.</given-names> <surname>Sugai</surname></string-name>, <string-name><given-names>K. E.</given-names> <surname>Hancock</surname></string-name>, <string-name><given-names>D. B.</given-names> <surname>Polley</surname></string-name>, <collab>. [Preprint]</collab></person-group><article-title>The human pupil and face encode sound affect and provide objective signatures of tinnitus and auditory hypersensitivity disorders</article-title> (<year>2024</year>). Available at: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2023.12.22.571929v2">https://www.biorxiv.org/content/10.1101/2023.12.22.571929v2</ext-link> [Accessed 31 July 2024].</mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. L.</given-names> <surname>Hunter</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Extended high frequency hearing and speech perception implications in adults and children</article-title>. <source>Hear. Res</source>. <volume>397</volume>, <issue>107922</issue> (<year>2020</year>).</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. G.</given-names> <surname>Shinn-Cunningham</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Best</surname></string-name></person-group>, <article-title>Selective attention in normal and impaired hearing</article-title>. <source>Trends Amplif</source>. <volume>12</volume>, <fpage>283</fpage>–<lpage>299</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. J.</given-names> <surname>McLaughlin</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Pupillometry reveals cognitive demands of lexical competition during spoken word recognition in young and older adults</article-title>. <source>Psychon. Bull. Rev</source>. <volume>29</volume>, <fpage>268</fpage>–<lpage>280</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. T.</given-names> <surname>Beck</surname></string-name>, <string-name><given-names>R. A.</given-names> <surname>Steer</surname></string-name>, <string-name><given-names>M. G.</given-names> <surname>Carbin</surname></string-name></person-group>, <article-title>Psychometric properties of the Beck Depression Inventory: Twenty-five years of evaluation</article-title>. <source>Clin. Psychol. Rev</source>. <volume>8</volume>, <fpage>77</fpage>–<lpage>100</lpage> (<year>1988</year>).</mixed-citation></ref>
<ref id="c81"><label>81.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Unsworth</surname></string-name>, <string-name><given-names>R. P.</given-names> <surname>Heitz</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Schrock</surname></string-name>, <string-name><given-names>R. W.</given-names> <surname>Engle</surname></string-name></person-group>, <article-title>An automated version of the operation span task</article-title>. <source>Behav. Res. Methods</source> <volume>37</volume>, <fpage>498</fpage>–<lpage>505</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Meyer</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Dentel</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Meunier</surname></string-name></person-group>, <article-title>Speech recognition in natural background noise</article-title>. <source>PloS One</source> <volume>8</volume>, <fpage>e79279</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. H.</given-names> <surname>Wilson</surname></string-name>, <string-name><given-names>H. B.</given-names> <surname>Abrams</surname></string-name>, <string-name><given-names>A. L.</given-names> <surname>Pillion</surname></string-name></person-group>, <article-title>A word-recognition task in multitalker babble using a descending presentation mode from 24 dB to 0 dB signal to babble</article-title>. <source>J. Rehabil. Res. Dev</source>. <volume>40</volume>, <issue>321</issue> (<year>2003</year>).</mixed-citation></ref>
<ref id="c84"><label>84.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. A.</given-names> <surname>Zekveld</surname></string-name>, <string-name><given-names>J. M.</given-names> <surname>Festen</surname></string-name>, <string-name><given-names>S. E.</given-names> <surname>Kramer</surname></string-name></person-group>, <article-title>Task Difficulty Differentially Affects Two Measures of Processing Load: The Pupil Response During Sentence Processing and Delayed Cued Recall of the Sentences</article-title>. <source>J. Speech Lang. Hear. Res</source>. <volume>56</volume>, <fpage>1156</fpage>–<lpage>1165</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c85"><label>85.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. B.</given-names> <surname>Winn</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Wendt</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Koelewijn</surname></string-name>, <string-name><given-names>S. E.</given-names> <surname>Kuchinsky</surname></string-name></person-group>, <article-title>Best Practices and Advice for Using Pupillometry to Measure Listening Effort: An Introduction for Those Who Want to Get Started</article-title>. <source>Trends Hear</source>. <volume>22</volume>, <issue>2331216518800869</issue> (<year>2018</year>).</mixed-citation></ref>
<ref id="c86"><label>86.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names> <surname>Koelewijn</surname></string-name>, <string-name><given-names>A. A.</given-names> <surname>Zekveld</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Lunner</surname></string-name>, <string-name><given-names>S. E.</given-names> <surname>Kramer</surname></string-name></person-group>, <article-title>The effect of reward on listening effort as reflected by the pupil dilation response</article-title>. <source>Hear. Res</source>. <volume>367</volume>, <fpage>106</fpage>–<lpage>112</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c87"><label>87.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><collab>R Core Team, R: a language and environment for statistical computing</collab></person-group>. (<year>2022</year>). Available at: <ext-link ext-link-type="uri" xlink:href="https://www.gbif.org/tool/81287/r-a-language-and-environment-for-statistical-computing">https://www.gbif.org/tool/81287/r-a-language-and-environment-for-statistical-computing</ext-link> [Accessed 11 December 2022].</mixed-citation></ref>
<ref id="c88"><label>88.</label><mixed-citation publication-type="software"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Barthelme</surname></string-name></person-group>, <source>GitHub</source> - <article-title>a-hurst/eyelinker: An R package for importing data from EyeLink ASC files</article-title>. Available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/a-hurst/eyelinker">https://github.com/a-hurst/eyelinker</ext-link> [Accessed 22 July 2024]. <year>no date</year></mixed-citation></ref>
<ref id="c89"><label>89.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Bates</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Mächler</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Bolker</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Walker</surname></string-name></person-group>, <article-title>Fitting Linear Mixed-Effects Models Using lme4</article-title>. <source>J. Stat. Softw</source>. <volume>67</volume>, <fpage>1</fpage>–<lpage>48</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c90"><label>90.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Kuznetsova</surname></string-name>, <string-name><given-names>P. B.</given-names> <surname>Brockhoff</surname></string-name>, <string-name><given-names>R. H. B.</given-names> <surname>Christensen</surname></string-name></person-group>, <article-title>lmerTest Package: Tests in Linear Mixed Effects Models</article-title>. <source>J. Stat. Softw</source>. <volume>82</volume>, <fpage>1</fpage>–<lpage>26</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c91"><label>91.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Ruotsalainen</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Haapalinna</surname></string-name>, <string-name><given-names>P. J.</given-names> <surname>Riekkinen</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Sirviö</surname></string-name></person-group>, <article-title>Dexmedetomidine Reduces Response Tendency, but Not Accuracy of Rats in Attention and Short-Term Memory Tasks</article-title>. <source>Pharmacol. Biochem. Behav</source>. <volume>56</volume>, <fpage>31</fpage>–<lpage>40</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c92"><label>92.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Ter-Mikaelian</surname></string-name>, <string-name><given-names>M. N.</given-names> <surname>Semple</surname></string-name>, <string-name><given-names>D. H.</given-names> <surname>Sanes</surname></string-name></person-group>, <article-title>Effects of spectral and temporal disruption on cortical encoding of gerbil vocalizations</article-title>. <source>J. Neurophysiol</source>. <volume>110</volume>, <fpage>1190</fpage>–<lpage>1204</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c93"><label>93.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. D.</given-names> <surname>Greenwood</surname></string-name></person-group>, <article-title>A Cochlear Frequency-Position function for several species -29 Years Later</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>87</volume>, <fpage>2592</fpage>–<lpage>2605</lpage> (<year>1990</year>).</mixed-citation></ref>
<ref id="c94"><label>94.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. D.</given-names> <surname>Liberman</surname></string-name>, <string-name><given-names>H. B.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Opposing Gradients of Ribbon Size and AMPA Receptor Expression Underlie Sensitivity Differences among Cochlear-Nerve/Hair-Cell Synapses</article-title>. <source>J. Neurosci</source>. <volume>31</volume>, <fpage>801</fpage>–<lpage>808</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c95"><label>95.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>E. R.</given-names> <surname>Girden</surname></string-name></person-group>, <source>ANOVA: Repeated measures</source> (<publisher-name>Sage Publications, Inc</publisher-name>, <year>1992</year>).</mixed-citation></ref>
<ref id="c96"><label>96.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Friedman</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Hastie</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Tibshirani</surname></string-name></person-group>, <article-title>Regularization Paths for Generalized Linear Models via Coordinate Descent</article-title>. <source>J. Stat. Softw</source>. <volume>33</volume>, <fpage>1</fpage>–<lpage>22</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c97"><label>97.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Kuhn</surname></string-name></person-group>, <article-title>Building Predictive Models in R Using the caret Package</article-title>. <source>J. Stat. Softw</source>. <volume>28</volume>, <fpage>1</fpage>–<lpage>26</lpage> (<year>2008</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102823.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Obleser</surname>
<given-names>Jonas</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Lübeck</institution>
</institution-wrap>
<city>Lübeck</city>
<country>Germany</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study is part of an ongoing effort to clarify the effects of cochlear neural degeneration on auditory processing in listeners with normal audiograms. Here the authors provide <bold>important</bold> new data demonstrating associations between cochlear neural degeneration, non-invasive assays of auditory processing, and speech perception. Based on a cross-species comparison, these findings pose <bold>compelling</bold> evidence that cochlear synaptopathy is associated with a significant part of hearing difficulties in complex environments for some listeners with normal hearing thresholds, such as older individuals.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102823.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This study is part of an ongoing effort to clarify the effects of cochlear neural degeneration (CND) on auditory processing in listeners with normal audiograms. This effort is important because ~10% of people who seek help for hearing difficulties have normal audiograms and current hearing healthcare has nothing to offer them.</p>
<p>The authors identify two shortcomings in previous work that they intend to fix. The first is a lack of cross-species studies that make direct comparisons between animal models in which CND can be confirmed and humans for which CND must be inferred indirectly. The second is the low sensitivity of purely perceptual measures to subtle changes in auditory processing. To fix these shortcomings, the authors measure envelope following responses (EFRs) in gerbils and humans using the same sounds, while also performing histological analysis of the gerbil cochleae, and testing speech perception while measuring pupil size in the humans.</p>
<p>The study begins with a comprehensive assessment of the hearing status of the human listeners. The only differences found between the young adult (YA) and middle-aged (MA) groups are in thresholds at frequencies &gt; 10 kHz and DPOAE amplitudes at frequencies &gt; 5 kHz. The authors then present the EFR results, first for the humans and then for the gerbils, showing that amplitudes decrease more rapidly with increasing envelope frequency for MA than for YA in both species. The histological analysis of the gerbil cochleae shows that there were, on average, 20% fewer IHC-AN synapses at the 3 kHz place in MA relative to YA, and the number of synapses per IHC was correlated with the EFR amplitude at 1024 Hz.</p>
<p>The study then returns to the humans to report the results of the speech perception tests and pupillometry. The correct understanding of keywords decreased more rapidly with decreasing SNR in MA than in YA, with a noticeable difference at 0 dB, while pupillary slope (a proxy for listening effort) increased more rapidly with decreasing SNR for MA than for YA, with the largest differences at SNRs between 5 and 15 dB. Finally, the authors report that a linear combination of audiometric threshold, EFR amplitude at 1024 Hz, and a few measures of pupillary slope is predictive of speech perception at 0 dB SNR.</p>
<p>I only have two questions/concerns about the specific methodologies used:</p>
<p>(1) Synapse counts were made only at the 3 kHz place on the cochlea. However, the EFR sounds were presented at 85 dB SPL, which means that a rather large section of the cochlea will actually be excited. Do we know how much of the EFR actually reflects AN fibers coming from the 3 kHz place? And are we sure that this is the same for gerbils and humans given the differences in cochlear geometry, head size, etc.?</p>
<p>(2) Unless I misunderstood, the predictive power of the final model was not tested on held-out data. The standard way to fit and test such a model would be to split the data into two segments, one for training and hyperparameter optimization, and one for testing. But it seems that the only split was for training and hyperparameter optimization.</p>
<p>While I find the study to be generally well executed, I am left wondering what to make of it all. The purpose of the study with respect to fixing previous methodological shortcomings was clear, but exactly how fixing these shortcomings has allowed us to advance is not. I think we can be more confident than before that EFR amplitude is sensitive to CND, and we now know that measures of listening effort may also be sensitive to CND. But where is this leading us?</p>
<p>I think what this line of work is eventually aiming for is to develop a clinical tool that can be used to infer someone's CND profile. That seems like a worthwhile goal but getting there will require going beyond exploratory association studies. I think we're ready to start being explicit about what properties a CND inference tool would need to be practically useful. I have no idea whether the associations reported in this study are encouraging or not because I have no idea what level of inferential power is ultimately required.</p>
<p>That brings me to my final comment: there is an inappropriate emphasis on statistical significance. The sample size was chosen arbitrarily. What if the sample had been half the size? Then few, if any, of the observed effects would have been significant. What if the sample had been twice the size? Then many more of the observed effects would have been significant (particularly for the pupillometry). I hope that future studies will follow a more principled approach in which relevant effect sizes are pre-specified (ideally as the strength of association that would be practically useful) and sample sizes are determined accordingly.</p>
<p>So, in summary, I think this study is a valuable but limited advance. The results increase my confidence that non-invasive measures can be used to infer underlying CND, but I am unsure how much closer we are to anything that is practically useful.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102823.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper addresses the bottom-up and top-down causes of hearing difficulties in middle-aged adults with clinically-normal audiograms using a cross-species approach (humans vs. gerbils, each with two age groups) mixing behavioral tests and electrophysiology. The study is not only a follow-up of Parthasarathy et al (eLife 2020), since there are several important differences.</p>
<p>Parthasarathy et al. (2020) only considered a group of young normal-hearing individuals with normal audiograms yet with high complaints of hearing in noisy situations. Here, this issue is considered specifically regarding aging, using a between-subject design comparing young NH and older NH individuals recruited from the general population, without additional criterion (i.e. no specifically high problems of hearing in noise). In addition, this is a cross-species approach, with the same physiological EFR measurements with the same stimuli deployed on gerbils.</p>
<p>This article is of very high quality. It is extremely clear, and the results show clearly a decrease of neural phase-locking to high modulation frequencies in both middle-aged humans and gerbils, compared to younger groups/cohorts. In addition, pupillometry measurements conducted during the QuickSIN task suggest increased listening efforts in middle-aged participants, and a statistical model including both EFRs and pupillometry features suggests that both factors contribute to reduced speech-in-noise intelligibility evidenced in middle-aged individuals, beyond their slight differences in audiometric thresholds (although they were clinically normal in both groups).</p>
<p>These provide strong support to the view that normal aging in humans leads to auditory nerve synaptic loss (cochlear neural degeneration - CNR- or, put differently, cochlear synaptopathy) as well as increased listening effort, before any clearly visible audiometric deficits as defined in current clinical standards. This result is very important for the community since we are still missing direct evidence that cochlear synaptopathy might likely underlie a significant part of hearing difficulties in complex environments for listeners with normal thresholds, such as middle-aged and senior listeners. This paper shows that these difficulties can be reasonably well accounted for by this sensory disorder (CND), but also that listening effort, i.e. a top-down factor, further contributes to this problem. The methods are sound and well described and I would like to emphasize that they are presented concisely yet in a very precise manner so that they can be understood very easily - even for a reader who is not familiar with the employed techniques. I believe this study will be of interest to a broad readership.</p>
<p>I have some comments and questions which I think would make the paper even stronger once addressed.</p>
<p>Main comments:</p>
<p>(1) Presentation of EFR analyses / Interpretation of EFR differences found in both gerbils and humans:</p>
<p>a) Could the authors comment further on why they think they found a significant difference only at the highest mod. frequency of 1024 Hz in their study? Indeed, previous studies employing SAM or RAM tones very similar to the ones employed here were able to show age effects already at lower modulation freqs. of ~100H; e.g. there are clear age effects reported in human studies of Vasilikov et al. (2021) or Mepani et al. (2021), and also in animals (see Garrett et al. bioXiv: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf">https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf</ext-link>).</p>
<p>Furthermore, some previous EEG experiments in humans that SAM tones with modulation freqs. of ~100Hz showed that EFRs do not exhibit a single peak, i.e. there are peaks not only at fm but also for the first harmonics (e.g. 2*fm or 3*fm) see e.g.Garrett et al. bioXiv <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf">https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf</ext-link>.</p>
<p>Did the authors try to extract EFR strength by looking at the summed amplitude of multiple peaks (Vasilikov Hear Res. 2021), in particular for the lower modulation frequencies? (indeed, there will be no harmonics for the higher mod. freqs).</p>
<p>b) How do the present EFR results relate to FFR results, where effects of age are already at low carrier freqs? (e.g. Märcher-Rørsted et al., Hear. Res., 2022 for pure tones with freq &lt; 500 Hz). Do the authors think it could be explained by the fact that this is not the same cochlear region, and that synapses die earlier in higher compared to lower CFs? This should be discussed. Beyond the main group effect of age, there were no negative correlations of EFRs with age in the data?</p>
<p>(2) Size of the effects / comparing age effects between two species:</p>
<p>Although the size of the age effect on EFRs cannot be directly compared between humans and gerbils - the comparison remains qualitative - could the authors at least provide references regarding the rate of synaptic loss with aging in both humans and gerbils, so that we understand that the yNH/MA difference can be compared between the two age groups used for gerbils; it would have been critical in case of a non-significant age effect in one species.</p>
<p>Equalization/control of stimuli differences across the two species: For measuring EFRs, SAM stimuli were presented at 85 dB SPL for humans vs. 30 dB above the detection threshold (inferred from ABRs) for gerbils - I do not think the results strongly depend on this choice, but it would be good to comment on why you did not choose also to present stimuli 30 dB above thresholds in humans.</p>
<p>Simulations of EFRs using functional models could have been used to understand (at least in humans) how the differences in EFRs obtained between the two groups are *quantitatively* compatible with the differences in % of remaining synaptic connections known from histopathological studies for their age range (see the approach in Märcher-Rørsted et al., Hear. Res., 2022)</p>
<p>(3) Synergetic effects of CND and listening effort:</p>
<p>Could you test whether there is an interaction between CNR and listening effort? (e.g. one could hypothesize that MA subjects with the largest CND have also higher listening effort).</p>
</body>
</sub-article>
</article>