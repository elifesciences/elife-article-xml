<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">95243</article-id>
<article-id pub-id-type="doi">10.7554/eLife.95243</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.95243.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Embedding stochastic dynamics of the environment in spontaneous activity by prediction-based plasticity</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0951-5791</contrib-id>
<name>
<surname>Asabuki</surname>
<given-names>Toshitake</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<email>toshitake.asabuki@riken.jp</email>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4507-8648</contrib-id>
<name>
<surname>Clopath</surname>
<given-names>Claudia</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>c.clopath@imperial.ac.uk</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Department of Bioengineering, Imperial College London</institution></institution-wrap>, <city>London</city>, <country>UK</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04j1n1c04</institution-id><institution>RIKEN Center for Brain Science, RIKEN ECL Research Unit</institution></institution-wrap>, <city>Wako</city>, <country>Japan</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01sjwvz98</institution-id><institution>RIKEN Cluster for Pioneering Research</institution></institution-wrap>, <city>Wako</city>, <country>Japan</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Gjorgjieva</surname>
<given-names>Julijana</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Technical University of Munich</institution>
</institution-wrap>
<city>Freising</city>
<country>Germany</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-04-12">
<day>12</day>
<month>04</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2024-12-03">
<day>03</day>
<month>12</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP95243</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-01-17">
<day>17</day>
<month>01</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-05-01">
<day>01</day>
<month>05</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.05.01.538909"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-04-12">
<day>12</day>
<month>04</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95243.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.95243.1.sa3">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.95243.1.sa2">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.95243.1.sa1">Reviewer #2 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.95243.1.sa0">Reviewer #3 (Public Review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Asabuki &amp; Clopath</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Asabuki &amp; Clopath</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-95243-v2.pdf"/>
<abstract>
<title>Abstract</title>
<p>The brain learns an internal model of the environment through sensory experiences, which is essential for high-level cognitive processes. Recent studies show that spontaneous activity reflects such learned internal model. Although computational studies have proposed that Hebbian plasticity can learn the switching dynamics of replayed activities, it is still challenging to learn dynamic spontaneous activity that obeys the statistical properties of sensory experience. Here, we propose a pair of biologically plausible plasticity rules for excitatory and inhibitory synapses in a recurrent spiking neural network model to embed stochastic dynamics in spontaneous activity. The proposed synaptic plasticity rule for excitatory synapses seeks to minimize the discrepancy between stimulus-evoked and internally predicted activity, while inhibitory plasticity maintains the excitatory-inhibitory balance. We show that the spontaneous reactivation of cell assemblies follows the transition statistics of the model’s evoked dynamics. We also demonstrate that simulations of our model can replicate recent experimental results of spontaneous activity in songbirds, suggesting that the proposed plasticity rule might underlie the mechanism by which animals learn internal models of the environment.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>New simulation results were included in the revised version.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The brain is thought to use its sensory experience to learn an appropriate internal model of the environment, which can improve perception and behavioral performance. (<xref ref-type="bibr" rid="c41">Merfeld et al., 1999</xref>; <xref ref-type="bibr" rid="c37">Lewald and Ehrenstein, 1998</xref>; <xref ref-type="bibr" rid="c9">Bell et al., 1997</xref>; <xref ref-type="bibr" rid="c57">Yasui and Young, 1975</xref>; <xref ref-type="bibr" rid="c55">Wolpert et al., 1995</xref>). Such learning is thought to be fundamental to higher-order cognitive processes such as perception, decision making, and prediction of sensory stimuli. Recent computational and experimental evidence suggests that the brain’s learned internal model may be reflected in spontaneous activity. For example, in the visual cortex of awake ferrets, spontaneous activity shows spatial similarity to activity elicited by natural scenes (<xref ref-type="bibr" rid="c10">Berkes et al., 2011</xref>). Furthermore, hippocampus generates sequential replay of place fields during rest and sleep (<xref ref-type="bibr" rid="c54">Wilson and McNaughton, 1994</xref>; <xref ref-type="bibr" rid="c48">Skaggs and McNaughton, 1996</xref>; <xref ref-type="bibr" rid="c35">Lee and Wilson, 2002</xref>). Such hippocampal replay occurs in a highly stereotyped temporal order, with the same sequence of replayed activities often observed across multiple events (<xref ref-type="bibr" rid="c16">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="c17">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="c27">Gupta et al., 2010</xref>; <xref ref-type="bibr" rid="c56">Wu and Foster, 2014</xref>).</p>
<p>Several computational studies have proposed variants of Hebbian plasticity rules for learning deterministic or even stochastic switching dynamics of replayed activities (<xref ref-type="bibr" rid="c36">Levy et al., 2001</xref>; <xref ref-type="bibr" rid="c38">Litwin-Kumar and Doiron, 2014</xref>; <xref ref-type="bibr" rid="c51">Triplett et al., 2018</xref>; <xref rid="c24" ref-type="bibr">Ocker and Doiron, 2019</xref>; <xref rid="c2" ref-type="bibr">Asabuki and Fukai, 2023</xref>). However, it has been challenging to extend these results to generate dynamic spontaneous activity obeying appropriate transition probabilities learned through sensory experience. Finding a plasticity rule which is capable of learning structured transitions in spontaneous activity could be instrumental for understanding the mechanism underlying cognitive processes in the brain.</p>
<p>In this paper, we propose a local biologically-plausible plasticity rule for learning the statistical transitions between assemblies in spontaneous activity. We use a recurrent spiking neural network model consisting of distinct excitatory and inhibitory populations. The proposed synaptic plasticity rule for excitatory synapses seeks to minimize the discrepancy between stimulus-evoked and internally predicted activity, while inhibitory plasticity maintains the excitatory-inhibitory balance. We explore the potential performance of our model by learning the Markovian transition statistics of evoked network states. Our results show that the trained model exhibits spontaneous stochastic transitions of cell assemblies, even after structured external inputs are removed. We show that the transition statistics of spontaneous activity show a striking similarity to those of the evoked dynamics.</p>
<p>To further validate our model, we compare the model behavior with recent experimental results in songbirds (<xref ref-type="bibr" rid="c12">Bouchard and Brainard, 2016</xref>), which show that the uncertainty of upcoming states in a bird song modulates the degree of neural predictability. Our model replicates this experimental result, suggesting that the connectivity structure learned via the proposed plasticity mechanism could plausibly underlie the songbird’s learned internal model.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Spontaneous replay of learnt stochastic sequences</title>
<p>While most studies have investigated plasticity mechanisms for learning random switching (<xref ref-type="bibr" rid="c38">Litwin-Kumar and Doiron, 2014</xref>; <xref ref-type="bibr" rid="c51">Triplett et al., 2018</xref>; <xref rid="c24" ref-type="bibr">Ocker and Doiron, 2019</xref>; <xref rid="c2" ref-type="bibr">Asabuki and Fukai, 2023</xref>) or deterministic transitions (<xref ref-type="bibr" rid="c14">Chadwick et al., 2015</xref>) between cell assemblies, our objective is to create a network model that spontaneously replays stochastic sequences of assemblies following synaptic plasticity. To that end, we first design a simple task whereby stimuli undergo stochastic transitions over time, and presentation of each stimulus increases excitatory drive to neurons targeted by that pattern (<xref rid="fig1" ref-type="fig">Fig.1a</xref>, top). We assume that a non-overlapping subset of excitatory network neurons receive its preferred stimulus (<xref rid="fig1" ref-type="fig">Fig. 1b</xref>). After learning, the network should replay stochastic sequences of assemblies with transitions that are statistically consistent with evoked dynamics, without relying on external stimuli (<xref rid="fig1" ref-type="fig">Fig.1a</xref>, bottom).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Task to be learned (a, top) An example of a task used to test the model. Stimulus patterns evolve in time according to structured transition probabilities. The presentation of each stimulus pattern activates the corresponding group of neurons. Recurrent connections are learned by synaptic plasticity (a, bottom). The learned network should replay assemblies spontaneously, where the transition statistics are consistent with the evoked stimuli. (b) A network model with distinct excitatory and inhibitory populations. Only excitatory populations are driven by external inputs. Only synapses that project to excitatory neurons are assumed to be plastic. (c) A schematic of the plasticity rules proposed in (Asabuki &amp; Clopath, 2023). Excitatory (blue) and inhibitory (orange) synapses projecting to an excitatory neuron (triangle) obey different plasticity rules. For excitatory synapses, errors between internally driven excitation (blue sigmoid) and the output of the cell provide feedback to the synapses (dashed arrow) and modulate plasticity (blue square; exc. error). All excitatory connections seek to minimize these errors. For inhibitory synapses, the error between internally driven excitation (blue sigmoid) and inhibition (orange sigmoid) must be minimized to maintain excitation-inhibition balance (orange square; inh. error).</p></caption>
<graphic xlink:href="538909v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We examined the possible learning mechanisms of stochastic neural sequences with a recurrent spiking network. Our network model consists of excitatory (E) and inhibitory (I) model neurons (<xref rid="fig1" ref-type="fig">Fig. 1b</xref>). Only excitatory neurons are driven by external stochastic sequences. Initially, neurons in the network have random recurrent connections.</p>
<p>To learn a network model to obtain transition statistics of evoked dynamics, we proposed different local plasticity mechanisms for excitatory and inhibitory synapses. We assumed that only connections onto excitatory neurons were plastic (<xref rid="fig1" ref-type="fig">Fig. 1b</xref>), while all others (i.e., connections onto inhibitory neurons) were fixed. In the excitatory recurrent connectivity, all synaptic weights were modified to reduce the error between internally generated and stimulus-evoked activities (<xref rid="fig1" ref-type="fig">Fig. 1c</xref>, blue square). This plasticity rule is mathematically similar to that proposed in (<xref ref-type="bibr" rid="c44">Pfister et al., 2006</xref>; <xref ref-type="bibr" rid="c52">Urbanczik and Senn, 2014</xref>), which minimizes the discrepancy between the somatic and dendritic activities (<xref ref-type="bibr" rid="c3">Asabuki and Fukai, 2020</xref>; Asabuki and <xref rid="c4" ref-type="bibr">Fukai, 2024</xref>). Through this process, excitatory synapses that contribute to predicting neural activity will be strengthened, thereby increasing the similarity between spontaneous and evoked activity. Instead of predicting the firing rate of neurons, the inhibitory synapses were modified to predict the recurrent excitatory potential (<xref rid="fig1" ref-type="fig">Fig. 1c</xref>, orange square). This inhibitory plasticity is crucial for the network to maintain excitatory-inhibitory balance (<xref ref-type="bibr" rid="c53">Vogels et al., 2011</xref>) and generate spontaneous replay of stochastic assembly sequences, as we will see later. All feedforward connections were fixed and receptive fields were preconfigured. Finally, as in previous study (<xref rid="c2" ref-type="bibr">Asabuki and Fukai, 2023</xref>), parameters of the response function are regulated according to the activity history of individual neurons (Methods). This regulation maintains the appropriate dynamic range of activities irrespective of the strength of external stimuli.</p>
<p>To examine how external stochastic sequences can influence network wiring, we trained a network model driven by stochastic external inputs. These inputs were generated by first-order Markovian chains with three 200ms long states, governed by fixed transition probabilities (<xref rid="fig2" ref-type="fig">Fig. 2a</xref>). During training, excitatory synapses were modified much quicker than inhibitory synapses (<xref rid="fig2" ref-type="fig">Fig.2b</xref>). This difference in plasticity timescales follows from the nature of our learning rules: the wiring of excitatory synapses is reorganized by external stimuli, while inhibitory synapses only change to rebalance excitation. As such, excitatory plasticity in our model occurs before inhibitory plasticity, consistent with the experimental results (<xref rid="c15" ref-type="bibr">D’amour JA and Froemke, 2015</xref>). Indeed, even when the learning rate of inhibitory plasticity was twice that of excitatory plasticity, inhibitory plasticity still occurred on a slower timescale than excitatory plasticity. (Supplementary Fig. 2).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Spontaneous replay of stochastic transition of assemblies. (a) First, we considered a simple stochastic transition between three stimulus patterns. (b) Dynamics of weight change via plasticity. Excitatory synapses (blue) converged quicker than inhibitory synapses (orange). (c) Example spontaneous assembly reactivations (top) and raster plot (bottom) of the learned network are shown. Colors indicate the corresponding stimulus patterns shown in a. (d) Distribution of assembly reactivations. (e, left) The network currents to assembly 1 (green) and assembly 2 (orange) immediately after the reactivation of assembly 3 ceased. Both currents were similar in magnitude. (e, right) Currents to assembly 2 (orange) and assembly 3 (blue) immediately after the reactivation of assembly 1 ceased. The current to assembly 3 was stronger than that to assembly 2. (f) Relationship between the transition statistics of stimulus patterns and that of replayed assemblies. The spontaneous activity reproduced transition statistics of external stimulus patterns.</p></caption>
<graphic xlink:href="538909v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We then asked how plasticity affects the neural dynamics by comparing the spontaneous activities of the network before and after learning. Here, we simulated spontaneous activity by replacing the temporally structured stimulation (i.e., the Markovian chain in <xref rid="fig2" ref-type="fig">Fig.2a</xref>) with constant background input. Further, all synapses were kept fixed during spontaneous activity. Before learning, due to uniform initial connectivity, all excitatory neurons showed synchronous and spatially unstructured spontaneous activity (Supplementary Fig.1). However, after learning, three cell assemblies emerged in the network, each of which encoded one external stimulus. Sequences of these cell assemblies were replayed stochastically in spontaneous activity (<xref rid="fig2" ref-type="fig">Fig. 2c</xref>), and durations of given assembly reactivations were biased toward shorter durations but distributed broadly (<xref rid="fig2" ref-type="fig">Fig.2d</xref>).</p>
<p>We next asked whether or not the statistics of assembly switching were influenced by the temporal structure of the external sequence received by the network while it was learning. Since each assembly reactivation was contingent upon previous assembly, statistics of external sequence may influence the strength of synaptic currents via recurrent connectivity. To test this prediction, we first investigated how spontaneous reactivation of assembly 3 drives the subsequent assemblies (i.e., assemblies 1 and 2). Immediately after the reactivation of assembly 3 ceased, currents onto both subsequent assemblies increased gradually, without showing significant difference (<xref rid="fig2" ref-type="fig">Fig.2e</xref>, left). This is due to the fact that state 1 and 2 are structurally symmetrical in our setting (<xref rid="fig2" ref-type="fig">Fig.2a</xref>). We then asked how reactivation of assembly 1 drives the subsequent assemblies (i.e., assemblies 2 and 3). We note that the transition probabilities in the stimulus patterns were biased towards state 3 in this case (<xref rid="fig2" ref-type="fig">Fig.2a</xref>). Consistent with this bias between transition probabilities, we found that assembly 3 was driven much strongly than assembly 2 (<xref rid="fig2" ref-type="fig">Fig.2e</xref>, right). These results suggest that the temporal statistics of the trained external sequence influence the strength of synaptic currents that drive each assembly. We then quantified the similarity between the transition statistics of stimulus patterns and that of the replayed assemblies. We defined the transition probabilities between assemblies by simply counting the occurrence of switching events over all possible pairs of assemblies (Methods). Comparison between transition probabilities of stimulus patterns and that of the reactivated assemblies revealed a clear alignment of temporal statistics (<xref rid="fig2" ref-type="fig">Fig.2f</xref>). Interestingly, even when the network was trained with input states of half the duration, the distributions of the durations of assembly reactivations remain almost identical to those in the original case (Supplementary Fig. 3a). Furthermore, the transition probabilities in the replay were still consistent with the true transition probabilities (Supplementary Fig. 3b).</p>
<p>We then asked how robust our model is to different stimulus settings and parameters. To this end, we first asked whether varying the size of the cell assemblies would affect learning. We ran simulations with two different configurations (in the task shown in <xref rid="fig2" ref-type="fig">Figure 2</xref>). The first configuration used three assemblies with a size ratio of 1:1.5:2. After training, these assemblies exhibited transition statistics that closely matched those of the evoked activity (Supplementary Fig. 4a). In contrast, the second configuration, which used a size ratio of 1:2:3, showed worse performance compared to the 1:1.5:2 case (Supplementary Fig. 4b). These results suggest that the model can learn appropriate transition statistics as long as the size ratio of the assemblies is not drastically varied. We next asked whether the speed of plasticity, controlled by the learning rate, would affect model performance. To see this, we trained the network model in two cases, one with a fast plasticity and one with a slow plasticity. We found that the two models still showed spontaneous assembly replay whose statistics clearly matched those of the evoked dynamics (Supplementary Fig. 5b,d). Interestingly, however, we found that the duration of assembly became longer in the slow learning case than in the fast case (Supplementary Fig. 5a,c). Finally, we found that the weaker background input causes spontaneous activity with a lower replay rate, which in turn leads to a high variance of the encoded transition (Supplementary Fig. 6a,b), while stronger inputs make the assembly replay transitions more uniform (Supplementary Fig. 6c,d).</p>
<p>We then tested whether learning performance would be affected by setting the ratio of excitatory to inhibitory neurons to 80% and 20% (Supplementary Figure 7a; left). Even in such a scenario, the network still showed structured spontaneous activity (Supplementary Figure 7a; center), with transition statistics of replayed events matching the true transition probabilities (Supplementary Figure 7a; right). We then asked whether the model with our plasticity rule applied to all synapses would reproduce the corresponding stochastic transitions. We found the network could replay the appropriate transition only under some conditions (Supplementary Fig. 7b). The replay failed when the inhibitory neurons were no longer driven by the synaptic currents reflecting the stimulus, due to a tight balance of excitatory and inhibitory currents on the inhibitory neurons. We found similarly that when each stimulus pattern activates a non-overlapping subset of neurons, the network does not exhibit the correct stochastic transition of assembly reactivation (Supplementary Fig. 7c). Interestingly, when the activity of each neuron is triggered by multiple stimuli and has mixed selectivity, the reactivation reproduced the appropriate stochastic transitions (Supplementary Fig. 7d).</p>
<p>In summary, the plasticity rules in our model learn the transition statistics of evoked patterns while maintaining excitation-inhibition balance. Our results show that the this prediction-based plasticity rule allows the model to learn and spontaneously replays the transition statistics of evoked patterns.</p>
</sec>
<sec id="s2b">
<title>Learned excitatory synapses encode transition statistics</title>
<p>To further understand the mechanism underlying the statistical similarity between the evoked patterns and spontaneous activity, we next asked how the transition statistics of stimulus patterns can influence network wiring. Over the course of training, the average weights of connections in each of the 3 cell assemblies increased gradually and converged to a strong value (<xref rid="fig3" ref-type="fig">Fig.3a</xref> middle and <xref rid="fig3" ref-type="fig">Fig.3b</xref>, top), indicating the formation of assemblies. On the other hand, we found that the average weights between each pair of assemblies decreased and settled at different stationary values (<xref rid="fig3" ref-type="fig">Fig.3a</xref>, right and <xref rid="fig3" ref-type="fig">Fig.3b</xref>, bottom). After training, we reasoned that the transition probabilities between states should be encoded exclusively via between-assembly connections, as none of the states in the Markovian chain have self-transitions. To test this prediction, we first compared the average between-assembly connection matrix (<xref rid="fig3" ref-type="fig">Fig.3a</xref>, right) and the ground truth transition aligned well to the ground truth probabilities (<xref rid="fig3" ref-type="fig">Fig.3d</xref>). These results indicate that the network learns the temporal statistics of sequences by modifying the structure of inter-assembly excitatory connections.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Learned excitatory synapses encode transition statistics. (a) A 3 by 3 matrix of excitatory connections, learned with the task in <xref rid="fig2" ref-type="fig">Fig.2a</xref> (left). The matrix can be decomposed to within-(middle) and between-assembly connections (right). (b) Strength of within-(top) and that of between-assembly excitatory synapses (bottom) during learning are shown. (c) True transition matrix of stimulus patterns. (d) Relationship between the strength of excitatory synapses between assemblies and true transition probabilities between patterns.</p></caption>
<graphic xlink:href="538909v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The above analysis of excitatory weights revealed its crucial role in learning transition probabilities. Next, we examined the role of inhibitory plasticity in our model’s function. To do so, we first simulated the network with fixed inhibitory weights performing the same task shown in <xref rid="fig2" ref-type="fig">Figure 2</xref>. We found that such a model exhibited spontaneous activity with blurred assembly structures compared to the original model (Supplementary Fig.8a). Furthermore, the transition probabilities between replayed assemblies in this case did not show clear alignment with true transition (Supplementary Fig. 8b), though the excitatory weights reached values which did encode transitions (Supplementary Fig. 8c, d). These results suggest that maintenance of EI balance through inhibitory plasticity is necessary for generating structured spontaneous activity, even if excitatory connections learn transition probabilities.</p>
</sec>
<sec id="s2c">
<title>Network can adapt fast to task switching</title>
<p>In the above results, transitions between stimulus patterns obeyed fixed transition probabilities. We then wondered how the network learning would be affected if transition structures of stimulus patterns changed over time. To test such a scenario, we considered a case where the transition matrix in a Markovian chain switches between the first half and the second half of the learning phase (Supplementary Fig. 9a). We will refer these matrices as task1- and task2-matrix, respectively, and examine whether switching of transition matrixes influences the connectivity. During the first half of learning phase, between-assembly connections converged to certain values to encode task1-matrix (Supplementary Fig. 9b, bottom, 0-500 seconds). However, such stable connectivity reorganized quickly once the imposed task was switched to task2-matrix (Supplementary Fig. 9b, bottom, 500-1,000 seconds). Note that in contrast to between-assemblies connections, within-assembly connections did not show such reorganization (Supplementary Fig. 9b, top). These results indicate that our model adapted to the second task even if distinct assembly structures were already formed during the first task.</p>
<p>To further understand how the model adapts to the new task, we next asked how error terms in excitatory and inhibitory plasticity (Eqs.11 and 13) change through learning. As expected, the low-pass filtered errors PE<sup>exc</sup> and PE<sup>inh</sup> decreased as the network trained on task1 (Supplementary Fig.9c, 0-500 seconds). However, once the task was switched, errors showed an abrupt increase followed by a gradual decrease as the network learned the second task (Supplementary Fig.9c, 500-1,000 seconds; Supplementary Fig.9d). Consistent with the previous result (<xref rid="fig2" ref-type="fig">Figure 2b</xref>), the peak of inhibitory error occurred delayed after that of excitatory one in each task (D’amour JA and Froemke, 2015; <xref ref-type="bibr" rid="c53">Vogels et al., 2011</xref>) (Supplementary Fig. 9d). In summary, our model is also capable of task switching, via the reorganization of its weight structures through continuing plasticity.</p>
</sec>
<sec id="s2d">
<title>The network can learn complex stochastic sequences</title>
<p>So far, we have considered the capabilities of our model in regard to the relatively simple class of stochastic dynamics. In particular, the task we considered above contains only three states, and the transition structure was symmetric. In a realistic sequence, like the song of a bird, transition statistics are typically heterogeneous and more structured. To evaluate the model performance over a wide variety of structures, we now consider a transition diagram with more complex structure (<xref rid="fig4" ref-type="fig">Fig.4a</xref>). Despite its complex structure, the learned network showed spontaneous reactivations of all assemblies evoked during learning (<xref rid="fig4" ref-type="fig">Fig.4b</xref>), and the transition dynamics between these assemblies were governed by learned transition probabilities (<xref rid="fig4" ref-type="fig">Fig.4c</xref>). Indeed, the learned weight structures were consistent with the transition probabilities between states as we have seen in simpler task (Supplementary Fig.10).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Learning complex structures. (a) Transition diagram of complex task. (b) Spontaneous activity of learned network. (c) Transition statistics of assemblies reproduce true statistics. (d) Transition diagram of temporal community structure. (e) Raster plot of spontaneous activity of the network trained over structure shown in (d). (f) Structure of learned excitatory synapses encode the community structure. (g) Spontaneous transition between assemblies connected in the diagram shown in d occurs much frequent than disconnected case. (h) Low dimensional representation of evoked activity patterns shows high similarity with community structure. (i) Time courses of replayed activities transitioning within (red) and between (blue) communities. (j) Comparison of mean durations in (i). P-value was calculated by two-sided Welch’s t-test.</p></caption>
<graphic xlink:href="538909v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Recent experimental studies which examined temporal community structure (i.e., highly structured graph structure consisting of clusters of densely interconnected nodes; <xref rid="fig4" ref-type="fig">Fig.4d</xref>) found that human subjects tend to associate a given visual stimulus with other stimuli within the same “community” (<xref ref-type="bibr" rid="c46">Schapiro et al., 2013</xref>; <xref ref-type="bibr" rid="c45">Pudhiyidath et al., 2022</xref>). To investigate whether the model can learn to associate states within a stimulated community, we first trained the network with a stochastic sequence of inputs, generated by a random walk over graph with temporal community structure (<xref rid="fig4" ref-type="fig">Fig.4d</xref>). The learned model showed stochastic assembly transition during spontaneous activity (<xref rid="fig4" ref-type="fig">Fig.4e</xref>) relying on the appropriate weight structure (<xref rid="fig4" ref-type="fig">Fig.4f</xref>). Although transition occurred between all pairs of assemblies, transitions between connected states in the diagram occurred much frequently than transitions between disconnected states (<xref rid="fig4" ref-type="fig">Fig.4g</xref>). This is because plasticity formed strong excitatory connections between assemblies with nonzero transition probabilities, as shown in <xref rid="fig4" ref-type="fig">Figure 4f</xref>.</p>
<p>In human participants, low-dimensional representations of evoked activities in different cortical regions have been reported to show clusters consistent with the structure of communities (<xref ref-type="bibr" rid="c46">Schapiro et al., 2013</xref>). To test whether our model could reproduce such representation of communities, we analyzed the low-dimensional representation of evoked activities in our model by applying principal component analysis (PCA) (see Methods). Such analysis revealed that the representation of stimulus patterns were grouped together into clusters or communities of mutually predictive stimuli, consistent with the experimental results (<xref rid="fig4" ref-type="fig">Fig.4h</xref>). We found that the clustered representations still exist even if the input sequences were scrambled after learning (Supplementary Fig.11), indicating that this result does not rely on the stimulus protocol, but instead on the learned weights.</p>
<p>We further asked whether within- and between-community reactivations showed any differences in terms of their behavior. To this end, we perturbed an assembly corresponding to non-boundary states in the first community (states 2-4 in the transition diagram shown in <xref rid="fig4" ref-type="fig">Fig.4d</xref>) and monitored the behavior of subsequent autonomous network activities. According to the above results, we expect that within-community reactivations should occur quicker than between-community assemblies, due to strong within-community coupling. To test this hypothesis, we calculated the duration from the end of the perturbation until subsequent activity reached a certain threshold (<xref rid="fig4" ref-type="fig">Fig.4i</xref>). As expected, the transition to within-community states showed much shorter durations than to between-community case (<xref rid="fig4" ref-type="fig">Fig.4j</xref>), indicating that between-community transition occurred with much slower time scale compared to within-community case. Together, these results indicate that our network can learn complex temporal structures in spontaneous activity and reproduce the neural representation of the temporal community structure observed in the experiment.</p>
</sec>
<sec id="s2e">
<title>Network dynamics consistent with recorded neural data of songbird</title>
<p>Finally, we tested whether the spontaneous activity in our model resembles recorded neural activity of HVC in Bengalese finch (Bf). Bf learns songs composed of multiple stereotyped short sequences, or syllables. The transitions between these syllables can be described via Markovian process with varying levels of certainty. Intuitively, given one syllable in a bird song, precise prediction about the neural response to the next syllable can be made if the transition from that syllable is highly certain, while imprecise transitions will lead to imprecise predictions about the neural response. Indeed, recent experimental study reported that uncertainty of upcoming syllables in a Bf song modulates the degree of predictability of subsequent neural activation (poststimulus activity; PSA) in HVC (<xref ref-type="bibr" rid="c12">Bouchard and Brainard, 2016</xref>). We sought to test whether our model would exhibit a similar property. To this end, we analyzed the behavior of a network model that had already learned the task (shown in <xref rid="fig4" ref-type="fig">Figure 4a</xref>). The transition structure we chose is relatively simple compared to the real song of a Bf, yet captures measured features of bird songs (i.e., both structures consist of highly certain and lesscertain transitions). In the experiment, similarities were calculated between the trial-averaged PSA following a short sequence of stimuli, and the response to an isolated stimulus. To mimic this experimental design, we measured stimulus-triggered averages of our autonomous network activity as a proxy for PSA (<xref rid="fig5" ref-type="fig">Fig.5a</xref>). To examine how uncertainty of state transitions in a sequence influence predictive strength in network activity, we first calculated the Pearson correlation coefficient between PSA and responses to next states in a sequence. We will refer to such correlations as “next-state correlations”. Note that if there were multiple next-states from a given state, all correlations corresponding to that state were averaged. We further calculated the correlation between PSA and responses to other states that did not follow the given state (“other-state correlations”). Similar to the next-state correlations, other-state correlations were averaged over all disconnected states from each state. We then compared next-state correlations and other-state correlations between highly certain (<xref rid="fig5" ref-type="fig">Fig.5b</xref>, left) and less-certain (<xref rid="fig5" ref-type="fig">Fig.5b</xref>, right) transitions. Here, highly certain transitions refer to those which have a transition probability greater than 1/2. Other transitions were classified as less-certain transitions. Consistent with experimental results, next-state correlations were significantly greater than other-state correlations in the highly certain case (<xref rid="fig5" ref-type="fig">Fig.5b</xref>, left). This correlation difference was less significant in less-certain case (<xref rid="fig5" ref-type="fig">Fig.5b</xref>, right). These results indicate that transition uncertainty modulated the degree to which PSA is predictive of upcoming states.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><p>Network dynamics consistent with recorded neural data of songbird (a) Example post-stimulus activity (PSA) for low-(left) and high-entropy (right) transition cases. (b) Comparison of correlation coefficients between PSA and evoked single-syllable responses for next syllables and other syllables. For low entropy transition case, the next-syllables correlations were significantly higher than other-syllables correlations (p &lt; 0.01, Wilcoxon signed-rank test) (left). In contrast, such correlation coefficients showed no significant difference for high entropy transition case (p &gt; 0.3, Wilcoxon signed-rank test) (right). Red crosses are mean. (c) The difference in correlation coefficients between next and other syllables (ΔR) was significantly greater for low entropy transitions than for high entropy transitions (p &lt; 0.01, two-sided Welch’ s t-test).</p></caption>
<graphic xlink:href="538909v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We performed a more direct comparison of predictive strength by measuring the difference between two types of correlations (i.e., next- and other-state correlations) over multiple levels of transition uncertainty. Here, for each state, next-state correlation was subtracted by other-state correlation. Transition uncertainties were quantified by calculating the conditional entropy of transition probabilities of stimulus patterns. Note that a higher value of entropy indicates less-certain transition, and vice versa. As expected, correlation differences increased as entropy decreased (<xref rid="fig5" ref-type="fig">Fig.5c</xref>), indicating that the predictive strength of network PSA was larger for low-entropy transitions (i.e., highly certain transitions) than for high-entropy transitions (i.e., less-certain transitions). What is the underlying mechanism of such predictability differences? Although each trial of assembly perturbation lead to subsequent reactivation of one of the assemblies, trial-averaged activities (i.e., PSAs) marginalized all possible transitions in the transition diagram (<xref rid="fig5" ref-type="fig">Fig.5a</xref>). Due to this averaging process, similarities between PSA and stimulus-evoked activities increases if conditional entropy is low (i.e., certain transition), and vice versa. Overall, our results suggest that our model learns transition statistics of stimulus patterns, with transition uncertainty influencing predictive strength in the network activity.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Understanding how the brain learns internal models of the environment is a challenging problem in neuroscience. In this study, we proposed synaptic plasticity rules for learning assembly transitions via sensory experiences. Our excitatory plasticity aims at minimizing the error between sensory-evoked and internally generated predictions of upcoming activity. We showed that the network learns the appropriate wiring patterns to encode the transition structure of states, and thus exhibits stochastic transitions between assemblies in spontaneous activity. We further showed that appropriate replay of stochastic transitions requires both excitatory and inhibitory plasticity. These plasticity rules showed a clear division of labor. For excitatory synapses, the connectivity learns transition probabilities during the evoked phase, and inhibitory plasticity seeks to maintain the excitatoryinhibitory balance. We showed that network excitatory plasticity alone cannot account for stochastic replay of learned activity, even if excitatory synapses learn an appropriate structure. Future experimental studies could examine our model’s predictions by testing how blocking synaptic plasticity specifically in excitatory or inhibitory neuron populations distinctly impacts the transition statistics in spontaneous replay events.</p>
<p>Variants of the Hebbian plasticity rule have been widely used to learn the precise order of sequential reactivations. For example, a rate-based Hebbian rule has been proposed to generate trajectories along a chain of metastable attractors, each corresponding to a reactivation of a single network state (<xref ref-type="bibr" rid="c19">Fonollosa et al., 2015</xref>). Another proposed mechanism is that the transitions are governed by theta oscillations, which form a temporal backbone of the sequential reactivation of assemblies (<xref ref-type="bibr" rid="c14">Chadwick et al., 2015</xref>). Despite the successes of these Hebbian rules in learning precise order in sequences, plasticity rules that learn structured transition probabilities and replay them in spontaneous activity were still unknown.</p>
<p>How does our plasticity mechanism differ from the Hebbian rule? In the Hebbian rule, synaptic strength is potentiated as long as pre- and postsynaptic neurons show correlated activities. Due to this nature of the Hebbian rule, after sufficient potentiation, synapses reach a predefined upper limit, making the strength uniform among strong synapses (<xref ref-type="bibr" rid="c33">Kempter et al., 1999</xref>; <xref ref-type="bibr" rid="c49">Song et al., 2000</xref>; <xref ref-type="bibr" rid="c40">Masquelier et al., 2008</xref>). Such connectivity is useful when the network learns deterministic sequences, but it alone is insufficient to learn transition probabilities. In contrast, our proposed model aims at predicting the evoked activities by internally generated dynamics, so that learning ceases when the prediction error is sufficiently minimized. A similar plasticity rule has been proposed to minimize the discrepancy between stimulus-evoked and internally predicted activity, generating a stable synaptic distribution that allows pattern completion and unsupervised feature detection from noisy sensory input. (<xref ref-type="bibr" rid="c50">Tavazoie 2013</xref>). These mechanisms result in learned synaptic distributions that are not uniform as observed in STDP, but rather converge to values proportional to the transition probabilities between assemblies (as shown in <xref rid="fig3" ref-type="fig">Figure 3b</xref>).</p>
<p>Our proposed plasticity mechanism could be implemented through somatodendritic interactions. Analogous to previous computational works (<xref ref-type="bibr" rid="c52">Urbanczik and Senn., 2014</xref>; <xref ref-type="bibr" rid="c3">Asabuki and Fukai., 2020</xref>; <xref ref-type="bibr" rid="c4">Asabuki et al., 2022</xref>), our model suggests that somatic responses may encode the stimulus-evoked neural activity states, while dendrites encode predictions based on recurrent dynamics that aim to minimize the discrepancy between somatic and dendritic activity. To directly test this hypothesis, future experimental studies could simultaneously record from both somatic and dendritic compartments to investigate how they encode evoked responses and predictive signals during learning (<xref rid="c20" ref-type="bibr">Francioni et al., 2022</xref>).</p>
<p>The proposed mechanism of learning stochastic transitions between cell assemblies may offer several advantages over deterministic transitions, as suggested by previous studies. One possibility is that the internal dynamics of stochastic transitions can be used as prior knowledge about the structure of the world. In particular, the learned information about the transition statistics can be used to make probabilistic predictions about upcoming sensory events. It may also provide a flexible representation of the environment. In a deterministic case, assemblies are replayed in a fixed temporal order, which may make the network susceptible to noise or unexpected changes in the environment. In contrast, stochastic transitions may allow the network to generate rich repertoires of representations that could provide flexible computation against an uncertain environment.</p>
<p>In reinforcement learning (RL), balancing the tradeoff between exploration and exploitation to maximize a long-term reward signal is one of the most challenging problems. While both exploration and exploitation phases are crucial in RL, exploration is often much more difficult. This difficulty arises from the fact that exploration is especially important when the agent does not have an optimal policy. One way in which the agent might bypass or speed up this exploration phase is through prior knowledge of the environment’s transition statistics. Furthermore, learning transition statistics as an internal model may be beneficial when an agent solves a task in an environment where the reward distribution is sparse. Having an internal model of the transition statistics may allow an agent to predict the expected value of the future reward for taking a particular action in a given state. However, the relationship between the reward-based plasticity rule and our proposed rule still needs further study.</p>
<p>Several computational models have demonstrated that Hebbian-like plasticity rule can learn appropriate Markovian statistics (Kappel et al., 2014; <xref ref-type="bibr" rid="c8">Barber 2002</xref>; <xref ref-type="bibr" rid="c7">Barber and Agakov 2002</xref>). However, our model differs conceptually from these previous models in some respects. While Kappel et al. demonstrated that STDP in winner-take-all circuits can approximate online learning of hidden Markov models (HMMs), a key distinction from our model is that their neural representations acquire deterministic sequential activations, rather than exhibiting stochastic transitions governing Markovian dynamics. Specifically, in their model, the neural representation of state B would be different in the sequences ABC and CBA, resulting in distinct deterministic representations like ABC and C’B’A’, where ‘A’ and ‘A’’ are represented by different neural states (e.g., activations of different cell assemblies). In contrast, our network learns to generate stochastically transitioning cell assemblies that replay Markovian trajectories of spontaneous activity obeying the learned transition probabilities between neural representations of states. For example, starting from reactivation from assembly ‘A’, there may be an 80% probability to transition to assembly ‘B’ and 20% to ‘C’. Although Kappel et al.’s model successfully solves HMMs, their neural representations do not themselves stochastically transition between states according to the learned model. Similar to the Kappel et al.’s model, while the models proposed in <xref ref-type="bibr" rid="c8">Barber (2002)</xref> and <xref ref-type="bibr" rid="c7">Barber and Agakov (2002)</xref> learn the Markovian statistics, these models learned a static spatiotemporal input patterns only and how assemblies of neurons show stochastic transition in spontaneous activity has been still unclear. In contrast with these models, our model captures the probabilistic neural state trajectories, allowing spontaneous replay of experienced sequences with stochastic dynamics matching the learned environmental statistics.</p>
<p>Our model results were also compared to experimental results of sequence predictability in a songbird. Recent experiments have shown that the predictive uncertainty of the upcoming stimulus modulates the degree of similarity between stimulus-evoked and post-stimulus autonomous activity in the HVC of the Bengal finch (<xref ref-type="bibr" rid="c12">Bouchard and Brainard, 2016</xref>). However, the underlying mechanism is still unknown. Here, we have shown that a stochastic state transition in spontaneous activity can explain such a dependence of activity similarity on stimulus uncertainty. Our model predicts that the PSA reflects a trial average of stochastic transitions of evoked activity from a given stimulus. Trial-averaged neural activity washes out the variability of all possible realizations of the stochastic transition. Thus, PSA of an uncertain stimulus results in a combination of multiple transitions, leading to activity less similar than that evoked by a single stimulus. Several studies have shown that Hidden Markov Models or other statistical methods could account for the transition statistics in bird song (<xref ref-type="bibr" rid="c34">Kogan and Margoliash, 1998</xref>; <xref ref-type="bibr" rid="c31">Katahira et al., 2011</xref>). However, our study suggests that trial averaging operations can influence the degree of similarity between stimulus-evoked and post-stimulus activity.</p>
<p>Although we have shown that the proposed model can learn Markovian transitions, several studies suggest that animals often exhibit behaviors with non-Markovian or hierarchical statistics (<xref ref-type="bibr" rid="c47">Seeds et al., 2014</xref>; <xref ref-type="bibr" rid="c11">Berman et al., 2016</xref>; <xref ref-type="bibr" rid="c29">Jovanic et al., 2016</xref>; <xref ref-type="bibr" rid="c28">Jin and Costa, 2015</xref>; <xref ref-type="bibr" rid="c25">Geddes et al., 2018</xref>; <xref ref-type="bibr" rid="c39">Markowitz et al., 2018</xref>; <xref ref-type="bibr" rid="c32">Kato et al., 2015</xref>; <xref ref-type="bibr" rid="c30">Kaplan et al., 2020</xref>). In principle, our learning rule cannot be applied to learning non-Markovian transitions, since it only learns local transitions between states (<xref ref-type="bibr" rid="c13">Brea et al., 2013</xref>). Therefore, to learn higher-order stochastic transitions, recurrent neural networks like ours may need to integrate higher-order inputs with longer time scales. Another limitation of our model is that it cannot learn transition statistics if the states are separated in time. Both of these problems could be solved by considering working memory (WM) (<xref ref-type="bibr" rid="c5">Baddeley, 1992</xref>; <xref ref-type="bibr" rid="c42">Miller and Cohen, 2001</xref>) in an activity-dependent (<xref ref-type="bibr" rid="c22">Funahashi et al., 1989</xref>; <xref ref-type="bibr" rid="c26">Goldman-Rakic, 1995</xref>; <xref ref-type="bibr" rid="c23">Fuster and Alexander, 1971</xref>; <xref ref-type="bibr" rid="c1">Amit and Brunel, 1997</xref>) or activity-silent manner (<xref ref-type="bibr" rid="c43">Mongillo et al., 2008</xref>; <xref ref-type="bibr" rid="c6">Barak and Tsodyks, 2014</xref>; <xref ref-type="bibr" rid="c58">Zucker and Regehr, 2002</xref>; <xref ref-type="bibr" rid="c18">Erickson et al., 2010</xref>). Clarifying the relationship between the proposed prediction-based plasticity rule and plasticity rules that support memory traces, such as short-term plasticity, will warrant future computational studies.</p>
<p>Our work sheds light on the learning mechanism of the brain’s internal model, which is a crucial step towards a better understanding of the role of spontaneous activity as an internal generative model of stochastic processes in complex environments.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<p>The source codes used in this study are available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/TAsabuki/stochastic_transition">https://github.com/TAsabuki/stochastic_transition</ext-link></p>
<sec id="s4a">
<title>Neural network model</title>
<p>Our recurrent neural networks consist of <italic>N</italic><sub><italic>E</italic></sub> excitatory and <italic>N</italic><sub><italic>I</italic></sub> inhibitory neurons. During learning, the membrane potentials of neuron at time <italic>t</italic> with external current <inline-formula><inline-graphic xlink:href="538909v2_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> were calculated as follows:
<disp-formula id="eqn1">
<graphic xlink:href="538909v2_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn2">
<graphic xlink:href="538909v2_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>where <inline-formula><inline-graphic xlink:href="538909v2_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="538909v2_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> are the membrane potential of <italic>i</italic>-th excitatory and inhibitory neuron, respectively (see <xref rid="tbl1" ref-type="table">Table 1</xref> for the list of variables and functions). The strength of external input <inline-formula><inline-graphic xlink:href="538909v2_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula> takes the value 1 if stimulus pattern targets neuron <italic>i</italic> was presented and 0 otherwise. This structured external input was replaced to constant inputs <inline-formula><inline-graphic xlink:href="538909v2_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula> of value 0.3 during spontaneous activity. We will describe the details of stimulus patterns later. <inline-formula><inline-graphic xlink:href="538909v2_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a recurrent connection weight from <italic>j</italic>-th neuron in population <italic>b</italic> to <italic>i</italic>-th neuron in population <italic>a</italic>. All neurons were connected with a coupling probability of <italic>p</italic> =0.5. Initial value of synaptic weights <inline-formula><inline-graphic xlink:href="538909v2_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula> were uniformly set to <inline-formula><inline-graphic xlink:href="538909v2_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula> if <italic>a</italic> = <italic>E</italic> and <inline-formula><inline-graphic xlink:href="538909v2_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula> if <italic>a</italic> = <italic>I</italic>. <inline-formula><inline-graphic xlink:href="538909v2_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a postsynaptic potential evoked by <italic>i</italic>-th neuron in population <italic>a</italic>, which will be described later.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Definition of variables and functions.</title></caption>
<graphic xlink:href="538909v2_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>Spiking of each neuron model in population <italic>E</italic> was modeled as an inhomogeneous Poisson process with instantaneous firing rate <inline-formula><inline-graphic xlink:href="538909v2_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula> with a dynamic sigmoidal response function <italic>φ</italic> with parameters of slope <italic>β</italic> and threshold <italic>θ</italic> as:
<disp-formula id="eqn3">
<graphic xlink:href="538909v2_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>φ</italic><sub>0</sub> is the maximum instantaneous firing rate of 50 Hz and <italic>g</italic> = 2. The slope <italic>β</italic> and threshold <italic>θ</italic> of sigmoidal function of population <italic>E</italic> was regulated by the memory trace <italic>h</italic><sub><italic>i</italic></sub> as:
<disp-formula id="eqn4">
<graphic xlink:href="538909v2_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn5">
<graphic xlink:href="538909v2_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the values of constant parameters are <italic>β</italic><sub>0</sub> = 5 and <italic>θ</italic><sub>0</sub> =1. The memory trace tracks the maximum value of the short history of membrane potential <inline-formula><inline-graphic xlink:href="538909v2_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula> as
<disp-formula id="eqn6">
<graphic xlink:href="538909v2_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>τ</italic><sub><italic>h</italic></sub> = 10 s is a time scale of memory trace. In the previous study (Asabuki and Fukai, 2023), such dynamic response function was introduced to prevent trivial solutions during the learning of recurrent and feedforward connections. In the current model, we assumed that each stimulus presentation drives a specific subset of network neurons with a fixed input strength, which avoids convergence to trivial solutions. Nevertheless, the dynamic sigmoid function could facilitate stable replay by regulating neuron activity to prevent saturation.</p>
<p>Inhibitory neurons’ firing rate were assumed to be calculated with static sigmoidal function as:
<disp-formula id="eqn7">
<graphic xlink:href="538909v2_eqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Where the maximum instantaneous firing rate <italic>φ</italic><sub>0</sub> was assumed to be same with that of excitatory neurons (i.e., 50 Hz). The parameters <italic>β</italic><sub>0</sub> and <italic>θ</italic><sub>0</sub> are the constant values already appeared in Eqs. (4) and (5).</p>
<p>Neuron <italic>i</italic> in population <italic>a</italic> generates a Poisson spike train at the instantaneous firing rate of <inline-formula><inline-graphic xlink:href="538909v2_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Let us describe the generated Poisson spike trains as:
<disp-formula id="eqn8">
<graphic xlink:href="538909v2_eqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>δ</italic> is the Dirac’s delta function and <inline-formula><inline-graphic xlink:href="538909v2_inline14.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the set of time of the spikes of the neuron. The postsynaptic potential evoked by the neuron (i.e., <inline-formula><inline-graphic xlink:href="538909v2_inline15.gif" mime-subtype="gif" mimetype="image"/></inline-formula>) was then calculated as:
<disp-formula id="eqn9">
<graphic xlink:href="538909v2_eqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn10">
<graphic xlink:href="538909v2_eqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>τ</italic><sub><italic>s</italic></sub> = 5ms, <italic>τ</italic> = 15 ms, and <italic>x</italic><sub>0</sub> = 25.</p>
</sec>
<sec id="s4b">
<title>The learning rules</title>
<p>All excitatory synaptic connections onto excitatory neurons were modified to minimize the following cost function:
<disp-formula id="eqn11">
<graphic xlink:href="538909v2_eqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="538909v2_inline16.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a recurrent prediction of a firing rate, defined as:
<disp-formula id="eqn12">
<graphic xlink:href="538909v2_eqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the function <inline-formula><inline-graphic xlink:href="538909v2_inline17.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the static sigmoid function defined in Eq.7. The above cost function evaluates to what extent the recurrent potential predicts the activity of postsynaptic neurons. Taking the gradient of the cost function in Eq.11, we derived the plasticity rule for the excitatory plasticity as :
<disp-formula id="eqn13">
<graphic xlink:href="538909v2_eqn13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>While the term the term <inline-formula><inline-graphic xlink:href="538909v2_inline18.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which arose from the derivative of <inline-formula><inline-graphic xlink:href="538909v2_inline19.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, avoids saturation of neural activity, we show numerically this can be ruled out in the learning rule. Hence, the resultant plasticity rule for the excitatory synapses can be written as:
<disp-formula id="eqn14">
<graphic xlink:href="538909v2_eqn14.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>ϵ</italic> is a learning rateand was set to <italic>ϵ</italic> = 10<sup>−4</sup>, unless otherwise specified.</p>
<p>We note that for Poisson spiking neurons, the derived learning rule is equivalent to the one that minimizes the Kullback-Leibler divergence between the distributions of output firing and the dendritic prediction, in our case, the recurrent prediction (Asabuki and Fukai; 2020). Thus, the rule suggests that the recurrent prediction learns the statistical model of the evoked activity, which in turn allows the network to reproduce the learned transition statistics.</p>
<p>Similarly, we defined the cost function for the inhibitory plasticity as:
<disp-formula id="eqn15">
<graphic xlink:href="538909v2_eqn15.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="538909v2_inline20.gif" mime-subtype="gif" mimetype="image"/></inline-formula> was the total inhibitory input onto postsynaptic neuron:
<disp-formula id="eqn16">
<graphic xlink:href="538909v2_eqn16.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Again, by taking the gradient with respect to <inline-formula><inline-graphic xlink:href="538909v2_inline21.gif" mime-subtype="gif" mimetype="image"/></inline-formula> derive the following inhibitory plasticity rule to maintain excitatory-inhibitory balance in all excitatory neurons:
<disp-formula id="eqn17">
<graphic xlink:href="538909v2_eqn17.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>In all simulations in this paper, we dropped the term <inline-formula><inline-graphic xlink:href="538909v2_inline22.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and modified the inhibitory synapses according to the following rule:
<disp-formula id="eqn18">
<graphic xlink:href="538909v2_eqn18.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s4c">
<title>Simulation details</title>
<p>The parameters used in the simulations are summarized in <xref rid="tbl2" ref-type="table">Table 2</xref>. All simulations were performed in customized Python3 code written by TA with numpy 1.17.3 and scipy 0.18. Differential equations were numerically integrated using a Euler method with integration time steps of 1 ms.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title>Parameter settings.</title></caption>
<graphic xlink:href="538909v2_tbl2.tif" mime-subtype="tiff" mimetype="image"/>
<graphic xlink:href="538909v2_tbl2a.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s4d">
<title>Stimulation protocols</title>
<p>In all simulations, each stimulus patterns had a duration of 200 ms and were presented without inter-pattern interval. We assumed each neuron in a network was stimulated by one of stimulus patterns and targeted assemblies were not overlapped. Presentation of each pattern triggers excitatory current to its targeted neurons of strength 1 and zero otherwise. During spontaneous activity, stimulus patterns were replaced with constant background input <inline-formula><inline-graphic xlink:href="538909v2_inline23.gif" mime-subtype="gif" mimetype="image"/></inline-formula> for all excitatory neurons. In <xref rid="fig5" ref-type="fig">Figure 5</xref>, we assumed all excitatory neurons receive both structured and constant background inputs over whole period.</p>
</sec>
<sec id="s4e">
<title>Calculation of transition probabilities in spontaneous activity</title>
<p>In <xref rid="fig2" ref-type="fig">Figs. 2f</xref>, <xref rid="fig4" ref-type="fig">4c</xref>, and <xref rid="fig4" ref-type="fig">4g</xref>, we first calculated the population average of the instantaneous firing rates of all neurons in each assembly, during spontaneous activity. We will term such activities as assembly activities. We then defined the assembly reactivations by events that the assembly activities exceeded the threshold of which the value 50% of maximum value of each assembly activities. Transition probabilities between assemblies across all possible pairs were then calculated by counting the occurrences of reactivation of the subsequent assembly within 100 ms of the end time of reactivation of the preceding assembly. In <xref rid="fig2" ref-type="fig">Fig. 2d</xref>, durations of each assembly reactivation event were defined as a period during each assembly activation exceeded threshold.</p>
</sec>
<sec id="s4f">
<title>Calculation of weight changes</title>
<p>In <xref rid="fig2" ref-type="fig">Fig.2b</xref>, the weight changes were calculated every 2 s for excitatory and inhibitory synapses as:
<disp-formula id="eqn19">
<graphic xlink:href="538909v2_eqn19.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn20">
<graphic xlink:href="538909v2_eqn20.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="538909v2_inline24.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a synapse at time <italic>t</italic> and <italic>dt</italic> is a simulation time step of 1 ms.</p>
</sec>
<sec id="s4g">
<title>Calculation of error dynamics in task switching</title>
<p>In Supplementary Figures 3c and 3d, two types of prediction errors for excitatory and inhibitory plasticity were calculated as follows. First, we obtained the lowpass filtered errors <inline-formula><inline-graphic xlink:href="538909v2_inline25.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="538909v2_inline26.gif" mime-subtype="gif" mimetype="image"/></inline-formula> calculated by instantaneous error values in the plasticity rules (i.e., <xref ref-type="disp-formula" rid="eqn14">Eqs. 14</xref> and 18) as:
<disp-formula id="eqn21">
<graphic xlink:href="538909v2_eqn21.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn22">
<graphic xlink:href="538909v2_eqn22.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>τ</italic><sub>avg</sub> = 30 s is a time constant for low-pass filter and <italic>i</italic> is a neuron index. We then calculated the averaged errors PE<sup>exc</sup> and PE<sup>inh</sup> as:
<disp-formula id="eqn23">
<graphic xlink:href="538909v2_eqn23.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn24">
<graphic xlink:href="538909v2_eqn24.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where |·| is an absolute value.</p>
</sec>
<sec id="s4h">
<title>Analysis of the low-dimensional representation in network</title>
<p>In <xref rid="fig4" ref-type="fig">Fig.4h</xref>, we first obtained matrix of network responses <italic>U</italic> = (<bold><italic>r</italic></bold><sub>1</sub>, …, <bold><italic>r</italic></bold><sub>15</sub>), where <bold><italic>r</italic></bold><sub><italic>i</italic></sub> (<italic>i</italic> = 1, …, 15) is a trial-averaged response of a whole network to one of 15 stimulus patterns shown in <xref rid="fig4" ref-type="fig">Fig.4d</xref>. Trial averaging was performed over multiple presentations of each stimulus. We then applied the principal component analysis (PCA) to matrix <italic>U</italic> and visualized the low dimensional representation of multiple stimulus in the learned network.</p>
</sec>
<sec id="s4i">
<title>Correlation measure for comparison with a songbird</title>
<p>In <xref rid="fig5" ref-type="fig">Fig 5</xref>, we calculated stimulus-triggered averages of autonomous network activity to obtain poststimulus activity (PSA) of a network model. In <xref rid="fig5" ref-type="fig">Figs 5b</xref> and <xref rid="fig5" ref-type="fig">5c</xref>, correlation between PSA and evoked activity triggered by one stimulus pattern was calculated neuron-wise and then averaged over all neurons.</p>
</sec>
</sec>
</body>
<back>
<sec id="s5">
<title>Additional information</title>
<sec id="s5a">
<title>Author Contributions</title>
<p>T.A. and C.C. conceived the study and wrote the paper.</p>
<p>T.A. performed the simulations and data analyses.</p>
</sec>
<sec id="s6">
<title>Competing Interest Statement</title>
<p>The authors declare no competing interests.</p>
</sec>
</sec>
<ack>
<title>Acknowledgments</title>
<p>This work was supported by BBSRC (BB/N013956/1), Wellcome Trust (200790/Z/16/Z), the Simons Foundation (564408) and EPSRC(EP/R035806/1). The authors also thank Ian Cone for his comments on the manuscript and technical assistance.</p>
</ack>
<sec id="d1e1394" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1440">
<label>Supplementary Figure 1</label>
<media xlink:href="supplements/538909_file02.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1447">
<label>Supplementary Figure 2</label>
<media xlink:href="supplements/538909_file03.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1454">
<label>Supplementary Figure 3</label>
<media xlink:href="supplements/538909_file04.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1461">
<label>Supplementary Figure 4</label>
<media xlink:href="supplements/538909_file05.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1469">
<label>Supplementary Figure 5</label>
<media xlink:href="supplements/538909_file06.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1476">
<label>Supplementary Figure 6</label>
<media xlink:href="supplements/538909_file07.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1483">
<label>Supplementary Figure 7</label>
<media xlink:href="supplements/538909_file08.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1490">
<label>Supplementary Figure 8</label>
<media xlink:href="supplements/538909_file09.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1497">
<label>Supplementary Figure 9</label>
<media xlink:href="supplements/538909_file10.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1504">
<label>Supplementary Figure 10</label>
<media xlink:href="supplements/538909_file11.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1512">
<label>Supplementary Figure 11</label>
<media xlink:href="supplements/538909_file12.pdf"/>
</supplementary-material>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Amit</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Brunel</surname> <given-names>N.</given-names></string-name></person-group> <article-title>Model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex</article-title>. <source>Cereb Cortex</source>. <year>1997</year>;<volume>7</volume>(<issue>3</issue>):<fpage>237</fpage>–<lpage>52</lpage>. doi: <pub-id pub-id-type="doi">10.1093/cercor/7.3.237</pub-id>. PMID: <pub-id pub-id-type="pmid">9143444</pub-id>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Asabuki</surname> <given-names>T</given-names></string-name>, <string-name><surname>Fukai</surname> <given-names>T.</given-names></string-name></person-group> <article-title>Learning rules for cortical-like spontaneous replay of an internal model</article-title>. <source>bioRxiv</source> <elocation-id>2023.02.17.528958</elocation-id>; doi: <pub-id pub-id-type="doi">10.1101/2023.02.17.528958</pub-id> <year>2023</year></mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Asabuki</surname> <given-names>T</given-names></string-name>, <string-name><surname>Fukai</surname> <given-names>T.</given-names></string-name></person-group> <article-title>Somatodendritic consistency check for temporal feature segmentation</article-title>. <source>Nat Commun</source>. <year>2020</year> <month>Mar</month> 25;<volume>11</volume>(<issue>1</issue>):<fpage>1554</fpage>. doi: <pub-id pub-id-type="doi">10.1038/s41467-020-15367-w</pub-id>. PMID: <pub-id pub-id-type="pmid">32214100</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC7096495</pub-id>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Asabuki</surname> <given-names>T</given-names></string-name>, <string-name><surname>Kokate</surname> <given-names>P</given-names></string-name>, <string-name><surname>Fukai</surname> <given-names>T.</given-names></string-name></person-group> <article-title>Neural circuit mechanisms of hierarchical sequence learning tested on large-scale recording data</article-title>. <source>PLOS Computational Biology</source>. <year>2022</year>.; <volume>18</volume>(<issue>6</issue>), <fpage>e1010214</fpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baddeley</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Working memory</article-title>. <source>Science</source>. <year>1992</year> <month>Jan</month> 31;<volume>255</volume>(<issue>5044</issue>):<fpage>556</fpage>–<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1126/science.1736359</pub-id>. PMID: <pub-id pub-id-type="pmid">1736359</pub-id>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barak</surname> <given-names>O</given-names></string-name>, <string-name><surname>Tsodyks</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Working models of working memory</article-title>. <source>Curr Opin Neurobiol</source>. <year>2014</year> <month>Apr</month>;<volume>25</volume>:<fpage>20</fpage>–<lpage>4</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.conb.2013.10.008</pub-id>. Epub 2013 Dec 4. PMID: <pub-id pub-id-type="pmid">24709596</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="report"><person-group person-group-type="author"><string-name><surname>Barber</surname> <given-names>D</given-names></string-name>, <string-name><surname>Agakov</surname> <given-names>F.</given-names></string-name></person-group> <source>Correlated sequence learning in a network of spiking neurons using maximum likelihood</source>. <publisher-name>Institute for Adaptive and Neural Computation</publisher-name>. <year>2002</year>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barber</surname> <given-names>D.</given-names></string-name></person-group> <article-title>Learning in spiking neural assemblies</article-title>. <source>Advances in neural information processing systems</source>. <year>2002</year>; <volume>15</volume>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bell</surname> <given-names>C</given-names></string-name>, <string-name><surname>Bodznick</surname> <given-names>D</given-names></string-name>, <string-name><surname>Montgomery</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bastian</surname> <given-names>J.</given-names></string-name></person-group> <article-title>The generation and subtraction of sensory expectations within cerebellum-like structures</article-title>. <source>Brain Behav Evol</source>. <year>1997</year>;<volume>50</volume> <issue>Suppl 1</issue>:<fpage>17</fpage>–<lpage>31</lpage>. doi: <pub-id pub-id-type="doi">10.1159/000113352</pub-id>. PMID: <pub-id pub-id-type="pmid">9217991</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berkes</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Orban</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Lengyel</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Fiser</surname>, <given-names>J.</given-names></string-name></person-group> <article-title>Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment</article-title>. <source>Science</source> <volume>331</volume>, <fpage>83</fpage>–<lpage>87</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berman</surname> <given-names>GJ</given-names></string-name>, <string-name><surname>Bialek</surname> <given-names>W</given-names></string-name>, <string-name><surname>Shaevitz</surname> <given-names>JW</given-names></string-name></person-group>. <article-title>Predictability and hierarchy in Drosophila behavior</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2016</year>; <volume>113</volume>(<issue>42</issue>):<fpage>11943</fpage>–<lpage>11948</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1607601113</pub-id> PMID: <pub-id pub-id-type="pmid">27702892</pub-id></mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bouchard</surname> <given-names>KE</given-names></string-name>, <string-name><surname>Brainard</surname> <given-names>MS</given-names></string-name></person-group>. <article-title>Auditory-induced neural dynamics in sensory-motor circuitry predict learned temporal and sequential statistics of birdsong</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2016</year> <month>Aug</month> 23;<volume>113</volume>(<issue>34</issue>):<fpage>9641</fpage>–<lpage>6</lpage>. doi: <pub-id pub-id-type="doi">10.1073/pnas.1606725113</pub-id>. Epub 2016 Aug 9. PMID: <pub-id pub-id-type="pmid">27506786</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC5003256</pub-id>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brea</surname> <given-names>J</given-names></string-name>, <string-name><surname>Senn</surname> <given-names>W</given-names></string-name>, <string-name><surname>Pfister</surname> <given-names>JP</given-names></string-name></person-group>. <article-title>Matching Recall and Storage in Sequence Learning with Spiking Neural Networks</article-title>. <source>Journal of Neuroscience</source>. <year>2013</year>; <volume>33</volume>(<issue>23</issue>):<fpage>9565</fpage>–<lpage>9575</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.4098-12.2013</pub-id> PMID: <pub-id pub-id-type="pmid">23739954</pub-id></mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chadwick</surname> <given-names>A</given-names></string-name>, <string-name><surname>van Rossum</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Nolan</surname> <given-names>MF</given-names></string-name></person-group>. <article-title>Independent theta phase coding accounts for CA1 population sequences and enables flexible remapping</article-title>. <source>Elife</source>. <year>2015</year> <month>Feb</month> 2;<volume>4</volume>:<elocation-id>e03542</elocation-id>. doi: <pub-id pub-id-type="doi">10.7554/eLife.03542</pub-id>. PMID: <pub-id pub-id-type="pmid">25643396</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC4383210</pub-id>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>D’amour</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name></person-group>. <article-title>Inhibitory and excitatory spike-timing-dependent plasticity in the auditory cortex</article-title>. <source>Neuron</source>. <year>2015</year> <month>Apr</month> 22;<volume>86</volume>(<issue>2</issue>):<fpage>514</fpage>–<lpage>28</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.014</pub-id>. Epub 2015 Apr 2. PMID: <pub-id pub-id-type="pmid">25843405</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC4409545</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Davidson</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Kloosterman</surname> <given-names>F</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name></person-group>. <article-title>Hippocampal replay of extended experience</article-title>. <source>Neuron</source>. <year>2009</year> <month>Aug</month> 27;<volume>63</volume>(<issue>4</issue>):<fpage>497</fpage>–<lpage>507</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.027</pub-id>. PMID: <pub-id pub-id-type="pmid">19709631</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC4364032</pub-id>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diba</surname> <given-names>K</given-names></string-name>, <string-name><surname>Buzsáki</surname> <given-names>G.</given-names></string-name></person-group> <article-title>Forward and reverse hippocampal place-cell sequences during ripples</article-title>. <source>Nat Neurosci</source>. <year>2007</year> <month>Oct</month>;<volume>10</volume>(<issue>10</issue>):<fpage>1241</fpage>–<lpage>2</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nn1961</pub-id>. Epub 2007 Sep 2. PMID: <pub-id pub-id-type="pmid">17828259</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC2039924</pub-id>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Erickson</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Maramara</surname> <given-names>LA</given-names></string-name>, <string-name><surname>Lisman</surname> <given-names>J.</given-names></string-name></person-group> <article-title>A single brief burst induces GluR1-dependent associative short-term potentiation: a potential mechanism for short-term memory</article-title>. <source>J Cogn Neurosci</source>. <year>2010</year> <month>Nov</month>;<volume>22</volume>(<issue>11</issue>):<fpage>2530</fpage>–<lpage>40</lpage>. doi: <pub-id pub-id-type="doi">10.1162/jocn.2009.21375</pub-id>. PMID: <pub-id pub-id-type="pmid">19925206</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC3195522</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fonollosa</surname> <given-names>J</given-names></string-name>, <string-name><surname>Neftci</surname> <given-names>E</given-names></string-name>, <string-name><surname>Rabinovich</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Learning of Chunking Sequences in Cognition and Behavior</article-title>. <source>PLoS Comput Biol</source>. <year>2015</year> <month>Nov</month> 19;<volume>11</volume>(<issue>11</issue>):<fpage>e1004592</fpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1004592</pub-id>. PMID: <pub-id pub-id-type="pmid">26584306</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC4652905</pub-id>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Francioni</surname> <given-names>V</given-names></string-name>, <string-name><surname>Tang</surname> <given-names>VD</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>NJ</given-names></string-name>, <string-name><surname>Toloza</surname> <given-names>EH</given-names></string-name>, <string-name><surname>Harnett</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Vectorized instructive signals in cortical dendrites during a brain-computer interface task</article-title>. <year>2023</year>. <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Merzenich</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Schreiner</surname> <given-names>CE</given-names></string-name></person-group>. <article-title>A synaptic memory trace for cortical receptive field plasticity</article-title>. <source>Nature</source>. <year>2007</year>; <volume>450</volume>(<issue>7168</issue>), <fpage>425</fpage>–<lpage>429</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Funahashi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Bruce</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Goldman-Rakic</surname> <given-names>PS</given-names></string-name></person-group>. <article-title>Mnemonic coding of visual space in the monkey’s dorsolateral prefrontal cortex</article-title>. <source>J Neurophysiol</source>. <year>1989</year> <month>Feb</month>;<volume>61</volume>(<issue>2</issue>):<fpage>331</fpage>–<lpage>49</lpage>. doi: <pub-id pub-id-type="doi">10.1152/jn.1989.61.2.331</pub-id>. PMID: <pub-id pub-id-type="pmid">2918358</pub-id>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fuster</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Alexander</surname> <given-names>GE</given-names></string-name></person-group>. <article-title>Neuron activity related to short-term memory</article-title>. <source>Science</source>. <year>1971</year> <month>Aug</month> 13;<volume>173</volume>(<issue>3997</issue>):<fpage>652</fpage>–<lpage>4</lpage>. doi: <pub-id pub-id-type="doi">10.1126/science.173.3997.652</pub-id>. PMID: <pub-id pub-id-type="pmid">4998337</pub-id>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gabriel Koch</surname> <given-names>Ocker</given-names></string-name>, <string-name><given-names>Brent</given-names> <surname>Doiron</surname></string-name></person-group>, <article-title>Training and Spontaneous Reinforcement of Neuronal Assemblies by Spike Timing Plasticity</article-title>, <source>Cerebral Cortex</source>, Volume <volume>29</volume>, <issue>3</issue>, <month>March</month> <year>2019</year>, Pages <fpage>937</fpage>–<lpage>951</lpage>, <pub-id pub-id-type="doi">10.1093/cercor/bhy001</pub-id></mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Geddes</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Li</surname> <given-names>H</given-names></string-name>, <string-name><surname>Jin</surname> <given-names>X.</given-names></string-name></person-group> <article-title>Optogenetic Editing Reveals the Hierarchical Organization of Learned Action Sequences</article-title>. <source>Cell</source>. <year>2018</year>; <volume>174</volume>(<issue>1</issue>):<fpage>32</fpage>–<lpage>43.e15</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2018.06.012</pub-id> PMID: <pub-id pub-id-type="pmid">29958111</pub-id></mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldman-Rakic</surname> <given-names>PS</given-names></string-name></person-group>. <article-title>Cellular basis of working memory</article-title>. <source>Neuron</source>. <year>1995</year> <month>Mar</month>;<volume>14</volume>(<issue>3</issue>):<fpage>477</fpage>–<lpage>85</lpage>. doi: <pub-id pub-id-type="doi">10.1016/0896-6273(95)90304-6</pub-id>. PMID: <pub-id pub-id-type="pmid">7695894</pub-id>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gupta</surname> <given-names>AS</given-names></string-name>, <string-name><surname>van der Meer</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Touretzky</surname> <given-names>DS</given-names></string-name>, <string-name><surname>Redish</surname> <given-names>AD</given-names></string-name></person-group>. <article-title>Hippocampal replay is not a simple function of experience</article-title>. <source>Neuron</source>. <year>2010</year> <month>Mar</month> 11;<volume>65</volume>(<issue>5</issue>):<fpage>695</fpage>–<lpage>705</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.034</pub-id>. PMID: <pub-id pub-id-type="pmid">20223204</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC4460981</pub-id>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jin</surname> <given-names>X</given-names></string-name>, <string-name><surname>Costa</surname> <given-names>RM</given-names></string-name></person-group>. <article-title>Shaping action sequences in basal ganglia circuits</article-title>. <source>Current Opinion in Neurobiology</source>. <year>2015</year>; <volume>33</volume>:<fpage>188</fpage>–<lpage>196</lpage>. <pub-id pub-id-type="doi">10.1016/j.conb.2015.06.011</pub-id> PMID: <pub-id pub-id-type="pmid">26189204</pub-id></mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jovanic</surname> <given-names>T</given-names></string-name>, <string-name><surname>Schneider-Mizell</surname> <given-names>CM</given-names></string-name>, <string-name><surname>Shao</surname> <given-names>M</given-names></string-name>, <string-name><surname>Masson</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Denisov</surname> <given-names>G</given-names></string-name>, <string-name><surname>Fetter</surname> <given-names>RD</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Competitive Disinhibition Mediates Behavioral Choice and Sequences in Drosophila</article-title>. <source>Cell</source>. <year>2016</year>; <volume>167</volume>(<issue>3</issue>):<fpage>858</fpage>–<lpage>870.e19</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2016.09.009</pub-id> PMID: <pub-id pub-id-type="pmid">27720450</pub-id></mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kaplan</surname> <given-names>HS</given-names></string-name>, <string-name><surname>Salazar Thula</surname> <given-names>O</given-names></string-name>, <string-name><surname>Khoss</surname> <given-names>N</given-names></string-name>, <string-name><surname>Zimmer</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Nested Neuronal Dynamics Orchestrate a Behavioral Hierarchy across Timescales</article-title>. <source>Neuron</source>. <year>2020</year>; <volume>105</volume>(<issue>3</issue>):<fpage>562</fpage>–<lpage>576.e9</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2019.10.037</pub-id> PMID: <pub-id pub-id-type="pmid">31786012</pub-id></mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katahira</surname> <given-names>K</given-names></string-name>, <string-name><surname>Suzuki</surname> <given-names>K</given-names></string-name>, <string-name><surname>Okanoya</surname> <given-names>K</given-names></string-name>, <string-name><surname>Okada</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Complex sequencing rules of birdsong can be explained by simple hidden Markov processes</article-title>. <source>PLoS One</source>. <year>2011</year>;<volume>6</volume>(<issue>9</issue>):<fpage>e24516</fpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0024516</pub-id>. Epub 2011 Sep 7. PMID: <pub-id pub-id-type="pmid">21915345</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC3168521</pub-id>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kato</surname> <given-names>S</given-names></string-name>, <string-name><surname>Kaplan</surname> <given-names>HS</given-names></string-name>, <string-name><surname>Schrödel</surname> <given-names>T</given-names></string-name>, <string-name><surname>Skora</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lindsay</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Yemini</surname> <given-names>E</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Global Brain Dynamics Embed the Motor Command Sequence of Caenorhabditis elegans</article-title>. <source>Cell</source>. <year>2015</year>; <volume>163</volume>(<issue>3</issue>):<fpage>656</fpage>–<lpage>669</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2015.09.034</pub-id> PMID: <pub-id pub-id-type="pmid">26478179</pub-id></mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kempter</surname> <given-names>R</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W</given-names></string-name>, <string-name><surname>van Hemmen</surname> <given-names>JL</given-names></string-name></person-group> (<year>1999</year>) <article-title>Hebbian learning and spiking neurons</article-title>. <source>Physical Review E</source> <volume>59</volume>: <fpage>4498</fpage>–<lpage>4514</lpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kogan</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Margoliash</surname> <given-names>D.</given-names></string-name></person-group> <article-title>Automated recognition of bird song elements from continuous recordings using dynamic time warping and hidden Markov models: a comparative study</article-title>. <source>J Acoust Soc Am</source>. <year>1998</year> <month>Apr</month>;<volume>103</volume>(<issue>4</issue>):<fpage>2185</fpage>–<lpage>96</lpage>. doi: <pub-id pub-id-type="doi">10.1121/1.421364</pub-id>. PMID: <pub-id pub-id-type="pmid">9566338</pub-id>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname> <given-names>A.K.</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>M.A.</given-names></string-name></person-group> <article-title>Memory of sequential experience in the hippocampus during slow wave sleep</article-title>. <source>Neuron</source>. <year>2002</year>;<volume>36</volume>:<fpage>1183</fpage>–<lpage>1194</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Levy</surname> <given-names>N</given-names></string-name>, <string-name><surname>Horn</surname> <given-names>D</given-names></string-name>, <string-name><surname>Meilijson</surname> <given-names>I</given-names></string-name>, <string-name><surname>Ruppin</surname> <given-names>E.</given-names></string-name></person-group> <article-title>Distributed synchrony in a cell assembly of spiking neurons</article-title>. <source>Neural Netw</source>. <year>2001</year>;<volume>14</volume>(<issue>6-7</issue>):<fpage>815</fpage>-<lpage>24</lpage>. doi: <pub-id pub-id-type="doi">10.1016/s0893-6080(01)00044-2</pub-id>. PMID: <pub-id pub-id-type="pmid">11665773</pub-id>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lewald</surname> <given-names>J</given-names></string-name>, <string-name><surname>Ehrenstein</surname> <given-names>WH</given-names></string-name></person-group>. <article-title>Influence of head-to-trunk position on sound lateralization</article-title>. <source>Exp Brain Res</source>. <year>1998</year> <month>Aug</month>;<volume>121</volume>(<issue>3</issue>):<fpage>230</fpage>–<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s002210050456</pub-id>. PMID: <pub-id pub-id-type="pmid">9746129</pub-id>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Litwin-Kumar</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Doiron</surname>, <given-names>B.</given-names></string-name></person-group> <article-title>Formation and maintenance of neuronal assemblies through synaptic plasticity</article-title>. <source>Nat Commun</source> <volume>5</volume>, <fpage>5319</fpage> (<year>2014</year>). <pub-id pub-id-type="doi">10.1038/ncomms6319</pub-id></mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Markowitz</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Gillis</surname> <given-names>WF</given-names></string-name>, <string-name><surname>Beron</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Neufeld</surname> <given-names>SQ</given-names></string-name>, <string-name><surname>Robertson</surname> <given-names>K</given-names></string-name>, <string-name><surname>Bhagat</surname> <given-names>ND</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>The Striatum Organizes 3D Behavior via Moment-to-Moment Action Selection</article-title>. <source>Cell</source>. <year>2018</year>; <volume>174</volume>(<issue>1</issue>):<fpage>44</fpage>–<lpage>58.e17</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2018.04.019</pub-id> PMID: <pub-id pub-id-type="pmid">29779950</pub-id></mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masquelier</surname> <given-names>T</given-names></string-name>, <string-name><surname>Guyonneau</surname> <given-names>R</given-names></string-name>, <string-name><surname>Thorpe</surname> <given-names>SJ</given-names></string-name></person-group> (<year>2008</year>) <article-title>Spike timing dependent plasticity finds the start of repeating patterns in continuous spike trains</article-title>. <source>PLoS One</source> <volume>3</volume>: <fpage>e1377</fpage>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Merfeld</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Zupan</surname> <given-names>L</given-names></string-name>, <string-name><surname>Peterka</surname> <given-names>RJ</given-names></string-name></person-group>. <article-title>Humans use internal models to estimate gravity and linear acceleration</article-title>. <source>Nature</source>. <year>1999</year> <month>Apr</month> 15;<volume>398</volume>(<issue>6728</issue>):<fpage>615</fpage>–<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1038/19303</pub-id>. PMID: <pub-id pub-id-type="pmid">10217143</pub-id>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miller</surname> <given-names>EK</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>JD</given-names></string-name></person-group>. <article-title>An integrative theory of prefrontal cortex function</article-title>. <source>Annu Rev Neurosci</source>. <year>2001</year>;<volume>24</volume>:<fpage>167</fpage>–<lpage>202</lpage>. doi: <pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.167</pub-id>. PMID: <pub-id pub-id-type="pmid">11283309</pub-id>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mongillo</surname> <given-names>G</given-names></string-name>, <string-name><surname>Barak</surname> <given-names>O</given-names></string-name>, <string-name><surname>Tsodyks</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Synaptic theory of working memory</article-title>. <source>Science</source>. <year>2008</year> <month>Mar</month> 14;<volume>319</volume>(<issue>5869</issue>):<fpage>1543</fpage>–<lpage>6</lpage>. doi: <pub-id pub-id-type="doi">10.1126/science.1150769</pub-id>. PMID: <pub-id pub-id-type="pmid">18339943</pub-id>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pfister</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Toyoizumi</surname> <given-names>T</given-names></string-name>, <string-name><surname>Barber</surname> <given-names>D</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name></person-group> <article-title>Optimal spike-timing-dependent plasticity for precise action potential firing in supervised learning</article-title>. <source>Neural Comput</source>. <year>2006</year> <month>Jun</month>;<volume>18</volume>(<issue>6</issue>):<fpage>1318</fpage>–<lpage>48</lpage>. doi: <pub-id pub-id-type="doi">10.1162/neco.2006.18.6.1318</pub-id>. PMID: <pub-id pub-id-type="pmid">16764506</pub-id>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pudhiyidath</surname> <given-names>A</given-names></string-name>, <string-name><surname>Morton</surname> <given-names>NW</given-names></string-name>, <string-name><surname>Viveros Duran</surname> <given-names>R</given-names></string-name>, <string-name><surname>Schapiro</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Momennejad</surname> <given-names>I</given-names></string-name>, <string-name><surname>Hinojosa-Rowland</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Molitor</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Preston</surname> <given-names>AR</given-names></string-name></person-group>. <article-title>Representations of Temporal Community Structure in Hippocampus and Precuneus Predict Inductive Reasoning Decisions</article-title>. <source>J Cogn Neurosci</source>. <year>2022</year> <month>Sep</month> 1;<volume>34</volume>(<issue>10</issue>):<fpage>1736</fpage>–<lpage>1760</lpage>. doi: <pub-id pub-id-type="doi">10.1162/jocn_a_01864</pub-id>. PMID: <pub-id pub-id-type="pmid">35579986</pub-id>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schapiro</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Rogers</surname> <given-names>TT</given-names></string-name>, <string-name><surname>Cordova</surname> <given-names>NI</given-names></string-name>, <string-name><surname>Turk-Browne</surname> <given-names>NB</given-names></string-name>, <string-name><surname>Botvinick</surname> <given-names>MM</given-names></string-name></person-group>. <article-title>Neural representations of events arise from temporal community structure</article-title>. <source>Nat Neurosci</source>. <year>2013</year> <month>Apr</month>;<volume>16</volume>(<issue>4</issue>):<fpage>486</fpage>–<lpage>92</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nn.3331</pub-id>. Epub 2013 Feb 17. PMID: <pub-id pub-id-type="pmid">23416451</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC3749823</pub-id>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seeds</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Ravbar</surname> <given-names>P</given-names></string-name>, <string-name><surname>Chung</surname> <given-names>P</given-names></string-name>, <string-name><surname>Hampel</surname> <given-names>S</given-names></string-name>, <string-name><surname>Midgley</surname> <given-names>FM</given-names></string-name>, <string-name><surname>Mensh</surname> <given-names>BD</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>A suppression hierarchy among competing motor programs drives sequential grooming in Drosophila</article-title>. <source>eLife</source>. <year>2014</year>; <volume>3</volume>:<elocation-id>e02951</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.02951</pub-id> PMID: <pub-id pub-id-type="pmid">25139955</pub-id></mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Skaggs</surname> <given-names>W.E.</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>B.L.</given-names></string-name></person-group> <article-title>Replay of neuronal firing sequences in rat hippocampus during sleep following spatial experience</article-title>. <source>Science</source>. <year>1996</year>;<volume>271</volume>:<fpage>1870</fpage>–<lpage>1873</lpage>. [PubMed] [Google Scholar]</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname> <given-names>S</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>KD</given-names></string-name>, <string-name><surname>Abbott</surname> <given-names>LF</given-names></string-name></person-group> (<year>2000</year>) <article-title>Competitive Hebbian learning through spike-timing dependent synaptic plasticity</article-title>. <source>Nature Neuroscience</source> <volume>3</volume>: <fpage>919</fpage>–<lpage>926</lpage>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tavazoie</surname> <given-names>S.</given-names></string-name></person-group> <article-title>Synaptic state matching: a dynamical architecture for predictive internal representation and feature detection</article-title>. <source>Plos one</source>. <year>2013</year>; <volume>8</volume>(<issue>8</issue>), <fpage>e72865</fpage>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Triplett</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Avitan</surname> <given-names>L</given-names></string-name>, <string-name><surname>Goodhill</surname> <given-names>GJ</given-names></string-name></person-group> (<year>2018</year>) <article-title>Emergence of spontaneous assembly activity in developing neural networks without afferent input</article-title>. <source>PLOS Computational Biology</source> <volume>14</volume>(<issue>9</issue>): <fpage>e1006421</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006421</pub-id></mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Urbanczik</surname> <given-names>R</given-names></string-name>, <string-name><surname>Senn</surname> <given-names>W.</given-names></string-name></person-group> <article-title>Learning by the dendritic prediction of somatic spiking</article-title>. <source>Neuron</source>. <year>2014</year> <month>Feb</month> 5;<volume>81</volume>(<issue>3</issue>):<fpage>521</fpage>–<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.030</pub-id>. PMID: <pub-id pub-id-type="pmid">24507189</pub-id>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vogels</surname> <given-names>TP</given-names></string-name>, <string-name><surname>Sprekeler</surname> <given-names>H</given-names></string-name>, <string-name><surname>Zenke</surname> <given-names>F</given-names></string-name>, <string-name><surname>Clopath</surname> <given-names>C</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name></person-group> <article-title>Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks</article-title>. <source>Science</source>. <year>2011</year> <month>Dec</month> 16;<volume>334</volume>(<issue>6062</issue>):<fpage>1569</fpage>–<lpage>73</lpage>. doi: <pub-id pub-id-type="doi">10.1126/science.1211095</pub-id>. Epub 2011 Nov 10. Erratum in: Science. 2012 May 18;336(6083):802. PMID: <pub-id pub-id-type="pmid">22075724</pub-id>.</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname> <given-names>M.A.</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>B.L.</given-names></string-name></person-group> <article-title>Reactivation of hippocampal ensemble memories during sleep</article-title>. <source>Science</source>. <year>1994</year>;<volume>265</volume>:<fpage>676</fpage>–<lpage>679</lpage>. [PubMed] [Google Scholar]</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wolpert</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Ghahramani</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Jordan</surname> <given-names>MI</given-names></string-name></person-group>. <article-title>An internal model for sensorimotor integration</article-title>. <source>Science</source>. <year>1995</year> <month>Sep</month> 29;<volume>269</volume>(<issue>5232</issue>):<fpage>1880</fpage>–<lpage>2</lpage>. doi: <pub-id pub-id-type="doi">10.1126/science.7569931</pub-id>. PMID: <pub-id pub-id-type="pmid">7569931</pub-id>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname> <given-names>X</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>DJ</given-names></string-name></person-group>. <article-title>Hippocampal replay captures the unique topological structure of a novel environment</article-title>. <source>J Neurosci</source>. <year>2014</year> <month>May</month> 7;<volume>34</volume>(<issue>19</issue>):<fpage>6459</fpage>–<lpage>69</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3414-13.2014</pub-id>. PMID: <pub-id pub-id-type="pmid">24806672</pub-id>; PMCID: <pub-id pub-id-type="pmcid">PMC4012305</pub-id>.</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yasui</surname> <given-names>S</given-names></string-name>, <string-name><surname>Young</surname> <given-names>LR</given-names></string-name></person-group>. <article-title>Perceived visual motion as effective stimulus to pursuit eye movement system</article-title>. <source>Science</source>. <year>1975</year> <month>Nov</month> 28;<volume>190</volume>(<issue>4217</issue>):<fpage>906</fpage>–<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1126/science.1188373</pub-id>. PMID: <pub-id pub-id-type="pmid">1188373</pub-id>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zucker</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Regehr</surname> <given-names>WG</given-names></string-name></person-group>. <article-title>Short-term synaptic plasticity</article-title>. <source>Annu Rev Physiol</source>. <year>2002</year>; <volume>64</volume>:<fpage>355</fpage>–<lpage>405</lpage>. doi: <pub-id pub-id-type="doi">10.1146/annurev.physiol.64.092501.114547</pub-id>. PMID: <pub-id pub-id-type="pmid">11826273</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95243.2.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Gjorgjieva</surname>
<given-names>Julijana</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Technical University of Munich</institution>
</institution-wrap>
<city>Freising</city>
<country>Germany</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>This is an <bold>important</bold> study that investigates how neural networks can learn to stochastically replay presented sequences of activity according to learned transition probabilities. The authors use error-based excitatory plasticity to minimize the difference between internally predicted activity and stimulus-driven activity, and inhibitory plasticity to maintain E-I balance. The approach is <bold>solid</bold> but the choice of learning rules and parameters is not always always justified, with some unclear aspects to the formal derivation.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95243.2.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work proposes a synaptic plasticity rule which explains the generation of learned stochastic dynamics during spontaneous activity. The proposed plasticity rule assumes that excitatory synapses seek to minimize the difference between the internal predicted activity and stimulus-evoked activity, and inhibitory synapses tries to maintain the E-I balance by matching the excitatory activity. By implementing this plasticity rule in a spiking recurrent neural network, the authors show that the state-transition statistics of spontaneous excitatory activity agrees with that of the learned stimulus patterns, which is reflected in the learned excitatory synaptic weights. The authors further demonstrate that inhibitory connections contribute to well-defined state-transitions matching the transition patterns evoked by the stimulus. Finally, they show that this mechanism can be expanded to more complex state-transition structures including songbird neural data.</p>
<p>Strengths:</p>
<p>This study makes an important contribution to computational neuroscience, by proposing a possible synaptic plasticity mechanism underlying spontaneous generations of learned stochastic state-switching dynamics that are experimentally observed in the visual cortex and hippocampus. This work is also very clearly presented and well-written, and the authors conducted comprehensive simulations testing multiple hypotheses. Overall, I believe this is a well-conducted study providing interesting and novel aspects on the capacity of recurrent spiking neural networks with local synaptic plasticity.</p>
<p>Weaknesses:</p>
<p>This study is very well-thought out and theoretically valuable to the neuroscience community, and I think the main weaknesses are in regard to how much biological realism is taken into account. For example, the proposed model assumes that only synapses targeting excitatory neurons are plastic, and uses an equal number of excitatory and inhibitory neurons.</p>
<p>
The model also assumes Markovian state dynamics while biological systems can depend more on history. This limitation, however, is acknowledged in the Discussion.</p>
<p>
Finally, to simulate spontaneous activity, the authors use a constant input of 0.3 throughout the study. Different amplitudes of constant input may correspond to different internal states, so it will be more convincing if the authors test the model with varying amplitudes of constant inputs.</p>
<p>Comments on revisions:</p>
<p>The authors have addressed all of the previously raised concerns satisfactorily, by running extra simulations with a biologically plausible composition of excitatory and inhibitory neurons, plasticity assumed for all synapses, and varied amounts of constant inputs representing internal states or background activities. While in some of these cases the stochastic dynamics during spontaneous activity change or do not replicate those of the learned stimulus patterns as well as before, these extended studies provide thorough evaluations of the strengths and limitations of the proposed plasticity rule as the underlying mechanism of stochastic dynamics during spontaneous activity. Overall, the revision has strengthened the paper significantly.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95243.2.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Asabuki and Clopath study stochastic sequence learning in recurrent networks of Poisson spiking neurons that obey Dale's law. Inspired by previous modeling studies, they introduce two distinct learning rules, to adapt excitatory-to-excitatory and inhibitory-to-excitatory synaptic connections. Through a series of computer experiments, the authors demonstrate that their networks can learn to generate stochastic sequential patterns, where states correspond to non-overlapping sets of neurons (cell assemblies) and the state-transition conditional probabilities are first-order Markov, i.e., the transition to a given next state only depends on the current state. Finally, the authors use their model to reproduce certain experimental songbird data involving highly-predictable and highly-uncertain transitions between song syllables. While the findings are only moderately surprising, this is a well-written and welcome detailed study that may be of interest to experts of plasticity and learning in recurrent neural networks that respect Dale's law.</p>
<p>Strengths:</p>
<p>This is an easy-to-follow, well-written paper, whose results are likely easy to reproduce. The experiments are clear and well-explained. In particular, the study of the interplay between excitation and inhibition (and their different plasticity rules) is a highlight of the study. The study of songbird experimental data is another good feature of this paper; finches are classical model animals for understanding sequence learning in the brain. I also liked the study of rapid task-switching, it's a good-to-know type of result that is not very common in sequence learning papers.</p>
<p>Weaknesses:</p>
<p>One weakness I see in this paper is the derivation of the learning rules, which is semi-heuristic. The paper studies Poisson spiking neurons, for which learning rules can be derived from a statistical objective, typically maximum likelihood, as previously done in the cited literature. The authors provide a brief section connecting the learning rules to gradient descent on objective functions, but the link is only heuristic or at least not entirely presented. The reason is that the neural network state is not fully determined by (or &quot;clamped to&quot;) the target during learning (for instance, inhibitory neurons do not even have a target assigned). So, the (total) gradient should take into account the recurrent contributions from other neurons, and equation 13 does not appear to be complete/correct to me. Moreover, the target firing rate is a mixture of external currents with currents arising from other neurons in the recurrent network. The authors ideally should start from an actual distribution matching objective (e.g., KL divergence, and not such a squared error), so that their main claims immediately follow from the mathematical derivations. Along the same line, it would be excellent to get some additional insights on the interaction of the two distinct plasticity rules, one of the highlights of the study. This could be naturally achieved by relating their distinct rules to a common principled objective.</p>
<p>The other major weakness (albeit one that is clearly discussed by the authors) is that the study assumes that every excitatory neuron is directly given its target state when learning. In machine learning language, there are no 'hidden' excitatory neurons. While this assumption greatly simplifies the derivation of efficient and biologically-plausible learning rules that can be mapped to synaptic plasticity, it also limits considerably the distributions that can be learned by the network, more precisely to those that satisfy the Markov property.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95243.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Asabuki</surname>
<given-names>Toshitake</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0951-5791</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Clopath</surname>
<given-names>Claudia</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4507-8648</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>In the presented manuscript, the authors investigate how neural networks can learn to replay presented sequences of activity. Their focus lies on the stochastic replay according to learned transition probabilities. They show that based on error-based excitatory and balance-based inhibitory plasticity networks can selforganize towards this goal. Finally, they demonstrate that these learning rules can recover experimental observations from song-bird song learning experiments.</p>
<p>Overall, the study appears well-executed and coherent, and the presentation is very clear and helpful. However, it remains somewhat vague regarding the novelty. The authors could elaborate on the experimental and theoretical impact of the study, and also discuss how their results relate to those of Kappel et al, and others (e.g., Kappel et al (<ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1371/journal.pcbi.1003511)">doi.org/10.1371/journal.pcbi.1003511))</ext-link>.</p>
</disp-quote>
<p>We agree with the reviewer that our previous manuscript lacked comparison with previously published similar works. While Kappel et al. demonstrated that STDP in winner-take-all circuits can approximate online learning of hidden Markov models (HMMs), a key distinction from our model is that their neural representations acquire deterministic sequential activations, rather than exhibiting stochastic transitions governing Markovian dynamics. Specifically, in their model, the neural representation of state B would be different in the sequences ABC and CBA, resulting in distinct deterministic representations like ABC and C'B'A', where ‘A’ and ‘A'’ are represented by different neural states (e.g., activations of different cell assemblies). In contrast, our network learns to generate stochastically transitioning cell assemblies which replay Markovian trajectories of spontaneous activity obeying the learned transition probabilities between neural representations of states. For example, starting from reactivation from assembly ‘A’, there may be an 80% probability to transition to assembly ‘B’ and 20% to ‘C’. Although Kappel et al.'s model successfully solves HMMs, their neural representations do not themselves stochastically transition between states according to the learned model. Similar to the Kappel et al.'s model, while the models proposed in Barber (2002) and Barber and Agakov (2002) learn the Markovian statistics, these models learned a static spatiotemporal input patterns only and how assemblies of neurons show stochastic transition in spontaneous activity has been still unclear. In contrast with these models, our model captures the probabilistic neural state trajectories, allowing spontaneous replay of experienced sequences with stochastic dynamics matching the learned environmental statistics.</p>
<p>We have included new sentences for explain these in ll. 509-533 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Overall, the work could benefit if there was either (A) a formal analysis or derivation of the plasticity rules involved and a formal justification of the usefulness of the resulting (learned) neural dynamics;</p>
</disp-quote>
<p>We have included a derivation of our plasticity rules in ll. 630-670 in the revised manuscript. Consistent with our claim that excitatory plasticity updates the excitatory synapse to predict output firing rates, we have shown that the corresponding cost function measures the discrepancy between the recurrent prediction and the output firing rate. Similarly, for inhibitory plasticity, we defined the cost function that evaluates the difference between the excitatory and inhibitory potential within each neuron. We showed that the resulting inhibitory plasticity rule updates the inhibitory synapses to maintain the excitation-inhibition balance.</p>
<disp-quote content-type="editor-comment">
<p>and/or (B) a clear connection of the employed plasticity rules to biological plasticity and clear testable experimental predictions. Thus, overall, this is a good work with some room for improvement.</p>
</disp-quote>
<p>Our proposed plasticity mechanism could be implemented through somatodendritic interactions. Analogous to previous computational works (Urbanczik and Senn., 2014; Asabuki and Fukai., 2020; Asabuki et al., 2022), our model suggests that somatic responses may encode the stimulus-evoked neural activity states, while dendrites encode predictions based on recurrent dynamics that aim to minimize the discrepancy between somatic and dendritic activity. To directly test this hypothesis, future experimental studies could simultaneously record from both somatic and dendritic compartments to investigate how they encode evoked responses and predictive signals during learning (Francioni et al., 2022).</p>
<p>We have included new sentences for explain these in ll. 476-484 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Summary:</p>
<p>This work proposes a synaptic plasticity rule that explains the generation of learned stochastic dynamics during spontaneous activity. The proposed plasticity rule assumes that excitatory synapses seek to minimize the difference between the internal predicted activity and stimulus-evoked activity, and inhibitory synapses try to maintain the E-I balance by matching the excitatory activity. By implementing this plasticity rule in a spiking recurrent neural network, the authors show that the state-transition statistics of spontaneous excitatory activity agree with that of the learned stimulus patterns, which are reflected in the learned excitatory synaptic weights. The authors further demonstrate that inhibitory connections contribute to well-defined state transitions matching the transition patterns evoked by the stimulus. Finally, they show that this mechanism can be expanded to more complex state-transition structures including songbird neural data.</p>
<p>Strengths:</p>
<p>This study makes an important contribution to computational neuroscience, by proposing a possible synaptic plasticity mechanism underlying spontaneous generations of learned stochastic state-switching dynamics that are experimentally observed in the visual cortex and hippocampus. This work is also very clearly presented and well-written, and the authors conducted comprehensive simulations testing multiple hypotheses. Overall, I believe this is a well-conducted study providing interesting and novel aspects of the capacity of recurrent spiking neural networks with local synaptic plasticity.</p>
<p>Weaknesses:</p>
<p>This study is very well-thought-out and theoretically valuable to the neuroscience community, and I think the main weaknesses are in regard to how much biological realism is taken into account. For example, the proposed model assumes that only synapses targeting excitatory neurons are plastic, and uses an equal number of excitatory and inhibitory neurons.</p>
</disp-quote>
<p>We agree with the reviewer. The network shown in the previous manuscript consists of an equal number of excitatory and inhibitory neurons, which seems to lack biological plausibility. Therefore, we first tested whether a biologically plausible scenario would affect learning performance by setting the ratio of excitatory to inhibitory neurons to 80% and 20% (Supplementary Figure 7a; left). Even in such a scenario, the network still showed structured spontaneous activity (Supplementary Figure 7a; center), with transition statistics of replayed events matching the true transition probabilities (Supplementary Figure 7a; right). We then asked whether the model with our plasticity rule applied to all synapses would reproduce the corresponding stochastic transitions. We found that the network can learn transition statistics but only under certain conditions. The network showed only weak replay and failed to reproduce the appropriate transition (Supplementary Fig. 7b) if the inhibitory neurons were no longer driven by the synaptic currents reflecting the stimulus, due to a tight balance of excitatory and inhibitory currents on the inhibitory neurons. We then tested whether the network with all synapses plastic can learn transition statistics if the external inputs project to the inhibitory neurons as well. We found that, when each stimulus pattern activates a non-overlapping subset of neurons, the network does not exhibit the correct stochastic transition of assembly reactivation (Supplementary Fig. 7c). Interestingly, when each neuron's activity is triggered by multiple stimuli and has mixed selectivity, the reactivation reproduced the appropriate stochastic transitions (Supplementary Fig. 7d).</p>
<p>We have included these new results as new Supplementary Figure 7 and they are explained in ll.215-230 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>The model also assumes Markovian state dynamics while biological systems can depend more on history. This limitation, however, is acknowledged in the Discussion.</p>
</disp-quote>
<p>We have included the following sentence to provide a possible solution to this limitation: “Therefore, to learn higher-order stochastic transitions, recurrent neural networks like ours may need to integrate higher-order inputs with longer time scales.” in ll.557-559 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Finally, to simulate spontaneous activity, the authors use a constant input of 0.3 throughout the study. Different amplitudes of constant input may correspond to different internal states, so it will be more convincing if the authors test the model with varying amplitudes of constant inputs.</p>
</disp-quote>
<p>We thank the reviewer for pointing this out. In the revised manuscript, we have tested constant input with three different strengths. If the strength is moderate, the network showed accurate encoding of transition statistics in the spontaneous activity as we have seen in Fig.2. We have additionally shown that the weaker background input causes spontaneous activity with lower replay rate, which in turn leads to high variance of encoded transition, while stronger inputs make assembly replay transitions more uniform. We have included these new results as new Supplementary Figure 6 and they are explained in ll.211214 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public Review):</bold></p>
<p>Summary:</p>
<p>Asabuki and Clopath study stochastic sequence learning in recurrent networks of Poisson spiking neurons that obey Dale's law. Inspired by previous modeling studies, they introduce two distinct learning rules, to adapt excitatory-to-excitatory and inhibitory-to-excitatory synaptic connections. Through a series of computer experiments, the authors demonstrate that their networks can learn to generate stochastic sequential patterns, where states correspond to non-overlapping sets of neurons (cell assemblies) and the state-transition conditional probabilities are first-order Markov, i.e., the transition to a given next state only depends on the current state. Finally, the authors use their model to reproduce certain experimental songbird data involving highly-predictable and highly-uncertain transitions between song syllables.</p>
<p>Strengths:</p>
<p>This is an easy-to-follow, well-written paper, whose results are likely easy to reproduce. The experiments are clear and well-explained. The study of songbird experimental data is a good feature of this paper; finches are classical model animals for understanding sequence learning in the brain. I also liked the study of rapid task-switching, it's a good-to-know type of result that is not very common in sequence learning papers.</p>
<p>Weaknesses:</p>
<p>While the general subject of this paper is very interesting, I missed a clear main result. The paper focuses on a simple family of sequence learning problems that are well-understood, namely first-order Markov sequences and fully visible (nohidden-neuron) networks, studied extensively in prior work, including with spiking neurons. Thus, because the main results can be roughly summarized as examples of success, it is not entirely clear what the main point of the authors is.</p>
</disp-quote>
<p>We apologize the reviewer that our main claim was not clear. While various computational studies have suggested possible plasticity mechanisms for embedding evoked activity patterns or their probability structures into spontaneous activity (Litwin-Kumar et al., Nat. Commun. 2014, Asabuki and Fukai., Biorxiv 2023), how transition statistics of the environment are learned in spontaneous activity is still elusive and poorly understood. Furthermore, while several network models have been proposed to learn Markovian dynamics via synaptic plasticity (Brea, et al. (2013); Pfister et al. (2004); Kappel et al. (2014)), they have been limited in a sense that the learned network does not show stochastic transition in a neural state space. For instance, while Kappel et al. demonstrated that STDP in winner-take-all circuits can approximate online learning of hidden Markov models (HMMs), a key distinction from our model is that their neural representations acquire deterministic sequential activations, rather than exhibiting stochastic transitions governing Markovian dynamics. Specifically, in their model, the neural representation of state B would be different in the sequences ABC and CBA, resulting in distinct deterministic representations like ABC and C'B'A', where ‘A’ and ‘A'’ are represented by different neural states (e.g., activations of different cell assemblies). In contrast, our network learns to generate stochastically transitioning cell assemblies that replay Markovian trajectories of spontaneous activity obeying the learned transition probabilities between neural representations of states. For example, starting from reactivation from assembly ‘A’, there may be an 80% probability to transition to assembly ‘B’ and 20% to ‘C’. Although Kappel et al.'s model successfully solves HMMs, their neural representations do not themselves stochastically transition between states according to the learned model. Similar to the Kappel et al.'s model, while the models proposed in Barber (2002) and Barber and Agakov (2002) learn the Markovian statistics, these models learned a static spatiotemporal input patterns only and how assemblies of neurons show stochastic transition in spontaneous activity has been still unclear. In contrast with these models, our model captures the probabilistic neural state trajectories, allowing spontaneous replay of experienced sequences with stochastic dynamics matching the learned environmental statistics.</p>
<p>We have explained this point in ll.509-533 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Going into more detail, the first major weakness I see in this paper is the heuristic choice of learning rules. The paper studies Poisson spiking neurons (I return to this point below), for which learning rules can be derived from a statistical objective, typically maximum likelihood. For fully-visible networks, these rules take a simple form, similar in many ways to the E-to-E rule introduced by the authors. This more principled route provides quite a lot of additional understanding on what is to be expected from the learning process.</p>
</disp-quote>
<p>We thank the reviewer for pointing this out. To better demonstrate the function of our plasticity rules, we have included the derivation of the rules of synaptic plasticity in ll. 630-670 in the revised manuscript. Consistent with our claim that excitatory plasticity updates the excitatory synapse to predict output firing rates, we have shown that the corresponding cost function measures the discrepancy between the recurrent prediction and the output firing rate. Similarly, for inhibitory plasticity, we defined the cost function that evaluates the difference between the excitatory and inhibitory potential within each neuron. We showed that the resulting inhibitory plasticity rule updates the inhibitory synapses to maintain the excitation-inhibition balance.</p>
<disp-quote content-type="editor-comment">
<p>For instance, should maximum likelihood learning succeed, it is not surprising that the statistics of the training sequence distribution are reproduced. Moreover, given that the networks are fully visible, I think that the maximum likelihood objective is a convex function of the weights, which then gives hope that the learning rule does succeed. And so on. This sort of learning rule has been studied in a series of papers by David Barber and colleagues [refs. 1, 2 below], who applied them to essentially the same problem of reproducing sequence statistics in recurrent fully-visible nets. It seems to me that one key difference is that the authors consider separate E and I populations, and find the need to introduce a balancing I-to-E learning rule.</p>
</disp-quote>
<p>The reviewer’s understanding that inhibitory plasticity to maintain EI balance is one of a critical difference from previous works is correct. However, we believe that the most striking point of our study is that we have shown numerically that predictive plasticity rules enable recurrent networks to learn and replay the assembly activations whose transition statistics match those of the evoked activity. Please see our reply above.</p>
<disp-quote content-type="editor-comment">
<p>Because the rules here are heuristic, a number of questions come to mind. Why these rules and not others - especially, as the authors do not discuss in detail how they could be implemented through biophysical mechanisms? When does learning succeed or fail? What is the main point being conveyed, and what is the contribution on top of the work of e.g. Barber, Brea, et al. (2013), or Pfister et al. (2004)?</p>
</disp-quote>
<p>Our proposed plasticity mechanism could be implemented through somatodendritic interactions. Analogous to previous computational works (Senn, Asabuki), our model suggests that somatic responses may encode the stimulusevoked neural activity states, while dendrites encode predictions based on recurrent dynamics that aim to minimize the discrepancy between somatic and dendritic activity. To directly test this hypothesis, future experimental studies could simultaneously record from both somatic and dendritic compartments to investigate how they encode evoked responses and predictive signals during learning.</p>
<p>To address the point of the reviewer, we conducted addionnal simulations to test where the model fails. We found that the model with our plasticity rule applied to all synapses only showed faint replays and failed to replay the appropriate transition (Supplementary Fig. 7b). This result is reasonable because the inhibitory neurons were no longer driven by the synaptic currents reflecting the stimulus, due to a tight balance of excitatory and inhibitory currents on the inhibitory neurons. Our model predicts that mixed selectivity in the inhibitory population is crucial to learn an appropriate transition statistics (Supplementary Fig. 7d). Future work should clarify the role of synaptic plasticity on inhibitory neurons, especially plasticity at I to I synapses. We have explained this result as new supplementary Figure7 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>The use of a Poisson spiking neuron model is the second major weakness of the study. A chief challenge in much of the cited work is to generate stochastic transitions from recurrent networks of deterministic neurons. The task the authors set out to do is much easier with stochastic neurons; it is reasonable that the network succeeds in reproducing Markovian sequences, given an appropriate learning rule. I believe that the main point comes from mapping abstract Markov states to assemblies of neurons. If I am right, I missed more analyses on this point, for instance on the impact that varying cell assembly size would have on the findings reported by the authors.</p>
</disp-quote>
<p>The reviewer’s understanding is correct. Our main point comes from mapping Markov statistics to replays of cell assemblies. In the revised manuscript, we performed additional simulations to ask whether varying the size of the cell assemblies would affect learning. We ran simulations with two different configurations in the task shown in Figure 2. The first configuration used three assemblies with a size ratio of 1:1.5:2. After training, these assemblies exhibited transition statistics that closely matched those of the evoked activity (Supplementary Fig.4a,b). In contrast, the second configuration, which used a size ratio of 1:2:3, showed worse performance compared to the 1:1.5:2 case (Supplementary Fig.4c,d). These results suggest that the model can learn appropriate transition statistics as long as the size ratio of the assemblies is not drastically varied.</p>
<disp-quote content-type="editor-comment">
<p>Finally, it was not entirely clear to me what the main fundamental point in the HVC data section was. Can the findings be roughly explained as follows: if we map syllables to cell assemblies, for high-uncertainty syllable-to-syllable transitions, it becomes harder to predict future neural activity? In other words, is the main point that the HVC encodes syllables by cell assemblies?</p>
</disp-quote>
<p>The reviewer's understanding is correct. We wanted to show that if the HVC learns transition statistics as a replay of cell assemblies, a high-uncertainty syllable-to-syllable transition would make predicting future reactivations more difficult, since trial-averaged activities (i.e., poststimulus activities; PSAs) marginalized all possible transitions in the transition diagram.</p>
<p>(1) Learning in Spiking Neural Assemblies, David Barber, 2002. URL: <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper/2002/file/619205da514e83f869515c782a328d3c-Paper.pdf">https://proceedings.neurips.cc/paper/2002/file/619205da514e83f869515c782a328d3c-Paper.pdf</ext-link></p>
<p>(2) Correlated sequence learning in a network of spiking neurons usingmaximum likelihood, David Barber, Felix Agakov, 2002. URL: <ext-link ext-link-type="uri" xlink:href="http://web4.cs.ucl.ac.uk/staff/D.Barber/publications/barber-agakovTR0149.pdf">http://web4.cs.ucl.ac.uk/staff/D.Barber/publications/barber-agakovTR0149.pdf</ext-link></p>
<disp-quote content-type="editor-comment">
<p><bold>Recommendations for the authors:</bold></p>
<p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p>
<p>In more detail:</p>
<p>A) Theoretical analysis</p>
<p>The plasticity rules in the study are introduced with a vague reference to previous theoretical studies of others. Doing this, one does not provide any formal insight as to why these plasticity rules should enable one to learn to solve the intended task, and whether they are optimal in some respect. This becomes noticeable, especially in the discussion of the importance of inhibitory balance, which does not go into any detail, but rather only states that its required, both in the results and discussion sections. Another unclarity appears when error-based learning is discussed and compared to Hebbian plasticity, which, as you state, &quot;alone is insufficient to learn transition probabilities&quot;. It is not evident how this claim is warranted, nor why error-based plasticity in comparison should be able to perform this (other than referring to the simulation results). Please either clarify formally (or at least intuitively) how plasticity rules result in the mentioned behavior, or alternatively acknowledge explicitly the (current) lack of intuition.</p>
<p>The lack of formal discussion is a relevant shortcoming compared to previous research that showed very similar results with formally more rigorous and principled approaches. In particular, Kappel et al derived explicitly how neural networks can learn to sample from HMMs using STDP and winner-take-all dynamics. Even though this study has limitations, the relation with respect to that work should be made very clear; potentially the claims of novelty of some results (sampling) should be adjusted accordingly. See also Yanping Huang, Rajesh PN Rao (NIPS 2014), and possibly other publications. While it might be difficult to formally justify the learning rules post-hoc, it would be very helpful to the field if you very clearly related your work to that of others, where learning rules have been formally justified, and elaborate on the intuition of how the employed rules operate and interact (especially for inhibition).</p>
<p>Lastly, while the importance of sampling learned transition probabilities is discussed, the discussion again remains on a vague level, characterized by the lack of references in the relevant paragraphs. Ideally, there should be a proof of concept or a formal understanding of how the learned behaviour enables to solve a problem that is not solved by deterministic networks. Please incorporate also the relation to the literature on neural sampling/planning/RL etc. and substantiate the claims with citations.</p>
</disp-quote>
<p>We have included sentences in ll. 691-696 in the revised manuscript to explain that for Poisson spiking neurons, the derived learning rule is equivalent to the one that minimizes the Kullback-Leibler divergence between the distributions of output firing and the dendritic prediction, in our case, the recurrent prediction (Asabuki and Fukai; 2020). Thus, the rule suggests that the recurrent prediction learns the statistical model of the evoked activity, which in turn allows the network to reproduce the learned transition statistics.</p>
<p>We have also added a paragraph to discuss the differences between previously published similar models (e.g., Kappel et al.). Please see our response above.</p>
<disp-quote content-type="editor-comment">
<p>B) Connection to biology</p>
<p>The plasticity rules in the study are introduced with a vague reference to previous theoretical studies of others. Please discuss in more detail if these rules (especially the error-based learning rule) could be implemented biologically and how this could be achieved. Are there connections to biologically observed plasticity? E.g. for error-based plasticity has been discussed in the original publication by Urbanzcik and Senn, or more recently by Mikulasch et al (TINS 2023). The biological plausibility of inhibitory balance has been discussed many times before, e.g. by Vogels and others, and a citation would acknowledge that earlier work. This also leaves the question of how neurons in the songbird experiment could adapt and if the model does capture this well (i.e., do they exhibit E-I balance? etc), which might be discussed as well.</p>
<p>Last, please provide some testable experimental predictions. By proposing an interesting experimental prediction, the model could become considerably more relevant to experimentalists. Also, are there potentially alternative models of stochastic sequence learning (e.g., Kappel et al)? How could they be distinguished? (especially, again, why not Hebbian/STDP learning?)</p>
</disp-quote>
<p>We have cited the Vogels paper to acknowledge the earlier work. We have also included additional paragraphs to discuss a possible biologically plausible implementation of our model and how our model differs from similar models proposed previously (e.g., Kappel et al.). Please see our response above.</p>
<disp-quote content-type="editor-comment">
<p>Other comments</p>
<p>As mentioned, a derivation of recurrent plasticity rules is missing, and parameters are chosen ad-hoc. This leaves the question of how much the results rely on the specific choice of parameters, and how robust they are to perturbations. As a robustness check, please clarify how the duration of the Markov states influences performance. It can be expected that this interacts with the timescale of recurrent connections, so having longer or shorter Markov states, as it would be in reality, should make a difference in learning that should be tested and discussed.</p>
</disp-quote>
<p>We thank the reviewer for pointing this out. To address this point, we performed new simulations and asked to what extent the duration of Markov states affect performance. Interestingly, even when the network was trained with input states of half the duration, the distributions of the durations of assembly reactivations remain almost identical to those in the original case (Supplementary Figure 3a). Furthermore, the transition probabilities in the replay were still consistent with the true transition probabilities (Supplementary Figure 3b). We have also included the derivation of our plasticity rule in ll. 630-670 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Similarly, inhibitory plasticity operates with the same plasticity timescale parameter as excitatory plasticity, but, as the authors discuss, lags behind excitatory plasticity in simulation as in experiment. Is this required or was the parameter chosen such that this behaviour emerges? Please clarify this in the methods section; moreover, it would be good to test if the same results appear with fast inhibitory plasticity.</p>
</disp-quote>
<p>We have performed a new simulation and showed that even when the learning rate of inhibitory plasticity was larger than that of excitatory plasticity, inhibitory plasticity still occurred on a slower timescale than excitatory plasticity. We have included this result in a new Supplementary Figure 2 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>What is the justification (biologically and theoretically) for the memory trace h and its impact on neural spiking? Is it required for the results or can it be left away? Since this seems to be an important and unconventional component of the model, please discuss it in more detail.</p>
</disp-quote>
<p>In the model, it is assumed that each stimulus presentation drives a specific subset of network neurons with a fixed input strength, which avoids convergence to trivial solutions. Nevertheless, we choose to add this dynamic sigmoid function to facilitate stable replay by regulating neuron activity to prevent saturation. We have explained this point in ll.605-611 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<p>I noticed a couple of minor typos:</p>
<p>Page 3 &quot;underly&quot;-&gt;&quot;underlie&quot;</p>
<p>Page 7 &quot;assemblies decreased settled&quot;-&gt;&quot;assemblies decreased and settled&quot;</p>
</disp-quote>
<p>We have modified the text. We thank the reviewer for their careful review.</p>
<disp-quote content-type="editor-comment">
<p>I think Figure 1C is rather confusing and not intuitive.</p>
</disp-quote>
<p>We apologize that the Figure 1C was confusing. In the revised figure, we have emphasized the flow of excitatory and inhibitory error for updating synapses.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p>
<p>One possible path to improve the paper would be to establish a relationship between the proposed learning rules and e.g. the ones derived by Barber.</p>
<p>When reading the paper, I was left with a number of more detailed questions I omitted from the public review:</p>
<p>(1) The authors introduce a dynamic sigmoidal function for excitatory neurons, Eq. 3. This point requires more discussion and analysis. How does this impact the results?</p>
</disp-quote>
<p>In the model, it is assumed that each stimulus presentation drives a specific subset of network neurons with a fixed input strength, which avoids convergence to trivial solutions. Nevertheless, we choose to add this dynamic sigmoid function to facilitate stable replay by regulating neuron activity to prevent saturation. We have explained this point in ll.605-611 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>(2) For Poisson spiking neurons, it would be great to understand what cell assemblies bring (apart from biological realism, i.e., reproducing data where assemblies can be found), compared to self-connected single neurons. For example, how do the results shown in Figure 2 depend on assembly size?</p>
</disp-quote>
<p>We have changed the cell assembly size ratio and how it affects learning performance in a new Supplementary Figure 4. Please see our reply above.</p>
<disp-quote content-type="editor-comment">
<p>(3) The authors focus on modeling spontaneous transitions, corresponding to a highly stochastic generative model (with most transition probabilities far from 1). A complementary question is that of learning to produce a set of stereotypical sequences, with probabilities close to 1. I wondered whether the learning rules and architecture of the model (in particular under the I-to-E rule) would also work in such a scenario.</p>
</disp-quote>
<p>We thank the reviewer for pointing this out. In fact, we had the same question, so we considered a situation in which the setting in Figure 2 includes both cases where the transition matrix is very stochastic (prob=0.5) and near deterministic (prob=0.9).</p>
<disp-quote content-type="editor-comment">
<p>(4) An analysis of what controls the time so that the network stays in a certain state would be welcome.</p>
</disp-quote>
<p>We trained the network model in two cases, one with a fast speed of plasticity and one with a slow speed of plasticity. As a result, we found that the duration of assembly becomes longer in the slow learning case than in the fast case. We have included these results as Supplementary Figure 5 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Regarding the presentation, given that this is a computational modeling paper, I wonder whether *all* the formulas belong in the Methods section. I found myself skipping back and forth to understand what the main text meant, mainly because I missed a few key equations. I understand that this is a style issue that is very much community-dependent, but I think readability would improve drastically if the main model and learning rule equations could be introduced in the main text, as they start being discussed.</p>
</disp-quote>
<p>We thank the reviewer for the suggestion. To cater to a wider audience, we try to explain the principle of the paper without using mathematical formulas as much as possible in the main text.</p>
</body>
</sub-article>
</article>