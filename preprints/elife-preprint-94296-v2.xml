<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">94296</article-id>
<article-id pub-id-type="doi">10.7554/eLife.94296</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.94296.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Decoding contextual influences on auditory perception from primary auditory cortex</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Englitz</surname>
<given-names>Bernhard</given-names>
</name>
<xref ref-type="aff" rid="a1">¹</xref>
<xref ref-type="aff" rid="a2">2</xref>
<email>benglitz@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Akram</surname>
<given-names>Sahar</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Elhilali</surname>
<given-names>Mounya</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Shamma</surname>
<given-names>Shihab</given-names>
</name>
<xref ref-type="aff" rid="a1">¹</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>¹</label><institution>Institute for Systems Research, University of Maryland, College Park</institution>, MD, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Computational Neuroscience Lab, Donders Institute for Brain Cognition and Behavior, Radboud University</institution>, Nijmegen, <country>The Netherlands</country></aff>
<aff id="a3"><label>3</label><institution>Equipe Audition, Ecole Normale Supérieure</institution>, Paris, <country>France</country></aff>
<aff id="a4"><label>4</label><institution>Department of Electrical and Computer Engineering, Johns Hopkins University</institution>, Baltimore, <country>USA</country></aff>
    <aff id="a5"><label>5</label><institution>Research Data Science, Meta Platforms</institution>, <country>United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-04-26">
<day>26</day>
<month>04</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2024-10-22">
<day>22</day>
<month>10</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP94296</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-01-14">
<day>14</day>
<month>01</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-12-24">
<day>24</day>
<month>12</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.12.24.573229"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-04-26">
<day>26</day>
<month>04</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94296.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.94296.1.sa3">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.94296.1.sa2">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.94296.1.sa1">Reviewer #2 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.94296.1.sa0">Reviewer #3 (Public Review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Englitz et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Englitz et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-94296-v2.pdf"/>
<abstract>
<title>Abstract</title><p>Perception can be highly dependent on stimulus context, but whether and how sensory areas encode the context remains uncertain. We used an ambiguous auditory stimulus - a tritone pair - to investigate the neural activity associated with a preceding contextual stimulus that strongly influenced the tritone pair’s perception: either as an ascending or a descending step in pitch.</p>
<p>We recorded single-unit responses from a population of auditory cortical cells in awake ferrets listening to the tritone pairs preceded by the contextual stimulus. We find that the responses adapt locally to the contextual stimulus, consistent with human MEG recordings from the auditory cortex under the same conditions. Decoding the population responses demonstrates that cells responding to pitch-class-changes are able to predict well the context-sensitive percept of the tritone pairs. Conversely, decoding the individual pitch-class representations and taking their distance in the circular Shepard tone space predicts the <italic>opposite</italic> of the percept. The various percepts can be readily captured and explained by a neural model of cortical activity based on populations of adapting, pitch-class and pitch-class-direction cells, aligned with the neurophysiological responses.</p>
<p>Together, these decoding and model results suggest that contextual influences on perception may well be already encoded at the level of the primary sensory cortices, reflecting basic neural response properties commonly found in these areas.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Shepard tones</kwd>
<kwd>bistable stimulus</kwd>
<kwd>ferret</kwd>
<kwd>human</kwd>
<kwd>electrophysiology</kwd>
<kwd>magnetoencephalography</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The revision was based on reviewer comments at the journal eLife. Details can be found on the website of eLife after the Version of Record becomes available.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>In real world scenarios, the elements of the sensory environment do not occur independently [<xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c2">2</xref>]. Temporal, spatial and informational predictability exists within and across modalities, already as a consequence of the basic physical properties, such as spatial and temporal continuity [<xref ref-type="bibr" rid="c3">3</xref>]. Neural systems make efficient use of this inherent predictability of the environment in the form of expectations [<xref ref-type="bibr" rid="c4">4</xref>]. Expectations are valuable, because they provide an internal mechanism to recognize stimuli faster [<xref ref-type="bibr" rid="c5">5</xref>] and more reliably under noisy conditions [<xref ref-type="bibr" rid="c6">6</xref>] with speech being of specific relevance for humans [<xref ref-type="bibr" rid="c7">7</xref>]. As a consequence, the same stimulus can be perceived differently, depending on the context it occurs in, e.g. which stimuli it is preceded by or which stimuli co-occur with it [<xref ref-type="bibr" rid="c8">8</xref>]. We can thus study the expectation underlying a percept by studying the nature of the contextual influence.</p>
<p>Within audition, several forms of contextual influences have been found to shape perception. They range from spatial (e.g. localization in different contexts), to grouping (e.g. ABA sequences, [<xref ref-type="bibr" rid="c9">9</xref>]) and phonetic [<xref ref-type="bibr" rid="c10">10</xref>] contextual influences. A striking example in human communication concerns the perception of certain syllable sequences, such as an ambiguous syllable between /ga/ and /da/ preceded by either /al/ or /ar/. In both, the second syllable is physically identical, but is heard as <italic>/da/</italic> or <italic>/ga/</italic> depending on the preceding syllable [<xref ref-type="bibr" rid="c11">11</xref>]. Subsequent psychoacoustic investigations have revealed that this effect still occurs if the preceding syllable was replaced by appropriately chosen tone sequences, that it persists with substantial silent gaps between the two syllables, and that only very few tones are in fact necessary to bias the percepts one way or another [<xref ref-type="bibr" rid="c10">10</xref>]. Hence, these contextual effects are likely not linguistic in nature, but reflect more basic adaptive neural mechanisms. Different interpretations have been provided to interpret these findings, such as the enhancement of contrasts [<xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c12">12</xref>].</p>
<p>Here, we investigate the neural correlates of these contextual effects using a simplified paradigm, in which the context reliably biases the percept of an <italic>ambiguous</italic> acoustic stimulus: A sequence of two <italic>Shepard</italic> tones [<xref ref-type="bibr" rid="c13">13</xref>], differing by half an octave in the frequencies of its constituent tones, can be perceived as ascending or descending in pitch. Shepard tones are complex tones with octave spaced constituent tones (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). This percept can be reliably manipulated by presenting a suitably chosen sequence of Shepard tones before, setting up different contexts (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). This contextual influence is highly effective, rapidly established and can last for multiple seconds [<xref ref-type="bibr" rid="c14">14</xref>,<xref ref-type="bibr" rid="c15">15</xref>]. Importantly, the ability to determine the changes in pitch has relevance for a wide spectrum of real-world tasks, ranging from distinguishing an approaching from a departing vehicle to distinguishing different emotions in human communication [<xref ref-type="bibr" rid="c16">16</xref>,<xref ref-type="bibr" rid="c17">17</xref>].</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Stimulus design and recording techniques</title><p><bold>A</bold> Shepard tones are acoustic complexes, composed of octave-spaced pure-tones (top). Each Shepard tone is uniquely characterized by its base frequency f<sub>base</sub>, and the difference between two Shepard tones by the difference of their base frequencies f<sub>diff</sub>, usually given in semitones. A Shepard tone shifted by a full octave ‘projects’ onto itself, and is therefore the physically same stimulus. The space of Shepard tones therefore forms a circle (bottom), in which each stimulus can be characterized as a so-called pitch class in semitones, which runs from 0 to 12, corresponding to a full octave. The base pitch class 0 was here chosen to correspond to f<sub>base</sub> = 440Hz. We use the displayed color mapping (hue) throughout the paper.</p><p><bold>B</bold> We used the tritone paradox - a sequence of two Shepard tones - to investigate how ambiguous percepts are resolved, for example by preceding stimuli. In the tritone paradox, two Shepard tones are presented, which are separated by half an octave (6 semitones). Listeners, asked to judge the relative pitch between the two Shepard tones, are ambiguous as to their percept of an ascending or a descending step. If the ambiguous Shepard pair is preceded with a sequence of Shepard tones with pitch classes above the first but below the second tone (red area), listeners report an ascending percept. Conversely, if the ambiguous Shepard pair is preceded by a sequence of Shepard tones with pitch classes below the first, but above the second tone (blue area), listeners perceive a descending step. The neural representation of this contextual influence is not known, and we conducted a series of physiological and psychophysical experiments to elucidate the neural basis.</p><p><bold>C</bold> Neural responses from individual neurons were collected in awake ferrets from the auditory cortex (left). Individual neurons modulated their firing rate during the presentation of the stimulus sequence and exhibited tuned responses (see <xref rid="figs1" ref-type="fig">Fig. S1</xref>). Using MEG recordings, we also collected neural responses from populations of neurons in auditory cortex from human subjects, performing the up/down discrimination task. The amplitude of the magnetic field was modulated as a function of time during the stimulus presentation.</p></caption>
<graphic xlink:href="573229v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We presented various Shepard tone sequences to awake ferrets and humans while simultaneously performing single-unit population recordings using chronically implanted electrode arrays in the left primary auditory cortex, and MEG (magnetoencephalographic) recordings, respectively. Exposure to the contextual sequence resulted in localized adaptation that faded over the time-course of ∼1 s, consistent with stimulus specific adaptation [<xref ref-type="bibr" rid="c12">12</xref>] and with findings from a related human MEG study [<xref ref-type="bibr" rid="c18">18</xref>]. A straight-forward decoding approach demonstrates that the perceived pitch-change direction can be directly related to the contextually adapted activity of direction selective cells, i.e. cells that have a preference for sounds with ascending or descending frequency over time [<xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c20">20</xref>]. Conversely, decoding the represented Shepard tone pitch classes and their respective differences, predicts a repulsive effect, opposite to the perceived direction of pitch change. These underlying neuronal adaptation dynamics are consistent with changes in neural activity in the auditory cortex estimated from human MEG recordings collected for the same sounds.</p>
<p>We can account for these effects in a simplified model of the cortical representation based on known properties of pitch-class-change selective cells, which matches both the results from the directional- and the distance-decoding analysis. Further, the model is consistent with multiple observed properties of the neural representation, including tuning changes and directional tuning of individual neurons as well as the build-up of the contextual effect in humans.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>We collected neural recordings from 7 awake ferrets (662 responsive, tuned single units) and from 16 humans (MEG recordings) in response to sequences of Shepard tones (the ‘Bias’) followed by an ambiguous, semi-octave separated test pair (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). The human participants performed a 2-alternative forced choice task, selecting between hearing an ascending or descending step in the test pair, while ferrets listened passively. It has been previously shown [<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c18">18</xref>] that the presence of the Bias reliably influences human perception, towards hearing a pitch step ’bridging’ the location of the Bias, i.e. if the Bias is located above the first tone an ascending step is heard (<xref rid="fig1" ref-type="fig">Fig. 1B</xref> middle), and a descending one, if it is below (<xref rid="fig1" ref-type="fig">Fig. 1B</xref> bottom). The present study investigates the neural representation underlying these modified percepts. In the following, we first show that the bias sequence induces a local adaptation in the neural population activity in both passive (ferret) and active (human) condition (<xref rid="fig2" ref-type="fig">Fig. 2</xref>, see Discussion for more details). Next, we demonstrate the effect of this adaptation on the stimulus representation by decoding the neural population response. We find a repulsive influence of the Bias sequence on the pitch classes in the pair, i.e. the pitch class of each Shepard tone shifts away from the Bias. This increases their distance in pitch class along the perceived direction (<xref rid="fig3" ref-type="fig">Fig. 3</xref>) and is thus not compatible with a simple, pitch (class)-distance based decoder as an explanation of the directionality percept (<xref rid="fig4" ref-type="fig">Fig. 4</xref>). We then provide a simplified model of neuronal activity in auditory cortex that captures both the population representation and the adaptive changes in tuning of individual cells (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). Finally, based on this model, we provide an alternative explanation for the directionality percept of the ambiguous pair by showing that the adaptation pattern of directional cells predicts the percept (<xref rid="fig6" ref-type="fig">Fig. 6</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Neural responses adapt locally during the Bias sequence for awake ferrets (top) and behaving humans (bottom).</title><p><bold>A1</bold> During the presentation of the Bias sequence (10 tones, black bars), the neural response adapts over time (individual cell). This adaptation occurs for all parts of the response, shown here is the onset part (0-50 ms, black). See <xref rid="figs1" ref-type="fig">Fig. S1</xref> for more details on the different response types. Errorbars denote 2 SEM across trials.</p><p><bold>A2</bold> On the population level, the response reaches an adapted plateau 13% below the initial response after about 5 stimuli (τ=3.9 stimuli, also for the onset response). This rate of reduction is similar to the rate of build-up of perceptual influence in human behavior [<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c18">18</xref>]. Errorbars denote 2 SEM across neurons.</p><p><bold>A3</bold> After the Bias the activity of the cells is significantly more reduced (<bold>Δ</bold>=33%, p=0.001) around the center or the Bias (&lt;2.5 semitones from the center) compared to the edges (2.5-3 semitones from the center). Errorbars denote 2 SEM across neurons.</p><p><bold>A4</bold> Recovery of spontaneous neural firing rates from the adaptation due to the Bias sequence progressed over multiple seconds with an exponential recovery time-constant of 1.2 s.</p><p><bold>B1</bold> In human auditory cortex the Bias sequences also evoked an adapting sequence of responses, here shown is the activity for a single subject (#8). Errorbars denote 2 SEM across trials.</p><p><bold>B2</bold> On average, the adaptation of the neural response proceeded with a similar time course as the single-unit response (A2), and plateaus after about 3-4 stimuli. Errorbars denote 2 SEM across subjects.</p><p><bold>B3</bold> Following the Bias, the activity state of the cortex is probed with a sequence of brief stimuli (35 ms Shepard tones, after 0.5 s silence). Responses to probe tones in the same (red) semi-octave are significantly reduced (21% for the first time window, signed ranks test, p&lt;0.0001) compared to the corresponding response in the opposite semi-octave (blue), indicating a local effect of adaptation. Errorbars denote one SEM across subjects.</p></caption>
<graphic xlink:href="573229v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Repulsive shifts are not consistent with minimal distance hypothesis</title><p><bold>A</bold> In the case of an unbiased Shepard pair, steps of less than 6 pitch classes lead to unambiguous percepts, e.g. a 0st to 3st steps leads to an ascending percept (red) and a 0st to 9st (i.e. 0st =&gt;-3st) step to a descending percept (blue). Semi-octave (0st to 6st, blue/red) steps lead to an ambiguous percept, which strongly depends on the stimulus history [<xref ref-type="bibr" rid="c18">18</xref>] [<xref ref-type="bibr" rid="c15">15</xref>] and even the individual’s specifics, such as language experience and vocal range [<xref ref-type="bibr" rid="c49">49</xref>]. This suggests the <italic>minimal distance hypothesis</italic> which predicts the percept to follow the smaller of the two distances along the circle between the two pitch classes</p><p><bold>B</bold> In the case of an ambiguous Shepard pair (0st to 6st), preceded by a Bias sequence (red bar, right), here an <italic>UP</italic>-Bias, the ascending percept together with the <italic>minimal distance hypothesis</italic> would predict the distance between the Shepard tones to be reduced on the side of the <italic>UP</italic>-Bias (red dots). However, the population decoding shows that the distance between the tones is indeed increased on the side of the <italic>UP</italic>-Bias, challenging the <italic>minimal distance hypothesis</italic>.</p></caption>
<graphic xlink:href="573229v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Population decoding predicts a Bias-induced, repulsive shift in pitch class.</title><p><bold>A</bold> We decoded the represented stimulus using dimensionality reduction techniques (see <xref rid="figs2" ref-type="fig">Fig. S2</xref> for population-vector decoding). The stimulus identity (top) is reflected in the joint activity of all neurons (middle). If the neurons are considered as dimensions of a high-dimensional response space, the circular stimulus space of Shepard tones induces a circular manifold of responses, which lies in a lower dimensional space (light red plane). Colors represent a Shepard tone’s pitch class, also in the following graphs.</p><p><bold>B</bold> The entire set of responses to the 240 distinct Shepard tones (from the various Bias sequences) is projected by the decoding into a low dimensional space (dots, hue = true pitch class), in which neighboring stimuli fall close to each other and the stimuli overall form a circle. The thick, colored line is computed from local averages along the range of pitch classes and emphasizes the circular structure. The Shepard tones in the ambiguous pairs are projected using the same decoder (denoted by the different triangles, hue = true pitch class), and roughly fall into their expected locations. However, if a stimulus was relatively above the Bias sequence (△, bright, upward triangles), their representation is shifted to higher pitch classes, compared to the same stimulus when located relatively below the Bias sequence (▾, dark, downward triangles). Hence, the preceding Bias repulsed the stimuli in the ambiguous pair in their represented pitch class. Both stimuli of the pair are treated equally here.</p><p><bold>C</bold> To demonstrate that decoding in this way is reliable, we compare real and estimated pitch classes (by taking the circular position in B) for each stimulus, which exhibits a reliable relation (r=0.995).</p><p><bold>D</bold> The influence of the Bias can be compared quantitatively by centering the represented test stimuli around their actual pitch class and inspecting the difference between the two different Bias conditions. After the Bias the decoded pitch class is shifted from their actual pitch class away from the biased pitch class range with high significance (p&lt;10<sup>-43</sup>, Wilcoxon-test).</p><p><bold>E</bold> The size of the shift is influenced by the length of the Bias sequence (5 tones = red, 10 tones = black) and the time between the Bias and the test tones (τ=1.1s).</p></caption>
<graphic xlink:href="573229v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Distributed activity &amp; local adaptation predict tuning changes and repulsive shifts</title><p><bold>A</bold> We model the encoding by a simplified model, which starts from the cochlea, includes only one intermediate station (e.g. the MGB), and then projects to cortical neurons. The model is general in the sense that a cascaded version would lead to the same response, as long as similar mechanisms act on each level. A stimulus elicits an activity distribution along the cochlea (bottom) which is retained in shape on the intermediate level (2nd from below). In the native state, the stimulus is transferred to the cortical level without adaptation (2nd from top, black) and integrated by the cortical neuron (top, black). After a stimulus presentation, an adapted trough is left behind in the connections leading up to the cortical level (2nd from top, red), which reduces the cortical tuning curve locally. Since tuning curves closer to the center adapt more strongly, the stimulus representation in the neural population shifts away from the region of adaptation.</p><p><bold>B</bold> Applying the same analysis as above (<xref rid="fig3" ref-type="fig">Fig. 3</xref>) for the real data leads again to a circular decoding (B1), with the estimated pitch classes of the tones the Shepard pair shifted repulsively by the preceding Bias (B2, for more details see the description of <xref rid="fig4" ref-type="fig">Fig. 4</xref>).</p><p><bold>C</bold> Single cells show adaptation of their responses colocalized (different colors) with the biased region (colored bars, bottom). The Bias was presented in 4 different regions in separate trials, and the tuning of the cell probed in between the biasing stimuli. The left side shows a model example and the right side a representative, neural example.</p><p><bold>D</bold> Centered on the Bias, neurons in the auditory cortex adapt their response colocal with the Bias. The curves represent the difference in response rate between the unadapted tuning and the adapted tuning, again for model cells on the left and actual data on the right.</p><p><bold>E</bold> The presence of the Bias reduces the firing rate relative to the initial discharge rate, by ∼40% (red), while the rate stays the same or is slightly elevated outside of the Bias regions (green) (see <xref rid="figs3" ref-type="fig">Fig. S3</xref> for the decoding results and two related, incompatible models, which demonstrate noteworthy subtleties of the decoding process).</p></caption>
<graphic xlink:href="573229v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Decoding based on the directionality of the individual cells predicts the directional percept.</title><p><bold>A</bold> The predicted directional percept <italic>D(S)</italic> for a stimulus <italic>S</italic> is computed by the average over the cells activity <italic>f<sub>i</sub>(S)</italic>, weighted by their directionality <italic>D<sub>i</sub></italic> and their distance to the stimulus <italic>w<sub>i</sub></italic> . The inset images show prototypical <italic>SSTRF</italic>s of cells with the ascending (top, <italic>up</italic>), descending (bottom, <italic>down</italic>) and undirected (middle) directional preference.</p><p><bold>B</bold> Examples three directional cells based on the Shepard tones based spectrotemporal receptive fields (<italic>SSTRF</italic>s). Directionality was determined by the asymmetry of the 2nd column of the <italic>SSTRF</italic> (response to previous stimulus), centered at the maximum (BF) of the first column (response to current stimulus, see Methods for details). As usual, time on the abscissa runs into the past. The middle cell for example is a down-cell, since it responds more strongly to a stimulus sequence 10st =&gt; 7st, than 4st =&gt; 7st based on the <italic>SSTRF</italic>.</p><p>|<bold>C</bold> The prediction of the decoding (ordinate) compared to the usually perceived direction for the two sequences (abscissa). Predictions depended on the length of the sequence (o = 5 tones, <bold>•</bold> = 10 tones) and the predicted tone (red = 1st tone, blue = 2nd tone). The dashed red line corresponds to a flat prediction.</p><p><bold>D</bold> Predictive performance increased as a function of Bias length and distance to the Bias, reflected as 1st (red) or 2nd (blue) tone after the Bias. Both dependencies are consistent with human performance and the build-up and recovery of adaptive processes.</p><p><bold>E</bold> The basis for the directional decoding can be analyzed by considering the entire set of Bias-induced differences in response, arranged by the directional preference of each cell (abscissa), and the location in BF relative to each stimulus in the Shepard pair (ordinate). Applying the analysis to the neural data, the obtained pattern of activity (top) is composed of two angled stripes of positive (red) and negative (blue) differential activity. For cells with BFs close to the pitch class of the test tones, the relative activities are significantly different (p=0.03, 1-way ANOVA) between ascending and descending preferring cells, thus predicting the percept of these tones. Gray boxes indicate combinations of directionality and relative location which did not exist in the cell population.</p><p><bold>F</bold> Applied to a population of model neurons (as in <xref rid="fig5" ref-type="fig">Fig. 5</xref>, see Methods for details) subjected to the same stimulus as the real neurons, in the absence of adaptation (left) no significant pattern emerges. If no directional cells are present (middle), adaptation leads to a distinct pattern for different relative spectral locations, but the lack of directional cells prevents a directional judgment. Finally, with adaptation and directional cells a pattern of differential activation is obtained, similar to the pattern in the neural data. T Cells located close to the target tone (near 0 on the ordinate) show a differential activity, predictive of the percept, which was used in the direct decoding above (shown separately in the lower plots). While these activities exhibit no significant dependence in the absence of adaptation or directional cells, the dependence becomes significantly characteristic with adaptation (p&lt;0.001, 1-way ANOVA, bottom right).</p><p><bold>G</bold> The above results can be summarized as a symmetric imbalance in the activities of directional cells after the Bias around it (right), which when decoded predict steps consistent with the percept, i.e. both are judged in their relative position to the Bias. Hence the percept of the pitch change direction is determined by the local activity, rather than by the circular distance between Shepard tones (<xref rid="fig3" ref-type="fig">Fig. 3</xref>).</p></caption>
<graphic xlink:href="573229v2_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>For simplicity, the term <italic>pitch</italic> is used interchangeably with <italic>pitch class as</italic> only Shepard tones are considered in this study. Pitch (class) is here mainly used as a term to describe the neural responses to Shepard tones, as in previous literature on the topic, and the fact that Shepard tones are composite stimuli that lead to a pitch percept.</p>
<sec id="s2a">
<title>The contextual bias adapts the neural population locally</title>
<p>Adaptation to a stimulus is a ubiquitous phenomenon in neural systems [<xref ref-type="bibr" rid="c21">21</xref>–<xref ref-type="bibr" rid="c23">23</xref>]. Multiple kinds and roles of adaptation have been proposed, ranging from fatigue to adaptation in statistics [<xref ref-type="bibr" rid="c24">24</xref>–<xref ref-type="bibr" rid="c27">27</xref>] to higher-order adaptation [<xref ref-type="bibr" rid="c28">28</xref>,<xref ref-type="bibr" rid="c29">29</xref>]. Since adaptation has previously been implicated in affecting perception, e.g. in the tilt-after effect in vision [<xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c31">31</xref>], we start out by characterizing the adaptation in neural response during and following the Bias under awake (ferrets, single units) and behaving (humans, MEG) conditions. The Bias was matched to the choice from a previous human study ( [<xref ref-type="bibr" rid="c18">18</xref>], see <xref rid="fig1" ref-type="fig">Fig. 1B</xref>), i.e. it consisted of a sequence of 5 or 10 Shepard tones with pitch classes randomly drawn from a range of 5 semitones, symmetrically arranged around a central pitch class, e.g. a Bias sequence centered at 3 semitones had individual tones drawn from 0.5-5.5 semitones. Relative to the ambiguous pairs, there were both an <italic>up</italic>- and a <italic>down</italic>-Bias, positioned above or below the first tone in the ambiguous pair, respectively. In the single unit data the average response strength decreases as a function of the position in the Bias sequence. Cells adapted their onset, sustained and offset response within a few tones in the biasing sequence (<xref rid="fig2" ref-type="fig">Fig. 2</xref> A1). This behavior was observable for the vast majority of cells (91%, p&lt;0.05, Kruskal-Wallis test), and is thus conserved in the grand average (<xref rid="fig2" ref-type="fig">Fig. 2</xref> A2). The adaptation plateaued after about 3-4 stimuli (corresponding to a time-constant of 0.59s) on a level about 13% below the initial level.</p>
<p>The single-unit response strength is reduced locally by the Bias sequence, i.e. more strongly for the range of Shepard tones occuring in the Bias. The responses to the tones in the ambiguous pair (<xref rid="fig2" ref-type="fig">Fig. 2</xref> A3, blue) - which are at the edges of the Bias sequence - are significantly less reduced (33%, p=0.0011, 2 group t-test) compared to within the bias (<xref rid="fig2" ref-type="fig">Fig. 2</xref> A3, blue vs. red), relative to the first responses of the bias. The average response was here compared against the unadapted response of the neurons measured via their Shepard tone tuning curve, collected prior to the Bias experiment (see <xref rid="figs1" ref-type="fig">Fig. S1</xref> for some examples). This difference is enhanced if longer sequences are used and the entire non-biased region is measured (see below).</p>
<p>The response strength remains adapted on the order of one second for single cells. The average spontaneous activity recovered with a time constant of 1.2 s (<xref rid="fig2" ref-type="fig">Fig. 2</xref> A4). The initial buildup before the reduction is probably due to offset responses of some cells.</p>
<p>For the human recordings, we obtained quite similar time-courses and qualitative response progressions. The neural response adapted both for individuals (<xref rid="fig2" ref-type="fig">Fig. 2</xref> B1) and on average (<xref rid="fig2" ref-type="fig">Fig. 2</xref> B2), with slightly faster time-constants (0.69s), which could stem from the lower repetition rate (4 Hz compared to 7 Hz) used in the human experiments, potentially leading to less adaptation. To the contrary though, the amount of adaptation under behaving conditions in humans appears to be more substantial (40%) than for the average single units under awake conditions. While this difference could be partly explained by desynchronization which is typically associated with active behavior or attention [<xref ref-type="bibr" rid="c32">32</xref>], general response adaptation to repeated stimuli is also typical in behaving humans [<xref ref-type="bibr" rid="c33">33</xref>]. However, comparisons between the level of adaptation in MEG and single neuron firing rates may be misleading, due to the differences in the signal measured and subsequent processing.</p>
<p>Similarly to the neuronal data, in the MEG data the responses to probe tones in the same semi-octave (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>3, red) are significantly reduced (21%, signed ranks test, p&lt;0.0001) compared to the corresponding response in the opposite semi-octave (blue). This local reduction is not surprising, given that single neurons in the auditory cortex can be well tuned to Shepard tones, with tuning widths of as little as 2-3 semitones (see <xref rid="figs1" ref-type="fig">Fig. S1E</xref>). The detailed effect adaptation has on individual cells is studied in detail further below. Note, that the term local here could mean that a neuron is adapted in multiple octaves, but this is collapsed into the Shepard tone space.</p>
<p>In summary, both under awake (ferret) and behaving (humans) conditions, we find that neural responses adapt with similar time courses. The adaptation is local in nature, despite the global, i.e. wide-band, nature of the Shepard tones. Together, this suggests that adaptation may play an important role in explaining the effect the Bias sequence has on perceiving the ambiguous Shepard pair. Below we investigate the specific influence of the Bias on the detailed neural representation using the neuronal recordings from the ferret auditory cortex, which cannot be achieved currently with the human MEG data.</p>
</sec>
<sec id="s2b">
<title>The contextual bias repels the ambiguous pair in pitch</title>
<p>Adaptation can have a variety of effects on the represented stimulus attributes (see [<xref ref-type="bibr" rid="c30">30</xref>]): stimulus properties can be attracted, repelled or left unchanged depending on the kind of adaptation. In the present paradigm, one hypothesis to explain the percept would be that <italic>the bias attracts subsequent tones, thus reducing the distance along this side of the pitch-circle</italic>, e.g. an <italic>UP</italic>-Bias would reduce an ambiguous 6 semitone step to a non-ambiguous 5 semitone step (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). To test this hypothesis, we decoded the represented stimulus using various decoding techniques from the neural population.</p>
<p>In population decoding the goal is to estimate a mapping from neural activity to stimulus properties, which assigns a stimulus to the population response. In the present context, this amounts to predicting the pitch class for a given neural response. Several decoding techniques exist which apply different algorithms and start from different assumptions. We here present a dimensionality reduction technique, based on principal component analysis, however, other techniques gave very similar results (e.g. Stochastic Neighborhood Embedding (tSNE, [<xref ref-type="bibr" rid="c34">34</xref>]), or for a population vector decoding, see <xref rid="figs2" ref-type="fig">Fig. S2</xref>).</p>
<p>Decoding techniques based on dimensionality reduction attempt to discover a new coordinate system, which accounts for a substantial portion of the variance within much fewer dimensions (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>). In other words, they estimate a new representation adapted to the intrinsic geometry of the set of neural responses. In the case of Shepard tones, we predict this geometry to be circular (assuming the neural representation is not degenerate), given the circular nature of the Shepard tones (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). As a circular variable can be represented (embedded) in a 2D Euclidean space, we only consider two dimensions of the decoding, typically the first two, if sorted by explained variance.</p>
<p>The projection of the neural data onto the first two principal components, forms indeed a circular arrangement (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>). Each point corresponds to a Shepard tone, with its actual pitch given by its color. The dimensionality reduction was based on the neural responses of 662 neurons to 240 distinct Shepard tones, compiled from the 32 biasing sequences (16 for both sequence lengths, 5 &amp; 10), which covered the octave evenly. The orderly progression of colors indicates that a proximity in stimulus space leads to a proximity in neural response space.</p>
<p>To reassign a pitch class to each point, we estimated a continuous pitch-circle (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>, colorful polygon), by computing the local average of each set of 10 adjacent points (w.r.t. actual pitch) and interpolating in between these points. This decoder produces an excellent mapping between actual and estimated pitch classes on the training set (r=0.995, Pearson correlation, <xref rid="fig4" ref-type="fig">Fig. 4C</xref>). Based on the responses to the Bias sequences, we have thus constructed a decoder of high accuracy.</p>
<p>Next, we apply the decoder to the responses of the Shepard tones in the ambiguous pair to estimate their represented pitch class, and check whether they are represented at their expected pitch class. We find that their pitch classes are shifted <italic>away</italic> from the Bias, i.e. tones in the pair that occur above the Bias are shifted further above (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>/D/E, △, bright, upward triangles), and vice versa (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>/D/E, ▾, dark, downward triangles). This result is highly significant (p=10<sup>-41</sup>, exact ranks test, MATLAB <italic>signrank</italic>) and holds for all tested pitch classes in the pair ([0,3,6,9], <xref rid="fig4" ref-type="fig">Fig. 4D</xref>). The size of the shift increases with the length of the Bias sequence (<xref rid="fig4" ref-type="fig">Fig. 4E</xref>, red: L=5, black: L=10) and decreases with the temporal separation between Bias and ambiguous pair (<xref rid="fig4" ref-type="fig">Fig. 4E</xref>, τ=1.1s). This time constant agrees well with the time course of recovery from adaptation (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>4). The effect size - ranging up to a total of 0.8 semitones - much greater than the human threshold of ∼0.2 semitones for distinguishing two Shepard tones (internal pilot experiment, data not shown). Practically the same result is obtained using population vector decoding instead (<xref rid="figs2" ref-type="fig">Fig. S2</xref>).</p>
<p>Consequently, the presence of the Bias has a <italic>repulsive</italic> effect on the tones in the pair. Therefore their distance increases (when measured on the Shepard pitch circle) on the side of the pitch circle where the Bias was presented, e.g. for a 6 semitone step an <italic>UP</italic>-Bias leads to a represented 7 semitone (or correspondingly -5 semitone) step (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>). Hence, the population decoding suggests that a decoder based on circular distance in pitch <italic>cannot</italic> account for the effect of the Bias on the percept, since this would have predicted the distance to shrink on the side of the Bias.</p>
</sec>
<sec id="s2c">
<title>An SSA-like model accounts for repulsion &amp; local adaptation</title>
<p>Before we can propose an alternative decoder for the directionality percept, we devise a basic neural model which is consistent with both the local nature of the adaptation (<xref rid="fig2" ref-type="fig">Fig. 2</xref>) and the repulsion in pitch (<xref rid="fig4" ref-type="fig">Fig. 4</xref>). This will serve to highlight a few boundary conditions coming from the neural activity and tuning properties that a complete model of the perceptual effect will have to obey. Generally, the model is a 2-layer, tonotopically organized model with spectral integration for both layers and adaptation occurring in the transition from the first to the second layer (see <xref rid="fig5" ref-type="fig">Fig. 5A</xref> for a depiction and Methods for more details).</p>
<p>As detailed below, the Bias not only leads to ’local’ adaptation in the sense of ’cells close to the location of the Bias’, but the adaptation even acts locally within the tuning curve of a given cell (<xref rid="fig5" ref-type="fig">Fig. 5D</xref>, left). Hence, while global, postsynaptic adaptation (fatigue) has been shown to be sufficient in producing a repulsion from the adaptor in decoded stimuli (see <xref rid="figs3" ref-type="fig">Fig. S3</xref>, [<xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c35">35</xref>]), the local reduction of individual tuning curves actually observed in our data requires us to consider non-global adaptation in the model. Adaptation of this type is not unheard of in the auditory cortex, given that another cortical property of stimulus representation - stimulus specific adaptation (SSA, [<xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c36">36</xref>] - is likely to rest on similar mechanisms.</p>
<p>The simplest possibility along these lines is very local adaptation, i.e. specific and limited to each stimulus. While this adaptation could account for the local changes in tuning-curves, it would not predict a repulsion to occur in decoding (<xref rid="figs3" ref-type="fig">Fig. S3</xref> A, see Methods for details on the model implementation). Since this adaptation is assumed to be specific for each stimulus, the population activity for this decoded stimulus would simply be scaled, which would leave the mean and all other moments the same (<xref rid="figs3" ref-type="fig">Fig. S3</xref> A3).</p>
<p>A more biological variant is adaptation that is based on the <italic>internal</italic>, <italic>neural representation of the stimulus</italic> (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>). As the auditory system has non-zero filter-bandwidths, every stimulus elicits a distributed, rather than a perfectly localized activity. At least up to the primary auditory cortex, acoustic stimuli are therefore represented in a distributed manner, in particular in the medial geniculate body (MGB) of the thalamus. If this distribution of activity adapts the corresponding channels locally, the tuning curves of cells in field AI of the primary auditory cortex - which receive forward input from the MGB - will be locally reduced, however, less local than in the point-like representation due to the width of the distribution in its inputs (<xref rid="figs3" ref-type="fig">Fig. S3</xref> C1). On the other hand, decoding of pitches will be repulsive after an adaptor, because cells closer in BF to the adapting stimulus will integrate more adaptation (<xref rid="fig5" ref-type="fig">Fig. 5A</xref> top right), and thus contribute less of their stimulus preference to the decoding. This imbalance shifts the average in the decoded pitch further away (<xref rid="figs3" ref-type="fig">Fig. S3</xref> C3). For simplicity, the adaptation here is attributed to the incoming synaptic connections to AI, yet, it could equally be localized at an earlier or multiple levels.</p>
<p>The models discussed above (<xref rid="figs3" ref-type="fig">Fig. S3</xref>) were implemented non-dynamically to illustrate the interaction between context and different types of adaptation. Based on the aforementioned considerations, we implemented a dynamical rate model including local adaptation and distributed representation (the latter two as in <xref rid="figs3" ref-type="fig">Fig. S3</xref> C3), which receives the identical stimulus sequences as were presented to the real neurons. The dynamical model provides a quantitative match to the adaptation of single cells and the repulsive representation of Shepard tones after the Bias and further allows us to estimate parameters of the underlying processing (<xref rid="fig5" ref-type="fig">Fig. 5B-E</xref>).</p>
<p>First, when subjected to population decoding analysis as for the real data before, the model exhibits a very similar circular representation of the space of Shepard tones (<xref rid="fig5" ref-type="fig">Fig. 5B</xref>1) and repulsive shifts in represented pitch class (<xref rid="fig5" ref-type="fig">Fig. 5B</xref>2). The basis for this representation is analyzed in the following.</p>
<p>Local adaptation in the tuning of individual cells is retained in the model (<xref rid="fig5" ref-type="fig">Fig. 5C</xref>). Individual cells showed adaptation patterns matched in location to the region where the Bias was presented (different colors represent different Bias regions), in comparison to the unbiased tuning curve (gray). Similarly, in the model, the locally implemented adaptation together with the distributed activity in the middle level leads to similarly adapted individual tuning curves.</p>
<p>To study the adaptation in a more standardized way, we computed the pointwise difference between adapted and unadapted tuning curve. These differences were then cocentered with the Bias before averaging (<xref rid="fig5" ref-type="fig">Fig. 5D</xref>). Both for the onset (brown) and the sustained response (red), the reduction is highly local, with steep flanks at the boundaries of the Bias for both the model and the actual data. The offset data appears to show some local reduction but not as sharply defined as the other two.</p>
<p>In order to find the relative reduction, the response rates inside (red lines) and outside (green lines) the biased regions are plotted against the corresponding regions in the unbiased case (<xref rid="fig5" ref-type="fig">Fig. 5E</xref>). While small firing rates appear to be less influenced, a reduction of ∼40% stabilized for higher firing rates, largely independent of the response bin. This analysis can illustrate dependencies on firing rate and prevents degenerate divisions by small firing rates.</p>
<p>The adaptation encapsulated in the model makes only few assumptions, yet provides a qualitatively matched description of the neural behavior in response to the stimulus sequences (w.r.t. the present level of analysis). The model can now be extended to directional cells, to provide a novel explanation for the directionality percept of the biased Shepard pairs.</p>
</sec>
<sec id="s2d">
<title>The contextual Bias differentially adapts directional cells predicting the percept</title>
<p>The decoding techniques used in the previous sections relied only on the cells’ tunings to the <italic>currently</italic> presented Shepard tone. However, cells in the auditory cortex also possess preferences for the <italic>succession of two</italic> (or more) stimuli, e.g. differing in frequency [<xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c37">37</xref>]. We hypothesized that perception of pitch steps could rely on the relative activities of cells preferring ascending and descending steps in frequency, or presently pitch class (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>), instead of the difference in decoded pitch class (as in the <italic>minimal distance hypothesis,</italic> disproven above).</p>
<p>We tested this <italic>directional hypothesis</italic> by decoding the perceived direction more directly by taking the directional preferences of each cell into account (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>). The directional percept is predicted by the population response weighted by each cell’s directionality index (DI) and the distance to the currently presented stimulus (see Methods for details). The DI is computed from the cells’ <italic>SSTRF</italic>s, which are estimated from the sequences of Shepard tones. This approach avoids estimating receptive fields from stimuli with different statistics. Directional cells have asymmetric spectro-temporal receptive fields (<italic>SSTRF</italic>, see <xref rid="fig6" ref-type="fig">Fig. 6B</xref> for some examples): down-selective cells have <italic>SSTRF</italic>s with active zones (red) angled down (from past to future, current time being on the left), up-selective cells the opposite. In both cases the <italic>SSTRF</italic> is dominated by the activity in response to the current stimulus, i.e. the recent past.</p>
<p>The directional decoding successfully predicts the percept for both stimuli in the ambiguous pair. Predictions are performed for each stimulus in the test pair separately. The step direction of the first stimulus is defined based on its relative position to the center of the Bias. For the analysis of the second Shepard tone in the pair, the step is assumed to be perceived on the side of the Bias, i.e. as previously shown in human perception [<xref ref-type="bibr" rid="c15">15</xref>]. Predictions (<xref rid="fig6" ref-type="fig">Fig. 6C</xref>) for the first tone (red) were generally more reliable than for the second tone (blue), and predictions also improved for both tones with the length of the Bias sequence (5 tones = o, 10 tones = •). This dependence of prediction reliability is consistent with the certainty of judgment in human psychophysics [<xref ref-type="bibr" rid="c15">15</xref>]. On average, the prediction was correct in 88% and 95% for the first tone, for a Bias length of 5 and 10 tones, respectively, and 67% and 88% for the second tone, respectively (<xref rid="fig6" ref-type="fig">Fig. 6D</xref>). In summary, the Bias seems to influence the relative activities of up- and down-preferring cells differentially above and below the Bias, such that responses from down-preferring cells prevail below the Bias, and up-preferring cells prevail above the Bias, predicting the human percept correctly.</p>
<p>We next investigate in what way the activities of directional cells are modified by the Bias to generate these perception-matched decodings. In the previous sections, we have seen that rather local adaptation occurs during the Bias and modifies the response properties of a cell. How does this adaptation affect a cell that has a directional-preference? To address this question we distinguish the differential response between the <italic>Up</italic> and <italic>Down</italic> Bias as a function of a cell’s directionality and pitch class separation from the test tone, i.e. Shepard tones in the ambiguous pair. Hence, the analysis (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>/F) plots the difference in response between a preceding <italic>Up</italic>- and <italic>Down</italic>-Bias (specifically: Bias-is-locally-above-tone minus Bias-is-locally-below-tone, color scale), as a function of the cells directional selectivity (abscissa) and the cell’s best pitch class location with respect to each tone (ordinate). For the present analysis, the responses to the first and second tone in the pair were analyzed together. For the second tone, a cell thus contributes also to a second relative-to-tone bin (ordinate) at the same directionality, however, with a different set of responses. Also, each cell contributed for each tone in multiple locations, since multiple target tones (4) were tested in the paradigm.</p>
<p>For the neural data, the differential responses exhibit an angled stripe pattern, formed by a positive and a negative stripe (<xref rid="fig6" ref-type="fig">Fig. 6E</xref> top). The stripes are connected at the top and bottom ends, due to the circularity of the Shepard space. The pattern of differential responses conforms to the <italic>directional hypothesis</italic>, if <italic>down</italic>-cells (left half) are more active than <italic>up</italic>-cells (right half) close to the pair tones (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>, ordinate around 0). This central region was considered here, since these are the cells that will respond most strongly to the tone. For the neural data, this differential activity is significantly dependent on the directionality of the cells (<xref rid="fig6" ref-type="fig">Fig. 6E</xref> bottom, ANOVA, p&lt;0.005).</p>
</sec>
<sec id="s2e">
<title>Extending the neuronal model to directionally sensitive cells</title>
<p>In order to better understand the mechanisms shaping this biasing pattern, the same analysis was applied to neural models including different properties (<xref rid="fig6" ref-type="fig">Fig. 6F</xref>). The same model as in the previous section was used, with the only difference that the tuning of the cells extended in time to include two stimuli instead of only one, comparable to the <italic>SSTRF</italic>s of the actual cells (<xref rid="fig6" ref-type="fig">Fig. 6B</xref>). To illustrate the effect of adaptation, three models are compared: without adaptation (<xref rid="fig6" ref-type="fig">Fig. 6F</xref> left), without directionally tuned cells (<xref rid="fig6" ref-type="fig">Fig. 6F</xref> middle), and with adaptation and directionality tuned cells (<xref rid="fig6" ref-type="fig">Fig. 6F</xref> right).</p>
<p>Without adaptation, the cells do not show a differential response (<xref rid="fig6" ref-type="fig">Fig. 6F</xref> left), since the Bias does not affect the responses in the test pair (Note, that there is a 200 ms pause between the end of the Bias and the test pair, such that the directionality itself cannot explain the pattern of responses). Here, the difference in activity around the current tone is not significant (ANOVA, p=0.5; <xref rid="fig6" ref-type="fig">Fig. 6F</xref> left bottom).</p>
<p>Without directional cells, the pattern reflects only the difference in activity generated by the interaction of the Bias with the adaptation. The lack of directional cells limits the pattern to a small range of directionalities, generated by estimation inaccuracy. Hence, the local pattern of differential response around the test tone is not significantly modulated, due to the lack of directional cells to span the range (ANOVA, p=0.7; <xref rid="fig6" ref-type="fig">Fig. 6F</xref> middle bottom).</p>
<p>In the model with adapting and directional cells, the pattern resembles the angled double stripe pattern from the neural data. The stripes in the pattern are generated by the adaptation, whereas the directionality of the cells leads to the angle of those stripes. Locally around the test tone, this difference shows a statistically significant dependence on the directionality of the cells (ANOVA, p&lt;0.0001; <xref rid="fig6" ref-type="fig">Fig. 6F</xref> right bottom).</p>
<p>The resulting distribution of activities in their relation to the Bias is, hence, symmetric around the Bias (<xref rid="fig6" ref-type="fig">Fig. 6G</xref>). Without prior stimulation, the population of cells is unadapted and thus exhibits balanced activity in response to a stimulus. After a sequence of stimuli, the population is partially adapted (<xref rid="fig6" ref-type="fig">Fig. 6G</xref> right), such that a subsequent stimulus now elicits an imbalanced activity. Translated concretely to the present paradigm, the Bias will locally adapt cells. The degree of adaptation will be stronger, if their tuning curve overlaps more with the biased region. Adaptation in this region should therefore most strongly influence a cell’s response. For example, if one considers two directional cells, an <italic>up-</italic> and a <italic>down-</italic>selective cell, cocentered in the same spectral location below the Bias, then the Bias will more strongly adapt the <italic>up</italic>-cell, which has its dominant, recent part of the <italic>SSTRF</italic> more inside the region of the Bias (<xref rid="fig6" ref-type="fig">Fig. 6G</xref> right). Consistent with the percept, this imbalance predicts the tone to be perceived as a descending step relative to the Bias. Conversely, for the second stimulus in the pair, located above the Bias, the <italic>down</italic>-selective cells will be more adapted, thus predicting an ascending step relative to the previous tone.</p>
<p><italic>In summary</italic>, taking into account the directional selectivities of the population of cells and local neural adaptation, the changes in the directional percept induced by the Bias sequences can be predicted from the neural data. Specifically, the local adaptation of specifically the directionally selective cells caused by the Bias underlies the imbalance in their responses, and thus is likely to be the underlying mechanism of the biase Shepard tones percept.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We have investigated the physiological basis underlying the influence of stimulus history on the perception of pitch-direction, using a bistable acoustic stimulus, pairs of Shepard tones. Stimulus history is found to persist as spectrally-localized adaptation in animal and human recordings, which specifically shapes the activity of direction-selective cells in agreement with the percept. The adaptation’s spectral and temporal properties suggest a common origin with previously described mechanisms, such as stimulus specific adaptation (SSA). Conversely, the typically assumed [<xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c14">14</xref>], but rarely explicitly discussed, circle-distance hypothesis in Shepard tone judgements is in conflict with the repulsive effect on cortically represented pitch revealed presently using different types of population decoding. While our entire study was based on Shepard tones, we hypothesize that the underlying mechanisms will influence many other stimuli as well, although the perceptual salience will depend on the level of ambiguity.</p>
<sec id="s3a">
<title>Relation to previous studies of Shepard tone percepts and their underlying physiology</title>
<p>While context-dependent auditory perception of Shepard tones has been studied previously in humans, we here provide a first account the underlying neurophysiological representation. Previous studies have considered how the stimulus context influences various judgements, e.g. whether subsequent tones influence each other in frequency [<xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c39">39</xref>], whether a sound is continuous [<xref ref-type="bibr" rid="c40">40</xref>] or which of two related phonemes of is perceived [<xref ref-type="bibr" rid="c10">10</xref>]. In the present study, we chose directional judgements, due to the fundamental role frequency-modulations play in the perception of natural stimuli and language. We find the preceding stimulus to locally bias directional cells, such that on a population level the first Shepard tone is perceived as a step downward, and the second tone as a step upward for an UP Bias, and conversely for a DOWN Bias. While the present study cannot directly rule out that the local adaptation occurs before the thalamo-cortical junction, both physiology [<xref ref-type="bibr" rid="c41">41</xref>] and psychophysical (binaural fusion, [<xref ref-type="bibr" rid="c42">42</xref>]) results suggest a location beyond the olivary nuclei.</p>
<p>The success of the directional decoder in linking the cellular activity in A1 to the human percept under the same stimulus conditions is of remarkable accuracy, ∼90%. We would like to emphasize that the use of the directional decoder is equally plausible as the use of a preferred frequency based decoder. In both cases it is assumed that a downstream region in the brain pools the neural responses from A1 assuming either only a frequency preference, or a combination of frequency and direction preference. The elegance of the directional decoder is that it makes a direction connection to well-known directional response characteristics of auditory cortical neurons (see below), while avoiding any mechanisms specific to Shepard tones, such as the computation of the circular distance.</p>
<p>Are these results compatible with the cellular mechanisms that give rise to direction selectivity? The cellular mechanisms underlying the emergence of directional selectivity in the auditory system have been elucidated in recent years using <italic>in-vivo</italic> intracellular recordings [<xref ref-type="bibr" rid="c43">43</xref>–<xref ref-type="bibr" rid="c45">45</xref>]. Two mechanisms have been identified in the auditory cortex, (i) excitatory inputs with different timing and spectral location and (ii) excitatory &amp; inhibitory inputs with different spectral location. In both mechanisms local adaptation by prior stimulation would tend to equalize direction selectivity, by diminishing (i) one excitatory channel or (ii) either the inhibitory or the excitatory channel. The observed changes in response properties under local stimulation are thus compatible with the network mechanisms underlying direction selectivity. This makes the prediction that the presentation of FM-sweeps of one direction should bias subsequent perception to the opposite direction. The timescales tested in these studies [<xref ref-type="bibr" rid="c43">43</xref>,<xref ref-type="bibr" rid="c46">46</xref>] are similar to what was presently used, e.g. Ye et al. (2010) used FM sweeps that lasted for up to 200 ms, which is quite comparable to our SOA of 150 ms. Psychophysical evidence in this respect has been observed previously in terms of threshold shifts of directional perception, which are in agreement with a local bias influencing the directional percept of subsequent stimuli [<xref ref-type="bibr" rid="c47">47</xref>,<xref ref-type="bibr" rid="c48">48</xref>]. More specific adaptation paradigms are required to resolve some of the more detailed effects e.g. local differences across the octave [<xref ref-type="bibr" rid="c48">48</xref>].</p>
<p>Conversely, we could disprove the hypothesis that directional judgements are based on the distance between the tones on the circular Shepard space. Earlier studies on directional judgements of Shepard pairs have - implicitly or explicitly - used the circular nature of the Shepard space to predict the percept [<xref ref-type="bibr" rid="c14">14</xref>,<xref ref-type="bibr" rid="c48">48</xref>,<xref ref-type="bibr" rid="c49">49</xref>], starting from the fundamental work of [<xref ref-type="bibr" rid="c13">13</xref>] The original idea was to construct a stimulus with tonal character but ambiguous pitch, and as such it has interesting applications in the study of pitch perception. However, as presently shown, the percept of directionality does not rest on the circular construction. This conclusion is obtained by decoding the represented pitch of the Shepard tones in the context of different biasing sequences. This analysis demonstrated that the biasing sequence exerts a repulsive rather than an attractive effect on the pitch of following stimuli. Repulsive effects of this kind have been widely investigated in the visual literature, in particular the <italic>tilt after-effect</italic> ([<xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c31">31</xref>,<xref ref-type="bibr" rid="c35">35</xref>,<xref ref-type="bibr" rid="c50">50</xref>,<xref ref-type="bibr" rid="c51">51</xref>], where exposure to a single oriented grating perceptually repels subsequently presented gratings of similar orientation. Repulsive effects have also been described in the auditory perception [<xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c40">40</xref>], but not in auditory physiology. In conclusion, we find the percept to be inconsistent with the increase in the circular distance in the Shepard tone space.</p>
<p>An interesting approach would be to provide a Bayesian interpretation for the effect of the Bias on the cortical representation. Typically an increase in activity is considered as a representation of the prior occurrence probability of stimuli [<xref ref-type="bibr" rid="c52">52</xref>]. Given the local reduction in activity described above, this interpretation would, however, not predict the percept. Alternatively, one could propose to interpret the <italic>negative</italic> deviation, i.e. local adaptation, as the local magnitude of the prior, which could be consistently interpreted with the percept in this paradigm, as has been proposed before [<xref ref-type="bibr" rid="c18">18</xref>]. Recordings from different areas in the auditory cortex might, however, show different characteristics, including a sign inversion.</p>
</sec>
<sec id="s3b">
<title>Relation to other principles of adaptation in audition</title>
<p>Adaptation has been attributed with several functions in sensory processing, ranging from fatigue (adaptation in excitability of spiking), representation of stimulus statistics [<xref ref-type="bibr" rid="c21">21</xref>], compensation for stimulus statistics [<xref ref-type="bibr" rid="c27">27</xref>], sensitization for novel stimuli [<xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c53">53</xref>] and sensory memory [<xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c54">54</xref>]. Adaptation is also present on multiple time-scales, ranging from milliseconds to minutes ([<xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c28">28</xref>,<xref ref-type="bibr" rid="c55">55</xref>]. Based on the time-scales of the stimulus and the task-design, the present experiments mainly revealed adaptation in the range of fractions of a second. Adaptation can be global - in the sense that a neuron responds less to all stimuli - or local - in the sense that adaptation is specific to certain, usually the previously presented stimuli, as in SSA [<xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c56">56</xref>]. Here, adaptation was well confined to the set of stimuli presented before. Hence, the adaptation identified presently is temporally and spectrally well matched to SSA described before. In recent years, the research on SSA has focussed on the aspect of stimulus novelty [<xref ref-type="bibr" rid="c57">57</xref>–<xref ref-type="bibr" rid="c59">59</xref>], as a potential single-cell correlate of mismatch-negativity (MMN) recorded in human EEG and MEG tasks. While the connection between SSA and MMN appears convincing when it comes to some properties, e.g. stimulus frequency, it appears to not transfer in a similar way to other, still primary properties, such as stimulus level or duration, which elicit robust MMN [<xref ref-type="bibr" rid="c60">60</xref>]. The present results reemphasize another putative role of SSA, namely sensory memory. Naturally, adaptation - if it is local - constitutes a ‘negative afterimage’ of the preceding stimulus history. Recent studies in humans suggest a functional role for this adapted state in representing properties of the task. This was recently demonstrated in an auditory delayed match-to-sample task, where a frequency-specific reduction in activity was maintained between the sample and the match ([<xref ref-type="bibr" rid="c61">61</xref>], see also [<xref ref-type="bibr" rid="c62">62</xref>]). Localized adaptation as described presently provides a likely substrate for such a sensory memory trace.</p>
</sec>
<sec id="s3c">
<title>Future directions</title>
<p>While in human perception task engagement is not necessary to be influenced by the biasing sequence, a natural continuation of the present work would be to record from behaving animals. This would allow us to investigate potential differences in neural activity depending on the activity state, and how individual neurons contribute to the decision on a trial-by-trial basis [<xref ref-type="bibr" rid="c63">63</xref>,<xref ref-type="bibr" rid="c64">64</xref>]. Furthermore, the current study was limited to the primary auditory cortex of the ferret, but secondary areas as well as parietal and frontal areas could also be involved and should be explored in subsequent research. Switching to mice as an experimental species would allow us to differentiate the roles of different cell types better [<xref ref-type="bibr" rid="c65">65</xref>]. On the paradigm level, an extension of the time between the end of the Bias sequence and the test pair would be of particular interest in the active condition, where human research suggests that the Bias can persist for more extended times than suggested by the decay properties of the adaptation in the present data set.</p>
</sec>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Experimental Procedures</title>
<p>All animal experiments were performed in accordance with the regulations of the National Institutes of Health and the University of Maryland Institutional Animal Care and Use Committee. All human experiments were performed in accordance with the ethical guidelines of the University of Maryland. We collected single unit recordings from 7 adult, female ferrets (age: 6-12 months, <italic>Mustela putorius furo</italic>) in the awake condition, MEG recordings from 16 human subjects (9 female, average age: 26y, range 23–34 y) and psychophysical recordings from 10 human subjects (5 female, average age: 28y, range 25–32 y).</p>
</sec>
<sec id="s4b">
<title>Surgical Procedures</title>
    <p>A dental cement cap and a headpost were surgically implanted on the animal’s head using sterile procedures, as described previously [<xref ref-type="bibr" rid="c66">66</xref>]. Microelectrode arrays (Microprobes Inc., 32-96 channels, 2.5 MOhm, shaft ø=125 μm, various planar layouts with 0.5mm interelectrode spacing) were surgically implanted in the primary auditory cortex AI at a depth of ∼500 μm, for 2 animals sequentially on both hemispheres. A custom-designed, <ext-link ext-link-type="uri" xlink:href="https://code.google.com/archive/p/edds-array-drive/">chronic drive system</ext-link> was used in some recordings to change the depth of the electrode array.</p>
</sec>
<sec id="s4c">
<title>Physiology : Stimulation &amp; Recording</title>
<p>Acoustic stimuli were generated at 80 kHz using custom written software in MATLAB (The Mathworks, Natick, USA) and presented via a flat calibrated (within +/-5dB in the range 0.1-32 kHz using the inverse impulse response) sound system (amplifier : Crown D75A; speaker: Manger, flat within 0.08-35 kHz). Animals were head-restrained in a standard position in a tube inside a soundproof chamber (mac3, Industrial Acoustics Corporation). The speaker was positioned centrally above the animal’s head and calibration was performed for the animal head’s position during recordings.</p>
<p>Signals were pre-amplified directly on the head (1x or 2x, Blackrock/TBSI) and further amplified (1000x, Plexon Inc.) and bandpass-filtered (0.1-8000 Hz, Plexon Inc.) before digitization ([-5,5]V, 16 bits, 25 kHz, M-series cards, National Instruments) and storage/display using an open-source DAQ system [<xref ref-type="bibr" rid="c67">67</xref>]. Single units were identified using custom written software for spike sorting (for details see [<xref ref-type="bibr" rid="c68">68</xref>]). All subsequent analyses were performed in Matlab.</p>
</sec>
<sec id="s4d">
<title>Magnetoencephalography &amp; Psychophysics : Stimulation, Recording and Data Analysis</title>
<p>Acoustic stimuli were generated at 44.1 kHz using custom written software in MATLAB and presented via a flat calibrated (within +/-5 dB in the range 40–3000 Hz) sound system. During MEG experiments, the sound was delivered to the ear via sound tubing (ER-3A, Etymotic), inserted with foam plugs (ER-3-14) into the ear canal, while during psychophysical experiments an over-the-ear headphone (Sony MDR-V700) was used. While the limited calibration range (due to the sound tubing) is not optimal, it still encompasses &gt;6 octaves/constituent tones for every Shepard tone. Sound stimuli were presented at 70 dBSPL. Magnetoencephalographic (MEG) signals were recorded in a magnetically shielded room (Yokogawa Corp.) using a 160 channel, whole-head system (Kanazawa Institute of Technology, Kanazawa, Japan), with the detection coils (ø = 15.5 mm) arranged uniformly (∼25 mm center-to-center spacing) around the top part of the head. Sensors are configured as first-order axial gradiometers with a baseline of 50 mm, with field sensitivities of &gt;5 fT/Hz in the white noise region. Three of the 160 channels were used as reference channels in noise-filtering methods [<xref ref-type="bibr" rid="c69">69</xref>]. The magnetic signals were band-passed between 1 Hz and 200 Hz, notch filtered at 60 Hz, and sampled at 1 kHz. Finally, the power spectrum was computed and the amplitude at the target rate of 4 Hz was extracted (as in [<xref ref-type="bibr" rid="c70">70</xref>], all magnetic field amplitudes in <xref rid="fig2" ref-type="fig">Fig. 2B</xref> represent this measure).</p>
<p>Subjects had to press one of two buttons (controller held in the right hand, away from the sensors) to indicate an ascending or a descending percept. Subjects listened to 120 stimuli in a block, and completed 3 blocks in a session, lasting ∼1 hour.</p>
</sec>
<sec id="s4e">
<title>Acoustic Stimuli</title>
<p>All stimuli were composed of sequences of Shepard tones. A Shepard tone is a complex tone built as the sum of octave-spaced pure-tones. To stimulate a wide range of neurons, we used a flat envelope, i.e. all constituent tones had the same amplitude. Phases of the constituent tones were randomized for each trial, to prevent any single, fixed phase relationship from influencing the pitch percept. Each Shepard tone was gated with 5 ms sinusoidal ramps at the beginning and end.</p>
<p>A Shepard tone can be characterized by its position in an octave, termed pitch class (in units of semitones), w.r.t. a base-tone. In the present study, the Shepard tone based on 440 Hz was assigned pitch class 0. The Shepard tone with pitch class 1 is one semitone higher than pitch class 0 and pitch class 12 is identical to pitch class 0, since all constituent tones are shifted by an octave and range from inaudibly low to inaudibly high frequencies. Hence, the space of Shepard tones is circular (see <xref rid="fig1" ref-type="fig">Fig. 1B</xref>). Across the entire set of experiments the duration of the Shepard tones was 0.1 s (neural recordings) / 0.125 s (MEG recordings) and the amplitude 70 dB SPL (at the ear).</p>
<p>We used two different stimulus sequences to probe the neural representation of the ambiguous Shepard pairs and their spectral and temporal tuning properties, (i) the Biased Shepard Pair and (ii) the Biased Shepard Tuning:</p>
<p><italic>i) Biased Shepard Pair</italic> In this paradigm, an ambiguous Shepard pair (6 st separation) preceded by a longer sequence of Shepard tones, the Bias (see <xref rid="fig1" ref-type="fig">Fig. 1C</xref>). The Bias consists of a sequence of Shepard tones (lengths: 5 and 10 stimuli) which are within 6 semitones above or below the first Shepard tone in the pair. These biases are called ‘up’ and ‘down’ Bias respectively, as they bias the perception of the ambiguous pair to be ‘ascending’ or ‘descending’, respectively, in pitch [<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c18">18</xref>]. A pause of different length ([0.05,0.2,0.5] s) was inserted between the Bias and the pair, to study the temporal aspects of the neural representation. Altogether we presented 32 different Bias sequences (4 base pitch classes ([0,3,6,9] st), 2 randomizations (pitch classes and position in sequence), 2 Bias lengths ([<xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c10">10</xref>] stimuli), ‘up’ and ‘down Bias), which in total contained 240 distinct Shepard tones. Their individual pitch classes in the Bias were drawn randomly and continuously from their respective range. Each stimulus was repeated 10 times. In all subsequent analyses, neural responses are averages over these repetitions, and all analyses are performed on the pooled data from all animals. For the neural data, these 240 different Shepard tones were also used to obtain a ‘Shepard tone tuning’ for individual cells (see <xref rid="figs1" ref-type="fig">Fig. S1</xref>). The stimulus described above was presented to both animals and humans. The human psychophysical data were only used to reproduce the previous findings by Chambers et al. (2014) with the current parameters. For the MEG recordings, a variation of the biased Shepard pair stimulus was used, which enabled the separate measurement of the activation state in the biased and the unbiased spectral regions. For this purpose a second sequence of Shepard tones (tone duration: 30 ms; SOA: 250 ms; pitch classes: 3 st above or below the tone of the pair) was inserted between the Bias sequence and the Shepard pair, with the time between the two adapted to include the duration of the sequence (2s) and a pause after the Bias sequence ([0.5,1,2] s).</p>
<p><italic>ii) Biased Shepard Tuning</italic> For estimating the changes in the tuning curve of individual neurons, much longer sequences (154 Shepard tones) were presented to a subset of the neurons. The duration and stimulus onset asynchrony was matched to the Bias sequence. The Shepard tones in these sequences were chosen to maintain the influence of the Bias over the entire sequence, while intermittently probing the entire octave of semitones to estimate the overall influence of the Bias on the tuning of neurons. For this purpose, 5/6 (∼83%) of the tones in the sequence were randomly drawn from one of the four Bias regions ([0–5],[3–8],[6–11],[9–2]st), while the 6th tone was randomly drawn from the entire octave, discretized to 24 steps (reminiscent of the studies of [<xref ref-type="bibr" rid="c24">24</xref>]). The 6th tone could thus be used to measure each neurons ’Shepard tuning’ at a resolution of 0.5 semitones, adapted to different Bias locations. To avoid onset effects, a lead-in sequence of 15 Bias tones preceded the first tuning estimation tone. Individual stimulus parameters (intensity, durations of tone and interstimulus interval) were chosen as above. Five pseudorandom sequences were presented for each of the four Bias regions, repeated 6 or more times, providing at least 30 repetitions for each location in the tuning curve (Results of these conditions are shown in <xref rid="fig5" ref-type="fig">Fig. 5</xref>). A randomly varied pause of ∼5 s separated the trials.</p>
</sec>
<sec id="s4f">
<title>Unit Selection</title>
<p>Overall, we recorded from 1467 neurons across all ferrets, out of which 662 were selected for the decoding analysis based on their driven firing rate (i.e. whether they responded significantly to auditory stimulation) and whether they showed a differential response to different Shepard tones. The thresholds for auditory response and tuning to Shepard tones were not very critical: setting the threshold low led to qualitatively the same result, however, with more noise. Setting the thresholds very high, reduced the set of cells included in the analysis, and eventually made the results less stable, as the cells did not cover the entire range of preferences to Shepard tones.</p>
</sec>
<sec id="s4g">
<title>Response Type Analysis</title>
<p>Whether a cell was adapting or facilitating within the Bias sequence was assessed by averaging the responses across all Bias sequences for a given cell separately. The resulting PSTH was then split up into Onset, Sustained and Offset bins, each 50 ms in time, for each stimulus in the Bias. The sequence of response rates was then fitted with an exponential function, and the direction of the adaptation assessed by comparing the initial rate and the asymptotic rate. If the asymptotic rate exceeded the initial rate, a cell was classified as facilitating, conversely as adapting. The three response bins showed similar proportions of adapting response and were thus averaged to assign a single response type to a given cell, as reported in the Results.</p>
</sec>
<sec id="s4h">
<title>Population Decoding</title>
<p>The represented stimuli in the ambiguous pair were estimated from the neural responses by training a decoder on the biasing sequences and then applying the decoder to the neural response of the pair. We used two different decoders to compare their results, one based on dimensionality reduction (PCA, Principal Component Analysis) and one based on a weighted population-vector, which both gave very similar results (see <xref rid="fig4" ref-type="fig">Fig. 4</xref> and S2). For both decoders, we first built a matrix of responses which had the (240) different Shepard tones occuring in all Bias sequences running along one dimension and the neurons along the other dimension.</p>
<p>The PCA decoder performed a linear dimensionality reduction, utilizing the stimuli as examples and the neurons as dimensions of the representation. The data were projected to the first three dimensions, which represented the pitch class as well as the position in the sequence of stimuli (see <xref rid="fig4" ref-type="fig">Fig. 4A</xref> for a schematic). As the position in the Bias sequence was not relevant for the subsequent pitch class decoding, we only focussed on the two dimensions that spanned the pitch circle. A wide range of linear and non-linear dimensionality reduction techniques - e.g. tSNE [<xref ref-type="bibr" rid="c34">34</xref>] - was tested leading to very similar results.</p>
<p>The weighted population decoder was computed by assigning each neuron its best pitch class (i.e. pitch class that evoked the highest response) and then evaluating the firing-rate weighted sum of all neurons’ best pitch classes (see <xref rid="figs2" ref-type="fig">Fig. S2A</xref> for a schematic). Since the stimulus space is circular, this weighted average was performed in the complex domain, where each neuron was represented by a unit vector in the complex plane, with an angle corresponding to the best pitch class. More precisely, this decoder is simply (omitting indices in the following)
<disp-formula>
<graphic xlink:href="573229v2_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>PC<sub>i,best</sub></italic>is the preferred pitch class of a cell and <italic>C</italic> is the set of pitch classes, <italic>f<sub>i</sub>(S</italic>) the firing rate of the neuron <italic>i</italic> for stimulus <italic>S</italic>. In the decoding, firing rate is normalized to the maximal firing rate for each cell, and the preferred pitch class for the empirical frequency of occurrence <italic>P</italic>(<italic>PC<sub>i,best</sub></italic>), to compensate for uneven sampling of preferred pitch classes.</p>
<p>To assign a pitch class to the decoded stimuli of the test pair, we projected them onto the ‘pitch-circle’ formed by the decoded stimuli from the Bias sequences (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>/B). More precisely, we first estimated a coarse pitch circle with 24 steps at a resolution of 0.5 st, by averaging over bins of 10 neighboring pitch classes (partitioning the total of 240 Bias tones). Next, a more finely resolved trajectory through the set of Bias-tones at a resolution of 0.05 st was created by linear interpolation. Then, the pitch class of the test tone was set to the pitch class of the closest point on the trajectory.</p>
<p>For the present purpose the decoder was not cross-validated within the Bias sequence data, because its purpose was to provide a reference for the ambiguous pair stimuli, which were not part of the training set.</p>
</sec>
<sec id="s4i">
<title>Neural modeling</title>
<p>We used rate-based models of neural responses in the auditory cortex to investigate the link between the Bias-induced changes in response characteristic and the population decoding results. These are not trivially related, as different kinds of adaptation can lead to different - repulsive or attractive - effects [<xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c35">35</xref>]. Two types of models were investigated for this purpose:</p>
<p>(i) a <italic>non-dynamic tuning model</italic>, which serves to investigate generally the effect of different types of adaptation on the represented stimuli. This model is detailed in the Supplementary Methods and results are shown in <xref rid="figs3" ref-type="fig">Fig. S3</xref>.</p>
<p>(ii) a <italic>dynamic model</italic>, which serves to use the insights of the non-dynamic model to account in more detail for the neural data. We used the identical stimulus sequences and analyses as for the real data. The structure of the dynamic model corresponded to non-dynamic model (c) (see Supplementary Methods), i.e. a distributed stimulus representation before cortex and local adaptation in the thalamo-cortical synapses and (see <xref rid="fig5" ref-type="fig">Fig. 5A</xref> for a schematic representation of the model). A sampling rate of 20 Hz was used for the simulations to speed up computations. Stimuli were represented as spectrograms - i.e. time-frequency representations - with ’frequency’ being encoded as Shepard tones, i.e. they ranged over one octave and wrapped at the spectral boundaries.</p>
<p>In the mid-level (e.g. MGB) neural representation of the stimulus, each cell’s response was modeled by a peak-normalized <italic>von Mises</italic> distribution for each time t of the filter, i.e. <inline-formula><inline-graphic xlink:href="573229v2_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where <italic>φ</italic> denotes the stimulus, <italic>φ<sub>i</sub></italic> the mean of the distribution <italic>μ</italic> denotes the best pitch class and <italic>σ</italic> the standard deviation, all in semitones. The maximal rate R<sub>max</sub> was arbitrarily set to 1, after normalizing the height to 1 by division via <italic>M</italic><sub>&amp;+&amp;(,</sub>. Hence, the responses on the mid-level <italic>T</italic><sub>j</sub>(<italic>S</italic>(<italic>t</italic>)) of each neuron <italic>j</italic> were modeled as a weighted average of the spectrogram at time <italic>t</italic> with the neuron’s tuning curve
<disp-formula>
<graphic xlink:href="573229v2_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
On the top-level, corresponding to auditory cortex, the activity of each neuron was modeled as a spectrotemporal filter on the activity of the mid-level representation with local synaptic depression at the synapses
<disp-formula>
<graphic xlink:href="573229v2_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the <italic>SSTRF<sub>i</sub>(τ</italic>, <italic>j</italic>) is the time-frequency filter for cortical neuron i, weighting the activity of the MGB neurons <italic>j</italic> at times <italic>τ</italic>=0…T before the current time. <italic>SSTRF</italic> stands for Shepard Spectro-Temporal Receptive Field, which is equivalent to a classical STRF [<xref ref-type="bibr" rid="c71">71</xref>], just for Shepard tones. The state of synaptic depression between cortical neuron <italic>i</italic> and thalamic neuron <italic>j</italic> is given by <italic>A<sub>i,j</sub></italic>(<italic>t</italic>). The adaptation was determined by the activity locally present at each synapse and thus led to relatively local changes in the postsynaptic tuning curves. The dynamics of <italic>A<sub>i,j</sub></italic>(<italic>t</italic>) are given by
<disp-formula>
<graphic xlink:href="573229v2_ueqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>F</italic><sub><italic>A</italic></sub> is a constant weighting factor, which scales the amount of adaptation. In both cases the response computed via the <italic>SSTRF</italic> is weighted with the adaptation coefficients <italic>A<sub>PC/G</sub></italic>, and each coefficient recovers by a fraction <italic>F</italic><sub><italic>R</italic></sub> in each step (leading to exponential recovery).</p>
<p>For the final simulations (<xref rid="fig6" ref-type="fig">Fig. 6</xref>), the model was extended to contain a subset of directional cells, by extending the dependence of the <italic>SSTRF</italic> by another 150 ms (3 timesteps at the SR). A directional preference was implemented by adding a von Mises distribution (see above for definition) at the time range 150-250 ms with a peak size of 0.25, roughly matching the observed peak-sizes in the <italic>SSTRF</italic>s of real directional cells. For downward preferring cells the center of the von Mises was placed relatively higher than the best semitone of the cell, and vice versa for upward preferring cells, in each case wrapping at the edges to account for the circularity of the Shepard tone response. The simulated population of 500 cells was split into one third non-directional cells, one third upward selective cells and one third downward selective cells.</p>
</sec>
<sec id="s4j">
<title>Tuning Curve Adaptation Analysis</title>
<p>We estimated the <italic>biased</italic> Shepard tunings from the long stimulus sequences (see Acoustic Stimuli: <italic>Biased Shepard Tuning</italic>) by averaging the test stimuli for each location in the octave (see <xref rid="fig4" ref-type="fig">Fig. 4C</xref>, different colors indicate different locations of the Bias sequence). To get an estimate of the unadapted tuning curve, we collected the initial 5 stimuli from each condition and thus constructed a corresponding tuning curve at a resolution of 1st. To evaluate the influence of the Bias, the local difference (<xref rid="fig5" ref-type="fig">Fig. 5D</xref>) and fraction (<xref rid="fig5" ref-type="fig">Fig. 5E</xref>) between the adapted and the unadapted tuning curve were analyzed. The same analysis was applied to model data generated from the identical stimuli using the same model as above (local adaptation, distributed input on the intermediate level, see Supplementary Methods and <xref rid="figs3" ref-type="fig">Fig. S3C</xref>).</p>
</sec>
<sec id="s4k">
<title>Directionality Analysis</title>
<p>We investigated the effect of the Bias sequence on directionally selective cells. For this purpose, each cell’s directional selectivity was estimated from the steps contained in the biasing sequences. <italic>SSTRF</italic> were approximated by reverse correlating each neuron’s response with the Bias sequences of Shepard tones (using normalized linear regression, three examples are shown in <xref rid="fig6" ref-type="fig">Fig. 6B</xref>). The <italic>SSTRF</italic>s were discretized at 50 ms, and include only the bins during the stimulus, not during the pause.</p>
<p>First, directional preference was assessed by computing the asymmetry in response strength in the second time bin <italic>t</italic><sub>2</sub>, centered on the maximal response in the first time bin, i.e.
<disp-formula>
<graphic xlink:href="573229v2_ueqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Positive values of <italic>DI</italic><sub>⬚</sub>indicate up-ward selective cells and vice versa. The <italic>SSTRF</italic> was first normalized to the maximal value to obtain comparable values between cells.</p>
<p>Second, a cell’s spectral location relative to the test stimulus was determined by computing the distance between a cell’s <italic>SSTRF</italic> center-of-mass and the pitch class of the test tone. These first two steps, located a cell on the x- and y-axis of the following analysis (see <xref rid="fig6" ref-type="fig">Fig. 6C</xref>/D, top).</p>
<p>Third, the difference in response for identical test stimuli with different preceding Bias locations (relative to each tone in the pair) was computed (‘above’ - ‘below’).</p>
<p>Finally, these differences were averaged for all cells with a given directionality and pitch-class relative to the target tone.</p>
<p>This analysis was also applied for the second test-stimulus, which means that each cell contributes to two locations, separated by the semi-octave distance between the two test-tones, however, the contribution was constituted by different (later) responses of the cell. This analysis was conducted both for the actual neural data, as well as for model data. These modeling results were obtained with the same model as above (local adaptation, distributed input on the intermediate level), although adaptation was set to 0 in one condition to demonstrate its role in generating the asymmetry of responses.</p>
</sec>
<sec id="s4l">
<title>Directional Decoder</title>
<p>The decoder above first estimated the neurally represented pitch class of the stimulus and then evaluated the circular distance between the pitch classes for a given ambiguous pair to predict the percept. This approach implicitly assumes that the neural system organizes the neural representations correspondingly and can compute distances in this way. A more general and direct way of assessing whether a given stimulus is relatively higher or lower in pitch than a preceding stimulus may be to integrate the responses of neurons with regards to their directional preference (see previous section). We refer to this as the <italic>directional hypothesis</italic>. Quantitatively, this approach for decoding simply takes estimated direction selectivity <italic>DI</italic> of each cell, and weighs it by its activity, and then sums across all cells. Analogously to decoding based on preferred pitch class, it thus assumes that a downstream decoder in the brain ’knows’ about one or multiple characteristic properties of the cell (e.g. spectral and/or direction selectivity) and combines the activity of many cells in a weighted manner to arrive at a single estimate. We assume that this directionality is evaluated at the location of the current stimulus, i.e. the contribution of each cell is therefore weighted by the distance in preferred pitch class to the pitch class of the currently presented stimulus (see <xref rid="fig6" ref-type="fig">Fig. 6A</xref> for the mathematical structure of the decoding).</p>
</sec>
<sec id="s4m">
<title>Statistical Analysis</title>
<p>Non-parametric tests were used throughout the study to avoid assumptions regarding distributional shape. Single group medians were assessed with the Wilcoxon signed rank test, two group median comparisons with the Mann-Whitney U-test, multiple groups with the Kruskal-Wallis (one-way) and Friedman test (two-way), with post-hoc testing performed using Bonferroni-correction of p-values.ll tests are implemented in the Matlab Statistics Toolbox (The Mathworks, Natick).</p>
</sec>
</sec>
<sec id="d1e1746" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1866">
<label>Sample Shepard Sounds</label>
<media xlink:href="supplements/573229_file02.zip"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>The authors would like to thank Barak Shechter, John Rinzel and Romain Brette for interesting discussions and comments on the manuscript. Funding information: European Research Council (Neume to SS); National Institutes of Health (to MH and SS: U01 AG058532). BE acknowledges funding from an NWO VIDI grant (016.VIDI.189.052) and a NWO ALW Open (ALWOP.146).</p>
</ack>
<sec id="s5">
<title>Supplementary Materials</title>
<sec id="s5a">
<title>Tuning Halfwidth</title>
<p>A neuron’s tuning halfwidth with respect to Shepard tones was estimated using the range of Shepard tones that the firing rate was above f<sub>50%</sub> = (f<sub>Max</sub> - f<sub>Min</sub>)/2. We used a conservative estimation method by determining f<sub>Min</sub> and then computing the range between the closest crossing of f<sub>50%</sub> above and below f<sub>Min</sub>. In this way, neurons with a small difference between f<sub>Max</sub> and f<sub>Min</sub> were assigned comparatively large tuning halfwidths, corresponding to their less salient tuning.</p>
</sec>
<sec id="s5b">
<title>Non-dynamic neural models</title>
<p>In the non-dynamic model each neuron is represented as a <italic>von Mises</italic> distribution
<disp-formula>
<graphic xlink:href="573229v2_ueqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
with two parameters, best pitch class <italic>φ<sub>i</sub></italic> and standard deviation <italic>σ<sub>i</sub></italic>, both measured in semitones, and <italic>M<sub>total</sub></italic>, normalizing the response to an area of 1. We simulate the response of a population of N=100 cortical neurons with <italic>φ<sub>i</sub></italic> equally spaced within [0,12] st. The models were run at the same sampling rate (20Hz) as the data analysis for consistency.</p>
<p>The influence of the Bias is modeled assuming an idealized, continuous range of Biases, rather than individual tones. We consider three different models of adaptation: (a) local adaptation (<xref rid="figs3" ref-type="fig">Fig. S3</xref> A) (b) global adaptation (<xref rid="figs3" ref-type="fig">Fig. S3</xref> B), and (c) local adaptation with spreaded representation (<xref rid="figs3" ref-type="fig">Fig. S3</xref> C):</p>
<p>a) <bold>Local adaptation</bold> refers to a multiplicative reduction of responses to individual stimuli, based on the local, recent stimulus history. The amount of local adaptation is taken as the prominence of this stimulus in the recent history, i.e.
<disp-formula>
<graphic xlink:href="573229v2_ueqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>S<sub>Bias</sub>(φ)</italic> is defined as a function over [0,12] st taking values in [0,1]. <italic>A</italic><sub>5</sub>is the maximal fraction of adaptation, set to 0.8 in Fig.S3. The cells adapted/biased response to a single Shepard tone is then given by
<disp-formula>
<graphic xlink:href="573229v2_ueqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In the more general case of a complex stimulus <italic>S</italic>, one would replace <italic>M<sub>i</sub>(S</italic>) with <italic>M<sub>i</sub>(S</italic>) ∗ <italic>S</italic>, i.e. the convolution of response and stimulus distribution.</p>
<p>This form of local adaptation resembles a highly stimulus specific version of adaptation. Hence, the responses are adapted only to previously presented stimuli, but no transfer to other stimuli occurs (see <xref rid="figs3" ref-type="fig">Fig. S3A</xref>). This type of local adaptation leads to no adaptation, since neurons uniformly reduce their response to the test stimulus, which keeps the mean of the population response the same.</p>
<p>b) <bold>Global adaptation</bold> refers to a multiplicative reduction of the <italic>entire</italic> tuning curve, based on the recent response history, irrespective of which stimulus caused it. The amount of global adaptation is computed as the correlation between a cell’s tuning curve and the stimulus history <italic>S<sub>Bias</sub>(PC)</italic>, i.e.
<disp-formula>
<graphic xlink:href="573229v2_ueqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where * denotes convolution. By the normalization of both <italic>S<sub>Bias</sub></italic> and <italic>R<sub>i</sub></italic>, <italic>A<sub>i</sub></italic> will also be normalized within [0,A<sub>0</sub>]. The cells biased tuning curve to a single Shepard tone is then given by
<disp-formula>
<graphic xlink:href="573229v2_ueqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Global adaptation in this sense captures summarized adaptation effects that occur ‘globally’ for the postsynaptic cell (e.g. a change in excitability which changes the slope of the IF-curve) (see <xref rid="figs3" ref-type="fig">Fig. S3</xref> B). Global adaptation shifts subsequent stimuli away from the adapting stimulus, since neurons close to the adaptor adapt more strongly (Series et al. 2009).</p>
<p>c) <bold>Local adaptation with input spread</bold> combines local adaptation with a distributed neural representation of pointlike stimuli (like a single tone or single Shepard tone), i.e. the stimulus is first represented on an intermediate level (e.g. the MGB) and then integrated on the cortical level, with adaptation occurring locally at the synapses connecting MGB-AI (see <xref rid="fig5" ref-type="fig">Fig. 5A</xref> for an illustration of the architecture). Concretely, the cortical response is given as
<disp-formula>
<graphic xlink:href="573229v2_ueqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Where the intermediate representation <italic>Tj</italic>(<italic>S</italic>)is given as
<disp-formula>
<graphic xlink:href="573229v2_ueqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
i.e. the convolution of the stimulus with the intermediate response properties <italic>M<sub>j</sub></italic>(<italic>φ</italic>) assumed to also be given by <italic>von Mises</italic> distributions as well. The adaptation <italic>A<sub>i</sub>(φ</italic>) is equated with the midlevel activity induced by the bias
<disp-formula>
<graphic xlink:href="573229v2_ueqn13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This form of local adaptation is ‘less local’ than the purely local adaptation described above. Hence, a presentation of a given stimulus will adapt the neural response not only to this stimulus, but - via the distributed representation - also for neighboring stimuli (see <xref rid="figs3" ref-type="fig">Fig. S3</xref> C), which in the decoding leads to repulsive shifts, while reducing tuning curves locally. The resulting shape of the adaptation has been described as a shift in tuning curve combined with a global adaptation (Jin et al. 2005). We propose that the adaptation proposed here provides a simpler explanation for this observed shape of tuning curve change.</p>
<p>Note that the differences in decoding emerge only at the boundaries of the Bias region, depicted by the encoding-decoding matrices in <xref rid="figs3" ref-type="fig">Fig. S3</xref> A3/B3/C3. If the distribution at the vertical line (at 0) has more weight above 0 on the abscissa, this corresponds to a repulsive shift.</p>
<p>In summary, purely local adaptation can account for the local changes in Shepard tunings of the real data, but fails to explain the repulsive decoding (<xref rid="figs3" ref-type="fig">Fig. S3A</xref>). Global adaptation is consistent with the repulsive decoding results, but fails to explain the local tuning curve changes (<xref rid="figs3" ref-type="fig">Fig. S3B</xref>). The combination of local adaptation and distributed input on the intermediate level (Fig.S3C, <xref rid="fig4" ref-type="fig">Fig.4</xref>) is consistent with both the encoding and decoding findings.</p>
</sec>
</sec>
<sec id="nt1">
<title>Note</title>
<p>This reviewed preprint has been updated to correct a typo in an author name.</p>
</sec>
<ref-list>
<title>Reference</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lewicki</surname> <given-names>MS</given-names></string-name></person-group>. <article-title>Efficient coding of natural sounds</article-title>. <source>Nat Neurosci</source>. <year>2002</year>;<volume>5</volume>: <fpage>356</fpage>–<lpage>363</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn831</pub-id></mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smith</surname> <given-names>EC</given-names></string-name>, <string-name><surname>Lewicki</surname> <given-names>MS</given-names></string-name></person-group>. <article-title>Efficient auditory coding</article-title>. <source>Nature</source>. <year>2006</year>;<volume>439</volume>: <fpage>978</fpage>–<lpage>982</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature04485</pub-id></mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname> <given-names>RP</given-names></string-name>, <string-name><surname>Ballard</surname> <given-names>DH</given-names></string-name></person-group>. <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title>. <source>Nat Neurosci</source>. <year>1999</year>;<volume>2</volume>: <fpage>79</fpage>–<lpage>87</lpage>. doi:<pub-id pub-id-type="doi">10.1038/4580</pub-id></mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sohn</surname> <given-names>H</given-names></string-name>, <string-name><surname>Narain</surname> <given-names>D</given-names></string-name>, <string-name><surname>Meirhaeghe</surname> <given-names>N</given-names></string-name>, <string-name><surname>Jazayeri</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Bayesian Computation through Cortical Latent Dynamics</article-title>. <source>Neuron</source>. <year>2019</year>;<volume>103</volume>: <fpage>934</fpage>–<lpage>947.e5.</lpage> doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2019.06.012</pub-id></mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simon</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Craft</surname> <given-names>JL</given-names></string-name></person-group>. <article-title>The effect of prediction accuracy on choice reaction time</article-title>. <source>Mem Cognit</source>. <year>1989</year>;<volume>17</volume>: <fpage>503</fpage>–<lpage>508</lpage>. doi:<pub-id pub-id-type="doi">10.3758/bf03202624</pub-id></mixed-citation></ref>
    <ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lawrance</surname> <given-names>ELA</given-names></string-name>, <string-name><surname>Harper</surname> <given-names>NS</given-names></string-name>, <string-name><surname>Cooke</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Schnupp</surname> <given-names>JWH</given-names></string-name></person-group>. <article-title>Temporal predictability enhances auditory detection</article-title>. <source>J Acoust Soc Am</source>. <year>2014</year>;<volume>135</volume>: <fpage>EL357</fpage>-<lpage>EL363</lpage>. doi:<pub-id pub-id-type="doi">10.1121/1.4879667</pub-id></mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Norris</surname> <given-names>D</given-names></string-name>, <string-name><surname>McQueen</surname> <given-names>JM</given-names></string-name>, <string-name><given-names>Cutler A.</given-names> <surname>Prediction</surname></string-name></person-group>, <article-title>Bayesian inference and feedback in speech recognition</article-title>. <source>Lang Cogn Neurosci</source>. <year>2016</year>;<volume>31</volume>: <fpage>4</fpage>–<lpage>18</lpage>. doi:<pub-id pub-id-type="doi">10.1080/23273798.2015.1081703</pub-id></mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Phillips</surname> <given-names>EAK</given-names></string-name>, <string-name><surname>Schreiner</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Hasenstaub</surname> <given-names>AR</given-names></string-name></person-group>. <article-title>Diverse effects of stimulus history in waking mouse auditory cortex</article-title>. <source>J Neurophysiol</source>. <year>2017</year>;<volume>118</volume>: <fpage>1376</fpage>–<lpage>1393</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00094.2017</pub-id></mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bregman</surname> <given-names>AS</given-names></string-name></person-group>. <source>Auditory Scene Analysis: The Perceptual Organization of Sound</source>. <publisher-name>MIT Press</publisher-name>; <year>1994</year>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holt</surname> <given-names>LL</given-names></string-name></person-group>. <article-title>Temporally nonadjacent nonlinguistic sounds affect speech categorization</article-title>. <source>Psychol Sci</source>. <year>2005</year>;<volume>16</volume>: <fpage>305</fpage>–<lpage>312</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.0956-7976.2005.01532.x</pub-id></mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lotto</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Holt</surname> <given-names>LL</given-names></string-name></person-group>. <article-title>Putting phonetic context effects into context: a commentary on Fowler (2006)</article-title>. <source>Percept Psychophys</source>. <year>2006</year>;<volume>68</volume>: <fpage>178</fpage>–<lpage>183</lpage>. doi:<pub-id pub-id-type="doi">10.3758/bf03193667</pub-id></mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ulanovsky</surname> <given-names>N</given-names></string-name>, <string-name><surname>Las</surname> <given-names>L</given-names></string-name>, <string-name><surname>Nelken</surname> <given-names>I</given-names></string-name></person-group>. <article-title>Processing of low-probability sounds by cortical neurons</article-title>. <source>Nat Neurosci</source>. <year>2003</year>;<volume>6</volume>: <fpage>391</fpage>–<lpage>398</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn1032</pub-id></mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shepard</surname> <given-names>RN</given-names></string-name></person-group>. <article-title>Circularity in Judgments of Relative Pitch</article-title>. <source>J Acoust Soc Am</source>. <year>1964</year>;<volume>36</volume>: <issue>2346</issue>. doi:<pub-id pub-id-type="doi">10.1121/1.1919362</pub-id></mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Repp</surname> <given-names>BH</given-names></string-name></person-group>. <article-title>Spectral envelope and context effects in the tritone paradox</article-title>. <source>Perception</source>. <year>1997</year>;<volume>26</volume>: <fpage>645</fpage>–<lpage>665</lpage>. doi:<pub-id pub-id-type="doi">10.1068/p260645</pub-id></mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chambers</surname> <given-names>C</given-names></string-name>, <string-name><surname>Pressnitzer</surname> <given-names>D</given-names></string-name></person-group>. <article-title>Perceptual hysteresis in the judgment of auditory pitch shift</article-title>. <source>Atten Percept Psychophys</source>. <year>2014</year>;<volume>76</volume>: <fpage>1271</fpage>–<lpage>1279</lpage>. doi:<pub-id pub-id-type="doi">10.3758/s13414-014-0676-5</pub-id></mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chebbi</surname> <given-names>S</given-names></string-name>, <string-name><given-names>Ben</given-names> <surname>Jebara S</surname></string-name></person-group>. <article-title>On the use of pitch-based features for fear emotion detection from speech</article-title>. 2018 <source>4th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP). IEEE</source>; <year>2018</year>. pp. <fpage>1</fpage>–<lpage>6</lpage>. doi:<pub-id pub-id-type="doi">10.1109/ATSIP.2018.8364512</pub-id></mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ethofer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Pourtois</surname> <given-names>G</given-names></string-name>, <string-name><surname>Wildgruber</surname> <given-names>D</given-names></string-name></person-group>. <article-title>Investigating audiovisual integration of emotional signals in the human brain</article-title>. <source>Understanding Emotions. Elsevier</source>; <year>2006</year>. pp. <fpage>345</fpage>–<lpage>361</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0079-6123(06)56019-4</pub-id></mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chambers</surname> <given-names>C</given-names></string-name>, <string-name><surname>Akram</surname> <given-names>S</given-names></string-name>, <string-name><surname>Adam</surname> <given-names>V</given-names></string-name>, <string-name><surname>Pelofi</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sahani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>S</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Prior context in audition informs binding and shapes simple features</article-title>. <source>Nat Commun</source>. <year>2017</year>;<volume>8</volume>: <issue>15027</issue>. doi:<pub-id pub-id-type="doi">10.1038/ncomms15027</pub-id></mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brosch</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schreiner</surname> <given-names>CE</given-names></string-name></person-group>. <article-title>Sequence sensitivity of neurons in cat primary auditory cortex</article-title>. <source>Cereb Cortex</source>. <year>2000</year>;<volume>10</volume>: <fpage>1155</fpage>–<lpage>1167</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/10.12.1155</pub-id></mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brosch</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schulz</surname> <given-names>A</given-names></string-name>, <string-name><surname>Scheich</surname> <given-names>H</given-names></string-name></person-group>. <article-title>Processing of sound sequences in macaque auditory cortex: response enhancement</article-title>. <source>J Neurophysiol</source>. <year>1999</year>;<volume>82</volume>: <fpage>1542</fpage>–<lpage>1559</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.1999.82.3.1542</pub-id></mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fairhall</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Lewen</surname> <given-names>GD</given-names></string-name>, <string-name><surname>Bialek</surname> <given-names>W</given-names></string-name>, <string-name><given-names>de Ruyter</given-names> <surname>Van Steveninck RR</surname></string-name></person-group>. <article-title>Efficiency and ambiguity in an adaptive neural code</article-title>. <source>Nature</source>. <year>2001</year>;<volume>412</volume>: <fpage>787</fpage>–<lpage>792</lpage>. doi:<pub-id pub-id-type="doi">10.1038/35090500</pub-id></mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ulanovsky</surname> <given-names>N</given-names></string-name>, <string-name><surname>Las</surname> <given-names>L</given-names></string-name>, <string-name><surname>Farkas</surname> <given-names>D</given-names></string-name>, <string-name><surname>Nelken</surname> <given-names>I</given-names></string-name></person-group>. <article-title>Multiple time scales of adaptation in auditory cortex neurons</article-title>. <source>J Neurosci</source>. <year>2004</year>;<volume>24</volume>: <fpage>10440</fpage>–<lpage>10453</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1905-04.2004</pub-id></mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clifford</surname> <given-names>CWG</given-names></string-name>, <string-name><surname>Webster</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Stanley</surname> <given-names>GB</given-names></string-name>, <string-name><surname>Stocker</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Kohn</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sharpee</surname> <given-names>TO</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Visual adaptation: neural, psychological and computational aspects</article-title>. <source>Vision Res</source>. <year>2007</year>;<volume>47</volume>: <fpage>3125</fpage>–<lpage>3131</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.visres.2007.08.023</pub-id></mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dean</surname> <given-names>I</given-names></string-name>, <string-name><surname>Harper</surname> <given-names>NS</given-names></string-name>, <string-name><surname>McAlpine</surname> <given-names>D</given-names></string-name></person-group>. <article-title>Neural population coding of sound level adapts to stimulus statistics</article-title>. <source>Nat Neurosci</source>. <year>2005</year>;<volume>8</volume>: <fpage>1684</fpage>–<lpage>1689</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn1541</pub-id></mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dean</surname> <given-names>I</given-names></string-name>, <string-name><surname>Robinson</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Harper</surname> <given-names>NS</given-names></string-name>, <string-name><surname>McAlpine</surname> <given-names>D</given-names></string-name></person-group>. <article-title>Rapid neural adaptation to sound level statistics</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>: <fpage>6430</fpage>–<lpage>6438</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0470-08.2008</pub-id></mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wen</surname> <given-names>B</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>GI</given-names></string-name>, <string-name><surname>Dean</surname> <given-names>I</given-names></string-name>, <string-name><surname>Delgutte</surname> <given-names>B</given-names></string-name></person-group>. <article-title>Time course of dynamic range adaptation in the auditory nerve</article-title>. <source>J Neurophysiol</source>. <year>2012</year>;<volume>108</volume>: <fpage>69</fpage>–<lpage>82</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00055.2012</pub-id></mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Benucci</surname> <given-names>A</given-names></string-name>, <string-name><surname>Saleem</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Carandini</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Adaptation maintains population homeostasis in primary visual cortex</article-title>. <source>Nat Neurosci</source>. <year>2013</year>;<volume>16</volume>: <fpage>724</fpage>–<lpage>729</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.3382</pub-id></mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shechter</surname> <given-names>B</given-names></string-name>, <string-name><surname>Depireux</surname> <given-names>DA</given-names></string-name></person-group>. <article-title>Response adaptation to broadband sounds in primary auditory cortex of the awake ferret</article-title>. <source>Hear Res</source>. <year>2006</year>;<volume>221</volume>: <fpage>91</fpage>–<lpage>103</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.heares.2006.08.002</pub-id></mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rabinowitz</surname> <given-names>NC</given-names></string-name>, <string-name><surname>Willmore</surname> <given-names>BDB</given-names></string-name>, <string-name><surname>Schnupp</surname> <given-names>JWH</given-names></string-name>, <string-name><surname>King</surname> <given-names>AJ</given-names></string-name></person-group>. <article-title>Contrast gain control in auditory cortex</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>70</volume>: <fpage>1178</fpage>–<lpage>1191</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2011.04.030</pub-id></mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seriès</surname> <given-names>P</given-names></string-name>, <string-name><surname>Stocker</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Simoncelli</surname> <given-names>EP</given-names></string-name></person-group>. <article-title>Is the homunculus “aware” of sensory adaptation?</article-title> <source>Neural Comput</source>. <year>2009</year>;<volume>21</volume>: <fpage>3271</fpage>–<lpage>3304</lpage>. doi:<pub-id pub-id-type="doi">10.1162/neco.2009.09-08-869</pub-id></mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kohn</surname> <given-names>A</given-names></string-name>, <string-name><surname>Movshon</surname> <given-names>JA</given-names></string-name></person-group>. <article-title>Adaptation changes the direction tuning of macaque MT neurons</article-title>. <source>Nat Neurosci</source>. <year>2004</year>;<volume>7</volume>: <fpage>764</fpage>–<lpage>772</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn1267</pub-id></mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alishbayli</surname> <given-names>A</given-names></string-name>, <string-name><surname>Tichelaar</surname> <given-names>JG</given-names></string-name>, <string-name><surname>Gorska</surname> <given-names>U</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>MX</given-names></string-name>, <string-name><surname>Englitz</surname> <given-names>B</given-names></string-name></person-group>. <article-title>The asynchronous state’s relation to large-scale potentials in cortex</article-title>. <source>J Neurophysiol</source>. <year>2019</year>;<volume>122</volume>: <fpage>2206</fpage>–<lpage>2219</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00013.2019</pub-id></mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Netser</surname> <given-names>S</given-names></string-name>, <string-name><surname>Zahar</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Gutfreund</surname> <given-names>Y</given-names></string-name></person-group>. <article-title>Stimulus-specific adaptation: can it be a neural correlate of behavioral habituation?</article-title> <source>J Neurosci</source>. <year>2011</year>;<volume>31</volume>: <fpage>17811</fpage>–<lpage>17820</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.4790-11.2011</pub-id></mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maaten</surname> <given-names>LJPVD</given-names></string-name></person-group>, <article-title>Hinton GE</article-title>. <source>Visualizing High-Dimensional Data using t-SNE</source>. <year>2008</year>. pp. <fpage>2579</fpage>– <lpage>2605</lpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jin</surname> <given-names>DZ</given-names></string-name>, <string-name><surname>Dragoi</surname> <given-names>V</given-names></string-name>, <string-name><surname>Sur</surname> <given-names>M</given-names></string-name>, <string-name><surname>Seung</surname> <given-names>HS</given-names></string-name></person-group>. <article-title>Tilt aftereffect and adaptation-induced changes in orientation tuning in visual cortex</article-title>. <source>J Neurophysiol</source>. <year>2005</year>;<volume>94</volume>: <fpage>4038</fpage>–<lpage>4050</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00571.2004</pub-id></mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Parras</surname> <given-names>GG</given-names></string-name>, <string-name><surname>Nieto-Diego</surname> <given-names>J</given-names></string-name>, <string-name><surname>Carbajal</surname> <given-names>GV</given-names></string-name>, <string-name><surname>Valdés-Baizabal</surname> <given-names>C</given-names></string-name>, <string-name><surname>Escera</surname> <given-names>C</given-names></string-name>, <string-name><surname>Malmierca</surname> <given-names>MS</given-names></string-name></person-group>. <article-title>Neurons along the auditory pathway exhibit a hierarchical organization of prediction error</article-title>. <source>Nat Commun</source>. <year>2017</year>;<volume>8</volume>: <fpage>2148</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-017-02038-6</pub-id></mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brosch</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schreiner</surname> <given-names>CE</given-names></string-name></person-group>. <article-title>Time course of forward masking tuning curves in cat primary auditory cortex</article-title>. <source>J Neurophysiol</source>. <year>1997</year>;<volume>77</volume>: <fpage>923</fpage>–<lpage>943</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.1997.77.2.923</pub-id></mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ronken</surname> <given-names>DA</given-names></string-name></person-group>. <article-title>Changes in frequency discrimination caused by leading and trailing tones</article-title>. <source>J Acoust Soc Am</source>. <year>1972</year>;<volume>51</volume>: <fpage>1947</fpage>–<lpage>1950</lpage>. doi:<pub-id pub-id-type="doi">10.1121/1.1913054</pub-id></mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Raviv</surname> <given-names>O</given-names></string-name>, <string-name><surname>Ahissar</surname> <given-names>M</given-names></string-name>, <string-name><surname>Loewenstein</surname> <given-names>Y</given-names></string-name></person-group>. <article-title>How recent history affects perception: the normative approach and its heuristic approximation</article-title>. <source>PLoS Comput Biol</source>. <year>2012</year>;<volume>8</volume>: <fpage>e1002731</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1002731</pub-id></mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Riecke</surname> <given-names>L</given-names></string-name>, <string-name><surname>Micheyl</surname> <given-names>C</given-names></string-name>, <string-name><surname>Vanbussel</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schreiner</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Mendelsohn</surname> <given-names>D</given-names></string-name>, <string-name><surname>Formisano</surname> <given-names>E</given-names></string-name></person-group>. <article-title>Recalibration of the auditory continuity illusion: sensory and decisional effects</article-title>. <source>Hear Res</source>. <year>2011</year>;<volume>277</volume>: <fpage>152</fpage>–<lpage>162</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.heares.2011.01.013</pub-id></mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wehr</surname> <given-names>M</given-names></string-name>, <string-name><surname>Zador</surname> <given-names>AM</given-names></string-name></person-group>. <article-title>Synaptic mechanisms of forward suppression in rat auditory cortex</article-title>. <source>Neuron</source>. <year>2005</year>;<volume>47</volume>: <fpage>437</fpage>–<lpage>445</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2005.06.009</pub-id></mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deutsch</surname> <given-names>D</given-names></string-name></person-group>. <article-title>Paradoxes of musical pitch</article-title>. <source>Sci Am</source>. <year>1992</year>;<volume>267</volume>: <fpage>88</fpage>–<lpage>95</lpage>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ye</surname> <given-names>C</given-names></string-name>, <string-name><surname>Poo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dan</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>X</given-names></string-name></person-group>. <article-title>Synaptic mechanisms of direction selectivity in primary auditory cortex</article-title>. <source>J Neurosci</source>. <year>2010</year>;<volume>30</volume>: <fpage>1861</fpage>–<lpage>1868</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3088-09.2010</pub-id></mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname> <given-names>LI</given-names></string-name>, <string-name><surname>Tan</surname> <given-names>AYY</given-names></string-name>, <string-name><surname>Schreiner</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Merzenich</surname> <given-names>MM</given-names></string-name></person-group>. <article-title>Topography and synaptic shaping of direction selectivity in primary auditory cortex</article-title>. <source>Nature</source>. <year>2003</year>;<volume>424</volume>: <fpage>201</fpage>–<lpage>205</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature01796</pub-id></mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kuo</surname> <given-names>RI</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>GK</given-names></string-name></person-group>. <article-title>The generation of direction selectivity in the auditory system</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>73</volume>: <fpage>1016</fpage>–<lpage>1027</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2011.11.035</pub-id></mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Fleshman</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Wiser</surname> <given-names>PR</given-names></string-name>, <string-name><surname>Versnel</surname> <given-names>H</given-names></string-name></person-group>. <article-title>Organization of response areas in ferret primary auditory cortex</article-title>. <source>J Neurophysiol</source>. <year>1993</year>;<volume>69</volume>: <fpage>367</fpage>–<lpage>383</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.1993.69.2.367</pub-id></mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gardner</surname> <given-names>RB</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>JP</given-names></string-name></person-group>. <article-title>Evidence for direction-specific channels in the processing of frequency modulation</article-title>. <source>J Acoust Soc Am</source>. <year>1979</year>;<volume>66</volume>: <fpage>704</fpage>–<lpage>709</lpage>. doi:<pub-id pub-id-type="doi">10.1121/1.383220</pub-id></mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dawe</surname> <given-names>LA</given-names></string-name>, <string-name><surname>Platt</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Welsh</surname> <given-names>E</given-names></string-name></person-group>. <article-title>Spectral-motion aftereffects and the tritone paradox among Canadian subjects</article-title>. <source>Percept Psychophys</source>. <year>1998</year>;<volume>60</volume>: <fpage>209</fpage>–<lpage>220</lpage>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deutsch</surname> <given-names>D.</given-names></string-name></person-group> <article-title>A Musical Paradox</article-title>. <source>Music Percept</source>. <year>1986</year>;<volume>3</volume>: <fpage>275</fpage>–<lpage>280</lpage>. doi:<pub-id pub-id-type="doi">10.2307/40285337</pub-id></mixed-citation></ref>
    <ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gibson</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Radner</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Adaptation, after-effect and contrast in the perception of tilted lines. I. Quantitative studies</article-title>. <source>J Exp Psychol</source>. <year>1937</year>;<volume>20</volume>: <fpage>453</fpage>–<lpage>467</lpage>. doi:<pub-id pub-id-type="doi">10.1037/h0059826</pub-id></mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kohn</surname> <given-names>A</given-names></string-name></person-group>. <article-title>Visual adaptation: physiology, mechanisms, and functional benefits</article-title>. <source>J Neurophysiol</source>. <year>2007</year>;<volume>97</volume>: <fpage>3155</fpage>–<lpage>3164</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00086.2007</pub-id></mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huys</surname> <given-names>QJM</given-names></string-name>, <string-name><surname>Zemel</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Natarajan</surname> <given-names>R</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Fast population coding</article-title>. <source>Neural Comput</source>. <year>2007</year>;<volume>19</volume>: <fpage>404</fpage>–<lpage>441</lpage>. doi:<pub-id pub-id-type="doi">10.1162/neco.2007.19.2.404</pub-id></mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pérez-González</surname> <given-names>D</given-names></string-name>, <string-name><surname>Malmierca</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Covey</surname> <given-names>E</given-names></string-name></person-group>. <article-title>Novelty detector neurons in the mammalian auditory midbrain</article-title>. <source>Eur J Neurosci</source>. <year>2005</year>;<volume>22</volume>: <fpage>2879</fpage>–<lpage>2885</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1460-9568.2005.04472.x</pub-id></mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jääskeläinen</surname> <given-names>IP</given-names></string-name>, <string-name><surname>Ahveninen</surname> <given-names>J</given-names></string-name>, <string-name><surname>Belliveau</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Raij</surname> <given-names>T</given-names></string-name>, <string-name><surname>Sams</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Short-term plasticity in auditory cognition</article-title>. <source>Trends Neurosci</source>. <year>2007</year>;<volume>30</volume>: <fpage>653</fpage>–<lpage>661</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tins.2007.09.003</pub-id></mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gourévitch</surname> <given-names>B</given-names></string-name>, <string-name><surname>Noreña</surname> <given-names>A</given-names></string-name>, <string-name><surname>Shaw</surname> <given-names>G</given-names></string-name>, <string-name><surname>Eggermont</surname> <given-names>JJ</given-names></string-name></person-group>. <article-title>Spectrotemporal receptive fields in anesthetized cat primary auditory cortex are context dependent</article-title>. <source>Cereb Cortex</source>. <year>2009</year>;<volume>19</volume>: <fpage>1448</fpage>– <lpage>1461</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhn184</pub-id></mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Condon</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Weinberger</surname> <given-names>NM</given-names></string-name></person-group>. <article-title>Habituation produces frequency-specific plasticity of receptive fields in the auditory cortex</article-title>. <source>Behav Neurosci</source>. <year>1991</year>;<volume>105</volume>: <fpage>416</fpage>–<lpage>430</lpage>.</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nelken</surname> <given-names>I</given-names></string-name>, <string-name><surname>Ulanovsky</surname> <given-names>N</given-names></string-name></person-group>. <article-title>Mismatch Negativity and Stimulus-Specific Adaptation in Animal Models</article-title>. <source>J Psychophysiol</source>. <year>2007</year>;<volume>21</volume>: <fpage>214</fpage>–<lpage>223</lpage>. doi:<pub-id pub-id-type="doi">10.1027/0269-8803.21.34.214</pub-id></mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>von der Behrens W, Bäuerle P, Kössl M, Gaese BH</collab></person-group>. <article-title>Correlating stimulus-specific adaptation of cortical neurons and local field potentials in the awake rat</article-title>. <source>J Neurosci</source>. <year>2009</year>;<volume>29</volume>: <fpage>13837</fpage>–<lpage>13849</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3475-09.2009</pub-id></mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bäuerle</surname> <given-names>P</given-names></string-name>, <string-name><surname>von der Behrens</surname> <given-names>W</given-names></string-name>, <string-name><surname>Kössl</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gaese</surname> <given-names>BH</given-names></string-name></person-group>. <article-title>Stimulus-specific adaptation in the gerbil primary auditory thalamus is the result of a fast frequency-specific habituation and is regulated by the corticofugal system</article-title>. <source>J Neurosci</source>. <year>2011</year>;<volume>31</volume>: <fpage>9708</fpage>–<lpage>9722</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.5814-10.2011</pub-id></mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Farley</surname> <given-names>BJ</given-names></string-name>, <string-name><surname>Quirk</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Doherty</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Christian</surname> <given-names>EP</given-names></string-name></person-group>. <article-title>Stimulus-specific adaptation in auditory cortex is an NMDA-independent process distinct from the sensory novelty encoded by the mismatch negativity</article-title>. <source>J Neurosci</source>. <year>2010</year>;<volume>30</volume>: <fpage>16475</fpage>–<lpage>16484</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2793-10.2010</pub-id></mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Linke</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Vicente-Grabovetsky</surname> <given-names>A</given-names></string-name>, <string-name><surname>Cusack</surname> <given-names>R</given-names></string-name></person-group>. <article-title>Stimulus-specific suppression preserves information in auditory short-term memory</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2011</year>;<volume>108</volume>: <fpage>12961</fpage>–<lpage>12966</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1102118108</pub-id></mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rinne</surname> <given-names>T</given-names></string-name>, <string-name><surname>Pekkola</surname> <given-names>J</given-names></string-name>, <string-name><surname>Degerman</surname> <given-names>A</given-names></string-name>, <string-name><surname>Autti</surname> <given-names>T</given-names></string-name>, <string-name><surname>Jääskeläinen</surname> <given-names>IP</given-names></string-name>, <string-name><surname>Sams</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Modulation of auditory cortex activation by sound presentation rate and attention</article-title>. <source>Hum Brain Mapp</source>. <year>2005</year>;<volume>26</volume>: <fpage>94</fpage>–<lpage>99</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hbm.20123</pub-id></mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haefner</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Berkes</surname> <given-names>P</given-names></string-name>, <string-name><surname>Fiser</surname> <given-names>J</given-names></string-name></person-group>. <article-title>Perceptual Decision-Making as Probabilistic Inference by Neural Sampling</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>90</volume>: <fpage>649</fpage>–<lpage>660</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.020</pub-id></mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haefner</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Gerwinn</surname> <given-names>S</given-names></string-name>, <string-name><surname>Macke</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Bethge</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Inferring decoding strategies from choice probabilities in the presence of correlated variability</article-title>. <source>Nat Neurosci</source>. <year>2013</year>;<volume>16</volume>: <fpage>235</fpage>–<lpage>242</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.3309</pub-id></mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Natan</surname> <given-names>RG</given-names></string-name>, <string-name><surname>Rao</surname> <given-names>W</given-names></string-name>, <string-name><surname>Geffen</surname> <given-names>MN</given-names></string-name></person-group>. <article-title>Cortical Interneurons Differentially Shape Frequency Tuning following Adaptation</article-title>. <source>Cell Rep</source>. <year>2017</year>;<volume>21</volume>: <fpage>878</fpage>–<lpage>890</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.celrep.2017.10.012</pub-id></mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fritz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>S</given-names></string-name>, <string-name><surname>Elhilali</surname> <given-names>M</given-names></string-name>, <string-name><surname>Klein</surname> <given-names>D</given-names></string-name></person-group>. <article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title>. <source>Nat Neurosci</source>. <year>2003</year>;<volume>6</volume>: <fpage>1216</fpage>–<lpage>1223</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn1141</pub-id></mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Englitz</surname> <given-names>B</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>, <string-name><surname>Sorenson</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name></person-group>. <article-title>MANTA--an open-source, high density electrophysiology recording suite for MATLAB</article-title>. <source>Front Neural Circuits</source>. <year>2013</year>;<volume>7</volume>: <issue>69</issue>. doi:<pub-id pub-id-type="doi">10.3389/fncir.2013.00069</pub-id></mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Englitz</surname> <given-names>B</given-names></string-name>, <string-name><surname>Tolnai</surname> <given-names>S</given-names></string-name>, <string-name><surname>Typlt</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jost</surname> <given-names>J</given-names></string-name>, <string-name><surname>Rübsamen</surname> <given-names>R</given-names></string-name></person-group>. <article-title>Reliability of synaptic transmission at the synapses of Held in vivo under acoustic stimulation</article-title>. <source>PLoS ONE</source>. <year>2009</year>;<volume>4</volume>: <fpage>e7014</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0007014</pub-id></mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Cheveigné</surname> <given-names>A</given-names></string-name>, <string-name><surname>Simon</surname> <given-names>JZ</given-names></string-name></person-group>. <article-title>Denoising based on time-shift PCA</article-title>. <source>J Neurosci Methods</source>. <year>2007</year>;<volume>165</volume>: <fpage>297</fpage>–<lpage>305</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.06.003</pub-id></mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Elhilali</surname> <given-names>M</given-names></string-name>, <string-name><surname>Xiang</surname> <given-names>J</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Simon</surname> <given-names>JZ</given-names></string-name></person-group>. <article-title>Interaction between attention and bottom-up saliency mediates the representation of foreground and background in an auditory scene</article-title>. <source>PLoS Biol</source>. <year>2009</year>;<volume>7</volume>: <fpage>e1000129</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.1000129</pub-id></mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Depireux</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Simon</surname> <given-names>JZ</given-names></string-name>, <string-name><surname>Klein</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name></person-group>. <article-title>Spectro-temporal response field characterization with dynamic ripples in ferret primary auditory cortex</article-title>. <source>J Neurophysiol</source>. <year>2001</year>;<volume>85</volume>: <fpage>1220</fpage>–<lpage>1234</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.2001.85.3.1220</pub-id></mixed-citation></ref>
</ref-list>
<sec id="s6">
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 1:</label>
<caption><p>Auditory cortex neurons respond tuned to Shepard tones. Three representative neurons are shown, which span the range of observed response types. Neurons differed in their pitch class tuning and their temporal response profiles. The top row depicts the response pattern for 10 repetitions of a fixed Bias sequence, in the bottom row the responses to all presented Shepard tones during the Bias sequences have been sorted by pitch class, much like in a classical pure tone based tuning.</p><p><bold>A</bold> Most cells exhibited an onset type tuning, i.e. a brief response within the first 50ms (orange) each after stimulus onset, but no sustained (red, 50-100ms) or offset response (black, 0-50 ms in the silence after the stimulus). These cells typically showed broad/complex tuning w.r.t. to the pitch class of the stimulus.</p><p><bold>B</bold> A considerable fraction of cells had a surprisingly sharp pitch class tuning, with tuning half-widths of only 2-3 semitones, leading to comparably sparse response patterns. These cells often showed cotuned onset and sustained responses.</p><p><bold>C</bold> The remaining cells exhibited predominant offset pitch class tunings, which showed similarly broad/complex tunings as the onset tuned cells.</p><p><bold>D</bold> Distribution of response types over the entire set of cells.</p><p><bold>E</bold> Tuning halfwidth (f<sub>50%</sub>) for individual cells as a function of pitch class (angle) and response type (colors as in <bold>D</bold>). The radius indicates the halfwidth of the tuning in octaves (see Methods). More precisely tuned cells lie in the center of the circle. This indicates that while many cells were tuned narrowly enough to only be excited by a single constituent tone, many others were excited and/or inhibited by multiple constituent tones of the Shepard tone.</p></caption>
<graphic xlink:href="573229v2_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 2:</label>
<caption><title>Populationvector-based decoding also predicts a repulsive shift in pitch class.</title><p><bold>A</bold> Individual stimuli (top) can also be decoded, by assigning each neuron its preferred pitch class (a complex number, gray vectors, bottom) and weighting these by the neural response (small purple dots, bottom) for the given stimulus. The angle of the average of these vectors (black vectors, bottom) then corresponds to the decoded stimulus (big purple dot, bottom).</p><p><bold>B</bold> As in <xref rid="fig3" ref-type="fig">Fig.3</xref>, the entire set of 240 distinct Shepard tones (from the various Bias sequences) is represented in a lower dimensional space (dots, hue = true pitch class), in which neighboring stimuli fall close to each other and the stimuli overall form a circle. The Shepard tones in the ambiguous pairs are projected using the same decoder (denoted by the different triangles, hue = true pitch class), and roughly fall into their expected locations. As before, if a stimulus was relatively above the Bias sequence (△, bright, upward triangles), their representation is shifted to higher pitch classes, compared to the same stimulus when located relatively below the Bias sequence (▾, dark, downward triangles). Hence, the preceding Bias repulsed the stimuli in the ambiguous pair in their represented pitch class. Both stimuli of the pair are treated equally here.</p><p><bold>C</bold> As before for the dimensionality reduction decoding we compare real and estimated pitch classes (by taking the circular position in B) for each stimulus, which explains &gt;99% of the variance.</p><p><bold>D</bold> The influence of the Bias can be compared quantitatively, by centering the represented test stimuli around their actual pitch class and inspecting the difference between the two different Bias conditions. The Bias shifts them away with high significance (p&lt;10I-43, Wilcoxon-test).</p><p><bold>E</bold> As before, the size of the shift is influenced by the length of the Bias sequence (5 tones = red, 10 tones = black) and the time between the Bias and the test tones (τ=0.92s).</p></caption>
<graphic xlink:href="573229v2_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 3:</label>
<caption><title>Local and global (postsynaptic) adaptation cannot explain both influences of the Bias on the tuning (<bold>A1-C1</bold>) and the represented stimuli (<bold>A2-C2</bold>).</title><p><bold>A</bold> The observed tuning curves could also be obtained if the adaptation was assumed to be strictly local, and no distributed activity in response to a stimulus was considered. In this case, however, no change in stimulus representation is expected (<bold>A2</bold>, below (red) and above (blue) curves are identical), since the local adaptation would reduce the response of each neuron (either multiplicatively or subtractively) and, hence, not changing the center of the represented stimulus.</p><p><bold>B</bold> The repulsive shifts in the represented stimulus could also be obtained, if adaptation was assumed to be global across all inputs, i.e. only on the postsynaptic side, determined by the total postsynaptic activity. In this case, however, tuning curves are predicted to scale, rather than change in shape or position (<bold>B1</bold>). This is inconsistent with the observed changes in tuning curve shape (<xref rid="fig5" ref-type="fig">Fig. 5C-E</xref>).</p><p><bold>C</bold> If local adaptation (either on the synaptic level or in the cells projecting on the present cell) is combined with a distributed activity in the ascending auditory system, sharply adapted tuning curves are obtained as well as a repulsive influence of a preceding sequence of Bias stimuli. In response to a stimulus, both local changes in tuning curves (<bold>C1</bold>) and Bias-repulsed stimulus representation are obtained (<bold>C2</bold>). It should be noted that other models exist which would produce similar results, yet, the present model makes only a limited set of well accepted assumptions and is consistent with the data. <bold>A3-C3</bold> The decoding curves are obtained from the encoding-decoding matrix, which relates the stimulus (abscissa) to the response for each neuron (ordinate). Decoding consists of reading off the population response at the test stimulus (blue vertical line). Here, the Bias below condition is illustrated (red curves in the other plots).</p></caption>
<graphic xlink:href="573229v2_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94296.2.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> study explores the neural basis for a well known auditory illusion, often utilized in movie soundtracks, in which a sequence of two complex tones can be perceived as either rising or falling in pitch depending on the context in which they are presented. <bold>Convincing</bold> single-neuron data and analyses are presented to show that correlates of these pitch-direction changes are found in the ferret primary auditory cortex. While these findings provide an interesting link between cortical activity and perception, the manuscript could be clearer on the wider implications of the failure of traditional decoding models to account for these results.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94296.2.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Previous work demonstrated a strong bias in the percept of an ambiguous Shepard tone as either ascending or descending in pitch, depending on the preceding contextual stimulus. The authors recorded human MEG and ferret A1 single-unit activity during presentation of stimuli identical to those used in the behavioral studies. They used multiple neural decoding methods to test if context-dependent neural responses to ambiguous stimulus replicated the behavioral results. Strikingly, a decoder trained to report stimulus pitch produced biases opposite to the perceptual reports. These biases could be explained robustly by a feed-forward adaptation model. Instead, a decoder that took into account direction selectivity of neurons in the population was able to replicate the change in perceptual bias.</p>
<p>Strengths:</p>
<p>This study explores an interesting and important link between neural activity and sensory percepts, and it demonstrates convincingly that traditional neural decoding models cannot explain percepts. Experimental design and data collection appear to have been executed carefully. Subsequent analysis and modeling appear rigorous. The conclusion that traditional decoding models cannot explain the contextual effects on percepts is quite strong.</p>
<p>Weaknesses:</p>
<p>Beyond the very convincing negative results, it is less clear exactly what the conclusion is or what readers should take away from this study. The presentation of the alternative, &quot;direction aware&quot; models is unclear, making it difficult to determine if they are presented as realistic possibilities or simply novel concepts. Does this study make predictions about how information from auditory cortex must be read out by downstream areas? There are several places where the thinking of the authors should be clarified, in particular, around how this idea of specialized readout of direction-selective neurons should be integrated with a broader understanding of auditory cortex.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94296.2.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This is an elegant study investigating possible mechanisms underlying the hysteresis effect in the perception of perceptually ambiguous Shepard tones. The authors make a fairly convincing case that the adaptation of pitch direction sensitive cells in auditory cortex is likely responsible for this phenomenon.</p>
<p>Strengths:</p>
<p>The manuscript is overall well written. My only slight criticism is that, in places, particularly for non-expert readers, it might be helpful to work a little bit more methods detail into the results section, so readers don't have to work quite so hard jumping from results to methods and back.</p>
<p>The methods seem sound and the conclusions warranted and carefully stated. Overall I would rate the quality of this study as very high, and I do not have any major issues to raise.</p>
<p>Weaknesses:</p>
<p>I think this study is about as good as it can be with the current state of the art. Generally speaking, one has to bear in mind that this is an observational, rather than an interventional study, and therefore only able to identify plausible candidate mechanisms rather than making definitive identifications. However, the study nevertheless represents a significant advance over the current state of knowledge, and about as good as it can be with the techniques that are currently widely available.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94296.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Englitz</surname>
<given-names>Bernhard</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Akram</surname>
<given-names>Sahar</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Elhilali</surname>
<given-names>Mounya</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Shamma</surname>
<given-names>Shihab</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Summary:</p>
<p>Previous work demonstrated a strong bias in the percept of an ambiguous Shepard tone as either ascending or descending in pitch, depending on the preceding contextual stimulus. The authors recorded human MEG and ferret A1 single-unit activity during presentation of stimuli identical to those used in the behavioral studies. They used multiple neural decoding methods to test if context-dependent neural responses to ambiguous stimulus replicated the behavioral results. Strikingly, a decoder trained to report stimulus pitch produced biases opposite to the perceptual reports. These biases could be explained robustly by a feed-forward adaptation model. Instead, a decoder that took into account direction selectivity of neurons in the population was able to replicate the change in perceptual bias.</p>
<p>Strengths:</p>
<p>This study explores an interesting and important link between neural activity and sensory percepts, and it demonstrates convincingly that traditional neural decoding models cannot explain percepts. Experimental design and data collection appear to have been executed carefully. Subsequent analysis and modeling appear rigorous. The conclusion that traditional decoding models cannot explain the contextual effects on percepts is quite strong.</p>
<p>Weaknesses:</p>
<p>Beyond the very convincing negative results, it is less clear exactly what the conclusion is or what readers should take away from this study. The presentation of the alternative, &quot;direction aware&quot; models is unclear, making it difficult to determine if they are presented as realistic possibilities or simply novel concepts. Does this study make predictions about how information from auditory cortex must be read out by downstream areas? There are several places where the thinking of the authors should be clarified, in particular, around how this idea of specialized readout of direction-selective neurons should be integrated with a broader understanding of auditory cortex.</p>
</disp-quote>
<p>While we have not used the term &quot;direction aware&quot;, we think the reviewer refers generally to the capability of our model to use a cell's direction selectivity in the decoding. In accordance with the reviewer's interpretation, we did indeed mean that the decoder assumes that a neuron does not only have a preferred frequency, but also a preferred direction of change in frequency (ascending/descending), which is what we use to demonstrate that the decoding in this way aligns with the human percept. We have adapted the text in several places to clarify this, in particular expanding the description in the Methods substantially.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>The authors aim to better understand the neural responses to Shepard tones in auditory cortex. This is an interesting question as Shepard tones can evoke an ambiguous pitch that is manipulated by a proceeding adapting stimulus, therefore it nicely disentangles pitch perception from simple stimulus acoustics.</p>
<p>The authors use a combination of computational modelling, ferret A1 recordings of single neurons, and human EEG measurements.</p>
<p>Their results provide new insights into neural correlates of these stimuli. However, the manuscript submitted is poorly organized, to the point where it is near impossible to review. We have provided Major Concerns below. We will only be able to understand and critique the manuscript fully after these issues have been addressed to improve the readability of the manuscript. Therefore, we have not yet reviewed the Discussion section.</p>
<p>Major concerns</p>
<p>Organization/presentation</p>
<p>The manuscript is disorganized and therefore difficult to follow. The biggest issue is that in many figures, the figure subpanels often do not correspond to the legend, the main body, or both. Subpanels described in the text are missing in several cases.</p>
</disp-quote>
<p>We have gone linearly through the text and checked that all figure subpanels are referred to in the text and the legend. As far as we can tell, this was already the case for all panels, with the exception of two subpanels of Fig. 5.</p>
<disp-quote content-type="editor-comment">
<p>Many figure axes are unlabelled.</p>
</disp-quote>
<p>We have carefully checked the axes of all panels and all but two (Fig. 5D) were labeled. As is customary, certain panels inherit the axis label from a neighboring panel, if the label is the same, e.g. subpanels in Fig. 6F or Fig. 5E, which helps to declutter the figure. We hope that with this clarification, the reviewer can understand the labels of each panel.</p>
<disp-quote content-type="editor-comment">
<p>There is an inconsistent style of in-text citation between figures and the main text. The manuscript contains typos and grammatical errors. My suggestions for edits below therefore should not be taken as an exhaustive list. I ask the authors to consider the following only a &quot;first pass&quot; review, and I will hopefully be able to think more deeply about the science in the second round of revisions after the manuscript is better organized.</p>
</disp-quote>
<p>While we are puzzled by the severity of issues that R2 indicates (see above, and R3 qualifies it as &quot;well written&quot;, and R1 does not comment on the writing negatively), we have carefully gone through all specific issues mentioned by R2 and the other reviewers. We hope that the revised version of the paper with all corrections and clarifications made will resolve any remaining issues.</p>
<disp-quote content-type="editor-comment">
<p>Frequency and pitch</p>
<p>The terms &quot;frequency&quot; and &quot;pitch&quot; seem to be used interchangeably at times, which can lead to major misconceptions in a manuscript on Shepard tones. It is possible that the authors confuse these concepts themselves at times (e.g. Fig 5), although this would be surprising given their expertise in this field. Please check through every use of &quot;frequency&quot; and &quot;pitch&quot; in this manuscript and make sure you are using the right term in the right place. In many places, &quot;frequency&quot; should actually be &quot;fundamental frequency&quot; to avoid misunderstanding.</p>
</disp-quote>
<p>Thanks for pointing this out. We have checked every occurrence and modified where necessary.</p>
<disp-quote content-type="editor-comment">
<p>Insufficient detail or lack of clarity in descriptions</p>
<p>There seems to be insufficient information provided to evaluate parts of these analysis, most critically the final pitch-direction decoder (Fig 6), which is a major finding. Please clarify.</p>
</disp-quote>
<p>Thanks for pointing this out. We have extended the description of the pitch-direction decoder and highlighted its role for interpreting the results.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public Review):</bold></p>
<p>Summary:</p>
<p>This is an elegant study investigating possible mechanisms underlying the hysteresis effect in the perception of perceptually ambiguous Shepard tones. The authors make a fairly convincing case that the adaptation of pitch direction sensitive cells in auditory cortex is likely responsible for this phenomenon.</p>
<p>Strengths:</p>
<p>The manuscript is overall well written. My only slight criticism is that, in places, particularly for non-expert readers, it might be helpful to work a little bit more methods detail into the results section, so readers don't have to work quite so hard jumping from results to methods and back.</p>
</disp-quote>
<p>Following this excellent suggestion, we have added more brief method sketches to the Results section, hopefully addressing this concern.</p>
<disp-quote content-type="editor-comment">
<p>The methods seem sound and the conclusions warranted and carefully stated. Overall I would rate the quality of this study as very high, and I do not have any major issues to raise.</p>
</disp-quote>
<p>Thanks for your encouraging evaluation of the work.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>I think this study is about as good as it can be with the current state of the art. Generally speaking, one has to bear in mind that this is an observational, rather than an interventional study, and therefore only able to identify plausible candidate mechanisms rather than making definitive identifications. However, the study nevertheless represents a significant advance over the current state of knowledge, and about as good as it can be with the techniques that are currently widely available.</p>
</disp-quote>
<p>Thanks for your encouraging evaluation of our work. The suggestion of an interventional study has also been on our minds, however, this appears rather difficult, as it would require a specific subset of cells to be inhibited. The most suitable approach would likely be 2p imaging with holographic inhibition of a subset of cells (using ArchT for example), that has a preference for one direction of pitch change, which should then bias the percept/behavior in the opposite direction.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p>
<p>MAJOR CONCERNS</p>
<p>(1) What is the timescale used to compute direction selectivity in neural tuning? How does it compare to the timing of the Shepard tones? The basic idea of up versus down pitch is clear, the intuition for the role of direction tuning and its relation to stimulus dynamics could be laid out more clearly. Are the authors proposing that there are two &quot;special&quot; populations of A1 neurons that are treated differently to produce the biased percept? Or is there something specific about the dynamics of the Shepard stimuli and how direction selective neurons respond to them specifically? It would help if the authors could clarify if this result links to broader concepts of dynamic pitch coding in general or if the example reported here is specific (or idiosyncratic) to Shepard tones.</p>
</disp-quote>
<p>We propose that the findings here are not specific to Shepard tones. To the contrary, only basic properties of auditory cortex neurons, i.e. frequency preference, frequency-direction (i.e. ascending or descending) preference, and local adaptation in the tuning curve, suffice. Each of these properties have been demonstrated many times before and we only verified this in the lead-up to the results in Fig. 6. While the same effects should be observable with pure tones, the lack of ambiguity in the perception of direction of a frequency step for pure tone pairs, would make them less noticeable here. Regarding the time-scale of the directional selectivity, we relied on the sequencing of tones in our paradigm, i.e. 150 ms spacing. The SSTRFs were discretized at 50 ms, and include only the bins during the stimulus, not during the pause. The directional tuning, i.e. differences in the SSTRF above and below the preferred pitchclass for stimuli before the last stimulus, typically extended only one stimulus back in time. We have clarified this in more detail now, in particular in the added Methods section on the directional decoder.</p>
<disp-quote content-type="editor-comment">
<p>(2) (p. 9) &quot;weighted by each cell's directionality index ... (see Methods for details)&quot; The direction-selective decoder is interesting and appears critical to the study. However, the details of its implementation are difficult to locate. Maybe Fig. 6A contains the key concepts? It would help greatly if the authors could describe it in parallel with the other decoders in the Methods.</p>
</disp-quote>
<p>We have expanded the description of the decoder in the Methods as the reviewer suggests.</p>
<disp-quote content-type="editor-comment">
<p>LESSER CONCERNS</p>
<p>p. 1. (L 24) &quot;distances between the pitch representations....&quot; It's not obvious what &quot;distances&quot; means without reading the main paper. Can some other term or extra context be provided?</p>
</disp-quote>
<p>We have added a brief description here.</p>
<disp-quote content-type="editor-comment">
<p>p. 2. (L 26) &quot;Shepard tones&quot; Can the authors provide a citation when they first introduce this class of stimuli?</p>
</disp-quote>
<p>Citation has been added.</p>
<disp-quote content-type="editor-comment">
<p>p. 3 (L 4) &quot;direction selective cells&quot; Please define or provide context for what has a direction. Selective to pitch changes in time?</p>
</disp-quote>
<p>Yes, selective to pitch changes in time is what is meant. We have further clarified this in the text.</p>
<disp-quote content-type="editor-comment">
<p>p. 4 (L 9-19). This paragraph seems like it belongs in the Introduction?</p>
</disp-quote>
<p>Given the concerns raised by R2 about the organization of the manuscript we prefer to keep this 'road-map' in the manuscript, as a guidance for the reader.</p>
<disp-quote content-type="editor-comment">
<p>p. 4 (L 32) &quot;majority of cells&quot; One might imagine that the overlap of the bias band and the frequency tuning curve of individual neurons might vary substantially. Was there some criterion about the degree of overlap for including single units in the analysis? Does overlap matter?</p>
</disp-quote>
<p>We are not certain which analysis the reviewer is referring to. Generally, cells were not excluded based on their overlap between a particular Bias band and their (Shepard) tuning curve. There are several reasons for this: The bias was located in 4 different, overlapping Shepard tone regions, and all sounds were Shepard tones. Therefore, all cells overlapped with their (Shepard) tuning curve with one or multiple of the Biases. For decoding analysis, all cells were included as both a response and lack of a response is contributing to the decoding. If the reviewer is referring only to the analysis of whether a cell adapts, then the same argument applies as above, i.e. this was an average over all Bias sequences, and therefore every responding cell was driven to respond by the Bias, and therefore it was possible to also assess whether it adapted its response for different positions inside the Bias. We acknowledge that the limited randomness of the Bias sequences in combination with the specific tuning of the cells could in a few cases create response patterns over time that are not indicative of the actual behavior for repeated stimulation, however, since the results are rather clear with 91% of cells adapting, we do not think this would significantly change the conclusions.</p>
<disp-quote content-type="editor-comment">
<p>p. 5 (L 17) &quot;desynchronization ... behaving conditions&quot; The logic here is not clear. Is less desynchronization expected during behavior? Typically, increased attention is associated with greater desynchronization.</p>
</disp-quote>
<p>Yes, we reformulated the sentence to: While this difference could be partly explained by desynchronization which is typically associated with active behavior or attention [30], general response adaptation to repeated stimuli is also typical in behaving humans [31].</p>
<disp-quote content-type="editor-comment">
<p>p. 7 (L 5) &quot;separation&quot; is this a separation in time?</p>
</disp-quote>
<p>Yes, added.</p>
<disp-quote content-type="editor-comment">
<p>p. 7 (L 33) &quot;local adaptation&quot; The idea of feedforward adaptation biasing encoding has been proposed before, and it might be worth citing previous work. This includes work from Nelken specifically related to SSA. Also, this model seems similar to the one described in Lopez Espejo et al (PLoS CB 2019).</p>
</disp-quote>
<p>Thanks for pointing this out. We think, however, that neither of these publications suggested this very narrow way of biasing, which we consider biologically implausible. We have therefore not added either of these citations.</p>
<disp-quote content-type="editor-comment">
<p>p. 11 (L. 17) The cartoon in Fig. 6G may provide some intuition, but it is quite difficult to interpret. Is there a way to indicate which neuron &quot;votes&quot; for which percept?</p>
</disp-quote>
<p>This is an excellent idea, and we have added now the purported perceptual relation of each cell in the diagram.</p>
<disp-quote content-type="editor-comment">
<p>p. 12 (L. 8). &quot;classically assumed&quot; This statement could benefit from a citation. Or maybe &quot;classically&quot; is not the right word?</p>
</disp-quote>
<p>We have changed 'classically' to 'typically', and now cite classical works from Deutsch and Repp. We think this description makes sense, as the whole concept of bistable percepts has been interpreted as being equidistant (in added or subtracted semitone steps) from the first tone, see e.g. Repp 1997, Fig.2.</p>
<disp-quote content-type="editor-comment">
<p>p. 12 (L. 12) &quot;...previous studies&quot; of Shepard tone percepts? Of physiology?</p>
</disp-quote>
<p>We have modified it to 'Relation to previous studies of Shepard tone percepts and their underlying physiology&quot;, since this section deals with both.</p>
<disp-quote content-type="editor-comment">
<p>p. 12 (L. 25) &quot;compatible with cellular mechanisms...&quot; This paragraph seems key to the study and to Major Concern 1, above. What are the dynamics of the task stimuli? How do they compare with the dynamics of neural FM tuning and previously reported studies of bias? And can the authors be more explicit in their interpretation - should direction selective neurons respond preferentially to the Shepard tone stimuli themselves? And/or is there a conceptual framework where the same neurons inform downstream percepts of both FM sweeps and both normal (unbiased) and biased Shepard tones?</p>
</disp-quote>
<p>The reviewer raises a number of different questions, which we address below:</p>
<p>- Dynamics of the task stimuli in relation to previously reported cellular biasing: The timescales tested in the studies mentioned are similar to what we used in our bias, e.g. Ye et al 2010 used FM sweeps that lasted for up to 200ms, which is quite comparable to our SOA of 150ms.</p>
<p>- Preferred responses to Shepard tones: no, we do not think that there should be preferred responses to Shepard tones, but rather that responses to Shepard tones can be thought of as the combined responses to the constituent tones.</p>
<p>- Conceptual framework where the same neurons inform about FM sweeps and both normal (unbiased) and biased Shepard tones: Our perspective on this question is as follows: To our knowledge, the classical approach to population decoding in the auditory system, i.e. weighted based on preferred frequency, has not been directly demonstrated to be read out inside the brain, and certainly not demonstrated to be read out in only this way in all areas of the brain that receive input from the auditory cortex. Rather it has achieved its credibility by being linked directly with animal performance or match with the presented stimuli. However, these approaches were usually geared towards a representation that can be estimated based on constituent frequencies. Additional response properties of neurons, such as directional selectivity have been documented and analyzed before, however, not been used for explaining the percept. We agree that our use of this cellular response preference in the decoding implicitly assumes that the brain could utilize this as well, however, this seems just as likely or unlikely as the use of the preferred frequency of a neuron. Therefore we do not think that this decoding is any more speculative than the classical decoding. In both cases, subsequent neurons would have to implicitly 'know' the preference of the input neuron, and weigh its input correspondingly.</p>
<p>We have added all the above considerations to the discussion in an abbreviated form.</p>
<disp-quote content-type="editor-comment">
<p>p. 15 (L. 15). Is there a citation for the drive system?</p>
</disp-quote>
<p>There is no publication, but an old repository, where the files are available, which we cite now: <ext-link ext-link-type="uri" xlink:href="https://code.google.com/archive/p/edds-array-drive/">https://code.google.com/archive/p/edds-array-drive/</ext-link></p>
<disp-quote content-type="editor-comment">
<p>p. 16 (L. 24) &quot;position in an octave&quot; It is implied but not explicitly stated that the Shepard tones don't contain the fundamental frequency. Can the authors clarify the relationship between the neural tuning band and the bands of the stimulus. Did a single stimulus band typically fall in a neuron's frequency tuning curve? If not 1, how many?</p>
</disp-quote>
<p>Yes, it is correct that the concept of fundamental frequency does not cleanly apply to Shepard tones, because it is composed of octave spaced pure tones, but the lowest tone is placed outside the hearing range of the animal and amplitude envelope (across frequencies). Therefore one or more constituent tones of the Shepard tone can fall into the tuning curve of a neuron and contribute to driving the neuron (or inhibiting it, if they fall within an inhibitory region of the tuning curve). The number of constituent tones that fall within the tuning curve depends on the tuning width of the neurons. The distribution of tuning widths to Shepard tones is shown in Fig. S1E, which indicated that a lot of neurons had rather narrow tuning (close to the center), but many were also tuned widely, indicated that they would be stimulated by multiple constituent tones of the Shepard tone. As the tuning bandwidth (Q30: 30dB above threshold) of most cortical neurons in the ferret auditory cortex (see e.g. Bizley et al. Cerebral Cortex, 2005, Fig.12) is below 1, this means that typically not more than 1 tone fell into the tuning curve of a neuron. However, we also observed multimodal tuning-curves w.r.t. to Shepard tones, which suggests that some neurons were stimulated by more than 2 or more constituent tones (again consistent with the existence of more broadly tuned neurons (see same citation). We have added this information partly to the manuscript in the caption of Fig. S1E.</p>
<disp-quote content-type="editor-comment">
<p>p. 17 (L. 32). &quot;Fig 4&quot; Correct figure ref? This figure appears to be a schematic rather than one displaying data.</p>
</disp-quote>
<p>Thanks for pointing this out, changed to Fig. 5.</p>
<disp-quote content-type="editor-comment">
<p>p. 18 (L. 25). &quot;assign a pitchclass&quot; Can the authors refer to a figure illustrating this process?</p>
</disp-quote>
<p>Added.</p>
<disp-quote content-type="editor-comment">
<p>p. 19 (L. 17). Is mu the correct symbol?</p>
</disp-quote>
<p>Thanks. We changed it to phi_i, as in the formula above.</p>
<disp-quote content-type="editor-comment">
<p>p. 19 (L 19). &quot;convolution&quot; in time? Frequency?</p>
</disp-quote>
<p>Thanks for pointing this out, the term convolution was incorrect in this context. We have replaced it by &quot;weighted average&quot; and also adapted and simplified the formula.</p>
<disp-quote content-type="editor-comment">
<p>p. 19 (L 25) &quot;SSTRF&quot; this term is introduced before it is defined. Also it appears that &quot;SSTRF&quot; and &quot;STRF&quot; are sometimes interchanged.</p>
</disp-quote>
<p>Apologies, we have added the definition, and also checked its usage in each location.</p>
<disp-quote content-type="editor-comment">
<p>p. 23 (Fig 2) There is a mismatch between panel labels in the figure and in the legend. Bottom right panel (B3), what does time refer to here?</p>
</disp-quote>
<p>Thanks for pointing these out, both fixed.</p>
<disp-quote content-type="editor-comment">
<p>p. 24 (L 23) &quot;shifts them away&quot; away from what?</p>
</disp-quote>
<p>We have expanded the sentence to: &quot;After the bias, the decoded pitchclass is shifted from their actual pitchclass away from the biased pitchclass range ... &quot;</p>
<disp-quote content-type="editor-comment">
<p>p. 25 (L 7) &quot;individual properties&quot; properties of individual subjects?</p>
</disp-quote>
<p>Thanks for pointing this out, the corresponding sentence has been clarified and citations added.</p>
<disp-quote content-type="editor-comment">
<p>p. 26 (L 20) What is plotted in panel D? The average for all cells? What is n?</p>
</disp-quote>
<p>Yes, this is an average over cells, the number of cells has now been added to each panel.</p>
<disp-quote content-type="editor-comment">
<p>p. 28 (L 3) How to apply the terms &quot;right&quot; &quot;right&quot; &quot;middle&quot; to the panel is not clear. Generally, this figure is quite dense and difficult to interpret.</p>
</disp-quote>
<p>We have changed the caption of Panel A and replaced the location terms with the symbols, which helps to directly relate them to the figure. We have considered different approaches of adding or removing content from the figure to help make it less dense, but that all did not seem to help. For lack of better options we have left it in its current form.</p>
<disp-quote content-type="editor-comment">
<p>MINOR/TYPOS</p>
<p>p. 3 (L 1) &quot;Stimulus Specific Adaptation&quot; Capitalization seems unnecessary</p>
</disp-quote>
<p>Changed.</p>
<disp-quote content-type="editor-comment">
<p>p. 4 (L 14) &quot;Siple&quot;</p>
</disp-quote>
<p>Corrected.</p>
<disp-quote content-type="editor-comment">
<p>p. 9 (L 10) &quot;an quantitatively&quot;</p>
</disp-quote>
<p>Corrected</p>
<disp-quote content-type="editor-comment">
<p>p. 9 (L 20) &quot;directional ... direction ... directly ... directional&quot; This is a bit confusing as directseems to mean several different things in its different usages.</p>
</disp-quote>
<p>We have gone through these sentences, and we think the terms are now more clearly used, especially since the term 'direction' occurs in several different forms, as it relates to different aspects (cells/percept/hypothesis). Unfortunately, some repetition is necessary to maintain clarity.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<p>Detailed critique</p>
<p>Stimuli</p>
<p>It would be very useful if the authors could provide demos of their stimuli on a website. Many readers will not be familiar with Shepard tones and the perceptual result of the acoustical descriptions are not intuitive. I ended up coding the stimuli myself to get some intuition for them.</p>
</disp-quote>
<p>We have created some sample tones and sequences and uploaded them with the revision as supplementary documents.</p>
<disp-quote content-type="editor-comment">
<p>Abstract</p>
<p>P1 L27 'pitch and...selective cells' - The authors haven't provided sufficient controls to demonstrate that these are &quot;pitch cells&quot; or &quot;selective&quot; to pitch direction. They have only shown that they are sensitive to these properties in their stimuli. Controls would need to be included to ensure that the cells aren't simply responding to one frequency component in the complex sound, for example. This is not really critical to the overall findings, but the claim about pitch &quot;selectivity&quot; is not accurate.</p>
</disp-quote>
<p>Fair point. We have removed the word 'selective' in both occurrences.</p>
<disp-quote content-type="editor-comment">
<p>Introduction</p>
<p>P2 L14-17: I do not follow the phonetic example provided. The authors state that the second syllable of /alga/ and /arda/ are physically identical, but how is this possible that ga = da? The acoustics are clearly different. More explanation is needed, or a correction.</p>
</disp-quote>
<p>Apologies for the slightly misleading description, it has now been corrected to be in line with the original reference.</p>
<disp-quote content-type="editor-comment">
<p>P2,L26-27: Should the two uses of &quot;frequency&quot; be &quot;F0&quot; and &quot;pitch&quot; here? The tones are not separated in frequency by half and octave, but &quot;separated in [F0]&quot; by half an octave, correct? Their frequency ranges are largely overlapping. And the second 'frequency', which refers to the percept, should presumably be &quot;pitch&quot;.</p>
</disp-quote>
<p>Indeed. This is now corrected.</p>
<disp-quote content-type="editor-comment">
<p>P3 L2-6: Unclear at this point in the manuscript what is the difference between the 3 percepts mentioned: perceived pitch-change direction, Shepard tone pitches, and &quot;their respective differences&quot;. (It becomes clear later, but clarification is needed here).</p>
</disp-quote>
<p>We have tried a few reformulations, however, it tends to overload the introduction with details. We believe it is preferable to present the gist of the results here, and present the complete details later in the MS.</p>
<disp-quote content-type="editor-comment">
<p>P3 L6-7 What does it mean that the MEG and single unit results &quot;align in direction and dynamics&quot;? These are very different signals, so clarification is needed.</p>
</disp-quote>
<p>We have phrased the corresponding sentence more clearly.</p>
<disp-quote content-type="editor-comment">
<p>Results</p>
<p>Throughout: Choose one of 'pitch class', 'pitchclass', or 'pitch-class' and use it consistently.</p>
</disp-quote>
<p>Done.</p>
<disp-quote content-type="editor-comment">
<p>P4L12 - would be helpful at this point to define 'repulsive effect'</p>
</disp-quote>
<p>We have added another sentence to clarify this term.</p>
<disp-quote content-type="editor-comment">
<p>P4, L14 &quot;simple&quot;</p>
</disp-quote>
<p>Done</p>
<disp-quote content-type="editor-comment">
<p>P4, L12 - not clear here what &quot;repulsive influence&quot; means</p>
</disp-quote>
<p>See above.</p>
<disp-quote content-type="editor-comment">
<p>P4, L17 - alternative to which explanation? Please clarify. In general, this paragraph is difficult to interpret because we do not yet have the details needed to understand the terms used and the results described. In my opinion, it would be better to omit this summary of the results at the very beginning, and instead reveal the findings as they come, when they can be fully explained to the Reader.</p>
</disp-quote>
<p>We agree, but we also believe that a rather general description here is useful for providing a roadmap to the results. However, we have added a half-sentence to clarify what is meant by alternative.</p>
<disp-quote content-type="editor-comment">
<p>P4 L30 - text says that cells adapt in their onset, sustained and offset responses, but only data for onset responses are shown (I think - clarification needed for fig 2A2). Supp figure shows only 1 example cell of sustained and offset, and in fact there is no effect of adaptation in the sustained response shown there.</p>
</disp-quote>
<p>Regarding the effect of adaptation and whether it can be discerned from the supplementary figure: the shown responses are for 10 repetitions of one particular Bias sequence. Since the response of the cell will depend on its tuning and the specific sequence of the Shepard tones in this Bias, it is not possible to assess adaptation for a given cell. We assess the level of adaptation, by averaging all biases (similar to what is shown in Fig. 2A2) per cell, and then fit an exponential to it, separately by response type. The step direction of the exponential, relative to the spontaneous rate is then used to assess the kind of adaptation. The vast majority of cells show adaptation. We have added this information to the Methods of the manuscript.</p>
<disp-quote content-type="editor-comment">
<p>P4, L32 - please state the statistical test and criterion (alpha) used to determine that 91% of cells decreased their responses throughout the Bias sequence. Was this specifically for onset responses?</p>
</disp-quote>
<p>Thanks for pointing this out, test and p-value added. Adaptation was observed for onset, sustained and offset responses, in all cases with the vast majority showing an adapting behavior, although the onset responses were adapting the most.</p>
<disp-quote content-type="editor-comment">
<p>P4 L36 - &quot;response strength is reduced locally&quot;. What does &quot;locally&quot; mean here? Nearby frequencies?</p>
</disp-quote>
<p>We have added a sentence here to clarify this question.</p>
<disp-quote content-type="editor-comment">
<p>Figure 1 - this appears to be the wrong version of the figure, as it doesn't match the caption or results text. It's not possible to assess this figure until these things are fixed. Figure 1A schematic of definition of f(diff) does not correspond to legend definition.</p>
</disp-quote>
<p>As far as we can tell, it is all correct, only the resolution of the figure appears to be rather low. This has been improved now.</p>
<disp-quote content-type="editor-comment">
<p>Fig 2 A2 - is this also onset responses only?</p>
</disp-quote>
<p>Yes, added to the caption.</p>
<disp-quote content-type="editor-comment">
<p>Fig 2 A3 - add y-axis label. The authors are comparing a very wide octave band (5.5 octaves) to a much narrower band (0.5 octaves). Could this matter? Is there something special about the cut-off of 2.5 octaves in the 2 bands, or was this an arbitrary choice?</p>
</disp-quote>
<p>Interesting question.... essentially our stimulus design left us only with this choice, i.e. comparing the internal region of the bias with the boundary region of the bias, i.e. the test tones. The internal region just corresponds to the bias, which is 5 st wide, and therefore the range is here given as 2.5 st relative to its center, while the test tones are at the boundary, as they are 3 st from the center. The axis for the bias was mislabelled, and has now been corrected. The y-axis label is matched with the panel to the left, but has now been added to avoid any confusion.</p>
<disp-quote content-type="editor-comment">
<p>Fig 2A4 - does not refer to ferret single unit data, as stated in the text (p5L8). Nor does supp Fig2, as stated. Also, the figure caption does not match the figure.</p>
</disp-quote>
<p>Apologies, this was an error in the code that led to this mislabelling. We have corrected the labels, which also added back the recovery from the Bias sequence in the new Panel A4.</p>
<disp-quote content-type="editor-comment">
<p>P5 l9 - Figure 3 is not understandable at this point in the text, and should not be referred to here. There is a lot going on in Fig 3, and it isn't clear what you are referring to.</p>
</disp-quote>
<p>Removed.</p>
<disp-quote content-type="editor-comment">
<p>P5 L12 - by Fig 2 B1, I assume you mean A4? Also, F2B1 shows only 1 subject, not 2.</p>
</disp-quote>
<p>Yes, mislabeled by mistake, and corrected now.</p>
<disp-quote content-type="editor-comment">
<p>Fig2B2 -What is the y-axis?</p>
</disp-quote>
<p>Same as in the panel to its left, added for clarity.</p>
<disp-quote content-type="editor-comment">
<p>Stimuli: why are tones presented at a faster rate to ferrets than to humans?</p>
</disp-quote>
<p>The main reason is that the response analysis in MEG requires more spacing in time than the neuronal analysis in the ferret brain.</p>
<disp-quote content-type="editor-comment">
<p>P5 L6 - there is no Fig 5 D2? I don't think it is a good idea to get the reader to skip so far ahead in the figures at this stage anyway, even if such a figure existed. It is confusing to jump around the manuscript</p>
</disp-quote>
<p>Changed to 'see below'</p>
<disp-quote content-type="editor-comment">
<p>P5 L8 - There is no Figure 2A4, so I don't know whether this time constant is accurate.</p>
</disp-quote>
<p>This was in reference to a panel that had been removed before, but we have added it back now.</p>
<disp-quote content-type="editor-comment">
<p>P5 L16: &quot;in humans appears to be more substantial (40%) than for the average single units under awake conditions&quot;. One cannot directly compare magnitude of effects in MEG and single unit signals in this way and assume it is due to behavioural state. You are comparing different measures of neural activity, averaged over vastly different numbers of numbers, and recorded from different species listening to different stimuli (presentation rates).</p>
</disp-quote>
<p>Yes, that's why the next sentence is: &quot;However, comparisons between the level of adaptation in MEG and single neuron firing rates may be misleading, due to the differences in the signal measured and subsequent processing.&quot;, and all statements in the preceding sentences are phrased as 'appears' and 'may'. We think we have formulated this comparison with an appropriate level of uncertainty. Further, the main message here is that adaptation is taking place in both active and passive conditions.</p>
<disp-quote content-type="editor-comment">
<p>P5 L25 -I do not see any evidence regarding tuning widths in Fig s2, as stated in the text.</p>
</disp-quote>
<p>Corrected to Fig. S1.</p>
<disp-quote content-type="editor-comment">
<p>P5 l26 - Do not skip ahead to Fig 5 here. We aren't ready to process that yet.</p>
</disp-quote>
<p>OK, reference removed.</p>
<disp-quote content-type="editor-comment">
<p>P5 l27 - Do you mean because it could be tuning to pitch chroma, not height?</p>
</disp-quote>
<p>Yes, that is a possible interpretation, although it could also arise from a combination of excitatory and inhibitory contributions across multiple octaves.</p>
<disp-quote content-type="editor-comment">
<p>P5 l33 - remove speculation about active vs passive for reasons given above.</p>
</disp-quote>
<p>Removed.</p>
<disp-quote content-type="editor-comment">
<p>P6L2-6 'In the present...5 semitone step' - This is an incorrect interpretation of the minimal distance hypothesis in the context of the Shepard tone ambiguity. The percept is ambiguous because the 'true' F0 of the Shepard tones are imperceptibly low. Each constituent frequency of a single tone can therefore be perceived either as a harmonic of some lower fundamental frequency or as an independent tone. The dominant pitch of the second tone in the tritone pair may therefore be biased to be perceived at a lower constituent frequency (when the bias sequence is low) or at a higher constituent frequency (when the bias sequence is high). The text states that the minimal distance hypothesis would predict that an up-bias would make a tritone into a perfect fourth (5 semitones). This is incorrect. The MDH would predict that an up-bias would reduce the distance between the 1st tone in the ambiguous pair and the upper constituent frequency of the 2nd tone in the pair, hence making the upper constituent frequency the dominant pitch percept of the 2nd tone, causing an ascending percept.</p>
</disp-quote>
<p>The reviewer here refers to a “minimal distance hypothesis”, which without a literature reference,is hard for us to fully interpret. However, some responses are given below:</p>
<p>- &quot;The percept is ambiguous because the 'true' F0 of the Shepard tones are imperceptibly low.&quot; This statement appears to be based on some misconception: due to the octave spacing (rather than multiple/harmonics of a lowest frequency), the Shepard tones cannot be interpreted as usual harmonic tones would be. It is correct that the lowest tone in a Shepard tone is not audible, due to the envelope and the fact that it could in principle be arbitrarily small... hence, speaking about an F0 is really not well-defined in the case of a Shepard tone. The closest one could get to it would be to refer to the Shepard tone that is both in the audible range and in the non-zero amplitude envelope. But again, since the envelope is fading out the highest and lowest constituent tones, it is not as easy to refer to the lowest one as F0 (as it might be much quieter than the next higher constituent.</p>
<p>- &quot;The dominant pitch of the second tone in the tritone pair may therefore be biased to be perceived at a lower constituent frequency (when the bias sequence is low) or at a higher constituent frequency (when the bias sequence is high).&quot; This may relate to some known psychophysics, but we are unable to interpret it with certainty.</p>
<p>- &quot;The text states that the minimal distance hypothesis would predict that an up-bias would make a tritone into a perfect fourth (5 semitones). This is incorrect.&quot; We are unsure how the reviewer reaches this conclusion.</p>
<p>- &quot;The MDH would predict that an up-bias would reduce the distance between the 1st tone in the ambiguous pair and the upper constituent frequency of the 2nd tone in the pair, hence making the upper constituent frequency the dominant pitch percept of the 2nd tone, causing an ascending percept.&quot; Again, in the absence of a reference to the MDH, we are unsure of the implied rationale. We agree that this is a possible interpretation of distance, however, we believe that our interpretation of distance (i.e. distances between constituent tones) is also a possible interpretation.</p>
<disp-quote content-type="editor-comment">
<p>Fig 4: Given that it comes before Figure 3 in the results text, these should be switched in order in the paper.</p>
</disp-quote>
<p>Switched.</p>
<disp-quote content-type="editor-comment">
<p>PCA decoder: The methods (p18) state that the PCA uses the first 3 dimensions, and that pitch classes are calculated from the closest 4 stimuli. The results (P6), however, state that the first 2 principal components are used, and classes are computed from the average of 10 adjacent points. Which is correct, or am I missing something?</p>
</disp-quote>
<p>Thanks for pointing this out, we have made this more concrete in the Methods to: &quot;The data were projected to the first three dimensions, which represented the pitch class as well as the position in the sequence of stimuli (see Fig. 43A for a schematic). As the position in the Bias sequence was not relevant for the subsequent pitch class decoding, we only focussed on the two dimensions that spanned the pitch circle.&quot; Regarding the number of stimuli that were averaged: this might be a slight misunderstanding: Each Shepard tone was decoded/projected without averaging. However, to then assign an estimated pitch class, we first had to establish an axis (here going around the circle), where each position along the axis was associated with a pitch class. This was done by stepping in 0.5 semitone steps, and finding the location in decoded space that corresponded to the median of the Shepard tones within +/- 0.25st. To increase the resolution, this circular 'axis' of 24 points was then linearly interpolated to a resolution of 0.05st. We have updated the text in the Methods accordingly. The mentioning of 10 points for averaging in the Results was correct, as there were 240 tones in all bias stimuli, and 24 bins in the pitch circle. The mentioning of an average over 4 tones in the Methods was a typo.</p>
<disp-quote content-type="editor-comment">
<p>Fig 3A: axes of pink plane should be PC not PCA</p>
</disp-quote>
<p>Done.</p>
<disp-quote content-type="editor-comment">
<p>Fig 3B: the circularity in the distribution of these points is indeed interesting! But what do the authors make of the gap in the circle between semitones 6-7? Is this showing an inherent bias in the way the ambiguous tone is represented?</p>
</disp-quote>
<p>While we cannot be certain, we think that this represents an inhomogeneous sampling from the overall set of neural tuning preferences, and that if we had recorded more/all neurons, the circle would be complete and uniformly sampled (which it already nearly is, see Fig.4C, which used to be Fig. 3C).</p>
<disp-quote content-type="editor-comment">
<p>Fig 3B (lesser note): It'd be preferable to replace the tint (bright vs. dark) differentiation of the triangles to be filled vs. unfilled because such a subtle change in tint is not easily differentiable from a change in hue (indicating a different variable in this plot) with this particular colour palette</p>
</disp-quote>
<p>We have experimented with this suggestion, and it didn't seem to improve the clarity. However, we have changed the outline of the test-pair triangles to white, which now visually separates them better.</p>
<disp-quote content-type="editor-comment">
<p>P6 l32 - Please indicate if cross-validation was used in this decoder, and if so, what sort. Ideally, the authors would test on a held-out data set, or at least take a leave-one-out approach. Otherwise, the classifier may be overfit to the data, and overfitting would explain the exceptional performance (r=.995) of the classifier.</p>
</disp-quote>
<p>Cross-validation was not used, as the purpose of the decoder is here to create a standard against which to compare the biased responses in the ambiguous pair, which were not used for training of the decoder. We agree that if we instead used a cross-validated decoder (which would only apply to the local average to establish the pitch class circle) the correlation would be somewhat lower, however, this is less relevant for the main question, i.e. the influence of the Bias sequence on the neural representation of the ambiguous pair. We have added this information to the corresponding section.</p>
<disp-quote content-type="editor-comment">
<p>Fig 3D: I understood that these pitch classifications shown by the triangles were carried out on the final ambiguous pair of stimuli. I thought these were always presented at the edges of the range of other stimuli, so I do not follow how they have so many different pitchclass values on the x-axis here.</p>
</disp-quote>
<p>There were 4 Biases, centered at 0,3,6 or 9 semitones, and covering [-2.5,2.5]st relative to this center. Therefore the edges of the bias ranges (3st away from their centers) happen to be the same as the centers, e.g. for the Bias centered at 3, the ambiguous pair would be a 0-6 or 6-0 step. Therefore there are 4 locations for the ambiguous tones on the x-axis of Fig. 4D (previously 3D).</p>
<disp-quote content-type="editor-comment">
<p>Figure 4: This demonstration of the ambiguity of Shepard pairs may be misleading. The actual musical interval is never ambiguous, as this figure suggests. Only the ascending vs descending percept is ambiguous. Therefore the predictions of the ferret A1 decoding (Fig 3D) and the model in Fig 5 are inconsistent with perception in two ways. One (which the authors mention) is the direction of the bias shift (up vs down). Another (not mentioned here) is that one never experiences a shift in the shepard tone at a fraction of a semitone - the musical note stays the same, and changes only in pitch height, not pitch chroma.</p>
</disp-quote>
<p>We are unsure of the reviewer’s direction with this question. In particular the second point is not clear to us: &quot;...one (who?) never (in this experiment? in real life?) experiences a bias shift in the Shepard tone at a fraction of a semitone&quot; (why is this relevant in the current experiment?). Pitch chrome would actually be a possible replacement for pitch class, but somehow, the previous Shepard tone literature has referred to it as pitch class.</p>
<disp-quote content-type="editor-comment">
<p>P7 l12 - omit one 'consequently'</p>
</disp-quote>
<p>Changed to 'Therefore'.</p>
<disp-quote content-type="editor-comment">
<p>P7 l24 - I encourage the authors to not use &quot;local&quot; and &quot;global&quot; without making it clear what space they refer to. One tends to automatically think of frequency space in the auditory system, but I think here they mean f0 space? What is a &quot;cell close to the location of the bias&quot;? Cells reside in the brain. The bias is in f0 space. The use of &quot;local&quot; and &quot;global&quot; throughout the manuscript is too vague.</p>
</disp-quote>
<p>Agreed, the reference here was actually to the cell's preferred pitch class, not its physical location (which one might arguably be able to disambiguate, given the context). We have changed the wording, and also checked the use of global/local throughout the manuscript. The main use of 'global/local' is now in reference to the range of adaptation, and is properly introduced on first mention.</p>
<disp-quote content-type="editor-comment">
<p>P7 L26 -there is no Fig 5D1. Do you mean the left panel of 5D?</p>
</disp-quote>
<p>Thanks. Changed.</p>
<disp-quote content-type="editor-comment">
<p>FigS3 is referred to a lot on p7-8. Should this be moved to the main text?</p>
</disp-quote>
<p>The main reason why we kept it in the supplement is that it is based on a more static model, which is intended to illustrate the consequences of different encoding schemes. In order to not confuse the reader about these two models, we prefer to keep it in the supplement, which - for an online journal - makes little difference since the reader can just jump ahead to this figure in the same way as any other figure.</p>
<disp-quote content-type="editor-comment">
<p>Fig 5C, D - label x-axis.</p>
</disp-quote>
<p>Added.</p>
<disp-quote content-type="editor-comment">
<p>Fig 5E - axis labels needed. I don't know what is plotted on x and y, and cannot see red and green lines in left plot</p>
</disp-quote>
<p>Thanks for noticing this, colors corrected, axes labeled.</p>
<disp-quote content-type="editor-comment">
<p>Page 8 L3-15 - If I follow this correctly, I think the authors are confusing pitch and frequency here in a way that is fundamental to their model. They seem to equate tonotopic frequency tuning to pitch tuning, leading to confused implications of frequency adaptation on the F0 representation of complex sounds like Shepard tones. To my knowledge, the authors do not examine pure tone frequency tuning in their neurons in this study. Please clarify how you propose that frequency tuning like that shown in Fig 5A relates to representation of the F0 of Shepard tones. Or...are the authors suggesting these neural effects have little to do with pitch processing and instead are just the result of frequency tuning for a single harmonic of the Shepard tones?</p>
</disp-quote>
<p>We agree that it is not trivial to describe this well, while keeping the text uncluttered, in particular, because often tuning properties to stimulus frequency contribute to tuning properties of the same neuron for pitch class, although this can be more or less straightforward: specifically, for some narrowly tuned cells, the Shepard tuning is simply a reflection of their tuning to a single octave range of the constituent tones (see Fig. S1). For more broadly tuned cells, multiple constituent tones will contribute to the overall Shepard tuning, which can be additive, subtractive, or more complex. The assumption in our approach is that we can directly estimate the Shepard tuning to evaluate the consequence for the percept. While this may seem artificial, as Shepard tones do not typically occur in nature, the same argument could be made against pure tones, on which classical tuning curves and associated decodings are often based. Relating the Shepard tuning to the classical tuning would be an interesting study in itself, although arguably relating the tuning of one artificial stimulus to another. Regarding the terminology of pitch, pitch class and frequency: The term pitch class is commonly used in the field of Shepard tones, and - as we indicated in the beginning of the results: &quot;the term <italic>pitch</italic> is used interchangeably with <italic>pitch class</italic> as only Shepard tones are considered in this study&quot;. We agree that the term pitch, which describes the perceptual convergence/construction of a tone-height from a range of possible physical stimuli, needs to be separated from frequency as one contributor/basis for the perception of a pitch. However, we think that the term pitch can - despite its perceptual origin - also be associated with neuron/neural responses, in order to investigate the neural origin of the pitch percept. At the same time, the present study is not targeted to study pitch encoding per se, as this would require the use of a variety of stimuli leading to consistent pitch percepts. Therefore, pitch (class) is here mainly used as a term to describe the neural responses to Shepard tones, based on the previous literature, and the fact that Shepard tones are composite stimuli that lead to a pitch percept. The last sentence has been added to the manuscript for clarity.</p>
<disp-quote content-type="editor-comment">
<p>P7-9: I wasn't left with a clear idea of how the model works from this text. I assume you have layers of neurons tuned to frequency or f0 (based on the real data?), which are connected in some way to produce some sort of output when you input a sound? More detail is needed here. How is the dynamic adaptation implemented?</p>
</disp-quote>
<p>The detailed description of the model can be found in the Methods section. We have gone through the corresponding paragraph and have tried to clarify the description of the model by introducing a high-level description and the reference to the corresponding Figure (Fig. 5A) in the Results.</p>
<disp-quote content-type="editor-comment">
<p>Fig6A: Figure caption can't be correct. In any case, these equations cannot be understood unless you define the terms in them.</p>
</disp-quote>
<p>We have clarified the description in the caption.</p>
<disp-quote content-type="editor-comment">
<p>Fig 6/directionality analysis: Assuming that the &quot;F&quot; in the STRFs here is Shepard tone f0, and not simple frequency?</p>
</disp-quote>
<p>We have changed the formula in the caption and the axis labels now.</p>
<disp-quote content-type="editor-comment">
<p>Fig 6C - y-axis values</p>
</disp-quote>
<p>In the submission, these values were left out on purpose, as the result has an arbitrary scale, but only whether it is larger or smaller than 0 counts for the evaluation of the decoded directionality (at the current level of granularity). An interesting refinement would be to relate the decoded values to animal performance. We have now scaled the values arbitrarily to fit within [-1,1], but we would like to emphasize that only their relative scale matters here, not their absolute scale.</p>
<disp-quote content-type="editor-comment">
<p>Fig 6E - can't both be abscissa (caption). I might be missing something here, but I don't see the &quot;two stripes&quot; in the data that are described in the caption.</p>
</disp-quote>
<p>Thank you. The typo is fixed. The stripes are most clearly visible in the right panel of Fig. 6E, red and blue, diagonally from top left to bottom right.</p>
<disp-quote content-type="editor-comment">
<p>Fig 6G -I have no idea what this figure is illustrating.</p>
</disp-quote>
<p>This panel is described in the text as follows: &quot;The resulting distribution of activities in their relation to the Bias is, hence, symmetric around the Bias (Fig. 6G). Without prior stimulation, the population of cells is unadapted and thus exhibits balanced activity in response to a stimulus. After a sequence of stimuli, the population is partially adapted (Fig. 6G right), such that a subsequent stimulus now elicits an imbalanced activity. Translated concretely to the present paradigm, the Bias will locally adapt cells. The degree of adaptation will be stronger, if their tuning curve overlaps more with the biased region. Adaptation in this region should therefore most strongly influence a cell’s response. For example, if one considers two directional cells, an up- and a down-selective cell, cocentered in the same frequency location below the Bias, then the Bias will more strongly adapt the up-cell, which has its dominant, recent part of the SSTRF more inside the region of the Bias (Fig. 6G right). Consistent with the percept, this imbalance predicts the tone to be perceived as a descending step relative to the Bias. Conversely, for the second stimulus in the pair, located above the Bias, the down-selective cells will be more adapted, thus predicting an ascending step relative to the previous tone.&quot;</p>
<disp-quote content-type="editor-comment">
<p>I might be just confused or losing steam at this point, but I do not follow what has been done or the results in Fig 6 and the accompanying text very well at all. Can this be explained more clearly? Perhaps the authors could show spike rate responses of an example up-direction and down-direction neuron? Explain how the decoder works, not just the results of it.</p>
</disp-quote>
<p>We agree that we are presenting something new here. However, it is conceptually not very different from decoding based on preferred frequencies. We have attempted to provide two illustrations of how the decoder works (Fig. 6A) and how it then leads to the percept using prototypical examples of cellular SSTRFs (Fig. 6G). We have added a complete, but accessible description to the Methods section. Showing firing rates of neurons would unfortunately not be very telling, given the usual variability in neural response and the fact that our paradigm did not have a lot of repetitions (but instead a lot of conditions), which would be able to average out the variability on a single neuron level.</p>
<disp-quote content-type="editor-comment">
<p>Discussion - I do not feel I can adequately critique the author's interpretation of the results until I understand their results and methods better. I will therefore save my critique of the discussion section for the next round of revisions after they have addressed the above issues of disorganization and clarity in the manuscript.</p>
</disp-quote>
<p>We hope that the updated version of the manuscript provides the reviewer now with this possibility.</p>
<disp-quote content-type="editor-comment">
<p>Methods</p>
<p>P15L7 - gender of human subjects? Age distribution? Age of ferrets?</p>
</disp-quote>
<p>We have added this information.</p>
<disp-quote content-type="editor-comment">
<p>P16L21 - What is the justification for randomizing the phase of the constituent frequencies?</p>
</disp-quote>
<p>The purpose of the randomization was to prevent idiosyncratic phase relationships for particular Shepard tones, which would depend in an orderly fashion on the included base-frequencies if non-randomized, and could have contributed to shaping the percept for each Shepard tone in a way that was only partly determined by the pitch class of the Shepard tone. Added to the section.</p>
<disp-quote content-type="editor-comment">
<p>P17L6 - what are the 2 randomizations? What is being randomized?</p>
</disp-quote>
<p>Pitch classes and position in the Bias sequence. Added to the section.</p>
<disp-quote content-type="editor-comment">
<p>P16 Shepard Tuning section - What were the durations of the tones and the time between tones within a trial?</p>
</disp-quote>
<p>Thanks, added!</p>
<disp-quote content-type="editor-comment">
<p>Equations - several undefined terms in the equations throughout the manuscript.</p>
</disp-quote>
<p>Thanks. We have gone through the manuscript and all equations and have introduced additional definitions where they had been missing.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p>
<p>P3L10: &quot;passive&quot; and &quot;active&quot; conditions come totally out of the blue. Need introducing first. (Or cut. If adaptation is always seen, why mention the two conditions if the difference is not relevant here?)</p>
</disp-quote>
<p>We have added an additional sentence in the preceding paragraph, that should clarify this. The reason for mentioning it is that otherwise a possible counter-argument could be made that adaptation does not occur in the active condition, which was not tested in ferrets (but presents an interesting avenue for future research).</p>
<disp-quote content-type="editor-comment">
<p>P3L14 &quot;siple&quot; typo</p>
</disp-quote>
<p>Corrected.</p>
<disp-quote content-type="editor-comment">
<p>P4L1 &quot;behaving humans&quot; you should elaborate just a little here on what sort of behavior the participants engaged in.</p>
</disp-quote>
<p>Thanks for pointing this out. We have clarified this by adding an additional sentence directly thereafter.</p>
<disp-quote content-type="editor-comment">
<p>P4 adaptation: I wonder whether it would be useful to describe the Bias condition a bit more here before going into the observations. The reader cannot know what to expect unless they jump ahead to get a sense of what the Bias looks like in the sense of how many stimuli are in it, and how similar they are to each other. Observations such as &quot;the average response strength decreases as a function of the position in the Bias sequence&quot; are entirely expected if the Bias is made up of highly repetitive material, but less expected if it is not. I appreciate that it can be awkward to have Methods after Results, but with a format like that, the broad brushstroke Methods should really be incorporated into the Results and only the tedious details should be reserved for the Methods to avoid readers having to jump back and forth.</p>
</disp-quote>
<p>Agreed, we have inserted a corresponding description before going into the details of the results.</p>
<disp-quote content-type="editor-comment">
<p>Related to this (perhaps): Bottom of P4, top of P5: &quot;significantly less reduced (33%, p=0.0011, 2 group t-test) compared to within the bias (Fig. 2 A3, blue vs. red), relative to the first responses of the bias&quot; ... I am at a loss as to what the red and blue symbols in Fig 2 A3 really show, and I wonder whether the &quot;at the edges&quot; to &quot;within the Bias&quot; comparison were to make sense if at this stage I had been told more about the composition of the Bias sequence. Do the ambiguous ('target') tones also occur within the Bias? As I am unclear about what is compared against what I am also not sure how sound that comparison is.</p>
</disp-quote>
<p>We have added an extended description of the Bias to the beginning of this section of the manuscript. For your reference: the Shepard tones that made up the ambiguous tones were not part of the Bias sequence, as they are located at 3st distance from the center of the Bias (above and below), while the Bias has a range of only +/- 2.5st.</p>
<disp-quote content-type="editor-comment">
<p>Fig 2: A4 B1 B2 labels should be B1 B2 B3</p>
</disp-quote>
<p>Corrected.</p>
<disp-quote content-type="editor-comment">
<p>Fig 2 A2, A3: consider adjusting y-axis range to have less empty space above the data. In A3 in particular, the &quot;interesting bit&quot; is quite compressed.</p>
</disp-quote>
<p>Done, however, while still matching the axes of A2 and A3 for better comparability.</p>
<disp-quote content-type="editor-comment">
<p>I am under the strong impression that the human data only made it into Fig 2 and that the data from Fig 3 onwards are animal data only. That is of course fine (MEG may not give responses that are differentiated enough to perform the sort of analyses shown in the later figures. But I do think that somewhere this should be explicitly stated.</p>
</disp-quote>
<p>Yes, the reviewer's observation is correct. The decoding analyses could not be conducted on the human MEG data and was therefore not further pursued. Its inclusion in the paper has the purpose of demonstrating that even in humans and active conditions, the local adaptation is present, which is a key contributor to the two decoding models. We now state this explicitly when starting the decoding analysis.</p>
<disp-quote content-type="editor-comment">
<p>P5L2 &quot;bias&quot; not capitalized. Be consistent.</p>
</disp-quote>
<p>All changed to capitalized.</p>
<disp-quote content-type="editor-comment">
<p>P5L8 reference to Fig 2 A4: something is amiss here. From legend of Fig 2 it seems clear that panel A4 label is mislabeled B1. Maybe some panels are missing to show recovery rates?</p>
</disp-quote>
<p>Apologies for this residual text from a previous version of the manuscript. We have gone through all references and corrected them.</p>
<disp-quote content-type="editor-comment">
<p>P6L7 comma after &quot;decoding&quot;.</p>
</disp-quote>
<p>Changed.</p>
<disp-quote content-type="editor-comment">
<p>Fig 3, I like this analysis. What would be useful / needed here though is a little bit more information about how the data were preprocessed and pooled over animals. Did you do the PCA separately for each animal, then combine, or pool all units into a big matrix that went into the PCA? What about repeat, presentations? Was every trial a row in the matrix, or was there some averaging over repeats? (In fact, were there repeats??)</p>
</disp-quote>
<p>Thanks for bringing up these relevant aspects, which were partly insufficiently detailed in the manuscript. Briefly, cells were pooled across animals and we only used cells that could meaningfully contribute to the decoding analysis, i.e. had auditory responses and different responses to different Shepard tones. Regarding the responses, as stated in the Methods, &quot;Each stimulus was repeated 10 times&quot;, and we computed average responses across these repetitions. Single trials were not analyzed separately. We have added this information in the Methods, and refer to it in the Results.</p>
<disp-quote content-type="editor-comment">
<p>Also, there doesn't appear to be a preselection of units. We would not necessarily expect all cortical neurons to have a meaningful &quot;best pitch&quot; as they may be coding for things other than pitch. Intuitively I suspect that, perhaps, the PCA may take care of that by simply not assigning much weight to units that don't contribute much to explained variance? In any event I think it should be possible, and would be of some interest, to pull out of this dataset some descriptive statistics on what proportion of units actually &quot;care about pitch&quot; in that they have a lot (or at least significantly more than zero) of response variance explained by pitch. Would it make sense to show a distribution of %VE by pitch? Would it make sense to only perform the analysis in Fig 3 on units that meet some criterion? Doing so is unlikely to change the conclusion, but I think it may be useful for other scientists who may want to build on this work to get a sense of how much VE_pitch to expect.</p>
</disp-quote>
<p>We fully agree with the reviewer, which is why this information is already presented in Supplementary Fig.1, which details the tuning properties of the recorded neurons. Overall, we recorded from 1467 neurons across all ferrets, out of which 662 were selected for the decoding analysis based on their driven firing rate (i.e. whether they responded significantly to auditory stimulation) and whether they showed a differential response to different Shepard tones The thresholds for auditory response and tuning to Shepard tones were not very critical: setting the threshold low, led to quantitatively the same result, however, with more noise. Setting the thresholds very high, reduced the set of cells included in the analysis, and eventually that made the results less stable, as the cells did not cover the entire range of preferences to Shepard tones. We agree that the PCA based preprocessing would also automatically exclude many of the cells that were already excluded with the more concrete criteria beforehand. We have added further information on this issue in the Methods section under the heading 'Unit selection'.</p>
<disp-quote content-type="editor-comment">
<p>P9 &quot;tones This&quot; missing period.</p>
</disp-quote>
<p>Changed.</p>
<disp-quote content-type="editor-comment">
<p>P10L17 comma after &quot;analysis&quot;</p>
</disp-quote>
<p>Changed.</p>
</body>
</sub-article>
</article>