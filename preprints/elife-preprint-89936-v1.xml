<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">89936</article-id>
<article-id pub-id-type="doi">10.7554/eLife.89936</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89936.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Task-specific invariant representation in auditory cortex</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9048-1201</contrib-id>
<name>
<surname>Heller</surname>
<given-names>Charles R.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0612-216X</contrib-id>
<name>
<surname>Hamersky</surname>
<given-names>Gregory R.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4135-3104</contrib-id>
<name>
<surname>David</surname>
<given-names>Stephen V.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Neuroscience Graduate Program</institution></aff>
<aff id="a2"><label>2</label><institution>Otolaryngology, Oregon Health &amp; Science University</institution>, Portland, OR, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Ding</surname>
<given-names>Nai</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Zhejiang University</institution>
</institution-wrap>
<city>Hangzhou</city>
<country>China</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Shinn-Cunningham</surname>
<given-names>Barbara G</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Carnegie Mellon University</institution>
</institution-wrap>
<city>Pittsburgh</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence: <email>davids@ohsu.edu</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-08-31">
<day>31</day>
<month>08</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP89936</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-06-15">
<day>15</day>
<month>06</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-06-29">
<day>29</day>
<month>06</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.06.29.547009"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Heller et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Heller et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-89936-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Categorical sensory representations are critical for many behaviors, including speech perception. In the auditory system, categorical information is thought to arise hierarchically, becoming increasingly prominent in higher order cortical regions. The neural mechanisms that support this robust and flexible computation remain poorly understood. Here, we studied sound representations in primary and non-primary auditory cortex while animals engaged in a challenging sound discrimination task. Population-level decoding of simultaneously recorded single neurons revealed that task engagement caused categorical sound representations to emerge in non-primary auditory cortex. In primary auditory cortex, task engagement caused a general enhancement of sound decoding that was not specific to task-relevant categories. These findings are consistent with mixed selectivity models of neural disentanglement, in which early sensory regions build an overcomplete representation of the world and allow neurons in downstream brain regions to flexibly and selectively read out behaviorally relevant, categorical information.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Perceptual decision making requires behavioral responses based on specific sensory patterns that ignore distracting and irrelevant information. In the auditory system, categorical sensory representation is essential to many natural behaviors (<xref ref-type="bibr" rid="c6">Bizley and Cohen, 2013</xref>). For example, during language processing, vowels are perceived categorically, even though the formant frequencies that define them vary continuously across utterances (<xref ref-type="bibr" rid="c23">Hillenbrand et al., 1995</xref>). Categorical perception is not limited to language, as subjects can learn to classify arbitrary, novel sounds according to one spectro-temporal feature while ignoring others (<xref ref-type="bibr" rid="c51">Stilp and Kluender, 2010</xref>).</p>
<p>Neurophysiological studies in auditory cortex have shown that engaging in auditory behavior can enhance sensory discriminability at the level of single neurons (<xref ref-type="bibr" rid="c10">Buran et al., 2014</xref>; <xref ref-type="bibr" rid="c35">Niwa et al., 2012a</xref>) and neural populations (<xref ref-type="bibr" rid="c4">Bagur et al., 2018</xref>; <xref ref-type="bibr" rid="c29">Kuchibhotla et al., 2017</xref>). Most of this work has demonstrated a generalized, overall improvement in sensory coding without contrasting neural representations of task-relevant versus -irrelevant features. In frontal cortex, neurons often only encode sound category (<xref ref-type="bibr" rid="c18">Fritz et al., 2010</xref>; <xref ref-type="bibr" rid="c54">Tsunada et al., 2011</xref>), suggesting that sound information is transformed into an invariant, categorical representation before exiting auditory cortex. Such representations require disentangling sensory features that are relevant for defining the object category from other features that are irrelevant to the category (<xref ref-type="bibr" rid="c16">DiCarlo and Cox, 2007</xref>). Theory predicts that neural systems can produce these invariant representations through hierarchical computation. In early processing regions, mixed selectivity of single neurons produces high-dimensional, overcomplete representations of sensory inputs and behavioral variables. From this population activity, it is straightforward for neurons in downstream areas to decode information about a specific feature that is important to the current behavior and whose representation is invariant to irrelevant sensory information (<xref ref-type="bibr" rid="c27">Kell et al., 2018</xref>; <xref ref-type="bibr" rid="c41">Rigotti et al., 2013</xref>).</p>
<p>We hypothesized that invariant auditory representations supporting perceptual discrimination arise through a behavior-dependent hierarchical process, consistent with mixed selectivity models. According to this model, engaging in an auditory behavior leads to a non-specific enhancement of auditory representations at early stages, followed by a selective enhancement of task-relevant features at later stages. Previous work has shown that effects of task engagement are larger in non-primary auditory fields (<xref ref-type="bibr" rid="c2">Atiani et al., 2014</xref>; <xref ref-type="bibr" rid="c28">Kline et al., 2023</xref>; <xref ref-type="bibr" rid="c34">Niwa et al., 2013</xref>), as are the effects of selective attention, which may be related to invariant sound feature coding (<xref ref-type="bibr" rid="c37">O’Sullivan et al., 2019</xref>). Some studies have also reported that choice related activity emerges in non-primary auditory cortex during a challenging perceptual discrimination behavior (<xref ref-type="bibr" rid="c55">Tsunada et al., 2015</xref>), although factors affecting choice coding may be task dependent (<xref ref-type="bibr" rid="c8">Bizley et al., 2013</xref>). Together, these findings are consistent with the idea that behaviorally relevant neural representations are computed hierarchically in auditory cortex (<xref ref-type="bibr" rid="c30">Lestang et al., 2023</xref>).</p>
<p>To investigate the emergence of invariant sound coding, we recorded neural population activity from primary and non-primary fields of ferret auditory cortex while animals alternated between active tone-in-noise detection and passive listening to task stimuli. We designed the task so that behavioral sessions contained multiple different target and distractor sounds and used decoding analysis to measure how neural populations discriminate between both task-relevant and -irrelevant sound features. For this analysis, we developed decoding-based dimensionality reduction (dDR), which projects neural activity into a low-dimensional subspace spanning both changes in mean firing rate between categories and covariability across trials (<xref ref-type="bibr" rid="c22">Heller and David, 2022</xref>) dDR prevents bias that can affect population decoding in behavioral studies with relatively limited numbers of trials (<xref ref-type="bibr" rid="c26">Kanitscheider et al., 2015</xref>; <xref ref-type="bibr" rid="c32">Moreno-Bote et al., 2014</xref>). Effects of task engagement were highly variable across individual neurons, but the population-level analysis revealed that sound coding in primary auditory cortex was broadly and non-specifically improved by task engagement. In contrast, an enhanced, selective representation of task-relevant features emerged in non-primary auditory cortex. The degree of task-relevant enhancement was correlated with behavioral performance, consistent with the hypothesis that categorical representations in non-primary auditory cortex inform behavioral choices.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Psychometric tone-in-noise detection behavior</title>
<p>To study how neural representations of sound category emerge in auditory cortex, we trained four ferrets to perform a go/no-go tone-in-noise detection task. Animals reported the occurrence of a target tone in a sequence of narrowband noise distractors by licking a piezo spout (<xref rid="fig1" ref-type="fig">Figure 1A</xref>, Methods: Behavioral paradigm). Targets were presented with variable signal-to-noise ratio (SNR), masked by noise centered at the same frequency. A subset of behavioral trials in each experiment included an explicit catch stimulus whose center frequency was matched to that of the target tone. This task design permitted us to probe neural coding of both task-relevant sound features (presence or absence of a target tone) and -irrelevant features (level of noise masking the target tone, <xref rid="fig1" ref-type="fig">Figure 1C</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Tone-in-noise detection behavior.</title>
<p><bold>a.</bold> Schematic of go/no-go tone-in-noise detection task. Licking responses to target tones were rewarded, while responses to narrowband noise distractors were penalized with a timeout. Target tone frequency was fixed during a single behavior session and masked by narrowband (0.3 octave) noise centered at the same frequency with variable signal-to-noise (SNR). The “Catch” distractor was identical to the masking noise but with no tone. <bold>b.</bold> Behavioral performance of individual animals as a function of SNR (<italic>d-prime</italic> = <italic>Z</italic>[target response rate] - <italic>Z</italic>[catch response rate], n = 4 animals). Black line and error bars indicate the mean and standard error of the mean across animals. <bold>c.</bold> Left: Stimulus set for an example experiment where the target tone frequency was 2828 Hz. Right: both task relevant (catch vs. target) and task irrelevant (target vs. target, distractor vs. distractor) sound discriminations were studied.</p></caption>
<graphic xlink:href="547009v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Behavioral performance was measured using d-prime (<xref ref-type="bibr" rid="c20">Green and Swets, 1966</xref>; <xref ref-type="bibr" rid="c43">Saderi et al., 2021</xref>), calculated as the z-scored hit rate for a given target minus the z-scored catch response rate. Across behavioral sessions and animals, performance showed a clear psychometric dependence on target SNR (<xref rid="fig1" ref-type="fig">Figure 1B</xref>, Supplemental Figure 1). All animals could easily discriminate between the pure tone (Inf dB) target and catch stimulus, while performance for lower SNR target stimuli approached chance level.</p>
</sec>
<sec id="s2b">
<title>Diverse effects of task engagement on single neurons in primary and non-primary auditory cortex</title>
<p>We used linear 64-channel silicon probes (<xref ref-type="bibr" rid="c48">Shobe et al., 2015</xref>) to record single unit activity from primary (A1) and non-primary (dPEG) auditory cortex while animals performed the tone-in-noise detection task. Recordings were targeted to each respective region based on functional mapping of neural responses (Methods, Supplemental Figure 2). Behavior alternated between blocks of active task engagement and passive listening to task stimuli. During passive listening, licking responses were not rewarded and animals quickly disengaged from the task (<xref ref-type="bibr" rid="c13">David et al., 2012</xref>).</p>
<p>Sound-evoked spiking activity was compared between active and passive states to study the impact of task engagement on sound representation. In both A1 and dPEG, responses to target and catch stimuli were distinct for many neurons (<xref rid="fig2" ref-type="fig">Figure 2A-C</xref>, Supplemental Figure 3), suggesting that stimulus identity could be decoded in both brain regions. The accuracy of catch vs. target discrimination was measured using neural d-prime, the z-scored difference in target minus catch spiking response for each neuron (Methods: Single neuron PSTHs and d-prime (<xref ref-type="bibr" rid="c35">Niwa et al., 2012a</xref>)). Task engagement increased catch vs. target d-prime for many neurons in both A1 and dPEG. However, effects across the population were diverse; many neurons showed no change or even a decrease in accuracy (<xref rid="fig2" ref-type="fig">Figure 2D-E</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>State-dependent modulation of singe neuron target vs. catch discrimination.</title>
<p><bold>a.</bold> Example peristimulus time histogram (PSTH) responses from a single recording site in A1. Heatmap color in each row indicates PSTH amplitude of one neuron. Dashed lines indicate sound onset / offset. Spikes were binned (20 ms), z-scored, and smoothed (σ = 30 ms Gaussian kernel). Example target responses are to the pure tone (Inf dB) target. Difference is computed as the response to target minus catch response. <bold>b-c.</bold> Mean z-scored response evoked by catch vs. Inf dB stimulus for each A1 neuron across passive (<bold>b</bold>) and active (<bold>c</bold>) trials. <bold>d.</bold> Histogram plots state-dependent change in target vs. catch stimulus discriminability for each A1 neuron. Neural d-prime is defined |Z[target] - Z[catch]|, and Δd-prime is the difference of active minus passive d-prime. <bold>e.</bold> Histogram of Δd-prime for dPEG neurons, plotted as in D.</p></caption>
<graphic xlink:href="547009v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2c">
<title>Population coding of task-relevant features is selectively enhanced in non-primary auditory cortex</title>
<p>Given the diversity of task-related changes in neural activity, we asked if a clearer pattern of task-dependent changes could be observed at the population level. We performed optimal linear decoding of task stimuli from the single-trial activity of simultaneously recorded neurons at each recording site. We quantified decoding performance with neural population d-prime (Methods: Neural population d-prime (<xref ref-type="bibr" rid="c1">Abbott and Dayan, 1999</xref>; <xref ref-type="bibr" rid="c35">Niwa et al., 2012a</xref>)). To prevent overfitting and allow visualization of population responses, we first projected single trial activity into a low dimensional subspace optimized for linear decoding of task stimuli (<xref rid="fig3" ref-type="fig">Figure 3</xref> (<xref ref-type="bibr" rid="c22">Heller and David, 2022</xref>)). In both A1 and dPEG, population d-prime for catch versus target stimuli consistently increased during task engagement. In A1, the increase in d-prime was consistent across all task categories; there was no difference between target vs. target and target vs. catch discrimination accuracy (Figure B-C). However, in dPEG the improvement of task-relevant catch vs. target discrimination was significantly larger than any other category (<xref rid="fig3" ref-type="fig">Figure 3E-F</xref>). Unlike A1, discrimination of task-relevant sound categories was selectively enhanced in non-primary auditory cortex.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Selective enhancement of task-relevant category representation in secondary auditory cortex.</title>
<p><bold>a.</bold> Left: Representative A1 population activity during passive listening projected into a 2-dimensional space optimized for discriminating target versus catch responses. Each dot indicates the population response on a single trial, color indicates different noise (catch) or tone-in-noise (target) stimuli, and ellipses describe the standard deviation of responses across trials. The degree of ellipse overlap provides a visualization of the neural discriminability (d-prime) between the corresponding stimuli. Right: A1 population activity during active behavior. <bold>b.</bold> Mean population d-prime between sounds from each category (target vs. catch, target vs. target, and distractor vs. distractor, <xref rid="fig1" ref-type="fig">Figure 1C</xref>) for each A1 recording site (n = 18 sessions, n = 3 animals). <bold>c.</bold> Δd-prime is the difference between active and passive d-prime, normalized by their sum (D vs. D / T vs. T p = 0.048, Wilcoxon signed rank test). <bold>d.</bold> Single-trial population responses for a single site in non-primary auditory cortex (dPEG), plotted as in A. <bold>e.</bold> Passive vs. Active category discriminability for dPEG recording sites, plotted as in B (n = 13 sessions, n = 4 animals). <bold>f.</bold> Changes in discriminability per category in dPEG. Δd-prime for target vs. catch pairs (T vs. C) was significantly greater than for the other categories (D vs. D: p = 0.003; T vs. T: p = 0.005, Wilcoxon signed rank test).</p></caption>
<graphic xlink:href="547009v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Prior work has demonstrated that generalized, pupil-indexed arousal can impact the responses of neurons in auditory cortex, independent of engagement in a specific task (<xref ref-type="bibr" rid="c31">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="c44">Schwartz et al., 2020</xref>). Importantly, task engagement is often correlated with increased arousal (<xref ref-type="bibr" rid="c14">de Gee et al., 2022</xref>; <xref ref-type="bibr" rid="c43">Saderi et al., 2021</xref>). To ensure that our results were not influenced by non-specific effects of arousal, decoding analysis was performed after first removing all spiking variability that could be explained using pupil-indexed arousal (Methods). Performing the same decoding analysis without first controlling for pupil size did not affect the selective enhancement that we observed in dPEG (Supplemental Figure 4). However, Δ d-prime, in both A1 and dPEG, was higher overall. The absence of a pupil effect on selectivity suggests that pupil-indexed arousal primarily operates on an orthogonal subspace to the global task engagement axis and tends to non-specifically improve coding accuracy.</p>
</sec>
<sec id="s2d">
<title>Behavioral performance is correlated with neural coding changes in non-primary auditory cortex only</title>
<p>If task-related changes in neural coding are linked to processes that guide behavior, then the changes in neural activity should be predictive of behavioral performance (<xref ref-type="bibr" rid="c55">Tsunada et al., 2015</xref>). While selective enhancement of task-relevant discriminability was observed only in dPEG, both areas showed an overall increase in sensory discriminability. We asked if either of these changes in neural decoding performance were predictive of behavioral performance. For each tone-in-noise target stimulus, we compared the task-related change in neural d-prime to behavioral d-prime in the same experiment. We found a significant correlation for populations in dPEG, but not in A1 (<xref rid="fig4" ref-type="fig">Figure 4</xref>). Thus, the task-specific changes in dPEG are coupled with the behavioral output reflecting those sound features.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Changes in neural decoding are correlated with behavior performance in dPEG, but not A1.</title>
<p><bold>a.</bold> Scatter plot compares neural Δd-prime (active minus passive) for all tone-in-noise target vs. catch noise combinations against the corresponding behavioral d-prime for that target vs. catch discrimination. Line shows the best linear fit, and shading represents bootstrapped 95% confidence interval for slope. Left, data from A1 (n = 60 unique target vs. catch combinations, n = 3 animals, 18 recording sessions). Right, data from dPEG (n = 44 unique target vs. catch combinations, n = 4 animals, 13 recording sessions). <bold>b.</bold> Pearson correlation between neural d-prime and behavioral d-prime in each brain region. Error bars indicate bootstrapped 95% confidence intervals (A1: p = 0.082; dPEG: p = 0.002, bootstrap test).</p></caption>
<graphic xlink:href="547009v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2e">
<title>Changes in evoked response gain, not shared population covariability, support the emergence of categorical representations in non-primary auditory cortex</title>
<p>The difference in task-dependent coding between A1 and dPEG could be explained by differential changes in the evoked responses of single neurons, patterns of covariability between neurons, or both (<xref ref-type="bibr" rid="c11">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="c12">Cowley et al., 2020</xref>). To measure task-dependent changes in covariability, we used Factor Analysis to model low-dimensional correlated activity in the neural population (Methods: Factor Analysis). We found that covariability patterns changed significantly between the passive and active state (Supplemental Figure 5). In both brain regions, task engagement caused a rotation of the principal covariability axis, consistent with an overall decorrelation of population activity (<xref ref-type="bibr" rid="c56">Umakantha et al., 2021</xref>). In theory, a rotation could either help, or hurt, decoding accuracy, depending on its alignment with the sound discrimination axis (<xref rid="fig5" ref-type="fig">Figure 5A</xref>). Therefore, we measured the alignment of population covariability with the sound discrimination axis in both passive and task engaged states (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). Surprisingly, in A1, task engagement caused covariability to become more aligned with the sound discrimination axis. These results are consistent with a model in which the principal covariability axis does not represent information limiting noise in early sensory areas (<xref ref-type="bibr" rid="c25">Kafashan et al., 2021</xref>), but instead reflects top-down, task-dependent gain modulation becoming more aligned with the task-relevant coding axis (<xref ref-type="bibr" rid="c15">Denfield et al., 2018</xref>; <xref ref-type="bibr" rid="c19">Goris et al., 2014</xref>; <xref ref-type="bibr" rid="c39">Rabinowitz et al., 2015</xref>). Conversely, in dPEG alignment was low in both the passive and engaged states, consistent with covariability reflecting non-sensory variables that do not directly interact with processing of the sensory stimulus (<xref ref-type="bibr" rid="c52">Stringer et al., 2019a</xref>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Task-related changes in shared population covariability do not impact coding of task-relevant features.</title>
<p><bold>a.</bold> Schematic of population response over many trials to a catch stimulus (grey) and target stimulus (red), projected into a low-dimensional space. Dashed line indicates the sensory discrimination axis and grey line indicates the axis of shared variability across trials during passive listening. Black lines indicate possible rotations in the axis of shared variability either toward or away from the discrimination axis during the task-engaged state. A larger angle (8) between the shared variability and the discrimination axes leads to increased discrimination accuracy. <bold>b.</bold> Alignment (cosine similarity) between the discrimination and shared variability axes during passive and active conditions. Error bars represent standard error of the mean. The axes become more aligned during task engagement in A1 (p &lt; 0.001, Wilcoxon signed-rank test) and do not change in dPEG. <bold>c.</bold> Mean selective enhancement of neural target vs. catch discriminability across recording sites for simulated and actual data. Selective enhancement is the difference in Δd-prime for target vs. catch and target vs. target (inset). Simulations sequentially introduced task-dependent changes in mean sound evoked response gain, single neuron variance, and population covariance matching changes in the actual neural data. <bold>d.</bold> Model performance, defined as the correlation coefficient between simulated and actual selective enhancement. Performance of each model was evaluated against the performance of the shared variance model to check for stepwise improvements in predictions. Stars indicate significance at alpha = 0.05 level, bootstrap test. Colors indicate brain regions: dPEG / black, A1 / grey.</p></caption>
<graphic xlink:href="547009v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To directly measure how these population-level changes relate to sound representation and emergent behavioral selectivity in non-primary auditory cortex, we performed simulations based on Factor Analysis model fits in which we sequentially introduced task-dependent changes in mean sound evoked response gain, single neuron variance, and population covariance matching changes in the actual neural data (Methods: Factor Analysis – Simulations). A simulation in which population covariability was fixed and only the evoked response gain changed between passive and active conditions (gain only) was sufficient to produce task-relevant selectivity in non-primary auditory cortex (<xref rid="fig5" ref-type="fig">Figure 5C-D</xref>). Thus, task-dependent changes in evoked response gain, not population covariability, support the emergence of a behaviorally relevant population code in non-primary auditory cortex.</p>
<p>This result is consistent with the fact that population covariability did not change in a systematic way with respect to the sound discrimination axis in non-primary auditory cortex (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). However, in A1 this was not the case. Therefore, we hypothesized that in A1 modeling changes in covariability would be required to explain the observed task-dependent changes in generalized sound discriminability. Indeed, we observed monotonic improvement in the model’s ability to predict overall Δd-prime in A1, confirming that the shared variability model captured real aspects of shared population covariability that contribute to the accuracy of sound representation in A1 (Supplemental Figure 6).</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We observed distinct changes in how neural populations represent sound categories between primary (A1) and non-primary (dPEG) auditory cortex during a challenging tone-in-noise task. In A1, task engagement improved neural coding uniformly across all sound categories, both relevant and irrelevant to the current task. In dPEG, on the other hand, the neural population selectively enhanced the representation only of sound categories relevant to the tone-in-noise behavior. Task-dependent changes neural response gain were sufficient to account for this emergent selectivity. In addition, we observed striking changes in population level correlated activity that were strongly dependent on brain region. The pattern of task-related effects is consistent with a hierarchical, mixed selectivity model of sensory decision-making (<xref ref-type="bibr" rid="c41">Rigotti et al., 2013</xref>). Neural populations in early brain areas form a sparse, overcomplete representation of sensory inputs, which supports a simple linear readout of task-relevant features in downstream areas. The selective changes are measurable only at the population level in dPEG, but a subsequent stage of processing would support category-specific coding by single neurons, as in frontal cortex (<xref ref-type="bibr" rid="c18">Fritz et al., 2010</xref>; <xref ref-type="bibr" rid="c54">Tsunada et al., 2011</xref>).</p>
<sec id="s3a">
<title>Emergent invariant, behaviorally relevant sound representations in non-primary auditory cortex</title>
<p>It has been proposed that auditory cortex dynamically computes representations of task-relevant sound features from non-specific spectro-temporal inputs to A1 (<xref ref-type="bibr" rid="c30">Lestang et al., 2023</xref>). Prior work has established that task-dependent modulation of auditory responses is larger in non-primary versus primary fields of auditory cortex (<xref ref-type="bibr" rid="c2">Atiani et al., 2014</xref>; <xref ref-type="bibr" rid="c28">Kline et al., 2023</xref>; <xref ref-type="bibr" rid="c34">Niwa et al., 2013</xref>). In our study, we asked how specific these changes in neural activity are to the encoding of task-relevant vs. irrelevant sound features. We found a clear dissociation between cortical fields; behaviorally relevant representations first emerged in the non-primary field, dPEG. In the frontal cortex (FC) of ferrets engaged in a similar tone detection behavior, single neuron activity is behaviorally gated. Responses to a set of target tones are strongly enhanced when they require a behavioral response (<xref ref-type="bibr" rid="c18">Fritz et al., 2010</xref>). In our task, the enhanced category representation in dPEG supports a simple linear readout of “go” versus “no-go” categories that could provide input to category-specific neurons in FC.</p>
<p>Consistent with the hypothesis that the selective enhancement of category representation is causally related to behavior, we found that decoding accuracy in dPEG tracked the animal’s behavioral performance. This correlation between neural activity and behavioral performance is consistent with previous observations that choice related activity is present or is stronger in non-primary versus primary auditory cortex (<xref ref-type="bibr" rid="c8">Bizley et al., 2013</xref>; <xref ref-type="bibr" rid="c55">Tsunada et al., 2015</xref>). However, some other studies have reported choice related activity emerging as early as A1 (<xref ref-type="bibr" rid="c36">Niwa et al., 2012b</xref>; <xref ref-type="bibr" rid="c45">Selezneva et al., 2006</xref>), suggesting that the role of different cortical regions in decision making may depend on aspects of the task, including the specifics of the auditory stimuli and the associated motor response. Future studies that precisely stimulate or suppress activity along the auditory pathway may definitively probe the causal role that each region plays in auditory perception.</p>
</sec>
<sec id="s3b">
<title>Population activity reveals hierarchically organized representations in the auditory system</title>
<p>Despite the diverse task-dependent changes in sound representations across individual neurons, analysis of sound discriminability at the population level revealed striking qualitative differences between A1 and dPEG. This finding highlights the value of studying auditory coding at the level of neural populations, which provides a more complete assessment of system-wide function than individual neurons (<xref ref-type="bibr" rid="c4">Bagur et al., 2018</xref>; <xref ref-type="bibr" rid="c30">Lestang et al., 2023</xref>). In our analysis, we defined population coding accuracy as the amount of stimulus information an ideal observer could extract from simultaneously recorded population activity. Thus, our results should be interpreted as an upper bound on the information transmitted by a group of neurons about a particular stimulus. Critically, these measures do not necessarily reflect the information utilized by the animal. In A1, for example, we found a decoding axis for every stimulus category along which task engagement improved sound representation. Despite this global improvement in A1, decoding downstream in dPEG was only improved for task-relevant sounds. This selective change indicates that dPEG does not always read out information optimally from A1. Instead, during the engaged state, it reads out activity along an axis of A1 population activity that is invariant to task-irrelevant stimuli.</p>
<p>At face value, these findings may seem paradoxical. If only one dimension of A1 activity is utilized downstream, why does task engagement improve sound representations so broadly? Theories of neural disentanglement and formation of categorical representations posit that the brain must first build overcomplete, high-dimensional representations of the sensory world (<xref ref-type="bibr" rid="c16">DiCarlo and Cox, 2007</xref>). From this high-dimensional activity, it is straightforward to build a linear decoder, tuned to the task at hand, that extracts only task-relevant information (<xref ref-type="bibr" rid="c41">Rigotti et al., 2013</xref>). Our findings are consistent with this theory and describe a hierarchical network for computing sound category. An overcomplete representation in A1 is selectively filtered at the population level in dPEG, and subsequently this activity may provide input to category-specific neurons in areas such as FC.</p>
</sec>
<sec id="s3c">
<title>Implications for the role of correlated activity in sensory processing</title>
<p>An important advantage of our experimental setup was that we simultaneously recorded the activity of populations of neurons, contrasting with previous studies that built pseudo-populations from serial experiments (<xref ref-type="bibr" rid="c4">Bagur et al., 2018</xref>). This approach allowed us to investigate how trial-by-trial covariability across the population depends on task engagement and contributes to sound encoding. Theoretical work has shown that trial-by-trial covariance can impair population coding accuracy (<xref ref-type="bibr" rid="c3">Averbeck et al., 2006</xref>). Early experiments in visual cortex supported this idea, demonstrating that selective attention improves perceptual discriminations primarily by reducing covariance (<xref ref-type="bibr" rid="c11">Cohen and Maunsell, 2009</xref>). We found task engagement modulated covariability patterns in both A1 and dPEG, broadly consistent with prior work in the auditory system (<xref ref-type="bibr" rid="c17">Downer et al., 2017</xref>).</p>
<p>Strikingly, however, the changes in covariance had no impact on emergent behavioral selectivity in dPEG or on the mean generalized improvement in sound coding in A1. What, then, do these changes in correlated neural activity reflect? In A1, we found that covariability became more aligned with the behaviorally relevant sensory decoding axis during task engagement. This finding is in opposition to a model in which covariability reflects information limiting noise (<xref ref-type="bibr" rid="c5">Bartolo et al., 2020</xref>; <xref ref-type="bibr" rid="c32">Moreno-Bote et al., 2014</xref>; <xref ref-type="bibr" rid="c42">Rumyantsev et al., 2020</xref>). Instead, we hypothesize that covariability in A1 primarily reflects top-down gain modulation that drives changes in selectivity (<xref ref-type="bibr" rid="c15">Denfield et al., 2018</xref>; <xref ref-type="bibr" rid="c19">Goris et al., 2014</xref>; <xref ref-type="bibr" rid="c21">Guo et al., 2017</xref>). During the task-engaged state, top-down signals selectively modulate sound evoked responses of neurons tuned to task-relevant stimuli, thus boosting the representation of task-relevant sounds for downstream readout. If gain is not perfectly static, but varies in strength from trial to trial, this could explain the observed increase in covariability amongst task-relevant neurons (<xref ref-type="bibr" rid="c15">Denfield et al., 2018</xref>). Simultaneous recordings from multiple auditory fields that permit analysis of the communication subspace between areas may provide further insight into the interaction between top-down signals and sound-evoked responses (<xref ref-type="bibr" rid="c46">Semedo et al., 2019</xref>; <xref ref-type="bibr" rid="c50">Srinath et al., 2021</xref>).</p>
<p>In contrast, the direction of covariability in dPEG changed randomly with respect to the behaviorally relevant decoding axis. During both passive and engaged states, covariability remained mostly orthogonal to the sensory decoding axis and therefore had little impact on population decoding accuracy. These findings are consistent with recent work suggesting that trial-by-trial covariability is primarily orthogonal to sensory coding dimensions and reflects non-sensory motor or cognitive variables, such as whisking, running, or arousal (<xref ref-type="bibr" rid="c33">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="c53">Stringer et al., 2019b</xref>). Our results contribute to a growing body of evidence that covariability does not usually reflect information limiting noise, but instead reflects important cognitive processes active in different brain regions during sensory decision making (<xref ref-type="bibr" rid="c50">Srinath et al., 2021</xref>).</p>
</sec>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Surgical procedures</title>
<p>All procedures were approved by the Oregon Health and Science University Institutional Animal Care and Use Committee (IACUC) and conform to the standard of the Association for Assessment and Accreditation of Laboratory Animal Care (AAALAC). Adult male ferrets were acquired from an animal supplier (Marshal Farms). To permit head fixation during neurophysiological recordings and behavioral training, all animals underwent head-post implantation surgeries. Surgeries were performed as described previously (<xref ref-type="bibr" rid="c43">Saderi et al., 2021</xref>; <xref ref-type="bibr" rid="c49">Slee and David, 2015</xref>). Two stainless steel head-posts were fixed to the skull along the midline with bone cement (Palacos or Charisma). Additionally, 8-10 stainless steel screws were inserted into the skull and bonded to the bone cement to form the structure of the implant. After a two-week recovery period, animals were slowly habituated to a head-fixed posture and auditory stimulation. Following behavioral training on the tone-in-noise task (see below), a microcraniotomy (0.5-1mm) was opened above either primary auditory cortex (A1) or the dorsal posterior ectosylvian gyrus (dPEG) to allow for insertion of neurophysiology recording electrodes. Recording sites were targeted based on external landmarks and tonotopic maps (<xref ref-type="bibr" rid="c2">Atiani et al., 2014</xref>; <xref ref-type="bibr" rid="c7">Bizley et al., 2005</xref>). After recordings were complete at one location, the microcraniotomy was allowed to close and a new one was opened at a different location.</p>
</sec>
<sec id="s4b">
<title>Behavioral paradigm</title>
<p>Four adult male ferrets were trained on a positively reinforced, go/no-go tone-in-noise detection task. Throughout behavioral training, animals were provided with free access to water on weekends and placed on partial water restriction during the week. During restriction periods, animals were only able to receive liquid rewards during behavioral training. Supplemental water was provided after a training session, if necessary, to ensure that animals maintained at least 90% of their baseline body weight throughout training.</p>
<p>Single behavioral trials consisted of a sequence of narrow band noise bursts (0.3 octave bandwidth, 0.3 s duration, 0.2 s ISI), followed by a target tone (0.3 s duration). Animals reported the presence of the target tone by licking a water spout. Licks were detected through a piezo electric sensor glued to the spout (2 animals) or by a video camera monitoring the luminance change in a window around the spout (2 animals). Licks occurring during a target window (0.2-1.0 s following target onset) were rewarded with a high-protein, high-calorie supplement (Ensure), while licks outside the window were penalized with a timeout (3 – 10 s). The number of distractor stimuli per trial was distributed randomly with a flat hazard function to prevent behavioral timing strategies. Each behavioral session consisted of 100 - 200 trials. A subset of trials contained an explicit catch stimulus – a noise burst with the same center frequency as the target tone and occurring with the same temporal distribution as targets. Trials containing a catch stimulus were always concluded by a pure tone reminder target, which was rewarded if the animal successfully withheld responding to the catch licked in response to the pure tone.</p>
<p>The center frequencies of distractor noise bursts spanned 3 octaves around the target tone frequency, which was varied randomly between days (0.l–20 kHz). Initially, training sessions contained only a single pure tone target (Inf dB SNR). As training progressed, masking noise was introduced to the target tone in order to increase task difficulty. By the end of training, a single behavioral session could consist of up to 4 different target stimuli (-10 dB, -5 dB, 0 dB, Inf dB). More difficult target stimuli (<italic>e.g.,</italic> -10 dB) occurred more rarely than easier stimuli (<italic>e.g.,</italic> Inf dB) during behavioral sessions to maintain motivation. In all cases, noise masking the target was exactly matched to the catch stimulus (centered at the target frequency). Target frequency was fixed within a session, and variable SNR was achieved by adjusting tone amplitude relative to the fixed masking noise. Neurophysiological recordings proceeded only after animals were able to perform the full, variable SNR task with consistently above chance level performance on –5 dB SNR target tones.</p>
</sec>
<sec id="s4c">
<title>Acoustic stimuli</title>
<p>All experiments were performed in a sound-attenuating chamber (Gretch-Ken). Sound presentation and behavioral control were provided by custom MATLAB software (<ext-link ext-link-type="uri" xlink:href="https://bitbucket.org/lbhb/baphy">https://bitbucket.org/lbhb/baphy</ext-link>). Digital acoustic signals were transformed to analog (National Instruments), amplified (Crown), and delivered through free-field speakers (Manger, 50-35,000 Hz flat gain). Speakers were located 80 cm from the animal at +/- 30 deg. azimuth. Stimuli were presented from a single speaker (left or right). During neurophysiology experiments, the speaker contralateral to the recording hemisphere was used. Sound level was equalized and calibrated against a standard reference (PCB Piezoelectronics).</p>
</sec>
<sec id="s4d">
<title>Neurophysiology</title>
<p>Neurophysiological recordings were performed using 64-channel silicon microelectrode arrays (<xref ref-type="bibr" rid="c48">Shobe et al., 2015</xref>). Electrode contacts were spaced 20 <italic>μ</italic>m horizontally and 25 <italic>μ</italic>m vertically in three columns, collectively spanning 1.05 mm of cortex. Data were amplified (RHD 128-channel headstage, Intan Technologies), digitized at 30 kHz (Open Ephys (<xref ref-type="bibr" rid="c9">Black et al., 2017</xref>)) and saved to disk for offline analysis.</p>
<p>Spike sorting was performed using Kilosort2 (<xref ref-type="bibr" rid="c38">Pachitariu et al., 2016</xref>), followed by curation in phy (<ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/phy">https://github.com/cortex-lab/phy</ext-link>). For all identified spike clusters, we quantified isolation as one minus a contamination percentage, defined based on the cluster’s isolation in feature space. We categorized spikes with isolation &gt;85% as isolated or nearly isolated units and included them in all analyses in this study.</p>
</sec>
<sec id="s4e">
<title>Auditory field localization</title>
<p>Initial recordings targeted A1 using external landmarks (<xref ref-type="bibr" rid="c40">Radtke-Schuller, 2018</xref>). Tuning curves were calculated using pure tone stimuli (100 ms duration, 200 ms ISI, 3-7 octaves). Neurons were confirmed to be in A1 based on stereotypical response properties: short latency responses to sound onset, sharp and consistent frequency tuning across layers, and a characteristic dorsal-ventral tonotopic map across penetrations (<xref ref-type="bibr" rid="c47">Shamma et al., 1993</xref>). Once A1 was located, subsequent craniotomies were opened in small lateral steps. Tuning was measured at each recording site, and the border between A1 and dPEG was defined as the location where the tonotopic map gradient reversed (<xref ref-type="bibr" rid="c2">Atiani et al., 2014</xref>; <xref ref-type="bibr" rid="c7">Bizley et al., 2005</xref>). After all recording sessions were completed, the best frequencies for each penetration were plotted according to their stereotactic coordinates for post-hoc confirmation of the boundary between A1 and dPEG. Ambiguous recording sites that could not be confidently placed into either area based on their frequency tuning were excluded from analysis.</p>
</sec>
<sec id="s4f">
<title>Pupil recording</title>
<p>To account for spontaneous fluctuations in arousal that can modulate cortical activity (<xref ref-type="bibr" rid="c31">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="c44">Schwartz et al., 2020</xref>), infrared video of the animal’s eye was recorded for offline analysis (camera: Adafruit TTL Serial Camera, lens: M12 Lenses PT-2514BMP 25.0mm). The eye ipsilateral to neurophysiological recording site was recorded so that camera hardware did not interfere with contralateral sound stimuli. To measure pupil size, we fit an ellipse to the boundary of the animal’s pupil on each frame using a custom machine learning algorithm based on DenseNet201 (<xref ref-type="bibr" rid="c24">Huang et al., 2018</xref>) and saved the dimensions of the ellipse on each frame. Pupil size was shifted 750 ms relative to spike times in order to account for the previously reported lagged relationship between neural activity and pupil in cortex (<xref ref-type="bibr" rid="c31">McGinley et al., 2015</xref>).</p>
</sec>
<sec id="s4g">
<title>Analysis of behavioral performance</title>
<p>Behavioral performance was measured using d-prime (<xref ref-type="bibr" rid="c20">Green and Swets, 1966</xref>), defined as the z-scored difference between the target hit rate and false alarm rate across a behavior session. We measured false alarm rate from response to the catch stimulus, whose temporal distribution within a trial was explicitly balanced with target locations across trials. Thus, for each target SNR, d-prime described how well theanimal could discriminate that target from the catch stimulus. A d-prime of 0 indicates chance level performance.</p>
</sec>
<sec id="s4h">
<title>Single neuron evoked activity and d-prime</title>
<p>Responses of single neurons to task stimuli were measured by computing each neuron’s peri-stimulus time histogram (PSTH) response to each stimulus. For visualization (e.g., <xref rid="fig2" ref-type="fig">Figure 2</xref>), spiking activity was binned at 20 ms, normalized to its 100 ms pre-stimulus baseline, z-scored, and smoothed with a gaussian kernel of width of 30 ms. Single trial responses were computed as a neuron’s mean z-scored activity during the 300 ms sound evoked window. For active trials, we included responses measured on hit, correct reject, and miss trials. To quantify neural discriminability between catch and target sounds, we measured the difference between the mean z-scored response to target versus catch stimuli (neural d-prime), which is analogous to the behavioral d-prime described above.</p>
</sec>
<sec id="s4i">
<title>Neural population d-prime</title>
<p>To determine how well the activity of simultaneously recorded populations of neurons could discriminate between task stimuli, we measured neural population d-prime. Similar to the single neuron metric, population d-prime was defined as the z-scored difference in the population response to two distinct sound stimuli. We projected high-dimensional z-scored population activity onto a one-dimensional optimal linear discrimination axis to compute d-prime (<xref ref-type="bibr" rid="c1">Abbott and Dayan, 1999</xref>), where Δµ is equal to the mean difference in response to the two stimuli and Σ is the stimulus-independent covariance matrix.
<disp-formula id="ueqn1">
<alternatives><graphic xlink:href="547009v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Prior work has shown that finding an optimal discrimination axis for large neural populations can be unreliable because of overfitting to trial-limited data (<xref ref-type="bibr" rid="c26">Kanitscheider et al., 2015</xref>). To avoid overfitting, we performed decoding-based Dimensionality Reduction (<italic>dDR</italic>) prior to computing the discrimination axis (<xref ref-type="bibr" rid="c22">Heller and David, 2022</xref>). In brief, this procedure projected the population activity into the two-dimensional space spanned by the population covariability axis (noise axis) and sound discrimination axis (signal axis), where <italic>e<sub>1</sub></italic> is the first eigenvector of the population covariance matrix.
<disp-formula id="ueqn2">
<alternatives><graphic xlink:href="547009v1_ueqn2.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
The full dimensionality reduction and decoding procedure was repeated for each stimulus pair individually to avoid bias from stimuli that produced different magnitude responses. Results were grouped into behaviorally relevant (target versus catch) and behaviorally irrelevant (target versus target, distractor versus distractor) categories. To be included in the analysis, we required that a sound stimulus must have been presented in at least five active and five passive trials. Thus, the number of target stimuli analyzed per session depended on animal’s performance and how long they remained engaged in the task; for shorter behavioral sessions, fewer repetitions of each stimulus were presented and target conditions with low repetition count were omitted.</p>
</sec>
<sec id="s4j">
<title>Factor analysis – population metrics</title>
<p>To characterize population-wide covariability we used factor analysis (<xref ref-type="bibr" rid="c56">Umakantha et al., 2021</xref>). Factor analysis is the simplest form of dimensionality reduction that explicitly separates shared variance across neurons from independent variance of single neurons, decomposing the spike count covariance matrix into two parts, a covariance matrix representing shared variance between neurons (Σ<sub>shared</sub>) and a diagonal matrix representing the independent variance of each single neuron (Ψ):
<disp-formula id="ueqn3">
<alternatives><graphic xlink:href="547009v1_ueqn3.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Because we were interested in stimulus-independent trial-trial variance and the role it played in behaviorally relevant sound decoding, we performed this analysis only on responses to the catch stimulus, as this was common to all measurements of pairwise target vs. catch discrimination accuracy. This way, spike-count covariance was not due to changing stimulus conditions and we could directly ask how it interacted with the behaviorally relevant, target vs. catch discrimination axis. We fit a unique Factor Analysis model for each behavior state (active verses passive) and experiment. The number of total factors was selected as the model which maximized log-likelihood. Following prior work, we quantified properties of each Factor Analysis model using three metrics (<xref ref-type="bibr" rid="c56">Umakantha et al., 2021</xref>):</p>
<p><italic>Loading similarity:</italic> Similarity of neuronal loading weights for the Factor that explained maximal shared variance. A value of 0 indicates maximal dissimilarity of weights and a value of 1 indicates that the weights for all neurons are identical.</p>
<p><italic>Percent shared variance (%sv):</italic> The percentage of each neuron’s variance that can be explained using other neurons in the population. Ranges from 0% to 100%.</p>
<p><italic>Dimensionality:</italic> The number of dimensions that maximized log-likelihood. In other words, the rank of the shared spike-count covariance matrix. Integer value.</p>
</sec>
<sec id="s4k">
<title>Factor analysis – simulations</title>
<p>We simulated neural population responses to each target and catch stimulus by drawing samples from a multivariate gaussian distribution (<italic>n</italic> = 2000 responses were generated for each sound / behavior state). The mean response of each neuron was determined using the neuron’s actual PSTH and covariance between neurons was defined as the rank R &lt; N covariance matrix that maximized the likelihood of the Factor Analysis model for each sound stimulus. Data were simulated independently for each behavior state (passive listening vs. active task engagement). We simulated activity with four models:</p>
<sec id="s4k1">
<title>Null</title>
<p>Mean response, independent variance, and covariance of the gaussian distribution were fixed to the active neuron PSTH, active independent variance (Ψ<sub>active</sub>), and active covariance matrix (Σ<sub>shared, active</sub>) for both passive and engaged states. Thus, simulated data (<italic>r<sub>sim</sub></italic>) were statistically identical between passive and engaged conditions.
<disp-formula id="ueqn4">
<alternatives><graphic xlink:href="547009v1_ueqn4.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
</p>
</sec>
<sec id="s4k2">
<title>Gain only</title>
<p>Independent variance and covariance for both passive and engaged states were fixed to the active estimates, but mean was matched to the actual condition’s PSTH. Thus, variance was independent of task but mean evoked response magnitude was allowed to be modulated by task engagement.
<disp-formula id="ueqn5">
<alternatives><graphic xlink:href="547009v1_ueqn5.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
</p>
</sec>
<sec id="s4k3">
<title>Independent variance</title>
<p>Mean evoked response and independent variance were modulated by task engagement. Covariance was fixed between states.
<disp-formula id="ueqn6">
<alternatives><graphic xlink:href="547009v1_ueqn6.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
</p>
</sec>
<sec id="s4k4">
<title>Shared variance</title>
<p>All parameters of the gaussian distribution were matched to the state-dependent estimates.
<disp-formula id="ueqn7">
<alternatives><graphic xlink:href="547009v1_ueqn7.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
</p>
</sec>
</sec>
<sec id="s4l">
<title>Alignment of population covariability axes</title>
<p>To measure the alignment of two population covariability axes, we used the absolute value of their cosine similarity. Thus, alignment ranged from 0 (perfectly orthogonal) to 1 (perfectly aligned). In the noise axis versus discrimination axis alignment analysis, we defined the noise axis as the Factor that explained the most shared variance in the catch response (see above section: Factor Analysis).</p>
</sec>
<sec id="s4m">
<title>Pupil-indexed arousal control</title>
<p>To control for changes in neural activity that were due to non-specific increases in arousal rather than task engagement (<xref ref-type="bibr" rid="c43">Saderi et al., 2021</xref>), we used linear regression to remove variability in the activity of single neurons that could be explained by pupil size. The response of each neuron to each stimulus, <italic>r<sub>i</sub></italic>(<italic>t</italic>), was modeled as a linear function of pupil size, <italic>p</italic>(<italic>t</italic>):
<disp-formula id="ueqn8">
<alternatives><graphic xlink:href="547009v1_ueqn8.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Then, to remove the pupil-explainable variance from each neuron’s response but preserve any pupil-independent effect of task engagement on activity, we defined the corrected firing rate, <italic>r<sub>i</sub></italic>(<italic>t</italic>), as the true response minus the pupil-dependent portion of the regression model:
<disp-formula id="ueqn9">
<alternatives><graphic xlink:href="547009v1_ueqn9.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Thus, the mean sound evoked response was preserved but changes correlated with pupil were removed. This procedure was performed prior to analysis of task-dependent selectivity in dPEG (<italic>e.g.,</italic> <xref rid="fig3" ref-type="fig">Figure 3</xref>). Results were similar for a control analysis that ignored pupil-dependent changes, indicating that the emergent selectivity in dPEG does not depend on this correction for generalized effects arousal (Supplemental Figure 4).</p>
</sec>
<sec id="s4n">
<title>Statistical tests</title>
<p>For each experimental recording session, we measured the decoding performance of multiple stimulus pairs. To control for any statistical dependencies between these data points within a recording session, we first took the mean projection across stimulus pairs within each recording session before measuring p-values. This procedure reduces our statistical power but provides more conservative estimates of statistical significance which are more robust to detecting spurious false positive results. For all pairwise statistical tests shown in <xref rid="fig3" ref-type="fig">Figures 3</xref>, 5, and Supplemental Figure 5 we performed a Wilcoxon signed rank test. Significance was determined at the alpha = 0.05 level. The number of unique recording sessions and animals that went into each comparison are listed in the main text / figure legends, along with the p-value for each analysis.</p>
<p>In <xref rid="fig4" ref-type="fig">Figure 4</xref>, we tested if the change in neural population d-prime was correlated with behavior performance on a per-target stimulus basis. Because each target had different behavioral performance (due to varying SNR), here we treated each stimulus as an independent sample. Therefore, correlation was measured between <italic>n</italic> sessions x <italic>n</italic> target stimuli neural vs. behavioral d-primes. To determine the significance of correlation in each brain region, we performed random bootstrap resampling to generate a null distribution of correlation values. The correlation for a given brain region was deemed significant if the actual observed correlation was greater than the 97.5-percentile of the null distribution.</p>
<p>To evaluate the performance of FA model simulations in predicting behavioral selectivity (<xref rid="fig5" ref-type="fig">Figure 5</xref>) and Δ d-prime (Supplemental Figure 6), we measured the correlation between simulated and actual metrics for each model. To determine if stepwise changes in the FA model (<italic>e.g.,</italic> adding task-dependent gain modulation) caused significant improvements in model performance, we compared correlation coefficients for each model to the correlation coefficient for the final model. To do this, we computed 1000 bootstrap resamples of the correlation coefficient for each model. If the 97.5-percentile of this distribution was greater than the observed correlation for the full model, we determined that it was not significantly different. That is, if the observed correlation for the full model lay within the 95% confidence interval of the null bootstrapped distribution for a given model, it was determined to not be significantly different than the full model.</p>
</sec>
</sec>
<sec id="d1e1060" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1142">
<label>Supplemental data figures</label>
<media xlink:href="supplements/547009_file02.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Abbott</surname> <given-names>LF</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P</given-names></string-name>. <year>1999</year>. <article-title>The effect of correlated variability on the accuracy of a population code</article-title>. <source>Neural Computation</source> <volume>11</volume>:<fpage>91</fpage>–<lpage>101</lpage>. doi:<pub-id pub-id-type="doi">10.1162/089976699300016827</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Atiani</surname> <given-names>S</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>, <string-name><surname>Elgueda</surname> <given-names>D</given-names></string-name>, <string-name><surname>Locastro</surname> <given-names>M</given-names></string-name>, <string-name><surname>Radtke-Schuller</surname> <given-names>S</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Fritz</surname> <given-names>JB</given-names></string-name>. <year>2014</year>. <article-title>Emergent selectivity for task-relevant stimuli in higher-order auditory cortex</article-title>. <source>Neuron</source> <volume>82</volume>:<fpage>486</fpage>–<lpage>499</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2014.02.029</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Averbeck</surname> <given-names>BB</given-names></string-name>, <string-name><surname>Latham</surname> <given-names>PE</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A</given-names></string-name>. <year>2006</year>. <article-title>Neural correlations, population coding and computation</article-title>. <source>Nature reviews Neuroscience</source> <volume>7</volume>:<fpage>358</fpage>–<lpage>66</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nrn1888</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Bagur</surname> <given-names>S</given-names></string-name>, <string-name><surname>Averseng</surname> <given-names>M</given-names></string-name>, <string-name><surname>Elgueda</surname> <given-names>D</given-names></string-name>, <string-name><surname>David</surname> <given-names>S</given-names></string-name>, <string-name><surname>Fritz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Yin</surname> <given-names>P</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>S</given-names></string-name>, <string-name><surname>Boubenec</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Ostojic</surname> <given-names>S</given-names></string-name>. <year>2018</year>. <article-title>Go/No-Go task engagement enhances population representation of target stimuli in primary auditory cortex</article-title>. <source>Nature communications</source> <volume>9</volume>:<fpage>2529</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-018-04839-9</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Bartolo</surname> <given-names>R</given-names></string-name>, <string-name><surname>Saunders</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Mitz</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Averbeck</surname> <given-names>BB</given-names></string-name>. <year>2020</year>. <article-title>Information-limiting correlations in large neural populations</article-title>. <source>Journal of Neuroscience</source> <volume>40</volume>:<fpage>1668</fpage>–<lpage>1678</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Bizley</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>YE</given-names></string-name>. <year>2013</year>. <article-title>The what, where and how of auditory-object perception</article-title>. <source>Nature Reviews Neuroscience</source> <volume>14</volume>:<fpage>693</fpage>–<lpage>707</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nrn3565</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Bizley</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Nodal</surname> <given-names>FR</given-names></string-name>, <string-name><surname>Nelken</surname> <given-names>I</given-names></string-name>, <string-name><surname>King</surname> <given-names>AJ</given-names></string-name>. <year>2005</year>. <article-title>Functional organization of ferret auditory cortex</article-title>. <source>Cerebral Cortex</source> <volume>15</volume>:<fpage>1637</fpage>–<lpage>1653</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Bizley</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Walker</surname> <given-names>KMM</given-names></string-name>, <string-name><surname>Nodal</surname> <given-names>FR</given-names></string-name>, <string-name><surname>King</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Schnupp</surname> <given-names>JWH</given-names></string-name>. <year>2013</year>. <article-title>Auditory cortex represents both pitch judgments and the corresponding acoustic cues</article-title>. <source>Current Biology</source> <volume>23</volume>:<fpage>620</fpage>–<lpage>5</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2013.03.003</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Black</surname> <given-names>C</given-names></string-name>, <string-name><surname>Voigts</surname> <given-names>J</given-names></string-name>, <string-name><surname>Agrawal</surname> <given-names>U</given-names></string-name>, <string-name><surname>Ladow</surname> <given-names>M</given-names></string-name>, <string-name><surname>Santoyo</surname> <given-names>J</given-names></string-name>, <string-name><surname>Moore</surname> <given-names>C</given-names></string-name>, <string-name><surname>Jones</surname> <given-names>S</given-names></string-name>. <year>2017</year>. <article-title>Open Ephys electroencephalography (Open Ephys + EEG): a modular, low-cost, open-source solution to human neural recording</article-title>. <source>Journal of neural engineering</source> <volume>14</volume>:<fpage>035002</fpage>. doi:<pub-id pub-id-type="doi">10.1088/1741-2552/aa651f</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Buran</surname> <given-names>BN</given-names></string-name>, <string-name><surname>von Trapp</surname> <given-names>G</given-names></string-name>, <string-name><surname>Sanes</surname> <given-names>DH.</given-names></string-name> <year>2014</year>. <article-title>Behaviorally gated reduction of spontaneous discharge can improve detection thresholds in auditory cortex</article-title>. <source>Journal of Neuroscience</source> <volume>34</volume>:<fpage>4076</fpage>–<lpage>81</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.4825-13.2014</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Cohen</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Maunsell</surname> <given-names>JHR</given-names></string-name>. <year>2009</year>. <article-title>Attention improves performance primarily by reducing interneuronal correlations</article-title>. <source>Nature neuroscience</source> <volume>12</volume>:<fpage>1594</fpage>–<lpage>1600</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2439</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Cowley</surname> <given-names>BR</given-names></string-name>, <string-name><surname>Snyder</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Acar</surname> <given-names>K</given-names></string-name>, <string-name><surname>Williamson</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>BM</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>MA</given-names></string-name>. <year>2020</year>. <article-title>Slow Drift of Neural Activity as a Signature of Impulsivity in Macaque Visual and Prefrontal Cortex</article-title>. <source>Neuron</source> <volume>108</volume>:<fpage>551</fpage>–<lpage>567</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2020.07.021</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>David</surname> <given-names>SV</given-names></string-name>, <string-name><surname>Fritz</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>. <year>2012</year>. <article-title>Task reward structure shapes rapid receptive field plasticity in auditory cortex</article-title>. <source>Proceedings of the National Academy of Science USA</source> <volume>109</volume>:<fpage>2150</fpage>–<lpage>55</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1117717109</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>de Gee</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Mridha</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Hudson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Shi</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Ramsaywak</surname> <given-names>H</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>S</given-names></string-name>, <string-name><surname>Karediya</surname> <given-names>N</given-names></string-name>, <string-name><surname>Thompson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jaspe</surname> <given-names>K</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>W.</given-names></string-name> <year>2022</year>. <article-title>Mice regulate their attentional intensity and arousal to exploit increases in task utility</article-title>. <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Denfield</surname> <given-names>GH</given-names></string-name>, <string-name><surname>Ecker</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Shinn</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Bethge</surname> <given-names>M</given-names></string-name>, <string-name><surname>Tolias</surname> <given-names>AS</given-names></string-name>. <year>2018</year>. <article-title>Attentional fluctuations induce shared variability in macaque primary visual cortex</article-title>. <source>Nature communications</source> <volume>9</volume>:<fpage>2654</fpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>DiCarlo</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Cox</surname> <given-names>DD</given-names></string-name>. <year>2007</year>. <article-title>Untangling invariant object recognition</article-title>. <source>Trends in cognitive sciences</source> <volume>11</volume>:<fpage>333</fpage>–<lpage>41</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2007.06.010</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Downer</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Niwa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sutter</surname> <given-names>ML</given-names></string-name>. <year>2017</year>. <article-title>Hierarchical differences in population coding within auditory cortex</article-title>. <source>Journal of Neurophysiology</source> <volume>118</volume>:<fpage>717</fpage>–<lpage>731</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Fritz</surname> <given-names>JB</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>, <string-name><surname>Radtke-Schuller</surname> <given-names>S</given-names></string-name>, <string-name><surname>Yin</surname> <given-names>P</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>. <year>2010</year>. <article-title>Adaptive, behaviorally gated, persistent encoding of task-relevant auditory information in ferret frontal cortex</article-title>. <source>Nature Neuroscience</source> <volume>13</volume>:<fpage>1011</fpage>–<lpage>9</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2598</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Goris</surname> <given-names>RLT</given-names></string-name>, <string-name><surname>Movshon</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Simoncelli</surname> <given-names>EP</given-names></string-name>. <year>2014</year>. <article-title>Partitioning neuronal variability</article-title>. <source>Nature neuroscience</source> <volume>17</volume>:<fpage>858</fpage>–<lpage>65</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.3711</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="book"><string-name><surname>Green</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Swets</surname> <given-names>J</given-names></string-name>. <year>1966</year>. <source>Signal detection theory and psychophysics</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Guo</surname> <given-names>W</given-names></string-name>, <string-name><surname>Clause</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Barth-Maron</surname> <given-names>A</given-names></string-name>, <string-name><surname>Polley</surname> <given-names>DB</given-names></string-name>. <year>2017</year>. <article-title>A Corticothalamic Circuit for Dynamic Switching between Feature Detection and Discrimination</article-title>. <source>Neuron</source> <volume>95</volume>:<fpage>180</fpage>–<lpage>194</lpage>.e5. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.019</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Heller</surname> <given-names>CR</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>. <year>2022</year>. <article-title>Targeted dimensionality reduction enables reliable estimation of neural population coding accuracy from trial-limited data</article-title>. <source>PLOS ONE</source> <volume>17</volume>:<fpage>e0271136</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0271136</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Hillenbrand</surname> <given-names>J</given-names></string-name>, <string-name><surname>Getty</surname> <given-names>LA</given-names></string-name>, <string-name><surname>Clark</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Wheeler</surname> <given-names>K</given-names></string-name>. <year>1995</year>. <article-title>Acoustic characteristics of American English vowels</article-title>. <source>The Journal of the Acoustical society of America</source> <volume>97</volume>:<fpage>3099</fpage>–<lpage>3111</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Huang</surname> <given-names>G</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>Z</given-names></string-name>, <string-name><surname>van der Maaten</surname> <given-names>L</given-names></string-name>, <string-name><surname>Weinberger</surname> <given-names>KQ.</given-names></string-name> <year>2018</year>. <source>Densely Connected Convolutional Networks</source>. doi:<pub-id pub-id-type="doi">10.48550/arXiv.1608.06993</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Kafashan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jaffe</surname> <given-names>AW</given-names></string-name>, <string-name><surname>Chettih</surname> <given-names>SN</given-names></string-name>, <string-name><surname>Nogueira</surname> <given-names>R</given-names></string-name>, <string-name><surname>Arandia-Romero</surname> <given-names>I</given-names></string-name>, <string-name><surname>Harvey</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Moreno-Bote</surname> <given-names>R</given-names></string-name>, <string-name><surname>Drugowitsch</surname> <given-names>J</given-names></string-name>. <year>2021</year>. <article-title>Scaling of sensory information in large neural populations shows signatures of information-limiting correlations</article-title>. <source>Nature communications</source> <volume>12</volume>:<fpage>473</fpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Kanitscheider</surname> <given-names>I</given-names></string-name>, <string-name><surname>Coen-Cagli</surname> <given-names>R</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A</given-names></string-name>. <year>2015</year>. <article-title>Origin of information-limiting noise correlations</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>112</volume>:<fpage>E6973</fpage>–<lpage>E6982</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Kell</surname> <given-names>AJE</given-names></string-name>, <string-name><surname>Yamins</surname> <given-names>DLK</given-names></string-name>, <string-name><surname>Shook</surname> <given-names>EN</given-names></string-name>, <string-name><surname>Norman-Haignere</surname> <given-names>SV</given-names></string-name>, <string-name><surname>McDermott</surname> <given-names>JH</given-names></string-name>. <year>2018</year>. <article-title>A Task-Optimized Neural Network Replicates Human Auditory Behavior, Predicts Brain Responses, and Reveals a Cortical Processing Hierarchy</article-title>. <source>Neuron</source> <volume>98</volume>:<fpage>630</fpage>–<lpage>644</lpage>.e16. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2018.03.044</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Kline</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Aponte</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Kato</surname> <given-names>HK.</given-names></string-name> <year>2023</year>. <article-title>Distinct nonlinear spectrotemporal integration in primary and secondary auditory cortices</article-title>. <source>bioRxiv</source> <fpage>2023</fpage>–<lpage>01</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Kuchibhotla</surname> <given-names>KV</given-names></string-name>, <string-name><surname>Gill</surname> <given-names>JV</given-names></string-name>, <string-name><surname>Lindsay</surname> <given-names>GW</given-names></string-name>, <string-name><surname>Papadoyannis</surname> <given-names>ES</given-names></string-name>, <string-name><surname>Field</surname> <given-names>RE</given-names></string-name>, <string-name><surname>Sten</surname> <given-names>TAHH</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>KD</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name>. <year>2017</year>. <article-title>Parallel processing by cortical inhibition enables context-dependent behavior</article-title>. <source>Nature Neuroscience</source> <volume>20</volume>:<fpage>62</fpage>–<lpage>71</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.4436</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Lestang</surname> <given-names>J-H</given-names></string-name>, <string-name><surname>Cai</surname> <given-names>H</given-names></string-name>, <string-name><surname>Averbeck</surname> <given-names>BB</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>YE</given-names></string-name>. <year>2023</year>. <article-title>Functional network properties of the auditory cortex</article-title>. <source>Hearing Research</source> <volume>108768</volume>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>McGinley</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>, <string-name><surname>McCormick</surname> <given-names>DA</given-names></string-name>. <year>2015</year>. <article-title>Cortical membrane potential signature of optimal states for sensory signal detection</article-title>. <source>Neuron</source> <volume>87</volume>:<fpage>179</fpage>–<lpage>192</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Moreno-Bote</surname> <given-names>R</given-names></string-name>, <string-name><surname>Beck</surname> <given-names>J</given-names></string-name>, <string-name><surname>Kanitscheider</surname> <given-names>I</given-names></string-name>, <string-name><surname>Pitkow</surname> <given-names>X</given-names></string-name>, <string-name><surname>Latham</surname> <given-names>P</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A</given-names></string-name>. <year>2014</year>. <article-title>Information-limiting correlations</article-title>. <source>Nature neuroscience</source> <volume>17</volume>:<fpage>1410</fpage>–<lpage>1417</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Musall</surname> <given-names>S</given-names></string-name>, <string-name><surname>Kaufman</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Juavinett</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Gluf</surname> <given-names>S</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>AK</given-names></string-name>. <year>2019</year>. <article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title>. <source>Nature Neuroscience</source> <volume>22</volume>:<fpage>1677</fpage>–<lpage>1686</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Niwa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>JS</given-names></string-name>, <string-name><surname>O’Connor</surname> <given-names>KN</given-names></string-name>, <string-name><surname>Sutter</surname> <given-names>ML</given-names></string-name>. <year>2013</year>. <article-title>Differences between primary auditory cortex and auditory belt related to encoding and choice for AM sounds</article-title>. <source>Journal of Neuroscience</source> <volume>33</volume>:<fpage>8378</fpage>–<lpage>95</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2672-12.2013</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Niwa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>JS</given-names></string-name>, <string-name><surname>O’Connor</surname> <given-names>KN</given-names></string-name>, <string-name><surname>Sutter</surname> <given-names>ML</given-names></string-name>. <year>2012a</year>. <article-title>Active engagement improves primary auditory cortical neurons’ ability to discriminate temporal modulation</article-title>. <source>Journal of Neuroscience</source> <volume>32</volume>:<fpage>9323</fpage>–<lpage>34</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.5832-11.2012</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Niwa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>JS</given-names></string-name>, <string-name><surname>O’Connor</surname> <given-names>KN</given-names></string-name>, <string-name><surname>Sutter</surname> <given-names>ML</given-names></string-name>. <year>2012b</year>. <article-title>Activity related to perceptual judgment and action in primary auditory cortex</article-title>. <source>Journal of Neuroscience</source> <volume>32</volume>:<fpage>3193</fpage>–<lpage>3210</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>O’Sullivan</surname> <given-names>J</given-names></string-name>, <string-name><surname>Herrero</surname> <given-names>J</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>E</given-names></string-name>, <string-name><surname>Schevon</surname> <given-names>C</given-names></string-name>, <string-name><surname>McKhann</surname> <given-names>GM</given-names></string-name>, <string-name><surname>Sheth</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Mehta</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Mesgarani</surname> <given-names>N</given-names></string-name>. <year>2019</year>. <article-title>Hierarchical Encoding of Attended Auditory Objects in Multi-talker Speech Perception</article-title>. <source>Neuron</source> <volume>104</volume>:<fpage>1195</fpage>–<lpage>1209</lpage>.e3. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.007</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>N</given-names></string-name>, <string-name><surname>Kadir</surname> <given-names>S</given-names></string-name>, <string-name><surname>Carandini</surname> <given-names>M</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name>. <year>2016</year>. <source>Kilosort: realtime spike-sorting for extracellular electrophysiology with hundreds of channels</source>. doi:<pub-id pub-id-type="doi">10.1101/061481</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Rabinowitz</surname> <given-names>NC</given-names></string-name>, <string-name><surname>Goris</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>M</given-names></string-name>, <string-name><surname>Simoncelli</surname> <given-names>EP</given-names></string-name>. <year>2015</year>. <article-title>Attention stabilizes the shared gain of V4 populations</article-title>. <source>eLife</source> <volume>4</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.08998</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Radtke-Schuller</surname> <given-names>S</given-names></string-name>. <year>2018</year>. <article-title>Cyto- and Myeloarchitectural Brain Atlas of the Ferret (Mustela putorius) in MRI Aided Stereotaxic Coordinates</article-title>. <source>Cham: Springer International Publishing</source>. doi:<pub-id pub-id-type="doi">10.1007/978-3-319-76626-3</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Rigotti</surname> <given-names>M</given-names></string-name>, <string-name><surname>Barak</surname> <given-names>O</given-names></string-name>, <string-name><surname>Warden</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>X-J</given-names></string-name>, <string-name><surname>Daw</surname> <given-names>ND</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>EK</given-names></string-name>, <string-name><surname>Fusi</surname> <given-names>S</given-names></string-name>. <year>2013</year>. <article-title>The importance of mixed selectivity in complex cognitive tasks</article-title>. <source>Nature</source> <volume>497</volume>:<fpage>585</fpage>–<lpage>590</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Rumyantsev</surname> <given-names>OI</given-names></string-name>, <string-name><surname>Lecoq</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Hernandez</surname> <given-names>O</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Savall</surname> <given-names>J</given-names></string-name>, <string-name><surname>Chrapkiewicz</surname> <given-names>R</given-names></string-name>, <string-name><surname>Li</surname> <given-names>J</given-names></string-name>, <string-name><surname>Zeng</surname> <given-names>H</given-names></string-name>, <string-name><surname>Ganguli</surname> <given-names>S</given-names></string-name>, <string-name><surname>Schnitzer</surname> <given-names>MJ</given-names></string-name>. <year>2020</year>. <article-title>Fundamental bounds on the fidelity of sensory cortical coding</article-title>. <source>Nature</source> <volume>580</volume>:<fpage>100</fpage>–<lpage>105</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41586-020-2130-2</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Saderi</surname> <given-names>D</given-names></string-name>, <string-name><surname>Schwartz</surname> <given-names>ZP</given-names></string-name>, <string-name><surname>Heller</surname> <given-names>CR</given-names></string-name>, <string-name><surname>Pennington</surname> <given-names>JR</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>. <year>2021</year>. <article-title>Dissociation of task engagement and arousal effects in auditory cortex and midbrain</article-title>. <source>Elife</source> <volume>10</volume>:<fpage>e60153</fpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Schwartz</surname> <given-names>ZP</given-names></string-name>, <string-name><surname>Buran</surname> <given-names>BN</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>. <year>2020</year>. <article-title>Pupil-associated states modulate excitability but not stimulus selectivity in primary auditory cortex</article-title>. <source>Journal of Neurophysiology</source> <volume>123</volume>:<fpage>191</fpage>–<lpage>208</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00595.2019</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Selezneva</surname> <given-names>E</given-names></string-name>, <string-name><surname>Scheich</surname> <given-names>H</given-names></string-name>, <string-name><surname>Brosch</surname> <given-names>M</given-names></string-name>. <year>2006</year>. <article-title>Dual time scales for categorical decision making in auditory cortex</article-title>. <source>Current Biology</source> <volume>16</volume>:<fpage>2428</fpage>–<lpage>2433</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Semedo</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Zandvakili</surname> <given-names>A</given-names></string-name>, <string-name><surname>Machens</surname> <given-names>CK</given-names></string-name>, <string-name><surname>Byron</surname> <given-names>MY</given-names></string-name>, <string-name><surname>Kohn</surname> <given-names>A</given-names></string-name>. <year>2019</year>. <article-title>Cortical areas interact through a communication subspace</article-title>. <source>Neuron</source> <volume>102</volume>:<fpage>249</fpage>–<lpage>259</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Fleshman</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Wiser</surname> <given-names>PR</given-names></string-name>, <string-name><surname>Versnel</surname> <given-names>H</given-names></string-name>. <year>1993</year>. <article-title>Organization of response areas in ferret primary auditory cortex</article-title>. <source>Journal of neurophysiology</source> <volume>69</volume>:<fpage>367</fpage>–<lpage>83</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Shobe</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Claar</surname> <given-names>LD</given-names></string-name>, <string-name><surname>Parhami</surname> <given-names>S</given-names></string-name>, <string-name><surname>Bakhurin</surname> <given-names>KI</given-names></string-name>, <string-name><surname>Masmanidis</surname> <given-names>SC</given-names></string-name>. <year>2015</year>. <article-title>Brain activity mapping at multiple scales with silicon microprobes containing 1,024 electrodes</article-title>. <source>Journal of neurophysiology</source> <volume>114</volume>:<fpage>2043</fpage>–<lpage>52</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00464.2015</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Slee</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>David</surname> <given-names>SV</given-names></string-name>. <year>2015</year>. <article-title>Rapid task-related plasticity of spectro-temporal receptive fields in the auditory midbrain</article-title>. <source>Journal of Neuroscience</source> <volume>35</volume>:<fpage>13090</fpage>–<lpage>102</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1671-15.2015</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Srinath</surname> <given-names>R</given-names></string-name>, <string-name><surname>Ruff</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>MR</given-names></string-name>. <year>2021</year>. <article-title>Attention improves information flow between neuronal populations without changing the communication subspace</article-title>. <source>Current Biology</source> <volume>31</volume>:<fpage>5299</fpage>–<lpage>5313</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Stilp</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Kluender</surname> <given-names>KR</given-names></string-name>. <year>2010</year>. <article-title>Cochlea-scaled entropy, not consonants, vowels, or time, best predicts speech intelligibility</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>107</volume>:<fpage>12387</fpage>–<lpage>92</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.0913625107</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Stringer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>N</given-names></string-name>, <string-name><surname>Carandini</surname> <given-names>M</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name>. <year>2019a</year>. <article-title>High-dimensional geometry of population responses in visual cortex</article-title>. <source>Nature</source> <volume>571</volume>:<fpage>361</fpage>–<lpage>365</lpage>. doi:<pub-id pub-id-type="doi">10.1101/374090</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Stringer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>N</given-names></string-name>, <string-name><surname>Reddy</surname> <given-names>CB</given-names></string-name>, <string-name><surname>Carandini</surname> <given-names>M</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name>. <year>2019b</year>. <article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title>. <source>Science</source> <volume>364</volume>. doi:<pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Tsunada</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>YE</given-names></string-name>. <year>2011</year>. <article-title>Representation of speech categories in the primate auditory cortex</article-title>. <source>Journal of neurophysiology</source> <volume>105</volume>:<fpage>2634</fpage>–<lpage>46</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00037.2011</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Tsunada</surname> <given-names>J</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>ASK</given-names></string-name>, <string-name><surname>Gold</surname> <given-names>JI</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>YE</given-names></string-name>. <year>2015</year>. <article-title>Causal contribution of primate auditory cortex to auditory perceptual decision-making</article-title>. <source>Nature Neuroscience</source> <volume>19</volume>:<fpage>135</fpage>–<lpage>142</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.4195</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Umakantha</surname> <given-names>A</given-names></string-name>, <string-name><surname>Morina</surname> <given-names>R</given-names></string-name>, <string-name><surname>Cowley</surname> <given-names>BR</given-names></string-name>, <string-name><surname>Snyder</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Byron</surname> <given-names>MY</given-names></string-name>. <year>2021</year>. <article-title>Bridging neuronal correlations and dimensionality reduction</article-title>. <source>Neuron</source> <volume>109</volume>:<fpage>2740</fpage>–<lpage>2754</lpage>.</mixed-citation></ref>
</ref-list>
<sec id="s5">
<title>Author Contributions</title>
<p>C.R.H and S.V.D designed experiments and C.R.H. and G.R.H carried out data collection. C.R.H. analyzed the data. All authors contributed to writing of the manuscript.</p>
</sec>
<sec id="s6">
<title>Competing Interests statement</title>
<p>The authors declare no competing interests.</p>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89936.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ding</surname>
<given-names>Nai</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Zhejiang University</institution>
</institution-wrap>
<city>Hangzhou</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study provides <bold>important</bold> insights into how the brain constructs categorical neural representations during a difficult auditory target detection task. Through simultaneous recordings from primary and secondary auditory areas, <bold>compelling</bold> evidence is provided that categorical neural representations emerge in a secondary auditory area, i.e., PEG. The study is of interests to neuroscientists and can also potentially shed light on human psychological studies</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89936.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This is a very interesting paper which addresses how auditory cortex represents sound while an animal is performing an auditory task. The study involves psychometric and neurophysiological measurement from ferrets engaged in a challenging tone in noise discrimination task, and relates these measurements using neurometric analysis. A novel neural decoding technique (decoding-based dimensionality reduction or dDR, introduced in a previous paper by two of the authors) is used to reduce bias so that stimulus parameters can be read out from neuronal responses.</p>
<p>The central finding of the study is that, when an animal is engaged in a task, non-primary auditory cortex represents task-relevant sound features in a categorical way. In primary cortex, task engagement also affects representations, but in a different way - the decoding is improved (suggesting that representations have been enhanced), but is not categorical in nature. The authors argue that these results are compatible with a model where early sensory representations form an overcomplete representation of the world, and downstream neurons flexibly read out behaviourally relevant information from these representations.</p>
<p>I find the concept and execution of the study very interesting and elegant. The paper is also commendably clear and readable. The differences between primary and higher cortex are compelling and I am largely convinced by the authors' claim that they have found evidence that broadly supports a mixed selectivity model of neural disentanglement along the lines of Rigotti et al (2013). I think that the increasing body of evidence for these kinds of representations is a significant development in our understanding of higher sensory representations. I also think that the dDR method is likely to be useful to researchers in a variety of fields who are looking to perform similar types of neural decoding analysis.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89936.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This study compares the activity of neural populations in the primary and non-primary auditory cortex of ferrets while the animals actively behaved or passively listened to a sound discrimination task. Using a variety of methods, the authors convincingly show differential effects of task engagement on population neural activity in primary vs non-primary auditory cortex; notably that in the primary auditory cortex, task-engagement (1) improves discriminability for both task-relevant and non-task relevant dimensions, and (2) improves the alignment between covariability and sound discrimination axes; whereas in the non-primary auditory cortex, task-engagement (1) improves discriminability for only task-relevant dimensions, and (2) does not affect the alignment between covariability and sound discrimination axes. They additionally show that task-engagement changes in gain can account for the selectivity noted in the discriminability of non-primary auditory neurons. They also admirably attempt to isolate task-engagement from arousal fluctuations, by using fluctuations in pupil size as a proxy for physiological arousal. This is a well-carried out study with thoughtful analyses which in large part achieves its aims to evaluate how task-engagement changes neural activity across multiple auditory regions. As with all work, there are several caveats or areas for future study/analysis. First, the sounds used here (tones, and narrow-band noise) are relatively simple sounds; previous work suggests that exactly what activity is observed within each region (e.g., sensory only, decision-related, etc) may depend in part upon what stimuli are used. Therefore, while the current study adds importantly to the literature, future work may consider the use of more varied stimuli. Second, the animals here were engaged in a behavioral task; but apart from an initial calculation of behavioral d', the task performance (and its effect on neural activity) is largely unaddressed.</p>
</body>
</sub-article>
</article>