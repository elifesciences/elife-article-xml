<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">85646</article-id>
<article-id pub-id-type="doi">10.7554/eLife.85646</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.85646.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Parahippocampal neurons encode task-relevant information for goal-directed navigation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7328-9533</contrib-id>
<name>
<surname>Gonzalez</surname>
<given-names>Alexander</given-names>
</name>
<xref ref-type="corresp" rid="cor1">*</xref>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0416-2528</contrib-id>
<name>
<surname>Giocomo</surname>
<given-names>Lisa M.</given-names>
</name>
<xref ref-type="corresp" rid="cor2">†</xref>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Neurobiology, Stanford University School of Medicine</institution>, Stanford, California 94035</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding author: <email>alex.gonzalez@stanford.edu</email></corresp>
<corresp id="cor2"><label>†</label>Corresponding author: <email>giocomo@stanford.edu</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-03-09">
<day>09</day>
<month>03</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP85646</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-01-05">
<day>05</day>
<month>01</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2022-12-15">
<day>15</day>
<month>12</month>
<year>2022</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.12.15.520660"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Gonzalez &amp; Giocomo</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Gonzalez &amp; Giocomo</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-85646-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>A behavioral strategy crucial to survival is directed navigation to a goal, such as a food or home location. One potential neural substrate for supporting goal-directed navigation is the parahippocampus, which contains neurons that represent an animal’s position, orientation, and movement through the world, and that change their firing activity to encode behaviorally relevant variables such as reward. However, little prior work on the parahippocampus has considered how neurons encode variables during goal-directed navigation in environments that dynamically change. Here, we recorded single units from rat parahippocampal cortex while subjects performed a goal-directed task. The maze dynamically changed goal-locations via a visual cue on a trial-to-trial basis, requiring subjects to use cue-location associations to receive reward. We observed a mismatch-like signal, with elevated neural activity on incorrect trials, leading to rate-remapping. The strength of this remapping correlated with task performance. Recordings during open-field foraging allowed us to functionally define navigational coding for a subset of the neurons recorded in the maze. This approach revealed that head-direction coding units remapped more than other functional-defined units. Taken together, this work thus raises the possibility that during goal-directed navigation, parahippocampal neurons encode error information reflective of an animal’s behavioral performance.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Navigation to a goal location, such as a food source or home, is a behavior central to the survival of many species. This behavior begins with a serial transformation of sensory inputs and ends in a sequence of motor actions reflective of a movement decision. Between sensation and motor action, several parahippocampal regions represent variables theorized to support the computations needed for goal-directed navigation. These regions include the medial entorhinal cortex (MEC) and pre- and para-subiculum (PrS, PaS), which contain functionally defined neurons that encode an animal’s spatial position, orientation and movement through the external environment [<xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c6">6</xref>]. Additionally, the PrS and PaS project to the MEC, which is reciprocally connected to the hippocampus [<xref ref-type="bibr" rid="c7">7</xref>], a region strongly implicated in supporting memory and navigation [<xref ref-type="bibr" rid="c8">8</xref>–<xref ref-type="bibr" rid="c10">10</xref>]. However, much of the prior work characterizing functionally defined neurons in MEC, PrS and PaS has considered neural activity recorded as rodents forage for random food rewards in open fields environments. One limitation inherent to such open field foraging behavioral data sets is the lack of pre-defined decision points, which creates challenges to understanding the relationship between neural activity and goal-directed navigation. While several studies have attempted to addresses these challenges by utilizing linear environments, these works typically employed alternation tasks that lack experimental control over decision making junctures [<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>]. Thus, how parahippocampal neurons encode navigational variables during goal-directed navigation in complex environments remains incompletely characterized.</p>
<p>Goal directed navigation encompasses both spatial and non-spatial coding elements, as an animal must estimate its current body position, head orientation, and running speed and integrate knowledge of behav-iorally relevant goals or sensory cues. Both the MEC and PaS contain large populations of neurons that encode navigationally relevant variables for computing an animals spatial position, including: body position, head direction and running speed. Individual MEC neurons often exhibit a mixture in their selectivity for encoding these variables and, while 50 % of MEC neurons can be classified using tuning curve based metrics, a larger proportion of neurons can be classified using more unbiased statistical approaches [<xref ref-type="bibr" rid="c13">13</xref>–<xref ref-type="bibr" rid="c15">15</xref>]. In the PaS, 50 % of neurons code for heading direction [<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c16">16</xref>], with coding for position or running speed present in about 40% neurons [<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c16">16</xref>]. MEC has also been shown to contain neurons that encode variables related to non-spatial features of a task or behavior. For example, subsets of MEC neurons encode time-elapsed during immobility [<xref ref-type="bibr" rid="c17">17</xref>], change their firing rate or the spatial location at which they are maximally active in response to reward locations [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>], and encode an animal’s position in task-relevant space during a non-spatial auditory frequency task [<xref ref-type="bibr" rid="c20">20</xref>].</p>
<p>In addition to encoding navigationally relevant variables, parahippocampal regions have been proposed to indirectly support memory through the reciprocal projections to the hippocampal formation [<xref ref-type="bibr" rid="c9">9</xref>]. Depending on the task, goal-directed navigational behaviors might require knowledge of remembered cue-reward associations or memory of previous rewarded or behaviorally significant spatial locations [<xref ref-type="bibr" rid="c21">21</xref>–<xref ref-type="bibr" rid="c23">23</xref>]. At the level of neural activity, these types of memory associations may be facilitated by changes in neural activity that occur in response to changes in environmental sensory cues, such as new visual landmarks, or the presence of a reward [<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref>]. For example, in the hippocampus, place cells that are active in one or a few spatial locations will move the spatial position at which they are maximally active across different open-field environments, a phenomenon referred to as ‘global remapping’. Place cells can also change their firing rate, a phenomenon referred to as ‘rate remapping’, which can occur with global remapping or independent of global remapping when changes to the environment are small [<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c26">26</xref>–<xref ref-type="bibr" rid="c28">28</xref>]. In the hippocampus, both global and rate remapping have been observed in response to changes in environmental sensory cues, such as the color or shape of the spatial environment, and the presence of reward [<xref ref-type="bibr" rid="c29">29</xref>–<xref ref-type="bibr" rid="c31">31</xref>]. Remapping events observed in the hippocampus have been shown to occur in concert with changes MEC spatial firing patterns, at both the correlational level (place cell remapping correlates with re-orientation of MEC grid-cells) [<xref ref-type="bibr" rid="c32">32</xref>], and at the causal level (inactivation of MEC coincides with hippocampal global remapping) [<xref ref-type="bibr" rid="c33">33</xref>]. Both global and rate remapping measurements provide, at the population level, a quantification of stability in the neural representation of an environment through spatial correlations [<xref ref-type="bibr" rid="c24">24</xref>]. However, remapping might be indicative of flexibility in the representation of space, other behaviorally relevant variables, or experience [<xref ref-type="bibr" rid="c28">28</xref>]. Thus, quantification of remapping can be experimentally leveraged to examine whether spatial representations flexibly adapt to behaviorally relevant factors such as distinct cue-reward associations that guide decisions made during goal-directed navigation.</p>
<p>Neurons in MEC also exhibit global and rate remapping between different spatial environments. Moreover, MEC neurons also remap in response to variables that flexibly change during goal-directed navigation, including: reward locations, running speed and an animal’s trajectory. The presence or change in the position of an unmarked remembered reward location can evoke both rate and global remapping in position and orientation encoding cells in MEC [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>]. Changes in an animal’s running speed have been observed to correlate with both rate remapping [<xref ref-type="bibr" rid="c34">34</xref>, <xref ref-type="bibr" rid="c35">35</xref>] and global remapping in MEC [<xref ref-type="bibr" rid="c36">36</xref>]. In structured linear track mazes, in which animals perform spatial alternation tasks, MEC exhibits trajectory dependent remapping for the same spatial location [<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c37">37</xref>]. However, while previously observed trajectory dependent remapping is indicative of prospective coding during stereotyped behavior (e.g. alternation), it remains unknown how MEC, PaS and PrS spatial patterns change in tasks with no trial-to-trial predictability or experimenter controlled cues and goals in the same environment. Moreover, while work in the hippocampus has shown that the degree of trajectory dependent remapping correlates with behavioral performance [<xref ref-type="bibr" rid="c38">38</xref>], and causal evidence revealed that shifted spatial representations correspondingly shifts the expected location of reward [<xref ref-type="bibr" rid="c21">21</xref>], such neural-behavior relationships have not been examined in the upstream MEC, PaS or PrS.</p>
<p>Here, we examined single unit neural activity in MEC, PrS, PaS as rats performed a visually cued navigational task that incorporated both goal-directed navigation and random foraging. We found that a large percentage of neurons changed their firing activity as a function of cue identity, and that the extent of separability (as measured through remapping) in this firing activity correlated with behavioral performance. Furthermore, using encoding models of rate and global remapping, we found that changes in neural activity in the task were sufficiently explained by rate remapping. Interestingly, neural representations were also separable contingent on the presence or absence of reward at the goal well. Finally, single-unit recordings during open field foraging revealed that neurons that encoded head-direction remapped more strongly than other functionally defined units. These results together point to the MEC and upstream PrS/PaS as nodes in the transmission of behaviorally relevant variables during goal-directed navigation.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Results</title>
<sec id="s2a">
<label>2.1</label>
<title>Tree-Maze behavior and electrophysiological recordings</title>
<p>To examine whether MEC, PrS and PaS neurons encode variables related to goal directed navigation, we designed a linear maze with two decision junctions, referred to here as the Tree-Maze (<xref ref-type="fig" rid="fig1">Fig. 1</xref>). Rats (n = 5) learned to navigate a sequence of wells to receive liquid milk rewards (<xref ref-type="fig" rid="fig1">Fig. 1a</xref>). There were four possible Goal-wells (G1-G4), and subjects received double rewards for triggering the correct Goal-well. Trials started at the Home-well (H). After animals triggered the Home-well (H), a visual cue turned on that indicated the correct branch to navigate after the Decision-well (D) (RC = Right-Cue, purple, Goal-wells G1-G2; LC = Left-Cue, green, Goal-wells G3-G4) (<xref ref-type="fig" rid="fig1">Fig. 1b</xref>). For the correct branch, only one Goal-well contained reward, which was randomly chosen on each trial. Thus, the task combined goal directed navigation (selecting the correct branch) with random foraging (selecting the first Goal-well to visit). After navigating correctly, or incorrectly (no reward and a 10 second timeout), the subject had to navigate back to the Home-well to initiate a new trial. The presence of two possible goal locations after the decisions kept subjects engaged, and dissociated the decision from the spatial location of the reward. For analyses, we segmented the maze into zones (<xref ref-type="fig" rid="fig1">Fig.1a</xref>), such that the location of the subject at any given time-point could be localized to a single zone (<xref ref-type="fig" rid="fig1">Fig. 1c</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><p>Goal directed navigation on the Tree-Maze task <bold>a.</bold> Top view of the Tree-Maze layout and segmentation (indicated by upper and lower case letters) used for analyses (height = 1.4 m, width = 1.2 m). The LED cue panel was located at the end of the maze (flattened for illustration). Colored cue cards on the side of the maze indicate the two cue types by trial (Purple = Right-Cue [RC], Green = Left-Cue [LC]). Possible reward locations denoted by capital letters (Home = H, Decision = D, Goal = G1-G4). Lower case letters correspond to the segments shown on the right side of panel c. Reward wells highlighted in blue. <bold>b.</bold> Colored lines indicate example trajectories of a rat, 5 trials per panel. L Dec indicates a trajectory towards the left branch and R Dec indicates a trajectory towards the right branch. Left column (Left/Green cue), trajectories to G3 (top) and G4 (bottom) for reward. Both of these were correct navigational decisions and were rewarded. Right column (Right/Purple cue), trajectories to G2 (top) and G3 (bottom), only the top trajectories resulted in reward at a goal. <bold>c.</bold> Binary trajectory segmentation time window. At any given time-point, the subject can only be at one location in the maze (indicated by the white bins). Bottom axis indicates trial start times (seconds). Top axis indicates the trial number (tr), colored coded by cue. Left/Right axis indicates the identity of the segment, lower case letters on the right correspond to those in panel a. Blue and red dashed vertical lines indicate the end of a trial (blue = correct; red = incorrect). <bold>d.</bold> Task performance by subject. Each dot corresponds to a session by subject. For <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline1.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, dots indicates the subject mean.</p></caption>
<graphic xlink:href="520660v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We trained 5 rats on the Tree-Maze task (see Methods-Behavioral Training). Subjects took an average of 25 sessions to reach the performance criterion for surgery (# sessions to criterion, range = 11-50; criterion: accuracy ≥ 70% and # trials ≥ 80; Sup. Fig. 1). Post-electrode implantation (Histology - Sup. Fig. 2, # units by subject Sup. Fig. 3), criteria for inclusion in the analyses were: # units ≥ 1, # trials ≥ 50 (across subject median accuracy = 72.6%, median number of trials per session = 110) (<xref ref-type="fig" rid="fig1">Fig. 1d</xref>). The cue on each trial was random, which allowed us to keep track of performance on Switch trials (in which the cue on trial N+1 was different than the cue on trial N, Sup. Fig. 1). Indicating that subjects were adept at the task and not simply following an alternation or exploitative strategy, the mean Switch trial performance was similar to non-Switch trials (Switch trial median accuracy = 76.9%; median number of Switch trials per session = 54). Together, the behavioral requirements of the task and structure of the Tree-Maze allowed us to then examine whether neural activity corresponded to different task dimensions (e.g. cue, decision, reward, spatial position).</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Visual cues evoked spatial remapping</title>
<p>To investigate the effect of the cue on the spatial firing profiles of single units (i.e. neurons), we generated spatial maps by cue condition for outbound trajectories (H-well to G-well, <xref ref-type="fig" rid="fig2">Fig. 2a</xref>. For each unit, the spatial locations of spikes along trajectories were used to obtain trial summary metrics for each maze segment as a function of cue (<xref ref-type="fig" rid="fig2">Fig. 2b</xref>; Sup. Fig. 4-5). Across trials, the difference on cue coding by maze segment was quantified by the Mann-Whitney Z transformed U statistic (<italic>U<sub>Z</sub></italic>), (<xref ref-type="fig" rid="fig2">Fig. 2b,c</xref>). In the scenario in which the cue had no effect on spatial coding, the distributions of <italic>U<sub>Z</sub></italic> scores will be close to zero for all maze segments (<xref ref-type="fig" rid="fig2">Fig. 2c</xref>). On the other hand, the statistic will be negative if firing rates for the Left-Cue (LC) trials were greater than for Right-Cue (RC) trials, and positive if the firing rates for the Right-Cue (RC) trials were greater than for the Left-Cue (LC) trials. Using a linear mixed effects model we found a main effect of Segment with follow-up pairwise comparisons showing a left&gt;stem&gt;right pattern (LMEM; accounted for within subject variance and repeated measures for each session, Segment Likelihood Ratio Test <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline2.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 3.07e<sup>-19</sup>). Hence, across the population there was a significant bias for Right-Cue trials to be associated with greater firing rates than Left-Cue trials on the left segment of the maze, and for Left-Cue trials to be associated with greater firing rates than Right-Cue on the right segment of the maze. In both of these instances, the increased firing rate thus follows an incorrect decision, that is, trajectories that did not lead to a reward were the trajectories associated with an increased firing rate.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><p>Spatial remapping was associated with the visual cue and correlated with task performance. <bold>a.</bold> Example session trajectories for all LC (Left-Cue) and RC (Right-Cue) trials. <bold>b.</bold> Four example single-units. For each example unit: Top row, left and middle, outbound trajectories separated by cue (red dots = spikes). Top-right, trial median activity by cue and maze segment (left, stem, right), numbers at the top indicate the Mann-Whitney Z transformed U statistic for the difference between the RC and LC trial distributions <italic>U<sub>z</sub></italic>. Bottom row, mean spatial rate maps by zone and cue, color coded for minimum (firing rate [FR] = 0, blue) and maximum (yellow) values. Bottom right, re-sampled distribution of correlations between RC and LC maps in blue for that unit, and in grey the corresponding null distribution. Remapping score <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline3.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> is the mean remapping score for each unit. <bold>c.</bold> Distributions of <italic>U<sub>Z</sub></italic> scores for all recorded units by maze segment. Purple means higher FR for RC than LC, Green means higher FR for LC than RC. Note the higher FR for RC on the left segment (far left) and higher FR for the LC on the right segment (far right). <bold>d.</bold> Distribution of mean remapping scores <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline4.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> by unit, note the negative shift in the distribution of scores. <bold>e.</bold> Scatter-plot between the task performance on a given session <italic>p<sub>se</sub></italic> and the cue remapping scores <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline5.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> for recorded units in that session. Size and color of dots scale with the x axis for illustration. Regression line in red with a <italic>CI</italic><sub>95%</sub> band. Kendall correlation score between behavior and remapping score shown. <bold>f.</bold> Scatter-plot between p<sub>se</sub> and the mean remapping score across units recorded in a given session <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline6.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. Size of dots indicate number of co-recorded units, color codes correspond to different subjects. Regression line and corresponding CI<sub>95</sub>% band shown in grey. <bold>g.</bold> Like (<bold>f</bold>) but with neural population correlation, composed of the spatial rate maps for all recorded units in a session. <bold>g.</bold> Correlation between <italic>p<sub>se</sub></italic> and <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline7.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> by subject, with bootstrapped standard deviation. <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline8.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> is the across subject mean.</p></caption>
<graphic xlink:href="520660v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Next, to quantify the degree of spatial firing rate changes, we generated spatial zone rate maps as a function of cue. Importantly, these maps were generated from balanced re-sampling of correct and incorrect trials. Concretely, the LC maps were generated by sampling an equal number of correct and incorrect trials from all the trials that had a LC (<xref ref-type="fig" rid="fig2">Fig. 2b</xref>). A distribution of scores was computed by taking the Kendall correlation, <italic>τ</italic>, between LC and RC spatial maps for each trial re-sampling instance (<xref ref-type="fig" rid="fig2">Fig. 2b</xref>). An appropriate null distribution was generated by sampling equal numbers of LC and RC trials from even and odd trial sets, computing the spatial correlation, and then comparing the resulting null correlation score to the cue correlation scores to generate a remapping score <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline9.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. Across units we observed a significant negative shift in <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline10.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> (LMEM: mean=−0.67, <italic>p</italic> = 0.003, <italic>CI<sub>95</sub>%</italic>=(−1.105,−0.225)) (<xref ref-type="fig" rid="fig2">Fig. 2d</xref>). This negative shift indicated that the cue induced a significant level of remapping in firing patterns when compared to a null distribution.</p>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Remapping of spatial representations relates to greater task performance</title>
<p>Given that trajectories after incorrect decisions tended to elicit an elevated FR (<xref ref-type="fig" rid="fig2">Fig. 2c</xref>), we hypothesized that the cue remapping score would related to a subject’s performance in the task. To examine this, we related the cue remapping score of each unit <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline11.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> to the corresponding task performance for the recorded session <italic>p<sub>se</sub></italic> (<xref ref-type="fig" rid="fig2">Fig. 2e</xref>). There was a significant negative relationship between performance accuracy on a given session <italic>p<sub>se</sub></italic> and the degree of cue remapping calculated for single units <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline12.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> (Kendall’s <italic>τ</italic>=-0.27; LMEM: <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline13.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>CI</italic><sub>95%</sub>=(−0.15,−0.09), <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline14.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 8.84e — 13). Given that this effect was observed for the majority of units, we hypothesized that the effect should be reflected in the mean of the cue remapping scores for co-recorded units in a session <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline15.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> (<xref ref-type="fig" rid="fig2">Fig. 2f</xref>). Indeed, when considering co-recorded units in a session, the correlation between cue remapping and behavioral performance was even more pronounced (Kendall’s <italic>τ</italic>=-0.41; LMEM: <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline16.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline17.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 1.4e — 4, <italic>CI</italic><sub>95%</sub>=(−0.33,−0.11)). Population level correlations showed the same effect, (<xref ref-type="fig" rid="fig2">Fig. 2g</xref>). At the individual subject level, this correlation between performance accuracy and cue remapping was observed in all but one subject, which had a small number of units (<xref ref-type="fig" rid="fig2">Fig. 2h</xref>). These same effects were observed on multiple versions of these analyses (Sup. Fig. 8,9). Together, these results demonstrate cue-based remapping of parahippocampal spatial firing patterns in a goal directed navigation task, with the extent of remapping significantly correlating with behavioral accuracy in the task.</p>
<p>Next, we sought to understand the extent and the manner in which the visual cue was encoded in the FR of individual units during the task. We compared three different linear encoding models: (1) a zone/position model <italic>Z</italic>, (2) a cue rate-remapping model <italic>Z</italic> + <italic>C</italic>, and (3) a cue global-remapping model <italic>Z</italic> × <italic>C</italic>. The zone only model <italic>Z</italic>, simply predicted a neuron’s FR based on the zone/position the subject was occupying at a given time. The cue rate-remapping model <italic>Z</italic> + <italic>C</italic>, also received a cue identity input, acting as gain on the model to uniformly modify the predicted FR across all zones as a function of cue (<xref ref-type="fig" rid="fig3">Fig. 3a,b</xref>). The cue global-remapping model <italic>Z</italic> × <italic>C</italic> doubled the number of input zones, such that only one set of zones could be active on a given cue trial. This approach thus modeled the possibility of a complete re-shuffle of the spatial firing patterns as a function of cue (Sup. Fig. 12). For each unit, the cross-validated coefficient of determination <italic>R</italic><sup>2</sup> was used to asses model performance (individual scores are shown in <xref ref-type="fig" rid="fig3">Fig. 3c</xref>). Note that a negative <italic>R</italic><sup>2</sup> indicates that the mean firing rate of the neuron explained more activity variance than the fitted model (on held-out test data). A subtle but consistent difference in model scores was apparent between the rate- and global remapping model (<xref ref-type="fig" rid="fig3">Fig. 3c,d</xref>), such that the rate remapping model outperformed the global remapping and position only model (LMEM: <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline18.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 1.24e<sup>-209</sup>) (<xref ref-type="fig" rid="fig3">Fig. 3d</xref>). The overall single unit scores showed a mean <italic>R</italic><sup>2</sup> of 12% for the <italic>Z</italic> + <italic>C</italic> model.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><p>Cue modeling revealed rate remapping and trial-wise correlations to behavior. <bold>a.</bold> Linear zone encoding model with cue <italic>Z</italic> + <italic>C</italic>, at a given sample time <italic>t</italic>, the current position of the animal and the cue identity is multiplied by learned weights to predict FR for each recorded unit <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline23.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. <bold>b.</bold> Example time window of <italic>Z</italic>[<italic>t</italic>], the true FR in black <italic>V</italic>[<italic>t</italic>] and the predicted FR in red <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline24.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. <bold>c.</bold> Model comparison between three types of zone encoding: <italic>Z</italic> → only zones, <italic>Z</italic> + <italic>C</italic> → zones + cue, <italic>Z</italic> × <italic>C</italic> → a set of zones for each cue. Each dot is a unit, blue dots were negative <italic>R</italic><sup>2</sup>, red scales with <italic>R</italic><sup>2</sup> and y-axis. <bold>d.</bold> Model comparison scores. Y-axis is the Mann-Whitney Z transformed statistic for comparing the <italic>R</italic><sup>2</sup> on test folds. Colorbar indicates the median difference in <italic>R</italic><sup>2</sup> across test folds. <bold>e.</bold> Performance of linear zone decoder models <italic>V</italic> (circles) and <italic>V</italic> + <italic>C</italic> (squares). Y-axis is the error distance in cm between the predicted and true zone, X-axis is the linearized Tree-Maze zones displayed as H (Home-well) to D (Decision-well) to i (second intersection/branching) to G (Goal-well). Linearization achieved through averaging the equivalent trajectories towards the goal. The hue shade provides groupings of sessions according to number of co-recorded units (both isolated an MUA included in these analyses). <bold>f.</bold> Performance of linear decision decoder by zone, with color indicating number of units. Note the sharp decision well split in the performance. BAC=balanced accuracy. <bold>e.</bold> Correlation between the subject’s performance and the model by zone. Color groupings as in (<bold>f.</bold>). Model performance is the comparison between the output of the decision decoder and the true identity of the cue, the same computation used to assess a subject’s performance.</p></caption>
<graphic xlink:href="520660v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To further understand how the encoding of the cue across units could modulate the strong position coding present in parahippocampal neurons, we trained a linear decoder to predict the position of the subject using the neural population activity patterns with and without the identity of the cue (<italic>V</italic> + <italic>C</italic> and <italic>V</italic> models, respectively, <xref ref-type="fig" rid="fig3">Fig. 3e</xref>). On held-out test data, we observed significant modulation with the cue as an input, reflected by decreased errors (the distance between the predicted and true position), but only in sessions with high number of units (LMEM: interaction between model and units groupings: <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline19.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 1.9e<sup>-4</sup>). Additionally, the addition of cue information was most beneficial in reducing errors post-decision (LMEM: triple interaction of model, unit grouping and pre-/post-decision marker: <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline20.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 2.9e<sup>-47</sup>). Next, we trained a classifier to predict the Left/Right decision of the subject using the population activity (<xref ref-type="fig" rid="fig3">Fig. 3f</xref>). Prospective decoding of the decision prior to the decision point (stem) was at chance, while it steadily increased beyond the decision point across sessions, more so in sessions with more than 8 units (LMEM: interaction of unit groupings and pre-/post decision marker, <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline21.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 3.28e<sup>-78</sup>). The decoding of decision is reflective of the strong position coding in parahippocampal units, and also indicative of the behaviorally relevant information content of these neurons. An important note is that the number of units in a session heavily influenced the ability of the decoder to predict an upcoming Left/Right decision in the stem. Concretely, 19/42 sessions had above chance decoding with 8 or fewer corecorded units, while 23/36 sessions with 20 or more co-recorded units had above chance decision decoding. Finally, because the decoder has trial-wise predictions of an animal’s decision Left/Right, we tested the extent to which parahippocampal representations matched the subject’s behavior (<xref ref-type="fig" rid="fig3">Fig. 3f</xref>). We compared decoder outputs (Left/Right decisions) to the identity of the cue, thus providing a measure comparable to the performance of subjects on the task. With this approach, we relate the performance of the subject to the model’s performance with a LMEM, with unit groupings and pre-/post-decision marker as covariates, and found a triple interaction between these predictors (<inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline22.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 3.61<sup>-10</sup>). The interaction can be broken down as follows: post-decision decoder predictions related to the subject’s performance and was modulated by the number of co-recorded neurons. These analyses demonstrate that the parahippocampal representations are not only reflective of behavior on the mean sense, as assessed through spatial remapping, but also at the individual trial-level.</p>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Absence of reward leads to higher activity and spatial remapping</title>
<p>After the subjects navigated to Goal-wells, they received reward contingent on whether they made the correct navigation decision. Inbound trajectories from the Goal-wells to the Home-well could thus be separated by rewarded (correct trials) versus unrewarded (incorrect trials) (Fig. 44a). Based on previous data [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>], we posited that reward could also elicit firing rate changes in the spatial representations of parahippocampal neurons. We quantified firing rate changes for each unit as a function of reward by maze segment (Fig. 44b,c). Across units, we found that unrewarded trials tended to have elevated firing rates across all maze segments (proportions: left=386/565, stem=340/565, right=412/565; LMEM: segment <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline25.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>,<italic>p</italic> = 7.9le<sup>-12</sup>).</p>
<p>Given the firing rate differences observed between rewarded and unrewarded trials, we expected to see differences in position coding for the spatial maps corresponding to these trials sets. For each unit we generated a distribution of correlations between rewarded and unrewarded inbound spatial trajectories (bootstrapped trials with equal numbers of LC and RC). The null distribution was then the correlations between even and odd inbound trial trajectories (bootstraps having an equal number of rewarded and unrewarded trials). As with the cue, we quantified the difference between these distributions for each unit to obtain a remapping score <italic>Z</italic><sub>Δ<italic>τ</italic></sub>, <xref ref-type="fig" rid="fig4">Fig. 4b,d</xref>. Across units, we observed a significant negative shift of the remapping score, which indicates that spatial maps changed based on the receipt or absence of reward <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline26.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> (LMEM: mean=−1.03, <italic>CI</italic><sub>95%</sub>=(−1.6,−0.46), <italic>p</italic> = 4.1<italic>e</italic><sup>-4</sup>) (<xref ref-type="fig" rid="fig4">Fig. 4d</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><p>Absence of reward leads to higher activity and spatial remapping. <bold>a.</bold> Example session RW (reward) and NRW (no-reward) trials. <bold>b.</bold> Four example units (i-iv). Top rows, inbound trials trajectories by RW/NRW (red dots = spikes). Top-right, trial median activity by RW and segment in the maze. Firing rate difference score <italic>U<sub>z</sub></italic> as described in the main text. Bottom rows, mean spatial rate maps by zone and RW, minimum FR=0. Bottom right, re-sampled distribution of correlations between RW and NRW maps in blue for that unit, and in grey the corresponding null distribution. Remapping score <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline32.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> is the mean remapping score for each unit. <bold>b.i</bold> Session is the same as in panel <bold>a.</bold>, other units from different sessions. <bold>c.</bold> Distributions of <italic>U<sub>z</sub></italic> scores for all recorded units by maze segment. Blues means higher FR for RW than NRW trials, Red higher NRN than RW. <bold>d.</bold> Distribution of mean remapping scores <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline33.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> by unit, note the negative shift in the distribution of scores. <bold>e.</bold> Scatter-plot between a session’s task performance <italic>p<sub>se</sub></italic> and the remapping scores <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline34.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> for recorded units. Size and color of dots scale with the x axis for illustration. Regression line in red with a <italic>CI</italic><sub>95%</sub> band. Kendall correlation score between behavior and remapping score shown. <bold>f.</bold> Scatter-plot between <italic>p<sub>se</sub></italic> and the mean remapping score across a sessions units <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline35.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. Size of dots indicate number of co-recorded units, color codes correspond to different subjects. Regression line and corresponding <italic>CI</italic><sub>95%</sub> band shown in grey. <bold>g.</bold> Like (<bold>f</bold>) but with neural population correlation, composed of the spatial rate maps for all recorded units in a session. <bold>h.</bold> Correlation between <italic>p<sub>se</sub></italic> and <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline36.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> by subject, with bootstrapped standard deviation. <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline37.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> is the across subject mean.</p></caption>
<graphic xlink:href="520660v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Furthermore, because rewarded trials are correct trials, we hypothesized that as with the cue, remapping scores <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline27.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> should relate to task performance. The extent of reward related remapping correlated with performance accuracy for a session at the level of individual units, across co-recorded units, and individual subjects (<xref ref-type="fig" rid="fig4">Fig. 4e–h</xref>, Sup. Fig. 10,11). Statistical analyses of these results were indicative of a strong relationship between reward remapping and task performance: unit-level (Kendall’s <italic>τ</italic>=-0.28; LMEM: <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline28.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>CI</italic><sub>95</sub>% = (−0.18,−0.11), <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline29.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 3.06e-20); across co-recorded units (<italic>τ</italic>=−0.43; LMEM: slope=−0.28, <italic>CI</italic><sub>95</sub>% = (−0.38,−0.19), <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline30.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 3.28e<sup>-8</sup>). Similar to cue induced remapping, the extent to which units remapped in response to reward receipt significantly correlated with behavioral accuracy in the task.</p>
<p>As with the cue, we modeled the firing rate activity of individual neurons through three linear encoding models: (1) a zone/position model <italic>Z<sub>i</sub></italic>, (2) a reward rate-remapping model <italic>Z<sub>i</sub></italic> + <italic>R</italic>, and (3) a reward global-remapping model <italic>Z<sub>i</sub></italic> × <italic>R</italic>. Whsere the <italic>i</italic> subscript indicates inbound trajectories, <xref ref-type="fig" rid="fig5">Fig. 5a,b</xref>. Similar to the cue models, we found that the activity of most units were better fitted by a rate-remapping model (<xref ref-type="fig" rid="fig5">Fig. 5c,d,e</xref>) (LMEM: <italic>U</italic><sub>Δ</sub><sub><italic>R</italic></sub><sup>2</sup> Model <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline31.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 1.98e<sup>-146</sup>) (<xref ref-type="fig" rid="fig5">Fig. 5d</xref>). Thus these set of results indicate that parahippocampal neurons (as a population) exhibit increased firing rates during inbound trajectories that follow unrewarded trials.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><p>Encoding model of reward remapping. <bold>a.</bold> Linear zone encoding model with reward <italic>Z<sub>i</sub></italic> + <italic>R</italic>, at a given sample time <italic>t</italic>, the current position of the animal and the reward identity is multiplied by learned weights to predict FR for each recorded unit <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline40.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. <bold>b.</bold> Example time window of <italic>Z</italic>[<italic>t</italic>], the true FR in black <italic>V</italic>[<italic>t</italic>] and the predicted FR in red <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline41.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. <bold>c.</bold> Model comparison between three types of zone Encoding during inbound trajectories: <italic>Z<sub>i</sub></italic>, <italic>Z<sub>i</sub></italic> + <italic>R</italic>, <italic>Z<sub>i</sub></italic> × <italic>R</italic>. Each dot is a unit, blue dots were negative <italic>R</italic><sup>2</sup>, red scales with <italic>R</italic><sup>2</sup> and y-axis. <bold>d.</bold> Model comparison scores. Y-axis is the Mann-Whitney Z transformed statistic for comparing the <italic>R</italic><sup>2</sup> on test folds. Color-bar indicates the median difference in <italic>R</italic><sup>2</sup> across test folds.</p></caption>
<graphic xlink:href="520660v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Given the observations of spatial remapping for both cue and RW condition contingencies, we sought to understand the relationship between these observations. First, we found that remapping scores were correlated (Sup. Fig. 13) across individual units and at the population level. Second, because correct/incorrect trial contingencies largely contributed to how cue and RW spatial maps were constructed, we partitioned the data into correct/incorrect coding and sought to find a the relationship across cue and RW, (Sup. Fig. 14). With this approach, found that incorrect coding units were more likely to overlap between cue and RW coding units than correct. However, remapping scores didn’t differed between these groupings. Third, we conditioned the activity of correct and incorrect inbound trajectories based on the activity of correct and incorrect outbound trajectories (Sup. Fig. 15). This analyses was motivated based on the structure of the trials: rewarded (correct) inbound trajectories followed correct outbound trajectories and that unrewarded (incorrect) inbound trajectories followed incorrect outbound trajectories. We found that incorrect&gt;correct activity levels on outbound trajectories predicted incorrect&gt;correct activity levels on inbound trajectories, suggesting that error signaling activity persisted through the inbound phase of the trial. Together, the remapping observations provide a quantification of this error or mismatch-like signal through different phases of the task and in the context of spatial representations.</p>
</sec>
<sec id="s2e">
<label>2.5</label>
<title>Units encoding head direction during open field foraging are more likely to remap</title>
<p>In addition to the Tree-Maze, single units were recorded from subjects while they foraged for randomly scattered food rewards in a rectangular open arena (open-field foraging, OF, <xref ref-type="fig" rid="fig6">Fig.6a</xref>). Removable panels forming the floor of the arena were placed on top of the Tree-Maze, thus keeping peripheral visual cues relatively constant between the two environments, with the main difference coming from the 12 cm in gained height for the OF environment. A model-based encoder approach was used to quantify the extent of navigational coding for each unit along the behavioral measures of speed, head-direction or position (<xref ref-type="fig" rid="fig6">Fig.6</xref>). The firing-rate predictions of these individual models was used to predict the firing rate of single units on test data in an aggregate model (<xref ref-type="fig" rid="fig6">Fig.6a,b</xref>). Across units, the aggregate model produced better results than individual models (LMEM: main effect of model <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline38.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 1.33e<sup>-122</sup>, <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline39.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 3.44<sup>-190</sup>) (<xref ref-type="fig" rid="fig6">Fig. 6c,d</xref>). Units across the Tree-Maze and OF tasks were matched through a waveform matching algorithm <xref ref-type="fig" rid="fig7">Fig. 7a</xref>. In total 217 units were matched across 76 OF and 82 Tree-Maze sessions <xref ref-type="fig" rid="fig7">Fig. 7b</xref>. The set of model coefficients (speed, head-direction, position) for each matched unit were clustered into three groups (<xref ref-type="fig" rid="fig7">Fig. 7c–e</xref>). Notably, the obtained unit cluster identified a main dimension of separation between clusters in the form of a coding trade-off between head-direction and speed (<xref ref-type="fig" rid="fig7">Fig. 7d,e</xref>). That is, units that coded strongly for head-direction (cluster 0, blue, n=98) coded poorly for speed, while units that coded strongly for speed coded poorly for head-direction (cluster 2, green, n=59). For completeness, OF tuning score metrics were also computed for these clusters with results qualitatively matching the model coefficients (<xref ref-type="fig" rid="fig7">Fig. 7f</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><p>Modeling navigational/spatial variables in neural coding during open-field foraging. <bold>a.</bold> Neural responses of four example units for subjects foraging an open-field (OF) arena [1.3m x 1.5m]. For each unit sub-panel (c0-c3): top-left, firing-rate map (number is the peak FR); top-right, head-direction tuning curve, color indicates FR magnitude by angle; bottom-left, speed tuning curve (s=speed); bottom-right, model-based variance explained on test data (<italic>R</italic><sup>2</sup>) by variable (h=heading-direction, p=position, a=aggregate model). <bold>b.</bold> Model-based responses by variable for a selected test time-window for units c0-c3. Each row corresponds to a different model prediction <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline45.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, the true firing-rate (fr) for that unit, or at the top the color-coded time-window (t). Top-right, the data on which the model was trained is in grey and super-imposed is the test-window color-coded by time and with firing rate magnitude in increasing dot-size. Other heat-maps are the resulting firing-rate maps generated for the test trajectory. Model predicted rates are shown with colors matching <bold>a.</bold>, with the background dotted line being the true (fr) <bold>a.</bold>. <bold>c.</bold> Population level (<italic>R</italic><sup>2</sup>) for train (tr) and test (te) sets. <bold>d.</bold> Population level firing-rate map Pearson correlation <italic>r<sub>p</sub></italic> between true <italic>m</italic> and predicted maps <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline46.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. Note that for both metrics, the aggregate model and the position model produced the best results. <bold>e.</bold> Relationship between coefficients on the aggregate model by unit. The color corresponds to the model’s training set <italic>R</italic><sup>2</sup>.</p></caption>
<graphic xlink:href="520660v1_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7:</label>
<caption><p>Matched units across tasks reveal that head-direction coding units remap the strongest. <bold>a.</bold> Procedure for matching units across tasks (OF-open field, TM-tree maze). Top, 6 tetrode waveforms color-coded by matched units; bottom-left, fitted Gaussians to the dimensionally reduced unit waveforms for that tetrode across matched depth sessions (grey, unmatched units); bottom-right, symmetric confusion error matrix across units, threshold for matching <italic>PE</italic> &lt;= 0.5. <bold>b.</bold> Venn diagram of matched units across tasks. <bold>c.</bold> UMAP clustering of the aggregate model coefficients for matched units. <bold>d.</bold> Head-direction (h) vs speed (s) coefficients formed a clustering subspace. <bold>e.</bold> Model coefficients of aggregate model used for finding clusters (p=position). Horizontal lines are the population mean, and error bars are the mean’s 95% CI. Statistics not performed, as the clusters were fitted from these parameters. <bold>f.</bold> Tuning metric scores (p=split-half rate-map correlation; s=speed-score; h=resultant-vector length score). Paired statistics through Mann-Whitney U tests (*=<italic>p</italic> &lt; 0.05, **=<italic>p</italic> &lt; 0.01, ***=<italic>p</italic> &lt; 0.001, ****=<italic>p</italic> &lt; 1e<sup>-4</sup>) <bold>h.</bold> Remap scores by OF cluster. <bold>g.</bold> TM model scores by OF cluster.</p></caption>
<graphic xlink:href="520660v1_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Next, we sought to relate how these clusters of units defined in the OF foraging task related to the results observed in the Tree-Maze. We observed that on this matched subset of neurons, significant remapping scores were still observed for both cue and RW contingencies, and that units in cluster 0 remapped more than the other clusters (LMEM: cluster x remap interaction <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline42.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 0.032; cluster <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline43.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 0.47), (<xref ref-type="fig" rid="fig7">Fig. 7g</xref>). Similarly, Tree-Maze encoder rate/global remapping scores were higher for cluster 0 (LMEM: cluster <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline44.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, <italic>p</italic> = 9.62e<sup>-4</sup>) (<xref ref-type="fig" rid="fig7">Fig. 7h</xref>). Additionally, we explored the extent to which these clusters related to other aspects of coding in the Tree-Maze like correct/incorrect coding and cue/RW coding by segment (Sup. Fig. 16-17). We found that these functionally defined units had some overlap with different aspect of the maze, suggesting a small degree of heterogeneity in coding. However, most units in the clusters did not overlap with cue/RW or correct/incorrect coding. Taken together, units in cluster 0, that corresponded to stronger head-direction coding, were more prone to remap for both cue and RW than units in cluster 1 or 2. Hence, we leveraged Open-Field recordings to identify head-direction coding units as showing changes of firing patterns in the Tree-Maze, with those changes being reflective of task performance.</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Discussion</title>
<p>During Open-Field foraging, individual MEC, PrS and PaS neurons encode an animal’s position, orientation and speed but the firing patterns of neurons in these parahippocampal regions during goal-directed navigation has been less well characterized. Here, we examined the firing patterns of hundreds of parahippocampal neurons as rats navigated a visually-guided goal directed Tree-Maze task. Rats successfully learned to use a visual cue to navigate the left or right branch of a multi-decision point linear maze to receive reward. We found that many neurons exhibited higher firing rates after incorrect left or right branch choices, which led to remapping of spatial firing rate maps. Further, the degree of remapping correlated with behavior, such that higher remapping scores corresponded to better task performance. Using encoder models, we then demonstrated that rate remapping, over global remapping, was sufficient to explain the observed changes in spatial firing rate maps. Finally, by using the navigational coefficients of encoder models fit to Open-Field foraging data, we further revealed that head direction coding cells showed the largest magnitude of remapping on the Tree-Maze. Conjunctively, these results demonstrate that parahippocampal representations of space and navigation, under goal-directed experimental conditions, project a flexible code reflective of behavior.</p>
<p>Neuronal encoder models serve as an important tool for identifying single-unit activity coding during open-field foraging that avoid imposing a prior on the shape of tuning curves or the generation of coding indices (e.g. tuning curve scores) [<xref ref-type="bibr" rid="c13">13</xref>]. Moreover, these models allow for the quantification of mixed selectivity in the coding for spatial/navigational variables, providing a more nuanced understanding of the possible variables a neural population encodes. Here, we fit linear encoder models that used speed, heading-direction and position during open-field foraging to predict each unit’s firing rate activity. Consistent with prior work, we find strong position coding, that is often complementary with coding for head-direction or speed ([<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c39">39</xref>]). Although there are differences in the proportion of cells that encode position, head direction and speed between MEC, PrS and PaS (e.g. PrS and PaS have higher proportions of head-direction tuned cells), these regions share a common substrate of spatial/navigational coding (position, head-direction, speed) [<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c16">16</xref>]. We further found a relationship between navigation variables after clustering that revealed an axis of separation along the head-direction and speed coefficients, such that these variables were negatively related. This anti-correlation between speed and head-direction coding replicated recent observations across parahippocampal regions (MEC, PaS and PrS) [<xref ref-type="bibr" rid="c15">15</xref>]. Thus, as a function of speed, the head-direction signal monotonically decreases at faster speeds, consistent with the observation that subjects are less likely to turn when they run fast. Thus, one possibility is that the head-direction signal in the parahippocampal region reflects a behavioral state related to navigational choice or the lack of commitment to a particular navigational route.</p>
<p>Prior works point to the MEC as a key node supporting spatial decisions, as it’s inactivation led to performance deficits in visual-scene based spatial decisions [<xref ref-type="bibr" rid="c40">40</xref>], and subsets of MEC neurons encode the near future position of the animal (&lt;1 second in the future) [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c41">41</xref>]. Nonetheless, in terms of navigation behavior, parahippocampal neural activity after incorrect decisions has been understudied. Depending on the task, there are often very few error trials or multiple confounds that prevent substantial quantification of errors (e.g. loss of attention or satiation). Error or mismatch signals conform a fundamental computation, that informs immediate behavior, learning and neural plasticity [<xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c43">43</xref>]. Our task structure enabled us to more rigorously consider error trials and the activity of MEC, PaS and PrS neurons before and after such trials. Given that many units exhibited higher firing rates on incorrect trials, leading to rate remapping, we hypothesized that the extent of remapping should correlate with behavioral performance. Indeed, we observed strong correlations between neural remapping and behavioral performance across multiple levels of analyses: individual units, across units, population correlations, individual subject level analyses and a neural population decoder model that mimicked the subject’s behavior (<xref ref-type="fig" rid="fig2">Figs. 2</xref>–<xref ref-type="fig" rid="fig4">4</xref>), as well as in control analyses that included multi-unit activity or the removal of periods of reward and/or immobility (Sup. Figs. 8-11). The robustness of this observation suggests that cortical regions encode error, expanding the possible brain regions involved in error signalling beyond downstream regions, like the basal ganglia, that prior work has shown carry error signals [<xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c43">43</xref>].</p>
<p>Additional support for the idea of a mismatch signal in the parahippocampus comes from prior works that observed changes in the hippocampus related to correct or incorrect decisions. For example, hippocampal place-cells showed more efficient representations of sequences during correct trials than during incorrect [<xref ref-type="bibr" rid="c44">44</xref>], and non-place cells show higher rates during correct versus incorrect trials [<xref ref-type="bibr" rid="c45">45</xref>]. Moreover, in the T-maze, the extent of discriminability for upcoming left or right trajectories in the firing rate of hippocampal cells active on the stem of the T-maze (i.e. splitter cells) correlated with behavioral performance [<xref ref-type="bibr" rid="c38">38</xref>]. Of note however, we did not observe a significant population of ‘splitter cells’ in the central stem of the maze, possibly because the Tree-Maze differs from previous T-or Y-Maze in that there is a reward well at the decision point [<xref ref-type="bibr" rid="c37">37</xref>] [<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>]. Even so, in our task, after training, subjects were more likely to be running on the left branch of the maze when the green visual cue (LC) was present, but after an incorrect decision, they were running on the left branch of the maze when the purple cue (RC) was present. These incorrect spatial decisions led to increase firing rates on the majority of units, and persisted on the inbound trajectories (quantified by rewarded vs unrewarded, Sup. Fig. 15). Notably, units coding for correct decisions on outbound trajectories rarely overlapped with units coding for correct decisions on inbound trajectories, while neurons coding for incorrect decisions often overlapped in their coding for inbound and outbound trajectories (Sup. Fig. 14). These observations are generally consistent with the idea that a mismatch signal could be transmitted by MEC, PaS and PrS neurons via a change in firing rate. However, it remains an open question as to where this type of mismatch signal originates such that it is broadly reflected across parahippocampal regions.</p>
<p>A growing set of studies have started to show that spatial and navigational codes in the parahippocampal region are more flexible than previously thought. Observations of spatial remapping in the MEC have been seen after significant changes to the environment in an open-field arena [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c46">46</xref>], provoking a coordinated re-organization of grid-cells and seemingly random re-organization of other spatially selective cells. Remapping was also observed to be more likely at low running speeds [<xref ref-type="bibr" rid="c36">36</xref>], switching between stable spatial representations. These observations would generally be considered global remapping, as the activity fields in space change position. Other studies, however, have shown changes in firing rate and small shifts in fields near rewarded locations during foraging [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>]. Our data, including deep MEC, points to changes in firing rate activity on the same spatial location (rate remapping) being sufficient to explain the differences in firing rate observed between conditions (both for cue and reward). The rate remapping result is again consistent with the idea of a mismatch or error signal acting as a gain on individual neurons. Our results demonstrate that through the use of a dynamic environment we increased the behavioral demands on the animal, providing a behavioral assay to contrast parahippocampal neural activity. Further, by recording from the well characterized parahippocampal navigational circuit, we were able show that there are additional dimensions of representation or computations only elucidated through the use complex behaviors.</p>
</sec>
<sec id="d1e1414" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1487">
<label>Supplemental Figures</label>
<media xlink:href="supplements/520660_file03.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<sec>
<label>4</label>
<ack>
<title>Acknowledgements</title>
<p>This work was supported by an NIMH F32 Fellowship (1F32MH119766) to AG, the Office of Naval Research (N00141812690), the Simons Foundation (SCGB 542987SPI), NIMH (MH126904), the Vallee Foundation, and the James S. McDonnell Foundation to LMG. We would like thank Loren M. Frank for initial discussions on the adaptation and building of the maze, David Jessen and Ashley Henderson for subject handling and training, and Adriana Diaz for animal husbandry and lab support.</p>
</ack>
<sec>
<label>5</label>
<title>Declaration of Interests</title>
<p>The authors declare no competing interests.</p>
</sec>
<sec>
<label>6</label>
<title>Data and Code Availability</title>
<p>Code is available for download as a repository on github <ext-link ext-link-type="uri" xlink:href="https://github.com/alexgonzl/TMA">https://github.com/alexgonzl/TMA</ext-link>. All data required to reproduce the paper figures will be available through links in the github repository.</p>
</sec>
<sec id="s7">
<label>7</label>
<title>Methods</title>
<sec id="s7a">
<label>7.1</label>
<title>Subjects</title>
<p>The subjects in this study were male Long Evans rats (Charles River Laboratories, n = 5) that were housed with liter-mates and kept on a 12-h light-dark cycle. Rats were moved to solitary housing and handling began when rats were 12-16 weeks old (400-500g). After a one week handling period, animals were introduced to the Tree-Maze environment, and behavioral training began. After animals were acclimated to the maze and we obtained their base-weight, a dietary food restriction was introduced. The animal’s weight was monitored daily, and kept at 90% of their base-weight throughout behavioral training by controlling their daily food intake. The dietary restriction motivated the animals, while still keeping them at a healthy weight. Food restriction was paused at least 3 days prior to surgery, and for a week post-surgery while animals recovered. During this recovery period, the animal’s health was monitored daily for signs of infection, or other behavioral indicators of a lack of recovery.</p>
<sec id="s7a1">
<label>7.1.1</label>
<title>Surgery</title>
<p>Surgeries were conducted in a designated laboratory space using aseptic technique. All rats used in the project were implanted with a micro-drive and ground wire for electrophysiological recordings (Halo-18 Neuralynx, Inc.). During surgery, the rat’s head was held in a stereotaxic carrier and heat was provided by a self-regulating heating pad. The entire procedure took approximately 5 hours. Anesthesia was isoflurane with buprenorphrine as a pre-anesthetic sedation (0.05 mg/kg subcutaneous). Ophthalmic ointment was applied to prevent eye drying. Subcutaneous fluids (0.9% NaCl) were administered during the procedure (5 mg/kg/hr). For the surgery, the top of the skull was first clipped and prepped, and then a midline incision was made to expose the top of the skull. A hand drill was used to secure several orthopedic screws to the skull (one serves as an electrical ground for data acquisition). After the screws were secured, a 1 mm diameter wide hole was drilled directly above the medial entorhinal cortex. The location of the hole was determined using a stereotaxic atlas (coordinates from Bregma −8.5 AP, 4.5 ML), and landmarks on the skull (hole was tangential to the side skull ridge and over the extended lambda skull crevice). During drilling, the skull and holes were kept from excessive drying by applying sterile saline, and drilled only deep enough to expose the dura. Using a sterile dura cutting tool, a small incision was made and the recording electrodes were slowly lowered into the brain (to a depth of 1000 microns). Surgical adhesive (Kwik-Sil) was used to fill in the space between the implant and the skull hole. With the implant in-place, the ground wire was connected to one of the ground screws, and carefully sealed with silver conductive ink. After curing, several layers of adhesive cement (C&amp;B Metabond) was applied to cover the screws and implant. Finally, dental acrylic cement was used to adhere the metabond layers to the rest of the implant. Sterile sutures were applied to secure the skin around the implant. Following the surgery, the rats recovered on a circulating warm water blanket and were checked every 15 minutes until mobile.</p>
</sec>
<sec id="s7a2">
<label>7.1.2</label>
<title>Histology</title>
<p>Upon completion of the final recording session, rats were anesthetized with 2–4% of isoflurane in <italic>O</italic><sup>2</sup> and euthanized using an overdose of pentobarbitol followed by transcardial perfusion with saline and 10% formalin. After the brain was stored in formalin for at least 24 hours, the hemisphere containing the implant was sliced into 25 μm sagittal sections using a cryostat microtome. Sections were mounted on slides and Nissl-stained with cresyl violet. Microdrive damage to the tissue was extensive and exact tetrode locations were difficult to pinpoint across the regions of interest (MEC, PaS, PrS). Rough coordinates of tetrodes ranged from 1mm from the cortical surface to 4mm (Dorso-Ventral), 7.5-9mm from Bregma, and 3.6-4.6mm to the right of the medial fissure (Medio-Lateral). Slices for the five animals reported can be seen in Sup. Fig. 2.</p>
</sec>
</sec>
<sec id="s7b">
<label>7.2</label>
<title>Recordings</title>
<p>Electrophysiological signals were recorded using a Digital Lynx 4Sx data acquisition system with up to 64 channels (Neuralynx, Inc.). A head-stage amplifier was attached to the subjects implant before each recording session, and the connecting light-weight cable was routed through a power commutator (Neuralynx Inc.), which then connects to the acquisition system. Data was collected at 32kHz, and digitized at 16 bits. We used the Cheetah interface (Neuralynx, Inc.) for data collection and monitoring. All of the events from the environment were sent via a micro-controller to the Digital Lynx TTL input board. One of the cameras synced with the Cheetah interface, and was set up to save color channels (at a user defined luminance threshold) for the detection of the subject’s location (LEDs for tracking are located on the head-stage amplifier). The processed video data only saved x, y positions and head angle. A second high-resolution/high-rate color camera worked independently to record the animals’ behavior in the maze (Basler Inc.)</p>
</sec>
<sec id="s7c">
<label>7.3</label>
<title>Behavioral Rig</title>
<sec id="s7c1">
<label>7.3.1</label>
<title>Housing Frame</title>
<p>A custom designed aluminum frame (80/20 Inc.) housed the behavioral apparatus, two high resolution cameras and commutator (dimensions: 1.3m width, 1.5m length, 2.5m height). The frame was connected to a ground port of the recording system and the behavioral micro-controller device. A series of supports beams were placed 1.35m above ground to hold the large “floor” panels that make the open-field setup. Black polycarbonate panels (0.5m height) around the frame were placed at 1.37m, which allow the floor panels to slide into the aluminum frame for open-field sessions. Signal cables and liquid reward tubing are routed through the indentures of the frame, where possible.</p>
</sec>
<sec id="s7c2">
<label>7.3.2</label>
<title>Tree-Maze</title>
<p>We adapted the Tree-Maze behavioral apparatus from [<xref ref-type="bibr" rid="c47">47</xref>], <xref ref-type="fig" rid="fig1">Fig. 1a</xref>. The overall dimensions of the maze were 1.4m x 1.2m, and it was suspended 1 meter above the ground in the Behavioral Rig aluminum frame. The maze featured six reward wells, each equipped with infra-red detectors for nose-poke detection and a white LED light that indicated the presence of reward. The reward wells were custom designed with luer-lock ports, space for IR detectors and the LED. The wells were 3D printed with a ONYX carbon plastic material, which provides it with the required stiffness and chemical resistivity. The luer-lock ports are used to connect to food-grade PVC tubes that transport the liquid reward. These wells also have an ethernet port that connects them to the electrical controls (LED, IR detection signal, power and ground). The control port and reward port are located below the maze, such that the animal has no visibility or access. The cue panel is a 16×16 RGB LED programmable array, placed on the back wall of the apparatus and 40 cm above the maze. Liquid milk rewards (80% evaporated milk / 20% H20 + 20grams of sucrose) are delivered via a custom designed pump system. The 6-pump system consists of linear actuators (3inch-12Volt actuators, Progressive Automations Inc.) operating on milk filled syringes. This system of pumps is enabled via an array of relays and custom circuit boards with switches, allowing both manual and programmatic control of the pumps. A custom designed housing box encloses the electronics and relays, with external attachment features to hold the pumps, syringes, switches and power input.</p>
<p>Low-level control of the environment (LEDs, sensors, reward delivery, cue, pulse event outputs; +5V binary signals) is achieved through an Arduino Mega micro-controller, with a custom designed input/output interface. Each well, the cue, and the pump system are connected to this interface via ethernet cables (RJ45). A Python custom-coded state machine framework is used to control the Arduino via USB. The PC-operated custom Python code provided a command line interface to monitor and control the environment parameters online (e.g. amount of reward for a well, well LEDs, cue, switch probability). Events are saved on the computer and are sent as TTL inputs to the electrophysiology recording device. Environmental control is enabled through the state-machine-like software architecture, in which states are defined by which well is enabled to give out reward. This platform allows for quick customization of environment parameters and task structure. Designs and software are available on <ext-link ext-link-type="uri" xlink:href="https://github.com/alexgonzl/TreeMaze">https://github.com/alexgonzl/TreeMaze</ext-link>.</p>
</sec>
<sec id="s7c3">
<label>7.3.3</label>
<title>Open-Field</title>
<p>Open-Field foraging experiments can be performed on the same Behavioral Rig, by sliding “floor panels” on the housing frame. The resulting field sits atop 20cm above the Tree-Maze, with all other peripheral cues remaining the same, including the LED cue panel as an in-environment cue landmark. The dimensions of field are 1.3m x 1.5m.</p>
</sec>
</sec>
<sec id="s7d">
<label>7.4</label>
<title>Behavioral Training</title>
<p>After subjects are acclimatized to human handling and receiving solid food reward (Cheerios), they are placed in the Tree-Maze environment. In initial sessions, subjects simply explore the environment that contain Cheerios at the reward wells, such that they associate these locations with reward. Once the location-reward association is established, the food restriction protocol begins (see the Subjects section). The training protocol then follows these stages: (0) introduction to milk-reward, (1) LED light - reward conditioning, (2) task-route training, (3) cue L/R navigation, and (4) reward wells LED off. In Stage 0 ( 1 session) the solid rewards are replaced with milk rewards. Stage 1 takes about 2 sessions to master, and in this stage the milk rewards are only provided after triggering (nose poke Infra-Red beam-break &gt; 10ms) active wells which have an ON LED light. After a detected beam-break on an active well, the milk reward is delivered and the LED light is turned OFF. A log of number of activated wells was kept to track progress. Stage 2 (~5 sessions to a 20 trial criteria) introduces the basic trial structure of the task by having reward sequences in the following pattern: (1) Home-well (H) → (2) Decision-well (D) → (3) Goal-well (G) → (4) H. In this training stage, any one of the Goal-wells (G1-G4) can be rewarded at the third point of the sequence; and once a goal is triggered the rewards on the others are no longer available. The subject then needs to return to H and trigger it to commence a new trial. Once subjects can perform more than 20 trials, they advance to the next stage. Stage 3 (<sup>~</sup>32 sessions to 75% behavioral accuracy and 80 trials criteria) is the final stage of training, it has two parts, and once subjects reach the performance and number of trials criterion they are candidates for surgery (Sup. Fig. 1). In Stage 3a, in addition to the sequence introduced in Stage 2, subjects now see a cue after triggering the HW at the beginning of a trial. The cue can be green pulsating at 7Hz indicating a left turn, or purple pulsating at 3Hz indicating a right turn. These turns indicate where the animal needs to turn after D to receive further reward at a goal. For a turn right cue (purple), the subject will need to turn right after the triggering D, and triggering one of G1 or G2. However, only one goal (experimentally chosen at random) on the right branch will have reward but both have LED lights on to indicate possible reward. Similarly for a turn left cue, and G3-4. In Stage 3b, the LED lights on the goals never light up, and after D the subject only has the ongoing cue signal to make a turn decision. Notably, the H and D retain their LED ligths ON at the appropriate times in the trial sequence.</p>
</sec>
<sec id="s7e">
<label>7.5</label>
<title>Data Processing</title>
<sec id="s7e1">
<label>7.5.1</label>
<title>Electrophysiolgy Pre-processing</title>
<p>Individual broadband traces for each channel are characterized includes quantification of clipped segments, power spectrum peaks, and amplitude histogram. This information is later used to determine if channels should be excluded from analyses. Each trace is digitally filtered using filter banks of IIR Second-Order Sections (high-pass 2Hz, low-pass 5kHz, notches at 60 and 120 Hz).</p>
</sec>
<sec id="s7e2">
<label>7.5.2</label>
<title>Unit clustering</title>
<p>The Kilosort2 algorithm [<xref ref-type="bibr" rid="c48">48</xref>], open-source python packages (SpikeInterface [<xref ref-type="bibr" rid="c49">49</xref>]), and custom python scripts were cell clustering for each recorded session. For Kilosort, mostly default values were used, with modifications appropriate for tetrode recordings (probe geometry, no common referencing and no data whitening). Manual curation was used to classify the resulting clusters from Kilosort as cells (units), multi-unit (MUA), or noise. Cluster statistics and heuristics used for classification were inter-spike interval violations, signal-to-noise ratio, waveform shape, and cross-correlogram relationship with other clusters within the session.</p>
</sec>
<sec id="s7e3">
<label>7.5.3</label>
<title>Across session unit matching</title>
<p>In order to match unit across sessions the following algorithm was used. First, we matched tetrodes across sessions according to their depth for each subject. That is, this algorithm only tries to match units across sessions for which the corresponding tetrodes was at the same depth for those sessions. Second, a random sampling of 1000 spike waveforms for each unit across the matched sessions are pooled into a single data matrix <italic>W</italic>. A single spike waveform has a total of 32 samples (centered around the peak) for each tetrode channel for a total of 128 features. The size of the matrix is then 1000 times the number of units by 128. Each row of <italic>W</italic> corresponds to a unit’s waveform, denoted as <italic>u<sub>k,i</sub></italic>, where <italic>k</italic> is the unit number and <italic>i</italic> corresponds to the ith spike of unit <italic>k</italic>. Second, <italic>W</italic> is then subjected to UMAP for unsurpervised dimensionality reduction into 2 dimensions <italic>W</italic><sub>UMAP</sub><sub>2</sub>. Third, for each unit <italic>u<sub>k</sub></italic>, robust mean and covariance estimates are obtained via (Minimum Covariance Determinant-MCD, [<xref ref-type="bibr" rid="c50">50</xref>]), such that the 2-d UMAP representation of wave-forms for unit <italic>k</italic> can be described with a compact 2d Gaussian <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline47.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. We then create a distance metric based on the expected probability of cluster mis-classification error:
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="520660v1_eqn1.gif" mime-subtype="gif" mimetype="image"/></alternatives>
</disp-formula>
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="520660v1_eqn2.gif" mime-subtype="gif" mimetype="image"/></alternatives>
</disp-formula>
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="520660v1_eqn3.gif" mime-subtype="gif" mimetype="image"/></alternatives>
</disp-formula>
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="520660v1_eqn4.gif" mime-subtype="gif" mimetype="image"/></alternatives>
</disp-formula>
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="520660v1_eqn5.gif" mime-subtype="gif" mimetype="image"/></alternatives>
</disp-formula>
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="520660v1_eqn6.gif" mime-subtype="gif" mimetype="image"/></alternatives>
</disp-formula></p>
<p>Note that the <italic>x</italic> in the above equations represents the 2-d UMAP waveform representation of one spike. The value of <italic>E<sub>kk</sub></italic>, <xref ref-type="disp-formula" rid="eqn2">equation 2</xref>, is the expected value of <italic>f<sub>k</sub></italic> evaluated on all the entries of <italic>W</italic><sub>UMAP</sub><sub>2</sub> that are from unit <italic>u<sub>k</sub></italic>, and serves as a normalizing factor the computations of normalized error 5. The value of <italic>E<sub>kp</sub></italic> is the expected value of evaluating spikes from unit <italic>u<sub>p</sub></italic> in <italic>f<sub>k</sub></italic>, and this quantity represents the unnormalized distance of unit <italic>u<sub>p</sub></italic> to the parameterized representation of unit <italic>u<sub>k</sub></italic>. The final step uses averages the normalized distances between <italic>u<sub>p</sub></italic> and <italic>u<sub>k</sub></italic> to obtain <italic>d<sub>kp</sub></italic>, the metric used in matching units across sessions, <xref ref-type="disp-formula" rid="eqn6">equation 6</xref>. An important point is that the 2D representation provided by UMAP is not deterministic and relatively fragile to algorithmic parameters. Nonetheless, our procedure was robust for a large range of parameters and replicated using t-SNE instead of UMAP.</p>
<p>We considered two additional metrics to evaluate distance metrics Hellinger distance <italic>H</italic><sup>2</sup> and Kullback-Leibler divergence <italic>D<sub>KL</sub></italic>. Equations provided below for reference in the context of multivariate Gaussians.
<disp-formula>
<alternatives><graphic xlink:href="520660v1_ueqn1.gif" mime-subtype="gif" mimetype="image"/></alternatives>
</disp-formula></p>
<p>In this context, the mis-classification error metric <italic>d</italic> had some appealing properties in comparison to <italic>H</italic><sup>2</sup> and <italic>D<sub>KL</sub></italic>. First, <italic>d</italic>v it is bounded from 0 to 1, with 1 indicating that the clusters do not overlap, while zero indicating that they perfectly overlap, and 0.5 indicating that both clusters are equally likely.Having a bounded metrics allowed for establishing a threshold that was consistent across multiple waveform scaling scenarios. Second, it is symmetric, <italic>d<sub>kp</sub></italic> = <italic>d<sub>pk</sub></italic>, a desired property in determining if the units are the same across multiple sessions. Note that <italic>H</italic><sup>2</sup> is both bounded and symmetric. Third, it has an intuitive interpretation as the distance between unit waveforms (or the parameterized representations) with data points being evaluated and not depending completely on the Gaussian parameterization. In contrast, both <italic>H</italic><sup>2</sup> and <italic>D<sub>KL</sub></italic> will only be as accurate as the Gaussian parameterization of the unit cluster is (as computed through the minimum covariance determinant algorithm).</p>
</sec>
</sec>
<sec id="s7f">
<label>7.6</label>
<title>Remapping</title>
<sec id="s7f1">
<label>7.6.1</label>
<title>Balanced Trial Resampling</title>
<p>An important component of the analyses that compared across conditions was obtaining a full and balanced coverage of the Tree-Maze environment. For example, for a session with 100 trials (40 LC / 60 RC) the actual coverage by cue condition will depend on the performance of the subject. If the subject performed at 50% for RC trials, the RC trial set is composed of 30 trials in which the subject navigated left after the Decision-well, and 30 trials navigated right. On average subjects perform at 75%, and on this example that means 45 trials in which the subject navigates to the right, and 15 in which the subject navigates left. Our procedure simply sampled an equal number of Correct and Incorrect trials per cue condition with replacement. This procedure was repeated 100 times for all statistical results reported, or 50 for plotting purposes. For generating the appropriate null distributions, even and odd trial sets were each balanced re-sampled by the number of Left-Cue and Right-Cue trials. Specifically, an equal number of Left-Cue and Right-Cue trials were sampled for each even and odd condition. The cue condition was defined by comparing Correct and Incorrect trials, and the balancing condition was cue. Sessions that do not meet a minimum of 5 trials in the nested conditions were excluded from these analyses.</p>
</sec>
<sec id="s7f2">
<label>7.6.2</label>
<title>Firing Rate Maps</title>
<p>Traditionally firing rate maps are generated by pooling all samples and the corresponding spikes of a single unit to generate a single firing rate map. Because of the trial structure of employed in the Tree-Maze, we instead obtained trial-wise firing rates for each segment in the maze (including linear sub-segments n=39) (<xref ref-type="fig" rid="fig2">Fig. 2b</xref>). This approach then allowed the selection of trials to generate mean firing rate maps across trials. In the presence of possible outlying trials, this approach can generate a more robust estimate of the true representation of the environment. Outbound trial trajectories are those in which the start is at when the subject receives the Home-well start trial reward (triggering the cue) and end at the last Goal-well detection. Inbound trial trajectories are those that start after the last Goal-well detection and end when the subject receives the reward to commence the next trial.</p>
</sec>
<sec id="s7f3">
<label>7.6.3</label>
<title>Remapping Scores</title>
<p>Remapping scores have two main components, a Test correlation score and a null correlation score. Each correlation score is the result of a Kendall correlation <italic>τ</italic> between mean firing rate maps for a given trial set. Thus, for a single remapping score there are 4 set of trials each used to generate firing rate maps, and 2 correlation scores <italic>τ<sub>Test</sub></italic> and <italic>τ<sub>Null</sub></italic>. The use of Kendall ranked correlation provided robust measure of correlation. Zones with no samples in a given trial set are not included in subsequent calculations. Kendall correlations are first converted to a Pearson equivalent score: <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline48.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, Fisher transformed <italic>z</italic> = arctan <italic>r</italic>, and scores between the test measure and null measure are then compared with the following formula for comparing Fisher transformed correlations <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline49.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. This procedure was performed for each bootstrapped instance and for each unit, and averaged to obtain a final remapping score: <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline50.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>.</p>
</sec>
<sec id="s7f4">
<label>7.6.4</label>
<title>Statistics</title>
<p>Analyses of firing rate differences by condition were quantified using the Mann-Whitney U statistic (subsequently transformed to a Z statistic, <italic>U<sub>Z</sub></italic>). As this is a ranking statistic, it is more robust against trial outliers in firing-rate magnitude and to low trial numbers.</p>
<p>Formal statistical analyses leveraged the power of Linear Mixed Effects Models (LMEM) to account for within subject variance, and repeated measures (units) in each session. This feature was of particular importance as there were different number of sessions and units by subject. For firing-rate analyses across units the condition difference statistic <italic>U<sub>Z</sub></italic> was modeled as a function of maze segment. For remapping analyses, the remapping score <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline51.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> to explain a sessions performance <italic>p<sub>se</sub></italic>, with subject and task versions as random effects. Coefficient estimates <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline52.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> (slope of the linear model) were reported along 95% confidence intervals. In addition, a Log Likelihood Ratio Test (LRT) was performed against a null LMEM that excludes <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline53.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> as an explanatory variable, with significance testing using a <italic>χ</italic><sup>2</sup> distribution. The LMEM approach was employed in all reported statistical analyses. These analyses were performed using the Stats-Models Python package and custom python scripts.</p>
</sec>
</sec>
<sec id="s7g">
<label>7.7</label>
<title>Tree-Maze Encoder/Decoder</title>
<sec id="s7g1">
<label>7.7.1</label>
<title>Encoder</title>
<p>Data (behavioral/experimental variables and neuronal firing rate) were binned in 20ms windows, and each cross-validation (n folds=5) training set contained an equal number of Left-Cue and Right-Cue trials, with each training sample weighted by the corresponding proportion of correct or incorrect trials. This crossvalidation approach attempts to fully represent the space and task in a balanced manner.</p>
<p>Position on the maze was modeled as a feature vector with a value of 1 on the feature location that corresponds to the subject’s location at a given time sample (# of possible positions = <italic>N<sub>Z</sub></italic> = 39). The values on the rest of the feature vector were zero for the base model (one-hot vector). We also employed modified versions of this feature vector with an inverse lag decay function <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline54.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> that modeled previous or future positions relative to the position at the given sample. These feature vectors were then used to train a Least-Squares Regression model to predict the firing rate of individual units on each 20ms sample bin. Three lag encoding models were used to fit the data: <italic>F<sub>Z<sub>0</sub></sub></italic> corresponding to the base feature vector, <italic>F<sub>Z<sub>50</sub></sub></italic> corresponding to prospective feature vector that ‘look ahead’ 50 samples (=1 second), and <italic>F<sub>Z-50</sub></italic> a retrospective feature vector that ‘look behind’ 50 samples. These feature modifications for the lag models (<italic>Z</italic><sub>50</sub> and <italic>Z</italic>—50) were performed by trial to avoid across trial confounds. Because the best performing lag model was the <italic>Z</italic><sub>50</sub> ‘look ahead’ encoder, all additional encoder models were trained with this zone feature scheme and therefor referred to the <italic>Z</italic> model.</p>
<p>Cue encoding is modeled in two ways. First as a global signal that does not interact with the feature vector (a rate-remapping model, <italic>F<sub>Z+C</sub></italic>). This was implemented with 2 additional inputs into the model, one for each cue, with value of 1 for the samples that corresponded to each trial type and zero otherwise (n of features = 41). Of note, because only one of the cues was ever present on a given trial, it was possible to model the cue with a single binary feature. This produced the qualitative results and predictions with one fewer degree of freedom, but zone coefficients then required an extra transformation for interpretation. Having each cue modeled separately produced immediately interpretable cue and zone coefficients. In the second modeling approach, each position of the maze was modeled as a function of cue (interactive model or global-remapping model, <italic>F<sub>ZxC</sub></italic>), that is - a second set of 39 features were added to model, with each 39 position set only being active on trials that correspond to each cue type (see Sup. Fig 12).</p>
<p>After fitting Least Squares Regression for the base model (<italic>Z</italic><sub>0</sub>, 0 lag, no cue signal), we obtained the weights <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline55.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> such that the predicted firing rate could be represented as <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline56.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. Where firing rate used to fit the data can then be expressed as <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline57.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, where <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline58.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. The <italic>N<sub>u</sub></italic> represents the number of fitted units.</p>
<p>The coefficient of determination (<italic>R</italic><sup>2</sup>) was computed for each neuron and test fold, with the average across folds used to summarize the extent to which a given encoding model predicted firing rate <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline59.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> the firing rate of each neuron (v<sub>u¿</sub>), where u¿ represents unit <italic>i</italic>.
<disp-formula>
<alternatives><graphic xlink:href="520660v1_ueqn2.gif" mime-subtype="gif" mimetype="image"/></alternatives>
</disp-formula></p>
<p>Where <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline60.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> represents the mean firing rate for unit <italic>i</italic>, and <bold>1</bold> is a vector of ones. On test data, <italic>R</italic><sup>2</sup> values can be negative as a model can be arbitrarily worse than the mean in estimating the firing rate fluctuations. However, values less than negative one reflected convergence issues and were excluded from further analyses (# unit exclusions by analysis: cue 32 units, RW 27 units).</p>
</sec>
<sec id="s7g2">
<label>7.7.2</label>
<title>Decoder</title>
<p>A decoder fitted with Multinomial Logistic Regression can be trained to predict position in the maze by time sample, where the probability of being in zone <italic>z</italic>[<italic>t</italic>] given population neural activity <italic>V</italic>[<italic>t</italic>] can be expressed as:
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="520660v1_eqn7.gif" mime-subtype="gif" mimetype="image"/></alternatives>
</disp-formula></p>
<p>Where <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline61.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula> represents the model’s matrix of weights that map population activity to maze position <italic>z</italic>, and Φ is the softmax function (multi-class version of the logistic function). This decoder provides probability values for all positions at a given time sample.</p>
<p>Other variables of interest have single output by trial, namely cue, decision and goal. In this work we employed a decision decoder, which can be represented as:
<disp-formula>
<alternatives><graphic xlink:href="520660v1_ueqn3.gif" mime-subtype="gif" mimetype="image"/></alternatives>
</disp-formula></p>
<p>Note that the decoder outputs a sample wise estimates of each of the trial-wise variables of interest, in this case the subject’s decision. To quantify performance, we take the average probability output by zone across samples by trial, producing a matrix of trials x zones. To get a more continuous estimate, probabilities are converted to logits and integrated across zones (Fig. <bold>??</bold>, Sup. Fig. 12).</p>
</sec>
</sec>
<sec id="s7h">
<label>7.8</label>
<title>Open-Field Tuning Metrics</title>
<p>Traditional open-field tuning metrics were quantified as in previous studies (e.g. [<xref ref-type="bibr" rid="c13">13</xref>]). Briefly, speed-score corresponded to the linear correlation between binned speeds and firing rate activity by unit. Head-direction scores were computed as <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline62.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>, where <italic>N</italic> is the number of samples, <italic>i</italic> is the sample number, <italic>θ</italic> is the head direction of the animal, and <inline-formula><alternatives><inline-graphic xlink:href="520660v1_inline63.gif" mime-subtype="gif" mimetype="image"/></alternatives></inline-formula>. Periods of immobility were excluded from this computation (speed &lt; 2cm/s), and to obtain a final score the magnitude of R is taken. Finally, position scores corresponded to the correlation between spatial rate maps corresponding to the first half and second half of the experimental sessions.</p>
</sec>
<sec id="s7i">
<label>7.9</label>
<title>Open-Field Encoding Models</title>
<p>Three main models were used to quantify the extent of spatial/navigational coding of single units: position, head-direction and speed. Blocked time-series cross validation was followed to generate training and test sets for the models, with each block being of length of 20 seconds. Periods of immobility <italic>speed &lt; 2cm/second</italic> were excluded from the head direction models. Binned head-direction and speed behavioral features were used to model those variables. The position model also employ binned positions, but then transformed into a lower dimensional space using PCA. All models predicted firing-rate using simple linear regression. Quantification on test sets was performed by comparing the test firing rate and corresponding predicted rates and using <italic>R</italic><sup>2</sup> and spatial map correlations <italic>r<sub>p</sub></italic>. Aggregate models took training set predicted firing rates for each model (speed, head-direction and position) as features (3 total features), and was correspondingly tested on unseen test data. The coefficients of the aggregate models were used to cluster these cells into functional coding groups.</p>
</sec>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Hafting</surname></string-name> <etal>et al.</etal> “<article-title>Microstructure of a spatial map in the entorhinal cortex</article-title>”. In: <source>Nature</source> <volume>436</volume>.<issue>7052</issue> (<year>2005</year>). Type: Journal Article, pp. <fpage>801</fpage>–<lpage>6</lpage>. URL: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=15965463">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=15965463</ext-link>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Kropff</surname></string-name> <etal>et al.</etal> “<article-title>Speed cells in the medial entorhinal cortex</article-title>”. In: <source>Nature</source> <volume>523</volume>.<issue>7561</issue> (<year>2015</year>). Type: Journal Article, pp. <fpage>419</fpage>–<lpage>24</lpage>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Solstad</surname></string-name> <etal>et al.</etal> “<article-title>Representation of geometric borders in the entorhinal cortex</article-title>”. In: <source>Science</source> <volume>322</volume>.<issue>5909</issue> (<year>2008</year>). Type: Journal Article, pp. <fpage>1865</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>F.</given-names> <surname>Sargolini</surname></string-name> <etal>et al.</etal> “<article-title>Conjunctive representation of position, direction, and velocity in entorhinal cortex</article-title>”. In: <source>Science</source> <volume>312</volume>.<issue>5774</issue> (<year>2006</year>). Type: Journal Article, pp. <fpage>758</fpage>–<lpage>62</lpage>. URL: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=16675704">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=16675704</ext-link>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>O. A.</given-names> <surname>Hoydal</surname></string-name> <etal>et al.</etal> “<article-title>Object-vector coding in the medial entorhinal cortex</article-title>”. In: <source>Nature</source> <volume>568</volume>.<issue>7752</issue> (<year>2019</year>). Type: Journal Article, pp. <fpage>400</fpage>–<lpage>404</lpage>. ISSN: <issn>1476-4687 (Electronic) 0028-0836 (Linking)</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41586-019-1077-7</pub-id>. URL: <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/30944479">https://www.ncbi.nlm.nih.gov/pubmed/30944479</ext-link>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>C. N.</given-names> <surname>Boccara</surname></string-name> <etal>et al.</etal> “<article-title>Grid cells in pre-and parasubiculum</article-title>”. In: <source>Nat Neurosci</source> <volume>13</volume>.<issue>8</issue> (<year>2010</year>). Type: Journal Article, pp. <fpage>987</fpage>–<lpage>94</lpage>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="book"><string-name><given-names>Natalie L.M.</given-names> <surname>Cappaert</surname></string-name>, <string-name><given-names>Niels M.</given-names> <surname>Van Strien</surname></string-name>, and <string-name><given-names>Menno P.</given-names> <surname>Witter</surname></string-name>. “<chapter-title>Chapter 20-Hippocampal Formation</chapter-title>”. In: <source>The Rat Nervous System (Fourth Edition)</source>. Ed. by <person-group person-group-type="editor"><string-name><given-names>George</given-names> <surname>Paxinos</surname></string-name></person-group>. <edition>Fourth</edition> Edition. <publisher-loc>San Diego</publisher-loc>: <publisher-name>Academic Press</publisher-name>, <year>2015</year>, pp. <fpage>511</fpage>–<lpage>573</lpage>. ISBN: <isbn>978-0-12-374245-2</isbn>. DOI: <pub-id pub-id-type="doi">10.1016/B978-0-12-374245-2.00020-6</pub-id>. URL: <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/B9780123742452000206">https://www.sciencedirect.com/science/article/pii/B9780123742452000206</ext-link>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>A. D.</given-names> <surname>Ekstrom</surname></string-name> and <string-name><given-names>C.</given-names> <surname>Ranganath</surname></string-name>. “<article-title>Space, time, and episodic memory: The hippocampus is all over the cognitive map</article-title>”. In: <source>Hippocampus</source> <volume>28</volume>.<issue>9</issue> (<month>Sept</month>. <year>2018</year>), pp. <fpage>680</fpage>–<lpage>687</lpage>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>G.</given-names> <surname>Buzsáki</surname></string-name> and <string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>. “<article-title>Memory, navigation and theta rhythm in the hippocampal-entorhinal system</article-title>”. In: <source>Nat Neurosci</source> <volume>16</volume>.<issue>2</issue> (<year>2013</year>). Type: Journal Article, pp. <fpage>130</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Lisman</surname></string-name> <etal>et al.</etal> “<article-title>Viewpoints: how the hippocampus contributes to memory, navigation and cognition</article-title>”. In: <source>Nat Neurosci</source> <volume>20</volume>.<issue>11</issue> (<month>Oct</month>. <year>2017</year>), pp. <fpage>1434</fpage>–<lpage>1447</lpage>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>L. M.</given-names> <surname>Frank</surname></string-name>, <string-name><given-names>E. N.</given-names> <surname>Brown</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Wilson</surname></string-name>. “<article-title>Trajectory encoding in the hippocampus and entorhinal cortex</article-title>”. In: <source>Neuron</source> <volume>27</volume>.<issue>1</issue> (<year>2000</year>). Type: Journal Article, pp. <fpage>169</fpage>–<lpage>78</lpage>. URL: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=10939340">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=10939340</ext-link>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>P. A.</given-names> <surname>Lipton</surname></string-name>, <string-name><given-names>J. A.</given-names> <surname>White</surname></string-name>, and <string-name><given-names>H.</given-names> <surname>Eichenbaum</surname></string-name>. “<article-title>Disambiguation of overlapping experiences by neurons in the medial entorhinal cortex</article-title>”. In: <source>J Neurosci</source> <volume>27</volume>.<issue>21</issue> (<year>2007</year>). Type: Journal Article, pp. <fpage>5787</fpage>–<lpage>95</lpage>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Hardcastle</surname></string-name> <etal>et al.</etal> “<article-title>A multiplexed, heterogeneous, and adaptive code for navigation in medial entorhinal cortex</article-title>”. In: <source>Neuron</source> <volume>94</volume>.<issue>2</issue> (<year>2017</year>). Type: Journal Article, pp. <fpage>375</fpage>–<lpage>387</lpage>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>G. W.</given-names> <surname>Diehl</surname></string-name> <etal>et al.</etal> “<article-title>Grid and nongrid cells in medial entorhinal cortex represent spatial location and environmental features with complementary coding schemes</article-title>”. In: <source>Neuron</source> <volume>94</volume>.<issue>1</issue> (<year>2017</year>). Type: Journal Article, pp. <fpage>83</fpage>–<lpage>92</lpage>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>Spalla</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Treves</surname></string-name>, and <string-name><given-names>C. N.</given-names> <surname>Boccara</surname></string-name>. “<article-title>Angular and linear speed cells in the parahippocampal circuits</article-title>”. In: <source>Nat Commun</source> <volume>13</volume>.<issue>1</issue> (<month>Apr</month>. <year>2022</year>), p. <fpage>1907</fpage>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>Q.</given-names> <surname>Tang</surname></string-name> <etal>et al.</etal> “<article-title>Functional Architecture of the Rat Parasubiculum</article-title>”. In: <source>J Neurosci</source> <volume>36</volume>.<issue>7</issue> (<month>Feb</month>. <year>2016</year>), pp. <fpage>2289</fpage>–<lpage>2301</lpage>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>J. G.</given-names> <surname>Heys</surname></string-name> and <string-name><given-names>D. A.</given-names> <surname>Dombeck</surname></string-name>. “<article-title>Evidence for a subcircuit in medial entorhinal cortex representing elapsed time during immobility</article-title>”. In: <source>Nat Neurosci</source> <volume>21</volume>.<issue>11</issue> (<year>2018</year>). Type: Journal Article, pp. <fpage>1574</fpage>–<lpage>1582</lpage>. ISSN: <issn>1546-1726 (Electronic) 1097-6256 (Linking)</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41593-018-0252-8</pub-id>. URL: <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/30349104">https://www.ncbi.nlm.nih.gov/pubmed/30349104</ext-link>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>W. N.</given-names> <surname>Butler</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Hardcastle</surname></string-name>, and <string-name><given-names>L. M.</given-names> <surname>Giocomo</surname></string-name>. “<article-title>Remembered reward locations restructure entorhinal spatial maps</article-title>”. In: <source>Science</source> <volume>363</volume>.<issue>6434</issue> (<year>2019</year>). Type: Journal Article, pp. <fpage>1447</fpage>–<lpage>1452</lpage>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>C. N.</given-names> <surname>Boccara</surname></string-name> <etal>et al.</etal> “<article-title>The entorhinal cognitive map is attracted to goals</article-title>”. In: <source>Science</source> <volume>363</volume>.<issue>6434</issue> (<year>2019</year>). Type: Journal Article, pp. <fpage>1443</fpage>–<lpage>1447</lpage>. ISSN: <issn>1095-9203 (Electronic) 0036-8075 (Linking)</issn>. DOI: <pub-id pub-id-type="doi">10.1126/science.aav4837</pub-id>. URL: <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/30923221">https://www.ncbi.nlm.nih.gov/pubmed/30923221</ext-link>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><given-names>Dmitriy</given-names> <surname>Aronov</surname></string-name>, <string-name><given-names>Rhino</given-names> <surname>Nevers</surname></string-name>, and <string-name><given-names>David W.</given-names> <surname>Tank</surname></string-name>. “<article-title>Mapping of a non-spatial dimension by the hippocampal-entorhinal circuit</article-title>”. In: <source>Nature</source> <volume>543</volume>.<issue>7647</issue> (<month>Mar</month>. <year>2017</year>), pp. <fpage>719</fpage>–<lpage>722</lpage>. ISSN: <issn>0028-0836, 14764687</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nature21692</pub-id>. URL: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/articles/nature21692">http://www.nature.com/articles/nature21692</ext-link>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><given-names>N. T. M.</given-names> <surname>Robinson</surname></string-name> <etal>et al.</etal> “<article-title>Targeted Activation of Hippocampal Place Cells Drives Memory-Guided Spatial Behavior</article-title>”. In: <source>Cell</source> <volume>183</volume>.<issue>7</issue> (<year>2020</year>). Type: Journal Article, pp. <fpage>2041</fpage>–<lpage>2042</lpage>. ISSN: <issn>1097-4172</issn> (Electronic) 0092-8674 (Linking). DOI: <pub-id pub-id-type="doi">10.1016/j.cell.2020.12.010</pub-id>. URL: <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/33357402">https://www.ncbi.nlm.nih.gov/pubmed/33357402</ext-link>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><given-names>J. L.</given-names> <surname>Gauthier</surname></string-name> and <string-name><given-names>D. W.</given-names> <surname>Tank</surname></string-name>. “<article-title>A dedicated population for reward coding in the hippocampus</article-title>”. In: <source>Neuron</source> <volume>99</volume>.<issue>1</issue> (<year>2018</year>). Type: Journal Article, pp. <fpage>179</fpage>–<lpage>193</lpage>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><given-names>S. A.</given-names> <surname>Hollup</surname></string-name> <etal>et al.</etal> “<article-title>Accumulation of hippocampal place fields at the goal location in an annular watermaze task</article-title>”. In: <source>J Neurosci</source> <volume>21</volume>.<issue>5</issue> (<year>2001</year>). Type: Journal Article, pp. <fpage>1635</fpage>–<lpage>1644</lpage>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>L. L.</given-names> <surname>Colgin</surname></string-name>, <string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>M. B.</given-names> <surname>Moser</surname></string-name>. “<article-title>Understanding memory through hippocampal remapping</article-title>”. In: <source>Trends Neurosci</source> <volume>31</volume>.<issue>9</issue> (<year>2008</year>), pp. <fpage>469</fpage>–<lpage>477</lpage>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><given-names>James C. R.</given-names> <surname>Whittington</surname></string-name> <etal>et al.</etal> “<article-title>The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation</article-title>”. In: <source>Cell</source> <volume>183</volume>.<issue>5</issue> (<year>2020</year>). ISSN: <issn>00928674</issn>. DOI: <pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>. “<article-title>Place units in the hippocampus of the freely moving rat</article-title>”. In: <source>Exp Neurol</source> <volume>51</volume>.<issue>1</issue> (<year>1976</year>). Type: Journal Article, pp. <fpage>78</fpage>–<lpage>109</lpage>. URL: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=1261644">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=1261644</ext-link>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Leutgeb</surname></string-name> <etal>et al.</etal> “<article-title>Independent codes for spatial and episodic memory in hippocampal neuronal ensembles</article-title>”. In: <source>Science</source> <volume>309</volume>.<issue>5734</issue> (<year>2005</year>). Type: Journal Article, pp. <fpage>619</fpage>–<lpage>23</lpage>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><given-names>M. H.</given-names> <surname>Plitt</surname></string-name> and <string-name><given-names>L. M.</given-names> <surname>Giocomo</surname></string-name>. “<article-title>Experience-dependent contextual codes in the hippocampus</article-title>”. In: <source>Nat Neurosci</source> <volume>24</volume>.<issue>5</issue> (<month>May</month> <year>2021</year>), pp. <fpage>705</fpage>–<lpage>714</lpage>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><string-name><given-names>R. U.</given-names> <surname>Muller</surname></string-name> and <string-name><given-names>J. L.</given-names> <surname>Kubie</surname></string-name>. “<article-title>The effects of changes in the environment on the spatial firing of hippocampal complex-spike cells</article-title>”. In: <source>J Neurosci</source> <volume>7</volume>.<issue>1951-1968</issue> (<year>1987</year>). Type: Journal Article.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Bostock</surname></string-name>, <string-name><given-names>R. U.</given-names> <surname>Muller</surname></string-name>, and <string-name><given-names>J. L.</given-names> <surname>Kubie</surname></string-name>. “<article-title>Experience-dependent modifications of hippocampal place cell firing</article-title>”. In: <source>Hippocampus</source> <volume>1</volume>.<issue>2</issue> (<month>Apr</month>. <year>1991</year>), pp. <fpage>193</fpage>–<lpage>205</lpage>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name>, <string-name><given-names>H. S.</given-names> <surname>Kudrimoti</surname></string-name>, and <string-name><given-names>B. L.</given-names> <surname>McNaughton</surname></string-name>. “<article-title>Interactions between idiothetic cues and external landmarks in the control of place cells and head direction cells</article-title>”. In: <source>J Neurophysiol</source> <volume>80</volume>.<issue>1</issue> (<year>1998</year>). Type: Journal Article, pp. <fpage>425</fpage>–<lpage>46</lpage>. URL: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=9658061">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=9658061</ext-link>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Fyhn</surname></string-name> <etal>et al.</etal> “<article-title>Hippocampal remapping and grid realignment in entorhinal cortex</article-title>”. In: <source>Nature</source> <volume>446</volume>.<issue>7132</issue> (<year>2007</year>). Type: Journal Article, pp. <fpage>190</fpage>–<lpage>4</lpage>. URL: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=17322902">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Citation&amp;list_uids=17322902</ext-link>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Miao</surname></string-name> <etal>et al.</etal> “<article-title>Hippocampal remapping after partial inactivation of the medial entorhinal cortex</article-title>”. In: <source>Neuron</source> <volume>88</volume>.<issue>3</issue> (<year>2015</year>). Type: Journal Article, pp. <fpage>590</fpage>–<lpage>603</lpage>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Hardcastle</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Ganguli</surname></string-name>, and <string-name><given-names>L. M.</given-names> <surname>Giocomo</surname></string-name>. “<article-title>Cell types for our sense of location: where we are and where we are going</article-title>”. In: <source>Nature Neuroscience</source> <volume>20</volume>.<issue>11</issue> (<year>2017</year>). Type: Journal Article, pp. <fpage>1474</fpage>–<lpage>1482</lpage>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="other"><string-name><given-names>J. S.</given-names> <surname>Bant</surname></string-name> <etal>et al.</etal> “<article-title>Topography in the bursting dynamics of entorhinal neurons</article-title>”. In: <source>Cell Reports</source> (<year>2020</year>). Type: Journal Article.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><string-name><given-names>I. I. C.</given-names> <surname>Low</surname></string-name> <etal>et al.</etal> “<article-title>Dynamic and reversible remapping of network representations in an unchanging environment</article-title>”. In: <source>Neuron</source> <volume>109</volume>.<issue>18</issue> (<month>Sept</month>. <year>2021</year>), pp. <fpage>2967</fpage>–<lpage>2980</lpage>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>O’Neill</surname></string-name> <etal>et al.</etal> “<article-title>Superficial layers of the medial entorhinal cortex replay independently of the hippocampus</article-title>”. In: <source>Science</source> <volume>355</volume>.<issue>6321</issue> (<year>2017</year>). Type: Journal Article, pp. <fpage>184</fpage>–<lpage>188</lpage>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><given-names>N. R.</given-names> <surname>Kinsky</surname></string-name> <etal>et al.</etal> “<article-title>Trajectory-modulated hippocampal neurons persist throughout memory-guided navigation</article-title>”. In: <source>Nat Commun</source> <volume>11</volume>.<issue>1</issue> (<month>May</month> <year>2020</year>), p. <fpage>2443</fpage>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><given-names>D. C.</given-names> <surname>Rowland</surname></string-name> <etal>et al.</etal> “<article-title>Ten years of grid cells</article-title>”. In: <source>Annu Rev Neurosci</source> <volume>39</volume> (<year>2016</year>). Type: Journal Article, pp. <fpage>19</fpage>–<lpage>40</lpage>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="web"><string-name><given-names>Seung-Woo</given-names> <surname>Yoo</surname></string-name> and <string-name><given-names>Inah</given-names> <surname>Lee</surname></string-name>. “<article-title>Functional double dissociation within the entorhinal cortex for visual scene-dependent choice behavior</article-title>”. In: <source>eLife</source> <volume>6</volume> (<year>2017</year>). Ed. by <person-group person-group-type="editor"><string-name><given-names>Neil</given-names> <surname>Burgess</surname></string-name></person-group>, <fpage>e21543</fpage>. issn: <issn>2050-084X</issn>. DOI: <pub-id pub-id-type="doi">10.7554/eLife.21543</pub-id>. URL: <pub-id pub-id-type="doi">10.7554/eLife.21543</pub-id>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><given-names>M. G.</given-names> <surname>Campbell</surname></string-name> <etal>et al.</etal> “<article-title>Distance-tuned neurons drive specialized path integration calculations in medial entorhinal cortex</article-title>”. In: <source>Cell Rep</source> <volume>36</volume>.<issue>10</issue> (<year>2021</year>), p. <fpage>109669</fpage>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><string-name><given-names>S. J.</given-names> <surname>Gershman</surname></string-name> and <string-name><given-names>N.</given-names> <surname>Uchida</surname></string-name>. “<article-title>Believing in dopamine</article-title>”. In: <source>Nat Rev Neurosci</source> <volume>20</volume>.<issue>11</issue> (<month>Nov</month>. <year>2019</year>), pp. <fpage>703</fpage>–<lpage>714</lpage>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Sosa</surname></string-name> and <string-name><given-names>L. M.</given-names> <surname>Giocomo</surname></string-name>. “<article-title>Navigating for reward</article-title>”. In: <source>Nat Rev Neurosci</source> <volume>22</volume>.<issue>8</issue> (<year>2021</year>). Type: Journal Article, pp. <fpage>472</fpage>–<lpage>487</lpage>. ISSN: <issn>1471-0048 (Electronic) 1471-003X (Linking)</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41583-021-00479-z</pub-id>. URL: <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/34230644">https://www.ncbi.nlm.nih.gov/pubmed/34230644</ext-link>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Zheng</surname></string-name> <etal>et al.</etal> “<article-title>Hippocampal place cell sequences differ during correct and error trials in a spatial memory task</article-title>”. In: <source>Nat Commun</source> <volume>12</volume>.<issue>1</issue> (<month>June</month> <year>2021</year>), p. <fpage>3373</fpage>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><string-name><given-names>L.</given-names> <surname>Zhang</surname></string-name> <etal>et al.</etal> “<article-title>Goal discrimination in hippocampal nonplace cells when place information is ambiguous</article-title>”. In: <source>Proc Natl Acad Sci U S A</source> <volume>119</volume>.<issue>11</issue> (<month>Mar</month>. <year>2022</year>), <fpage>e2107337119</fpage>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Marozzi</surname></string-name> <etal>et al.</etal> “<article-title>Purely translational realignment in grid cell firing patterns following nonmetric context change</article-title>”. In: <source>Cereb Cortex Jun 5.pii</source>: <volume>bhv120</volume> (<year>2015</year>). Type: Journal Article, Epub ahead of print.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><string-name><given-names>H. R.</given-names> <surname>Joo</surname></string-name> <etal>et al.</etal> “<article-title>Rats use memory confidence to guide decisions</article-title>”. In: <source>Curr Biol</source> <volume>31</volume>.<issue>20</issue> (<year>2021</year>), pp. <fpage>4571</fpage>–<lpage>4583</lpage>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="web"><string-name><given-names>Marius</given-names> <surname>Pachitariu</surname></string-name> <etal>et al.</etal> “<article-title>Kilosort: realtime spike-sorting for extracellular electrophysiology with hundreds of channels</article-title>”. In: <source>bioRxiv</source> (<year>2016</year>). DOI: <pub-id pub-id-type="doi">10.1101/061481</pub-id>. URL: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/early/2016/06/30/061481">https://www.biorxiv.org/content/early/2016/06/30/061481</ext-link>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><string-name><given-names>Alessio P</given-names> <surname>Buccino</surname></string-name> <etal>et al.</etal> “<article-title>SpikeInterface, a unified framework for spike sorting</article-title>”. In: <source>eLife</source> <volume>9</volume> (<month>Nov</month>. <year>2020</year>). DOI: <pub-id pub-id-type="doi">10.7554/elife.61834</pub-id>. URL: <pub-id pub-id-type="doi">10.7554/elife.61834</pub-id>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><string-name><given-names>Peter J.</given-names> <surname>Rousseeuw</surname></string-name> and <string-name><given-names>Katrien</given-names> <surname>van Driessen</surname></string-name>. “<article-title>A Fast Algorithm for the Minimum Covariance Determinant Estimator</article-title>”. In: <source>Technometrics</source> <volume>41</volume>.<issue>3</issue> (<year>1999</year>), pp. <fpage>212</fpage>–<lpage>223</lpage>. ISSN: <issn>00401706</issn>. URL: <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/1270566">http://www.jstor.org/stable/1270566</ext-link>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.85646.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>In this study, neurons were recorded and combined across the parahippocampal area while rats performed a memory-guided spatial navigation task. Sophisticated analytical tools were used to provide <bold>convincing</bold> evidence that neuronal populations in these areas show behavior-related changes that might indicate the encoding of errors by the system. The <bold>valuable</bold> results suggest that rate remapping is a likely mechanism to support changes in representations that support memory-guided behavior in these regions, most interestingly in neurons that code head direction.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.85646.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this study, single neurons were recorded, using tetrodes, from the parahippocampal cortex of 5 rats navigating a double-Y maze (in which each arm of a Y-maze forks again). The goal was located at any one of the 4 branch terminations, and rats were given partial information in the form of a light cue that indicated whether the reward was on the right or left side of the maze. The second decision point was uncued and the rat had no way of knowing which of the two branches was correct, so this phase of the task was more akin to foraging. Following the outbound journey, with or without reward, the rat had to return (inbound journey) to the maze and start to begin again.</p>
<p>Neuronal activity was assessed for correlations with multiple navigation-relevant variables including location, head direction, speed, reward side, and goal location. The main finding is that a high proportion of neurons showed an increase in firing rate when the animal made a wrong turn at the first branch point (the one in which the correct decision was signalled). This increase, which the authors call rate remapping, persisted throughout the inbound journey as well. It was also found that head direction neurons (assessed by recording in an open field arena) in the same location in the room were more likely to show the rate change. The overall conclusion is that &quot;during goal-directed navigation, parahippocampal neurons encode error information reflective of an animal's behavioral performance&quot; or are &quot;nodes in the transmission of behaviorally relevant variables during goal-directed navigation.&quot;</p>
<p>Overall I think this is a well-conducted study investigating an important class of neural representation: namely, the substrate for spatial orientation and navigation. The analyses are very sophisticated - possibly a little too much so, as the basic findings are relatively straightforward and the analyses take quite a bit of work to understand. A difficulty with the study is that it was exploratory (observational) rather than hypothesis-driven. Thus, the findings reveal correlations in the data but do not allow us to infer causal relationships. That said, the observation of increased firing in a subset of neurons following an erroneous choice is potentially interesting. However, the effect seems small. What were the actual firing rate values in Hz, and what was the effect size?</p>
<p>I also feel we are lacking information about the underlying behavior that accompanies these firing rate effects. The authors say &quot;one possibility is that the head-direction signal in the parahippocampal region reflects a behavioral state related to the navigational choice or the lack of commitment to a particular navigational route&quot; which is a good thought and raises the possibility that on error trials, rats are more uncertain and turn their heads more (vicarious trial and error) and thus sample the preferred firing direction more thoroughly. Another possibility is that they run more slowly, which is associated with a higher firing rate in these cells. I think we, therefore, need a better understanding of how behavior differed between error trials in terms of running speed, directional sampling, etc. A few good, convincing raw-data plots showing a remapping neuron on an error trial and a correct trial on the same arm would also be helpful (the spike plots were too tiny to get a good sense of this: fewer, larger ones would be more helpful). It would be useful to know at what point the elevated response returned to baseline, how - was it when the next trial began, and was the drop gradual (suggesting perhaps a more neurohumoral response) or sudden.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.85646.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This work recorded neurons in the parahippocampal regions of the medial entorhinal cortex (MEC) and pre- and para-subiculum (PrS, PaS) during a visually guided navigation task on a 'tree maze'. They found that many of the neurons reflected in their firing the visual cue (or the associated correct behavioral choice of the animal) and also the absence of reward in inbound passes (with increased firing rate). Rate remapping explained best these firing rate changes in both conditions for those cells that exhibited place-related firing. This work used a novel task, and the increased firing rate at error trials in these regions is also novel. The limitation is that cells in these regions were analyzed together.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.85646.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The authors set out to explore how neurons in the rodent parahippocampal area code for environmental and behavioral variables in a complex goal-directed task. The task required animals to learn the association between a cue and a spatial response and to use this information to guide behavior flexibly on a trial-by-trial basis. The authors then used a series of sophisticated analytical techniques to examine how neurons in this area encode spatial location, task-relevant cues, and correct vs. incorrect responding. While these questions have been addressed in studies of hippocampal place cells, these questions have not been addressed in these upstream parahippocampal areas.</p>
<p>Strengths:</p>
<p>1. The study presents data from ensembles of simultaneously recorded neurons in the parahippocampal region. The authors use a sophisticated method for ensuring they are not recording from the same neurons in multiple sessions and yet still report impressive sample sizes.</p>
<p>2. The use of the complex behavioral task guards against stereotyped behavior as rats need to continually pay attention to the relevant cue to guide behavior. The task is also quite difficult ensuring rats do not reach a ceiling level of performance which allows the authors to examine correct and incorrect trials and how spatial representations differ between them.</p>
<p>3. The authors take the unusual approach of not pre-processing the data to group neurons into categories based on the type of spatial information that they represent. This guards against preconceived assumptions as to how certain populations of neurons encode information.</p>
<p>4. The sophisticated analytical tools used throughout the manuscript allow the authors to examine spatial representations relative to a series of models of information processing.</p>
<p>5. The most interesting finding is that neurons in this region respond to situations where rewards are not received by increasing their firing rates. This error or mismatch signal is most commonly associated with regions of the basal ganglia and so this finding will be of particular interest to the field.</p>
<p>Weaknesses:</p>
<p>1. The histological verification of electrode position is poor and while this is acknowledged by the authors it does limit the ability to interpret these data. Recent advances have enabled researchers to look at very specific classes of neurons within traditionally defined anatomical regions and examine their interactions with well-defined targets in other parts of the brain. The lack of specificity here means that the authors have had to group MEC, PaS, and PrS into a functional group; the parahippocampus. Their primary aim is then to examine these neurons as a functional group. Given that we know that neurons in these areas differ in significant ways, there is not a strong argument for doing this.</p>
<p>2. The analytical/statistical tools used are very impressive but beyond the understanding of many readers. This limits the reader's ability to understand these data in reference to the rest of the literature. There are lots of places where this applies but I will describe one specific example. As noted above the authors use a complex method to examine whether neurons are recorded on multiple consecutive occasions. This is commendable as many studies in the field do not address this issue at all and it can have a major impact as analyses of multiple samples of the same neurons are often treated as if they were independent. However, there is no illustration of the outputs of this method. It would be good to see some examples of recordings that this method classifies as clearly different across days and those which are not. Some reference to previously used methods would also help the reader understand how this new method relates to those used previously.</p>
<p>3. The effects reported are often subtle, especially at the level of the single neuron. Examples in the figures do not support the interpretations from the population-level analysis very convincingly.</p>
<p>The authors largely achieve their aims with an interesting behavioral task that rats perform well but not too well. This allows them to examine memory on a trial-by-trial basis and have sufficient numbers of error trials to examine how spatial representations support memory-guided behavior. They report ensemble recordings from the parahippocampus which allows them to make conclusions about information processing within this region. This aim is relatively weak though given that this collection of areas would not usually be grouped together and treated as a single unitary area. They largely achieve their aim of examining the mechanisms underlying how these neurons code task-relevant factors such as spatial location, cue, and presence of reward. The mismatch or error-induced rate remapping will be a particularly interesting target for future research. It is also likely that the analytical tools used in this study could be used in future studies.</p>
</body>
</sub-article>
</article>