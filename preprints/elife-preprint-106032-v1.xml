<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">106032</article-id>
<article-id pub-id-type="doi">10.7554/eLife.106032</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106032.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Neural signatures of model-based and model-free reinforcement learning across prefrontal cortex and striatum</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Miranda</surname>
<given-names>Bruno</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes">
<name>
<surname>Butler</surname>
<given-names>James L</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
<email>james.butler@psy.ox.ac.uk</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Malalasekera</surname>
<given-names>W M Nishantha</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Behrens</surname>
<given-names>Timothy EJ</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dayan</surname>
<given-names>Peter</given-names>
</name>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kennerley</surname>
<given-names>Steven W</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Institute of Neurology, Department of Clinical and Movement Neurosciences, University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01c27hj86</institution-id><institution>Instituto de Fisiologia, Faculdade de Medicina, Universidade de Lisboa</institution></institution-wrap>, <city>Lisbon</city>, <country country="PT">Portugal</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>Department of Experimental Psychology, University of Oxford</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0172mzb45</institution-id><institution>Wellcome Centre for Integrative Neuroimaging, University of Oxford, FMRIB, John Radcliffe Hospital</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Sainsbury Wellcome Centre for Neural Circuits and Behaviour College, University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/026nmvv73</institution-id><institution>Max Planck Institute for Biological Cybernetics</institution></institution-wrap>, <city>Tübingen</city>, <country country="DE">Germany</country></aff>
<aff id="a7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a1kwz48</institution-id><institution>University of Tübingen</institution></institution-wrap>, <city>Tübingen</city>, <country country="DE">Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Kahnt</surname>
<given-names>Thorsten</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Institute on Drug Abuse Intramural Research Program</institution>
</institution-wrap>
<city>Baltimore</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes><fn id="n1" fn-type="equal"><label>†</label><p>equal contribution</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-04-15">
<day>15</day>
<month>04</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP106032</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-01-18">
<day>18</day>
<month>01</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-01-12">
<day>12</day>
<month>01</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.01.11.632388"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Miranda et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Miranda et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-106032-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Animals integrate knowledge about how the state of the environment evolves to choose actions that maximise reward. Such goal-directed behaviour - or model-based (MB) reinforcement learning (RL) - can flexibly adapt choice to changes, being thus distinct from simpler habitual - or model-free (MF) RL - strategies. Previous inactivation and neuroimaging work implicates prefrontal cortex (PFC) and the caudate striatal region in MB-RL; however, details are scarce about its implementation at the single-neuron level. Here, we recorded from two PFC regions – the dorsal anterior cingulate cortex (ACC) and dorsolateral PFC (DLPFC), and two striatal regions, caudate and putamen – while two rhesus macaques performed a sequential decision-making (two-step) task in which MB-RL involves knowledge about the statistics of reward and state transitions. All four regions, but particularly the ACC, encoded the rewards received and tracked the probabilistic state transitions that occurred. However, ACC (and to a lesser extent caudate) encoded the key variables of the task - namely the interaction between reward, transition and choice – which underlies MB decision-making. ACC and caudate neurons also encoded MB-derived estimates of choice values. Moreover, caudate value estimates of the choice options flipped when a rare transition occurred, demonstrating value update based on structural knowledge of the task. The striatal regions were unique (relative to PFC) in encoding the current and previous rewards with opposing polarities, reminiscent of dopaminergic neurons, and indicative of a MF prediction error. Our findings provide a deeper understanding of selective and temporally dissociable neural mechanisms underlying goal-directed behaviour.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Animals use at least two major reinforcement learning (RL) systems for behavioural control in sequential decision-making: a goal-directed or model-based (MB) system and a habitual or model-free (MF)<sup><xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c4">4</xref></sup> system. Both approaches rely on previous experience and converge to the same behaviour given enough practice in a stable environment, but they differ as to how this information is used to infer the values of choices. MB-RL computes estimates prospectively by integrating reward information with knowledge about the state-transition function, which specifies how the state of the world evolves probabilistically given particular choices<sup><xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c6">6</xref></sup>. MF-RL, a less flexible but simpler approach, learns without any model of the environment by bootstrapping sampled experience to train cached predictions of long-run rewards via reward prediction errors (RPEs)<sup><xref ref-type="bibr" rid="c7">7</xref>,<xref ref-type="bibr" rid="c8">8</xref></sup>.</p>
<p>Neural substrates of reward-based learning and decision-making involve complex anatomical connections between the basal ganglia and the prefrontal cortex (PFC)<sup><xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c10">10</xref></sup>. Lesion studies and human neuroimaging suggest an involvement of the primate putamen in MF-RL<sup><xref ref-type="bibr" rid="c11">11</xref>–<xref ref-type="bibr" rid="c13">13</xref></sup>, whereas more anterior regions of the caudate<sup><xref ref-type="bibr" rid="c13">13</xref>–<xref ref-type="bibr" rid="c15">15</xref></sup>, PFC<sup><xref ref-type="bibr" rid="c16">16</xref>–<xref ref-type="bibr" rid="c23">23</xref></sup> and hippocampus<sup><xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c24">24</xref>,<xref ref-type="bibr" rid="c25">25</xref></sup> have been implicated in MB-RL. However, there is also much work on the online<sup><xref ref-type="bibr" rid="c26">26</xref>–<xref ref-type="bibr" rid="c28">28</xref></sup> and offline<sup><xref ref-type="bibr" rid="c29">29</xref>–<xref ref-type="bibr" rid="c32">32</xref></sup> integration of MF and MB quantities, emphasising a closer inter-play between both learning systems. At the single-neuron level, midbrain dopaminergic cells report a RPE that could drive the updating of MF-RL predictions<sup><xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c34">34</xref></sup>. Furthermore, neurons in the striatum have been found to encode cached MF-RL action-values at choice time<sup><xref ref-type="bibr" rid="c35">35</xref></sup>, but the paradigms used did not elicit differences between MF and MB computations.</p>
<p>One such task that does enable the dissociation of MB and MF computations is Daw et al. (2011)’s ‘two-step’ task<sup><xref ref-type="bibr" rid="c18">18</xref></sup>. It contains a probabilistic transition between task states to uncouple MF learners (who would assign credit to which state was rewarded regardless of the transition) from MB learners (who would appropriately assign credit based on the reward and transition that occurred). Rodents<sup><xref ref-type="bibr" rid="c19">19</xref></sup>, monkeys<sup><xref ref-type="bibr" rid="c36">36</xref></sup>, and humans<sup><xref ref-type="bibr" rid="c18">18</xref></sup> all use MB-like behaviour to solve the task. Evidence in rodents suggests dorsal anterior cingulate cortex (ACC) tracks rewards, states, and the probabilistic transition structure, and that ACC is essential in implementing a MB-strategy<sup><xref ref-type="bibr" rid="c37">37</xref></sup>. Here, we compare primate single neuron activity of 4 different subregions implicated in reward-based learning and choice (ACC, dorsolateral PFC (DLPFC), caudate, and striatum) during performance of the classic two-step task, and demonstrate signatures of MB-RL primarily in ACC, and MF-RL signatures most notably in putamen.</p>
</sec>
<sec id="s2">
<title>Methods</title>
<sec id="s2a">
<title>Subjects and neurophysiological procedures</title>
<p>Subjects C/J were two male rhesus monkeys (Macaca mulatta) that were 5-6 years of age and weighed 8–10kg at the time of neural recordings. Surgical procedures were performed using aseptic techniques and under general anaesthesia. Subjects were implanted with a titanium head positioner for restraint, then implanted with two recording chambers that were located based on 3T MRI and stereotactic measurements. The centre of each chamber along the anterior–posterior (AP) coordinate plane was as follows: left hemisphere at AP = 38(C)/37(J) mm, right hemisphere at AP = 27(C)/27.5(J) mm. The chambers were angled along the medial–lateral plane to target different regions. Craniotomies were then performed inside each chamber to allow for neuronal recordings. We used gadolinium-attenuated MRI imaging and electrophysiological mapping of gyri and sulci to confirm chamber placement and electrode trajectories within our recording grid. A custom-built MATLAB® (version R2014b, MathWorks, Massachusetts, USA) algorithm was used to project each recording location (using grid position and depth from dura penetration) onto the MRI images (<xref rid="figs1" ref-type="fig">Figures S1</xref>-<xref rid="figs2" ref-type="fig">S2</xref>).</p>
<p>Neuronal activity was measured with epoxy-coated (FHC Instruments, Bowdoin, USA) or glass-coated (AlphaOmega Engineering, Nazareth, Israel) tungsten microelectrodes inserted through a guide tube mounted in a custom-designed grid with 1 mm spacing between adjacent grid locations. Electrodes were slowly advanced through the dura each recording session using either custom-built manually controlled micro-drives that lowered electrodes in pairs or triplets, or from motorised microdrives (Flex MT and EPS, Alpha Omega Engineering, Nazareth, Israel) with individual control of electrodes. During a typical recording session, 8–28 electrodes were lowered bilaterally into multiple target regions until well-isolated neurons were found. Neuronal signals were recorded at 40 kHz (OmniPlex System, Plexon Instruments, Dallas, USA). Single-unit isolation was achieved with manual spike sorting (Offline Sorter by Plexon Instruments, Dallas, USA). Neurons were randomly sampled; no attempt was made to select neurons based on responsiveness or specific cortical layer. After each recording session, the microelectrodes were retracted and the microdrive assemblies were removed.</p>
<p>We recorded neuronal data from four target regions: ACC, DLPFC, caudate and putamen (<xref rid="figs1" ref-type="fig">Figures S1</xref>-<xref rid="figs2" ref-type="fig">S2</xref>). In subject C, we recorded simultaneously from the ACC (dorsal bank of the ACC sulcus, primarily area 9/32) and the DLPFC (dorsal bank of the principal sulcus, area 46d) in both the left and right hemispheres, and from the dorsal caudate and the dorsal putamen in the right hemisphere. In Subject J, we recorded from the ACC (dorsal bank of the ACC sulcus, primarily area 9/32), and the DLPFC (dorsal bank of the principal sulcus, area 46d) in the left hemisphere, and from the dorsal caudate and the dorsal putamen from the right hemisphere. In total we recorded single-unit activity from 661 neurons (C: 508 and J: 153) in 57 recording sessions (C: 30 and J: 27) across all four investigated regions: ACC: 240 neurons, DLPFC: 187 neurons, Caudate: 115 neurons, Putamen: 119 neurons. In some sessions, neurons were recorded from all four regions simultaneously, whereas in other sessions, only two or three regions were sampled.</p>
</sec>
<sec id="s2b">
<title>Task</title>
<p>Full task details are reported elsewhere<sup><xref ref-type="bibr" rid="c36">36</xref></sup>. We monitored eye position and pupil dilation during the task using an infra-red system (ISCAN ETL-200). In brief, subjects initiated a trial by fixating a central red cue, and once extinguished, subjects were free to view the stimuli and indicate their decision by moving a manual joystick in the direction of the chosen stimulus (<xref rid="fig1" ref-type="fig">Figure 1</xref>). Two decisions were required (first-stage, second-stage states) on each trial to obtain reward. The first-stage state was indicated by a grey background and the choice was between two options indicated by pictures. Each first-stage choice could lead to either a common (70% transition probability) or rare (30% transition probability) second-stage state, represented by different background colours (brown and violet). This state-transition structure was fixed throughout the experiment. In the second-stage state, another two-option choice between pictures was required, which could lead to three different outcome levels: high (big reward and no delay), medium (small reward and small delay) or low (no reward and big delay). To promote learning and updating of stimulus values, each second-stage stimulus had an independent reward structure: the outcome level (high, medium, low) remained the same for 5-9 trials, and then, either stayed the same level (with one-third probability) or changed randomly to one of the other two possible outcome levels. Rather than fixed reward amounts, small Gaussian drifts of reward (mean/standard deviation of 0/200ms for high reward and 0/100ms for medium reward) were also added to promote constant valuation of the reward amounts. Fifteen percent of the trials were forced (i.e., without allowing a choice as only one option was presented), which could be at either the first or second-stage. The trial type sequence was randomly generated at the start of the session and was followed even after error trials. Trials with either no choice, no eye fixation, break of eye fixation, early joystick response, or the joystick not centred before choice resulted in time-outs for the subjects, and were excluded from the data analysis (C: M = 5%; J: M = 8%). In both decision stages, the choice options were randomized to one of three possible locations, and subjects indicated their choice by moving a joystick towards the stimulus (C: left, right and down; J: left, right and up). The reward (C: diluted cranberry juice; J: diluted apple juice) was provided by a spout positioned in front of the subject’s mouth and delivered at a constant flowrate using a peristaltic pump (Ismatec IPC). We used Monkeylogic software (<ext-link ext-link-type="uri" xlink:href="http://www.monkeylogic.net/">http://www.monkeylogic.net/</ext-link>) to control the presentation of stimuli and task contingencies and acquire joystick and eye data. All visual stimuli used were the same across sessions for both subjects. All experimental procedures were approved by the UCL Local Ethical Procedures Committee and the UK Home Office (PPL Number 70/8842) and carried out in accordance with the UK Animals (Scientific Procedures) Act.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Two-stage decision task performance.</title>
<p><bold>A</bold>, Timeline of events. Eye fixation was required while a red fixation cue was shown, otherwise subjects could saccade freely and indicate their decision (arrow as an example) by moving a manual joystick in the direction of the chosen stimulus. Once the second-stage choice had been made, the nature of the outcome was revealed by a secondary reinforcer cue (here, the pause symbol represents high outcome). Once the latter cue was off the screen, there was a fixed 500 ms delay and the possibility of a further delay (for both medium and low outcomes) before juice was provided (for both high and medium outcomes). <bold>B</bold>, The state-transition structure (kept fixed throughout the experiment). Each second stage stimuli had an independent reward structure: the outcome level (defined by the magnitude of the reward and the delay to its delivery) remained the same for a minimum number of trials (a uniformly distributed pseudorandom integer between 5 and 9) and then, either stayed in the same level (with one-third probability) or changed randomly to one of the other two possible outcome levels. <bold>C</bold>, Likelihood of first-stage choice repetition, averaged across sessions, as a function of reward and transition on the previous trial. Error bars depict SEM. <bold>B-C</bold>, Logistic regression results on first-stage choice with the contributions of the reward main effect (B) and reward × transition (C) from the five previous trials. Dots represent fixed-effects coefficients for each session (red when p &lt; 0.05, grey otherwise).</p></caption>
<graphic xlink:href="632388v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2c">
<title>Neural analysis</title>
<p>All data analysis was conducted using Python 3.7.6 (Python Software Foundation).</p>
</sec>
<sec id="s2d">
<title>Raster generation</title>
<p>Each cell’s spike raster was smoothed with a gaussian kernel (σ = 50ms) and epoched relative to the time at which either an epoch started (choice 1, choice 2, feedback) or an action was taken (initial fixation, choice 1 made, choice 2 made). Rasters were then downsampled to 100Hz resolution by averaging every 10 points and standardised using the mean and standard deviation of each epoch across all trials.</p>
</sec>
<sec id="s2e">
<title>Multiple linear regression models</title>
<p>Multiple linear regression was used to index encoding of different task parameters. Three different general linear models (GLMs) were constructed. The first design matrix (GLM1) included task parameters without considering any algorithmically derived MF or MB computations (<xref rid="tbl1" ref-type="table">Table 1</xref>). The second design matrix (GLM2) included state value estimates of choice 1 and choice 2’s value derived from the best-fitting computational models which generate MB and MF Q-value estimates on each trial<sup><xref ref-type="bibr" rid="c36">36</xref></sup> (<xref rid="tbl2" ref-type="table">Table 2</xref>).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>The contents of GLM1. Far right column indicates which figure panels each regressor was used for.</title></caption>
<graphic xlink:href="632388v1_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title>The contents of GLM2. Far right column indicates which figure panels each regressor was used for.</title></caption>
<graphic xlink:href="632388v1_tbl2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>The third design matrix (GLM3) combined MB and MF Q-value estimates based on the animal’s behaviour, which was shown to better predict animal’s choices than any tested MB or MF model in isolation<sup><xref ref-type="bibr" rid="c36">36</xref></sup> (‘hybrid’ model) (<xref rid="tbl3" ref-type="table">Table 3</xref>).
<disp-formula>
<graphic xlink:href="632388v1_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p><italic>Equation 1. The Hybrid model assumes that first-stage choices are computed as a weighted sum of the state-action values from MF and MB learning systems. a, action, s, stage (choice 1/2), t, trial, w, fitted hyperparameter</italic>.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><title>The contents of GLM3. Far right column indicates which figure panels each regressor was used for.</title></caption>
<graphic xlink:href="632388v1_tbl3.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>The GLMs also included several control regressors to account for any neural drift that occurred over time. This included linear and quadratic time functions, and sin curves of various frequency (see <xref rid="tbl1" ref-type="table">Tables 1</xref>-<xref rid="tbl3" ref-type="table">3</xref>). Examination of the false positive rates using session shuffled data<sup><xref ref-type="bibr" rid="c38">38</xref>–<xref ref-type="bibr" rid="c40">40</xref></sup> demonstrated that these adequately controlled for neural drift and autocorrelations (<xref rid="figs3" ref-type="fig">Figure S3</xref>).</p>
</sec>
<sec id="s2f">
<title>Population level encoding</title>
<p>To assess the presence of coding for a particular explanatory variable in multiple linear regression we used the coefficient of partial determination (<italic>partial R</italic><sup>2</sup>, CPD):
<disp-formula>
<graphic xlink:href="632388v1_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Where SSE is the sum of squared error using either the full design matrix (SSE<sub>Full</sub>) or the design matrix with the relevant regressor omitted (SSE<sub>Red</sub>). This represents the percentage of additional variance that the full model explains compared to the reduced model. This measure was then averaged across all cells from a region and the mean and standard error used as summary statistics.</p>
<p>To determine significance of our CPD measure we computed the null distribution by shuffling the dependent variable 500 times and repeating the analysis. Several control regressors were also included to capture autocorrelation in the data (<xref rid="tbl1" ref-type="table">Table 1</xref>-3). Rare cases where NaNs were generated due to a lack of variance in certain time points from low firing rate neurons were discarded. Periods of encoding that crossed the 95<sup>th</sup> percentile of this distribution were then considered as putatively significant. A second null distribution was then computed of the lengths of periods of significance that occurred in the null distribution. Significant events in the true data had to remain above threshold for longer than the Bonferroni corrected (by 4 as there were 4 areas) 95<sup>th</sup> percentile of the null distribution of lengths to be counted as significant. This resulted in an acceptable false positive rate of approximately 5% (<xref rid="figs3" ref-type="fig">Figure S3</xref>).</p>
<p>To compare differences in CPD between regions, an independent sample’s t-test was initially used to find periods where CPD’s differed significantly. A permutation test was then conducted by shuffling neurons between the two regions and repeating the t-test over time for 500 permutations. Any observed runs of significance in the real data had to be longer than the 95<sup>th</sup> percentile of runs of significance in the null distribution.</p>
</sec>
<sec id="s2g">
<title>Single neuron encoding</title>
<p>An equivalent cluster-based permutation test was used to quantify the number of individual neurons that significantly encoded a particular parameter. The neurons firing rate in the relevant epoch was shuffled across trials and the null distribution of the CPD computed for 500 permutations. The neuron’s CPD then had to be higher for 95% of the null distribution, for longer than 95% of runs of spurious significance in the null distribution, to be considered significant. This resulted in an acceptable false positive rate of approximately 5% (<xref rid="figs3" ref-type="fig">Figure S3</xref>).</p>
<p>To test whether the proportion of significant neurons was larger than expected by chance, a binomial test against 5% was used. To test whether there were significant regional differences in the proportion of significant neurons observed, a chi-square test was used.</p>
</sec>
<sec id="s2h">
<title>Pattern of encoding</title>
<p>Similarities in the pattern of neural encoding between different parameters was quantified using Pearson’s r. Significance was determined by computing the null distribution of correlations by shuffling coefficients. Any observed runs of significance had to be longer than 95% of any spurious runs of significance that occurred in this null distribution.</p>
</sec>
<sec id="s2i">
<title>Decoding analysis</title>
<p>A support vector machine (SVM) was used to decode the first-stage choice (choice 1). First, a pseudopopulation was generated by collapsing across all neurons recorded from a region. The session with the fewest number of trials for each sample was determined, and all other sessions randomly subsampled to this length to create a dataset with an equal number of samples for each neuron and each condition. The data were then split using stratified five-fold cross validation; whereby 80% of trials were used to train an SVM (using sklearn.svm.LinearSVC from the Python Scikit-learn package), which was then tested on the remaining 20% of trials. This process was repeated for the remaining 4 folds of the data and decoder accuracies averaged over the 5 folds. As this process involved leaving out a random selection of trials each time, it was repeated 20 times and the average and standard error of these 20 permutations logged as the indicator of the decoder’s performance.</p>
<p>To determine whether the decoder was performing significantly better than chance, the above procedure was repeated 500 times while shuffling the trial labels on each iteration to ascertain the null distribution of the decoder’s performance. The observed data were then compared to this distribution to calculate the reported p-values, and significance counted as an accuracy &gt; 95% of the null distribution. To compare whether one condition was significantly better than another, a null distribution of differences was created by shuffling condition labels and calculating the difference in decoder performance between the randomly split conditions 500 times. The observed difference in accuracy between conditions was then compared to this null distribution of differences.</p>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<p>Two male rhesus macaques (Macaca mulatta) completed a variation of the classic two-step task<sup><xref ref-type="bibr" rid="c18">18</xref></sup>. After an initial eye fixation period, subjects first chose between two first-stage options (A, B, ‘choice 1’), each leading to a different second-stage state (indicated by background colour) (<xref rid="fig1" ref-type="fig">Figure 1A, B</xref>). Crucially, the transition between these two stages was probabilistic, with each option transitioning to its preferred second-stage state in 70% (‘common’) of trials; and transitioning to the alternative second-stage state in 30% (‘rare’) of trials (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). This state-transition allows the dissociation of MF-RL strategies (that estimate state values using bootstrapped sampling of experienced states) from MB-RL strategies (which use the transition structure to assign rewards prospectively to states based on the probability of that state occurring). Both second-stage states then required another choice (‘choice 2’) between two options (C and D, or E and F), leading to one of three possible rewarding outcomes (high, medium, low outcome) indicated by a secondary reinforcer cue (‘feedback’). In our version of the task, the outcome values of each second-stage state randomly and independently changed value every 5-9 trials, thus requiring subjects to continue sampling the different second-stage states to determine where the highest rewards were located across trials (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). This reward schedule resulted in an advantage of a MB-policy over an MF-policy, the former of which consistently gained more reward per trial than the latter in simulations [MB gained 1.2979 ± 0.0071 units of reward per trial (n=57 recording sessions, the 3 reward levels were counted as 0, 1, or 2 AU); MF 1.2416 ± 0.0069 reward per trial; difference between them: p&lt;0.0001, paired t-test; <xref rid="figs4" ref-type="fig">Figure S4</xref>]. Both strategies were also better than a random policy (0.9953 ± 0.007 reward per trial, vs MF/MB: p&lt;0.001).</p>
<p>In a prior comprehensive behavioural analysis<sup><xref ref-type="bibr" rid="c41">41</xref></sup>, we demonstrated that both subjects estimated the value of each choice 1 option using a combination of MF and MB-RL algorithms, but with MB dominating (<xref rid="fig1" ref-type="fig">Figure 1C-E</xref>). MF-RL does not exploit information about task structure, so it predicts no difference in the probability of repeating choice 1 dependent on common/rare transition, whereas a key signature of MB-RL is just such a difference. We found that both subjects were significantly more likely to repeat choice 1 when a high reward was obtained through a common (rather than rare) transition, with the opposite pattern evident following low rewards (<xref rid="fig1" ref-type="fig">Figure 1C</xref>), indicating a strong MB influence on behaviour. Having established the influence of MF- and MB-RL strategies on behaviour<sup><xref ref-type="bibr" rid="c36">36</xref></sup>, we next examined whether signatures of MF- and MB-RL were evident in neuronal activity in four key brain regions implicated in learning and choice: we recorded single-neuron activity from two regions in PFC – dorsal anterior cingulate cortex (ACC; n=240) and dorsolateral PFC (DLPFC; n=187), and two regions in the striatum – caudate (n=115) and putamen (n=119) (see <xref rid="figs1" ref-type="fig">Figures S1</xref>-<xref rid="figs2" ref-type="fig">S2</xref> for recording locations).</p>
<p>As parameters were correlated over trials (e.g., the same choice was made repeatedly when it led to a high reward), there was a risk that intrinsic temporal autocorrelations in firing rate across trials would confound the analysis<sup><xref ref-type="bibr" rid="c38">38</xref>–<xref ref-type="bibr" rid="c40">40</xref></sup>. We therefore incorporated several nuisance regressors to account for temporal autocorrelations in neuronal activity that may have been present (see Methods, <xref rid="tbl1" ref-type="table">Tables 1</xref>-<xref rid="tbl3" ref-type="table">3</xref>). To check this was an adequate control, we analysed neural firing rates with respect to a different session’s trial data (i.e., the dependent and independent variables for the regression were from different sessions)<sup><xref ref-type="bibr" rid="c38">38</xref>–<xref ref-type="bibr" rid="c40">40</xref></sup>. No significant encoding of any of our parameters of interest were observed at either the population or single neuron level in such null controls (<xref rid="figs3" ref-type="fig">Figure S3</xref>). Therefore, temporal autocorrelations in neuronal activity were adequately controlled, and we next turned to examining neural encoding of task parameters.</p>
<sec id="s3a">
<title>ACC encoded reward across task events; striatal regions encoded a MF RPE signal</title>
<p>We first examined the extent of reward encoding in each region by examining the response of neurons to the secondary reinforcer cue. At the population level, all regions strongly encoded the value of the secondary reinforcer cue at feedback; furthermore, this encoding persisted throughout a vast period of the following trial – being significantly stronger for ACC during this particular time period (<xref rid="fig2" ref-type="fig">Figure 2A</xref>; GLM1). The same was true at the single neuron level, with large populations of neurons within each region encoding the reward during feedback and long into the following trial (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). ACC’s encoding of reward was stronger than all other regions at both the population level (p&lt;0.05 cluster-based permutation test; <xref rid="fig2" ref-type="fig">Figure 2A</xref>) and single neuron level (p&lt;0.05, chi-square test; <xref rid="fig2" ref-type="fig">Figure 2B</xref>). Encoding of the value of the secondary reinforcer peaked earlier in striatal neurons (507.7 ± 19.16-ms) compared to prefrontal neurons (588.5 ± 13.9 ms; p=0.005 independent t-test; <xref rid="fig2" ref-type="fig">Figure 2C</xref>). Therefore, all four regions, but especially ACC, encoded the previous trial’s reward throughout the next trial.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>ACC is the strongest reward coding region</title>
<p><bold>A</bold>, Average coefficient of partial determination (CPD) across neurons in each region for the encoding of the reward received on the previous trial. Feedback is shown both for the previous trial (left) and the current trial (right). Solid horizontal lines represent periods where that area’s CPD differed significantly from all other areas CPDs (p&lt;0.05, cluster-based permutation test). Dashed horizontal line indicates the confidence interval for each region derived from the null distribution. All epochs are 0-500ms with the exception of 0-1000ms for the first feedback epoch. <bold>B</bold>, Percent of neurons within each region that significantly encoded reward in the feedback epoch and epochs of the subsequent trial (p&lt;0.05 cluster-based permutation test). Solid horizontal line represent period where that area’s CPD differed significantly from all other areas CPDs (p&lt;0.05, chi-squared test). <bold>C</bold>, The time (relative to feedback onset) at which the peak encoding of the secondary reinforcer occurred, across significant encoding neurons. ***,0.001, independent t-test. <bold>D</bold>, Average coefficients for encoding the value of the secondary reinforcer. Solid horizontal lines represent periods where the coefficients in a particular region differed from 0 (p&lt;0.05, 1-sample t-test). <bold>E</bold>, Same as in <bold>D</bold> but for the percentage of significant neurons. Dashed lines indicate the net percentage of significant neurons (positive – negative percentages). <bold>F</bold>, Average coefficients across Caudate neurons for the reward received on the current trial and the previous two trials. Inset, the average activity for each of the three conditions at the time point of peak reward encoding. **, ***, p&lt;0.01,0.001 1-sample t-test against 0. <bold>G</bold>, Same as <bold>F</bold> but for Putamen neurons. <bold>H</bold>, Same as in A, but for encoding of the prediction error at feedback.</p></caption>
<graphic xlink:href="632388v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The direction of this reward coding differed between regions from PFC and striatum. The latter encoded the predicted reward (i.e., from secondary reinforcer) positively (i.e., firing rate positively correlated with reward; p&lt;0.05 from 190- and 160-ms for caudate and putamen respectively, 1 sample t-test of coefficients against 0; <xref rid="fig2" ref-type="fig">Figure 2D</xref>, E); whereas ACC encoded reward with a negative polarity and slower response time (p&lt;0.05 at 410-ms onwards, <xref rid="fig2" ref-type="fig">Figure 2D, E</xref>). Additionally, both caudate and putamen encoded the reward from the previous trial negatively during the feedback period of the current trial (<xref rid="fig2" ref-type="fig">Figure 2F, G</xref>). Such quantitative features in both striatal areas (i.e., positive coding of current reward and negative encoding of past rewards) is typical of a dopaminergic RPE signal<sup><xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c34">34</xref></sup>. <sup><xref ref-type="bibr" rid="c3">3</xref></sup></p>
</sec>
<sec id="s3b">
<title>ACC encoded MB state-transition information</title>
<p>Tracking the state-transition structure of the task is imperative for solving the task as a MB-learner. While all four regions encoded whether the current trial’s first-stage choice transitioned to the common or rare second-stage state, this signal was significantly stronger in ACC – where state-transition information was maintained from transition until the feedback epoch (CPD &gt; 0.3%, p&lt;0.002, cluster-based permutation test; <xref rid="fig3" ref-type="fig">Figure 3A</xref>; GLM1). A similar pattern was also observed at the individual neuron level (<xref rid="fig3" ref-type="fig">Figure 3B</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>ACC encodes transition information until feedback</title>
<p><bold>A</bold>, Average coefficient of partial determination (CPD) across neurons in each region for the encoding of the transition that occurred. Solid horizontal lines represent periods where that area’s CPD differed significantly from all other areas CPDs (p&lt;0.05 cluster-based permutation test). Dashed horizontal line indicates the confidence interval for each region derived from the null distribution. All epochs are 0-1000ms. <bold>B</bold>, Percent of neurons within each region that significantly encoded transition (p&lt;0.05 cluster-based permutation test). <bold>C</bold>, <bold>D</bold>, Same as <bold>A, B</bold>, but for encoding of the interaction of previous reward and transition. <bold>E</bold>, ACC coefficients for transition and feedback were correlated (coefficients taken from 300 ms post onset of each epoch). In <bold>A</bold>, <bold>B</bold>, and <bold>D</bold>, solid horizontal line indicates periods where ACC was significantly greater than all three other regions (<bold>A</bold>: permutation test, <bold>B</bold> and <bold>D</bold>: chi-squared test, p&lt;0.05/3).</p></caption>
<graphic xlink:href="632388v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>As reward expectations would change on rare transitions if using a MB strategy, we next examined whether the encoding of previous trial reward was modulated by current trial’s transition. While all four regions exhibited some selectivity for the interaction between the previous trial’s reward and the current trial’s transition, a larger proportion of ACC neurons encoded this parameter compared to all other regions (p&lt;0.05, chi-squared test, <xref rid="fig3" ref-type="fig">Figure 3C-D</xref>). Thus, ACC reward expectancy signals were modulated by the state-transition structure of the task.</p>
<p>All regions, but particularly ACC, encoded a common transition (at the time of transition) similar to a high reward (at the time of feedback), as there was a positive correlation between the coefficients for reward and transition (the transition parameter was signed such that common and rare transitions were equivalent to high and low rewards, respectively) (ACC r=0.4963, DLPFC r=0.3273, caudate r=0.4712, putamen, r=0.5052; all p&lt;0.0001; <xref rid="fig3" ref-type="fig">Figure 3E</xref>, S5). This suggests that the brain treats being diverted away from your current objective equivalent to losing reward, which is sensible as the subject would normally expect lower rewards on rare trials if their reward-seeking behaviour was efficient. This signal also reflects awareness of the (MB-like) state-transition structure.</p>
</sec>
<sec id="s3c">
<title>ACC and Caudate encoded MB-value estimates</title>
<p>Due to this encoding of the state-transition and its interaction with other variables, we next tested whether neurons encoded MB- or MF-derived chosen values of the choice 1 options (using RL computational modelling to estimate these values in a subject- and trial-specific manner<sup><xref ref-type="bibr" rid="c36">36</xref></sup>). At the single neuron level, ACC was unique in having a large population of neurons that encoded both the MB and MF value of the choice 1 options (<xref rid="fig4" ref-type="fig">Figure 4A-B</xref>; GLM2). The encoding of MB emerged 280 ms before the cues were displayed, indicating the subjects were anticipating the upcoming choice, whereas MF-derived chosen value coding only emerged after the cues were presented (170 ms post cue presentation, p&lt;0.05 binomial test). Caudate also had a population of neurons encoding the MB-derived value of choice 1, which emerged 430-ms after choice onset (<xref rid="fig4" ref-type="fig">Figure 4A</xref>). At the population level all 4 regions encoded the MB value estimate of choice 1, with ACC and caudate encoding it more than 500-ms before the options were displayed (<xref rid="fig4" ref-type="fig">Figure 4C</xref>). All 4 regions, also encoded MF-RL estimates of choice 1’s value, again with ACC encoding emerging more than 500-ms before choice onset (<xref rid="fig4" ref-type="fig">Figure 4D</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Value estimate encoding was predominantly model-based</title>
<p><bold>A</bold>, Percentage of cells in each region that encoded the model-based (MB) derived estimates of the value of each of the choice 1 options. Solid horizontal lines indicate periods where the percentage of neurons was significant (p&lt;0.05, binomial test). <bold>B</bold>, Same as in <bold>A</bold>, but for model-free (MF) derived estimates of each option’s value. <bold>C</bold>, <bold>D</bold>, Same as in <bold>A</bold>, <bold>B</bold> but for the average CPD across neurons in a region. Dashed lines represent the 95% confidence interval determined by permutation testing. Solid lines indicate periods where the strength of encoding was significant (p&lt;0.05, cluster-based permutation test). <bold>E</bold>, Distribution of the peak CPD values (i.e., the highest CPD value observed over the epoch shown in A-D for either PicA or PicB cues) for each neuron during the epoch shown in <bold>C</bold> (MB, blue) and <bold>D</bold> (MF, orange) values. Horizontal lines indicate median and extrema. *, ***, p&lt;0.05,0.001 paired t-test. <bold>F</bold>, The percentage of neurons in each region that significantly encoded a MB-estimate of the chosen option’s value (left), a MF estimate (middle), or both (right) assessed using cluster-length permutation testing. Coloured asterisks indicate that population is significantly greater than 10% (blue and orange) or 1% (green), binomial test. Asterisks between bars indicate a difference in size between the two populations (*, ***, p&lt;0.05, 0.001, chi-square test).</p></caption>
<graphic xlink:href="632388v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To further compare this encoding, we examined the peak strength of encoding of each neuron for either of the two choice 1 options (i.e., MB and MF value estimates for PicA/PicB; <xref rid="tbl2" ref-type="table">Table 2</xref>) at any point from 500-ms before to 1000-ms after choice 1 was presented. In all regions except DLPFC, peak CPD values across neurons were higher for MB compared to MF estimates (ACC: t=19.8812, p&lt;0.0001 paired t-test; DLPFC: t=-2.1474, p=0.1319; caudate: t=14.659, p&lt;0.0001; putamen: t=6.1911, p&lt;0.0001; <xref rid="fig4" ref-type="fig">Figure 4E</xref>). ACC’s peak MB and MF encoding was significantly higher than in all other regions (p&lt;0.001 independent t-test; <xref rid="figs6" ref-type="fig">Figure S6</xref>).</p>
<p>Examining the specificity of MB versus MF coding within neurons, we found that all regions had a significant population of neurons that encoded MB-, but not MF-, derived value (30, 18.72, 23 and 24% of neurons in ACC, DLPFC, caudate and putamen respectively; all p&lt;0.0014 binomial test against 10% (as the strongest response to either of the two options was used); <xref rid="fig4" ref-type="fig">Figure 4F</xref>). All regions had a population of neurons that encoded both MB- and MF-derived option value (18, 4, 8, 5% of neurons in ACC, DLPFC, caudate and putamen respectively; all p&lt;0.012 binomial test against 1; <xref rid="fig4" ref-type="fig">Figure 4F</xref>), but ACC’s population was significantly higher than all other regions (p&lt;0.05, chi-square test, <xref rid="fig4" ref-type="fig">Figure 4F</xref>). This dominance of MB encoding in caudate but not putamen at the population level may explain similar dissociations in these two striatal regions observed in human neuroimaging studies<sup><xref ref-type="bibr" rid="c13">13</xref></sup>.</p>
</sec>
<sec id="s3d">
<title>Caudate value estimates remapped following a rare transition</title>
<p>The observed prominence of transition-related selectivity, in addition to strong encoding of MB-derived value estimates, led us to next examine how transition type altered the value estimation of the chosen first-stage option. To explore this, we used a combination of MB- and MF-value estimations (or the hybrid estimate) derived from the animal’s behaviour, which better explained their choices during the task than either of the two models in isolation<sup><xref ref-type="bibr" rid="c36">36</xref></sup> (GLM3). In common trials, caudate was unique in encoding the value of the chosen option more positively than the unchosen option’s value (p&lt;0.025 280- to 320-ms post transition revealed, paired t-test; <xref rid="fig5" ref-type="fig">Figure 5</xref>). After a rare transition, caudate was again unique in encoding the chosen and unchosen option values differently, but this time it was the unchosen option that was encoded positively and the chosen option negatively (p&lt;0.025 170- to 370-ms, paired t-test; <xref rid="fig5" ref-type="fig">Figure 5</xref>). Thus, caudate activity appeared to represent the value of the state the subject was currently in.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Direction of the encoding of chosen and unchosen choice 1 options, depending on the transition that occurred.</title>
<p><bold>A</bold>, Average coefficients across neurons in the ACC with respect to the value of chosen (blue) and unchosen (orange) options of choice 1 in common trials. Value estimates were calculated using a hybrid of MB and MF estimates derived from each monkey’s behaviour. Red horizontal line indicates portions where the coefficients in the two conditions differed significantly from one another (p&lt;0.05, paired t-test). <bold>B</bold>, Same as in <bold>A</bold>, but for trials where a rare transition occurred. <bold>C-H</bold>, Same as in A-B but for DLPFC, Caudate, and Putamen, respectively.</p></caption>
<graphic xlink:href="632388v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s3e">
<title>Reward-modulated encoding of first-stage choice</title>
<p>We next examined the encoding of the choice 1 option (i.e., the stimulus identity of what they chose). All regions encoded it to an equal extent around the time of choice (difference between regions all p&gt;0.05, cluster-based permutation test; <xref rid="fig6" ref-type="fig">Figure 6A</xref>; GLM1). Strikingly, all regions also encoded the interaction of choice 1, transition, and reward from the previous trial during the choice 1 epoch (<xref rid="fig6" ref-type="fig">Figure 6B</xref>); with ACC encoding it stronger than DLPFC and Putamen (ACC vs DLPFC p=0.006 between −180 to 190-ms, vs Putamen p=&lt;0.002 between −150 to 450-ms; cluster-based permutation test; <xref rid="fig6" ref-type="fig">Figure 6B</xref>). Importantly, none of the intermediate pairwise interactions were encoded to a similar extent (<xref rid="figs7" ref-type="fig">Figure S7</xref>). Therefore, both ACC and caudate performed a very specific MB computation of integrating the reward, transition, and choice from the previous trial into a signal which could inform which option to choose on the current trial.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Choice 1 was encoded by neurons sensitive to reward and transition</title>
<p><bold>A</bold>, Average coefficient of partial determination (CPD) across neurons in each region for the encoding of choice 1. Dashed horizontal line indicates the confidence interval for each region derived from the null distribution. <bold>B</bold>, Same as <bold>A</bold> but for encoding of the interaction of reward, transition, and choice 1, all from the previous trial. <bold>C</bold>, A support vector machine was used to decode from each neural population which cue the monkeys would choose at choice 1 on each trial. Dashed horizontal line indicates the 95<sup>th</sup> confidence interval (permutation test) and solid horizontal lines indicate periods of significant decoding (p&lt;0.05, cluster-based permutation test). Dashed vertical line indicates the time at which the subjects made their choice (0 ms). <bold>D, E</bold>, Same as in <bold>C</bold> but neurons were median split into two groups depending on the strength with which they encoded reward at feedback and transition at transition. <bold>F</bold>, Difference in decoder strength between <bold>A</bold> and <bold>B</bold>. Solid horizontal line indicates periods of significant difference assessed using permutation test.</p></caption>
<graphic xlink:href="632388v1_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Furthermore, we also found that choice 1 stimulus identity was encoded by the same neurons that encoded reward and transition. Choice 1 could be decoded from all four neural populations using a support vector machine, with it being most strongly represented in ACC and caudate (<xref rid="fig6" ref-type="fig">Figure 6C</xref>). We then performed a median split of neurons within each region depending on the strength with which they encoded reward at feedback, and transition at transition (taking the average of the two coefficients). In ACC only, the neurons that were more sensitive to reward and transition encoded choice 1 more strongly than those neurons that were less sensitive to these attributes (<xref rid="fig6" ref-type="fig">Figure 6D-F</xref>). Therefore, it was the same subpopulation of neurons within ACC that tracked the different task parameters relevant for guiding MB choice.</p>
</sec>
<sec id="s3f">
<title>Explore/Exploit strategy modulates encoding of first-stage choice</title>
<p>In this task, the outcome level (high, medium, low) of each second-stage stimulus remained the same for 5-9 trials, thus providing task periods where subjects could ‘exploit’ the same Choice 1 to maximize reward for several trials; and other periods where rewards would change and subjects should ‘explore’ different second-stage stimuli to optimize reward. We thus repeated our decoding analysis of choice 1 stimulus identity, but this time limited trials to those where they had not received a high reward for the previous two trials (‘explore’ trials), and those where the previous two rewards had been the highest level (‘exploit’ trials). Choice 1 less strongly decoded in the former condition compared to the latter (Figure 7A-C). Indeed, during exploitation ACC encoded choice 1 before the choice was even presented to the subject (Figure S8). As a control, we also attempted to decode the direction of the Choice 1 (where choice was indicated via joystick movement), which was randomised each trial and therefore orthogonal to the stimulus that was chosen. Again, all four regions encoded its direction (Figure 7D, E). However, there was no difference in the strength of the representation between explore and exploit conditions (Figure 7F). Therefore, exploit behaviour specifically upregulated relevant task parameters that were worth remembering across trials.</p>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>Despite the extensive work in both MF-RL (or habitual) and MB-RL (or goal-directed) behaviour<sup><xref ref-type="bibr" rid="c3">3</xref></sup>, few studies have shown simultaneous single-neuron signatures of both learning strategies<sup><xref ref-type="bibr" rid="c37">37</xref></sup>, let alone across a number of relevant cortical and subcortical regions, and in the primate brain. Using a decision task which formally distinguishes MF and MB values, and by adopting an analytical approach that considered both observable variables and computational measures, we showed that key RL elements underlying choice behaviour were encoded in neurons in the primate PFC and striatum at different time points. The observed widespread and simultaneous representations of MF and MB related computations are consistent with the view that these controllers operate in parallel<sup><xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c18">18</xref></sup>, but their associated signals are more richly intertwined than had originally been expected. Additionally, we found convincing evidence supporting a prominent role of ACC, and to a lesser extent, the caudate, in MB-RL.The ability of single neurons to encode reward-related parameters has been described throughout the brain<sup><xref ref-type="bibr" rid="c42">42</xref>–<xref ref-type="bibr" rid="c46">46</xref></sup>. Here we found reward coding at feedback (of MF and MB relevance) to be significantly stronger in ACC. However, at feedback a RPE (a hallmark of MF-RL) can also be computed to support learning. The midbrain dopamine neurons have been strongly implicated in encoding such RPE compared to other areas with similar (but not identical) feedback-related activity<sup><xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c34">34</xref></sup>. Signals in other brain regions, such as PFC, have been found to report differences between received and expected outcome<sup><xref ref-type="bibr" rid="c47">47</xref>–<xref ref-type="bibr" rid="c50">50</xref></sup>, but in most of these cases either the definition of RPE did not conform to the normative RL theory or the neurons did not exhibit the quantitative properties and negative aspect of the error. In our study, both caudate and putamen neurons clearly responded at feedback with the parametric features of a dopamine-like RPE<sup><xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c34">34</xref></sup>. It is important to underline that, despite being seen as a signal that drives MF-RL, both MF and MB approaches coincide at feedback and use this RPE to update their valuations<sup><xref ref-type="bibr" rid="c36">36</xref></sup>. The data presented here confirms that basal ganglia structures (both dopaminergic and striatal neurons) are unique (relative to PFC) in computing RPE-like signals.</p>
<p>The knowledge of the state-transition structure differentiates MB from MF-RL and hence we investigated neurons that significantly discriminated a common from a rare transition. Our findings are in line with the neural changes seen in the rat ACC when an animal’s belief is modified after an environmental change<sup><xref ref-type="bibr" rid="c51">51</xref></sup>; and the observation that inhibition of mouse ACC impairs the use of the transition, but not rewards<sup><xref ref-type="bibr" rid="c37">37</xref></sup>. Additionally, the selectivity of ACC neurons for detecting state-transition fits well with the neuroimaging signal observed in ACC on a saccadic planning task when an internal model required update<sup><xref ref-type="bibr" rid="c52">52</xref></sup>, endorsing its role in dynamically updating behavioural policies. As all regions adjusted their value estimates as a function of the transition type occurred, our simultaneous recordings extend previous findings by supporting that the ubiquitous use of state-transition information across fronto-striatal circuits is likely propagated from (or via) ACC to other (reward-focused) regions.</p>
<p>It is important to highlight that MB-like behaviour can arise from sophisticated MF-strategies, such as tracking state-transition probabilities and the reward function<sup><xref ref-type="bibr" rid="c37">37</xref>,<xref ref-type="bibr" rid="c53">53</xref>,<xref ref-type="bibr" rid="c54">54</xref></sup>. Further work should be undertaken to carefully evaluate whether the MB-like signals seen here are truly derived from a MB-RL mechanism, or instead reflect predictions about hidden states that can be used as inputs for learning by MF systems<sup><xref ref-type="bibr" rid="c54">54</xref></sup>.</p>
<p>It is well established that ACC neurons can multiplex task variables during decision-making tasks<sup><xref ref-type="bibr" rid="c50">50</xref>,<xref ref-type="bibr" rid="c55">55</xref>,<xref ref-type="bibr" rid="c56">56</xref></sup>. The interaction between reward and transition coding is particularly critical for MB-RL valuation and choice in the two-step task. Here we demonstrate that ACC was the primary region to simultaneously encode key variables of the task structure for MB choice, namely the interaction between reward, transition and choice. This was also borne out in the computationally derived MB estimates of the first-stage choice, where ACC activity (and to a lesser extend caudate) strongly encoded this information. Another clear distinction between ACC and the other regions when coding either reward or transition information was the timescale of responses. ACC neurons have some of the slowest intrinsic timescales (i.e. the rate of their autocorrelation decay) across the brain<sup><xref ref-type="bibr" rid="c57">57</xref>,<xref ref-type="bibr" rid="c58">58</xref></sup>, which likely underlies the persistent encoding of these task variables. Maintaining these representations over long time periods likely potentiates the ability to contextualise outcomes by state, as well as the monitoring of action-outcome relationships relevant for behavioural adjustment<sup><xref ref-type="bibr" rid="c59">59</xref>–<xref ref-type="bibr" rid="c61">61</xref></sup>. In fact, the encoding of the next trial’s chosen cue and its expected value was evident in ACC long before the choice epoch even started. Thus, our data provide novel correlates of prospective planning in single-neuron activity<sup><xref ref-type="bibr" rid="c62">62</xref></sup> and contributes to our understanding of the mechanisms underlying MB-RL.</p>
<p>Along with ACC, caudate appears to have an important role in MB behaviour. Choice 1 decoding was most strongly represented by ACC and caudate, and specifically by neurons that tracked both reward and transition information. Furthermore, the distinctive caudate signal of updating (flipping) the value estimates of the currently experienced option on rare trials implies this signal is not a general temporal-difference RPE, but instead more reflective of a state-PE<sup><xref ref-type="bibr" rid="c17">17</xref></sup>, and further supports the role of caudate in MB valuation. Our recordings were predominantly in anterior parts of caudate, which is where others have described flexible value coding<sup><xref ref-type="bibr" rid="c63">63</xref></sup>, representations of sequences<sup><xref ref-type="bibr" rid="c64">64</xref></sup>, and preference for early phases of learning<sup><xref ref-type="bibr" rid="c65">65</xref></sup> – features more often embraced by MB-RL. Anatomically, it is also the part of the caudate with the highest afferent projections from ACC – the area we observed to support MB computations<sup><xref ref-type="bibr" rid="c66">66</xref></sup>.</p>
<p>On the other hand, MF-based estimates were neither as striking nor as specific to striatal regions as expected and observed in previous studies<sup><xref ref-type="bibr" rid="c18">18</xref></sup>. The monkeys were extensively trained on the task before recordings commenced, which may have caused a shift towards both MB behaviour and MB value representation within the striatum. Alternatively, this training may have allowed more sophisticated representations to occur, such as using latent states to expand the task space<sup><xref ref-type="bibr" rid="c53">53</xref></sup>. Despite this, ACC was the only region that significantly encoded both MB and MF values. Having access to both MF and MB values at the time of choice, implicates ACC in the arbitration process between the two learning strategies<sup><xref ref-type="bibr" rid="c67">67</xref></sup> that has been considered crucial to guide optimal behaviour. It is also in line with alternative theoretical proposals for ACC that propose a specific role in monitoring the error likelihoods of all possible expected outcomes<sup><xref ref-type="bibr" rid="c68">68</xref></sup>. In fact, the use of a RL framework could indeed unify other roles attributed to ACC, in particular conflict resolution<sup><xref ref-type="bibr" rid="c69">69</xref></sup> and cognitive control<sup><xref ref-type="bibr" rid="c70">70</xref></sup>.</p>
<p>Having a discrete reward structure with a wide yet sparse reward distribution injected a naturalistic foraging element into the task, allowing us to link our findings with contemporary ACC theories of RL and behavioural adaptation<sup><xref ref-type="bibr" rid="c46">46</xref>,<xref ref-type="bibr" rid="c60">60</xref>,<xref ref-type="bibr" rid="c71">71</xref></sup>. Behaviour could be categorized into cases when subjects were heading towards a known highly rewarded state (exploiting) versus cases when they were searching for a highly rewarded state (exploring). ACC activity reflects a belief confirmation signal about whether current evidence favours exploring or exploiting the previous choice<sup><xref ref-type="bibr" rid="c72">72</xref>,<xref ref-type="bibr" rid="c73">73</xref></sup>, and predicts when a monkey will change patch during foraging<sup><xref ref-type="bibr" rid="c55">55</xref></sup>. ACC has also been found to encode both expected value and expected uncertainty in a valence specific manner<sup><xref ref-type="bibr" rid="c74">74</xref></sup>. These observations demonstrate an intimate link between uncertainty, motivational state, information seeking and current choice in ACC – well-known features of adaptive (or MB) behaviour<sup><xref ref-type="bibr" rid="c75">75</xref>,<xref ref-type="bibr" rid="c76">76</xref></sup>.</p>
</sec>
</body>
<back>
<sec id="s8" sec-type="data-availability">
<title>Data and materials availability</title>
<p>Code and data are available upon request by the corresponding author.</p>
</sec>
<sec id="s9">
<title>Supplementary Figures</title>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Figure S1.</label>
<caption><title>Locations of each neuron recorded from subject C</title></caption>
<graphic xlink:href="632388v1_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Figure S2.</label>
<caption><title>Locations of each neuron recorded from subject J</title></caption>
<graphic xlink:href="632388v1_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Figure S3.</label>
<caption><title>Temporal autocorrelations of neuronal activity did not confound analyses.</title>
<p><bold>A</bold>, To check for the effect of autocorrelations over time we repeated the CPD analysis in <xref rid="fig3" ref-type="fig">Figures 3</xref>, <xref rid="fig4" ref-type="fig">4</xref>, and 7 but using trial data from a different session to the neural data. Average coefficient of partial determination (CPD) across neurons in each region for the encoding of the reward received on the previous trial (of a different session). Feedback is shown both for the previous trial (left) and the current trial (right). Solid horizontal lines represent p&lt;0.05 assessed using permutation testing against the null distribution (indicated by dashed horizontal line). <bold>B-E</bold>, Same as in <bold>A</bold>, but for the encoding of transition, the interaction of reward and transition, choice 1, and the interaction of previous reward, previous transition and previous choice 1. <bold>F</bold>, The percentage of neurons that were found to significantly encode each parameter in its respective epoch assessed using cluster-based permutation testing (p&lt;0.05). n.s., not significant, binomial test against 0.05 Bonferroni corrected for the 4 regions tested.</p></caption>
<graphic xlink:href="632388v1_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Figure S4.</label>
<caption><title>A model-based strategy was best to solve the task.</title>
<p>The amount of reward attained by an agent that either always chose the option with the highest MB-derived estimate of value (‘MB policy’) or the highest MF-derived estimate of value (‘MF policy’). This was compared to an agent that chose randomly (‘Random policy’). The average reward per trial over all recording sessions was used (n=57). ***, p&lt;0.001, paired t-test.</p></caption>
<graphic xlink:href="632388v1_figs4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>Figure S5.</label>
<caption><title>Reward coding and transition coding is correlated</title>
<p><bold>A-D</bold>, Correlation of coefficients for transition at the transition epoch (x-axis) with reward at the feedback epoch (y-axis) for ACC, DLPFC, Caudate, and Putamen neurons, respectively. Non-significant points have been removed for clarity (white). Top right numbers indicate the extreme values of each plot (Pearson r).</p></caption>
<graphic xlink:href="632388v1_figs5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs6" position="float" orientation="portrait" fig-type="figure">
<label>Figure S6.</label>
<caption><title>Coding of the interaction of choice 1, transition and reward from the previous trial.</title>
<p><bold>A</bold>, Average coefficient of partial determination (CPD) across neurons in each region for the encoding of the interaction of reward and transition from the previous trial at the time the subjects made their first choice on the next trial. Dashed horizontal lines indicate the 95<sup>th</sup> percentile of the null distribution and solid horizontal lines indicate periods of significant coding (p&lt;0.05, cluster-based permutation test). <bold>B-D</bold>, Same as in A but for the interaction between reward and choice 1, transition and choice 1, and the triple interaction between all three variables.</p></caption>
<graphic xlink:href="632388v1_figs6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs7" position="float" orientation="portrait" fig-type="figure">
<label>Figure S7.</label>
<caption><title>ACC encoded the upcoming choice during the preceding fixation period</title>
<p><bold>A</bold>, A support vector machine was used to decode from each neural population which cue the monkeys would choose at choice 1 on each trial. Decoding was restricted to trials where they had received a high reward on the previous two trials. Dashed lines represents the 95% confidence interval (permutation test). <bold>B</bold>, Same as in <bold>A</bold> but only for trials following two consecutive low/medium reward trials.</p></caption>
<graphic xlink:href="632388v1_figs7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<ack>
<title>Acknowledgments</title>
<p>We would like to thank Thomas Akam for helpful comments on the manuscript.</p>
</ack>
<sec id="d1e1429" sec-type="additional-information">
<title>Additional information</title>
<sec id="s5">
<title>Funding</title>
<p>J.L.B. and S.W.K. were supported by Wellcome Trust Investigator Awards (096689/Z/11/Z, 220296/Z/20/Z). B.M. was supported by the Fundacão para a Ciência e Tecnologia (scholarship SFRH/BD/51711/2011) and the Premio João Lobo Antunes 2017 - Santa Casa da Misericordia de Lisboa. N.M. was supported by Astor Foundation, Rosetrees Charitable Trust. T.E.J.B. is supported by a Wellcome Principal Research Fellowship (219525/Z/19/Z), a Wellcome Trust Collaborator award (214314/Z/18/Z), and the Gatsby Initiative for Brain Development and Psychiatry (GAT3955), and by the Jean Francois and Marie-Laure de Clermont Tonerre Foundation. P.D. was supported by the Max Planck Society and the Alexander von Humboldt Foundation. S.W.K. is supported by BBSRC Strategic Longer and Larger Grant (BB/W003392/1).</p>
</sec>
<sec id="s6">
<title>Author contributions</title>
<p>Conceptualization: BM, PD, SWK. Methodology: JLB, BM, WMNM, TEJB, PD, SWK. Investigation: BM, SWK. Visualization: JLB, BM. Funding acquisition: TEJB, PD, SWK. Project administration: PD, SWK. Supervision: PD, SWK. Writing – original draft: JLB, BM. Writing – review &amp; editing: JLB, BM, PD, SWK</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dickinson</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Balleine</surname>, <given-names>B.</given-names></string-name></person-group> <source>Animal Learning &amp; Behavior</source> <volume>22</volume>, <fpage>1</fpage>–<lpage>18</lpage> (<year>1994</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Daw</surname>, <given-names>N.D.</given-names></string-name>, <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name></person-group> <source>Nature Neuroscience</source> <volume>8</volume>, <fpage>1704</fpage>–<lpage>1711</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dolan</surname>, <given-names>R.J.</given-names></string-name> &amp; <string-name><surname>Dayan</surname>, <given-names>P</given-names></string-name></person-group>. <source>Neuron</source> <volume>80</volume>, <fpage>312</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dickinson</surname>, <given-names>A</given-names></string-name></person-group>. <source>Philosophical Transactions of the Royal Society of London. B, Biological Sciences</source> <volume>308</volume>, <fpage>67</fpage>–<lpage>78</lpage> (<year>1985</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tolman</surname>, <given-names>E.C</given-names></string-name></person-group>. <source>Psychol Rev</source> <volume>55</volume>, <fpage>189</fpage>–<lpage>208</lpage> (<year>1948</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Daw</surname>, <given-names>N.D.</given-names></string-name> &amp; <string-name><surname>Dayan</surname>, <given-names>P</given-names></string-name></person-group>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source> <volume>369</volume>, (<year>2014</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Thorndike</surname>, <given-names>E.</given-names></string-name></person-group> (<publisher-name>Macmillan Company</publisher-name>: <publisher-loc>New York</publisher-loc>, <year>1911</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sutton</surname>, <given-names>R.S</given-names></string-name></person-group>. <source>Machine Learning</source> <volume>3</volume>, <fpage>9</fpage>–<lpage>44</lpage> (<year>1988</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Balleine</surname>, <given-names>B.W.</given-names></string-name> &amp; <string-name><surname>O’Doherty</surname>, <given-names>J.P</given-names></string-name></person-group>. <source>Neuropsychopharmacology</source> <volume>35</volume>, <fpage>48</fpage>–<lpage>69</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haber</surname>, <given-names>S.N.</given-names></string-name> &amp; <string-name><surname>Behrens</surname>, <given-names>T.E.J.</given-names></string-name></person-group> <source>Neuron</source> <volume>83</volume>, <fpage>1019</fpage>–<lpage>1039</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yin</surname>, <given-names>H.H.</given-names></string-name>, <string-name><surname>Knowlton</surname>, <given-names>B.J.</given-names></string-name> &amp; <string-name><surname>Balleine</surname>, <given-names>B.W</given-names></string-name></person-group>. <source>Eur J Neurosci</source> <volume>19</volume>, <fpage>181</fpage>–<lpage>189</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tricomi</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Balleine</surname>, <given-names>B.W.</given-names></string-name> &amp; <string-name><surname>O’Doherty</surname>, <given-names>J.P.</given-names></string-name></person-group> <source>Eur J Neurosci</source> <volume>29</volume>, <fpage>2225</fpage>–<lpage>2232</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wunderlich</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Dolan</surname>, <given-names>R.J</given-names></string-name></person-group>. <source>Nature Neuroscience</source> <volume>15</volume>, <fpage>786</fpage>–<lpage>791</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yin</surname>, <given-names>H.H.</given-names></string-name>, <string-name><surname>Ostlund</surname>, <given-names>S.B.</given-names></string-name>, <string-name><surname>Knowlton</surname>, <given-names>B.J.</given-names></string-name> &amp; <string-name><surname>Balleine</surname>, <given-names>B.W</given-names></string-name></person-group>. <source>Eur J Neurosci</source> <volume>22</volume>, <fpage>513</fpage>–<lpage>523</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tanaka</surname>, <given-names>S.C.</given-names></string-name>, <string-name><surname>Balleine</surname>, <given-names>B.W.</given-names></string-name> &amp; <string-name><surname>O’Doherty</surname>, <given-names>J.P.</given-names></string-name></person-group> <source>The Journal of Neuroscience</source> <volume>28</volume>, <fpage>6750</fpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Valentin</surname>, <given-names>V. V.</given-names></string-name>, <string-name><surname>Dickinson</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>O’Doherty</surname>, <given-names>J.P.</given-names></string-name></person-group> <source>J Neurosci</source> <volume>27</volume>, <fpage>4019</fpage>–<lpage>4026</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gläscher</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Daw</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>O’Doherty</surname>, <given-names>J.P</given-names></string-name></person-group>. <source>Neuron</source> <volume>66</volume>, <fpage>585</fpage>–<lpage>595</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Daw</surname>, <given-names>N.D.</given-names></string-name>, <string-name><surname>Gershman</surname>, <given-names>S.J.</given-names></string-name>, <string-name><surname>Seymour</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Dolan</surname>, <given-names>R.J.</given-names></string-name></person-group> <source>Neuron</source> <volume>69</volume>, <fpage>1204</fpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miller</surname>, <given-names>K.J.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M.M.</given-names></string-name> &amp; <string-name><surname>Brody</surname>, <given-names>C.D.</given-names></string-name></person-group> <source>Nature Neuroscience</source> <volume>20</volume>, <fpage>1269</fpage>–<lpage>1276</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schuck</surname>, <given-names>N.W.</given-names></string-name>, <string-name><surname>Cai</surname>, <given-names>M.B.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R.C.</given-names></string-name> &amp; <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name></person-group> <source>Neuron</source> <volume>91</volume>, <fpage>1402</fpage>–<lpage>1412</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chan</surname>, <given-names>S.C.Y.</given-names></string-name>, <string-name><surname>Schuck</surname>, <given-names>N.W.</given-names></string-name>, <string-name><surname>Lopatina</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Schoenbaum</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Niv</surname>, <given-names>Y</given-names></string-name></person-group>. <source>Behavioral Neuroscience</source> <volume>135</volume>, <fpage>487</fpage>–<lpage>497</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kolling</surname>, <given-names>N.</given-names></string-name> <etal>et al.</etal></person-group> <source>Nat Neurosci</source> <volume>19</volume>, <fpage>1280</fpage>–<lpage>1285</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname>, <given-names>T.E.J.</given-names></string-name> <etal>et al.</etal></person-group> <source>Neuron</source> <volume>100</volume>, <fpage>490</fpage>–<lpage>509</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Redish</surname>, <given-names>A.D</given-names></string-name></person-group>. <source>Journal of Neuroscience</source> <volume>27</volume>, <fpage>12176</fpage>–<lpage>12189</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boorman</surname>, <given-names>E.D.</given-names></string-name>, <string-name><surname>Rajendran</surname>, <given-names>V.G.</given-names></string-name>, <string-name><surname>O’Reilly</surname>, <given-names>J.X.</given-names></string-name> &amp; <string-name><surname>Behrens</surname>, <given-names>T.E.</given-names></string-name></person-group> <source>Neuron</source> <volume>89</volume>, <fpage>1343</fpage>–<lpage>1354</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Morris</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Cushman</surname>, <given-names>F</given-names></string-name></person-group>. <source>Front Psychol</source> <volume>10</volume>, (<year>2019</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moran</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Keramati</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Dolan</surname>, <given-names>R.J</given-names></string-name></person-group>. <source>PLoS Comput Biol</source> <volume>17</volume>, <fpage>e1008552</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sezener</surname>, <given-names>C.E.</given-names></string-name>, <string-name><surname>Dezfouli</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Keramati</surname>, <given-names>M</given-names></string-name></person-group>. <source>PLoS Comput Biol</source> <volume>15</volume>, <fpage>e1006827</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Antonov</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Gagne</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Eldar</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Dayan</surname>, <given-names>P</given-names></string-name></person-group>. <source>PLoS Comput Biol</source> <volume>18</volume>, (<year>2022</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eldar</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Lièvre</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Dolan</surname>, <given-names>R.J</given-names></string-name></person-group>. <source>eLife</source> <volume>9</volume>, <fpage>1</fpage>–<lpage>23</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Mattar</surname>, <given-names>M.G.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T.E.J.</given-names></string-name>, <string-name><surname>Daw</surname>, <given-names>N.D.</given-names></string-name> &amp; <string-name><surname>Dolan</surname>, <given-names>R.J</given-names></string-name></person-group>. <source>Science</source> <volume>372</volume>, (<year>2021</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mattar</surname>, <given-names>M.G.</given-names></string-name> &amp; <string-name><surname>Daw</surname>, <given-names>N.D.</given-names></string-name></person-group> <source>Nature Neuroscience</source> <volume>21</volume>, <fpage>1609</fpage>–<lpage>1617</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schultz</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Montague</surname>, <given-names>P.R</given-names></string-name></person-group>. <source>Science (1979)</source> <volume>275</volume>, <fpage>1593</fpage>–<lpage>1599</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bayer</surname>, <given-names>H.M.</given-names></string-name> &amp; <string-name><surname>Glimcher</surname>, <given-names>P.W</given-names></string-name></person-group>. <source>Neuron</source> <volume>47</volume>, <fpage>129</fpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lau</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Glimcher</surname>, <given-names>P.W</given-names></string-name></person-group>. <source>Neuron</source> <volume>58</volume>, <fpage>451</fpage>–<lpage>463</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miranda</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Nishantha Malalasekera</surname>, <given-names>W.M.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T.E.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Kennerley</surname>, <given-names>S.W</given-names></string-name></person-group>. <source>PLoS Comput Biol</source> <volume>16</volume>, <fpage>e1007944</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Akam</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> <source>Neuron</source> <volume>109</volume>, <fpage>149</fpage>–<lpage>163.e7</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shin</surname>, <given-names>E.J.</given-names></string-name> <etal>et al.</etal></person-group> <source>eLife</source> <volume>10</volume>, (<year>2021</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Elber-Dorozko</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Loewenstein</surname>, <given-names>Y</given-names></string-name></person-group>. <source>eLife</source> <volume>7</volume>, (<year>2018</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Harris</surname>, <given-names>K.D.</given-names></string-name></person-group> <source>bioRxiv</source> (<year>2020</year>).doi:<pub-id pub-id-type="doi">10.1101/2020.11.29.402719</pub-id></mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miranda</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Malalasekera</surname>, <given-names>W.M.N.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T.E.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Kennerley</surname>, <given-names>S.W</given-names></string-name></person-group>. <source>PLoS Comput Biol</source> <volume>16</volume>, <fpage>e1007944</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Apicella</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Ljungberg</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Scarnati</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Schultz</surname>, <given-names>W</given-names></string-name></person-group>. <source>Exp Brain Res</source> <volume>85</volume>, <fpage>491</fpage>–<lpage>500</lpage> (<year>1991</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Platt</surname>, <given-names>M.L.</given-names></string-name> &amp; <string-name><surname>Glimcher</surname>, <given-names>P.W</given-names></string-name></person-group>. <source>Nature</source> <volume>400</volume>, <fpage>233</fpage>–<lpage>238</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roesch</surname>, <given-names>M.R.</given-names></string-name> &amp; <string-name><surname>Olson</surname>, <given-names>C.R.</given-names></string-name></person-group> <source>J Neurophysiol</source> <volume>90</volume>, <fpage>1766</fpage>–<lpage>1789</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wallis</surname>, <given-names>J.D.</given-names></string-name> &amp; <string-name><surname>Kennerley</surname>, <given-names>S.W</given-names></string-name></person-group>. <source>Curr Opin Neurobiol</source> <volume>20</volume>, <fpage>191</fpage>–<lpage>198</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Muller</surname>, <given-names>T.H.</given-names></string-name> <etal>et al.</etal></person-group> <source>Nat Neurosci</source> <volume>27</volume>, <fpage>403</fpage>–<lpage>408</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Apicella</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Deffains</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ravel</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Legallet</surname>, <given-names>E</given-names></string-name></person-group>. <source>Eur J Neurosci</source> <volume>30</volume>, <fpage>515</fpage>–<lpage>526</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seo</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Lee</surname>, <given-names>D.</given-names></string-name></person-group> <source>Journal of Neuroscience</source> <volume>27</volume>, <fpage>8366</fpage>–<lpage>8377</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Matsumoto</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Matsumoto</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Abe</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Tanaka</surname>, <given-names>K</given-names></string-name></person-group>. <source>Nat Neurosci</source> <volume>10</volume>, <fpage>647</fpage>–<lpage>656</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kennerley</surname>, <given-names>S.W.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T.E.</given-names></string-name> &amp; <string-name><surname>Wallis</surname>, <given-names>J.D.</given-names></string-name></person-group> <source>Nat Neurosci</source> <volume>14</volume>, <fpage>1581</fpage>–<lpage>1589</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Karlsson</surname>, <given-names>M.P.</given-names></string-name>, <string-name><surname>Tervo</surname>, <given-names>D.G.R.</given-names></string-name> &amp; <string-name><surname>Karpova</surname>, <given-names>A.Y</given-names></string-name></person-group>. <source>Science (1979)</source> <volume>338</volume>, <fpage>135</fpage>–<lpage>139</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Reilly</surname>, <given-names>J.X.</given-names></string-name> <etal>et al.</etal></person-group> <source>Proceedings of the National Academy of Sciences</source> <volume>110</volume>, (<year>2013</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Akam</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Costa</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Dayan</surname>, <given-names>P</given-names></string-name></person-group>. <source>PLoS Comput Biol</source> <volume>11</volume>, <fpage>e1004648</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Blanco-Pozo</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Akam</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Walton</surname>, <given-names>M.E</given-names></string-name></person-group>. <source>Nature Neuroscience</source> <volume>27</volume>, <fpage>286</fpage>–<lpage>297</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hayden</surname>, <given-names>B.Y.</given-names></string-name>, <string-name><surname>Pearson</surname>, <given-names>J.M.</given-names></string-name> &amp; <string-name><surname>Platt</surname>, <given-names>M.L</given-names></string-name></person-group>. <source>Nat Neurosci</source> <volume>14</volume>, <fpage>933</fpage>–<lpage>939</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kennerley</surname>, <given-names>S.W.</given-names></string-name> &amp; <string-name><surname>Wallis</surname>, <given-names>J.D.</given-names></string-name></person-group> <source>J Neurophysiol</source> <volume>102</volume>, <fpage>3352</fpage>–<lpage>3364</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murray</surname>, <given-names>J.D.</given-names></string-name> <etal>et al.</etal></person-group> <source>Nat Neurosci</source> <volume>17</volume>, <fpage>1661</fpage>–<lpage>1663</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cavanagh</surname>, <given-names>S.E.</given-names></string-name>, <string-name><surname>Towers</surname>, <given-names>J.P.</given-names></string-name>, <string-name><surname>Wallis</surname>, <given-names>J.D.</given-names></string-name>, <string-name><surname>Hunt</surname>, <given-names>L.T.</given-names></string-name> &amp; <string-name><surname>Kennerley</surname>, <given-names>S.W.</given-names></string-name></person-group> <source>Nat Commun</source> <volume>9</volume>, <fpage>3498</fpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hadland</surname>, <given-names>K.A.</given-names></string-name>, <string-name><surname>Rushworth</surname>, <given-names>M.F.S.</given-names></string-name>, <string-name><surname>Gaffan</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Passingham</surname>, <given-names>R.E.</given-names></string-name></person-group> <source>J Neurophysiol</source> <volume>89</volume>, <fpage>1161</fpage>–<lpage>1164</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kennerley</surname>, <given-names>S.W.</given-names></string-name>, <string-name><surname>Walton</surname>, <given-names>M.E.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T.E.J.</given-names></string-name>, <string-name><surname>Buckley</surname>, <given-names>M.J.</given-names></string-name> &amp; <string-name><surname>Rushworth</surname>, <given-names>M.F.S</given-names></string-name></person-group>. <source>Nat Neurosci</source> <volume>9</volume>, <fpage>940</fpage>–<lpage>947</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rudebeck</surname>, <given-names>P.H.</given-names></string-name> <etal>et al.</etal></person-group> <source>J Neurosci</source> <volume>28</volume>, <fpage>13775</fpage>–<lpage>13785</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Doll</surname>, <given-names>B.B.</given-names></string-name>, <string-name><surname>Duncan</surname>, <given-names>K.D.</given-names></string-name>, <string-name><surname>Simon</surname>, <given-names>D.A.</given-names></string-name>, <string-name><surname>Shohamy</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Daw</surname>, <given-names>N.D</given-names></string-name></person-group>. <source>Nature Neuroscience</source> <volume>18</volume>, <fpage>767</fpage>–<lpage>772</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname>, <given-names>H.F.</given-names></string-name> &amp; <string-name><surname>Hikosaka</surname>, <given-names>O.</given-names></string-name></person-group> <source>Neuron</source> <volume>79</volume>, <fpage>1001</fpage>–<lpage>1010</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seo</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Averbeck</surname>, <given-names>B.B</given-names></string-name></person-group>. <source>Neuron</source> <volume>74</volume>, <fpage>947</fpage>–<lpage>960</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pasupathy</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Miller</surname>, <given-names>E.K</given-names></string-name></person-group>. <source>Nature</source> <volume>433</volume>, <fpage>873</fpage>–<lpage>876</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Griggs</surname>, <given-names>W.S.</given-names></string-name> <etal>et al.</etal></person-group> <source>Front Neuroanat</source> <volume>11</volume>, (<year>2017</year>).</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wan Lee</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Shimojo</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>O’Doherty</surname>, <given-names>J.P.</given-names></string-name></person-group> <source>Neuron</source> <volume>81</volume>, <fpage>687</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alexander</surname>, <given-names>W.H.</given-names></string-name> &amp; <string-name><surname>Brown</surname>, <given-names>J.W.</given-names></string-name></person-group> <source>Nat Neurosci</source> <volume>14</volume>, <fpage>1338</fpage>–<lpage>1344</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van Veen</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>J.D.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M.M.</given-names></string-name>, <string-name><surname>Stenger</surname>, <given-names>V.A.</given-names></string-name> &amp; <string-name><surname>Carter</surname>, <given-names>C.S.</given-names></string-name></person-group> <source>Neuroimage</source> <volume>14</volume>, <fpage>1302</fpage>– <lpage>1308</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shenhav</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M.M.</given-names></string-name> &amp; <string-name><surname>Cohen</surname>, <given-names>J.D</given-names></string-name></person-group>. <source>Neuron</source> <volume>79</volume>, <fpage>217</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heilbronner</surname>, <given-names>S.R.</given-names></string-name> &amp; <string-name><surname>Hayden</surname>, <given-names>B.Y</given-names></string-name></person-group>. <source>Annu Rev Neurosci</source> <volume>39</volume>, <fpage>149</fpage>–<lpage>170</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hunt</surname>, <given-names>L.T.</given-names></string-name> <etal>et al.</etal></person-group> <source>Nat Neurosci</source> <volume>21</volume>, <fpage>1471</fpage>–<lpage>1481</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quilodran</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Rothé</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Procyk</surname>, <given-names>E</given-names></string-name></person-group>. <source>Neuron</source> <volume>57</volume>, <fpage>314</fpage>–<lpage>325</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Monosov</surname>, <given-names>I.E</given-names></string-name></person-group>. <source>Nature Communications</source> <volume>8</volume>, <fpage>1</fpage>–<lpage>12</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rushworth</surname>, <given-names>M.F.S.</given-names></string-name> &amp; <string-name><surname>Behrens</surname>, <given-names>T.E.J</given-names></string-name></person-group>. <source>Nature Neuroscience</source> <volume>11</volume>, <fpage>389</fpage>–<lpage>397</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Soltani</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Izquierdo</surname>, <given-names>A</given-names></string-name></person-group>. <source>Nat Rev Neurosci</source> <volume>20</volume>, <fpage>635</fpage>–<lpage>644</lpage> (<year>2019</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106032.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Kahnt</surname>
<given-names>Thorsten</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Institute on Drug Abuse Intramural Research Program</institution>
</institution-wrap>
<city>Baltimore</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> study presents single-unit activity collected during model-based (MB) and model-free (MF) reinforcement learning in non-human primates. The dataset was carefully collected, and the statistical analyses, including the modeling, are rigorous. The evidence <bold>convincingly</bold> supports different roles for particular cortical and subcortical areas in representing key variables during reinforcement learning.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106032.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Using single-unit recording in 4 regions of non-human primate brains, the authors tested whether these regions encode computational variables related to model-based and model-free reinforcement learning strategies. While some of the variables seem to be encoded by all regions, there is clear evidence for stronger encoding of model-based information in the anterior cingulate cortex and caudate.</p>
<p>Strengths:</p>
<p>The analyses are thorough, the writing is clear, and the work is well-motivated by prior theory and empirical studies.</p>
<p>Weaknesses:</p>
<p>My comments here are quite minor.</p>
<p>The correlation between transition and reward coefficients is interesting, but I'm a little worried that this might be an artifact. I suspect that reward probability is higher after common transitions, due to the fact that animals are choosing actions they think will lead to higher reward. This suggests that the coefficients might be inevitably correlated by virtue of the task design and the fact that all regions are sensitive to reward. Can the authors rule out this possibility (e.g., by simulation)?</p>
<p>The explore/exploit section seems somewhat randomly tacked on. Is this really relevant? If yes, then I think it needs to be integrated more coherently.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106032.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors investigate single-neuron activity in rhesus macaques during model-based (MB) and model-free (MF) reinforcement learning (RL). Using a well-established two-step choice task, they analyze neural correlates of MB and MF learning across four brain regions: the anterior cingulate cortex (ACC), dorsolateral PFC (DLPFC), caudate, and putamen. The study provides strong evidence that these regions encode distinct RL-related signals, with ACC playing a dominant role in MB learning and caudate updating value representations after rare transitions. The authors apply rigorous statistical analyses to characterize neural encoding at both population and single-neuron levels.</p>
<p>Strengths:</p>
<p>(1) The research fills a gap in the literature, which has been limited in directly dissociating MB vs. MF learning at the single unit level and across brain areas known to be involved in reinforcement learning. This study advances our understanding of how different brain regions are involved in RL computations.</p>
<p>(2) The study used a two-step choice task Miranda et al., (2020), which was previously established for distinguishing MB and MF reinforcement learning strategies.</p>
<p>(3) The use of multiple brain regions (ACC, DLPFC, caudate, and putamen) in the study enabled comparisons across cortical and subcortical structures.</p>
<p>(4) The study used multiple GLMs, population-level encoding analyses, and decoding approaches. With each analysis, they conducted the appropriate controls for multiple comparisons and described their methods clearly.</p>
<p>(5) They implemented control regressors to account for neural drift and temporal autocorrelation.</p>
<p>(6) The authors showed evidence for three main findings:</p>
<p>
a) ACC as the strongest encoder of MB variables from the four areas, which emphasizes its role in tracking transition structures and reward-based learning. The ACC also showed sustained representation of feedback that went into the next trial.</p>
<p>
b) ACC was the only area to represent both MB and MF value representations.</p>
<p>
c) The caudate selectively updates value representations when rare transitions occur, supporting its role in MB updating.</p>
<p>(7) The findings support the idea that MB and MF reinforcement learning operate in parallel rather than strictly competing.</p>
<p>(8) The paper also discusses how MB computations could be an extension of sophisticated MF strategies.</p>
<p>Weaknesses: o</p>
<p>(1) There is limited evidence for a causal relationship between neural activity and behavior. The authors cite previous lesion studies, but causality between neural encoding in ACC, caudate, and putamen and behavioral reliance on MB or MF learning is not established.</p>
<p>(2) There is a heavy emphasis on ACC versus other areas, but it is unclear how much of this signal drives behavior relative to the caudate.</p>
<p>(3) The role of the putamen is somewhat underexplored here.</p>
<p>(4) The authors mention the monkeys were overtrained before recording, which might have led to a bias in the MB versus MF strategy.</p>
<p>(5) The GLM3 model combines MB and MF value estimates but does not clearly mention how hyperparameters were optimized to prevent overfitting. While the hybrid model explains behavior well, it does not clarify whether MB/MF weighting changes dynamically over time.</p>
<p>(6) It was unclear from the task description whether the images used changed periodically or how the transition effect (e.g., in Figure 3) could be disambiguated from a visual response to the pair of cues.</p>
</body>
</sub-article>
</article>