<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">95449</article-id>
<article-id pub-id-type="doi">10.7554/eLife.95449</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.95449.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Dynamic organization of visual cortical networks revealed by machine learning applied to massive spiking datasets</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Graber</surname>
<given-names>Colin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5864-3346</contrib-id>
<name>
<surname>Vlasov</surname>
<given-names>Yurii</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schwing</surname>
<given-names>Alexander</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>University of Illinois Urbana Champaign, Department of Electrical and Computer Engineering</institution></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Latham</surname>
<given-names>Peter</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Behrens</surname>
<given-names>Timothy E</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label> Corresponding author; email: <email>yvlasov@illinois.edu</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-04-04">
<day>04</day>
<month>04</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP95449</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-01-14">
<day>14</day>
<month>01</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-12-20">
<day>20</day>
<month>12</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.08.08.552512"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Graber et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Graber et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-95449-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Complex cognitive functions in a mammalian brain are distributed across many anatomically and functionally distinct areas and rely on highly dynamic routing of neural activity across the network. While modern electrophysiology methods enable recording of spiking activity from increasingly large neuronal populations at a cellular level, development of probabilistic methods to extract these dynamic inter-area interactions is lagging. Here, we introduce an unsupervised machine learning model that infers dynamic connectivity across the recorded neuronal population from a synchrony of their spiking activity. As opposed to traditional population decoding models that reveal dynamics of the whole population, the model produces cellular-level cell-type specific dynamic functional interactions that are otherwise omitted from analysis. The model is evaluated on ground truth synthetic data and compared to alternative methods to ensure quality and quantification of model predictions. Our strategy incorporates two sequential stages – extraction of static connectivity structure of the network followed by inference of temporal changes of the connection strength. This two-stage architecture enables detailed statistical criteria to be developed to evaluate confidence of the model predictions in comparison with traditional descriptive statistical methods. We applied the model to analyze large-scale in-vivo recordings of spiking activity across mammalian visual cortices. The model enables the discovery of cellular-level dynamic connectivity patterns in local and long-range circuits across the whole visual cortex with temporally varying strength of feedforward and feedback drives during sensory stimulation. Our approach provides a conceptual link between slow brain-wide network dynamics studied with neuroimaging and fast cellular-level dynamics enabled by modern electrophysiology that may help to uncover often overlooked dimensions of the brain code.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Significantly revised version to address many recommendations of editors and reviewers</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/NeuroTechnologies/DyNetCP">https://github.com/NeuroTechnologies/DyNetCP</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Information processing in a mammalian brain is distributed across many anatomically and functionally distinct areas<sup><xref ref-type="bibr" rid="c1">1</xref></sup>. The inter-areal functional and anatomical connectivity can be reconstructed using electron microscopy<sup><xref ref-type="bibr" rid="c2">2</xref></sup>, gene co-expression<sup><xref ref-type="bibr" rid="c3">3</xref></sup>, projection tracing methods<sup><xref ref-type="bibr" rid="c4">4</xref>,<xref ref-type="bibr" rid="c5">5</xref></sup>, and functional neuro-imaging<sup><xref ref-type="bibr" rid="c6">6</xref></sup>. Further analysis of the temporal variation of neural activity across this connectome<sup><xref ref-type="bibr" rid="c7">7</xref></sup> using functional neuroimaging<sup><xref ref-type="bibr" rid="c8">8</xref>-<xref ref-type="bibr" rid="c11">11</xref></sup> have indicated that complex cognitive functions rely on highly dynamic routing of neural activity within this anatomically constrained structural backbone<sup><xref ref-type="bibr" rid="c12">12</xref></sup>. Neuroimaging, however, captures activity averaged over large populations (over 500K neurons per voxel) at relatively slow time scales (minutes to hours) that typically shows relatively low dimensionality<sup><xref ref-type="bibr" rid="c13">13</xref></sup> hence hindering mechanistic explanation. Further insights into dynamic routing of information flows across the brain are expected with adoption of recent technological advances in multielectrode arrays<sup><xref ref-type="bibr" rid="c14">14</xref>,<xref ref-type="bibr" rid="c15">15</xref></sup> and volumetric 2-photon imaging<sup><xref ref-type="bibr" rid="c16">16</xref></sup> that enable simultaneous recording from large neuronal populations at a cellular level with single spike temporal resolution that reveals rich and high-dimensional dynamic interactions<sup><xref ref-type="bibr" rid="c17">17</xref>,<xref ref-type="bibr" rid="c18">18</xref></sup>. Descriptive statistical approaches<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c20">20</xref></sup> that summarize the pairwise millisecond-timescale synchrony of spiking within recorded neuronal population indicate a directional flow of functional connectivity<sup><xref ref-type="bibr" rid="c15">15</xref></sup> ascending along the anatomical hierarchy<sup><xref ref-type="bibr" rid="c5">5</xref></sup> and reveal distinct engaged modules across the cortical hierarchy<sup><xref ref-type="bibr" rid="c20">20</xref>-<xref ref-type="bibr" rid="c22">22</xref></sup>. However, both descriptive statistical<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c20">20</xref></sup> as well as modern probabilistic models<sup><xref ref-type="bibr" rid="c23">23</xref>-<xref ref-type="bibr" rid="c25">25</xref></sup> typically extract interactions as time-independent “static” variables<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c26">26</xref></sup> or consider temporal dynamics of the whole population<sup><xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c27">27</xref>-<xref ref-type="bibr" rid="c30">30</xref></sup>.</p>
<p>Here, to uncover the dynamic routing of information in cortical networks, we develop an unsupervised probabilistic model - Dynamic Network Connectivity Predictor (DyNetCP). Our approach is fundamentally different from most of latent variable models that infer the dynamics of the entire recorded population in a low-dimensional latent feature space<sup><xref ref-type="bibr" rid="c27">27</xref>-<xref ref-type="bibr" rid="c30">30</xref></sup>. Instead, to enable interpretation as directed time-dependent network connectivity across distinct cellular-level neuronal ensembles, DyNetCP extracts latent variables that are assigned to individual neurons.</p>
</sec>
<sec id="s2">
<title>Model</title>
<sec id="s2a">
<title>M<sc>odel architecture</sc></title>
<p>Classical machine learning approaches like variational autoencoders<sup><xref ref-type="bibr" rid="c27">27</xref>,<xref ref-type="bibr" rid="c31">31</xref></sup> successfully train dynamic models of brain activity across entire recorded neural population. However, to uncover cellular-level dynamic connectivity structure, development of such models is becoming difficult in the absence of experimental or synthetic datasets with known ground truth (GT) to justify the choice of model parameters as well as to verify the results of model inference. To address this challenge, here, learning of the directed dynamic cellular-level connectivity structure in a network of spiking neurons is divided into two stages (<xref ref-type="fig" rid="fig1">Fig.1A</xref>). First, the static component, infers the static connectivity weight matrix <bold>W</bold><sub><bold>st</bold></sub> (<xref ref-type="fig" rid="fig1">Fig.1A</xref>, left) via a generalized linear model (GLM). Next, <bold>W</bold><sub><bold>st</bold></sub> is used to influence the dynamic offset weight term <bold>W</bold><sub><bold>off</bold></sub> learned via a recurrent long-short-term-memory (LSTM) algorithm (<xref ref-type="fig" rid="fig1">Fig.1A</xref>, right). The final dynamic weight <bold>W</bold><sub><bold>dyn</bold></sub> = <bold>W</bold><sub><bold>st</bold></sub> + <bold>W</bold><sub><bold>off</bold></sub> is averaged across all trials. Dividing the problem into two stages enables independent verification of static weights and dynamic offsets against GT synthetic and experimental data as well as a direct comparison of DyNetCP performance to existing models.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Model architecture and components design</title>
<p><bold>A)</bold> Two-stage model architecture consisting of a static and a dynamic part. <bold>Inset:</bold> structure of the “drifting grating” visual stimulation trial. <bold>B)</bold> Schematics of spike trains recorded from neuron <italic>i</italic> and neuron <italic>j</italic> for three trials and corresponding output of the static part of the model <bold>W</bold><sub><bold>st</bold></sub>. <bold>C)</bold> Schematics of the dynamic part of the mode consisting of a Fourier features transformation, followed by recurrent long-short-term-memory model, multilayer perceptron, embedding, and positional encoding.</p></caption>
<graphic xlink:href="552512v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The model operates on trial-aligned binned neural spikes. We collect <italic>N</italic> neurons recorded for <italic>T</italic> time bins binned at <italic>d</italic> bin width across <italic>M</italic> trials in tensor <italic>X</italic> ∈ {0,1}<sup><italic>M</italic>×<italic>N</italic>×<italic>T</italic></sup>, where each entry <inline-formula><inline-graphic xlink:href="552512v3_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> represents the presence or absence of a spike from neuron <italic>j</italic> at time <italic>t</italic> in trial <italic>i</italic>. The spiking probability <inline-formula><inline-graphic xlink:href="552512v3_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> of neuron <italic>i</italic> at time <italic>t</italic> is modelled as follows:
<disp-formula id="eqn1">
<graphic xlink:href="552512v3_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where σ is the sigmoid function, <italic>E</italic><sub><italic>static</italic></sub> ∈ ℝ and <italic>E</italic><sub><italic>dyn</italic></sub> ∈ ℝ are static and dynamic connectivity logits depending on the trainable weight matrix <bold>W</bold><sub><bold>st</bold></sub> and the dynamic offset model <bold>W</bold><sub><bold>off</bold></sub> respectively. Given spiking data as input, the model produces two sets of output weight matrices. The first set, <bold>W</bold><sub><bold>st</bold></sub>, encodes an estimate of the static network structure and contains one weight per pair of neurons averaged across the trial time. These represent the time-averaged influence the spikes of the whole population have on spiking probability of a given neuron. The second set, <bold>W</bold><sub><bold>dyn</bold></sub>, contains a single weight for every pair of neurons for every point in time during the experimental trial. These weights, which are a function of the input spiking data of all neurons in a population, represent a time-varying offset to the static weights. Hence, they encode temporal changes in activity patterns, and are used to determine when a given connection is being active and when it is unused. Therefore, in this formulation, the model learns time-varying connectivity patterns that can be directly linked to the underlying network structure at a cellular level.</p>
</sec>
<sec id="s2b">
<title>S<sc>tatic connectivity inference</sc></title>
<p>The static component of DyNetCP (<xref ref-type="fig" rid="fig1">Fig.1A</xref>, left), i.e.,
<disp-formula id="eqn2">
<graphic xlink:href="552512v3_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
learns static connectivity weights <inline-formula><inline-graphic xlink:href="552512v3_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> that encode static network structure averaged over the time of the trial <italic>t</italic>, and <italic>b</italic><sub><italic>i</italic></sub> ∈ ℝ are biases. We adopt a multivariate autoregressive GLM model<sup><xref ref-type="bibr" rid="c24">24</xref></sup> without temporal kernel smoothing that learns <bold>W</bold><sub><bold>st</bold></sub> as a function of a time lag <italic>d</italic> (<xref ref-type="fig" rid="fig1">Fig.1B</xref>). Sharp peak at short time lags implies increased probability of spiking of neuron <italic>j</italic> when neuron <italic>i</italic> is producing a spike that can be an indication that these two neurons are synaptically connected. An apparent time lag of the low-latency peak indicates a functional delay and defines the directionality of the putative connection. The static component of DyNetCP is implemented for all neurons jointly using a 1-dimensional convolution. Each convolutional filter contains the static weights used to predict the spiking probability for a single neuron as a function of the spiking history of all other neurons. The bias term <italic>b</italic><sub><italic>i</italic></sub> in <xref ref-type="disp-formula" rid="eqn2">Eq.2</xref> is initialized to the logit function σ (i.e., inverse sigmoid) applied to the spike rate of each neuron calculated for a given time bin.</p>
</sec>
<sec id="s2c">
<title>D<sc>ynamic connectivity inference</sc></title>
<p>The dynamic component of DyNetCP (<xref ref-type="fig" rid="fig1">Fig.1A</xref>, right), i.e.,
<disp-formula id="eqn3">
<graphic xlink:href="552512v3_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
learns the dynamic connectivity weights <inline-formula><inline-graphic xlink:href="552512v3_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> which are a function of input spike trains <inline-formula><inline-graphic xlink:href="552512v3_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and all other <inline-formula><inline-graphic xlink:href="552512v3_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Each of these weights represents an offset to the time-averaged static weight at time <italic>t</italic> for a connection at time lag <italic>d</italic> (<xref ref-type="disp-formula" rid="eqn2">Eq.2</xref>). Hence, assuming the spikes of neuron <italic>i</italic> at a time lag <italic>d</italic> are influenced by spikes from all <inline-formula><inline-graphic xlink:href="552512v3_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, the total influence applied to the spiking of neuron <italic>i</italic> from neuron <italic>j</italic> at time <italic>t</italic> is <inline-formula><inline-graphic xlink:href="552512v3_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Unlike the static weights, these dynamic weights are allowed to change throughout an experimental trial as a function of the spiking history of the connected neurons.</p>
<p>The architecture of the dynamic part (<xref ref-type="fig" rid="fig1">Fig.1C</xref>) consists of several stages including generation of Fourier features, recurrent long-short-term-memory (LSTM) model, multilayer perceptron (MLP), embedding, and positional encoding. First, we shift each spike train such that each entry lies in {−1, 1} and then represent each spike train using Fourier features<sup><xref ref-type="bibr" rid="c32">32</xref></sup> that were recently introduced in the computer vision domain to facilitate the learning of high-frequency functions from low-dimensional input. Specifically, we encode every spike <inline-formula><inline-graphic xlink:href="552512v3_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula> using the following transformation:
<disp-formula id="eqn4">
<graphic xlink:href="552512v3_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Here, we use <italic>m</italic> = 64 features, where coefficients <italic>b</italic><sub>1</sub>, …, <italic>b</italic><sub><italic>m</italic></sub> are linearly spaced between –1 and 1. We evaluate the use of Fourier features within the model on synthetic data consisting of a simulated network of neurons, where one neuron induces spiking in a second neuron during the middle 250 ms of each trial (<xref ref-type="fig" rid="figS1">Fig.1 - figure supplement 1B</xref>). DyNetCP without Fourier features is unable to properly localize the period where induced spiking is occurring, while the model with Fourier features can do so correctly.</p>
<p>The spike train features for each neuron are then input into separate LSTMs to produce an embedding per neuron per time step. Each of these LSTMs uses a separate set of weights and has a hidden dimension of 64. The LSTM embeddings are passed through two MLPs, <italic>f</italic><sub>send</sub> and <italic>f</italic><sub>recv</sub>, where <italic>f</italic><sub>send</sub> produces an embedding which represents the outgoing neural signal to other neurons and <italic>f</italic><sub>recv</sub> produces an embedding which represents the incoming signal from other neurons. Each of these MLPs consists of one linear layer with output size 64 and a ReLU activation. For each pair <italic>n</italic><sub><italic>j</italic></sub> → <italic>n</italic><sub><italic>i</italic></sub> of neurons being modeled, the send embedding <italic>h</italic><sub><italic>s,j</italic></sub> (<italic>t</italic>) is concatenated with the receive embedding <italic>h</italic><sub><italic>r,i</italic></sub> (<italic>t</italic> − 1) as well as a time encoding <italic>h</italic><sub><italic>T</italic></sub>(<italic>t</italic>) which represents the trial time and is represented as
<disp-formula id="eqn5">
<graphic xlink:href="552512v3_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>D</italic><sub>τ</sub> is the size of the positional encoding which we set to 128. Note that the send embedding contains spiking information through time <italic>t</italic>, i.e., it contains information about the most recent spikes, which is necessary to properly represent synchronous connections. Importantly, the receive embedding only contains spiking information through time <italic>t</italic> − 1 such that the output spiking probability is not trivially recoverable. Finally, this concatenated embedding is passed through a 2-layer MLP with hidden size 384 and a Rectified Linear Unit (ReLU) activation, producing the dynamic weight vector <inline-formula><inline-graphic xlink:href="552512v3_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula> which contains dynamic weight offsets for each delay <italic>d</italic> ∈ {1, …, <italic>M</italic>}.</p>
</sec>
<sec id="s2d">
<title>Model Training</title>
<p>The loss used to train the model consists of two terms. The first is a negative log likelihood over the predicted spike probabilities, which encourages the weights to accurately encode the influence of spiking from other neurons on the spiking of the neuron in question. The entire loss is written as
<disp-formula id="eqn6">
<graphic xlink:href="552512v3_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>w</italic> represents all the predicted static and dynamic weights, and <italic>λ</italic> is a coefficient used to balance the magnitudes of the losses. Loss optimization during training results in predicted spike rate (PSTH) that is approaching the actual spike rate (<xref ref-type="fig" rid="figS1">Fig.1 – figure supplement 1A</xref>).</p>
<p>We introduce a squared <italic>L2</italic> penalty on all the produced static and dynamic weights as the second term to discourage the network from overpredicting activity for times when no spikes are present <inline-formula><inline-graphic xlink:href="552512v3_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and the weight multiplied by zero is unconstrained. In these cases, adding the penalty provides a training target. For all experiments we used an <italic>L2</italic> weight between 0.1 and 1 that produced the best fit to the descriptive statistics results discussed in detail below (Methods).</p>
<fig id="figS1" position="float" fig-type="figure">
<label>Fig.1 - figure supplement 1.</label>
<caption><title>Model training and implementation</title>
<p><bold>A) Loss optimization</bold>. Blue curve is actual spike rate for a representative unit taken from the VCN dataset (see below) as a function of trial time. The dotted yellow curve is a spike rate predicted by DyNetCP model during training. <bold>Inset:</bold> Loss function is designed to push the predicted spike rate to approach the actual spike rate during training. <bold>B) Model performance with and without Fourier features</bold>. Blue bars (left y-axis) represent a histogram of joint spiking probability (JPSTH anti-diagonal) for an example neuron pair with direct connection taken from the synthetic dataset (see below). Red curves (right y-axis) correspond to trial-averaged learned dynamic weights, while dotted magenta line represents static weight value. DyNetCP model without Fourier features (top plot) failed to properly localize the period where induced spiking is occurring, while use of Fourier features (bottom plot) enables to do so correctly.</p></caption>
<graphic xlink:href="552512v3_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<p>The DyNetCP model is designed to be trained in a single step to produce both static and dynamic weight matrices simultaneously for the whole dataset. However, for the purpose of this work, we are interested in verification and detailed comparative analysis of the model performance that enables clear justification for the choice of model parameters. Therefore, here, training of the model to analyze a new dataset is implemented in two separate stages. In the first stage, only the static weights <bold>W</bold><sub><bold>st</bold></sub> are trained for all the valid neurons while the dynamic weights <bold>W</bold><sub><bold>dyn</bold></sub> are all set to zero. In the second stage, the static model parameters and static weights are fixed, and we train only the dynamic component of the model.</p>
<p>This two-stage architecture enables detailed comparison of static and dynamic matrices to classical descriptive statistical methods as well as to modern probabilistic models. In the virtual absence of synthetic or experimental datasets with known GT such comparisons are becoming crucial for tuning the model parameters and for validation of the results. It is especially important for validation of the dynamic stage of the DyNetCP since it predicts <bold>W</bold><sub><bold>dyn</bold></sub> that describes temporal variation of the connection strength that is assigned to individual neurons, and, therefore, could not be directly compared to most of the population dynamics models that produce temporal trajectories in a latent feature space of the whole population<sup><xref ref-type="bibr" rid="c27">27</xref>-<xref ref-type="bibr" rid="c30">30</xref></sup>. In what follows we consider these comparisons separately.</p>
<sec id="s3a">
<title>Static DyNetCP can faithfully reproduce descriptive statistics cross-correlogram</title>
<p>The DyNetCP formulation of its static stage (<xref ref-type="disp-formula" rid="eqn2">Eq.2</xref>) is similar to classical cross-correlogram<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c19">19</xref></sup> (CCG) between a pair of neurons <italic>n</italic><sub>1</sub> and <italic>n</italic><sub>2</sub> that is defined as:
<disp-formula id="eqn7">
<graphic xlink:href="552512v3_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where τ represents the time lag between spikes from <italic>n</italic><sub>1</sub> and <italic>n</italic><sub>2</sub>, <italic>λ</italic><sub><italic>j</italic></sub> is the spike rate of neuron <italic>j</italic>, and θ(τ) is a triangular function which corrects for the varying number of overlapping bins per delay. However, instead of constructing the statistical CCG histogram for each pair individually, the model given in <xref ref-type="disp-formula" rid="eqn2">Eq.2</xref> infers coupling terms from spiking history of all <italic>N</italic> neurons jointly. Typically, to minimize the influence of a potential stimulus-locked joint variation in population spiking that often occurs due to common input from many shared presynaptic neurons, a jitter correction<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c33">33</xref>-<xref ref-type="bibr" rid="c35">35</xref></sup> is applied. To directly compare the results of static DyNetCP with jitter-corrected CCG, we train two static models (Methods) – one on original spike trains and the second on a jitter-corrected version of the data generated using a pattern jitter algorithm<sup><xref ref-type="bibr" rid="c33">33</xref></sup> with a jitter window of 25ms.</p>
<p>For this comparison we used a subset of the Allen Brain Observatory-Visual Coding Neuropixels (VCN) database<sup><xref ref-type="bibr" rid="c15">15</xref></sup> that contains spiking activity collected in-vivo from 6 different visual cortical areas in 26 mice (Methods, <xref ref-type="table" rid="tbl1">Table 1</xref>) passively viewing a “drifting grating” video (top left inset in <xref ref-type="fig" rid="fig1">Fig.1A</xref>). For a pair of local units (spatially close units from Layer 5 of the VISam area) comparison of static DyNetCP (<xref ref-type="fig" rid="fig2">Fig.2A</xref>, red curve) with jitter-corrected CCG (<xref ref-type="fig" rid="fig2">Fig.2A</xref>, black curve) shows close correspondence (Pearson correlation coefficient r<sub>p</sub>=0.99 and p-value P<sub>p</sub>&lt;0.0001). Residual analysis (<xref ref-type="fig" rid="fig2">Fig.2A</xref>, bottom panel) shows a mean value of 0.01±0.02 SEM (<xref ref-type="fig" rid="fig2">Fig.2A</xref>, top right panel) that is smaller than the CCG values on the flanks (bottom right panel) (mean:0.11±0.06 SEM). For such a local connection the peak is narrow (∼2ms) with a functional delay of -2.3ms. For a pair of spatially distant units (units in VISam and VISp areas) a comparison of static DyNetCP (<xref ref-type="fig" rid="fig2">Fig.2B</xref>, red curve) with jitter-corrected CCG (<xref ref-type="fig" rid="fig2">Fig.2B</xref>, black curve) also shows close correspondence (r<sub>p</sub>=0.99 and P<sub>p</sub>&lt;0.0001). For such a distant connection the peak is wider (∼9ms) with a functional delay of -5.8ms. Further examples of comparisons of both models for all the units in the session showed similar results (see accompanying Jupyter Notebook).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table. 1.</label>
<caption><title>Experimental dataset recorded in-vivo in 6 visual cortices.</title>
<p>Sessions used for model training and analysis taken from the publicly available Allen Brain Observatory-Visual Coding Neuropixels (VCN) database. We use a “functional connectivity” subset of these recordings corresponding to the “drifting grating 75 repeats” setting recorded for 26 animals. Filtering of recorded units (see statistical analysis criteria below) and classification of valid pairs results in a significant reduction of units (5.6% of raw units or 23% of clean units) used for dynamic connectivity inference. The last two columns represent the number and percentage of trials when the animal was running with average speed over 5cm/sec</p></caption>
<graphic xlink:href="552512v3_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Comparison of inferred static connectivity to alternative methods.</title>
<p><bold>A)</bold> Comparison of static DyNetCP (red curve) with jitter-corrected CCG (black curve) for a representative pair of local units (session 771160300, spatially close units from Layer 5 of the VISam area). Residuals (bottom panel) and residual analysis (right panels). <bold>B)</bold> Comparison of static DyNetCP (red curve) with jitter-corrected CCG (black curve) for a representative pair of spatially distant units (session 771160300, units from VISam and VISp areas). <bold>C)</bold> Comparison of jitter-corrected CCG (black), GLMCC (magenta), and DyNetCP (red) weights for a pair of excitatory HH neurons from a synthetic dataset. <bold>D)</bold> MCC calculated for GLMCC (black) and for DyNetCP with <italic>α</italic><sub><italic>w</italic></sub> =5SD (red) and 7SD (blue). <bold>E)</bold> Static connectivity <bold>W</bold><sub><bold>st</bold></sub> for a subset of excitatory HH neurons with GT (crossed circles) compared to connections recovered by GLMCC (red triangles) and DyNetCP (blue triangles).</p></caption>
<graphic xlink:href="552512v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Following the common formulation, a putative excitatory (or inhibitory) synaptic connection can be considered statistically significant for both methods when the magnitude of the short-latency peak (or trough) exceeds the peak height threshold α<sub>w</sub> (lower than -α<sub>w</sub>) compared to the standard deviation (SD) of the noise in the flanks far from the peak<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c26">26</xref></sup> (whisker plots on top right panels in <xref ref-type="fig" rid="fig2">Fig.2A,B</xref>).</p>
</sec>
<sec id="s3b">
<title>Static DyNetCP reproduces GT connections on par with alternative probabilistic method</title>
<p>We compare the performance of DyNetCP to a recent GLM-based cross correlation method (GLMCC)<sup><xref ref-type="bibr" rid="c26">26</xref></sup> that detects connectivity by fitting a parameterized synaptic potential filter (<xref ref-type="fig" rid="fig2">Fig.2C</xref>, magenta). For these experiments, we use the synthetic dataset<sup><xref ref-type="bibr" rid="c26">26</xref></sup> consisting of 1000 Hodgkin-Huxley (HH) neurons with known GT synaptic connections (Methods). We focus specifically on recovering ground-truth (GT) excitatory connections. The <bold>W</bold><sub><bold>st</bold></sub> inferred by DyNetCP for a representative pair of neurons (<xref ref-type="fig" rid="fig2">Fig.2C</xref>, red) reproduces well the short-latency narrow peak and the flanks of the postsynaptic potential (PSP) filter learned by GLMCC (<xref ref-type="fig" rid="fig2">Fig.2C</xref>, magenta). Comparing to CCG histogram (<xref ref-type="fig" rid="fig2">Fig.2C</xref>, black), the DyNEtCP is performing much better than GLMCC (r<sub>p</sub>=0.67 and P<sub>p</sub>&lt;0.001), however the results are not as directly interpretable as GLMCC that outputs synaptic weight from the PSP fitting. Both models, however, can infer presence or absence of the connection by examining the height of the low latency peak.</p>
<p>To facilitate a performance comparison, we use the Matthews Correlation Coefficient (MCC), defined as
<disp-formula id="eqn8">
<graphic xlink:href="552512v3_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>TP, TN, FP</italic>, and <italic>FN</italic> are true positive, true negative, false positive, and false negative pair predictions, respectively. MCC optimization balances between maximizing the number of <italic>TP</italic> pairs recovered while minimizing the number of <italic>FP</italic> pairs which are predicted.</p>
<p>Performance of all three methods, classical CCG and probabilistic GLMCC and DyNetCP, will be strongly affected by the total number of spikes available for inference. To ensure the statistical significance of connections inferred by all 3 methods a large enough number of spikes should be present in each time bin (Methods) that is tracked by two threshold parameters: a unit average spike rate α<sub><italic>s</italic></sub>, and a pair spike parameter <italic>α</italic><sub><italic>p</italic></sub> that is the number of spikes that both units generate in a time window of interest (Methods). <xref ref-type="fig" rid="fig2">Fig.2D</xref> compares the performance of DyNetCP and GLMCC on a synthetic dataset, while the number of spikes present for learning is varied via a threshold pair spike parameter <italic>α</italic><sub><italic>p</italic></sub>. Increasing <italic>α</italic><sub><italic>p</italic></sub> ensures statistically significant inference about the presence or absence of a connection<sup><xref ref-type="bibr" rid="c26">26</xref></sup> (Methods). As α<sub><italic>p</italic></sub> increases, the MCC for both models shows a maximum around α<sub><italic>p</italic></sub>=80 corresponding to the optimal balance. For a conservative value of <italic>α</italic><sub><italic>w</italic></sub>=7SD (blue), the MCC for the DyNetCP model is 63%, approaching the performance of GLMCC (68%, black). When <italic>α</italic><sub><italic>w</italic></sub> is relaxed to 5SD (red), DyNetCP recovers a larger number of TP with a reasonable increase of FP connections (<xref ref-type="fig" rid="figS2">Fig.2 - figure supplement 1</xref>), increasing MCC up to 74%, thus outperforming GLMCC. Overall, as long as DyNetCP has access to a sufficient number of spikes for inference, it can restore GT static connectivity on par with or even better than GLMCC (<xref ref-type="fig" rid="fig2">Fig.2E</xref>).</p>
<p>Though GLMCC performs well in recovering static network structure and it produces directly biologically interpretable results, we emphasize that GLMCC is not compatible with modeling the network dynamics and thus cannot be integrated into DyNetCP. Specifically, our goal is to model the correlations of spiking of a network of neurons and track the changes of these correlations across time. GLMCC learns correlations as a function of the time lag relative to the spiking time of a reference neuron. It is hence unable to link correlations to specific moments in a trial time. Therefore, it cannot represent the dynamics of correlations, preventing its use in analysis of network activity relative to subject behavior. In contrast, the formulation of static DyNetCP model of <xref ref-type="disp-formula" rid="eqn2">Eq.2</xref> provides a weight matrix <bold>W</bold><sub><bold>st</bold></sub> which is compatible with the subsequent inference of time-dependent dynamic weights <bold>W</bold><sub><bold>dyn</bold></sub>.</p>
<fig id="figS2" position="float" fig-type="figure">
<label>Fig.2 - figure supplement 1.</label>
<caption><title>TP and FP rates as a function of pair spike threshold</title>
<p><bold>A) Recovery of True Positive (TP) connections in HH synthetic dataset</bold>. TP connections recovered by DyNetCP model at different pair spike thresholds <italic>α</italic><sub><italic>p</italic></sub>. Yellow, green, and red curves correspond to peak threshold taken as 3SD, 5SD, and 7SD, respectively. TP connections recovered by GLMCC model are shown by blue curve. Since a predicted connection is counted as a <italic>TP</italic> only once (i.e., <italic>i</italic> → <italic>j</italic> and j→ <italic>i</italic> do not count as two negatives if <italic>i</italic> is not connected to <italic>j</italic>) and the number of <italic>GT</italic> connections decreases when α<sub><italic>p</italic></sub> increases, the MCC exhibits an increase beyond <italic>α</italic><sub><italic>p</italic></sub>=100. <bold>B) Generation of False Positive (TP) connections in HH synthetic dataset</bold>. FP connections generated by the DyNetCP model at different pair spike rates. Yellow, green, and red curves correspond to peak threshold <italic>α</italic><sub><italic>p</italic></sub> taken as 3SD, 5SD, and 7SD, respectively. FP connections recovered by GLMCC model are shown by blue curve.</p></caption>
<graphic xlink:href="552512v3_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3c">
<title>Static connectivity inferred by the DyNetCP from in-vivo recordings is biologically interpretable</title>
<p>Recent reconstruction of the brain-wide connectome of the adult mouse brain using viral tracing of axonal projections<sup><xref ref-type="bibr" rid="c4">4</xref>,<xref ref-type="bibr" rid="c5">5</xref></sup> enables assignment of anatomical hierarchical score values to cortico-cortical projections across visual cortices<sup><xref ref-type="bibr" rid="c4">4</xref></sup> (<xref ref-type="fig" rid="fig3">Fig.3A</xref>). Analysis of functional delays of the CCG peaks extracted from massive recording of spiking activity across visual cortices<sup><xref ref-type="bibr" rid="c15">15</xref></sup> revealed strong correlation of area-averaged functional delays and the hierarchical score values indicative of the hierarchical processing of visual information. Classical CCG (as well as GLMCC), however, recovers static network structure by modeling pairwise correlations and hence must be run separately for each pair in the dataset without considering the relative influence of other pairs in the network. In contrast, DyNetCP learns connections of an entire network jointly in one pass. It is, therefore, instructional to compare the hierarchical interactions between visual cortices inferred by DyNetCP to CCG results using the same large-scale in-vivo VCN dataset<sup><xref ref-type="bibr" rid="c15">15</xref></sup>. Following the previous methodology<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c20">20</xref></sup>, functional delays corresponding to the time lags of jitter-corrected CCG peaks are determined for all recorded pairs across all six cortical areas with peak amplitudes above α<sub>w</sub> of 7SD (5023 pairs, n=26 animals). The median time lags averaged across pairs within a given visual area (<xref ref-type="fig" rid="fig3">Fig.3B</xref>) are identified as the area’s functional delay. When plotted against the hierarchical score difference (<xref ref-type="fig" rid="fig3">Fig.3C</xref>, red triangles), the area median functional delays exhibit strong correlation (r<sub>p</sub>=0.76 and P<sub>p</sub>&lt;0.0001).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Static connectivity inferred by the model is biologically interpretable.</title>
<p><bold>A)</bold> Feedforward and feedback connections between 6 cortical areas ordered with respect to their anatomical hierarchy scores (after Ref.4). <bold>B)</bold> Histograms of the functional delays extracted from the jitter-corrected CCG for all pairs across all 26 sessions for each visual area combination. Dashed red line indicates the median of the distribution. <bold>C)</bold> Comparison of median functional delays vs anatomical hierarchy score difference extracted by DyNetCP (blue triangles) and by jitter-corrected CCG (red triangles) (VCN dataset, n=26 animals). <bold>D)</bold> Histograms of the functional delays inferred by static DyNetCP across all 26 sessions of VCN dataset for each visual area combination. Dashed red line indicates the median of the distribution.</p></caption>
<graphic xlink:href="552512v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The DyNetCP trained on the same 5023 pairs with <bold>W</bold><sub><bold>st</bold></sub> peak amplitudes above α<sub>w</sub> of 7SD, whose shape is statistically indistinguishable (typical r<sub>p</sub>&gt;0.9 and P<sub>p</sub>&lt;0.0001) from the corresponding jitter-corrected CCG, produce similar functional delays (<xref ref-type="fig" rid="fig3">Fig.3D</xref>). The median functional delays predicted by DyNetCP by learning from all units (<xref ref-type="fig" rid="fig3">Fig.3C</xref>, blue triangles) also show strong correlation (r<sub>p</sub>=0.73, P<sub>p</sub>&lt;0.0001) with the visual area anatomical hierarchical score difference<sup><xref ref-type="bibr" rid="c5">5</xref></sup>, very closely replicating (r<sub>p</sub>=0.99, P<sub>p</sub>&lt;0.0001) the correlation observed with the descriptive pairwise CCG-based analysis. Therefore, the static DyNetCP is able to confirm previous observation of hierarchical organization of inter-area functional delays<sup><xref ref-type="bibr" rid="c15">15</xref></sup>.</p>
</sec>
<sec id="s3d">
<title>Comparison of inferred dynamic connectivity to descriptive statistical methods</title>
<p>Once the static connectivity <bold>W</bold><sub><bold>st</bold></sub> is established and verified, the dynamic stage of DyNetCP learns <bold>W</bold><sub><bold>dyn</bold></sub> that is strongly temporally modulated (SM, Movie 1). While no GT data are currently available to verify the model performance, model predictions can be compared to a classical pairwise Joint Peristimulus Time Histogram<sup><xref ref-type="bibr" rid="c36">36</xref></sup> (JPSTH) that represents the joint correlations of spiking between two neurons and their variation across time. Specifically, given trial-aligned data with a trial length of <italic>T</italic> bins, the JPSTH is a <italic>T</italic> × <italic>T</italic> matrix where each entry (<italic>a, b</italic>) represents the percent of trials where neuron <italic>i</italic> spiked at time <italic>a</italic> and neuron <italic>j</italic> spiked at time <italic>b</italic>. For an example pair of excitatory spatially close units located in Layer 5 of the VISp area (session 766640955) corresponding JPSTH is shown in <xref ref-type="fig" rid="fig4">Fig.4A</xref>. Averaging over the columns of the JPSTH recovers the peristimulus time histogram (PSTH) of neuron <italic>i</italic> (left panel in <xref ref-type="fig" rid="fig3">Fig.3A</xref>), while averaging over the rows of the JPSTH recovers the PSTH for neuron <italic>j</italic> (bottom panel in <xref ref-type="fig" rid="fig3">Fig.3A</xref>). Since DyNetCP learns the conditional probability of the spiking of one neuron conditioned on others, we cannot directly compare dynamic weights to a standard JPSTH, which models joint correlations. Instead, for a proper comparison, we use a conditional joint peristimulus time histogram (cJPSTH), where we divide the columns of the JPSTH by the PSTH of neuron <italic>i</italic> (<xref ref-type="fig" rid="fig4">Fig.4B</xref>). This changes the meaning of each entry (<italic>a, b</italic>) in the cJPSTH that represents the conditional probability that neuron <italic>j</italic> spikes at time <italic>b</italic>, conditioned on neuron <italic>i</italic> having spiked at time <italic>a</italic> (<xref ref-type="fig" rid="fig4">Fig.4C</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Comparison of inferred dynamic connectivity to descriptive statistical methods.</title>
<p><bold>A)</bold> An example of JPSTH for a local pair of excitatory units (session 766640955 of the VCN dataset, spatially close units from Layer 5 of the VISp area). Panels on the left and at the bottom show corresponding spike rates for receive and send units, correspondingly. White dotted square corresponds to the area of interest. See also (SM, Movie 1) <bold>B)</bold> Construction of the conditional cJPSTH. Pixels from the white dotted square in A) are normalized by spiking rate of the send neuron. Row of pixels marked by red rectangle is used in C). <bold>C)</bold> cJPSTH corresponding to the white dotted square in A). Red rectangle corresponds to red rectangle pixels in B). <bold>D)</bold> Dynamic weight <bold>W</bold><sub><bold>dyn</bold></sub> for the same pair of excitatory units inferred for <italic>L2</italic> of 1 (see also SM, Movie 1). <bold>E)</bold> cJPSTH for the same pair of units.</p></caption>
<graphic xlink:href="552512v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The dynamic weights <bold>W</bold><sub><bold>dyn</bold></sub> matrix inferred by DyNetCP for the same example pair (<xref ref-type="fig" rid="fig4">Fig.4D</xref>, see also (SM, Movie 1) reveal strong temporal modulation peaking at around 70ms, 220ms, 300ms, and 480ms indicating increased connection strength. Comparison with the cJPSTH matrix (<xref ref-type="fig" rid="fig4">Fig.4E</xref>) shows similar temporal variation. This comparison can be used to validate the choice of an optimal squared <italic>L2</italic> penalty that is introduced into the model loss function (<xref ref-type="disp-formula" rid="eqn6">Eq.6</xref>) to compensate the sparseness and irregularity of spiking often observed in cortical recordings (Methods). For a given set of thresholds α<sub><italic>w</italic></sub>, α<sub><italic>s</italic></sub>, and α<sub><italic>p</italic></sub>, scanning of <italic>L2</italic> from 0.01 to 10 (<xref ref-type="fig" rid="figS4">Fig.4 – figure supplement 1A</xref>) demonstrates statistically significant correlation (r<sub>p</sub>&gt;0.77 and P<sub>p</sub>&lt;0.001) of the dynamic weights <bold>W</bold><sub><bold>dyn</bold></sub> matrices and cJPSTH matrices observed for all <italic>L2</italic> values with the best results obtained for <italic>L2</italic> between 0.1 and 1 (<xref ref-type="fig" rid="figS4">Fig.4 – figure supplement 1B</xref>). The two-sided paired equivalence test (TOST) (Fig.3 – figure supplement 1C) confirms that the average difference between normalized weights inferred from both models is smaller than 0.09. Therefore, the DyNetCP reliably recovers the time-dependent dynamic weights <bold>W</bold><sub><bold>dyn</bold></sub> even in the presence of strong nonstationary spiking irregularities and sparce spiking.</p>
<fig id="figS4" position="float" fig-type="figure">
<label>Fig.4 – figure supplement 1.</label>
<caption><title>Tuning loss parameter.</title>
<p><bold>A)</bold> Set of dynamic weights <bold>W</bold><sub><bold>dyn</bold></sub> for a local pair of excitatory VISp neurons (session 771160300, same as in <xref rid="fig4" ref-type="fig">Fig.4D,E</xref>) learnt with different <italic>L2</italic> values. The corresponding cJPSTH is shown on the bottom. Left column shows a set of corresponding static weights <bold>W</bold><sub><bold>st</bold></sub>. <bold>B)</bold> A histogram of Pearson correlation coefficients between the dynamic weights and cJPSTH for each pair (comparing each pixel of the weight/cJPSTH matrix) calculated for all 41 pairs found to be significant for this session. <bold>C)</bold> The two-sided paired equivalence tests (TOST) for all 41 pairs in this session indicate that the average difference between normalized weights inferred from both models is smaller than 0.09.</p></caption>
<graphic xlink:href="552512v3_figS4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3e">
<title>Model enables discovery of cellular-level dynamic connectivity patterns in visual cortex</title>
<p>The model architecture (<xref ref-type="fig" rid="fig1">Fig.1A</xref>) designed with two interacting static and dynamic parts enables justification of the choice of model parameters and verification of model inference results by comparison with the results of descriptive statistical methods. Therefore, even in the absence of experimental or synthetic datasets with known ground truth (GT) of cellular-level dynamic connectivity, the model can provide an otherwise unattainable insights into dynamic flows of information in cortical networks. To ensure statistical significance of inferred connections three thresholds (Methods) were applied simultaneously to each of the 26 sessions in the VCN database: a unit average spike rate α<sub><italic>s</italic></sub>&gt;1Hz, a pair spike rate threshold α<sub><italic>p</italic></sub>&gt;4800, and a static weight peak threshold α<sub><italic>w</italic></sub>&gt;7SD that produced 808 valid units forming 1020 valid pairs across all 6 cortical areas (Methods, <xref ref-type="table" rid="tbl1">Table 1</xref>).</p>
</sec>
<sec id="s3f">
<title>Reconstruction of dynamic connectivity in a local circuit</title>
<p>To illustrate reconstruction of static and dynamic connectivity in a local circuit we use recording from a single animal (session 819701982) from a single Neuropixel probe implanted in the VISam area. Application of three thresholds α<sub><italic>s</italic></sub>, α<sub><italic>p</italic></sub>, and α<sub><italic>w</italic></sub> to all clean units passing quality metrics (Methods) produce 6 pairs with statistically significant (α<sub><italic>w</italic></sub>&gt;7SD) and narrow (&lt;2ms) peak in a static weight <bold>W</bold><sub><bold>st</bold></sub> (Methods, <xref ref-type="table" rid="tbl2">Table 2</xref>) indicating strong putative connections (<xref ref-type="fig" rid="fig5">Fig.5A</xref>). Units are classified as excitatory (waveform duration longer than 0.4ms) or inhibitory (less than 0.4ms) and are assigned to cortical depth and cortical layers based on their spatial coordinates (Methods). Directionality of the connection is defined by negative functional time lag in a static weight <bold>W</bold><sub><bold>st</bold></sub> (or jitter corrected CCG) binned at 1ms. Local circuit reconstructed from static weights matrices is shown in <xref ref-type="fig" rid="fig5">Fig.5B</xref>.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table. 2.</label>
<caption><title>Experimental dataset used for reconstruction of local circuit in <xref rid="fig5" ref-type="fig">Fig.5</xref> and <xref rid="fig6" ref-type="fig">Fig.6</xref></title>
<p>Clean units (passed unit quality metrics) that from valid pairs (passed through all three thresholds α<sub><italic>s</italic></sub>, α<sub><italic>p</italic></sub>, and α<sub><italic>w</italic></sub>) from recordings in VISam area in session 819701982. Units are classified as excitatory (waveform duration longer than 0.4ms) or inhibitory (less than 0.4ms) and are assigned to cortical depth and cortical layers based on their spatial coordinates. Local circuit reconstructed from static weights matrices (max_static weight) is shown in <xref rid="fig5" ref-type="fig">Fig.5B</xref>. Maximum dynamic weight (max_dynamic_weight) is taken at functional time lag. Distance between units (send_recv_distance) is estimated from vertical positions of corresponding principal electrodes (probe_vertical_position).</p></caption>
<graphic xlink:href="552512v3_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Model enables discovery of cellular-level dynamic connectivity patterns in visual cortex.</title>
<p><bold>A)</bold> Jitter-corrected static weights <bold>W</bold><sub><bold>st</bold></sub> for a connected pairs in an example local circuit (session # 819701982, VISam area). Units are numbered by local indices (Methods, <xref ref-type="table" rid="tbl2">Table 2</xref>). <bold>B)</bold> Dynamic weights <bold>W</bold><sub><bold>dyn</bold></sub> for the same pairs. <bold>C)</bold> Schematic diagram of static directional connectivity in pairs in a local circuit in A). Circles and triangles correspond to excitatory and inhibitory units, respectively. <bold>D)</bold> An example of a dynamic weight <bold>W</bold><sub><bold>dyn</bold></sub> for a pair (3→4) classified as un-connected.</p></caption>
<graphic xlink:href="552512v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Corresponding dynamic matrices <bold>W</bold><sub><bold>dyn</bold></sub> (<xref ref-type="fig" rid="fig5">Fig.5C</xref>) for the same pairs demonstrate strong temporal modulation (see also SM, Movie 2). Prior to presentation of a stimulus (t&lt;0ms) the inhibitory drives (negative values of <bold>W</bold><sub><bold>dyn</bold></sub> marked by deep blue color in <xref ref-type="fig" rid="fig5">Fig.5C</xref>) prevail. The first positive peak of <bold>W</bold><sub><bold>dyn</bold></sub> around 70ms (positive values of <bold>W</bold><sub><bold>dyn</bold></sub> marked by bright yellow color in <xref ref-type="fig" rid="fig5">Fig.5C</xref>) is shared by all but one pair. Such synchronous spiking at short time lags does not necessarily indicate a TP direct connection but can also be an FP artefact induced by arrival of afferent signals<sup><xref ref-type="bibr" rid="c37">37</xref></sup>. However, at later times, additional strong peaks appear for some of the pairs that are not accompanied by corresponding increase of the firing rates. Some of the pairs form an indirect serial chain connections (e.g., 3→2 and 2→4 <xref ref-type="fig" rid="fig5">Fig.5B</xref>) that can also generate confounding FP correlations that is notoriously difficult to identify using descriptive statistical models<sup><xref ref-type="bibr" rid="c25">25</xref></sup>. However, the DyNetCP being a probabilistic model might lessen the impact of both the common input and the serial chain FP artefacts by abstracting out such co-variates that do not contribute significantly to a prediction. For example, the <bold>W</bold><sub><bold>dyn</bold></sub> for a potential 3→4 artefactual connection does not show peaks expected from the serial chain.</p>
<p>To aid identification of such confounding FP connections, we performed preliminary tests on a synthetic dataset that contain a number of common input and serial chain triplets and were able to identify them by comparing <bold>W</bold><sub><bold>dyn</bold></sub> values at a given trial time to corresponding <bold>W</bold><sub><bold>st</bold></sub> (Methods). <xref rid="fig6" ref-type="fig">Figure 6</xref> shows temporal evolution of normalized dynamic weight values taken from <xref ref-type="fig" rid="fig5">Fig.5C</xref> along the trial time axis at corresponding functional time lags. We assign excitatory (inhibitory) connection to a given pair as present when the ratio <bold>W</bold><sub><bold>dyn</bold></sub> / <bold>W</bold><sub><bold>st</bold></sub> is larger (or smaller) than 1 (-1). Corresponding dynamic graphs for a local circuit of <xref ref-type="fig" rid="fig5">Fig.5</xref> are shown in <xref ref-type="fig" rid="fig6">Fig.6B</xref> for characteristic trial times. Such dynamic circuit reconstruction is aided by observation of the troughs (inhibitory connection) and peaks (excitatory connection) in the <bold>W</bold><sub><bold>dyn</bold></sub> cross-sections along the lag time axis taken at a given trial time (<xref ref-type="fig" rid="figS6">Fig.6 – figure supplement 1</xref>, see also SM, Movie 2).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Fig.6.</label>
<caption><title>Temporal variation of dynamic weight and reconstruction of dynamic local circuit.</title>
<p><bold>A)</bold> Normalized dynamic weights for all valid pairs in an example local circuit (session # 819701982, VISam area). Units are numbered by local indices. <bold>B)</bold> Schematic diagram of dynamic connectivity in a local circuit for different trial times. Circles and triangles correspond to excitatory and inhibitory units, respectively. The size of blue (red) arrows reflects the dynamic weight of the inhibitory (excitatory) connection at a given time.</p></caption>
<graphic xlink:href="552512v3_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Note, that since DyNetCP, as opposed to population dynamic models<sup><xref ref-type="bibr" rid="c27">27</xref>-<xref ref-type="bibr" rid="c30">30</xref></sup>, learns latent variables assigned to individual units, the anatomical and cell-type specific information in static graph of <xref ref-type="fig" rid="fig5">Fig.5B</xref> is preserved. As in <xref ref-type="fig" rid="fig5">Fig.5B</xref>, units in the circuit of <xref ref-type="fig" rid="fig6">Fig.6B</xref> are ordered with respect to their cortical depth, assigned to specific cortical layers, classified as inhibitory (excitatory) based on their waveform duration. Further analysis of optotagging<sup><xref ref-type="bibr" rid="c38">38</xref></sup> (Methods) was used to identify that none of inhibitory units in this local circuit belong to a Vasoactive Intestinal Polypeptide (Vip) cell class. DyNetCP can also be trained separately on trials when animal was running, and animal was at rest (Methods, <xref ref-type="table" rid="tbl1">Table 1</xref>) to explore the role of brain state on dynamic connectivity patterns. Therefore, not only DyNetCP can provide static connections in this local circuit, but, more importantly, can also track the time epochs when individual cellular-level connections are activated or inhibited that are time-aligned to the stimulus presentation, brain state, and behavior.</p>
<fig id="figS6" position="float" fig-type="figure">
<label>Figure 6 - figure supplement 1.</label>
<caption><title>Reconstruction of a dynamic connectivity in a local circuit.</title>
<p>Dynamic weights <bold>W</bold><sub><bold>dyn</bold></sub> for 6 valid pairs in an example local circuit in <xref rid="fig6" ref-type="fig">Fig.6</xref> taken at different trial times. <bold>A)</bold> at 20ms. <bold>B)</bold> at 70ms. <bold>C)</bold> at 150ms. <bold>D)</bold> at 200ms. Reconstruction of dynamic connectivity is shown on top of each figure. Circles and triangles correspond to excitatory and inhibitory units, respectively. The size of blue (red) arrows reflects the dynamic weight of the inhibitory (excitatory) connection at a given time. See also SM, Movie 2.</p></caption>
<graphic xlink:href="552512v3_figS6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3g">
<title>Dynamic connectivity in VISp primary visual area</title>
<p>Going beyond local circuits, the dynamic analysis of information flows during stimulus presentation can be extended to area-wide dynamic maps. However, with the aggressive choice of threshold parameters (α<sub><italic>s</italic></sub>&gt;1Hz, α<sub><italic>p</italic></sub>&gt;4800, α<sub><italic>w</italic></sub>&gt;7SD) the average number of valid pairs per session (Methods, <xref ref-type="table" rid="tbl1">Table 1</xref>) is relatively low to generalize (mean:39 ± 4 SEM). To analyze area-wide connectivity, an example of cellular-level dynamic interactions in primary visual area VISp learned from all 26 sessions is shown in SM Movie 3. Still frames from this movie are presented in <xref ref-type="fig" rid="fig7">Fig.7A</xref> for a number of characteristic trial times. Units are ordered by cortical depth and assigned to cortical layers. Circles represent the magnitude of a dynamic weight <bold>W</bold><sub><bold>dyn</bold></sub> taken at corresponding functional time lag. The circles diameter is proportional to the dynamic offset <bold>W</bold><sub><bold>dyn</bold></sub> − <bold>W</bold><sub><bold>st</bold></sub>. Red, blue, and magenta circles correspond to excitatory-excitatory, inhibitory-inhibitory, and mixed connections, respectively. Complex dynamic pattern is characteristic for both within each cortical layer (along the anti-diagonal), as well as between layers (outside of the anti-diagonal). Extra-laminar interactions reveal formation of neuronal ensembles with both feedforward (e.g., layer 4 to layer 5), and feedback (e.g., layer 5 to layer 4) drives.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Dynamic functional connectivity prediction along the hierarchy axis of visual cortices.</title>
<p><bold>A) W</bold><sub><bold>off</bold></sub> at different trial times (VISp area, n=26 animals). Units ordered by cortical depth and assigned to layers. The circles diameter is proportional to the dynamic offset. Red, blue, and magenta circles correspond to excitatory-excitatory, inhibitory-inhibitory, and mixed connections, respectively. <bold>B) W</bold><sub><bold>off</bold></sub> matrices for all visual areas (n=26 animals) ordered by their hierarchical</p></caption>
<graphic xlink:href="552512v3_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3h">
<title>Dynamic connectivity along the hierarchy axis of all visual cortices</title>
<p>Similarly, cellular-level dynamic interactions at the cortex-wide level for all 6 cortical areas learned from all 26 sessions are shown in SM Movie 4. Still frames from this movie for the same characteristic times are shown in <xref ref-type="fig" rid="fig7">Fig.7B</xref>. Inter-areal long-range interactions across various visual cortices (off-diagonal terms in <xref ref-type="fig" rid="fig7">Fig.7B</xref>) exhibit complex temporal evolution with rich feedforward (along the anatomical hierarchical score difference<sup><xref ref-type="bibr" rid="c5">5</xref></sup>) and feedback interactions. Therefore, DyNetCP can uncover the dynamics of feedforward- and feedback-dominated epochs during sensory stimulation, as well as behavioral states (e.g., epochs in the VCN dataset when animals are running or sitting), however, as opposed to population decoding models<sup><xref ref-type="bibr" rid="c27">27</xref>-<xref ref-type="bibr" rid="c30">30</xref></sup>, produce cellular-level cell-type specific connectivity patterns that are otherwise hidden from analysis.</p>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>DyNetCP can reveal cellular-level dynamic interactions within local circuits, within a single brain area, as well as across global hierarchically organized information pathways. Such detailed information, although present in the original datasets, is otherwise hidden from usual analysis that typically relies on time-averaged spike rate coding or population-averaged coding. It is instructional to assess whether the temporal cellular-level interactions uncovered by DyNetCP are bringing new latent dimensions to the analysis of neural code. Dimensionality reduction methods<sup><xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c35">35</xref>,<xref ref-type="bibr" rid="c39">39</xref></sup> are often used to estimate the number of independent dimensions of the code that can better explain the variability of spike trains. When principal component (PC) dimensionality reduction<sup><xref ref-type="bibr" rid="c30">30</xref></sup> is applied to the dynamic weights <bold>W</bold><sub><bold>dyn</bold></sub> of all valid pairs (i.e., passed through all 3 thresholds) in a single animal (65 units, 105 pairs, session 831882777), up to 33 components are required to account for 95% of the variance (<xref ref-type="fig" rid="fig8">Fig.8A</xref>, black). In contrast, only 5 PC are sufficient to explain 95% variance of spike rates for the same units (<xref ref-type="fig" rid="fig8">Fig.8A</xref>, red). If all clean units in all visual cortices are taken (264 VIS units) the dimensionality increases, but only slightly to 8 PC (<xref ref-type="fig" rid="fig8">Fig.8A</xref>, blue). The normalized intrinsic dimensionality (NID) estimated as a number of major PC components divided by the number of units is between 0.03 and 0.08 for spike rates exhibiting striking simplicity consistent with an often observed trend<sup><xref ref-type="bibr" rid="c40">40</xref></sup>. However, in contrast, the NID for dynamic weights is as large as 0.5 showing dramatic increase of dimensionality.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Intrinsic dimensionality of dynamic connectivity is large</title>
<p><bold>A)</bold> Intrinsic dimensionality of neural activity manifold (session 831882777, no temporal smoothing) using spiking data for all VIS cortical units (red), units in selected pairs (blue), and for the same unit pairs using dynamic weights (black). <bold>Inset</bold>: Intrinsic dimensionality as a function of temporal gaussian kernel width. B<bold>)</bold> Intrinsic dimensionality (n=26 animals) in spike rate space normalized by the number of all VIS units (violet) and units in selected pairs (green). Intrinsic dimensionality in a weight space for units in selected pairs (orange). Box: SD, whiskers: 5%-95% range, box: mean, horizontal line: median, distribution: kernel Scott, **** is p-value&lt;0.0001.</p></caption>
<graphic xlink:href="552512v3_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>This result holds for each of the 26 sessions with the NID in the spiking rate space for valid pairs (<xref ref-type="fig" rid="fig8">Fig.8B</xref>, green, mean:0.20±0.018 SEM) and for all VIS units (<xref ref-type="fig" rid="fig8">Fig.8B</xref>, violet, mean:0.08±0.01 SEM). In contrast, much larger NID is observed in the space of dynamic weights (<xref ref-type="fig" rid="fig8">Fig.8B</xref>, orange, mean:0.55±0.02 SEM) indicating that the dimensionality of a dynamic network manifold is becoming comparable to the number of recorded units. Hence the observed complexity stems from a relatively small subpopulation (valid units in pairs mean: 42.7±3.3 SEM) comprising just 20% of the total (all clean VIS units mean: 194.9±11.9 SEM) and at relatively short time scales below 30ms when it survives temporal Gaussian kernel smoothing (inset in <xref ref-type="fig" rid="fig8">Fig.8A</xref>). DyNetCP, therefore, reveals the dynamically reconfigurable functional architecture of cortical networks that is otherwise hidden from analysis.</p>
<p>In summary, DyNetCP provides a fully reproducible and generalizable processing framework that allows investigators to explore often overlooked dimensions of the neural code that are potentially rich for novel biological insights. We believe that our approach can help to provide a conceptual link between brain-wide network dynamics studied with neuroimaging methods and modern electrophysiology approaches resolving such dynamics at a cellular level.</p>
</sec>
<sec id="s5">
<title>Methods</title>
<sec id="s5a">
<label>1.</label>
<title>M<sc>odel implementation and training</sc></title>
<sec id="s5a1">
<title>Computational resources</title>
<p>The DyNetCP model can be trained in a single step to produce both static and dynamic weight matrices simultaneously. Alternatively, static, and dynamic training can be done sequentially to minimize the computational resources and to enable intermediate checking of the model parameters with respect to descriptive statistical results. In this case, prior to implementing the dynamic part of DyNetCP, the pairs are classified as putative connections based on a statistical analysis (see below) of the static weights, and the dynamic component is trained only on these pairs.</p>
<p>Computation time and memory consumption can also be optimized by the choice of the bin size <italic>d</italic> at the cost of temporal precision of the weight prediction. To better identify putative connections and to ease comparison with descriptive CCG models, we use a bin size of 1ms for training of static weights. For training the dynamic part, we use spiking data binned at a 5ms resolution. Evaluation of statistical significance of the model predictions (see below) indicates that a 5ms bin size strikes a good balance between computational efficiency, temporal resolution, and data sparsity.</p>
<p>All models are trained using the ADAM optimizer<sup><xref ref-type="bibr" rid="c41">41</xref></sup>, a batch size of 16, and a learning rate of 0.0001 for 2000 epochs, where the learning rate is reduced by a factor of 10 after 1000 epochs. For each dataset, we set aside some of the data for validation. We use the validation data for early stopping: after every epoch of training, we compute the loss on the validation data, and terminate training early if the validation loss has not improved for a specific number of epochs (100 when training the static portion and 50 when training the dynamic portion). Note, to properly assess generalization, all plots in this work show DyNetCP static and dynamic weights outputs from the validation data.</p>
<p>When training the static part of the model on the synthetic HH dataset<sup><xref ref-type="bibr" rid="c26">26</xref></sup>, we use <italic>λ</italic> = 1. For training the static part on the VCN dataset<sup><xref ref-type="bibr" rid="c15">15</xref></sup> we use <italic>λ</italic> = 100, which we found to lead to a lower residual when comparing to CCG values. For training the dynamic weights for all models we use <italic>λ</italic> = 10.</p>
</sec>
<sec id="s5a2">
<title>Averaging Dynamic Weights</title>
<p>To extract a strong signal from the DyNetCP dynamic weights, we need to aggregate information over experimental trials. However, we do not want to simply average the weights over trials, as all weights which are not paired with an incoming spike (i.e., all weights <inline-formula><inline-graphic xlink:href="552512v3_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula> such that <inline-formula><inline-graphic xlink:href="552512v3_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) do not contribute to the spike rate prediction and therefore are not constrained to capture the spiking correlations. As a result, when computing trial-aggregated DyNetCP weights, we average over weights that are time-aligned with spike times of corresponding unit (<xref ref-type="fig" rid="fig9">Fig.9A</xref>) as follows:</p>
<p>
<disp-formula id="eqn9">
<graphic xlink:href="552512v3_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Additionally, to compensate for the sparsity of spiking, we average these aggregated dynamic weights over the 10 most recent bins (<xref ref-type="fig" rid="fig9">Fig.9B</xref>).</p>
<fig id="fig9" position="float" fig-type="figure">
<label>Fig.9.</label>
<caption><title>Selection of dynamic weight values and weights averaging</title>
<p><bold>A)Selection of weights which contribute to averaging</bold>. Single trial spiking times for a given unit (black bars). Inferred dynamic weight values (orange curve) are selected at times when associated unit spikes (black dots), as the remaining weights do not contribute to the predicted spiking probability and therefore are not supervised to represent a meaningful value. <bold>B) Averaging of weights</bold>. Each blue point corresponds to a dynamic weight from a single trial. The orange curve represents a trial-average of every weight time-aligned with spikes. Green curve represents the Gaussian smoothing with a kernel including the 10 most recent bins.</p></caption>
<graphic xlink:href="552512v3_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s5a3">
<title>Jitter correction</title>
<p>Jittering method <sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c33">33</xref>-<xref ref-type="bibr" rid="c35">35</xref></sup> is often used in analysis of pairwise spiking correlations to minimize the influence of a potential stimulus-locked joint variation in population spiking that often occurs due to common input from many shared presynaptic neurons. To lessen the impact of such false positive (FP) connections in DyNetCP results and to ease the comparison with classical jitter-corrected CCG, we train a second static model on a jitter-corrected version of the data generated using a pattern jitter algorithm<sup><xref ref-type="bibr" rid="c33">33</xref></sup> with a jitter window of 25ms. When the dataset is trial-aligned (e.g. VCN dataset), we use the correction procedure<sup><xref ref-type="bibr" rid="c33">33</xref></sup> which determines the probability of a spike being present in each bin for all possible random shuffles of spikes among trials. For data which is not trial-aligned (e.g. synthetic dataset of HH neurons<sup><xref ref-type="bibr" rid="c26">26</xref></sup>), we randomly permute the spike times within the interval [-5ms, +5ms] before every weight update. New spike resampling is performed during every epoch of training. To assess putative connectivity, the jitter-corrected static weights <italic>w</italic>’<sub><italic>j</italic>→<italic>i</italic></sub> produced by a jitter-corrected model are subtracted from the weights <italic>w</italic><sub><italic>j</italic>→<italic>i</italic></sub> trained on the original data to obtain <italic>w</italic><sup>∗</sup> <sub><italic>j</italic>→<italic>i</italic></sub>= <italic>w</italic><sub><italic>j</italic>→<italic>i</italic></sub> − <italic>w</italic> <sup>′</sup> <sub><italic>j</italic>→<italic>i</italic></sub> and <italic>w</italic><sup>∗</sup> <sub><italic>i</italic>→<italic>j</italic></sub> = <italic>w</italic><sub><italic>i</italic>→<italic>j</italic></sub> – <italic>w</italic><sup>′</sup> <sub><italic>i</italic>→<italic>j</italic></sub>.</p>
</sec>
</sec>
<sec id="s5b">
<label>2.</label>
<title>D<sc>atasets</sc></title>
<sec id="s5b1">
<title>Synthetic network of HH neurons</title>
<p>We use a synthetic dataset consisting of Hodgkin-Huxley (HH) 800 excitatory and 200 inhibitory neurons with known ground truth (GT) synaptic connections<sup><xref ref-type="bibr" rid="c26">26</xref></sup>. The excitatory neurons influence 12.5% and the inhibitory neurons influence 25% of other neurons. We use the first 4320s of the 5400s-long data for training and the remaining 1080s for validation. Since DyNetCP requires training with trial-aligned data, we split each of these datasets into 1s “trials” consisting of 1000 bins each. For training and evaluation we use spikes from the same subset of 20 excitatory neurons as was used for GLMCC validation<sup><xref ref-type="bibr" rid="c26">26</xref></sup> (<xref ref-type="fig" rid="fig2">Fig.2.C,D,E</xref>).</p>
</sec>
<sec id="s5b2">
<title>Synthetic dataset with FP connections</title>
<p>Synchronous spiking at short time lags does not necessarily indicate a direct connection but can also be induced by a shared common input (<xref ref-type="fig" rid="fig10">Fig.10A</xref>) or an indirect serial chain connection (<xref ref-type="fig" rid="fig10">Fig.10B</xref>) among others. While it is notoriously difficult to distinguish these confounding correlations using descriptive statistical models<sup><xref ref-type="bibr" rid="c25">25</xref></sup>, the DyNetCP being a probabilistic model might lessen their impact by abstracting out such co-variates that do not contribute significantly to a prediction. To test the ability of DyNetCP to identify such confounds, we generate a synthetic dataset with known GT static and dynamic connectivity. The dataset consists of 100 excitatory neurons with their spikes generated by independent sampling from a Bernoulli distribution with spike rate between 0.002 and 0.01 per bin. The GT connection is active when spikes in neuron <italic>n</italic><sub>1</sub> at time <italic>t</italic> are followed by spikes in neuron <italic>n</italic><sub>2</sub> at a time <italic>t</italic> + <italic>d</italic> with a probability of 0.6. Randomly generated 100 “triplets” emulating common input and serial chain connections are added to the pool. The “triplets” are active either during the first and last 125 bin period or only during the middle 375 bin period.</p>
<fig id="fig10" position="float" fig-type="figure">
<label>Fig.10.</label>
<caption><title>Performance of the model on synthetic dataset with FP connections</title>
<p><bold>A)Identification of FP connections for a “common input” triplet. Inset:</bold> schematics of a triplet with common input from the unit 0 to both units 1 and 2. <bold>Top row:</bold> connection is active during the first and last 125 bin period of the trial. <bold>Bottom row:</bold> Connection is active only during the middle 375 bin period. Blue bars (left y-axis) represent a histogram of joint spiking probability (JPSTH anti-diagonal). Red curves correspond to inferred dynamic weights (right y-axis), while dotted magenta line represents static weight value. Comparison of dynamic and static weights might help to distinguish TP connections 0→1 and 0→2 from an artifactual FP connection 1→2. <bold>B) Identification of FP connections for a “serial input” triplet. Inset:</bold> schematics of a triplet with serial input from the unit 0 to 1 followed by 1 to 2. <bold>Top row:</bold> connection is active during the first and last 125 bin period of the trial. <bold>Bottom row:</bold> Blue bars (left y-axis) represent a histogram of joint spiking probability (JPSTH anti-diagonal). Red curves correspond to inferred dynamic weights (right y-axis), while dotted magenta line represents static weight value. Comparison of dynamic and static weights may help to distinguish TP connections 0→1 and 1→2 from an artifactual FP connection 0→2.</p></caption>
<graphic xlink:href="552512v3_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>DyNetCP trained on this dataset (400 train and 200 validation trials, each 500 bins long) enables comparison of static and dynamic weights (<xref ref-type="fig" rid="fig10">Fig.10</xref>) that indicate that when the GT connection is present the <bold>W</bold><sub><bold>dyn</bold></sub> tends to be larger than <bold>W</bold><sub><bold>st</bold></sub>, which enables classification of connections as TP and FP for both common input (<xref ref-type="fig" rid="fig10">Fig.10A</xref>) and serial chain (<xref ref-type="fig" rid="fig10">Fig.10B</xref>) connections for this synthetic dataset.</p>
</sec>
<sec id="s5b3">
<title>Experimental dataset recorded in visual cortex</title>
<p>To demonstrate DyNetCP performance with in-vivo high-density electrophysiological recordings, we used the publicly available Allen Brain Observatory-Visual Coding Neuropixels (VCN) database<sup><xref ref-type="bibr" rid="c15">15</xref></sup> that contains spiking activity collected across 99,180 units from 6 different visual cortical areas in 58 awake mice viewing diverse visual stimuli. We use a “functional connectivity” subset of these recordings corresponding to the “drifting grating 75 repeats” setting recorded for 26 animals (26 sessions in <xref ref-type="table" rid="tbl1">Table 1</xref>). Full-field drifting grating stimuli was passively viewed by a head-fixed animal freely running on a treadmill<sup><xref ref-type="bibr" rid="c15">15</xref></sup>. Stimuli consists of 2s presentation of drifting diffraction grating (temporal frequency 2 cycles/s, spatial frequency = 0.04 cycles per degree) that is interleaved with a 1s grey period (top left inset in <xref ref-type="fig" rid="fig1">Fig.1A</xref>). Presentation of gratings were repeated 75 times per orientation (0, 45, 90, and 135 degrees) and per contrast (0.8 and 0.4). To maximize the number of spikes available for training we use all angles and all contrast trials.</p>
<p>We split the 600 total experimental trials for each session into 480 training and 120 validation trials by selecting 60 training trials from each configuration of contrast or grating angle and 15 for validation. To further investigate the influence of brain state on connectivity dynamics we identify in each session trials with the average running speed above 5cm/s that are marked as “running”. The rest of the trials are marked as “not running”. When trained and validated, the model results can then be analyzed and compared for “running” vs “non-running” conditions separately.</p>
</sec>
<sec id="s5b4">
<title>M<sc>odels used</sc></title>
<sec id="s5b4a">
<title>GLMCC model</title>
<p>Python code for GLMCC method is taken from the author’s version<sup><xref ref-type="bibr" rid="c42">42</xref></sup>. For these experiments, we use the synthetic dataset of interconnected HH neurons<sup><xref ref-type="bibr" rid="c26">26</xref></sup>. We focus specifically on recovering ground-truth (<italic>GT</italic>) excitatory connections. To facilitate a comparison with GLMCC model<sup><xref ref-type="bibr" rid="c26">26</xref></sup>, we here choose thresholds α<sub><italic>w</italic></sub>, α<sub><italic>s</italic></sub>, and α<sub><italic>p</italic></sub> to maximize the Matthews Correlation Coefficient (MCC, <xref ref-type="disp-formula" rid="eqn9">Eq.9</xref>). MCC optimization balances between maximizing the number of <italic>TP</italic> pairs recovered while minimizing the number of <italic>FP</italic> pairs which are predicted.</p>
<p>Since a predicted connection is counted as a <italic>TP</italic> only once (i.e., <italic>i</italic>→ <italic>j</italic> and j→ <italic>i</italic> do not count as two negatives if <italic>i</italic> is not connected to <italic>j</italic>) and the number of <italic>GT</italic> connections decreases when α<sub><italic>p</italic></sub> increases, the MCC exhibits an increase beyond α<sub><italic>p</italic></sub>=100. A more detailed analysis of TP and FP rates as a function of pair spike threshold is presented in <xref ref-type="fig" rid="figS2">Fig.2 - figure supplement 1</xref>.</p>
<p>Though GLMCC performs well in recovering static network structure, we emphasize that GLMCC is not compatible with modeling network dynamics and thus cannot be integrated into DyNetCP. Specifically, our goal is to model the correlations of spiking of a network of neurons and track the changes of these correlations across time. GLMCC learns correlations as a function of the time lag relative to the spiking time of a reference neuron. It is hence unable to link correlations to specific moments in a trial time. Therefore, it cannot represent the dynamics of correlations, preventing its use in analysis of network activity relative to subject behavior.</p>
</sec>
<sec id="s5b4b">
<title>Conditional Joint Peristimulus Time Histogram (cJPSTH)</title>
<p>The Joint Peristimulus Time Histogram (JPSTH) is a classical tool<sup><xref ref-type="bibr" rid="c36">36</xref></sup> used to analyze the joint correlations of spiking behavior between two neurons and their variation across time. For a proper comparison with conditional DyNetCP results, we use a conditional joint peristimulus time histogram (cJPSTH), where we divide the columns of the JPSTH by the PSTH of neuron <italic>i</italic> (<xref ref-type="fig" rid="fig4">Fig.4B,C</xref>). Due to the sparsity of spiking in the data we use, it is beneficial to average the entries of the cJPSTH over short windows in time to more clearly extract the dynamics of the correlations between neurons. Specifically, we replace each entry (<italic>a, b</italic>) in the cJPSTH by the average of the <italic>T</italic> most recent bins having the same delay <italic>a</italic> − <italic>b</italic>, that is,
<disp-formula id="eqn10">
<graphic xlink:href="552512v3_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
For most of the comparisons we use <italic>T</italic>=10 bins. Note that for most cJPSTH plots (e.g., <xref ref-type="fig" rid="fig4">Fig.4E</xref>), to directly compare to DyNetCP plots (e.g., <xref ref-type="fig" rid="fig4">Fig.4D</xref>), we only show data representing the “upper diagonal” of the full plot which represents data where neuron <italic>i</italic> spikes at the same time or before neuron <italic>j</italic> spikes. Specific implementation and comparisons of both models can be found in the accompanying Jupyter Notebook.</p>
</sec>
<sec id="s5b4c">
<title>Dimensionality reduction</title>
<p>Dimensionality reduction<sup><xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c35">35</xref>,<xref ref-type="bibr" rid="c39">39</xref></sup> is based on calculating principal components (PC) on the dataset and estimating the data variance that can be explained by a minimal number of PC. The dimensionality reduction code following a standard PCA reduction method<sup><xref ref-type="bibr" rid="c39">39</xref></sup> is rewritten in Python and is used for analysis in <xref rid="fig8" ref-type="fig">Fig. 8A,B</xref>.</p>
</sec>
</sec>
</sec>
<sec id="s5c">
<label>4.</label>
<title>S<sc>tatistical analysis of filtering and classification of units and pairs</sc></title>
<p>The total number of units (raw units) recorded from visual cortices in 26 sessions of the VCN dataset<sup><xref ref-type="bibr" rid="c15">15</xref></sup> is 18168. Units and pairs are filtered and classified by the following procedure.</p>
<sec id="s5c1">
<title>Unit quality metrics</title>
<p>First, we apply standard unit quality metrics<sup><xref ref-type="bibr" rid="c15">15</xref></sup> including amplitude cutoff &lt; 0.1; violations of inter-spike interval (ISI) &lt; 0.1; presence ratio &gt; 0.95; isolation distance &gt; 30; and signal to noise ratio (snr) &gt; 1. This results in 5067 units (clean units).</p>
</sec>
<sec id="s5c2">
<title>Static weight peak threshold</title>
<p>Second, short-latency peaks within the first 10ms in the <italic>w</italic><sup>∗</sup><sub><italic>j</italic>→<italic>i</italic></sub> and <italic>w</italic><sup>∗</sup> <sub><italic>i</italic>→<italic>j</italic></sub> of static weights are examined (example analysis for session 771160300 is shown <xref ref-type="fig" rid="fig2">Fig.2A,B</xref>). Following the accepted approach<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c26">26</xref></sup> a putative connection is considered statistically significant when the magnitude of the peak exceeds a certain peak weight threshold α<sub>w</sub> measured in units of standard deviations (SD) of the noise in the flanks, calculated within [51ms, 100ms] from both directions <italic>w</italic><sup>∗</sup> <sub><italic>j</italic>→<italic>i</italic></sub> and <italic>w</italic><sup>∗</sup><sub><italic>i</italic>→<italic>j</italic></sub>. When pairs are filtered with increasing peak weight threshold α<sub><italic>w</italic></sub> (<xref ref-type="fig" rid="fig11">Fig.11A</xref>), the number of corresponding valid units is fast decreasing (black curve). For all 26 sessions 5067 clean units participate in formation of 5203 pairs with noticeable weight peaks. Filtering them using α<sub>w</sub>=7SD results in 1680 pairs corresponding to 1102 units. Close examination of these pairs (example analysis for session 771160300 is shown in <xref ref-type="fig" rid="fig11">Fig.11A</xref>) reveals that units not only form pairs (violet curve), but also form triplets (green), quintuplets (blue), and even participate in connections above 10-tuples (red). High radix hubs of this type are most likely FP artefacts imposed by sparse spiking (see below) and need to be filtered out. Indeed, electrophysiology spiking datasets are typically very sparse, with many interesting units often generating spikes at rates below 1Hz. Increasing the threshold α<sub><italic>w</italic></sub> does help to filter out high radix connections, but still even for α<sub><italic>w</italic></sub> as large as 8 there is a substantial number of units participating in connections larger than 3.</p>
<fig id="fig11" position="float" fig-type="figure">
<label>Fig.11.</label>
<caption><title>Thresholds for units and pairs filtering</title>
<p>A) Number of valid units (session #771160300) that form pairs with distinct static peak (black curve) for different peak weight thresholds. Violet, green, blue, and red curves correspond to units that participate in formation of pairs, triplets, quintuplets, and connections above 10-tuples, correspondingly. <bold>B)</bold> Number of valid units that form pairs with static peak above 4SD (black curve) for different pair spike rate. Violet, green, blue, and red curves correspond to units that participate in formation of pairs, triplets, quintuplets, and connections above 10-tuples, correspondingly. <bold>C)</bold> 3D plot of a number of valid units that form pairs for different peak thresholds and pair spike rates.</p></caption>
<graphic xlink:href="552512v3_fig11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s5c3">
<title>Unit spike rate</title>
<p>Therefore, as a third filtering step, we apply a unit spike rate threshold α<sub>s</sub> to limit the minimal spike rate to 1Hz.</p>
</sec>
<sec id="s5c4">
<title>Pair spike rate threshold</title>
<p>It has been argued<sup><xref ref-type="bibr" rid="c26">26</xref></sup> that, to reliably infer that a connection is present (i.e. to disprove the null hypothesis that a connection is absent), each binned time interval in the CCG histogram <italic>d</italic> should contain a sufficiently large number of spikes from both participating units. This implies that the spike rate of each neuron in a pair <italic>λ</italic><sub><italic>i</italic></sub> and <italic>λ</italic><sub><italic>j</italic></sub> should exceed the threshold α<sub><italic>s</italic></sub>, and the joint number of spikes in each time bin should exceed the pair spike threshold, defined as
<disp-formula id="eqn11">
<graphic xlink:href="552512v3_eqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The confidence interval for a null hypothesis that two spike trains are independent stationary Poisson processes<sup><xref ref-type="bibr" rid="c26">26</xref></sup> is then defined as
<disp-formula id="eqn12">
<graphic xlink:href="552512v3_eqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
To disprove the null hypothesis and infer that a connection is statistically significant, α<sub><italic>p</italic></sub> should exceed<sup><xref ref-type="bibr" rid="c26">26</xref></sup> To train the dynamic DyNetCP we use recordings binned at <italic>d</italic> of 5ms repeated over <italic>M</italic> of 480 randomized trials and the dynamic weights are influenced by <italic>T</italic>=10 most recent bins (<xref ref-type="fig" rid="fig9">Fig.9B</xref>). This corresponds to the <italic>TMd</italic> product of 24 that implies the minimum joint pair spike rate <italic>λ</italic><sub><italic>i</italic></sub> <italic>λ</italic><sub><italic>j</italic></sub> of 0.41s<sup>-2</sup>. This threshold, however, might be insufficient for inference of the dynamic weight since only spikes within a short trial time interval are being used for learning. Indeed, analysis of an example pair (<xref ref-type="fig" rid="fig12">Fig.12A</xref>) that passed the α<sub>w</sub>=7SD threshold and has <italic>λ</italic><sub><italic>i</italic></sub> <italic>λ</italic><sub><italic>j</italic></sub> = 0.73s<sup>-2</sup>, reveals that it exhibits on average just 2 spikes per trial or a total of 272 spikes for all 480 trials in a 500ms trial time window of interest. Corresponding jitter-corrected static weight matrix (<xref ref-type="fig" rid="fig12">Fig.12A</xref>, left) and cJPSTH (<xref ref-type="fig" rid="fig12">Fig.12A</xref>, bottom right) are very sparsely populated. The dynamic weight matrix (right top), although it is reproducing this sparseness, is not statistically convincing. Moreover, such pairs contribute significantly to high radix tuples.</p>
<fig id="fig12" position="float" fig-type="figure">
<label>Fig.12.</label>
<caption><title>Example of pairs and dynamic model performance</title>
<p><bold>A)</bold> Example of a pair of units (session #771160300, excitatory units from VISam and VISpm areas with spike rates 1.92Hz and 0.35Hz) that pass a peak weight threshold of 7SD (left static weight matrix plot), however, has pair spike rate as small as 0.73 s<sup>-2</sup>. Corresponding cJPSTH (bottom right) and dynamic weight plots (top right) are sparse. <bold>B)</bold> Example of a pair of units (session #771160300, excitatory VISp unit with 7.2Hz spike rate and inhibitory VISp unit with 6.8Hz rate) that pass a peak weight threshold of 7SD (left static weight plot), however, has moderate pair spike rate of 50 s<sup>-2</sup>. Corresponding cJPSTH and dynamic weight plots are shown on the right. <bold>C)</bold> Example of a pair of units that pass peak weight threshold of 7SD (left static weight plot), that has a relatively high pair spike rate of 130 s<sup>-2</sup>. Corresponding cJPSTH and dynamic weight plots are shown on the right.</p></caption>
<graphic xlink:href="552512v3_fig12.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>By increasing the <italic>λ</italic><sub><italic>i</italic></sub> <italic>λ</italic><sub><italic>j</italic></sub> pair spike rate threshold, the number of high radix tuples is decreasing (example analysis for session 771160300 is shown in <xref ref-type="fig" rid="fig11">Fig.11B</xref>), however the α<sub><italic>p</italic></sub> threshold alone is not sufficient to eliminate them. Hence, for a given pair to be classified as a putative connection, the classification procedure requires the use of all three thresholds: α<sub><italic>w</italic></sub>, α<sub><italic>s</italic></sub>, and α<sub><italic>p</italic></sub> (see Jupyter Notebook for specific implementation).</p>
</sec>
<sec id="s5c5">
<title>Choice of thresholds</title>
<p>When all three thresholds α<sub><italic>s</italic></sub>, α<sub><italic>w</italic></sub> and α<sub><italic>p</italic></sub> are applied simultaneously (<xref ref-type="fig" rid="fig11">Fig.11C</xref>) the number of valid units is decreasing rapidly with the increase of α<sub><italic>w</italic></sub> to 7SD and <italic>λ</italic><sub><italic>i</italic></sub> <italic>λ</italic><sub><italic>j</italic></sub> beyond 10 with slower decrease at higher thresholds. Examination of an example pair with joint pair spiking rate <italic>λ</italic><sub><italic>i</italic></sub> <italic>λ</italic><sub><italic>j</italic></sub> of 50 s<sup>-2</sup> (<xref ref-type="fig" rid="fig12">Fig.12B</xref>) indicates that while the static weight matrix shows a prominent (α<sub><italic>w</italic></sub> &gt;7SD) small latency peak, the cJPSTH is still populated relatively sparsely and the dynamic weight matrix resembles it much less (r<sub>p</sub>=0.27). In contrast, for an example pair with joint pair spiking rate <italic>λ</italic><sub><italic>i</italic></sub> <italic>λ</italic><sub><italic>j</italic></sub> of 130 s<sup>-2</sup> (<xref ref-type="fig" rid="fig12">Fig.12C</xref>) the resemblance between cJPSTH and the dynamic weight matrix is striking (r<sub>p</sub>=0.82, P<sub>p</sub>&lt;0.001).</p>
<p>For a fixed α<sub><italic>s</italic></sub> of 1Hz and α<sub><italic>w</italic></sub> of 7SD the distribution of all valid pairs with respect to their joint spike rates (<xref ref-type="fig" rid="fig13">Fig.13A</xref>) shows a maximum around <italic>λ</italic><sub><italic>i</italic></sub> <italic>λ</italic><sub><italic>j</italic></sub>=200 s<sup>-2</sup> with a long tail to higher rates. To be conservative, for all the analysis of the inferred connectivity patterns in this work, we used <italic>λ</italic><sub><italic>i</italic></sub> <italic>λ</italic><sub><italic>j</italic></sub> of 200 s<sup>-2</sup> (α<sub><italic>p</italic></sub>=4800, red arrow in <xref ref-type="fig" rid="fig13">Fig.13A</xref>).</p>
<fig id="fig13" position="float" fig-type="figure">
<label>Fig.13.</label>
<caption><title>Filtered pairs and potential biases.</title>
<p><bold>A)</bold> Histogram of pairs recorded in all VIS cortices for all 26 animals that pass 7SD peak weight threshold and are formed from units with spike rate exceeding 1Hz. Red arrow shows the pair spike threshold of 200 s<sup>-2</sup>. <bold>B)</bold> Histograms of inferred static and maximum dynamic weights for filtered pairs. <bold>C)</bold> Histograms of unit spike rates for clean units and for valid units belonging to filtered pairs. <bold>D)</bold> Histograms of waveform duration for clean units and valid units. Red arrow indicates a threshold to classify units as inhibitory or excitatory.</p></caption>
<graphic xlink:href="552512v3_fig13.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Application of all 3 filters to all 26 sessions produces 808 units forming 1020 pairs (<xref ref-type="table" rid="tbl1">Table 1</xref>) with distribution of inferred static and dynamic weights shown in <xref ref-type="fig" rid="fig13">Fig.13B</xref>.</p>
</sec>
</sec>
<sec id="s5d">
<title>Units’ classification</title>
<p>Once all pairs are filtered, the directionality is assigned to each putative connection, either <italic>j</italic> → <italic>i</italic> or <italic>i</italic> → <italic>j</italic>, that is identified by the functional delay of the static weight peak binned at 1ms. Cortical depth perpendicular to cortical surface is calculated from unit coordinates in ccfv3 format (Allen Mouse Brain Common Coordinate Framework <sup><xref ref-type="bibr" rid="c43">43</xref></sup>). Layer assignment is performed following method<sup><xref ref-type="bibr" rid="c15">15</xref></sup> using units coordinates in the ccfv3 framework and the annotation matrix with reference space key ‘annotation/ccf_2017’. All units are classified as excitatory if their waveform duration is longer than 0.4ms and the rest as inhibitory (<xref ref-type="fig" rid="fig13">Fig.13D</xref>). Since transgenic mice were used for some of the sessions in the VCN dataset, optical activation of light-gated ion channel (in this case, ChR2) in Cre+ neurons with light pulses delivered to the cortical surface generate precisely time-aligned spikes that enable to link spike trains to genetically defined cell classes. Optical tagging was used to further classify inhibitory units<sup><xref ref-type="bibr" rid="c38">38</xref></sup> as Parvalbumin-positive neurons (Pvalb), Somatostatin-positive neurons (Sst), and Vasoactive Intestinal Polypeptide neurons (Vip).</p>
</sec>
<sec id="s5e">
<title>Potential biases</title>
<p>The statistical analysis and filtering procedure described above is biased towards strongly spiking units (<xref ref-type="fig" rid="fig13">Fig.13C</xref>) and as such can generate certain biases in connectivity patterns. For example, inhibitory units constitute about 18% of all 5067 clean units that pass unit quality metrics (<xref ref-type="fig" rid="fig13">Fig.13D</xref>). However, after filtering down to 808 valid units, they constitute over 50% of the population (<xref ref-type="fig" rid="fig13">Fig.13D</xref>). In general, inhibitory units have a higher spiking rate (for all clean units mean: 15.4Hz±0.29 SEM) than excitatory (mean: 6.3Hz±0.08 SEM). This might explain, at least partially, the over-representation of connections involving inhibitory units in the dynamic connectivity plots.</p>
</sec>
</sec>
<sec id="d1e2780" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e2865">
<label>video 1</label>
<media xlink:href="supplements/552512_file02.mp4"/>
</supplementary-material>
<supplementary-material id="d1e2872">
<label>video 2</label>
<media xlink:href="supplements/552512_file03.mp4"/>
</supplementary-material>
<supplementary-material id="d1e2879">
<label>video 3</label>
<media xlink:href="supplements/552512_file04.mp4"/>
</supplementary-material>
<supplementary-material id="d1e2886">
<label>video 4</label>
<media xlink:href="supplements/552512_file05.mp4"/>
</supplementary-material>
</sec>
</body>
<back>
<sec id="s6">
<title>Data Availability</title>
<p>All of the datasets used in this article are publicly available online under the Creative Commons Attribution 4.0 International license. Synthetic data of interconnected HH neurons<sup><xref ref-type="bibr" rid="c26">26</xref></sup> is available at figshare<sup><xref ref-type="bibr" rid="c44">44</xref></sup> (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.9637904">https://doi.org/10.6084/m9.figshare.9637904</ext-link>). The Allen Brain Observatory-Visual Coding Neuropixels (VCN) database<sup><xref ref-type="bibr" rid="c15">15</xref></sup> is available for download in Neurodata Without Borders (NWB) format via the AllenSDK. The NWB files are available as an AWS public dataset (<ext-link ext-link-type="uri" xlink:href="https://registry.opendata.aws/allen-brain-observatory/">https://registry.opendata.aws/allen-brain-observatory/</ext-link>). Synthetic dataset with artifactual FP connections is available on GitHub.</p>
</sec>
<sec id="s7">
<title>Code Availability</title>
<p>DyNetCP introduced and used in this article is open-source software (GNU General Public License v3.0). The source code is available in a GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/NeuroTechnologies/DyNetCP">https://github.com/NeuroTechnologies/DyNetCP</ext-link>) that contains codes for model training as well as a Jupyter notebook for generating the results used in the paper and in the SM.</p>
</sec>
<sec id="s8">
<title>Supplementary materials</title>
<p><bold>SM Movie 1: Dynamic weight for an exemplary pair</bold></p>
<p>Dynamic weight <bold>W</bold><sub><bold>dyn</bold></sub> for a local pair of excitatory units from Layer 5 VISp area, session 766640955 (same pair as in <xref rid="fig4" ref-type="fig">Fig.4D, E</xref>). Static weight is shown on the background. Dashed horizontal line is a maximum static weight. Static and dynamic weights are binned at 5ms.</p>
<p><bold>SM Movie 2: Dynamic weights for an exemplary local circuit</bold></p>
<p>Top row: Dynamic connectivity for an example local circuit (same as in <xref ref-type="fig" rid="fig5">Fig.5</xref>) from VISam area, session 819701982 for different trial times. Circles and triangles correspond to excitatory and inhibitory units, respectively. Units are numbered by local indices and ordered with respect to cortical layers. The size of blue (red) arrows reflects the dynamic weight of the corresponding connection at a given time. Bottom two rows: Dynamic weight <bold>W</bold><sub><bold>dyn</bold></sub> for each pair in the circuit. Dashed horizontal line is a maximum static weight. Static and dynamic weights are binned at 5ms.</p>
<p><bold>SM Movie 3: Laminar distribution of dynamic weights for VISp area</bold></p>
<p><bold>W</bold><sub><bold>off</bold></sub> for a VISp area for all n=26 animals (same as in <xref ref-type="fig" rid="fig7">Fig.7A</xref>) for different trial times. Units ordered by cortical depth and assigned to cortical layers. The circles diameter is proportional to the dynamic offset. Red, blue, and magenta circles correspond to excitatory-excitatory, inhibitory-inhibitory, and mixed connections, respectively.</p>
<p><bold>SM Movie 4: Dynamic weights along the hierarchy axis for all VIS areas</bold></p>
<p><bold>W</bold><sub><bold>off</bold></sub> for all VIS areas for all n=26 animals (same as in <xref ref-type="fig" rid="fig7">Fig.7B</xref>). Units ordered by cortical depth and assigned to cortical layers. The circles diameter is proportional to the dynamic offset. Red, blue, and magenta circles correspond to excitatory-excitatory, inhibitory-inhibitory, and mixed connections, respectively.</p>
</sec>
<ref-list>
<ref id="c1"><label>1</label><mixed-citation publication-type="journal"><string-name><surname>Hubel</surname>, <given-names>D. H.</given-names></string-name> &amp; <string-name><surname>Wiesel</surname>, <given-names>T. N.</given-names></string-name> <article-title>Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex</article-title>. <source>J Physiol</source> <volume>160</volume>, <fpage>106</fpage>–<lpage>154</lpage> (<year>1962</year>). <pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006837</pub-id></mixed-citation></ref>
<ref id="c2"><label>2</label><mixed-citation publication-type="journal"><string-name><surname>Mahalingam</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal> <article-title>A scalable and modular automated pipeline for stitching of large electron microscopy datasets</article-title>. <source>eLife</source> <volume>11</volume> (<year>2022</year>). <pub-id pub-id-type="doi">10.7554/eLife.76534</pub-id></mixed-citation></ref>
<ref id="c3"><label>3</label><mixed-citation publication-type="journal"><string-name><surname>Hawrylycz</surname>, <given-names>M. J.</given-names></string-name> <etal>et al.</etal> <article-title>An anatomically comprehensive atlas of the adult human brain transcriptome</article-title>. <source>Nature</source> <volume>489</volume>, <fpage>391</fpage>–<lpage>399</lpage> (<year>2012</year>). <pub-id pub-id-type="doi">10.1038/nature11405</pub-id></mixed-citation></ref>
<ref id="c4"><label>4</label><mixed-citation publication-type="journal"><string-name><surname>Oh</surname>, <given-names>S. W.</given-names></string-name> <etal>et al.</etal> <article-title>A mesoscale connectome of the mouse brain</article-title>. <source>Nature</source> <volume>508</volume>, <fpage>207</fpage>–<lpage>214</lpage> (<year>2014</year>). <pub-id pub-id-type="doi">10.1038/nature13186</pub-id></mixed-citation></ref>
<ref id="c5"><label>5</label><mixed-citation publication-type="journal"><string-name><surname>Harris</surname>, <given-names>J. A.</given-names></string-name> <etal>et al.</etal> <article-title>Hierarchical organization of cortical and thalamic connectivity</article-title>. <source>Nature</source> <volume>575</volume>, <fpage>195</fpage>–<lpage>202</lpage> (<year>2019</year>). <pub-id pub-id-type="doi">10.1038/s41586-019-1716-z</pub-id></mixed-citation></ref>
<ref id="c6"><label>6</label><mixed-citation publication-type="journal"><string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Tononi</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Kötter</surname>, <given-names>R.</given-names></string-name> <article-title>The Human Connectome: A Structural Description of the Human Brain</article-title>. <source>PLOS Computational Biology</source> <volume>1</volume>, <fpage>e42</fpage> (<year>2005</year>). <pub-id pub-id-type="doi">10.1371/journal.pcbi.0010042</pub-id></mixed-citation></ref>
<ref id="c7"><label>7</label><mixed-citation publication-type="journal"><string-name><surname>Calhoun</surname>, <given-names>Vince D.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Pearlson</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Adali</surname>, <given-names>T.</given-names></string-name> <article-title>The Chronnectome: Time-Varying Connectivity Networks as the Next Frontier in fMRI Data Discovery</article-title>. <source>Neuron</source> <volume>84</volume>, <fpage>262</fpage>–<lpage>274</lpage> (<year>2014</year>). <pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.015</pub-id></mixed-citation></ref>
<ref id="c8"><label>8</label><mixed-citation publication-type="journal"><string-name><surname>Bassett</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wymbs</surname>, <given-names>N. F.</given-names></string-name> &amp; <string-name><surname>Grafton</surname>, <given-names>S. T.</given-names></string-name> <article-title>Learning-induced autonomy of sensorimotor systems</article-title>. <source>Nature Neuroscience</source> <volume>18</volume>, <fpage>744</fpage>–<lpage>751</lpage> (<year>2015</year>). <pub-id pub-id-type="doi">10.1038/nn.3993</pub-id></mixed-citation></ref>
<ref id="c9"><label>9</label><mixed-citation publication-type="journal"><string-name><surname>Cole</surname>, <given-names>Michael W.</given-names></string-name>, <string-name><surname>Bassett Danielle</surname> <given-names>S.</given-names></string-name>, <string-name><surname>Power Jonathan</surname> <given-names>D.</given-names></string-name>, <string-name><surname>Braver Todd</surname> <given-names>S.</given-names></string-name> &amp; <string-name><surname>Petersen Steven</surname> <given-names>E.</given-names></string-name> <article-title>Intrinsic and Task-Evoked Network Architectures of the Human Brain</article-title>. <source>Neuron</source> <volume>83</volume>, <fpage>238</fpage>–<lpage>251</lpage> (<year>2014</year>). <pub-id pub-id-type="doi">10.1016/j.neuron.2014.05.014</pub-id></mixed-citation></ref>
<ref id="c10"><label>10</label><mixed-citation publication-type="journal"><string-name><surname>Shine</surname>, <given-names>James M.</given-names></string-name> <etal>et al.</etal> <article-title>The Dynamics of Functional Brain Networks: Integrated Network States during Cognitive Task Performance</article-title>. <source>Neuron</source> <volume>92</volume>, <fpage>544</fpage>–<lpage>554</lpage> (<year>2016</year>). <pub-id pub-id-type="doi">10.1016/j.neuron.2016.09.018</pub-id></mixed-citation></ref>
<ref id="c11"><label>11</label><mixed-citation publication-type="journal"><string-name><surname>Shine</surname>, <given-names>J. M.</given-names></string-name> <etal>et al.</etal> <article-title>Human cognition involves the dynamic integration of neural activity and neuromodulatory systems</article-title>. <source>Nature Neuroscience</source> <volume>22</volume>, <fpage>289</fpage>–<lpage>296</lpage> (<year>2019</year>). <pub-id pub-id-type="doi">10.1038/s41593-018-0312-0</pub-id></mixed-citation></ref>
<ref id="c12"><label>12</label><mixed-citation publication-type="journal"><string-name><surname>Shen</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Hutchison</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Bezgin</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Everling</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>McIntosh</surname>, <given-names>A. R.</given-names></string-name> <article-title>Network Structure Shapes Spontaneous Functional Connectivity Dynamics</article-title>. <source>The Journal of Neuroscience</source> <volume>35</volume>, <fpage>5579</fpage> (<year>2015</year>). <pub-id pub-id-type="doi">10.1523/JNEUROSCI.4903-14.2015</pub-id></mixed-citation></ref>
<ref id="c13"><label>13</label><mixed-citation publication-type="other"><string-name><surname>Nozari</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal> <article-title>Is the brain macroscopically linear? A system identification of resting state dynamics</article-title>. <source>bioRxiv</source>, 2020.2012.2021.423856 (<year>2021</year>). <pub-id pub-id-type="doi">10.1101/2020.12.21.423856</pub-id></mixed-citation></ref>
<ref id="c14"><label>14</label><mixed-citation publication-type="journal"><string-name><surname>Jun</surname>, <given-names>J. J.</given-names></string-name> <etal>et al.</etal> <article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title>. <source>Nature</source> <volume>551</volume>, <fpage>232</fpage>–<lpage>236</lpage> (<year>2017</year>). <pub-id pub-id-type="doi">10.1038/nature24636</pub-id></mixed-citation></ref>
<ref id="c15"><label>15</label><mixed-citation publication-type="other"><string-name><surname>Siegle</surname>, <given-names>J. H.</given-names></string-name> <etal>et al.</etal> <article-title>Survey of spiking in the mouse visual system reveals functional hierarchy</article-title>. <source>Nature</source> (<year>2021</year>). <pub-id pub-id-type="doi">10.1038/s41586-020-03171-x</pub-id></mixed-citation></ref>
<ref id="c16"><label>16</label><mixed-citation publication-type="journal"><string-name><surname>Sofroniew</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Flickinger</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>King</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Svoboda</surname>, <given-names>K.</given-names></string-name> <article-title>A large field of view two-photon mesoscope with subcellular resolution for in vivo imaging</article-title>. <source>eLife</source> <volume>5</volume>, <fpage>e14472</fpage> (<year>2016</year>). <pub-id pub-id-type="doi">10.7554/eLife.14472</pub-id></mixed-citation></ref>
<ref id="c17"><label>17</label><mixed-citation publication-type="journal"><string-name><surname>Engel</surname>, <given-names>T. A.</given-names></string-name>, <string-name><surname>Schölvinck</surname>, <given-names>M. L.</given-names></string-name> &amp; <string-name><surname>Lewis</surname>, <given-names>C. M.</given-names></string-name> <article-title>The diversity and specificity of functional connectivity across spatial and temporal scales</article-title>. <source>NeuroImage</source> <volume>245</volume>, <fpage>118692</fpage> (<year>2021</year>). <pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118692</pub-id></mixed-citation></ref>
<ref id="c18"><label>18</label><mixed-citation publication-type="journal"><string-name><surname>Engel</surname>, <given-names>T. A.</given-names></string-name> &amp; <string-name><surname>Steinmetz</surname>, <given-names>N. A.</given-names></string-name> <article-title>New perspectives on dimensionality and variability from large-scale cortical dynamics</article-title>. <source>Current Opinion in Neurobiology</source> <volume>58</volume>, <fpage>181</fpage>–<lpage>190</lpage> (<year>2019</year>). <pub-id pub-id-type="doi">10.1016/j.conb.2019.09.003</pub-id></mixed-citation></ref>
<ref id="c19"><label>19</label><mixed-citation publication-type="journal"><string-name><surname>Fujisawa</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Amarasingham</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Harrison</surname>, <given-names>M. T.</given-names></string-name> &amp; <string-name><surname>Buzsáki</surname>, <given-names>G.</given-names></string-name> <article-title>Behavior-dependent short-term assembly dynamics in the medial prefrontal cortex</article-title>. <source>Nature Neuroscience</source> <volume>11</volume>, <fpage>823</fpage>–<lpage>833</lpage> (<year>2008</year>). <pub-id pub-id-type="doi">10.1038/nn.2134</pub-id></mixed-citation></ref>
<ref id="c20"><label>20</label><mixed-citation publication-type="journal"><string-name><surname>Jia</surname>, <given-names>X.</given-names></string-name> <etal>et al.</etal> <article-title>Multi-regional module-based signal transmission in mouse visual cortex</article-title>. <source>Neuron</source> <volume>110</volume>, <fpage>1585</fpage>–<lpage>1598</lpage>.e1589 (<year>2022</year>). <pub-id pub-id-type="doi">10.1016/j.neuron.2022.01.027</pub-id></mixed-citation></ref>
<ref id="c21"><label>21</label><mixed-citation publication-type="journal"><string-name><surname>Semedo</surname>, <given-names>J. D.</given-names></string-name> <etal>et al.</etal> <article-title>Feedforward and feedback interactions between visual cortical areas use different population activity patterns</article-title>. <source>Nature Communications</source> <volume>13</volume>, <fpage>1099</fpage> (<year>2022</year>). <pub-id pub-id-type="doi">10.1038/s41467-022-28552-w</pub-id></mixed-citation></ref>
<ref id="c22"><label>22</label><mixed-citation publication-type="journal"><string-name><surname>Gokcen</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal> <article-title>Disentangling the flow of signals between populations of neurons</article-title>. <source>Nature Computational Science</source> <volume>2</volume>, <fpage>512</fpage>–<lpage>525</lpage> (<year>2022</year>). <pub-id pub-id-type="doi">10.1038/s43588-022-00282-5</pub-id></mixed-citation></ref>
<ref id="c23"><label>23</label><mixed-citation publication-type="journal"><string-name><surname>Okatan</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>M. A.</given-names></string-name> &amp; <string-name><surname>Brown</surname>, <given-names>E. N.</given-names></string-name> <article-title>Analyzing Functional Connectivity Using a Network Likelihood Model of Ensemble Neural Spiking Activity</article-title>. <source>Neural Computation</source> <volume>17</volume>, <fpage>1927</fpage>–<lpage>1961</lpage> (<year>2005</year>). <pub-id pub-id-type="doi">10.1162/0899766054322973</pub-id></mixed-citation></ref>
<ref id="c24"><label>24</label><mixed-citation publication-type="journal"><string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name> <etal>et al.</etal> <article-title>Spatio-temporal correlations and visual signalling in a complete neuronal population</article-title>. <source>Nature</source> <volume>454</volume>, <fpage>995</fpage>–<lpage>999</lpage> (<year>2008</year>). <pub-id pub-id-type="doi">10.1038/nature07140</pub-id></mixed-citation></ref>
<ref id="c25"><label>25</label><mixed-citation publication-type="journal"><string-name><surname>Stevenson</surname>, <given-names>I. H.</given-names></string-name>, <string-name><surname>Rebesco</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>L. E.</given-names></string-name> &amp; <string-name><surname>Körding</surname>, <given-names>K. P.</given-names></string-name> <article-title>Inferring functional connections between neurons</article-title>. <source>Current Opinion in Neurobiology</source> <volume>18</volume>, <fpage>582</fpage>–<lpage>588</lpage> (<year>2008</year>). <pub-id pub-id-type="doi">10.1016/j.conb.2008.11.005</pub-id></mixed-citation></ref>
<ref id="c26"><label>26</label><mixed-citation publication-type="journal"><string-name><surname>Kobayashi</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal> <article-title>Reconstructing neuronal circuitry from parallel spike trains</article-title>. <source>Nature Communications</source> <volume>10</volume>, <fpage>4468</fpage> (<year>2019</year>). <pub-id pub-id-type="doi">10.1038/s41467-019-12225-2</pub-id></mixed-citation></ref>
<ref id="c27"><label>27</label><mixed-citation publication-type="journal"><string-name><surname>Pandarinath</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal> <article-title>Inferring single-trial neural population dynamics using sequential auto-encoders</article-title>. <source>Nature Methods</source> <volume>15</volume>, <fpage>805</fpage>–<lpage>815</lpage> (<year>2018</year>). <pub-id pub-id-type="doi">10.1038/s41592-018-0109-9</pub-id></mixed-citation></ref>
<ref id="c28"><label>28</label><mixed-citation publication-type="journal"><string-name><surname>Kaufman</surname>, <given-names>M. T.</given-names></string-name>, <string-name><surname>Churchland</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Ryu</surname>, <given-names>S. I.</given-names></string-name> &amp; <string-name><surname>Shenoy</surname>, <given-names>K. V.</given-names></string-name> <article-title>Cortical activity in the null space: permitting preparation without movement</article-title>. <source>Nature Neuroscience</source> <volume>17</volume>, <fpage>440</fpage>–<lpage>448</lpage> (<year>2014</year>). <pub-id pub-id-type="doi">10.1038/nn.3643</pub-id></mixed-citation></ref>
<ref id="c29"><label>29</label><mixed-citation publication-type="journal"><string-name><surname>Keeley</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Zoltowski</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Aoi</surname>, <given-names>M. C.</given-names></string-name> &amp; <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name> <article-title>Modeling statistical dependencies in multiregion spike train data</article-title>. <source>Current Opinion in Neurobiology</source> <volume>65</volume>, <fpage>194</fpage>–<lpage>202</lpage> (<year>2020</year>). <pub-id pub-id-type="doi">10.1016/j.conb.2020.11.005</pub-id></mixed-citation></ref>
<ref id="c30"><label>30</label><mixed-citation publication-type="journal"><string-name><surname>Semedo</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Gokcen</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Machens</surname>, <given-names>C. K.</given-names></string-name>, <string-name><surname>Kohn</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Yu</surname>, <given-names>B. M.</given-names></string-name> <article-title>Statistical methods for dissecting interactions between brain areas</article-title>. <source>Current Opinion in Neurobiology</source> <volume>65</volume>, <fpage>59</fpage>–<lpage>69</lpage> (<year>2020</year>). <pub-id pub-id-type="doi">10.1016/j.conb.2020.09.009</pub-id></mixed-citation></ref>
<ref id="c31"><label>31</label><mixed-citation publication-type="book"><string-name><surname>Graber</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Loh</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Vlasov</surname>, <given-names>Y. A.</given-names></string-name> &amp; <string-name><surname>Schwing</surname>, <given-names>A.</given-names></string-name> in <source>Proc. 33rd Annu. Conf. Neural Inf. Process. Syst</source>. (<ext-link ext-link-type="uri" xlink:href="https://openreview.net/pdf?id=S1leV7t8IB">https://openreview.net/pdf?id=S1leV7t8IB</ext-link>, <publisher-loc>Vancouver</publisher-loc>, <year>2019</year>).</mixed-citation></ref>
<ref id="c32"><label>32</label><mixed-citation publication-type="other"><string-name><surname>Tancik</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains</article-title>. <source>arXiv e-prints</source>, arXiv:2006.10739 (<year>2020</year>). <pub-id pub-id-type="doi">10.48550/arXiv.2006.10739</pub-id></mixed-citation></ref>
<ref id="c33"><label>33</label><mixed-citation publication-type="journal"><string-name><surname>Harrison</surname>, <given-names>M. T.</given-names></string-name> &amp; <string-name><surname>Geman</surname>, <given-names>S.</given-names></string-name> <article-title>A Rate and History-Preserving Resampling Algorithm for Neural Spike Trains</article-title>. <source>Neural Computation</source> <volume>21</volume>, <fpage>1244</fpage>–<lpage>1258</lpage> (<year>2009</year>). <pub-id pub-id-type="doi">10.1162/neco.2008.03-08-730</pub-id></mixed-citation></ref>
<ref id="c34"><label>34</label><mixed-citation publication-type="journal"><string-name><surname>Amarasingham</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Harrison</surname>, <given-names>M. T.</given-names></string-name>, <string-name><surname>Hatsopoulos</surname>, <given-names>N. G.</given-names></string-name> &amp; <string-name><surname>Geman</surname>, <given-names>S.</given-names></string-name> <article-title>Conditional modeling and the jitter method of spike resampling</article-title>. <source>J Neurophysiol</source> <volume>107</volume>, <fpage>517</fpage>–<lpage>531</lpage> (<year>2012</year>). <pub-id pub-id-type="doi">10.1152/jn.00633.2011</pub-id></mixed-citation></ref>
<ref id="c35"><label>35</label><mixed-citation publication-type="journal"><string-name><surname>Platkiewicz</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Saccomano</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>McKenzie</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>English</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Amarasingham</surname>, <given-names>A.</given-names></string-name> <article-title>Monosynaptic inference via finely-timed spikes</article-title>. <source>J Comput Neurosci</source> <volume>49</volume>, <fpage>131</fpage>–<lpage>157</lpage> (<year>2021</year>). <pub-id pub-id-type="doi">10.1007/s10827-020-00770-5</pub-id></mixed-citation></ref>
<ref id="c36"><label>36</label><mixed-citation publication-type="other"><string-name><surname>Gerstein</surname>, <given-names>G. L.</given-names></string-name> <article-title>Joint Peri Stimulus Time Histogram (JPSTH)</article-title>. <source>Encyclopedia of Computational Neuroscience</source>, <fpage>1</fpage>–<lpage>4</lpage> (<year>2013</year>). <pub-id pub-id-type="doi">10.1007/978-1-4614-7320-6_397-1</pub-id></mixed-citation></ref>
<ref id="c37"><label>37</label><mixed-citation publication-type="journal"><string-name><surname>Brody</surname>, <given-names>C. D.</given-names></string-name> <article-title>Correlations Without Synchrony</article-title>. <source>Neural Computation</source> <volume>11</volume>, <fpage>1537</fpage>–<lpage>1551</lpage> (<year>1999</year>). <pub-id pub-id-type="doi">10.1162/089976699300016133</pub-id></mixed-citation></ref>
<ref id="c38"><label>38</label><mixed-citation publication-type="web"><collab>Optotagging Analysis</collab>. <source>Tutorial overview</source> (<ext-link ext-link-type="uri" xlink:href="https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_optotagging.html">https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_optotagging.html</ext-link>, <year>2022</year>).</mixed-citation></ref>
<ref id="c39"><label>39</label><mixed-citation publication-type="journal"><string-name><surname>Cowley</surname>, <given-names>B. R.</given-names></string-name> <etal>et al.</etal> <article-title>DataHigh: graphical user interface for visualizing and interacting with highdimensional neural activity</article-title>. <source>Journal of Neural Engineering</source> <volume>10</volume>, <fpage>066012</fpage> (<year>2013</year>). <pub-id pub-id-type="doi">10.1088/1741-2560/10/6/066012</pub-id></mixed-citation></ref>
<ref id="c40"><label>40</label><mixed-citation publication-type="other"><string-name><surname>Gao</surname>, <given-names>P.</given-names></string-name> <etal>et al.</etal> <article-title>A theory of multineuronal dimensionality, dynamics and measurement</article-title>. <source>bioRxiv</source>, <fpage>214262</fpage> (<year>2017</year>). <pub-id pub-id-type="doi">10.1101/214262</pub-id></mixed-citation></ref>
<ref id="c41"><label>41</label><mixed-citation publication-type="other"><string-name><surname>Kingma</surname>, <given-names>D. P.</given-names></string-name> &amp; <string-name><surname>Ba</surname>, <given-names>J.</given-names></string-name> <article-title>Adam: A Method for Stochastic Optimization</article-title>. <source>arXiv e-prints</source>, arXiv:1412.6980 (<year>2014</year>). <pub-id pub-id-type="doi">10.48550/arXiv.1412.6980</pub-id></mixed-citation></ref>
<ref id="c42"><label>42</label><mixed-citation publication-type="web"><collab>GLMCC: The generalized linear model for spike cross-correlation</collab> (<ext-link ext-link-type="uri" xlink:href="https://github.com/NII-Kobayashi/GLMCC">https://github.com/NII-Kobayashi/GLMCC</ext-link>, <year>2019</year>).</mixed-citation></ref>
<ref id="c43"><label>43</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>Q.</given-names></string-name> <etal>et al.</etal> <article-title>The Allen Mouse Brain Common Coordinate Framework: A 3D Reference Atlas</article-title>. <source>Cell</source> <volume>181</volume>, <fpage>936</fpage>–<lpage>953</lpage>.e920 (<year>2020</year>). <pub-id pub-id-type="doi">10.1016/j.cell.2020.04.007</pub-id></mixed-citation></ref>
<ref id="c44"><label>44</label><mixed-citation publication-type="other"><string-name><surname>Kobayashi</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal> <article-title>Synthetic spike data generated by a network of 1000 hodgkin-huxley type neurons</article-title>. <source>Figshare</source> (<year>2019</year>). &lt;<pub-id pub-id-type="doi">10.6084/m9.figshare.9637904</pub-id>&gt;.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95449.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Latham</surname>
<given-names>Peter</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents a <bold>useful</bold> method for using multi-electrode spike recordings to track the time-varying functional connectivity between neurons. However, the evidence is <bold>incomplete</bold>: a demonstration of the utility of the method relative to conventional approaches is needed. If such a demonstration is made, this could be a tool for gaining insight into circuit structure.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95449.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work proposes a new method, DyNetCP, for inferring dynamic functional connectivity between neurons from spike data. DyNetCP is based on a neural network model with a two-stage model architecture of static and dynamic functional connectivity.</p>
<p>This work evaluates the accuracy of the synaptic connectivity inference and shows that DyNetCP can infer the excitatory synaptic connectivity more accurately than a state-of-the-art model (GLMCC) by analyzing the simulated spike trains. Furthermore, it is shown that the inference results obtained by DyNetCP from large-scale in-vivo recordings are similar to the results obtained by the existing methods (jitter-corrected CCG and JPSTH). Finally, this work investigates the dynamic connectivity in the primary visual area VISp and in the visual areas using DyNetCP.</p>
<p>Strengths:</p>
<p>The strength of the paper is that it proposes a method to extract the dynamics of functional connectivity from spike trains of multiple neurons. The method is potentially useful for analyzing parallel spike trains in general, as there are only a few methods (e.g. Aertsen et al., J. Neurophysiol., 1989, Shimazaki et al., PLoS Comput Biol 2012) that infer the dynamic connectivity from spikes. Furthermore, the approach of DyNetCP is different from the existing methods: while the proposed method is based on the neural network, the previous methods are based on either the descriptive statistics (JSPH) or the Ising model.</p>
<p>Weaknesses:</p>
<p>Although the paper proposes a new method, DyNetCP, for inferring the dynamic functional connectivity, its strengths are neither clear nor directly demonstrated in this paper. That is, insufficient analyses are performed to support the usefulness of DyNetCP.</p>
<p>First, this paper attempts to show the superiority of DyNetCP by comparing the performance of synaptic connectivity inference with GLMCC (Figure 2). However, the improvement in the synaptic connectivity inference does not seem to be convincing. While this paper compares the performance of DyNetCP with a state-of-the-art method (GLMCC), there are several problems with the comparison. For example:</p>
<p>(1) This paper focused only on excitatory connections (i.e., ignoring inhibitory neurons).</p>
<p>(2) This paper does not compare with existing neural network-based methods (e.g., CoNNECT: Endo et al. Sci. Rep. 2021; Deep learning: Donner et al. bioRxiv, 2024).</p>
<p>(3) Only a population of neurons generated from the Hodgkin-Huxley model was evaluated.</p>
<p>Thus, the results in this paper are not sufficient to conclude the superiority of DyNetCP in the estimation of synaptic connections. In addition, this paper compares the proposed method with the standard statistical methods Jitter-corrected CCG (Figure 3) and JPSTH (Figure 4). Unfortunately, these results do not show the superiority of the proposed method. It only shows that the results obtained by the proposed method are consistent with those obtained by the existing methods (CCG or JPSTH). This paper also compares the proposed method with standard statistical methods, such as jitter-corrected CCG (Figure 3) and JPSTH (Figure 4). It only shows that the results obtained by the proposed method are consistent with those obtained by the existing methods (CCG or JPSTH), which does not show the superiority of the proposed method.</p>
<p>In summary, although DyNetCP has the potential to infer synaptic connections more accurately than existing methods, the paper does not provide sufficient analysis to make this claim. It is also unclear whether the proposed method is superior to the existing methods for estimating functional connectivity, such as jitter-corrected CCG and JPSTH. Thus, the strength of DyNetCP is unclear.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95449.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Here the authors describe a model for tracking time-varying coupling between neurons from multi-electrode spike recordings. Their approach extends a GLM with static coupling between neurons to include dynamic weights, learned by a long-short-term-memory (LSTM) model. Each connection has a corresponding LSTM embedding and is read out by a multi-layer perceptron to predict the time-varying weight.</p>
<p>Strengths:</p>
<p>This is an interesting approach to an open problem in neural data analysis. I think, in general, the method would be interesting to computational neuroscientists.</p>
<p>Weaknesses:</p>
<p>It is somewhat difficult to interpret what the model is doing. I think it would be worthwhile to add some additional results that make it more clear what types of patterns are being described and how.</p>
<p>Major Issues:</p>
<p>Simulation for dynamic connectivity. It certainly seems doable to simulate a recurrent spiking network whose weights change over time, and I think this would be a worthwhile validation for this DyNetCP model. In particular, I think it would be valuable to understand how much the model overfits, and how accurately it can track known changes in coupling strength. If the only goal is &quot;smoothing&quot; time-varying CCGs, there are much easier statistical methods to do this (c.f. McKenzie et al. Neuron, 2021. Ren, Wei, Ghanbari, Stevenson. J Neurosci, 2022), and simulations could be useful to illustrate what the model adds beyond smoothing.</p>
<p>Stimulus vs noise correlations. For studying correlations between neurons in sensory systems that are strongly driven by stimuli, it's common to use shuffling over trials to distinguish between stimulus correlations and &quot;noise&quot; correlations or putative synaptic connections. This would be a valuable comparison for Figure 5 to show if these are dynamic stimulus correlations or noise correlations. I would also suggest just plotting the CCGs calculated with a moving window to better illustrate how (and if) the dynamic weights differ from the data.</p>
</body>
</sub-article>
</article>