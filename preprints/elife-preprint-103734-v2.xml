<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">103734</article-id>
<article-id pub-id-type="doi">10.7554/eLife.103734</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.103734.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Humans adapt rationally to approximate estimates of uncertainty</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2170-0677</contrib-id>
<name>
<surname>Pulcu</surname>
<given-names>Erdem</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<email>erdem.pulcu@psych.ox.ac.uk</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Browning</surname>
<given-names>Michael</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a2">b</xref>
</contrib>
<aff id="a1"><label>a</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>Department of Psychiatry, University of Oxford</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a2"><label>b</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04c8bjx39</institution-id><institution>Oxford Health NHS Trust</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Diaconescu</surname>
<given-names>Andreea Oliviana</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country country="CA">Canada</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: MB has received travel expenses from Lundbeck for attending conferences and consultancy from Jansen, CHDR and Novartis. EP declares no potential conflict of interest.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-01-13">
<day>13</day>
<month>01</month>
<year>2025</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-06-27">
<day>27</day>
<month>06</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP103734</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-10-03">
<day>03</day>
<month>10</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-09-19">
<day>19</day>
<month>09</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.11.26.568699"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2025-01-13">
<day>13</day>
<month>01</month>
<year>2025</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.103734.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.103734.1.sa3">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.103734.1.sa2">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.103734.1.sa1">Reviewer #2 (Public review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.103734.1.sa0">Author response:</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Pulcu &amp; Browning</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Pulcu &amp; Browning</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-103734-v2.pdf"/>
<abstract>
<title>Summary</title>
<p>Efficient learning requires estimation of, and adaptation to, different forms of uncertainty. If uncertainty is caused by randomness in outcomes (noise), observed events should have less influence on beliefs, whereas if uncertainty is caused by a change in the process being estimated (volatility) the influence of events should increase. Previous work has demonstrated that humans respond appropriately to changes in volatility, but there is less evidence of a rational response to noise. Here, we test adaptation to variable levels of volatility and noise in human participants, using choice behaviour and pupillometry as a measure of the central arousal system. We find that participants adapt as expected to changes in volatility, but not to changes in noise. Using a Bayesian observer model, we demonstrate that participants are, in fact, adapting to estimated noise, but that their estimates are imprecise, leading them to misattribute it as volatility and thus to respond inappropriately.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Uncertainty</kwd>
<kwd>Bayesian Models</kwd>
<kwd>Pupillometry</kwd>
<kwd>Learning</kwd>
</kwd-group>
<funding-group>
<award-group id="funding-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/03x94j517</institution-id>
<institution>Medical Research Council</institution>
</institution-wrap>
</funding-source>
<award-id>MR/N008103/1</award-id>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>In this revision, we have done formal model comparisons and analysed our data with alternative models from different model families for robustness.</p></fn>
</fn-group>
</notes>
</front>
<body>
<p>It is much easier to respond appropriately to an event if we know what has caused it. For example, if heavy traffic means that our drive into work takes longer than normal, the best course of action the next time we have to make the journey depends on what caused the traffic to be heavier (<xref ref-type="bibr" rid="c27">Yu &amp; Dayan, 2005</xref>). If it was caused by a one-off or random event, such as a broken-down lorry, then we should continue using the same route as before, whereas if it was caused by some longer-term change, perhaps there are new road works nearby disrupting the traffic, we should consider a different route. Frequently, however, the causes of events are not obvious, we experience the heavy traffic but aren’t sure why it has occurred. In these situations, the best we can do is make an educated guess, based on our experience, about what broad type of causal process has led to recent events. In the case of the drive into work, if the traffic has been heavier for a number of days in a row it is likely that some prolonged shift has occurred, and we should change routes, whereas if the traffic changes noisily from day to day, then we should probably stick with our usual route. In the learning literature, this problem is often framed as a competitive attribution of uncertainty to one of two types; expected uncertainty, which is caused by the variability of noisy associations and unexpected uncertainty, which is caused by longer lasting changes (sometimes called volatility) in an association (<xref ref-type="bibr" rid="c3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="c16">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="c21">Pulcu &amp; Browning, 2017</xref>; <xref ref-type="bibr" rid="c27">Yu &amp; Dayan, 2005</xref>). The behavioural importance of this attribution process can be seen in the driving example given above; an event caused by noise requires the opposite behavioural response (continuing to use the same route) than the same event caused by volatility (switching routes). Consequently, effective decision making often depends on the accurate attribution of uncertainty, with misattribution having a substantial detrimental effect on choice (<xref ref-type="bibr" rid="c22">Pulcu &amp; Browning, 2019</xref>).</p>
<p>The influence of events on subsequent choice can be estimated within a reinforcement learning framework as the learning rate parameter (<xref ref-type="bibr" rid="c24">Sutton &amp; Barto, 2018</xref>), with a higher learning rate indicating a greater influence of the event on behaviour. As described above, the normative response to changes in volatility and noise is to use a higher learning rate when volatility is high and/or noise is low (<xref ref-type="bibr" rid="c22">Pulcu &amp; Browning, 2019</xref>; <xref ref-type="bibr" rid="c27">Yu &amp; Dayan, 2005</xref>). A large number of studies have found the predicted increase in learning rates in response to higher outcome volatility in human learners (<xref ref-type="bibr" rid="c3">Behrens et al., 2007</xref>, <xref ref-type="bibr" rid="c2">2008</xref>; <xref ref-type="bibr" rid="c4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="c8">Gagne et al., 2020</xref>; <xref ref-type="bibr" rid="c16">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="c21">Pulcu &amp; Browning, 2017</xref>). In contrast, the evidence for adaptation of learning in response to changes in outcome noise is less complete. Previous studies have described the expected reduction of learning rates when outcome noise is high, but only when the level of noise is explicitly signalled in a task (<xref ref-type="bibr" rid="c7">Diederen &amp; Schultz, 2015</xref>), or when it is made unambiguous by virtue of being very much smaller than changes in outcome caused by volatility (<xref ref-type="bibr" rid="c17">Nassar et al., 2010</xref>, <xref ref-type="bibr" rid="c16">2012</xref>). As illustrated in the driving example above, we are often faced with situations in which there exists significant uncertainty about whether an event has been caused by volatility or noise. To date however, the degree to which human learners are able to discriminate between these types of uncertainty, when they are not explicitly labelled, has not been closely examined.</p>
<p>From a neurobiological perspective, activity of central modulatory neurotransmitter systems have been argued to represent distinct sources of uncertainty during learning, with central norepinepheric (NE)/locus coeruleus (LC) activity described as signalling changes in the associations (i.e. volatility) and central cholinergic activity representing noise (<xref ref-type="bibr" rid="c27">Yu &amp; Dayan, 2005</xref>). Electrophysiological measures of LC activity in non-human primates have been shown to correlate with pupil dilation (<xref ref-type="bibr" rid="c10">Joshi et al., 2016</xref>) suggesting it may be possible to estimate activity in this system in humans using pupilometry. Taking this approach, indirect support for this role of the NE system has been provided by studies of human participants that report greater pupillary size in volatile relative to stable contexts (<xref ref-type="bibr" rid="c4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="c16">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="c21">Pulcu &amp; Browning, 2017</xref>). However, the pupil also responds to other learning signals, such as surprise (<xref ref-type="bibr" rid="c4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="c18">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="c20">Preuschoff et al., 2011</xref>) and has been reported as being smaller when outcome noise is high (<xref ref-type="bibr" rid="c16">Nassar et al., 2012</xref>). Neuroimaging evidence suggests an association between activity in other central neurotransmitter nuclei, including the cholinergic basal forebrain, and pupil dilation (<xref ref-type="bibr" rid="c6">de Gee et al., 2017</xref>). Overall, this suggests that the pupillary signal may reflect a more general belief updating process (<xref ref-type="bibr" rid="c18">O’Reilly et al., 2013</xref>) rather than a specific volatility signal and thus that, like learning rates, pupil size should increase when noise is reduced as well as when volatility is increased.</p>
<p>In this paper we test whether human participants modify their learning in situations in which the attribution of uncertainty as volatility or noise is challenging (<xref rid="fig1" ref-type="fig">Figure 1a-c</xref>). We report the results of a study in which participants completed a learning task during which the noise and volatility of both win and loss outcomes were independently manipulated. Participant behaviour was characterised using learning rate parameters derived from reinforcement learning models of choice, while interpretation of the results was facilitated by a Bayesian Ideal Observer model that was developed to provide a benchmark comparator to participant behaviour (<xref ref-type="bibr" rid="c3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c16">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="c19">Piray &amp; Daw, 2021</xref>; <xref ref-type="bibr" rid="c23">Pulcu et al., 2022</xref>) and by the collection of pupillometry data as a physiological marker of central neurotransmitter function (<xref ref-type="bibr" rid="c6">de Gee et al., 2017</xref>; <xref ref-type="bibr" rid="c10">Joshi et al., 2016</xref>). It was predicted that human participants would be able to adapt appropriately to the cause of the events they encountered—using a higher learning rate, and displaying increased pupil size, when volatility was high and when noise was low for both win and loss outcomes (<xref rid="fig1" ref-type="fig">Figure 1d</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>The Magnitude Learning Task</title>
<p><bold>(a)</bold> Timeline of one trial from the learning task. On each trial participants were presented with two abstract shapes and were asked to choose one of them. The empty bars above and below the fixation cross represented the total available wins and losses for the trial, the full length of each bar was equivalent to £1. Participants chose a shape and then were shown the proportion of each outcome that was associated with their chosen shape as coloured regions of the bars (green for wins and red for losses). The empty portions of the bars indicated the win and loss magnitudes associated with the unchosen option, allowing participants to infer which shape would have been the better option on every trial. The task consisted of six blocks of sixty trials each. The volatility and noise of the two outcomes varied independently between blocks with different shapes used in each block. Panel <bold>b</bold> illustrates outcomes from the four block types. As can be seen blocks with high volatility and low noise (top left), and those with low volatility and high noise (bottom right), present participants with a similar range of magnitudes. Participants therefore have to distinguish whether variability in the outcomes is caused by volatility or noise from the temporal structure of the outcomes rather than the size of changes in magnitude (cf; <xref ref-type="bibr" rid="c7">Diederen &amp; Schultz, 2015</xref>; <xref ref-type="bibr" rid="c13">Krishnamurthy et al., 2017</xref>; <xref ref-type="bibr" rid="c16">Nassar et al., 2012</xref>). Panel <bold>c</bold> shows two example blocks (one block in grey, the other in white) with both win (green) and loss outcomes (red) displayed. Panel <bold>d</bold> shows the expected adaptation of learning rates in response to the manipulation of volatility and noise; for both win and loss outcomes, learning rates should be increased when volatility is high and when noise is low.</p></caption>
<graphic xlink:href="568699v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s1">
<title>Results</title>
<sec id="s1a">
<title>Participant Demographics</title>
<p>70 participants (see Supplementary Table 1 for demographic information) completed a learning task in which they had to choose one of two stimuli based on the separately estimated magnitudes of win and loss outcomes associated with the stimuli (<xref rid="fig1" ref-type="fig">Figure 1</xref>). Participants were able to learn the best option to choose in the task, selecting the most highly rewarded option on an average of 71% of trials (range 65% - 74%).</p>
</sec>
<sec id="s1b">
<title>Experimental Manipulation of Volatility and Noise Influences Participant Choice Behaviour</title>
<p>As explained above, high levels of volatility and low levels of noise should increase the degree to which outcomes influence choice behaviour. A crude metric of this effect is provided by examining participant choice as a function of the previous outcome. In the task, a win outcome of &gt;50p or a loss outcome of &lt;50p associated with Shape A prompts participants to select Shape A in the subsequent trial, with the other outcomes (i.e. win &lt;50p and loss &gt;50p) prompting choice of Shape B. The influence of the outcomes on choice can therefore be roughly estimated as the relative proportion of trials in which Shape A was chosen when it was prompted by a previous outcome of a given magnitude, compared to when Shape B was prompted. Analysis of this choice metric (<xref rid="fig2" ref-type="fig">Figure 2a-b</xref>) found the expected effect of volatility, with participant choice being more influenced by previous outcomes when volatility was higher (F(1,696)=99.8, <italic>p</italic>&lt;0.001). An effect of noise was observed, but in the opposite direction to expected, with outcomes influencing choice more when noise was increased (F(1,696)=4.79, <italic>p</italic>=0.03). No significant difference between the influence of win and loss outcomes was found (F(1,696)=1, <italic>p</italic>=0.32) and there was no interaction between volatility and noise (F(1,693)=0.61, <italic>p</italic>=0.4). Having found some evidence of an impact of the uncertainty manipulations on a crude measure of subject choice we next sought to characterise this effect using reinforcement learning models fitted to participant choices.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>The impact of uncertainty manipulations on participant choice.</title>
<p>Panels <bold>a</bold> and <bold>b</bold> report a summary metric for the effect of win and loss outcomes on subsequent choice. The metric was calculated as the proportion of trials in which an outcome of magnitude 51-65 associated with Shape A was followed by choice of the shape prompted by the outcome (i.e. Shape A for win outcomes, Shape B for loss outcomes) relative to when the outcome magnitude was 49-35 (see methods and materials for more details). We focused on this outcome range as these range of magnitudes were covered by all volatility x noise conditions and it was dictated by the relatively smaller range coverage in the low volatility low noise condition (also see <xref ref-type="fig" rid="fig1">Figure 1C</xref> loss outcomes shown in red between trials 60-120). The higher this number, the greater the tendency for a participant to choose the shape prompted by an outcome. As can be seen, the outcome of previous trials had a greater influence on participant choice when volatility was high, with a small effect of noise, in the opposite direction to that predicted. Panels <bold>c</bold> and <bold>d</bold> report the win and loss learning rates estimated from the same data. Again, the expected effect of volatility is observed, this time with no consistent effect of noise. Bars represent the mean (±SEM) of the data, with individual data points superimposed.</p></caption>
<graphic xlink:href="568699v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s1c">
<title>Participants Adjust Normatively to Changes in Volatility but not Noise</title>
<p>We aimed to capture the computational process that underlies participant choice behaviour by fitting different reinforcement learning models to choice data separately for each block of the task and each participant. The best fitting RL model included separate learning rates for win and loss outcomes allowing estimation of the degree to which participants adjusted these learning rates in response to the block-wise changes in outcome volatility and noise (see supplementary Materials and Methods for model comparison and selection analyses).</p>
<p>Consistent with the analysis of choice data reported above, there was a significant main effect of volatility (<xref rid="fig2" ref-type="fig">Figure 2c-d</xref>; F(1,696)=22.2, <italic>p</italic>&lt;0.001), with a higher learning rate used when volatility was high. There was no main effect of noise (F(1,696)=0.63, <italic>p</italic>=0.43) on learning rate or outcome valence (F(1,696)=0.15, <italic>p</italic>=0.7). An interaction between volatility and noise (F(1,693)=7.74, <italic>p</italic>=0.006) was also significant. A higher volatility led to a significantly raised learning rate when noise was low (F(1,383)=27.1, <italic>p</italic>&lt;0.01), with a non-significant increase when noise was high (F(1,311)=1.13, <italic>p</italic>=0.29). Higher noise was associated with a non-significant reduction in learning rates when volatility was high (F(1,347)=2.57, <italic>p</italic>=0.11) but to a significant increase in learning rate when volatility was low (F(1,347)=4.7, p=0.031).</p>
<p>In summary, analysis of both crude choice data and learning rates indicates that participants adapted appropriately to changes in the volatility of learned associations but did not show a consistent response to changes in noise. In the next section we utilise a Bayesian Observer Model (BOM) to investigate potential causes for this relative insensitivity to noise.</p>
</sec>
<sec id="s1d">
<title>Using a Bayesian Observer Model to Characterise Noise Insensitivity</title>
<p>Bayesian Observer Models (BOM) can be used as normative benchmarks against which human behaviour may be compared (<xref ref-type="bibr" rid="c3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c16">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="c19">Piray &amp; Daw, 2021</xref>; <xref ref-type="bibr" rid="c23">Pulcu et al., 2022</xref>). BOMs are generally not fit to participant choice, rather these models invert a generative process assumed to underlie observed events and provide an estimate of the belief of an idealised agent exposed to the same outcomes as participants. We developed a BOM (<xref ref-type="bibr" rid="c23">Pulcu et al., 2022</xref>) based on the generative process underlying the outcome magnitudes of our task (<xref rid="fig3" ref-type="fig">Figure 3a</xref>). The BOM explicitly estimates the volatility and noise of the outcomes and uses these estimates to influence its belief about the likely magnitude of upcoming outcomes (see methods for more details). We first tested whether the BOM reproduced the normative learning rate adaptation to changes in volatility and noise described in the introduction, by exposing the model to the same outcomes as participants and using the model’s belief about the likely magnitude of the win and loss outcome on each trial to generate choices. We then estimated the effective learning rate of the model by fitting the same RL model used to analyse participants’ choices to the model’s choices. These learning rates are presented in <xref rid="fig3" ref-type="fig">Figure 3f</xref> (<xref rid="fig3" ref-type="fig">Figure 3e</xref> reproduces the learning rates of participants, averaged across wins and losses, for comparison). As can be seen the BOM adapts as expected, using a higher learning rate both when volatility increases (F(1,696)=422, <italic>p</italic>&lt;0.001) and when noise decreases (F(1,696)=21.2, <italic>p</italic>&lt;0.001). No effect of outcome valence or interaction between volatility and noise (all <italic>p</italic>&gt;0.09) was observed.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>The Behaviour of Bayesian Observer Models.</title>
<p>Bayesian Observer Models (BOM) invert generative descriptions of a process, indicating how an idealised observer may learn. We developed a BOM based on the generative model of the task we used (<bold>a</bold>). Details of the BOM are provided in the methods, briefly it assumes that observations (<italic>y</italic><sub><italic>i</italic></sub>) are generated from a Gaussian distribution with a mean (<italic>mu</italic><sub><italic>i</italic></sub>) and standard deviation (<italic>SD</italic><sub><italic>i</italic></sub>). Between observations, the mean changes with the rate of change controlled by the volatility parameter (<italic>vmu</italic><sub><italic>i</italic></sub>). The standard deviation and volatility of this model estimate the noise and volatility described for the task. The last parameters control the change in volatility (<italic>kmu</italic>) and standard deviation (vs) between observations, allowing the model to account for different periods when these types of uncertainty are high and others when they are low. The BOM adjusts it learning rate in a normative fashion (<bold>f</bold>), increasing it when volatility is higher, or noise is lower. The BOM was lesioned in a number of different ways in an attempt to recapitulate the learning rate adaptation observed in participants (shown in panel e). Removing the ability of the BOM to adapt to changes in volatility (<bold>b</bold>) or noise (<bold>c</bold>) did not achieve this goal (<bold>g</bold>,<bold>h</bold>). However, degrading the BOMs representation of uncertainty (<bold>d</bold>) was able to recapitulate the behavioural pattern of participants (i). Bars represent the mean (±SEM) of participant learning rates, with raw data points presented as circles behind each bar.</p></caption>
<graphic xlink:href="568699v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Having shown that an optimal learner adjusts its learning rate to changes in volatility and noise as expected, we next sought to understand the relative noise insensitivity of participants. In these analyses we “lesion” the BOM, to reduce its performance in some way, and then assess whether doing so recapitulates the pattern of learning rate adaptation observed for participants (<xref rid="fig3" ref-type="fig">Fig 3e</xref>). In other words, we damage the model so it performs less well and then assess whether this damage makes the behaviour of the BOM (shown in <xref rid="fig3" ref-type="fig">Fig 3f</xref>) more closely resemble that seen in participants (<xref rid="fig3" ref-type="fig">Fig 3e</xref>). First, we tested the impact of completely removing the ability of the BOM to adjust to changes in either volatility (<xref rid="fig3" ref-type="fig">Figure 3b</xref>) or noise (<xref rid="fig3" ref-type="fig">Figure 3c</xref>) by removing the top nodes of the model (i.e. <italic>kmu</italic> or <italic>vs</italic> respectively). Removing these nodes forces the BOM to estimate the mean volatility or noise across all task blocks rather than estimating local periods where they are higher or lower (see supplementary video). As illustrated in <xref rid="fig3" ref-type="fig">Figure 3g-h</xref>, neither of these lesions recapitulates the pattern of learning rates observed in participants, with the volatility lesioned model attributing increased volatility to noise and thus decreasing its learning rate during periods of higher volatility (main effect of volatility; F(1,696)=11.9, p&lt;0.001) and the SD-lesioned model treating any form of uncertainty as volatility and thus increasing its learning rate in response to increased noise (main effect of noise; F(1,696)=227, p&lt;0.001). This suggests that human participants are able to adapt to changes in outcome volatility and noise to some degree but are less sensitive to these changes than the intact BOM.</p>
<p>We next assessed whether a relative degrading of the model’s representation of volatility and noise (<xref rid="fig3" ref-type="fig">Figure 3d</xref>) altered its behaviour in a manner similar to participants. This was achieved by independently coarsening the model’s representation of volatility and noise, with the degree of coarsening selected to make the model’s choices as similar as possible to those of a given participant. Details of this coarsening process are provided in the methods section, but in simple terms, at one extreme, the intact model’s beliefs about current volatility and noise are represented as probability distributions over many possible values, with the number of values used gradually reduced during coarsening, until the coarsest model treats each form of uncertainty as being either “high” or “low”. As can be seen from <xref rid="fig3" ref-type="fig">Figure 3i</xref>, this relative degrading of the model’s representation of uncertainty more closely recapitulated the learning rates observed in participants, with a significant increase in learning rate in response to increased volatility (F(1,696)=59, <italic>p</italic>&lt;0.001) and no effect of noise (F(1,696)=2.3, <italic>p</italic>=0.13). In total the BOM fitted to participant choices had 5 parameters (i.e. volatility and SD acuity for rewards and losses and a single inverse temperature term). This was compared with two reinforcement learning models: the measurement model described previously, which was fitted to individual blocks and therefore had many more parameters (18 in total; learning rates for wins and losses for each block, one inverse temperature term per block), and a simple version of the same model which was fitted across all blocks and had 3 parameters in total (win and loss LR and one inverse temperature parameter). Model comparison between the BOM and the RW models based on BIC scores favoured the BOM (mean (SD) for BOM; 235 (54), for complex RL measurement model; 281 (57), for simple RL model; 246 (58)).</p>
<p>In the next sections we characterise how coarsening the BOM changes its behaviour and assess whether it provides an accurate account of participants’ noise insensitivity.</p>
</sec>
<sec id="s1e">
<title>The Degraded BOM Misattributes Noise as Volatility</title>
<p>The BOM was degraded by reducing the number of bins it used to represent volatility and/or noise, until its behaviour most closely matched that of participants. This process led to a greater coarsening of the noise than the volatility dimension (<xref rid="fig4" ref-type="fig">Figure 4a</xref>; F(1,69)=49, <italic>p</italic>&lt;0.001), with no effect of outcome valence (F(1,69)=0.73, <italic>p</italic>=0.4), suggesting that the degraded model maintained a generally lessprecise representation of noise than volatility. In order to investigate the impact of this coarsening on the model’s beliefs, we used the degraded BOM’s estimates of volatility and noise to categorise task trials as either high or low volatility/noise (i.e. trials in which the model’s estimates of these variables were higher/lower than the mean) and compared these to the same trial labels generated by the intact BOM. Consistent with the greater degradation of the noise dimension, coarsening the model caused it to miscategorise more trials which the intact BOM had labelled as having high than low noise (<xref rid="fig4" ref-type="fig">Figure 4b</xref>; F(1,69)=30.7, <italic>p</italic>&lt;0.01) with no effect of volatility (F(1,69)=1.9, <italic>p</italic>=0.17) or outcome valence (F(1,69)=0.004, <italic>p</italic>=0.95). As illustrated in <xref rid="fig4" ref-type="fig">Figure 4c</xref>, when the degraded BOM miscategorised high noise trials, it tended to label them as having high, rather than low, volatility. Overall, these results indicate that coarsening the BOM caused it, relative to the intact BOM, to misattribute high noise trials as high volatility trials.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Analysis of the behaviour of the degraded BOM.</title>
<p>The process of degrading the BOM involved reducing the number of bins used to represent the volatility and noise dimensions independently until the choice of the model matched that of participants. Panel <bold>a</bold> illustrates the number of bins selected by this process for the volatility and noise dimensions (averaged across win and loss outcomes). As can be seen the degraded BOM maintained a less precise representation of noise than volatility. In order to understand the behaviour of the degraded model, the model’s estimated <italic>vmu</italic><sub><italic>i</italic></sub> and <italic>SD</italic><sub><italic>i</italic></sub> were used to label individual trials as high/low volatility and noise (NB greater than or less than the mean value of the estimates). These trial labels were compared with the same labels from the intact model, which were used as an ideal comparator (panels <bold>b</bold> and <bold>c</bold>). Panel <bold>b</bold> illustrates the proportion of trials in which the labels of the two models agreed, arranged by the ground truth labels of the full model and averaged across win and loss outcomes. The dotted line indicates the agreement expected by chance. The degraded model trial labels differed from those of the full model particularly for high noise trials, with no impact of trial volatility. Panel c provides more details on how the degraded model misattributes trials. In this figure, the labels assigned by the full model are arranged along the x axis. The colour of each square represents the proportion of trials with a specific full model label that received the indicated label of the degraded model (arranged along the y axis). The diagonal squares illustrate agreement between models as reported in panel <bold>b</bold>. As highlighted by the red outlines, trials which the full model labelled as having high noise were generally mislabelled by the degraded model as having high volatility. Reanalysis of participant choices using the trial labels provided by the full (panel <bold>e</bold>) and degraded (panel <bold>f</bold>) models indicate that participants adapt their learning rates in a normative fashion when the degraded model trial labels are used (panel <bold>f</bold>), but not when the full model labels are used (panel <bold>e</bold>). Panel <bold>d</bold> illustrates the same analysis using the original task block labels for comparison. Bars represent the mean (±SEM) of participant learning rates, with raw data points presented as circles behind each bar. See supplementary figure 1 for a comparison of the behaviour of the degraded BOM with an alternative fitted model.</p></caption>
<graphic xlink:href="568699v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s1f">
<title>The Degraded BOM Rescues Optimal Behaviour</title>
<p>The process of fitting the degraded BOM to participant behaviour can be understood as searching for a configuration of the model (akin to a grid-based maximum likelihood estimation) in which participant choice conforms to the normative response to volatility and noise coded in the model’s structure. In other words, participants’ learning rates should increase when the degraded BOM’s estimate of volatility is high and, critically, when it estimates that noise is low. We demonstrate this by reanalysing participant behaviour, using the trial labels of the degraded BOM to indicate periods of low/high volatility and noise in place of the task block labels used in the original analysis. In effect, this approach allows us to test whether participants make internally consistent errors during learning, i.e. reducing their learning rates for outcomes that they thought — instead of the actual task structure — were associated with high volatility and/or low noise. As can be seen (<xref rid="fig4" ref-type="fig">Figure 4f</xref>), participants significantly increased their learning rate when the degraded BOM estimated volatility to be high (F(1,566)=86, <italic>p</italic>&lt;0.001) and noise to be low (F(1,566)=81, <italic>p</italic>&lt;0.001). In control analyses, this normative response to uncertainty was not seen when the labels from the intact rather than the degraded BOM were used (<xref rid="fig4" ref-type="fig">Figure 4e</xref>), or when the BOM’s representation of outcome mean was degraded, rather than its estimates of volatility and noise (supplementary materials).</p>
</sec>
<sec id="s1g">
<title>Assuming Human Participants Use the Degraded BOM’s Estimates of Volatility and Noise also Rescues Normative Pupillary Response</title>
<p>If the degraded BOM is a fair representation of how participants are performing the learning task, then we would expect it to be better able to explain physiological markers of uncertainty estimation than the simple task block structure or the intact BOM. Specifically, participants’ pupils should be larger when the degraded BOM thinks that volatility is high and when it thinks noise is low. We first show (<xref rid="fig5" ref-type="fig">Figures 5a-c</xref>) that participants’ pupils do not adapt normatively to the task block structure, with no main effect of block volatility (F(1,1723)=0.002, p=0.9) and an increase of pupil size in response to higher noise (F(1,1723)=13.8 p&lt;0.001). In contrast, analysis using the trial labels derived from the degraded model (<xref rid="fig5" ref-type="fig">Figure 5d-f</xref>) recovered the expected increase in pupil size in response to both raised volatility (F(1,2067)=105, p&lt;0.001) and reduced noise (F(1,2067)=42.3, p&lt;0.001) suggesting that the model provides a reasonable measure of participants’ estimates of these parameters. Finally, we tested whether the degraded BOM was able to explain more variance in the pupil data than the intact BOM. In order to do this, we first regressed participants’ pupil data against the estimated volatility and noise of the intact BOM, as well as a range of other task related factors (<xref rid="fig5" ref-type="fig">Figure 5g</xref>; see methods for more details of analysis). Having removed the variance accounted for by these factors, we then regressed the residuals of this first level analyses against the degraded model’s estimates of volatility and noise. This second level analysis (<xref rid="fig5" ref-type="fig">Figure 5h-i</xref>) indicated that the degraded model was able to account for variance associated with outcome noise that was not explained by the full model (F(1,286)=4.1, p=0.04), but did not explain additional variance associated with outcome volatility (F(1,286)=0.1, p=0.75). In summary, assuming that participants used the degraded BOM’s estimates of outcome volatility and noise rescued the normative pattern of physiological adaptation during the task.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Analysis of pupillometry data.</title>
<p>Z-scored pupil area from 2 seconds before to 6 seconds after win (panel <bold>a</bold>) and loss (panel <bold>b</bold>) outcomes, split by task block. Lines illustrate average size, with shaded area illustrating SEM. Panel c Pupil size averaged across whole outcome period and both win and loss outcomes. Pupil size did not systematically vary by task block. Panels <bold>d-f</bold>, as above but using the trial labels derived from the degraded model. Pupil size was significantly larger for trials labelled as having high vs. low volatility and low vs. high noise. Panel <bold>g</bold> displays the mean (SEM) effect of volatility and noise as estimated by the full BOM derived from a regression analysis of pupil data. The residuals from this analysis were then regressed against the estimated volatility and noise from the degraded model. A time course of the regression weights from this analysis is shown in panel <bold>h</bold>, with the mean coefficients across the whole period shown in panel i. The degraded model’s estimated noise accounted for a significant amount of variance not captured by the full model (pink line in h is below 0, the mean effect across the period is represented by dashed lines and arrows in panel i). See supplementary figure 2 for comparison of the degraded BOM with an alternative fitted model.</p></caption>
<graphic xlink:href="568699v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s2">
<title>Discussion</title>
<p>Humans respond in a rational, if approximate, manner to the causal statistics of dynamic environments. We found that participants adapted as expected to changes in outcome volatility, but were relatively insensitive to changes in noise. Using a degraded Bayesian Observer Model (BOM) to characterise participants’ behaviour suggested that they responded appropriately to a relatively coarse estimation of the level of noise, that led to its misattribution as volatility. Analysis of pupillometry data using the degraded model again suggested that participants were responding normatively to changes in estimated noise, but that these estimates diverged from the true noise of experienced outcomes. These results illustrate that human learners are able adapt to the statistical properties of their environment, but during this process they make internally consistent errors, utilising higher learning rates as a result of misattributing environmental noise as volatility which also leads to suboptimal choice.</p>
<p>Using a task in which volatility and noise varied independently between blocks, we found that human learners adapted as expected (<xref ref-type="bibr" rid="c3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="c16">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="c22">Pulcu &amp; Browning, 2019</xref>) to blockwise changes in the volatility of both win and loss outcomes, increasing the learning rate used when volatility was high vs. low. In contrast, the expected reduction of learning rates in response to increased outcome noise was not apparent, with participants employing a significantly higher learning rate in response to increased noise when volatility was low and a numerically lower learning rate when volatility was high. The absence of a normative response to blockwise changes in noise is at odds with previous work which has described a reduction in learning rates during periods of high noise (<xref ref-type="bibr" rid="c7">Diederen &amp; Schultz, 2015</xref>; <xref ref-type="bibr" rid="c17">Nassar et al., 2010</xref>, <xref ref-type="bibr" rid="c16">2012</xref>). However, in this previous work the level of noise was either explicitly presented to participants (as a bar on screen representing the standard deviation of the generative process in Diederen &amp; Schultz) or was made unambiguous by being very different from changes caused by volatility (in Nassar et al, noise was generated using an SD of 5 or 10, while the average change due to volatility was 100). By design, in the current task high noise and volatility resulted in a similar range of magnitudes (<xref rid="fig1" ref-type="fig">Figure 1b</xref>) forcing participants to use the temporal sequence of outcomes to discriminate between the different forms of uncertainty. Our behavioural results suggest that, in the absence of unambiguous differences between outcomes caused by volatility and those caused by noise, participants’ ability to estimate and/or adapt to changes in noise is reduced. Interestingly, a recent study reported that participants do not adjust their choice or estimated confidence in response to variability in the orientation of arrays of visual gratings (<xref ref-type="bibr" rid="c9">Herce Castañón et al., 2019</xref>), suggesting that an insensitivity to outcome noise may be a general feature of human decision making, rather than a specific component of learning.</p>
<p>Noise fundamentally limits the reliability of information (<xref ref-type="bibr" rid="c14">MacKay, 2003</xref>) and ignoring it has a clear detrimental impact on inference (<xref rid="fig3" ref-type="fig">Figure 3h</xref>), causing agents to be unnecessarily influenced by chance events (<xref ref-type="bibr" rid="c22">Pulcu &amp; Browning, 2019</xref>). It would therefore be surprising if human learners were completely insensitive to this process, particularly given evidence that they can respond normatively when the level of noise is unambiguous (<xref ref-type="bibr" rid="c7">Diederen &amp; Schultz, 2015</xref>; <xref ref-type="bibr" rid="c17">Nassar et al., 2010</xref>, <xref ref-type="bibr" rid="c16">2012</xref>). We developed an ideal Bayesian Observer Model (BOM; <xref ref-type="bibr" rid="c3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c17">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="c19">Piray &amp; Daw, 2021</xref>; <xref ref-type="bibr" rid="c23">Pulcu et al., 2022</xref>) to investigate the degree to which participants were adapting to noise. The intact BOM displayed the expected behavioural response to changes in both volatility and noise (<xref rid="fig3" ref-type="fig">Figure 3f</xref>) and, as a result, did not accurately capture the behaviour of participants (<xref rid="fig3" ref-type="fig">Figure 3e</xref>). Completely removing the BOM’s ability to adapt to noise (or volatility) did not recapitulate participant choice behaviour (<xref rid="fig3" ref-type="fig">Figure 3g-h</xref>), whereas coarsening its representation of volatility and noise, produced a much closer match (<xref rid="fig3" ref-type="fig">Figure 3i</xref>). This suggests that participants were relatively, rather than completely insensitive to noise and that they tended to misattribute high noise as volatility (<xref rid="fig4" ref-type="fig">Figure 4</xref>). However, an important caveat to this interpretation is that the degree of coarsening was selected using participants’ choices. The better behavioural match of the coarsened BOM to participant learning rates may therefore be simply because this model was fitted to the same choices used to calculate the learning rates, whereas the intact and fully lesioned models were not. We therefore sought to validate the coarsened BOM by assessing its ability to account for participants’ pupillary data, and by comparing it with an alternative fitted BOM which coarsened the representation of the generative mean, rather than the estimated uncertainty (see supplementary materials). Participants’ pupil size did not vary systematically between different block types, whereas they were significantly larger when the degraded BOM estimated volatility to be high and noise to be low (<xref rid="fig5" ref-type="fig">Figure 5a-f</xref>). Similarly, the estimated noise of the degraded BOM accounted for additional variance in pupil size, over and above the intact BOM (<xref rid="fig5" ref-type="fig">Figure 5g-i</xref>). In contrast, the alternative mean-degraded BOM did not recapitulate participants’ learning rates (supplementary figure 3) and was not able to account for changes in participant pupil size (supplementary figure 4). The finding that participants’ pupil size covaries in the expected direction with the degraded BOM’s estimated levels of both volatility and noise provides some reassurance that the model is capturing the dynamics of participants’ uncertainty estimates. More generally, the presence of both volatility and noise signals in this data, indicate that, as suggested previously (<xref ref-type="bibr" rid="c16">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="c18">O’Reilly et al., 2013</xref>), the pupillometry signal reflects general belief updating rather than specifically volatility.</p>
<p>An outstanding question is why participants might be particularly insensitive to changes in outcome noise. It is tempting to try to answer this question by reference to the processes by which the BOM was coarsened (i.e. the insensitivity was caused by a reduction in the precision by which noise was represented in a multi-dimensional probability distribution). However, the BOM described here was developed as an algorithmic description of how the learning task may be solved. As far as we are aware, there is little evidence that it accurately describes the cognitive or neural implementation of uncertainty estimation. Alternative algorithmic approaches to the general problem of uncertainty estimation have been described (<xref ref-type="bibr" rid="c11">Kalman, 1960</xref>; <xref ref-type="bibr" rid="c17">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="c19">Piray &amp; Daw, 2021</xref>; <xref ref-type="bibr" rid="c22">Pulcu &amp; Browning, 2019</xref>), including simpler approaches that avoid computationally expensive representations of multi-dimensional distributions (<xref ref-type="bibr" rid="c11">Kalman, 1960</xref>; <xref ref-type="bibr" rid="c17">Nassar et al., 2010</xref>) and which therefore may be more likely implementational candidates. In other words, the current results indicate that human learners are relatively insensitive to changes in outcome noise, but do not specify the lower level mechanisms that determine this effect.</p>
<p>Previous work examining the neural representations of uncertainty have tended to report correlations between brain activity and some task-based estimate of one form of uncertainty at a time (<xref ref-type="bibr" rid="c3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c25">Walker et al., 2020</xref>, <xref ref-type="bibr" rid="c26">2023</xref>). We are not aware of work that has, for example, systematically varied volatility and noise and reported distinct correlations for each. An interesting possibility as to how different forms of uncertainty may be encoded is suggested by parallels with the neuronal decoding literature. One question addressed by this literature is how the brain decodes changes in the world from the distributed, noisy neural responses to those changes, with a particular focus on the influence of different forms of between-neuron correlation (<xref ref-type="bibr" rid="c1">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="c12">Kohn et al., 2016</xref>). Specifically, signal-correlation, the degree to which different neurons represent similar external quantities (required to track volatility) is distinguished from, and often limited by, noise-correlation, the degree to which the activity of different neurons covaries independently of these external quantities. One possibility relevant to the current study, which resembles the underlying logic of the BOM, is that a population of neurons represents the estimated mean of the generative process that produces task outcomes. In this case, volatility would be tracked as the signal-correlation across this population, whereas noise would be analogous to the noise-correlation and, crucially, misestimation of noise as volatility might arise as misestimation of these two forms of correlation. While the current study clearly cannot adjudicate on the neural representation of these processes, our finding of distinct behavioural and physiological responses to the two forms of uncertainty, does suggest that separable neural representations of uncertainty are maintained.</p>
<p>A related question is whether other, non-Bayesian model formulations may be able to account for participants’ learning adaptation in response to volatility and noise. Of note, the reinforcement learning model used to measure learning rates in separate blocks does not achieve this goal—as this model is fitted separately to each block rather than adapting between blocks (NB the simple reinforcement learning model that is fitted across all blocks does not capture participant behaviour, see supplementary information). One candidate class of model that has potential here is latent-state models (<xref ref-type="bibr" rid="c5">Cochran &amp; Cisler, 2019</xref>), in which the variance and unexpected changes in the process being learned (which have a degree of similarity with noise and volatility respectively) is estimated and used to alter the model’s rates of updating as well as the estimated number of states being considered. Using the model described by Cochran and Cisler, we were unable to replicate the learning rate adaptation demonstrated by participants in the current study (see supplementary information) although it remains possible that other latent state formulations may be more successful. In conclusion, human learners adapt rationally, to estimates of the volatility and noise of experienced outcomes. However, these estimates are approximate leading to a relative insensitivity to outcome noise.</p>
</sec>
<sec id="s3">
<title>Methods</title>
<sec id="s3a">
<title>Experimental model and subject details</title>
<p>Participants. 70 English-speaking participants aged between 18 and 65 were recruited from the general public using print and online advertisements. A previous study (<xref ref-type="bibr" rid="c21">Pulcu &amp; Browning, 2017</xref>) on behavioural response to changes in volatility reported an effect size of d=0.7. As the effect size of a noise manipulation was not clear, we recruited a sample size sufficient to detect an effect size of half this value (d=0.35) with 80% power. Participants were excluded from the study if they had any psychological or neurological disorders or were currently on psychotropic medication. No exclusion criteria related to task performance were used.</p>
</sec>
<sec id="s3b">
<title>Method details</title>
<sec id="s3b1">
<title>General procedure</title>
<p>Participants attended a single study visit during which they completed the learning task. The study was approved by the University of Oxford Central Research Ethics Committee (R49753/RE001). All participants provided written informed consent to take part in the study, in accordance with the Declaration of Helsinki.</p>
</sec>
<sec id="s3b2">
<title>Behavioural Paradigm</title>
<p>The reinforcement learning (RL) task consisted of six blocks, each comprising 60 trials. In each trial, participants were presented with two abstract shapes taken from the Agathodaimon font (i.e. shape A and shape B). Two different shapes were used in each block, with rest sessions between blocks. The shapes were presented randomly on either side of the screen. Participants were explicitly instructed that this randomised location did not influence the outcome magnitudes. Participants attempted to accumulate as much money as possible by learning the likely magnitude of the wins and losses associated with each shape and using this information to guide their choice. On each trial, participants chose one of two shapes, with their choice highlighted by a black frame (see <xref rid="fig1" ref-type="fig">Fig 1a</xref>). Following the choice, the win and loss amounts associated with the chosen shape were presented, in randomised order, for a jittered period (2-6 sec, mean: 4 sec) inside two empty bars, above and below the fixation cross. The win amount was shown as a green area in the upper bar, and the loss amount represented as a red area in the lower bar. The total length of each bar represented £1 (i.e. of wins or losses) and thus the amount associated with the chosen shape was the proportion of the bar filled by the green/red areas (e.g. three quarters of the upper bar being green, would mean that the chosen option was associated with a win of 75p). Participants were informed that the unshaded area of each bar was the amount associated with the unchosen option. Thus, on each trial participants knew how much they had won/lost and how much they would have won/lost if they had chosen the other option. This feature simplified the task; rather than having to separately estimate the wins and losses associated with each shape, participants only had to estimate these values for one shape (with the other shape being £1 minus this value). For each trial participants received the difference between the win and loss amounts associated with their choice. A running total amount of money was displayed in the centre of the screen, under the bars and was updated at the beginning of the subsequent trial with the recent winnings. Participants were informed that the task would be split into 6 blocks, that they had to learn which was the best option to choose, and that this option may change over time. They were not informed about the different forms of uncertainty we were investigating or of the underlying structure of the task (that uncertainty varied between blocks).</p>
<p>The wins and the losses associated with each shape followed independent outcome schedules (<xref rid="fig1" ref-type="fig">Figure 1b</xref>), generated from a Gaussian distribution. In each block, the win and loss outcomes had either high or low volatility and high or low noise. When volatility was low, the mean of the Gaussian distribution remained constant, when volatility was high the mean changed from between 25-40 and 60-75 every 9-15 trials. When noise was low the standard deviation of the Gaussian was set to 5, whereas when noise was high the standard deviation was 35. As can be seen from <xref rid="fig1" ref-type="fig">Figure 1b</xref>, these schedules resulted in similar ranges of outcome magnitudes for periods of high noise and high volatility. The first block for every participant had high volatility and low noise for both win and loss outcomes and was used to familiarise participants with the task. Choices from this block were not used in the analyses presented (although including them does not alter the reported pattern of results). The schedules in the remaining five blocks were presented in a randomised order with the constraint that, across both win and loss outcomes, each of the four combinations of volatility and noise level (<xref rid="fig1" ref-type="fig">Figure 1B</xref>) were presented either 2 or 3 times. Thus, while each participant completed at least two blocks with each of the four combinations of high/low volatility/noise, the specific pairings of win and loss volatility/noise levels, differed across participants. This approach was used in preference to a fully factorial design in order to keep the total task duration to a manageable level. At the end of the experiment, participants were paid one fifth of their total winnings, plus a £15 baseline rate for turning up to take part.</p>
<p>Pupillometry data was collected for 36 of the 70 participants. During collection of pupillary data, the task was presented on a VGA monitor connected to a laptop computer running Presentation software version 18.3 (Neurobehavioural Systems). An identical behavioural version of the task, presented using Psychtoolbox 3.0 on MATLAB (MathWorks Inc.), was used to collect behavioural data from the remaining 34 participants. In the pupillometry version, participants’ heads were stabilised using a head-and-chin rest placed 70 cm from the screen on which the eye tracking system was mounted (Eyelink 1000 Plus; SR Research). The eye tracking device was configured to record the coordinates of both of the eyes and pupil area at a rate of 500 Hz. The task stimuli were drawn on either side of a fixation cross which marked the middle of the screen and were offset by 7° visual angle. The testing session lasted approximately 70 min per participant.</p>
</sec>
</sec>
<sec id="s3c">
<title>Analysis of Choice Data</title>
<p>Non-model based measure of the influence of outcomes. The manipulation of uncertainty in the reinforcement learning task is expected to alter the degree to which participants’ choices are influenced by the outcomes they experience. A simple, if somewhat crude, measure of this influence can be calculated as the proportion of trials in a block in which participants select the choice prompted by the win or loss outcomes on the previous trial. Generally, win outcomes of &gt;50p and loss outcomes of &lt;50p associated with a shape will prompt selection of the same shape on the next trial, whereas other outcomes will prompt selection of the alternative shape. The overall effect of win outcomes on choice can therefore be estimated as:
<disp-formula id="ueqn1">
<graphic xlink:href="568699v3_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
That is, the probability of choosing shape A, given that, on the previous trial, a win of &gt;50p was associated with shape A – the probability of choosing Shape A, given that, on the previous trial a win of &lt;50p was associated with Shape A. Similarly, the effect of loss outcomes is estimated as:
<disp-formula id="ueqn2">
<graphic xlink:href="568699v3_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
However, choice is also influenced by the magnitude of the outcome; a win of 90p will have a greater effect on subsequent choice than a win of 55p. Blocks with high levels of either volatility or noise have more extreme magnitudes than blocks with low levels of both (<xref rid="fig1" ref-type="fig">Figure 1b</xref>) which will bias any comparison of this metric between blocks. In order to limit the effect of this bias, we estimated the simple choice metric only for trials in which the previous outcome lay in the range of magnitudes common to all four blocks, 35-65.</p>
<sec id="s3c1">
<title>Reinforcement Learning Model</title>
<p>While the choice metric described above provides a relatively transparent measure of the influence of task outcomes on choice, it does not account for differences in outcome magnitude making it liable to bias. We therefore fitted a simple reinforcement learning model to measure block-wise learning rates, which provide a more principled estimate of the degree to which choices are influenced by outcomes. The model combines a learning phase in which the magnitude of wins and losses associated with a shape are estimated (note that it is not necessary to learn the magnitudes associated with the other shape, as these are simply 1-those described below)
<disp-formula id="ueqn3">
<graphic xlink:href="568699v3_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
In these equations, <italic>Qwin</italic>_<italic>a</italic><sub>(<italic>t</italic>)</sub> and <italic>Qlss</italic>_<italic>a</italic><sub>(<italic>t</italic>)</sub> are the estimated win and loss magnitudes associated with Shape A on trial <italic>t</italic>, <italic>win</italic><sub>(<italic>t</italic>)</sub> and <italic>loss</italic><sub>(<italic>t</italic>)</sub> are the observed win and loss outcome magnitudes and <italic>α</italic><sub><italic>win</italic></sub> and <italic>α</italic><sub><italic>loss</italic></sub> are the win and loss learning rates. These values are then combined in a decision phase such that:
<disp-formula id="ueqn4">
<graphic xlink:href="568699v3_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Where <italic>Pchoice</italic>_<italic>a</italic><sub>(<italic>t</italic>)</sub> is the probability that Shape A will be chosen on trial <italic>t</italic> and <italic>β</italic> is a single inverse decision temperature. This model was initiated with <italic>Qwin</italic>_<italic>a</italic><sub>(0)</sub> = <italic>Qloss</italic>_<italic>a</italic><sub>(0)</sub> = 0.5 and the three free parameters (<italic>win</italic><sub>(<italic>t</italic>)</sub>, <italic>loss</italic><sub>(<italic>t</italic>)</sub> and <italic>β</italic>) were estimated for each block and each participant by calculating the joint posterior probability given participant choice, marginalising each parameter and deriving the parameters’ expected values (<xref ref-type="bibr" rid="c3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c4">Browning et al., 2015</xref>). See supplementary materials for model selection data.</p>
<p>Some analyses reported in the paper (i.e. where trials are labelled as high/low volatility and high/low noise by the Bayesian Observer Model rather than by task block) cannot be modelled using this block-wise approach (as different types of trial are interleaved throughout the task, rather than blocked). In these analyses a similar, single model was fit across all trials in the task. This model had 8 different learning rates (separate win and loss learning rates, for each combination of high/low volatility and high/low noise labelled trials) and a single inverse temperature parameter. Although this model is somewhat less flexible than the blockwise modelling approach (i.e. it has 8, rather than 10 learning rates, and 1 rather than 5 inverse temperatures), it produces the same pattern of results when applied to participant choices split by task block (all estimated learning rates correlate at r&gt;0.8, <xref rid="fig2" ref-type="fig">Figure 2c-d</xref> show results from blockwise fitting, <xref rid="fig3" ref-type="fig">Figure 3e</xref> from the simpler model). This simpler model was fit using stan, with 5000 burn in and 5000 estimation trials, with posterior convergence visually checked and rhat values of less than 1.1 accepted.</p>
<p>Note that neither of these models describe how participants adjust to different levels of volatility and noise, they simply estimate the learning rates used in each block/type of trial, which are expected to vary in response to differences in levels of uncertainty (in contrast, the Bayesian Observer Model described below does estimate uncertainty and adjust to levels of uncertainty).</p>
<p>Bayesian Observer Model: A recursive, grid-based Bayesian Observer Model (BOM) was developed, similar to that described by Behrens and colleagues (<xref ref-type="bibr" rid="c3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c23">Pulcu et al., 2022</xref>). The BOM is based on a generative process (see <xref rid="fig3" ref-type="fig">Figure 3</xref>), and described fully in Pulcu et al. (<xref ref-type="bibr" rid="c23">Pulcu et al., 2022</xref>). Below we summarise the key aspects of the model.</p>
<p>The BOM assumes that the observed outcomes at a given time point <italic>t, y</italic><sub><italic>t</italic></sub>, are generated from a Gaussian distribution with an unknown mean, <italic>µ</italic> <sub><italic>t</italic></sub>, and standard deviation, <italic>e</italic><sup><italic>SD</italic><sub><italic>t</italic></sub></sup>, with the later producing noise in the observed outcomes (<xref ref-type="fig" rid="fig1">Figure 1b-c</xref>).
<disp-formula id="ueqn5">
<graphic xlink:href="568699v3_ueqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
As illustrated in <xref rid="fig1" ref-type="fig">Figure 1b-c</xref>, the mean of this distribution may change between time points, leading to volatility in the task environment, with this change described by a second level Gaussian distribution, centered on the current mean and with a standard deviation of <italic>e</italic><sup><italic>vum</italic><sub><italic>t</italic></sub></sup>. The mean of the generative Gaussian distribution in the following trial is drawn from:
<disp-formula id="ueqn6">
<graphic xlink:href="568699v3_ueqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Both the noise (<italic>SD</italic><sub><italic>t</italic></sub>) and volatility (<italic>vmu</italic><sub><italic>t</italic></sub>) parameters can also change between time points with their change governed by Gaussian distributions centered on their current value with standard deviations of <italic>e</italic><sup><italic>vSD</italic></sup> and <italic>e</italic><sup><italic>kmu</italic></sup> respectively. These higher-level parameters allow the model to account for periods in which noise and volatility are high and other periods in which they are low (for example, as caused by the uncertainty changes between task blocks).
<disp-formula id="ueqn7">
<graphic xlink:href="568699v3_ueqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="ueqn7a">
<graphic xlink:href="568699v3_ueqn7a.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The BOM estimates the joint posterior probability of the five causal parameters, given the choice outcome it has observed. The joint probability distribution at time point t is defined as:
<disp-formula id="ueqn8">
<graphic xlink:href="568699v3_ueqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This joint probability distribution can be thought of as the BOM’s belief about the values of each parameter in the generative model. A Markovian assumption (i.e. that nodes of the model are sufficient to describe the generative process) simplifies this process and illustrates the recursive update performed by the BOM:
<disp-formula id="ueqn9">
<graphic xlink:href="568699v3_ueqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We initialized the joint posterior, before observation of any task outcomes as a uniform distribution. The BOM performs the update, first using Bayes’ rule to incorporate the effect of the most recently observed outcome, and then accounts for the drifting parameters by using the conditional probability of the new value of the drifting parameter, given the initial value and drift rate (See; <xref ref-type="bibr" rid="c23">Pulcu et al., 2022</xref> for a detailed account of this updating process):
<disp-formula id="ueqn10">
<graphic xlink:href="568699v3_ueqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The value of each node is derived at every time point by marginalizing over all but the relevant dimension of the joint probability distribution and calculating the expected value of that dimension.</p>
<p>During the task, the shapes presented to participants change between each task block, which means that, at the start of each block, participants have to relearn the mean associated with each shape. This was dealt with in the BOM by flattening the mu dimension of the joint probability distribution at the start of each trial (i.e. replacing the values of the mean dimension, with the average of the joint distribution across this dimension). The effect of this is to reset the model’s belief about the actual magnitude associated with the two new shapes, while maintaining its belief about the overall volatility and noise of the outcomes.</p>
<p>The BOM was provided with the win and loss outcomes (as values between 0 and 1) for each trial, across all trials in the task (excluding the first practice block, although including this did not alter the pattern of results). It treated the two outcomes as independent (i.e. the win outcome did not influence estimates for the loss outcome and vice versa) and transformed the outcomes to the infinite real line using the logistic transform before estimating the posterior probability (<xref ref-type="bibr" rid="c23">Pulcu et al., 2022</xref>).</p>
</sec>
<sec id="s3c2">
<title>Lesioning the Bayesian Observer Model</title>
<p>A number of different lesions were applied to the BOM. First, it’s ability to estimate changes in either volatility or noise was removed. This was achieved simply by removing the kmu or vSD nodes from the BOM (reducing the dimensionality of the joint distribution by one in each case). The effect of this is to force the BOM to estimate the mean volatility and noise (respectively) across the whole task, rather than to modify its estimates of these parameters between trials.</p>
<p>The second approach induced a graded, rather than absolute, lesion. This was achieved by reducing the precision with which the BOM represented the volatility-related nodes (<italic>vmu</italic> and <italic>kmu</italic>) and/or the noise related nodes (<italic>SD</italic> and <italic>vSD</italic>). More specifically, the BOM’s estimates of the values of each of the five nodes are encoded on a five dimensional grid, with each dimension on the grid representing the possible range of values of a particular node, from low to high, using a fixed number of points. The probability ascribed by the model to a specific point on this dimension is the relative probability that the value of the node lies within the bin of values that is closer to the point, than to adjacent points. For example, say the value of volatility (<italic>vmu</italic>) ranged from 0 to 10 and was represented by 10 bins. In this case volatility would be represented by a probability mass function over the 10 bins (&lt;0.5, 0.5-1.5, 1.5-2.5, …, &gt; 9.5). Lesioning occurred by independently varying the number of bins used in the volatility-related and/or noise-related dimensions, from a maximum of 20, to a minimum of 2 (i.e. with only 2 bins volatility/noise would be represented as simply “high” or “low”). The degree of lesioning selected for each individual participant was determined as the number of bins for the volatility and noise dimensions that, after passing the model estimates through a softmax action selector with a single inverse temperature parameter (i.e. as described for the RL model), maximized the likelihood that the model would make the same choices as the participant, across all task blocks. This process of lesioning therefore progressively coarsens the BOM’s representation of the two types of uncertainty and selects the degree of coarsening that results in choices as similar as possible to participants (see supplementary materials for an alternative model that coarsens the representation of the mean values).</p>
<p>Pupilometry Data Preprocessing. Pupilometry data were collected using the Eyelink II system (SRresearch) from both eyes, sampled at 500Hz. Preprocessing involved the following steps: Eye blinks were identified using the built in filter of the Eyelink system and were removed from the data. A linear interpolation was implemented for all missing data points (including blinks). The resulting trace was subjected to a low pass Butterworth filter (cut-off of 3.75 Hz), z transformed across the session (<xref ref-type="bibr" rid="c4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="c16">Nassar et al., 2012</xref>), and then averaged across the two eyes. The pupil response to the win and the loss outcomes were extracted separately from each trial, using a time window based on the presentation of the outcomes. This included a 2-s pre-outcome period, and a 6-s period following outcome presentation. Individual trials were excluded from the pupilometry analysis if more than 50% of the data from the outcome period had been interpolated (mean =6.7% of trials) (<xref ref-type="bibr" rid="c4">Browning et al., 2015</xref>). The first 5 trials from each block were not used in the analysis as initial pupil adaption can occur in response to luminance changes in this period (<xref ref-type="bibr" rid="c4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="c16">Nassar et al., 2012</xref>). The preprocessing resulted in two sets of timeseries per participant, one set containing pupil size data for each included trial when the win outcomes were displayed and the other when the loss outcomes were displayed. These pupil area data were binned into one second bins across the outcome period for analysis (NB <xref rid="fig5" ref-type="fig">Figure 5a-f</xref>). This analysis was supplemented by an individual regression approach (<xref rid="fig5" ref-type="fig">Figure 5g-i</xref>) in which individual participants’ pupil area timeseries was first regressed against estimated trialwise volatility and noise from the intact BOM (<xref rid="fig5" ref-type="fig">Figure 5g</xref>), as well as a number of control variables (constant term, amount won/lost on trial (i.e. magnitude of outcome), valence of outcome (win or loss), order in which outcomes were presented (win first/loss first), trial number (1:360), whether shape chosen switched on next trial or not (1:0)). The residuals from this regression were then regressed against estimated trialwise volatility and noise from the degraded BOM (<xref rid="fig5" ref-type="fig">Figure 5h,i</xref>). These regression analyses resulted in timeseries of beta-weights that were analysed in the same manner as raw pupil size data.</p>
</sec>
</sec>
<sec id="s3d">
<title>Quantification and statistical analysis</title>
<p>Behavioural data were analysed using linear mixed effect models (<italic>fitlme</italic> function of Matlab (2022a)) with participant ID included as a random factor and volatility, noise and valence added as fixed factors. Two-way interactions between fixed effects were also tested (main effects are reported from models without interaction terms). Addition of random slopes for any of the fixed factors decreased LME model fit statistics and so were not included (<xref ref-type="bibr" rid="c15">Matuschek et al., 2017</xref>). Analysis of timeseries pupillometry data included the additional fixed effect factor of time across the outcome period. Learning rates were transformed to the infinite real line using a logistic transform before analyses (untransformed data are displayed in figures for ease of interpretation). The normality of the distribution of the residuals of the LME analyses were checked both visually and with a one-sample Kolmogorov-Smirnov test. Changes in the classification of trials between the full and degraded BOM (<xref rid="fig4" ref-type="fig">Figure 4b</xref>) were analysed using a repeated measures ANOVA with within subject factors of volatility, noise and valence. Raw data are superimposed on all summary figures.</p>
</sec>
</sec>

</body>
<back>
<sec id="s4" sec-type="data-availability">
<title>Code and Data Availability</title>
<p>Study data and analysis scripts, including code for the various models used are available at: <ext-link ext-link-type="uri" xlink:href="https://osf.io/j7md3/">https://osf.io/j7md3/</ext-link>.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We would like to thank James Gunnell for help in collecting the data. This study was funded by a MRC Clinician Scientist Fellowship awarded to MB (MR/N008103/1). MB was supported by the Oxford Health NIHR Biomedical Research Centre. The views expressed are those of the authors and not necessarily those of the NHS, the NIHR or the Department of Health.</p>
</ack>
<sec id="d1e1400" sec-type="additional-information">
<title>Additional information</title>
<sec id="s5">
<title>Author Contributions</title>
<p>MB and EP conceived the study, EP collected the data, MB and EP wrote the paper.</p>
</sec>
</sec>
<sec id="suppd1e1400" sec-type="supplementary-material">
<title>Additional files</title>
<supplementary-material id="d1e1391">
<label>Supplementary Materials</label>
<media xlink:href="supplements/568699_file02.docx"/>
</supplementary-material>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Averbeck</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Latham</surname>, <given-names>P. E.</given-names></string-name>, &amp; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Neural correlations, population coding and computation</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>7</volume>(<issue>5</issue>), <fpage>358</fpage>–<lpage>366</lpage>. <pub-id pub-id-type="doi">10.1038/nrn1888</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Hunt</surname>, <given-names>L. T.</given-names></string-name>, <string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name>, &amp; <string-name><surname>Rushworth</surname>, <given-names>M. F.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Associative learning of social value</article-title>. <source>Nature</source>, <volume>456</volume>(<issue>7219</issue>), <fpage>245</fpage>–<lpage>249</lpage>. <pub-id pub-id-type="doi">10.1038/nature07538</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Walton</surname>, <given-names>M. E.</given-names></string-name>, &amp; <string-name><surname>Rushworth</surname>, <given-names>M. F. S.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nature Neuroscience</source>, <volume>10</volume>(<issue>9</issue>), <fpage>1214</fpage>–<lpage>1221</lpage>. <pub-id pub-id-type="doi">10.1038/nn1954</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Browning</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Jocham</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>O’Reilly</surname>, <given-names>J. X.</given-names></string-name>, &amp; <string-name><surname>Bishop</surname>, <given-names>S. J.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Anxious individuals have difficulty learning the causal statistics of aversive environments</article-title>. <source>Nature Neuroscience</source>, <volume>18</volume>(<issue>4</issue>), <fpage>590</fpage>–<lpage>596</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3961</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cochran</surname>, <given-names>A. L.</given-names></string-name>, &amp; <string-name><surname>Cisler</surname>, <given-names>J. M.</given-names></string-name></person-group> (<year>2019</year>). <article-title>A flexible and generalizable model of online latent-state learning</article-title>. <source>PLoS Computational Biology</source>, <volume>15</volume>(<issue>9</issue>), <fpage>e1007331</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1007331</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Gee</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Colizoli</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Kloosterman</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Knapen</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Nieuwenhuis</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Donner</surname>, <given-names>T. H.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Dynamic modulation of decision biases by brainstem arousal systems</article-title>. <source>eLife</source>, <volume>6</volume>, <elocation-id>e23232</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.23232</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diederen</surname>, <given-names>K. M. J.</given-names></string-name>, &amp; <string-name><surname>Schultz</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Scaling prediction errors to reward variability benefits error-driven learning in humans</article-title>. <source>Journal of Neurophysiology</source>, <volume>114</volume>(<issue>3</issue>), <fpage>1628</fpage>–<lpage>1640</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00483.2015</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gagne</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Zika</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Bishop</surname>, <given-names>S. J.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Impaired adaptation of learning to contingency volatility in internalizing psychopathology</article-title>. <source>eLife</source>, <volume>9</volume>, <elocation-id>e61387</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.61387</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Herce Castañón</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Moran</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Ding</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Egner</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Bang</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Human noise blindness drives suboptimal cognitive inference</article-title>. <source>Nature Communications</source>, <volume>10</volume>(<issue>1</issue>), <fpage>1719</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-019-09330-7</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Joshi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Kalwani</surname>, <given-names>R. M.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Relationships between Pupil Diameter and Neuronal Activity in the Locus Coeruleus, Colliculi, and Cingulate Cortex</article-title>. <source>Neuron</source>, <volume>89</volume>(<issue>1</issue>), <fpage>221</fpage>– <lpage>234</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kalman</surname>, <given-names>R. E.</given-names></string-name></person-group> (<year>1960</year>). <article-title>A New Approach to Linear Filtering and Prediction Problem</article-title>. <source>Transactions of the ASME</source>, <volume>82</volume>(<issue>D</issue>), <fpage>35</fpage>–<lpage>45</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kohn</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Coen-Cagli</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kanitscheider</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Correlations and Neuronal Population Information</article-title>. <source>Annual Review of Neuroscience</source>, <volume>39</volume>, <fpage>237</fpage>–<lpage>256</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-neuro-070815-013851</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krishnamurthy</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Sarode</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Arousal-related adjustments of perceptual biases optimize perception in dynamic environments</article-title>. <source>Nature Human Behaviour</source>. <volume>1</volume>:<elocation-id>0107</elocation-id> <pub-id pub-id-type="doi">10.1038/s41562-017-0107</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>MacKay</surname>, <given-names>D. J. C.</given-names></string-name></person-group> (<year>2003</year>). <source>InformationTheory,Inference,and Learning Algorithms (1st ed)</source>. <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Matuschek</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Kliegl</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Vasishth</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Baayen</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Bates</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Balancing Type I error and power in linear mixed models</article-title>. <source>Journal of Memory and Language</source>, <volume>94</volume>, <fpage>305</fpage>–<lpage>315</lpage>. <pub-id pub-id-type="doi">10.1016/j.jml.2017.01.001</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Rumsey</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Parikh</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Heasly</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title>. <source>Nat Neurosci</source>, <volume>15</volume>(<issue>7</issue>), <fpage>1040</fpage>– <lpage>1046</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3130</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Heasly</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2010</year>). <article-title>An Approximately Bayesian Delta-Rule Model Explains the Dynamics of Belief Updating in a Changing Environment</article-title>. <source>Journal of Neuroscience</source>, <volume>30</volume>(<issue>37</issue>), <fpage>12366</fpage>–<lpage>12378</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Reilly</surname>, <given-names>J. X.</given-names></string-name>, <string-name><surname>Schüffelgen</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Cuell</surname>, <given-names>S. F.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Mars</surname>, <given-names>R. B.</given-names></string-name>, &amp; <string-name><surname>Rushworth</surname>, <given-names>M. F. S.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Dissociable effects of surprise and model update in parietal and anterior cingulate cortex</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>110</volume>(<issue>38</issue>), <fpage>E3660</fpage>–<lpage>3669</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1305373110</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Piray</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name></person-group> (<year>2021</year>). <article-title>A model for learning based on the joint estimation of stochasticity and volatility</article-title>. <source>Nature Communications</source>, <volume>12</volume>(<issue>1</issue>), <fpage>6587</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-021-26731-9</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Preuschoff</surname>, <given-names>K.</given-names></string-name>, ‘t <string-name><surname>Hart</surname>, <given-names>B. M.</given-names></string-name>, &amp; <string-name><surname>Einhäuser</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Pupil Dilation Signals Surprise: Evidence for Noradrenaline’s Role in Decision Making</article-title>. <source>Frontiers in Neuroscience</source>, <volume>5</volume>, <fpage>115</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2011.00115</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pulcu</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Browning</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Affective bias as a rational response to the statistics of rewards and punishments</article-title>. <source>eLife</source> <volume>6</volume>:<elocation-id>e27879</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.27879</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pulcu</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Browning</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2019</year>). <article-title>The Misestimation of Uncertainty in Affective Disorders</article-title>. <source>Trends in Cognitive Sciences</source>. <volume>23</volume> <fpage>865</fpage>–<lpage>875</lpage> <pub-id pub-id-type="doi">10.1016/j.tics.2019.07.007</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pulcu</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Saunders</surname>, <given-names>K. E. A.</given-names></string-name>, <string-name><surname>Harmer</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Harrison</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Goodwin</surname>, <given-names>G. M.</given-names></string-name>, <string-name><surname>Geddes</surname>, <given-names>J. R.</given-names></string-name>, &amp; <string-name><surname>Browning</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Using a generative model of affect to characterize affective variability and its response to treatment in bipolar disorder</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>119</volume>(<issue>28</issue>), <fpage>e2202983119</fpage>. <pub-id pub-id-type="doi">10.1073/pnas.2202983119</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Sutton</surname>, <given-names>R. S.</given-names></string-name>, &amp; <string-name><surname>Barto</surname>, <given-names>A. G.</given-names></string-name></person-group> (<year>2018</year>). <source>Reinforcement Learning: An Introdcution (Second)</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walker</surname>, <given-names>E. Y.</given-names></string-name>, <string-name><surname>Cotton</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, &amp; <string-name><surname>Tolias</surname>, <given-names>A. S.</given-names></string-name></person-group> (<year>2020</year>). <article-title>A neural basis of probabilistic computation in visual cortex</article-title>. <source>Nature Neuroscience</source>, <volume>23</volume>(<issue>1</issue>), <fpage>122</fpage>–<lpage>129</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-019-0554-5</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walker</surname>, <given-names>E. Y.</given-names></string-name>, <string-name><surname>Pohl</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Denison</surname>, <given-names>R. N.</given-names></string-name>, <string-name><surname>Barack</surname>, <given-names>D. L.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Block</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, &amp; <string-name><surname>Meyniel</surname>, <given-names>F.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Studying the neural representations of uncertainty</article-title>. <source>Nature Neuroscience</source>, <volume>26</volume>(<issue>11</issue>), <fpage>1857</fpage>– <lpage>1867</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-023-01444-y</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>A. J.</given-names></string-name>, &amp; <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Uncertainty, neuromodulation, and attention</article-title>. <source>Neuron</source>, <volume>46</volume>(<issue>4</issue>), <fpage>681</fpage>–<lpage>692</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103734.2.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Diaconescu</surname>
<given-names>Andreea Oliviana</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country>Canada</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study makes an <bold>important</bold> contribution by showing that humans adapt learning rates rationally to environmental volatility yet systematically misattribute noise as volatility, demonstrating approximate rationality with simplified internal models. The evidence is <bold>compelling</bold>, encompassing a cleverly designed volatility-versus-noise paradigm, innovative lesion-based comparisons between reinforcement-learning and degraded Bayesian Observer Models, and convergent behavioural and pupillometric data. Expanding formal model comparisons (e.g., BIC/AIC) and directly contrasting RL and Bayesian fits to physiological markers would further enhance the work, but these are minor limitations that do not detract from the core findings.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103734.2.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors present an interesting study using RL and Bayesian modelling to examine differences in learning rate adaptation in conditions of high and low volatility and noise respectively. Through &quot;lesioning&quot; an optimal Bayesian model, they reveal that apparently suboptimal adaptation of learning rates results from incorrectly detecting volatility in the environment when it is not in fact present.</p>
<p>Strengths:</p>
<p>The experimental task used is cleverly designed and does a good job of manipulating both volatility and noise. The modelling approach takes an interesting and creative approach to understand the source of apparently suboptimal adaptation of learning rates to noise, through carefully &quot;lesioning&quot; and optimal Bayesian model to determine which components are responsible for this behaviour.</p>
<p>Weaknesses:</p>
<p>The model space could be more extensive, although the authors have covered the most relevant models for the question at hand.</p>
<p>Comments on revisions: I have no further recommendations for the authors, they have addressed my previous comments very well.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103734.2.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this study, the authors aimed to investigate how humans learn and adapt their behavior in dynamic environments characterized by two distinct types of uncertainty: volatility (systematic changes in outcomes) and noise (random variability in outcomes). Specifically, they sought to understand how participants adjust their learning rates in response to changes in these forms of uncertainty.</p>
<p>To achieve this, the authors employed a two-step approach:</p>
<p>Reinforcement Learning (RL) Model:</p>
<p>
They first used an RL model to fit participants' behavior, revealing that the learning rate was context-dependent-it varied based on the levels of volatility and noise. However, the RL model showed that participants misattributed noise as volatility, leading to higher learning rates in noisy conditions, where the optimal strategy would be to be less sensitive to random fluctuations.</p>
<p>Bayesian Observer Model (BOM):</p>
<p>
To better account for this context dependency, they introduced a Bayesian Observer Model (BOM), which models how an ideal Bayesian learner would update their beliefs about environmental uncertainty. They found that a degraded version of the BOM, where the agent had a coarser representation of noise compared to volatility, best fit the participants' behavior. This suggested that participants were not fully distinguishing between noise and volatility, instead treating noise as volatility and adjusting their learning rates accordingly.</p>
<p>The authors also aimed to use pupillometry data (measuring pupil dilation) as a physiological marker to arbitrate between models and understand how participants' internal representations of uncertainty influenced both their behavior and physiological responses. Their objective was to explore whether the BOM could explain not just behavioral choices but also these physiological responses, thereby providing stronger evidence for the model's validity.</p>
<p>Overall, the study sought to reconcile approximate rationality in human learning by showing that participants still follow a Bayesian-like learning process, but with simplified internal models that lead to suboptimal decisions in noisy environments.</p>
<p>Strengths:</p>
<p>The generative model presented in the study is both innovative and insightful. The authors first employ a Reinforcement Learning (RL) model to fit participants' behavior, revealing that the learning rate is context-dependent-specifically, it varies based on the levels of volatility and noise in the task. They then introduce a Bayesian Observer Model (BOM) to account for this context dependency, ultimately finding that a degraded BOM-in which the agent has a coarser representation of noise compared to volatility-provides the best fit to the participants' behavior. This suggests that participants are not fully distinguishing between noise and volatility, leading to misattribution of noise as volatility. Consequently, participants adopt higher learning rates even in noisy contexts, where an optimal strategy would involve being less sensitive to new information (i.e., using lower learning rates). This finding highlights a rational but approximate learning process, as described in the paper.</p>
<p>Weaknesses:</p>
<p>While the RL and Bayesian models both successfully predict behavior, it remains unclear how to fully reconcile the two approaches. The RL model captures behavior in terms of a fixed or context-dependent learning rate, while the BOM provides a more nuanced account with dynamic updates based on volatility and noise. Both models can predict actions when fit appropriately, but the pupillometry data offers a promising avenue to arbitrate between the models. However, the current study does not provide a direct comparison between the RL framework and the Bayesian model in terms of how well they explain the pupillometry data. It would be valuable to see whether the RL model can also account for physiological markers of learning, such as pupil responses, or if the BOM offers a unique advantage in this regard. A comparison of the two models using pupillometry data could strengthen the argument for the BOM's superiority, as currently, the possibility that RL models could explain the physiological data remains unexplored.</p>
<p>The model comparison between the Bayesian Observer Model and the self-defined degraded internal model could be further enhanced. Since different assumptions about the internal model's structure lead to varying levels of model complexity, using a formal criterion such as Bayesian Information Criterion (BIC) or Akaike Information Criterion (AIC) would allow for a more rigorous comparison of model fit. Including such comparisons would ensure that the degraded BOM is not simply favored due to its flexibility or higher complexity, but rather because it genuinely captures the participants' behavioral and physiological data better than alternative models. This would also help address concerns about overfitting and provide a clearer justification for using the degraded BOM over other potential models.</p>
<p>Comments on revisions:</p>
<p>The authors have addressed all my questions. Congratulations on the impressive work accomplished by the authors!</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103734.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Pulcu</surname>
<given-names>Erdem</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2170-0677</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Browning</surname>
<given-names>Michael</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>Summary:</p>
<p>The authors present an interesting study using RL and Bayesian modelling to examine differences in learning rate adaptation in conditions of high and low volatility and noise respectively. Through &quot;lesioning&quot; an optimal Bayesian model, they reveal that apparently a suboptimal adaptation of learning rates results from incorrectly detecting volatility in the environment when it is not in fact present.</p>
<p>Strengths:</p>
<p>The experimental task used is cleverly designed and does a good job of manipulating both volatility and noise. The modelling approach takes an interesting and creative approach to understanding the source of apparently suboptimal adaptation of learning rates to noise, through carefully &quot;lesioning&quot; and optimal Bayesian model to determine which components are responsible for this behaviour.</p>
<p>We thank the reviewer for this assessment.</p>
<p>Weaknesses:</p>
<p>The study has a few substantial weaknesses; the data and modelling both appear robust and informative, and it tackles an interesting question. The model space could potentially have been expanded, particularly with regard to the inclusion of alternative strategies such as those that estimate latent states and adapt learning accordingly.</p>
</disp-quote>
<p>We thank the reviewer for this suggestion. We agree that it would be interesting to assess the ability of alternative models to reproduce the sub-optimal choices of participants in this study. The Bayesian Observer Model described in the paper is a form of Hierarchical Gaussian Filter, so we will assess the performance of a different class of models that are able to track uncertainty-- RL based models that are able to capture changes of uncertainty (the Kalman filter, and the model described by Cochran and Cisler, Plos Comp Biol 2019). We will assess the ability of the models to recapitulate the core behaviour of participants (in terms of learning rate adaption) and, if possible, assess their ability to account for the pupillometry response.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>Summary:</p>
<p>In this study, the authors aimed to investigate how humans learn and adapt their behavior in dynamic environments characterized by two distinct types of uncertainty: volatility (systematic changes in outcomes) and noise (random variability in outcomes). Specifically, they sought to understand how participants adjust their learning rates in response to changes in these forms of uncertainty.</p>
<p>To achieve this, the authors employed a two-step approach:</p>
<p>(1) Reinforcement Learning (RL) Model: They first used an RL model to fit participants' behavior, revealing that the learning rate was context-dependent. In other words, it varied based on the levels of volatility and noise. However, the RL model showed that participants misattributed noise as volatility, leading to higher learning rates in noisy conditions, where the optimal strategy would be to be less sensitive to random fluctuations.</p>
<p>(2) Bayesian Observer Model (BOM): To better account for this context dependency, they introduced a Bayesian Observer Model (BOM), which models how an ideal Bayesian learner would update their beliefs about environmental uncertainty. They found that a degraded version of the BOM, where the agent had a coarser representation of noise compared to volatility, best fit the participants' behavior. This suggested that participants were not fully distinguishing between noise and volatility, instead treating noise as volatility and adjusting their learning rates accordingly.</p>
<p>The authors also aimed to use pupillometry data (measuring pupil dilation) as a physiological marker to arbitrate between models and understand how participants' internal representations of uncertainty influenced both their behavior and physiological responses. Their objective was to explore whether the BOM could explain not just behavioral choices but also these physiological responses, thereby providing stronger evidence for the model's validity.</p>
<p>Overall, the study sought to reconcile approximate rationality in human learning by showing that participants still follow a Bayesian-like learning process, but with simplified internal models that lead to suboptimal decisions in noisy environments.</p>
<p>Strengths:</p>
<p>The generative model presented in the study is both innovative and insightful. The authors first employ a Reinforcement Learning (RL) model to fit participants' behavior, revealing that the learning rate is context-dependent-specifically, it varies based on the levels of volatility and noise in the task. They then introduce a Bayesian Observer Model (BOM) to account for this context dependency, ultimately finding that a degraded BOM - in which the agent has a coarser representation of noise compared to volatility - provides the best fit for the participants' behavior. This suggests that participants do not fully distinguish between noise and volatility, leading to the misattribution of noise as volatility. Consequently, participants adopt higher learning rates even in noisy contexts, where an optimal strategy would involve being less sensitive to new information (i.e., using lower learning rates). This finding highlights a rational but approximate learning process, as described in the paper.</p>
</disp-quote>
<p>We thank the reviewer for their assessment of the paper.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>While the RL and Bayesian models both successfully predict behavior, it remains unclear how to fully reconcile the two approaches. The RL model captures behavior in terms of a fixed or context-dependent learning rate, while the BOM provides a more nuanced account with dynamic updates based on volatility and noise. Both models can predict actions when fit appropriately, but the pupillometry data offers a promising avenue to arbitrate between the models. However, the current study does not provide a direct comparison between the RL framework and the Bayesian model in terms of how well they explain the pupillometry data. It would be valuable to see whether the RL model can also account for physiological markers of learning, such as pupil responses, or if the BOM offers a unique advantage in this regard. A comparison of the two models using pupillometry data could strengthen the argument for the BOM's superiority, as currently, the possibility that RL models could explain the physiological data remains unexplored.</p>
</disp-quote>
<p>We thank the reviewer for this suggestion. In the current version of the paper, we use an extremely simple reinforcement learning model to simply measure the learning rate in each task block (as this is the key behavioural metric we are interested in). As the reviewer highlights, this simple model doesn’t estimate uncertainty or adapt to it. Given this, we don’t think we can directly compare this model to the Bayesian Observer Model—for example, in the current analysis of the pupillometry data we classify individual trials based on the BOM’s estimate of uncertainty and show that participants adapt their learning rate as expected to the reclassified trials, this analysis would not be possible with our current RL model. However, there are more complex RL based models that do estimate uncertainty (as discussed above in response to Reviewer #1) and so may more directly be compared to the BOM. We will attempt to apply these models to our task data and describe their ability to account for participant behaviour and physiological response as suggested by the Reviewer.</p>
<disp-quote content-type="editor-comment">
<p>The model comparison between the Bayesian Observer Model and the self-defined degraded internal model could be further enhanced. Since different assumptions about the internal model's structure lead to varying levels of model complexity, using a formal criterion such as Bayesian Information Criterion (BIC) or Akaike Information Criterion (AIC) would allow for a more rigorous comparison of model fit. Including such comparisons would ensure that the degraded BOM is not simply favored due to its flexibility or higher complexity, but rather because it genuinely captures the participants' behavioral and physiological data better than alternative models. This would also help address concerns about overfitting and provide a clearer justification for using the degraded BOM over other potential models.</p>
</disp-quote>
<p>Thank you, we will add this.</p>
<disp-quote content-type="editor-comment">
<p><bold>Recommendations for the authors:</bold></p>
<p><bold>Reviewer #1 (Recommendations for the authors):</bold></p>
<p>For clarity, the methods would benefit from further detail of task framing to participants. I.e. were there explicit instructions regarding volatility/task contingencies? Or were participants told nothing?</p>
</disp-quote>
<p>We have added in the following explanatory text to the methods section (page 20), clarifying the limited instructions provided to participants:</p>
<p>“Participants were informed that the task would be split into 6 blocks, that they had to learn which was the best option to choose, and that this option may change over time. They were not informed about the different forms of uncertainty we were investigating or of the underlying structure of the task (that uncertainty varied between blocks).”</p>
<p>In the results, it would be useful to report the general task behavior of participants to get a sense of how they performed across different parts of the task. Also, were participants excluded if they didn't show evidence of learning adaptation to volatility?</p>
<p>We have added the following text reporting overall performance to the results (page 6):</p>
<p>“Participants were able to learn the best option to choose in the task, selecting the most highly rewarded option on an average of 71% of trials (range 65% - 74%).”</p>
<p>And the following text to the methods, confirming that participants were not excluded if they didn’t respond to volatility/noise (the failure in this adaptation is the focus of the current study) (page 19):</p>
<p>“No exclusion criteria related to task performance were used.”</p>
<disp-quote content-type="editor-comment">
<p>The results would benefit from a more intuitive explanation of what the lesioning is trying to recapitulate; this can get quite technical and the objective is not necessarily clear, especially for the less computationally-minded reader.</p>
</disp-quote>
<p>We have amended the relevant section of the results to clarify this point (page 9):</p>
<p>“Having shown that an optimal learner adjusts its learning rate to changes in volatility and noise as expected, we next sought to understand the relative noise insensitivity of participants. In these analyses we “lesion” the BOM, to reduce its performance in some way, and then assess whether doing so recapitulates the pattern of learning rate adaptation observed for participants (Fig 3e). In other words, we damage the model so it performs less well and then assess whether this damage makes the behaviour of the BOM (shown in Fig 3f) more closely resemble that seen in participants (Fig 3e).”</p>
<disp-quote content-type="editor-comment">
<p>The modelling might be improved by the inclusion of another class of model. Specifically, models that adapt learning rates in response to the estimation of latent states underlying the current task outcomes would be very interesting to see. In a sense, these are also estimating volatility through changeability of latent states, and it would be interesting to explore whether the findings could also be explained by an incorrect assumption that the latent state has changed when outcomes are noisy.</p>
</disp-quote>
<p>Thank you for this suggestion. We have added additional sections to the supplementary materials in which we use a general latent state model and a simple RL model to try to recapitulate the behaviour of participants (and to compare with the BOM). These additional sections are extensive, so are not reproduced here. We have also added in a section to the discussion in the main paper covering this interesting question in which we confirm that we were unable to reproduce participant behaviour (or the normative effect of the lesioned BOMs) using these models but suggest that alternative latent state formulations would be interesting to explore in future work (page 18):</p>
<p>“A related question is whether other, non-Bayesian model formulations may be able to account for participants’ learning adaptation in response to volatility and noise. Of note, the reinforcement learning model used to measure learning rates in separate blocks does not achieve this goal—as this model is fitted separately to each block rather than adapting between blocks (NB the simple reinforcement learning model that is fitted across all blocks does not capture participant behaviour, see supplementary information). One candidate class of model that has potential here is latent-state models (Cochran &amp; Cisler, 2019), in which the variance and unexpected changes in the process being learned (which have a degree of similarity with noise and volatility respectively) is estimated and used to alter the model’s rates of updating as well as the estimated number of states being considered. Using the model described by Cochran and Cisler, we were unable to replicate the learning rate adaptation demonstrated by participants in the current study (see supplementary information) although it remains possible that other latent state formulations may be more successful. “</p>
<disp-quote content-type="editor-comment">
<p>The discussion may benefit from a little more discussion of where this work leads us - what is the next step?</p>
</disp-quote>
<p>As above, we have added in a suggestion about future modelling work. We have also added in a section about the outstanding interesting questions concerning the neural representation of these quantities, reproduced in response to the suggestion by reviewer #2 below.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations for the authors):</bold></p>
<p>The study presents an opportunity to explore potential neural coding models that could account for the cognitive processes underlying the task. In the field of neural coding, noise correlation is often measured to understand how a population of neurons responds to the same stimulus, which could be related to the noise signal in this task. Since the brain likely treats the stimulus as the same, with noise representing minor changes, this aspect could be linked to the participants' difficulty distinguishing noise from volatility. On the other hand, signal correlation is used to understand how neurons respond to different stimuli, which can be mapped to the volatility signal in the task. It would be highly beneficial if the authors could discuss how these established concepts from neural population coding might relate to the Bayesian behavior model used in the study. For instance, how might neurons encode the distinction between noise and volatility at a population level? Could noise correlation lead to the misattribution of noise as volatility at a neural level, mirroring the behavioral findings? Discussing possible neural models that could explain the observed behavior and relating it to the existing literature on neural population coding would significantly enrich the discussion. It would also open up avenues for future research, linking these behavioral findings to potential neural mechanisms.</p>
</disp-quote>
<p>We thank the reviewer for this interesting suggestion. We have added in the following paragraph to the discussion section which we hope does justice to this interesting questions (page 18):</p>
<p>Previous work examining the neural representations of uncertainty have tended to report correlations between brain activity and some task-based estimate of one form of uncertainty at a time (Behrens et al., 2007; Walker et al., 2020, 2023). We are not aware of work that has, for example, systematically varied volatility and noise and reported distinct correlations for each. An interesting possibility as to how different forms of uncertainty may be encoded is suggested by parallels with the neuronal decoding literature. One question addressed by this literature is how the brain decodes changes in the world from the distributed, noisy neural responses to those changes, with a particular focus on the influence of different forms of between-neuron correlation (Averbeck et al., 2006; Kohn et al., 2016). Specifically, signal-correlation, the degree to which different neurons represent similar external quantities (required to track volatility) is distinguished from, and often limited by, noise-correlation, the degree to which the activity of different neurons covaries independently of these external quantities. One possibility relevant to the current study, which resembles the underlying logic of the BOM, is that a population of neurons represents the estimated mean of the generative process that produces task outcomes. In this case, volatility would be tracked as the signal-correlation across this population, whereas noise would be analogous to the noise-correlation and, crucially, misestimation of noise as volatility might arise as misestimation of these two forms of correlation. While the current study clearly cannot adjudicate on the neural representation of these processes, our finding of distinct behavioural and physiological responses to the two forms of uncertainty, does suggest that separable neural representations of uncertainty are maintained. “</p>
</body>
</sub-article>
</article>