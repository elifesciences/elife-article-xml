<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">107005</article-id>
<article-id pub-id-type="doi">10.7554/eLife.107005</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.107005.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Synaptic Encoding of Time in Working Memory</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6885-9394</contrib-id>
<name>
<surname>Mongillo</surname>
<given-names>Gianluigi</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<email>gianluigi.mongillo@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5661-4349</contrib-id>
<name>
<surname>Tsodyks</surname>
<given-names>Misha</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f809463</institution-id><institution>School of Natural Sciences, Institute for Advanced Study</institution></institution-wrap>, <city>Princeton</city>, <country country="US">United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/000zhpw23</institution-id><institution>Sorbonne Université, INSERM, CNRS, Institut de la Vision</institution></institution-wrap>, <city>Paris</city>, <country country="FR">France</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02feahw73</institution-id><institution>Centre National de la Recherche Scientifique</institution></institution-wrap>, <city>Paris</city>, <country country="FR">France</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0316ej306</institution-id><institution>Department of Brain Sciences, Weizmann Institute of Science</institution></institution-wrap>, <city>Rehovot</city>, <country country="IL">Israel</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Sharpee</surname>
<given-names>Tatyana O</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Salk Institute for Biological Studies</institution>
</institution-wrap>
<city>La Jolla</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country country="GR">Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-07-22">
<day>22</day>
<month>07</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP107005</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-04-21">
<day>21</day>
<month>04</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-04-23">
<day>23</day>
<month>04</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.04.21.649874"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Mongillo &amp; Tsodyks</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Mongillo &amp; Tsodyks</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-107005-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>The processing of temporally-extended sequences of stimuli critically relies on Working Memory (WM). Yet, how WM supports the encoding and retrieval of novel sequences is unknown. Existing theories rely on associative learning driven by repetitions and are, thus, unable to explain how people can reproduce novel sequences of stimuli immediately. Here, we propose that detailed temporal information about a novel sequence can be rapidly stored in WM by short-term synaptic plasticity over multiple time scales. To substantiate this proposal, we extend our previously-proposed synaptic theory of WM to include synaptic augmentation, besides more short-lived depression and facilitation, consistently with experimental observations. The long time scales associated with augmentation naturally lead to the emergence of a temporal gradient in the synaptic efficacies, which can be used to immediately replay, at normal speed or in a time-compressed way, novel sequences. The theory is consistent with behavioral and neurophysiological observations.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>sequences</kwd>
<kwd>interval timing</kwd>
<kwd>working memory</kwd>
<kwd>synaptic augmentation</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Purposeful behavior requires storing and retrieving relevant information over multiple time scales. Typically, this information also includes a temporal component that is key to achieve the goal. For instance, to reach the closest coffee place we just asked directions to, we have to turn left at the next corner, walk one block, and then turn right. We’ll get no espresso following the directions in the <italic>wrong</italic> order.</p>
<p>The Working Memory (WM) – a specialized, low-capacity component of the memory system – is believed to be responsible for rapidly encoding and maintaining novel information (e.g., the directions we just asked) over short time scales <xref rid="c1" ref-type="bibr">Cowan [2001</xref>], <xref rid="c2" ref-type="bibr">Baddeley [2003</xref>]. But, exactly, which information about a novel sequence of stimuli is stored in WM?</p>
<p>People effortlessly remember short but otherwise arbitrary (i.e., novel) sequences of familiar stimuli. For instance, people routinely hum short tunes they have just heard while musicians can even replay them with fidelity. A person can finger-tap, out of memory and with good accuracy, a pattern of irregularly spaced clicks spread over a few seconds which has been just experienced. The encoding of serial order, in particular, has been extensively investigated in the <italic>serial recall</italic> task <xref rid="c3" ref-type="bibr">Kahana [2012</xref>]. In this task, a list of randomly chosen items (e.g., words) is presented sequentially to the subject that, then, has to recall them in the presented order. This task is thought to rely on WM and, indeed, the number of correctly recalled items – typically about 4 items – is a standard measure of WM capacity. Interestingly, people almost invariably recall short lists (i.e., within WM capacity) in the presented order, even without explicit instructions to do so, as in the <italic>free recall</italic> task <xref rid="c4" ref-type="bibr">Dimperio et al. [2005]</xref>, <xref rid="c5" ref-type="bibr">Ward et al. [2010]</xref>, <xref rid="c6" ref-type="bibr">Grenfell-Essam and Ward [2012]</xref>.</p>
<p>These observations suggest that WM rapidly and automatically stores quite detailed temporal information about a novel sequence of familiar stimuli, besides information about the stimuli themselves. Furthermore, this temporal information can be retrieved without any special training.</p>
<p>The models originally proposed for the computational architecture of WM have no mechanism for the encoding of temporal information <xref rid="c1" ref-type="bibr">Cowan [2001]</xref>, <xref rid="c2" ref-type="bibr">Baddeley [2003]</xref>. As to neuronal models of WM (i.e., short-term memory maintenance), there have been different proposals. The most popular idea is that active maintenance relies on the co-existence of stable steady states of activity in the memory network (attractors) that are selected by stimulus presentations <xref rid="c7" ref-type="bibr">Amit [1995]</xref>, <xref rid="c8" ref-type="bibr">Amit and Brunel [1997]</xref>, <xref rid="c9" ref-type="bibr">Wang [2021]</xref>. The current state of activity, thus, reflects the recent history of stimulation. This mechanism can store the identity of the stimuli in the sequence but not information about their relative timing (e.g., the order of occurrence). Instead, this information needs to be learned in the course of multiple repetitions of the <italic>same</italic> sequence Kleinfeld [1986], <xref rid="c11" ref-type="bibr">Sompolinsky and Kanter [1986]</xref>.</p>
<p>Partly to address the inability of attractor networks to <italic>rapidly</italic> store temporal information, an alternative account has been proposed <xref rid="c12" ref-type="bibr">Maass et al. [2002]</xref>, <xref rid="c13" ref-type="bibr">Buonomano and Maass [2009]</xref>. In this account, active maintenance relies on the transitory, but high-dimensional, responses elicited by stimulus presentation in the memory network (liquid state machine). Such a mechanism can rapidly store the identify of the stimuli as well as detailed information about their times of occurrence, thanks to the high-dimensionality of the response. However, it is now the read-out of this information that needs to be learned, again in the course of multiple repetitions <xref rid="c14" ref-type="bibr">Cueva et al. [2020]</xref>, <xref rid="c15" ref-type="bibr">Zhou et al. [2023]</xref>.</p>
<p>Somehow surprisingly in view of their profound differences, these two accounts make one identical prediction; temporal information about a <italic>novel</italic> sequence of stimuli is not immediately available (e.g., to produce some behavior), either because it has not been stored yet (attractor networks) or because it cannot yet be read-out (liquid state machines). We have just discussed evidence contrary to this prediction.</p>
<p>We have proposed that information is maintained in WM by synaptic facilitation within the neuronal populations that code for the items, rather than by the enhanced, persistent activity of those populations <xref rid="c16" ref-type="bibr">Mongillo et al. [2008]</xref>. Facilitation is an experimentally well-characterized transient enhancement of the synaptic efficacy that is quickly induced by pre-synaptic spiking activity and can last for up to several seconds <xref rid="c17" ref-type="bibr">Markram et al. [1998]</xref>, <xref rid="c18" ref-type="bibr">Zucker and Regehr [2002]</xref>. In particular, facilitation was reported at inter-pyramidal connections in the prefrontal cortex, a region heavily implicated in WM <xref rid="c19" ref-type="bibr">Hempel et al. [2000]</xref>, <xref rid="c20" ref-type="bibr">Wang et al. [2006]</xref>. The theory is compatible with multiple experimental observations and motivated further experiments aimed at disentangling persistent activity and information maintenance <xref rid="c21" ref-type="bibr">Rose et al. [2016]</xref>, <xref rid="c22" ref-type="bibr">Wolff et al. [2017]</xref>, <xref rid="c23" ref-type="bibr">Panichello et al. [2024]</xref>.</p>
<p>In the framework of the synaptic theory of WM, the maintenance of information can be achieved by different regimes of neuronal activity, depending on the background input to the network; at increasing levels of the background input, these regimes are: (i) activity-silent, where the information is transiently maintained without enhanced spiking activity; (ii) low-activity, where the information is periodically refreshed, at low rate, by brief spontaneous reactivations of corresponding neuronal populations (i.e., population spikes, PSs); (iii) persistent-activity, where the information is maintained by tonically active neuronal populations.</p>
<p>Facilitation is not the only form of transient synaptic enhancement induced by repetitive pre-synaptic activity. Exper-iments reveal other forms, such as augmentation and potentiation, which build up more slowly than facilitation but are significantly more long-lived <xref rid="c24" ref-type="bibr">Fisher et al. [1997]</xref>, <xref rid="c25" ref-type="bibr">Thomson [2000]</xref>, <xref rid="c26" ref-type="bibr">Fioravante and Regehr [2011]</xref>. As a result, the instantaneous value of the synaptic efficacy can reflect the history of pre-synaptic activation over tens of seconds (i.e., the time scale of augmentation) or even minutes (i.e., the time scale of potentiation) rather than just seconds (i.e., the time scale of facilitation). In the present contribution, we propose that such a transient synaptic enhancement over multiple time scales allows the encoding of <italic>both</italic> stimulus <italic>and</italic> temporal information in the instantaneous synaptic efficacies.</p>
<p>To substantiate this proposal, we extend the synaptic theory of WM to include synaptic augmentation, observed in the prefrontal cortex at the same synapses that exhibit significant short-term facilitation <xref rid="c19" ref-type="bibr">Hempel et al. [2000]</xref>, <xref rid="c20" ref-type="bibr">Wang et al. [2006]</xref>.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Results</title>
<p>To illustrate the putative role of synaptic augmentation in the encoding of temporal information, we consider the simplified setting used in <xref rid="c22" ref-type="bibr">Mi et al. [2017]</xref>. The network is composed of <italic>P</italic> distinct excitatory populations, that represent the memory items, and one inhibitory population, that prevents simultaneous activity at enhanced rates in the excitatory populations. The recurrent synaptic connections within each excitatory population display short-term synaptic plasticity according to the Tsodyks-Markram (TM) model <xref rid="c17" ref-type="bibr">Markram et al. [1998]</xref>. The population-averaged synaptic input to population <italic>a</italic> (<italic>a</italic> = 1, …, <italic>P</italic>), <italic>h</italic><sub><italic>a</italic></sub>, evolves in time according to
<disp-formula id="eqn1">
<graphic xlink:href="649874v1_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>τ</italic> is the neuronal time constant; <italic>I</italic><sub><italic>a</italic></sub>(<italic>t</italic>), the external input to population <italic>a</italic>, is the sum of two components: a background input, to control the activity regime of the network, and a selective input, to elicit enhanced activity during the presentation of the corresponding item; <italic>A</italic><sub><italic>a</italic></sub> is the average strength of the synapses within excitatory population <italic>a</italic>; <italic>r</italic><sub><italic>a</italic></sub>, the average activity of population <italic>a</italic>, is a smoothed threshold-linear function of <italic>h</italic><sub><italic>a</italic></sub>, i.e.,
<disp-formula id="eqn2">
<graphic xlink:href="649874v1_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>α &gt;</italic> 0 is a parameter controlling the smoothing; <italic>u</italic><sub><italic>a</italic></sub> and <italic>x</italic><sub><italic>a</italic></sub> are, respectively, the levels of short-term facilitation and depression of the recurrent synapses within population <italic>a</italic>; <italic>A</italic><sub><italic>EI</italic></sub> is the strength of the synapses from the inhibitory population to any excitatory population; <italic>r</italic><sub><italic>I</italic></sub> = <italic>ϕ</italic> (<italic>h</italic><sub><italic>I</italic></sub>) is the average activity of the inhibitory population, and
<disp-formula id="eqn3">
<graphic xlink:href="649874v1_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>I</italic><sub><italic>I</italic></sub> is the constant background input to the inhibitory population and <italic>A</italic><sub><italic>IE</italic></sub> is the strength of the synapses from any excitatory population to the inhibitory population.</p>
<p>The levels of short-term facilitation and depression, <italic>u</italic><sub><italic>a</italic></sub> and <italic>x</italic><sub><italic>a</italic></sub>, evolve in time according to <xref rid="c17" ref-type="bibr">Tsodyks et al. [1998]</xref>:
<disp-formula id="eqn4">
<graphic xlink:href="649874v1_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn5">
<graphic xlink:href="649874v1_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>U</italic> is the baseline release probability; <italic>τ</italic><sub><italic>F</italic></sub> and <italic>τ</italic><sub><italic>D</italic></sub> are the facilitation and depression time constants, respectively. In words: Activity in the population induces both facilitation, i.e., it increases <italic>u</italic><sub><italic>a</italic></sub>, and depression, i.e., it decreases <italic>x</italic><sub><italic>a</italic></sub>, while, in the absence of activity (i.e., <italic>r</italic><sub><italic>a</italic></sub> = 0), facilitation and depression decay to their respective baseline levels, <italic>u</italic><sub><italic>a</italic></sub> = <italic>U</italic> and <italic>x</italic><sub><italic>a</italic></sub> = 1.</p>
<p>In <xref rid="c22" ref-type="bibr">Mi et al. [2017]</xref>, the <italic>A</italic><sub><italic>a</italic></sub>’s in <xref ref-type="disp-formula" rid="eqn1">Equation 1</xref> are time-independent parameters with the same value for all the excitatory populations. By contrast here, to model synaptic augmentation, the <italic>A</italic><sub><italic>a</italic></sub>’s are activity-dependent dynamic variables that increase with the <italic>r</italic><sub><italic>a</italic></sub>’s according to
<disp-formula id="eqn6">
<graphic xlink:href="649874v1_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>Ā</italic> is the basal average strength of the synapses within an excitatory population (i.e., following a long period of synaptic inactivity), <italic>τ</italic><sub><italic>A</italic></sub> is the augmentation time constant, <italic>K</italic><sub><italic>A</italic></sub> controls how fast the average strength of the synapses, <italic>A</italic><sub><italic>a</italic></sub>, increases with the activity, and <italic>A</italic><sub><italic>M</italic></sub> is the maximal increase of the basal synaptic strength that can be induced by augmentation. In the following, we take <italic>A</italic><sub><italic>M</italic></sub> = 3<italic>Ā</italic>.</p>
<p>The physiological mechanisms responsible for synaptic augmentation are poorly understood <xref rid="c24" ref-type="bibr">Fisher et al. [1997]</xref>, <xref rid="c25" ref-type="bibr">Thomson [2000]</xref>, <xref rid="c26" ref-type="bibr">Fioravante and Regehr [2011]</xref>. <xref ref-type="disp-formula" rid="eqn6">Equation 6</xref> provides a minimal phenomenological description of synaptic augmentation in the spirit of the original TM model <xref rid="c17" ref-type="bibr">Markram et al. [1998]</xref>. However, as it will become clear in the following, our results do not depend critically on this modeling choice. For instance, one would obtain the same results by modeling augmentation as an activity-dependent increase in the baseline release probability <italic>U</italic> (data not shown). Facilitating synaptic transmission observed at inter-pyramidal synapses in the prefrontal cortex is well described by the above model with the following choice of synaptic parameters: <italic>U</italic> ∼ 0.2, <italic>τ</italic><sub><italic>F</italic></sub> ∼ 1s, <italic>τ</italic><sub><italic>D</italic></sub> ∼ 0.1s, <italic>τ</italic><sub><italic>A</italic></sub> ∼ 10s and <italic>K</italic><sub><italic>A</italic></sub> ≪ 1 <xref rid="c19" ref-type="bibr">Hempel et al. [2000]</xref>, <xref rid="c20" ref-type="bibr">Wang et al. [2006]</xref>, <xref rid="c29" ref-type="bibr">Barri et al. [2016]</xref>. The full set of network and short-term plasticity parameters used in the simulations can be found in the caption of <xref rid="fig1" ref-type="fig">Fig. 1</xref>.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Network activity encodes sequence information.</title>
<p>Network responses to 3 sequentially presented items with (A) and without synaptic augmentation (B). The bottom panel in (A) shows the level of synaptic augmentation in the corresponding synaptic populations. The presentation of an item is simulated by a 10-fold increase of the background input selectively to the corresponding neuronal population for 250ms (gray areas). The background input to the remaining populations is kept constant at its baseline level. Network parameters: <italic>P</italic> = 16, <italic>τ</italic> = 8ms, <italic>α</italic> = 1.5Hz, <italic>A</italic><sub><italic>EE</italic></sub> = 6.0, <italic>A</italic><sub><italic>EI</italic></sub> = 1.1, <italic>A</italic><sub><italic>IE</italic></sub> = 1.75, <italic>I</italic><sub><italic>bkg</italic></sub> = 8.0Hz; Short-term plasticity parameters: <italic>U</italic> = 0.3, <italic>K</italic><sub><italic>A</italic></sub> = 0.01, <italic>τ</italic><sub><italic>D</italic></sub> = 0.3s, <italic>τ</italic><sub><italic>F</italic></sub> = 1.5s, <italic>τ</italic><sub><italic>A</italic></sub> = 20s.</p></caption>
<graphic xlink:href="649874v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In <xref rid="fig1" ref-type="fig">Fig. 1A</xref>, we show the response of the model network to a sequence of 3 items with variable inter-item intervals. The interval between the onset of the first and second item is 1 second, while the interval between the onset of the second and the third item is 2 seconds. Following the presentation of the last item, the neuronal populations that have been stimulated reactivate in a repeating cycle, indicating that the corresponding items are being actively maintained in WM. Importantly, this regime of activity does not correspond to a steady state of the network dynamics. This is evident from the amplitudes of the PS and from the levels of synaptic augmentation in the reactivating neuronal populations (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>, bottom panel) that are still changing with time. Note that the amplitudes of the PS are different for the different populations.</p>
<p>For comparison, we show in <xref rid="fig1" ref-type="fig">Fig. 1B</xref> the response of the network to the same sequence in the absence of synaptic augmentation (i.e., <italic>A</italic><sub><italic>a</italic></sub> = <italic>Ā</italic> and <italic>K</italic><sub><italic>A</italic></sub> = 0). As can be seen, in this case the network dynamics rapidly (on a time scale ∼ <italic>τ</italic><sub><italic>F</italic></sub>) converge to a steady, attractor state; the amplitude of the PS is the same for all the reactivating populations. Once this state reached, the network activity carries no information about the sequence beyond the identity of the stimuli composing the sequence.</p>
<p>The transient regime exhibited by the model network in the presence of augmentation is long-lived because the level of augmentation grows slowly with time. As can be seen in the bottom panel of <xref rid="fig1" ref-type="fig">Fig. 1A</xref>, significant augmentation only occurs during the reactivations. The increase of the augmentation level with each reactivation is mainly controlled by <italic>K</italic><sub><italic>A</italic></sub> and <italic>K</italic><sub><italic>A</italic></sub> is small, consistently with the experiments. As a result, the levels of synaptic augmentation in the reactivating neuronal populations are still changing with time long after the presentation of the last item in the sequence. At the same time, the decay of the level of augmentation between two consecutive reactivations of the same population (∼<italic>τ</italic><sub><italic>D</italic></sub>) is negligible, because <italic>τ</italic><sub><italic>D</italic></sub> ≪ <italic>τ</italic><sub><italic>A</italic></sub>. Therefore, the longer an item has been active in WM – that is, the larger the number of reactivations – the larger the corresponding level of augmentation. Indeed, the level of augmentation encodes, quite accurately, the time elapsed since item’s presentation (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>, bottom panel).</p>
<p>In summary, in the presence of synaptic augmentation, WM activity naturally encodes the temporal structure of a novel sequence of familiar items, besides encoding information about the identity of the single items. As this information is present in the levels of synaptic augmentation and in the amplitudes of the PSs during the reactivations, it is readily accessible to a downstream read-out network.</p>
<p>To illustrate this important point, we consider a very simple read-out mechanism to reconstruct/replay the sequence stored in WM (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Replay of a novel sequence.</title>
<p>(A) Architecture of the memory and read-out network (see main text for details). (B) Top panel: Input to the read-out network from the memory network. Middle panel: Activation state of the item-selective populations in the read-out network, as determined by comparing the sum of the input from the memory network and of the background input to the threshold. Bottom panel: Time course of the background input to the read-out network. (C) Same as (B) for a different sequence. Note that the time course of the background input to the read-out network is the same in (B) and (C).</p></caption>
<graphic xlink:href="649874v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Each item-selective population in the memory network sends excitatory inputs to the corresponding item-selective population in a read-out network. For simplicity, we assume that the excitatory synapses between the memory and the read-out network feature the same dynamics as the excitatory synapses within the memory network. The activation of a population in the read-out network signals the retrieval of the corresponding item. The item-selective populations in the read-out network do not interact with each other. Rather, they receive a uniform background input (i.e., the same for all populations) that effectively sets the threshold for their activation. To read-out the contents of WM, following the presentation of the last stimulus, the background input ramps up until the first population in the read-out network activates, and then stays constant.</p>
<p>This mechanism results in the approximate replay of the sequence stored in WM. We illustrate this in <xref rid="fig2" ref-type="fig">Fig. 2B</xref> and <xref rid="fig2" ref-type="fig">C</xref> for two different sequences and the <italic>same</italic> read-out network. This is because the temporal evolution of the level of augmentation and of the amplitude of the PSs in the active populations are approximately time-translation invariant; that is, they are approximately the same when aligned to stimulus onset. Hence, the inputs from the memory to the read-out network will reach the same level (i.e., the same threshold) at time intervals that (approximately) match the time intervals between the presentations of the corresponding items. For the same reason, the accuracy of the replay is rather robust against (reasonable) changes in the rate of increase of the input to the read-out network.</p>
<p>The augmentation gradient can also be used to fast-replay the sequence stored in WM (i.e., in a time-compressed way). Fast replay has been suggested as a mechanism for consolidating the storage of information in the long-term memory, by bringing patterns of neuronal activity representing temporally distant events within a time window in which associative, long-term synaptic plasticity can most effectively operate <xref rid="c30" ref-type="bibr">Melamed et al. [2004]</xref>, <xref rid="c31" ref-type="bibr">Jensen and Lisman [2005]</xref>. The time-compressed replay of the sequence is initiated by decreasing the level of background input to the WM network for (at least) a time ∼ <italic>τ</italic><sub><italic>F</italic></sub> (3, bottom panel). This prevents further reactivations (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, top panel) and the synaptic variables start decaying toward their baseline levels (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, middle panel). The background input is then raised again to a suitably larger level. The levels of augmentation, i.e., the <italic>A</italic><sub><italic>a</italic></sub>’s, have hardly changed because <italic>τ</italic><sub><italic>F</italic></sub> ≪ <italic>τ</italic><sub><italic>A</italic></sub>. However, short-term depression and facilitation will be close to their corresponding baseline levels (i.e., <italic>x</italic><sub><italic>a</italic></sub> ≃ 1 and <italic>u</italic><sub><italic>a</italic></sub> ≃ <italic>U</italic> for <italic>a</italic> = 1, …, <italic>P</italic>). For the once-active neuronal populations, however, the steady, low-rate state of activity becomes unstable when the background input is raised above a critical level. Hence, they will start reactivating, with the most unstable one (i.e., the one with the larger <italic>A</italic><sub><italic>a</italic></sub>) reactivating first, the next most unstable one reactivating second, and so on <xref rid="c22" ref-type="bibr">Mi et al. [2017]</xref>. As a result, the reactivations follow the temporal gradient encoded in the augmentation levels (<xref rid="fig2" ref-type="fig">Fig. 2</xref>, top panel). Note that the network replays the sequence in about 250 ms, thus achieving a compression factor of about 10.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Fast-replay of a novel sequence.</title>
<p>The top panel shows the response of the network to the external inputs depicted in the bottom panel. After the presentation of the sequence, the background input is first decreased for 3 seconds and then increased for 250 milliseconds. The middle panel shows the resulting time course of <italic>Aux</italic> in the corresponding synaptic populations. Immediately before the background input is increased again, <italic>Aux</italic> ≃ <italic>AU</italic>.</p></caption>
<graphic xlink:href="649874v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>There is significant experimental evidence that items can be maintained in WM in different <italic>representational</italic> states and that these states can be rapidly altered by task demand <xref rid="c32" ref-type="bibr">LaRocque et al. [2014]</xref>, <xref rid="c33" ref-type="bibr">Oberauer and Awh [2022]</xref>. A case in point is the study of <xref rid="c21" ref-type="bibr">Rose et al. [2016]</xref>, who used a retro-cue design to manipulate these putative representational states. Briefly, human subjects performed a two-item delayed recognition task with two retro-cues and two recognition probes per trial. Following items’ presentation and an initial delay period, the first retro-cue informed the subject about which of the two items will be probed in the impending (i.e., after a delay period) recognition test. The cued item is considered <italic>prioritized</italic> for upcoming behavior. After the first recognition test, a second retro-cue indicated the item to be probed, following another delay period, in the second recognition test. Importantly, each retro-cue randomly prioritized either of the two items with the same probability and, hence, both items had to be kept in WM until the second retro-cue. <xref rid="c21" ref-type="bibr">Rose et al. [2016]</xref> found that, during the initial delay period, both items could be reliably decoded from the fMRI signal. By contrast, during the delay period between a retro-cue and the subsequent recognition test, only the prioritized item could be reliably decoded. However, the decodability of the de-prioritized item could be recovered by transcranial magnetic stimulation.</p>
<p>The experimental observations of <xref rid="c21" ref-type="bibr">Rose et al. [2016]</xref> (see also <xref rid="c22" ref-type="bibr">Wolff et al. [2017]</xref>) support the idea that there exist (at least) two states of ‘maintenance in WM’ with distinct neurophysiological signatures. Though the relationship between the fMRI signal and neural activity is not an obvious one, these results have been interpreted as indicating that these two states differ in their level of neural activity. In particular, the failure to decode would indicate the absence of enhanced spiking activity (but see <xref rid="c34" ref-type="bibr">Barbosa et al. [2021]</xref>).</p>
<p>Our model network can reproduce these experimental observations, as illustrated in <xref rid="fig4" ref-type="fig">Fig. 4</xref>. Similarly to the experiment of <xref rid="c21" ref-type="bibr">Rose et al. [2016]</xref>, two items are presented and, after the initial delay period, one of the two is prioritized. We simulate the effect of the retro-cue on neural activity by assuming that the de-prioritized item receives a lower external input as compared to the prioritized item (<xref rid="fig4" ref-type="fig">Fig. 4</xref>, bottom panel). Note that, as in the experiment of <xref rid="c21" ref-type="bibr">Rose et al. [2016]</xref> there are only two items, prioritizing one item is the same as de-prioritizing the other item. Following the first retro-cue, the neuronal population encoding the prioritized item keeps reactivating while the neuronal population encoding the de-prioritized item stops reactivating (<xref rid="fig4" ref-type="fig">Fig. 4</xref>, top panel). We account for the results of <xref rid="c21" ref-type="bibr">Rose et al. [2016]</xref> by assuming that only reactivating items can be decoded.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Reactivation of an activity-silent memory.</title>
<p>The top panel shows the response of the network to the external inputs depicted in the bottom panel. 8 seconds after the presentation of the two items, the background input to the neuronal population selective to second item (red) is decreased for 8 seconds, and then restored to its original level, while decreasing the background input to the neuronal population selective to the first item (blue). The middle panel shows the resulting time course of the level of augmentation in the corresponding synaptic populations.</p></caption>
<graphic xlink:href="649874v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In the absence of neural activity, the ‘working memory’ of the de-prioritized item is kept by the augmentation level (<xref rid="fig4" ref-type="fig">Fig. 4</xref>, middle panel). To illustrate this, we prioritize with the second retro-cue the previously de-prioritized item and, indeed, the corresponding neuronal population resumes its reactivating dynamics (<xref rid="fig4" ref-type="fig">Fig. 4</xref>, top panel). In the presence of synaptic augmentation, the time span of the activity-silent regime becomes of the order of <italic>τ</italic><sub><italic>A</italic></sub>, which is of the order of 10 seconds, and hence fully consistent with the experimental observations of <xref rid="c21" ref-type="bibr">Rose et al. [2016]</xref>. We note that in the model originally proposed in <xref rid="c16" ref-type="bibr">Mongillo et al. [2008]</xref>, instead, the time span of the activity-silent regime was of the order of <italic>τ</italic><sub><italic>F</italic></sub> (∼ 1 s), <italic>quantitatively</italic> inconsistent with the results of <xref rid="c21" ref-type="bibr">Rose et al. [2016]</xref>.</p>
</sec>
<sec id="s3">
<label>3</label>
<title>Discussion</title>
<p>We propose that transient, non-associative synaptic plasticity over multiple time scale can support the temporally-structured encoding of a sequence of stimuli. We have illustrated this idea in a minimal model network that extends the synaptic theory of WM to include synaptic augmentation, besides synaptic depression and facilitation. In the low-activity regime, where items are maintained by short-lived reactivations of the corresponding neuronal populations, the presence of synaptic augmentation naturally leads to a temporal gradient in the synaptic efficacies that encodes both the items and their relative times of occurrence. This gradient can then be used to replay the sequence either at normal speed or in a time-compressed way. The mechanism that generates the temporal gradient is robust, because it relies on the order-of-magnitude differences between the build-up and the decay time of the augmentation and those of the depression and facilitation.</p>
<p>Our model allows the storage and the retrieval of short sequences of items by relying on synaptic plasticity mechanisms that are well-characterized experimentally, that is, the transient enchancement on multiple time scales of the synaptic efficacy driven <italic>solely</italic> by pre-synaptic activity <xref rid="c24" ref-type="bibr">Fisher et al. [1997]</xref>, <xref rid="c25" ref-type="bibr">Thomson [2000]</xref>, <xref rid="c26" ref-type="bibr">Fioravante and Regehr [2011]</xref>. Alternative models, as already pointed out, rely instead on some form of <italic>associative</italic> learning <xref rid="c35" ref-type="bibr">Botvinick and Watanabe [2007]</xref>, <xref rid="c36" ref-type="bibr">Gillett et al. [2020]</xref>, <xref rid="c37" ref-type="bibr">Ryom et al. [2021]</xref>, <xref rid="c15" ref-type="bibr">Zhou et al. [2023]</xref>. At the physiological level, associative learning is thought to entail long-term synaptic plasticity. This is because the induction of long-term synaptic plasticity is dependent on the joint pattern of pre- and post-synaptic activity, as required for associativity. However, there is presently no evidence that long-term synaptic plasticity can be induced and/or expressed on the time scales relevant to explain the experimental observations, that is, a few seconds <xref rid="c38" ref-type="bibr">Lansner et al. [2023]</xref>.</p>
<p>A key prediction of our theory is that items are maintained in the low-activity regime. Indeed, if the items are maintained either in the activity-silent regime or in the persistent-activity regime, the proposed mechanism fails. In the first case, because in the absence of reactivations the gradient does not build up; in the second case, because the augmentation levels quickly saturate due to the enhanced firing rates. This prediction is consistent with multiple experimental observations <xref rid="c39" ref-type="bibr">Siegel et al. [2009]</xref>, <xref rid="c40" ref-type="bibr">Fuentemilla et al. [2010]</xref>, <xref rid="c41" ref-type="bibr">Lundqvist et al. [2016]</xref>, <xref rid="c23" ref-type="bibr">Panichello et al. [2024]</xref>. In multi-item working memory tasks, the neuronal activity during the maintenance period is characterized by short episodes of spiking synchrony, detected as brief gamma bursts in the local field potential <xref rid="c39" ref-type="bibr">Siegel et al. [2009]</xref>, <xref rid="c41" ref-type="bibr">Lundqvist et al. [2016]</xref> or in the MEG/EEG signal <xref rid="c40" ref-type="bibr">Fuentemilla et al. [2010]</xref>. These episodes, which we identify with the population spikes in our model, are associated with the reactivation of the neural representation of the items, as evidenced by the fact that item’s identity can be reliably decoded only during the gamma bursts. Importantly, during a given gamma burst, only information about one of the maintained items can be reliably decoded <xref rid="c40" ref-type="bibr">Fuentemilla et al. [2010]</xref>, <xref rid="c41" ref-type="bibr">Lundqvist et al. [2016]</xref>, suggesting that the items are reactivated one at a time, as required by our theory.</p>
<p>Behavioral data in serial-recall tasks strongly support the notion that the encoding of serial order relies on a <italic>primacy gradient</italic> that prioritizes recall <xref rid="c42" ref-type="bibr">Grossberg [1978]</xref>, <xref rid="c43" ref-type="bibr">Farrell and Lewandowsky [2004]</xref>, <xref rid="c45" ref-type="bibr">Hurlstone and Hitch [2015, 2018]</xref>. Our theory makes an explicit proposal as to its neurophysiological substrate: The primacy gradient is encoded by the augmentation levels and its generation depends on a specific interplay of the synaptic and neuronal dynamics (as described above). As such, the generation of the gradient is an inescapable consequence of the active maintenance of an item in WM. This would naturally explain why the recall order tends to be the same as the presentation order also in free-recall tasks, provided that the sequence does not exceed WM capacity.</p>
<p>In the behavioral context, our theory also makes novel predictions. For instance, the temporal gradient builds up gradually with the reactivations of the corresponding neuronal populations between consecutive presentations. This requires a presentation rate that is slow enough for these reactivations to occur in sufficient number. Hence, as the presentation rate is increased, the theory predicts that encoding of the serial order should degrade. Consistently with this prediction, increasing the presentation rate of the items results in a larger number of transposition errors, that is, some items are recalled at the wrong serial position (see, e.g., <xref rid="c43" ref-type="bibr">Farrell and Lewandowsky [2004]</xref>). Experiments with very rapid serial visual presentation (RSVP) of the items show that the subjects are unable to report the correct order of presentation, even when the number of items is below capacity <xref rid="c46" ref-type="bibr">Reeves and Sperling [1986]</xref>. At the other extreme, if the presentation rate is too slow, or the list is too long, then the primacy gradient will also degrade because of the saturation of the synaptic augmentation, or the inability of actively maintaining all the items. Consistently with this prediction, in serial-recall tasks, the spontaneous tendency in recalling the items with the presented order rapidly degrades with increasing list lengths <xref rid="c6" ref-type="bibr">Grenfell-Essam and Ward [2012]</xref>.</p>
<p>We have used, to illustrate our theory, a minimal model network that neglects many physiological details. Hence, a comparison between the model behavior and the electrophysiological observations cannot be completely direct. Nevertheless, the model provides a unified account of diverse features of the experimental data, at least qualitatively.</p>
<p>The model naturally generates ramping activity as a consequence of active maintenance, that is, the average level of activity in a reactivating neuronal population increases with time (see, e.g., <xref rid="fig1" ref-type="fig">Fig. 1</xref>). Ramping activity has been proposed as a potential neuronal mechanism to encode time and it is commonly observed in electrophysiological studies of WM. A case in point is the recent study of <xref rid="c14" ref-type="bibr">Cueva et al. [2020]</xref>, who found ramping activity during the maintenance period of different delayed-response tasks, regardless of whether or not timing was important to perform the task. Interestingly, the non-steady dynamics of neuronal activity during the delay period was almost entirely explained by the ramping activity <xref rid="c14" ref-type="bibr">Cueva et al. [2020]</xref>. We note that these observations are fully consistent with our model.</p>
<p>In neurophysiological studies of WM for sequences, the conjunctive coding of item identity and serial-order information at the single-neuron level has also commonly been observed <xref rid="c47" ref-type="bibr">Barone and Joseph [1989]</xref>, <xref rid="c48" ref-type="bibr">Funahashi et al. [1997]</xref>, <xref rid="c49" ref-type="bibr">Xie et al. [2022]</xref>. Conjunctive coding refers to the modulation of neuron’s activity by both item and order information, so that, for instance, the average firing rate of the neuron during the delay period following different sequences with the same item changes depending on the position of the item in the sequence <xref rid="c49" ref-type="bibr">Xie et al. [2022]</xref>. Also in our model the firing rate of a neuron is naturally sensitive to the temporal order due to the augmentation gradient (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). It remains to be seen whether our model, in a more physiologically-detailed setting, is able to quantitatively account for some features of conjunctive coding as observed in experiments <xref rid="c49" ref-type="bibr">Xie et al. [2022]</xref>. In this respect, an important caveat is that animals in these studies have been extensively trained on the task with a limited number of sequences. Extensive training and sequences’ repetition could lead to the emergence of stimulus-adapted neuronal representations via associative plasticity mechanisms <xref rid="c35" ref-type="bibr">Botvinick and Watanabe [2007]</xref>, <xref rid="c36" ref-type="bibr">Gillett et al. [2020]</xref>, <xref rid="c37" ref-type="bibr">Ryom et al. [2021]</xref>.</p>
<p>The long time scales brought about by synaptic augmentation significantly extend the time span of memories maintained in the activity-silent state. As discussed in the Results section, the time scales of synaptic augmentation are fully compatible with the experimental observations, such as those of <xref rid="c21" ref-type="bibr">Rose et al. [2016]</xref>, suggesting that a memory that has been <italic>silent</italic> for 10 seconds can still be successfully retrieved upon cueing (see <xref rid="fig4" ref-type="fig">Fig. 4</xref>). Accordingly, one would expect a very large <italic>storage</italic> capacity in the activity-silent mode. For instance, by assuming that an item is to be refreshed every ∼ 10 seconds to prevent its loss (based on <xref rid="c21" ref-type="bibr">Rose et al. [2016]</xref>), and that the refresh takes 100 milliseconds (based on <xref rid="c40" ref-type="bibr">Fuentemilla et al. [2010]</xref>, <xref rid="c41" ref-type="bibr">Lundqvist et al. [2016]</xref>), one would estimate a storage capacity of 100 items for the activity-silent WM. This raises the possibility that WM capacity, which is an experimental estimate of (uncued) <italic>recall</italic>, could result from the inability to retrieve the information, rather than from the inability to encode and/or maintain it. In this scenario, WM capacity is ultimately determined by the degree of <italic>selectivity</italic> that the background control – that we identify with the “central executive” or the “focus of attention” of cognitive theories – can attain.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>G.M. work is supported by grants ANR-19-CE16-0024-01 and ANR-20-CE16-0011-02 from the French National Research Agency and by a grant from the Simons Foundation (891851, G.M.). M.T. is supported by the Israeli Science Foundation grant 1657/19 and Foundation Adelis.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N</given-names> <surname>Cowan</surname></string-name></person-group>. <article-title>The magical number 4 in short-term memory: A reconsideration of mental storage capacity</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>24</volume>:<fpage>87</fpage>–<lpage>114</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alan</given-names> <surname>Baddeley</surname></string-name></person-group>. <article-title>Working memory: looking back and looking forward</article-title>. <source>Nature reviews neuroscience</source>, <volume>4</volume>(<issue>10</issue>):<fpage>829</fpage>–<lpage>839</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Michael Jacob</given-names> <surname>Kahana</surname></string-name></person-group>. <source>Foundations of human memory</source>. <publisher-name>Oxford University Press</publisher-name>, <year>2012</year>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Krystal</given-names> <surname>Dimperio</surname></string-name>, <string-name><given-names>Kelly</given-names> <surname>Addis</surname></string-name>, and <string-name><given-names>Michael</given-names> <surname>Kahana</surname></string-name></person-group>. <article-title>A comparative analysis of serial and free recall</article-title>. <source>Memory &amp; Cognition</source>, <volume>33</volume>:<fpage>833</fpage>–<lpage>839</lpage>, 08 <year>2005</year>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Geoff</given-names> <surname>Ward</surname></string-name>, <string-name><given-names>Lydia</given-names> <surname>Tan</surname></string-name>, and <string-name><given-names>Rachel</given-names> <surname>Grenfell-Essam</surname></string-name></person-group>. <article-title>Examining the relationship between free recall and immediate serial recall: the effects of list length and output order</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>36</volume>(<issue>5</issue>):<fpage>1207</fpage>–<lpage>1241</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Rachel</given-names> <surname>Grenfell-Essam</surname></string-name> and <string-name><given-names>Geoff</given-names> <surname>Ward</surname></string-name></person-group>. <article-title>Examining the relationship between free recall and immediate serial recall: The role of list length, strategy use, and test expectancy</article-title>. <source>Journal of Memory and Language</source>, <volume>67</volume>(<issue>1</issue>):<fpage>106</fpage>–<lpage>148</lpage>, <year>2012</year>. ISSN <issn>0749-596X</issn>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Daniel J.</given-names> <surname>Amit</surname></string-name></person-group>. <article-title>The hebbian paradigm reintegrated: Local reverberations as internal representations</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>18</volume>(<issue>4</issue>):<fpage>617</fpage> – <lpage>626</lpage>, <year>1995</year>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Daniel J</given-names> <surname>Amit</surname></string-name> and <string-name><given-names>Nicolas</given-names> <surname>Brunel</surname></string-name></person-group>. <article-title>Model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex</article-title>. <source>Cerebral cortex (New York, NY: 1991)</source>, <volume>7</volume>(<issue>3</issue>):<fpage>237</fpage>–<lpage>252</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name></person-group>. <article-title>50 years of mnemonic persistent activity: quo vadis?</article-title> <source>Trends in Neurosciences</source>, <volume>44</volume>(<issue>11</issue>):<fpage>888</fpage>–<lpage>902</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>David</given-names> <surname>Kleinfeld</surname></string-name></person-group>. <article-title>Sequential state generation by model neural networks</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>83</volume>(<issue>24</issue>):<fpage>9469</fpage>–<lpage>9473</lpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Haim</given-names> <surname>Sompolinsky</surname></string-name> and <string-name><given-names>Ido</given-names> <surname>Kanter</surname></string-name></person-group>. <article-title>Temporal association in asymmetric neural networks</article-title>. <source>Physical review letters</source>, <volume>57</volume> (<issue>22</issue>):<fpage>2861</fpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Wolfgang</given-names> <surname>Maass</surname></string-name>, <string-name><given-names>Thomas</given-names> <surname>Natschläger</surname></string-name>, and <string-name><given-names>Henry</given-names> <surname>Markram</surname></string-name></person-group>. <article-title>Real-time computing without stable states: A new framework for neural computation based on perturbations</article-title>. <source>Neural computation</source>, <volume>14</volume>(<issue>11</issue>):<fpage>2531</fpage>–<lpage>2560</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Dean V</given-names> <surname>Buonomano</surname></string-name> and <string-name><given-names>Wolfgang</given-names> <surname>Maass</surname></string-name></person-group>. <article-title>State-dependent computations: spatiotemporal processing in cortical networks</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>10</volume>(<issue>2</issue>):<fpage>113</fpage>–<lpage>125</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Christopher J</given-names> <surname>Cueva</surname></string-name>, <string-name><given-names>Alex</given-names> <surname>Saez</surname></string-name>, <string-name><given-names>Encarni</given-names> <surname>Marcos</surname></string-name>, <string-name><given-names>Aldo</given-names> <surname>Genovesio</surname></string-name>, <string-name><given-names>Mehrdad</given-names> <surname>Jazayeri</surname></string-name>, <string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name>, <string-name><given-names>C Daniel</given-names> <surname>Salzman</surname></string-name>, <string-name><given-names>Michael N</given-names> <surname>Shadlen</surname></string-name>, and <string-name><given-names>Stefano</given-names> <surname>Fusi</surname></string-name></person-group>. <article-title>Low-dimensional dynamics for working memory and time encoding</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>117</volume>(<issue>37</issue>):<fpage>23021</fpage>–<lpage>23032</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Shanglin</given-names> <surname>Zhou</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Seay</surname></string-name>, <string-name><given-names>Jiannis</given-names> <surname>Taxidis</surname></string-name>, <string-name><given-names>Peyman</given-names> <surname>Golshani</surname></string-name>, and <string-name><given-names>Dean V</given-names> <surname>Buonomano</surname></string-name></person-group>. <article-title>Multiplexing working memory and time in the trajectories of neural networks</article-title>. <source>Nature Human Behaviour</source>, <volume>7</volume>(<issue>7</issue>):<fpage>1170</fpage>–<lpage>1184</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gianluigi</given-names> <surname>Mongillo</surname></string-name>, <string-name><given-names>Omri</given-names> <surname>Barak</surname></string-name>, and <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name></person-group>. <article-title>Synaptic theory of working memory</article-title>. <source>Science</source>, <volume>319</volume>(<issue>5869</issue>):<fpage>1543</fpage>–<lpage>1546</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Henry</given-names> <surname>Markram</surname></string-name>, <string-name><given-names>Yun</given-names> <surname>Wang</surname></string-name>, and <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name></person-group>. <article-title>Differential signaling via the same axon of neocortical pyramidal neurons</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>95</volume>(<issue>9</issue>):<fpage>5323</fpage>–<lpage>5328</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Robert S.</given-names> <surname>Zucker</surname></string-name> and <string-name><given-names>Wade G.</given-names> <surname>Regehr</surname></string-name></person-group>. <article-title>Short-term synaptic plasticity</article-title>. <source>Annual Review of Physiology</source>, <volume>64</volume>(<issue>1</issue>):<fpage>355</fpage>–<lpage>405</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Chris M</given-names> <surname>Hempel</surname></string-name>, <string-name><given-names>Kenichi H</given-names> <surname>Hartman</surname></string-name>, <string-name><given-names>X-J</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Gina G</given-names> <surname>Turrigiano</surname></string-name>, and <string-name><given-names>Sacha B</given-names> <surname>Nelson</surname></string-name></person-group>. <article-title>Multiple forms of short-term plasticity at excitatory synapses in rat medial prefrontal cortex</article-title>. <source>Journal of neurophysiology</source>, <volume>83</volume>(<issue>5</issue>):<fpage>3031</fpage>–<lpage>3041</lpage>, <year>2000</year>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yun</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Henry</given-names> <surname>Markram</surname></string-name>, <string-name><given-names>Philip H</given-names> <surname>Goodman</surname></string-name>, <string-name><given-names>Thomas K</given-names> <surname>Berger</surname></string-name>, <string-name><given-names>Junying</given-names> <surname>Ma</surname></string-name>, and <string-name><given-names>Patricia S</given-names> <surname>Goldman-Rakic</surname></string-name></person-group>. <article-title>Heterogeneity in the pyramidal network of the medial prefrontal cortex</article-title>. <source>Nature neuroscience</source>, <volume>9</volume>(<issue>4</issue>):<fpage>534</fpage>—542, <year>2006</year>. ISSN <issn>1097-6256</issn>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Nathan S.</given-names> <surname>Rose</surname></string-name>, <string-name><given-names>Joshua J.</given-names> <surname>LaRocque</surname></string-name>, <string-name><given-names>Adam C.</given-names> <surname>Riggall</surname></string-name>, <string-name><given-names>Olivia</given-names> <surname>Gosseries</surname></string-name>, <string-name><given-names>Michael J.</given-names> <surname>Starrett</surname></string-name>, <string-name><given-names>Emma E.</given-names> <surname>Meyering</surname></string-name>, and <string-name><given-names>Bradley R.</given-names> <surname>Postle</surname></string-name></person-group>. <article-title>Reactivation of latent working memories with transcranial magnetic stimulation</article-title>. <source>Science</source>, <volume>354</volume> (<issue>6316</issue>):<fpage>1136</fpage>–<lpage>1139</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Michael J</given-names> <surname>Wolff</surname></string-name>, <string-name><given-names>Janina</given-names> <surname>Jochim</surname></string-name>, <string-name><given-names>Elkan G</given-names> <surname>Akyürek</surname></string-name>, and <string-name><given-names>Mark G</given-names> <surname>Stokes</surname></string-name></person-group>. <article-title>Dynamic hidden states underlying working-memory-guided behavior</article-title>. <source>Nature neuroscience</source>, <volume>20</volume>(<issue>6</issue>):<fpage>864</fpage>–<lpage>871</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Matthew F</given-names> <surname>Panichello</surname></string-name>, <string-name><given-names>Donatas</given-names> <surname>Jonikaitis</surname></string-name>, <string-name><given-names>Yu Jin</given-names> <surname>Oh</surname></string-name>, <string-name><given-names>Shude</given-names> <surname>Zhu</surname></string-name>, <string-name><given-names>Ethan B</given-names> <surname>Trepka</surname></string-name>, and <string-name><given-names>Tirin</given-names> <surname>Moore</surname></string-name></person-group>. <article-title>Intermittent rate coding and cue-specific ensembles support working memory</article-title>. <source>Nature</source>, pages <fpage>1</fpage>–<lpage>8</lpage>, <year>2024</year>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Stephen A</given-names> <surname>Fisher</surname></string-name>, <string-name><given-names>Thomas M</given-names> <surname>Fischer</surname></string-name>, and <string-name><given-names>Thomas J</given-names> <surname>Carew</surname></string-name></person-group>. <article-title>Multiple overlapping processes underlying short-term synaptic enhancement</article-title>. <source>Trends in neurosciences</source>, <volume>20</volume>(<issue>4</issue>):<fpage>170</fpage>–<lpage>177</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alex M</given-names> <surname>Thomson</surname></string-name></person-group>. <article-title>Facilitation, augmentation and potentiation at central synapses</article-title>. <source>Trends in neurosciences</source>, <volume>23</volume>(<issue>7</issue>): <fpage>305</fpage>–<lpage>312</lpage>, <year>2000</year>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Diasynou</given-names> <surname>Fioravante</surname></string-name> and <string-name><given-names>Wade G</given-names> <surname>Regehr</surname></string-name></person-group>. <article-title>Short-term forms of presynaptic plasticity</article-title>. <source>Current opinion in neurobiology</source>, <volume>21</volume>(<issue>2</issue>):<fpage>269</fpage>–<lpage>274</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yuanyuan</given-names> <surname>Mi</surname></string-name>, <string-name><given-names>Mikhail</given-names> <surname>Katkov</surname></string-name>, and <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name></person-group>. <article-title>Synaptic correlates of working memory capacity</article-title>. <source>Neuron</source>, <volume>93</volume>(<issue>2</issue>): <fpage>323</fpage>–<lpage>330</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name>, <string-name><given-names>Klaus</given-names> <surname>Pawelzik</surname></string-name>, and <string-name><given-names>Henry</given-names> <surname>Markram</surname></string-name></person-group>. <article-title>Neural networks with dynamic synapses</article-title>. <source>Neural Computation</source>, <volume>10</volume>(<issue>4</issue>):<fpage>821</fpage>–<lpage>835</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alessandro</given-names> <surname>Barri</surname></string-name>, <string-name><given-names>Yun</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>David</given-names> <surname>Hansel</surname></string-name>, and <string-name><given-names>Gianluigi</given-names> <surname>Mongillo</surname></string-name></person-group>. <article-title>Quantifying repetitive transmission at chemical synapses: a generative-model approach</article-title>. <source>ENeuro</source>, <volume>3</volume>(<issue>2</issue>), <year>2016</year>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ofer</given-names> <surname>Melamed</surname></string-name>, <string-name><given-names>Wulfram</given-names> <surname>Gerstner</surname></string-name>, <string-name><given-names>Wolfgang</given-names> <surname>Maass</surname></string-name>, <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name>, and <string-name><given-names>Henry</given-names> <surname>Markram</surname></string-name></person-group>. <article-title>Coding and learning of behavioral sequences</article-title>. <source>Trends in neurosciences</source>, <volume>27</volume>(<issue>1</issue>):<fpage>11</fpage>–<lpage>14</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ole</given-names> <surname>Jensen</surname></string-name> and <string-name><given-names>John E</given-names> <surname>Lisman</surname></string-name></person-group>. <article-title>Hippocampal sequence-encoding driven by a cortical multi-item working memory buffer</article-title>. <source>Trends in neurosciences</source>, <volume>28</volume>(<issue>2</issue>):<fpage>67</fpage>–<lpage>72</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Joshua J</given-names> <surname>LaRocque</surname></string-name>, <string-name><given-names>Jarrod A</given-names> <surname>Lewis-Peacock</surname></string-name>, and <string-name><given-names>Bradley R</given-names> <surname>Postle</surname></string-name></person-group>. <article-title>Multiple neural states of representation in short-term memory? it’sa matter of attention</article-title>. <source>Frontiers in human neuroscience</source>, <volume>8</volume>:<fpage>5</fpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Klaus</given-names> <surname>Oberauer</surname></string-name> and <string-name><given-names>Edward</given-names> <surname>Awh</surname></string-name></person-group>. <article-title>Is There an Activity-silent Working Memory?</article-title> <source>Journal of Cognitive Neuroscience</source>, <volume>34</volume>(<issue>12</issue>):<fpage>2360</fpage>–<lpage>2374</lpage>, 11 <year>2022</year>. ISSN <issn>0898-929X</issn>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Joao</given-names> <surname>Barbosa</surname></string-name>, <string-name><given-names>Diego</given-names> <surname>Lozano-Soldevilla</surname></string-name>, and <string-name><given-names>Albert</given-names> <surname>Compte</surname></string-name></person-group>. <article-title>Pinging the brain with visual impulses reveals electrically active, not activity-silent, working memories</article-title>. <source>PLoS biology</source>, <volume>19</volume>(<issue>10</issue>):<fpage>e3001436</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Matthew</given-names> <surname>Botvinick</surname></string-name> and <string-name><given-names>Takamitsu</given-names> <surname>Watanabe</surname></string-name></person-group>. <article-title>From numerosity to ordinal rank: a gain-field model of serial order representation in cortical working memory</article-title>. <source>Journal of Neuroscience</source>, <volume>27</volume>(<issue>32</issue>):<fpage>8636</fpage>–<lpage>8642</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Maxwell</given-names> <surname>Gillett</surname></string-name>, <string-name><given-names>Ulises</given-names> <surname>Pereira</surname></string-name>, and <string-name><given-names>Nicolas</given-names> <surname>Brunel</surname></string-name></person-group>. <article-title>Characteristics of sequential activity in networks with temporally asymmetric hebbian learning</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>117</volume>(<issue>47</issue>):<fpage>29948</fpage>–<lpage>29958</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Kwang Il</given-names> <surname>Ryom</surname></string-name>, <string-name><given-names>Vezha</given-names> <surname>Boboeva</surname></string-name>, <string-name><given-names>Oleksandra</given-names> <surname>Soldatkina</surname></string-name>, and <string-name><given-names>Alessandro</given-names> <surname>Treves</surname></string-name></person-group>. <article-title>Latching dynamics as a basis for short-term recall</article-title>. <source>PLoS computational biology</source>, <volume>17</volume>(<issue>9</issue>):<fpage>e1008809</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Anders</given-names> <surname>Lansner</surname></string-name>, <string-name><given-names>Florian</given-names> <surname>Fiebig</surname></string-name>, and <string-name><given-names>Pawel</given-names> <surname>Herman</surname></string-name></person-group>. <article-title>Fast hebbian plasticity and working memory</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>83</volume>:<fpage>102809</fpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Markus</given-names> <surname>Siegel</surname></string-name>, <string-name><given-names>Melissa R</given-names> <surname>Warden</surname></string-name>, and <string-name><given-names>Earl K</given-names> <surname>Miller</surname></string-name></person-group>. <article-title>Phase-dependent neuronal coding of objects in short-term memory</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>106</volume>(<issue>50</issue>):<fpage>21341</fpage>–<lpage>21346</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Lluís</given-names> <surname>Fuentemilla</surname></string-name>, <string-name><given-names>Will D</given-names> <surname>Penny</surname></string-name>, <string-name><given-names>Nathan</given-names> <surname>Cashdollar</surname></string-name>, <string-name><given-names>Nico</given-names> <surname>Bunzeck</surname></string-name>, and <string-name><given-names>Emrah</given-names> <surname>Düzel</surname></string-name></person-group>. <article-title>Theta-coupled periodic replay in working memory</article-title>. <source>Current Biology</source>, <volume>20</volume>(<issue>7</issue>):<fpage>606</fpage>–<lpage>612</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mikael</given-names> <surname>Lundqvist</surname></string-name>, <string-name><given-names>Jonas</given-names> <surname>Rose</surname></string-name>, <string-name><given-names>Pawel</given-names> <surname>Herman</surname></string-name>, <string-name><given-names>Scott L</given-names> <surname>Brincat</surname></string-name>, <string-name><given-names>Timothy J</given-names> <surname>Buschman</surname></string-name>, and <string-name><given-names>Earl K</given-names> <surname>Miller</surname></string-name></person-group>. <article-title>Gamma and beta bursts underlie working memory</article-title>. <source>Neuron</source>, <volume>90</volume>(<issue>1</issue>):<fpage>152</fpage>–<lpage>164</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Stephen</given-names> <surname>Grossberg</surname></string-name></person-group>. <article-title>Behavioral contrast in short term memory: serial binary memory models or parallel continuous memory models?</article-title> <source>Journal of Mathematical Psychology</source>, <volume>17</volume>(<issue>3</issue>):<fpage>199</fpage>–<lpage>219</lpage>, <year>1978</year>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Simon</given-names> <surname>Farrell</surname></string-name> and <string-name><given-names>Stephan</given-names> <surname>Lewandowsky</surname></string-name></person-group>. <article-title>Modelling transposition latencies: Constraints for theories of serial order memory</article-title>. <source>Journal of Memory and Language</source>, <volume>51</volume>(<issue>1</issue>):<fpage>115</fpage>–<lpage>135</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mark J</given-names> <surname>Hurlstone</surname></string-name> and <string-name><given-names>Graham J</given-names> <surname>Hitch</surname></string-name></person-group>. <article-title>How is the serial order of a spatial sequence represented? insights from transposition latencies</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>41</volume>(<issue>2</issue>):<fpage>295</fpage>–<lpage>324</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mark J</given-names> <surname>Hurlstone</surname></string-name> and <string-name><given-names>Graham J</given-names> <surname>Hitch</surname></string-name></person-group>. <article-title>How is the serial order of a visual sequence represented? Insights from transposition latencies</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>44</volume>(<issue>2</issue>):<fpage>167</fpage>–<lpage>192</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Adam</given-names> <surname>Reeves</surname></string-name> and <string-name><given-names>George</given-names> <surname>Sperling</surname></string-name></person-group>. <article-title>Attention gating in short-term visual memory</article-title>. <source>Psychological review</source>, <volume>93</volume>(<issue>2</issue>): <fpage>180</fpage>–<lpage>206</lpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P</given-names> <surname>Barone</surname></string-name> and <string-name><given-names>JP</given-names> <surname>Joseph</surname></string-name></person-group>. <article-title>Prefrontal cortex and spatial sequencing in macaque monkey</article-title>. <source>Experimental brain research</source>, <volume>78</volume>:<fpage>447</fpage>–<lpage>464</lpage>, <year>1989</year>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Shintaro</given-names> <surname>Funahashi</surname></string-name>, <string-name><given-names>Masato</given-names> <surname>Inoue</surname></string-name>, and <string-name><given-names>Kisou</given-names> <surname>Kubota</surname></string-name></person-group>. <article-title>Delay-period activity in the primate prefrontal cortex encoding multiple spatial positions and their order of presentation</article-title>. <source>Behavioural brain research</source>, <volume>84</volume>(<issue>1-2</issue>):<fpage>203</fpage>–<lpage>223</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yang</given-names> <surname>Xie</surname></string-name>, <string-name><given-names>Peiyao</given-names> <surname>Hu</surname></string-name>, <string-name><given-names>Junru</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Jingwen</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Weibin</given-names> <surname>Song</surname></string-name>, <string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Tianming</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>Stanislas</given-names> <surname>Dehaene</surname></string-name>, <string-name><given-names>Shiming</given-names> <surname>Tang</surname></string-name>, <string-name><given-names>Bin</given-names> <surname>Min</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Geometry of sequence working memory in macaque prefrontal cortex</article-title>. <source>Science</source>, <volume>375</volume> (<issue>6581</issue>):<fpage>632</fpage>–<lpage>639</lpage>, <year>2022</year>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107005.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Sharpee</surname>
<given-names>Tatyana O</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Salk Institute for Biological Studies</institution>
</institution-wrap>
<city>La Jolla</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> manuscript addresses the longstanding question of how the brain maintains serial order in working memory, proposing a biologically grounded model based on synaptic augmentation mechanisms that operates on longer time scales than facilitation. The authors show that augmentation provides a mechanism by which this order can be maintained in memory thanks to a temporal gradient of synaptic efficacies. Although the evidence remains <bold>incomplete</bold> at present, it can be made stronger by demonstrating robustness to network heterogeneity, spiking, and threshold values for encoding the working memory.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107005.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The issue of how the brain can maintain the serial order of presented items in working memory is a major unsolved question in cognitive neuroscience. It has been proposed that this serial order maintenance could be achieved thanks to periodic reactivations of different presented items at different phases of an oscillation, but the mechanisms by which this could be achieved by brain networks, as well as the mechanisms of read-out, are still unclear. In an influential 2008 paper, the authors have proposed a mechanism by which a recurrent network of neurons could maintain multiple items in working memory, thanks to `population spikes' of populations of neurons encoding for the different items, occurring at alternating times. These population spikes occur in a specific regime of the network and are a result of synaptic facilitation, an experimentally observed type of synaptic short-term dynamics with time scales of order hundreds of ms.</p>
<p>In the present manuscript, the authors extend their model to include another type of experimentally observed short-term synaptic plasticity termed synaptic augmentation, which operates on longer time scales on the order of 10s. They show that while a network without augmentation loses information about serial order, augmentation provides a mechanism by which this order can be maintained in memory thanks to a temporal gradient of synaptic efficacies. The order can then be read out using a read-out network whose synapses are also endowed with synaptic augmentation. Interestingly, the read-out speed can be regulated using background inputs.</p>
<p>Strengths:</p>
<p>This is an elegant solution to the problem of serial order maintenance that only relies on experimentally observed features of synapses. The model is consistent with a number of experimental observations in humans and monkeys. The paper will be of interest to a broad readership, and I believe it will have a strong impact on the field.</p>
<p>Weaknesses:</p>
<p>(1) The network they propose is extremely simple. This simplicity has pros and cons: on the one hand, it is nice to see the basic phenomenon exposed in the simplest possible setting. On the other hand, it would also be reassuring to check that the mechanism is robust when implemented in a more realistic setting, using, for instance, a network of spiking neurons similar to the one they used in the 2008 paper. The more noisy and heterogeneous the setting, the better.</p>
<p>(2) One major issue with the population spike scenario is that (to my knowledge) there is no evidence that these highly synchronized events occur in delay periods of working memory experiments. It seems that highly synchronized population spikes would imply (a) a strong regularity of spike trains of neurons, at odds with what is typically observed in vivo (b) high synchronization of neurons encoding for the same item (and also of different items in situations where multiple items have to be held in working memory), also at odds with in vivo recordings that typically indicate weak synchronization at best. It would be nice if the authors at least mention this issue, and speculate on what could possibly bridge the gap between their highly regular and synchronized network, and brain networks that seem to lie at the opposite extreme (highly irregular and weakly synchronized). Of course, if they can demonstrate using a spiking network simulation that they can bridge the gap, even better.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107005.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this manuscript, the authors present a model to explain how working memory (WM) encodes both existence and timing simultaneously using transient synaptic augmentation. A simple yet intriguing idea.</p>
<p>The model presented here has the potential to explain what previous theories like 'active maintenance via attractors' and 'liquid state machine' do not, and describe how novel sequences are immediately stored in WM. Altogether, the topic is of great interest to those studying higher cognitive processes, and the conclusions the authors draw are certainly thought-provoking from an experimental perspective. However, several questions remain that need to be addressed.</p>
<p>The study relates to the well-known computational theory for working memory, which suggests short-term synaptic facilitation is required to maintain working memory, but doesn't rely on persistent spiking. This previous theory appears similar to the proposed theory, except for the change from facilitation to augmentation. A more detailed explanation of why the authors use augmentation instead of facilitation in this paper is warranted: is the facilitation too short to explain the whole process of WM? Can the theory with synaptic facilitation also explain the immediate storage of novel sequences in WM?</p>
<p>In Figure 1, the authors mention that synaptic augmentation leads to an increased firing rate even after stimulus presentation. It would be good to determine, perhaps, what the lowest threshold is to see the encoding of a WM task, and whether that is biologically plausible.</p>
<p>In the middle panel of Figure 4, after 15-16 sec, when the neuronal population prioritizes with the second retro-cue, although the second retro-cue item's synaptic spike dominates, why is the augmentation for the first retro-cue item higher than the second-cue augmentation until the 20 sec?</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107005.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Mongillo</surname>
<given-names>Gianluigi</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6885-9394</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Tsodyks</surname>
<given-names>Misha</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5661-4349</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>(1) The network they propose is extremely simple. This simplicity has pros and cons: on the one hand, it is nice to see the basic phenomenon exposed in the simplest possible setting. On the other hand, it would also be reassuring to check that the mechanism is robust when implemented in a more realistic setting, using, for instance, a network of spiking neurons similar to the one they used in the 2008 paper. The more noisy and heterogeneous the setting, the better.</p>
</disp-quote>
<p>The choice of a minimal model to illustrate our hypothesis is deliberate. Our main goal was to suggest a physiologically-grounded mechanism to rapidly encode temporally-structured information (i.e., sequences of stimuli) in Working Memory, where none was available before. Indeed, as discussed in the manuscript, previous proposals were unsatisfactory in several respects. In view of our main goal, we believe that a spiking implementation is beyond the scope of the present work.</p>
<p>We would like to note that the mechanism originally proposed in Mongillo et al. (2008), has been repeatedly implemented, by many different groups, in various spiking network models with different levels of biological realism (see, e.g., Lundquivst et al. (2016), for an especially ‘detailed’ implementation) and, in all cases, the relevant dynamics has been observed. We take this as an indication of ‘robustness’; the relevant network dynamics doesn’t critically depend on many implementation details and, importantly, this dynamics is qualitatively captured by a simple rate model (see, e.g., Mi et al. (2017)).</p>
<p>In the present work, we make a relatively ‘minor’ (from a dynamical point of view) extension of the original model, i.e., we just add augmentation. Accordingly, we are fairly confident that a set of parameters for the augmentation dynamics can be found such that the spiking network behaves, qualitatively, as the rate model. A meaningful study, in our opinion, then would require extensively testing the (large) parameters’ space (different models of augmentation?) to see how the network behavior compares with the relevant experimental observations (which ones? behavioral? physiological?). As said above, we believe that this is beyond the scope of the present work.</p>
<p>This being said, we definitely agree with the reviewer that not presenting a spiking implementation is a limitation of the present work. We will clearly acknowledge, and discuss, this limitation in the revised version.</p>
<disp-quote content-type="editor-comment">
<p>(2) One major issue with the population spike scenario is that (to my knowledge) there is no evidence that these highly synchronized events occur in delay periods of working memory experiments. It seems that highly synchronized population spikes would imply (a) a strong regularity of spike trains of neurons, at odds with what is typically observed in vivo (b) high synchronization of neurons encoding for the same item (and also of different items in situations where multiple items have to be held in working memory), also at odds with in vivo recordings that typically indicate weak synchronization at best. It would be nice if the authors at least mention this issue, and speculate on what could possibly bridge the gap between their highly regular and synchronized network, and brain networks that seem to lie at the opposite extreme (highly irregular and weakly synchronized). Of course, if they can demonstrate using a spiking network simulation that they can bridge the gap, even better.</p>
</disp-quote>
<p>Direct experimental evidence (in monkeys) in support of the existence of highly synchronized events -- to be identified with the ‘population spikes’ of our model -- during the delay period of a memory task is available in the literature and we have cited it, i.e., Panichello et al. (2024). In the revised version, we will provide an explicit discussion of the results of Panichello et al. (2024) and how these results directly relate to our model. After submission, we became aware of another experimental study (in humans) specifically dealing with sequence memory, i.e., Liebe et al. (2025). Their results, again, are fully consistent with our model. We will also provide an explicit discussion of these results in the revised version.</p>
<p>We note that there is no fundamental contradiction between highly synchronized events in ‘small’ neural populations (e.g., a cell assembly) on one hand, and temporally irregular (i.e., Poisson-like) spiking at the single-neuron level and weakly synchronized activity at the network level, on the other hand. This was already illustrated in our original publication, i.e., Mongillo et al. (2008) (see, in particular, Fig. S2).</p>
<p>We further note that the mechanism we propose to encode temporal order -- a temporal gradient in the synaptic efficacies brought about by synaptic augmentation -- would also work if the memory of the items is maintained by ‘tonic’ persistent activity (i.e., without highly synchronized events), provided this activity occurs at suitably low rates such as to prevent the saturation of the synaptic augmentation.</p>
<p>We will include a detailed discussion of these points in the revised version.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>The study relates to the well-known computational theory for working memory, which suggests short-term synaptic facilitation is required to maintain working memory, but doesn't rely on persistent spiking. This previous theory appears similar to the proposed theory, except for the change from facilitation to augmentation. A more detailed explanation of why the authors use augmentation instead of facilitation in this paper is warranted: is the facilitation too short to explain the whole process of WM? Can the theory with synaptic facilitation also explain the immediate storage of novel sequences in WM?</p>
</disp-quote>
<p>In the model, synaptic dynamics displays both short-term facilitation and augmentation (and shortterm depression). Indeed, synaptic facilitation, alone, would be too short-lived to encode novel sequences. This is illustrated in Fig. 1B. We will provide a more detailed discussion of this point in the revised version.</p>
<disp-quote content-type="editor-comment">
<p>In Figure 1, the authors mention that synaptic augmentation leads to an increased firing rate even after stimulus presentation. It would be good to determine, perhaps, what the lowest threshold is to see the encoding of a WM task, and whether that is biologically plausible.</p>
</disp-quote>
<p>We believe that this comment is related to the above point. The reviewer is correct; augmentation alone would require fairly long stimulus presentations to encode an item in WM. ‘Fast’ encoding, indeed, is guaranteed by the presence of short-term facilitation. We will emphasize this important point in the revised version.</p>
<disp-quote content-type="editor-comment">
<p>In the middle panel of Figure 4, after 15-16 sec, when the neuronal population prioritizes with the second retro-cue, although the second retro-cue item's synaptic spike dominates, why is the augmentation for the first retro-cue item higher than the second-cue augmentation until the 20 sec?</p>
</disp-quote>
<p>This is because of the slow build-up and slow decay of the augmentation. When the second item is prioritized, and the corresponding neuronal population re-activates, its augmentation level starts to increase. At the same time, as the first item is now de-prioritized and the corresponding neuronal population is now silent, its augmentation level starts to decrease. Because of the ‘slowness’ of both processes (i.e., augmentation build-up and decay), it takes about 5 seconds for the augmentation level of the second item to overcome the augmentation level of the first item.</p>
<p>We note that the slow time scales of the augmentation dynamics, consistently with experimental observations, are necessary for our mechanism to work.</p>
</body>
</sub-article>
</article>