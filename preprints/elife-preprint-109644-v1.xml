<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">109644</article-id>
<article-id pub-id-type="doi">10.7554/eLife.109644</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.109644.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Immunology and Inflammation</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Evolutionary Biology</subject>
</subj-group>
</article-categories><title-group>
<article-title>Separating selection from mutation in antibody language models</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0607-6025</contrib-id>
<name>
<surname>Matsen</surname>
<given-names>Frederick A</given-names>
<suffix>IV</suffix></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<email>matsen@fredhutch.org</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8617-476X</contrib-id>
<name>
<surname>Dumm</surname>
<given-names>Will</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7289-845X</contrib-id>
<name>
<surname>Sung</surname>
<given-names>Kevin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3915-2023</contrib-id>
<name>
<surname>Johnson</surname>
<given-names>Mackenzie M</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0005-2501-4032</contrib-id>
<name>
<surname>Rich</surname>
<given-names>David</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6713-6904</contrib-id>
<name>
<surname>Starr</surname>
<given-names>Tyler</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0734-9868</contrib-id>
<name>
<surname>Song</surname>
<given-names>Yun S</given-names>
</name>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7590-5563</contrib-id>
<name>
<surname>Fukuyama</surname>
<given-names>Julia</given-names>
</name>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8324-8324</contrib-id>
<name>
<surname>Haddox</surname>
<given-names>Hugh K</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/007ps6h72</institution-id><institution>Computational Biology Program, Fred Hutchinson Cancer Center</institution></institution-wrap>, <city>Seattle</city>, <country country="US">United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00cvxb145</institution-id><institution>Department of Genome Sciences, University of Washington</institution></institution-wrap>, <city>Seattle</city>, <country country="US">United States</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00cvxb145</institution-id><institution>Department of Statistics, University of Washington</institution></institution-wrap>, <city>Seattle</city>, <country country="US">United States</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/006w34k90</institution-id><institution>Howard Hughes Medical Institute</institution></institution-wrap>, <city>Seattle</city>, <country country="US">United States</country></aff>
<aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03r0ha626</institution-id><institution>Department of Biochemistry, University of Utah</institution></institution-wrap>, <city>Salt Lake City</city>, <country country="US">United States</country></aff>
<aff id="a6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an7q238</institution-id><institution>Computer Science Division and Department of Statistics, University of California, Berkeley</institution></institution-wrap>, <city>Berkeley</city>, <country country="US">United States</country></aff>
<aff id="a7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kg8sb98</institution-id><institution>Department of Statistics, Indiana University</institution></institution-wrap>, <city>Bloomington</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Bitbol</surname>
<given-names>Anne-Florence</given-names>
</name>
<contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1020-494X</contrib-id><role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Ecole Polytechnique Federale de Lausanne (EPFL)</institution>
</institution-wrap>
<city>Lausanne</city>
<country country="CH">Switzerland</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Walczak</surname>
<given-names>Aleksandra M</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>CNRS</institution>
</institution-wrap>
<city>Paris</city>
<country country="FR">France</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2026-01-05">
<day>05</day>
<month>01</month>
<year>2026</year>
</pub-date>
<volume>15</volume>
<elocation-id>RP109644</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-10-29">
<day>29</day>
<month>10</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-10-22">
<day>22</day>
<month>10</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.10.21.683652"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2026, Matsen et al</copyright-statement>
<copyright-year>2026</copyright-year>
<copyright-holder>Matsen et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-109644-v1.pdf"/>
<abstract>
<p>Antibodies are encoded by nucleotide sequences that are generated by V(D)J recombination and evolve according to mutation and selection processes. Existing antibody language models, however, focus exclusively on antibodies as strings of amino acids and are fitted using standard language modeling objectives such as masked or autoregressive prediction. In this paper, we first show that fitting models using this objective implicitly incorporates nucleotide-level mutation processes as part of the protein language model, which degrades performance when predicting effects of mutations on functional properties of antibodies. To address this limitation, we devise a new framework: a Deep Amino acid Selection Model (DASM) that learns the selection effects of amino-acid mutations while explicitly factoring out the nucleotide-level mutation process. By fitting selection as a separate term from the mutation process, the DASM exclusively quantifies functional effects: effects that change some aspect of the function of the antibody. This factorization leads to substantially improved performance on standard functional benchmarks. Moreover, our model is an order of magnitude smaller and multiple orders of magnitude faster to evaluate than existing approaches, as well as being readily interpretable.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>antibody language model</kwd>
<kwd>somatic hypermutation</kwd>
<kwd>affinity maturation</kwd>
<kwd>mutation-selection model</kwd>
<kwd>antibody engineering</kwd>
<kwd>functional prediction</kwd>
</kwd-group>
<funding-group>
<award-group id="par-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>HHS | National Institutes of Health (NIH)</institution>
</institution-wrap>
</funding-source>
<award-id>R01-AI146028</award-id>
<principal-award-recipient>
<name>
<surname>Johnson</surname>
<given-names>Mackenzie M</given-names>
</name>
<name>
<surname>Rich</surname>
<given-names>David H</given-names>
</name>
<name>
<surname>Fukuyama</surname>
<given-names>Julia</given-names>
</name>
<name>
<surname>Matsen</surname>
<given-names>Frederick A</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-4">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>HHS | National Institutes of Health (NIH)</institution>
</institution-wrap>
</funding-source>
<award-id>R01-AI146028</award-id>
<principal-award-recipient>

</principal-award-recipient>
</award-group>
<award-group id="par-5">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>HHS | National Institutes of Health (NIH)</institution>
</institution-wrap>
</funding-source>
<award-id>R56-HG013117</award-id>
<principal-award-recipient>
<name>
<surname>Song</surname>
<given-names>Yun S</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-6">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>HHS | National Institutes of Health (NIH)</institution>
</institution-wrap>
</funding-source>
<award-id>R01-HG013117</award-id>
<principal-award-recipient>
<name>
<surname>Song</surname>
<given-names>Yun S</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-7">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>HHS | National Institutes of Health (NIH)</institution>
</institution-wrap>
</funding-source>
<award-id>DP2-AI177890</award-id>
<principal-award-recipient>
<name>
<surname>Starr</surname>
<given-names>Tyler N</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-8">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100014185</institution-id>
<institution>Searle Scholars Program (SSP)</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name>
<surname>Starr</surname>
<given-names>Tyler N</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-9">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id>
<institution>Howard Hughes Medical Institute (HHMI)</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name>
<surname>Haddox</surname>
<given-names>Hugh</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-10">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id>
<institution>Howard Hughes Medical Institute (HHMI)</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name>
<surname>Dumm</surname>
<given-names>Will</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-11">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id>
<institution>Howard Hughes Medical Institute (HHMI)</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name>
<surname>Matsen</surname>
<given-names>Frederick A</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-12">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id>
<institution>Howard Hughes Medical Institute (HHMI)</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name>
<surname>Sung</surname>
<given-names>Kevin</given-names>
</name>
</principal-award-recipient>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Antibodies are remarkable molecules that can bind essentially any target with high affinity and specificity. They are generated naturally through V(D)J recombination and refined through affinity maturation in germinal centers. Antibodies are also important drugs, and improving binding and other important properties is thus an area of active research. A major goal in the field is to predict the effect of changing one amino acid for another at a given site of an antibody, both for antibody engineering and for understanding naturally occurring antibodies.</p>
<p>Antibody “foundation” language models are trained on large datasets of naturally occurring antibody sequences to assist with this and related problems. These models are trained using the masked objective, in which a site is masked from an antibody amino-acid sequence, and the model is trained to predict the masked amino acid given the remaining sequence. Recent models of this type have hundreds of millions or billions of parameters, and are trained on around a billion sequences [<xref ref-type="bibr" rid="c1">1</xref>].</p>
<p>While the masked objective has been very useful for modeling human language [<xref ref-type="bibr" rid="c2">2</xref>], this approach may not be ideal for learning functional effects of mutations to antibody sequences. To understand why, it is useful to consider: what could a language model learn in order to succeed under the masked modeling objective? First, it could memorize the germline genes [<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c4">4</xref>] and learn about the probabilities of V(D)J recombination. Second, it could learn the codon table, as according to this table some amino-acid mutations are much more likely than others. Third, it could learn rates of somatic hypermutation, because codons containing mutable nucleotide sites are more likely to deviate from germline than those in sites that are less mutable [<xref ref-type="bibr" rid="c5">5</xref>]. Finally, after all of these other effects, the model could learn about the impact of amino acid mutations on antibody function, which is the desired signal [<xref ref-type="bibr" rid="c6">6</xref>].</p>
<p>In this paper, we first demonstrate that masked language models learn all these factors shaping antibody sequences, despite most being irrelevant for functional prediction. Indeed, we show that conflating mutation and selection processes degrades performance on functional prediction tasks. We then develop a model that explicitly accounts for phylogenetic relationships, the codon table, and somatic hypermutation patterns, allowing it to focus exclusively on functional effects.</p>
<p>Our approach separates mutation and selection processes by encoding functional effects in a Deep Amino acid Selection Model (DASM) while explicitly modeling mutation using a separate fixed model [<xref ref-type="bibr" rid="c7">7</xref>]. The DASM, trained on substantially less data, outperforms AbLang2 [<xref ref-type="bibr" rid="c3">3</xref>] and general protein language models including ESM2 [<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c9">9</xref>] and ProGen2-small [<xref ref-type="bibr" rid="c10">10</xref>]. Unlike existing models, DASMs process complete sequences in a single pass and directly output selection factors for all possible mutations. DASMs are thus orders of magnitude faster than existing models, enabling intensive use on a laptop without a GPU. We provide a paired (heavy and light chain) model with open weights and associated code as part of our netam package <ext-link ext-link-type="uri" xlink:href="https://github.com/matsengrp/netam">https://github.com/matsengrp/netam</ext-link>.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Antibody language models are biased by nucleotide-level mutation processes</title>
<p>We first sought to understand the effect of nucleotide-level mutation processes on antibody language model prediction. To do so, we used AbLang2 [<xref ref-type="bibr" rid="c3">3</xref>] as a case study. It has been implemented with more consideration of biology than other models, as it distinguishes between germline-encoded and non-germline-encoded sites in its training. To start, we examined a single naive BCR sequence obtained from a recent study that performed deep sequencing of human antibody repertoires [<xref ref-type="bibr" rid="c12">12</xref>]. We iterated over each site in this antibody’s protein sequence, masked the site’s amino acid, and used AbLang2 to compute the likelihood of each of the 19 alternative amino acids at that site, then normalized to get a probability. Next, using the antibody’s nucleotide sequence, we split the alternative amino acids at a given site into two groups: those that can be encoded by a codon a single nucleotide change away from the original codon, and those that require multiple mutations.</p>
<p>We found a striking difference in the AbLang2 amino-acid probabilities (<xref rid="fig1" ref-type="fig">Figure 1a</xref>). The median probability for amino acids requiring multiple mutations to a codon was almost two orders of magnitude lower compared to those that only required one. This bias is consistent with the hypothesis that the AbLang2 predictions are influenced by mutation processes unrelated to selection.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Nucleotide-level mutation processes distort protein language model predictions.</title>
<p><bold>a</bold>: AbLang2 assigns almost 100 lower probabilities to amino acids requiring multiple nucleotide mutations compared to single-mutation variants. Each point represents a possible amino acid substitution at a single site in the amino acid sequence. <bold>b</bold>: AbLang2 probabilities correlate with neutral somatic hypermutation probabilities across the V-encoded portion of nine naive sequences, demonstrating how the model is strongly impacted by mutation bias. Each point represents a site in the sequence. Triangles are outliers that have been brought into the y range. <bold>c</bold>: AbLang2 functional prediction accuracy drops substantially for amino acids that are multiple (2 or 3) nucleotide mutations away from the wildtype codon. Data from [<xref ref-type="bibr" rid="c11">11</xref>].</p></caption>
<graphic xlink:href="683652v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The bias can be explained by the masked training procedure. It has already been established that language models trained with the masked objective memorize germline sequences [<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>]. During somatic hypermutation (SHM), singlenucleotide-per-codon mutations to the germline sequence are much more likely than multi-nucleotide codon mutations. As a result, when predicting relative probabilities of alternative amino acids, language models might be expected to assign much higher probabilities to alternative amino acids that only require a single-nucleotide codon mutation (<xref rid="fig1" ref-type="fig">Figure 1a</xref>).</p>
<p>Given this observation, we also hypothesized that AbLang2 probabilities are influenced by differences in the rate of SHM between sites. SHM is a purpose-built enzymatic process that introduces mutations into BCR-coding DNA [<xref ref-type="bibr" rid="c13">13</xref>], which occurs independently of the process of natural selection in the germinal center. The rate of SHM varies by an order of magnitude or more between sites, and these biases are well characterized using probabilistic models [<xref ref-type="bibr" rid="c7">7</xref>,<xref ref-type="bibr" rid="c14">14</xref>]. To test our hypothesis, we examined nine arbitrarily selected sequences from [<xref ref-type="bibr" rid="c12">12</xref>]. For each sequence, we used a recent model of SHM [<xref ref-type="bibr" rid="c7">7</xref>] to compute per-nucleotide-site rates, and then used the method of [<xref ref-type="bibr" rid="c15">15</xref>] to convert these rates into per-codon-site probabilities of nonsynonymous mutations.</p>
<p>We found a clear correlation between these neutral SHM probabilities and probabilities of mutations estimated using AbLang2 (<xref rid="fig1" ref-type="fig">Figure 1b</xref>). The Wald test for a nonzero slope reported a p-value below machine precision in each case.</p>
<p>We next sought to understand if these biases distorted predictions on a functional prediction task. To do so, we used the largest dataset [<xref ref-type="bibr" rid="c11">11</xref>] of the FLAb [<xref ref-type="bibr" rid="c6">6</xref>] collection of benchmarks. Following the protocol in FLAb, we investigated the correlation between a mutation’s effect on an experimentally measured phenotype, here expression, and the mutation’s plausibility (quantified as pseudoperplexity) according to a model. Perplexity (as defined in the Methods) is the standard way of evaluating the plausibility of a sequence according to a model. Pseudo-perplexity is a variant of perplexity (Methods) which is the standard means of evaluating perplexity for masked language models [<xref ref-type="bibr" rid="c6">6</xref>]. In both defi-nitions, lower perplexity corresponds to a more plausible sequence, and we use negative perplexity here so that correlations between model predictions (negative perplexity) and observable (expression) should be positive. We split these predictions by number of nucleotide mutations per codon mutation, as before.</p>
<p>We found a significant drop (from 0.49 to 0.30) in predictive performance when going from amino acids that required one mutation to those that required multiple mutations (<xref rid="fig1" ref-type="fig">Figure 1c</xref>). Furthermore, when we considered all amino acids together, the correlation remained at 0.34. When we colored these data points by their probability of mutation under an SHM process (<xref rid="figS1" ref-type="fig">Figure S1</xref>), we can clearly see that the data points are spread out by the AbLang2 model according to their SHM rate, hindering functional prediction.</p>
<p>In summary, we found that nucleotide-level effects hamper the ability of AbLang2 to predict functional effects of mutations. We then developed an alternative modeling framework that directly factors out nucleotide-level effects.</p>
</sec>
<sec id="s2b">
<title>Fitting a deep amino acid selection model (DASM)</title>
<p>We implemented a model to learn amino-acid preferences of antibodies without being influenced by germline genes, phylogeny, or SHM biases (<xref rid="fig2" ref-type="fig">Figure 2</xref>). To do so, we extended our previous work estimating a single selection value for every site [<xref ref-type="bibr" rid="c15">15</xref>] to estimating a value for every alternative amino acid at every site. This extension is analogous to going from a dN/dS type estimate [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>] to a sitewise mutation-selection model [<xref ref-type="bibr" rid="c18">18</xref>]. Our previous model only operated on antibody heavy chains. This new model operates on heavy chains, light chains, or heavy-light pairs.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Our model separates mutation from selection to predict functional effects without nucleotide-level biases.</title>
<p><bold>a</bold>: Our model combines a fixed mutation component (trained on non-functional data) with a learned selection component (DASM transformer). Training uses inferred parent-child sequence pairs from reconstructed B cell phylogenies to predict natural affinity maturation after a jointly-inferred time <italic>t</italic>. <bold>b</bold>: The DASM directly predicts selection factors for all amino acid substitutions at every position in a single forward pass. Positive factors indicate beneficial changes, and negative factors indicate deleterious changes.</p></caption>
<graphic xlink:href="683652v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As in this previous work, we performed clonal-family clustering, phylogenetic inference, and ancestral sequence reconstruction to generate collections of nucleotide “parent-child pairs” or PCPs (<xref rid="fig2" ref-type="fig">Figure 2a</xref>). This resulted in around 2 million PCPs that were used for training (Table S1). Instead of predicting the likelihood of nonsynonymous mutations, we predicted the likelihood of codon mutations using a deep-learning analog of a mutation-selection model. The neutral-probability model was inferred separately using out-of-frame data [<xref ref-type="bibr" rid="c7">7</xref>]. We also added a “multihit correction” (see Methods) to this neutral model which accounts for the spatial clustering of SHM [<xref ref-type="bibr" rid="c19">19</xref>], resulting in an elevated probability of multiple mutations in a given codon.</p>
<p>The selection component of the model estimates per-site per-amino-acid selection factors given an input amino-acid sequence via a transformer-encoder (<xref rid="fig2" ref-type="fig">Figure 2b</xref>). We trained DASMs of several sizes (<italic>∼</italic> 1M, <italic>∼</italic>4M, <italic>∼</italic> 7M) using joint optimization of branch length <italic>t</italic> and parameters of the DASM. We found that the <italic>∼</italic> 4M parameter model performed the best according to our objective function. This DASM has 8 attention heads, 32 dimensions per head, a feedforward dimension of 1024, 5 transformer layers, and a dropout probability of 0.1; we will use this version for the rest of the paper.</p>
<p>As an initial comparison between DASM and AbLang2, we used DASM to predict selection factors for the unmutated antibody sequence used in the Koenig benchmark [<xref ref-type="bibr" rid="c11">11</xref>]; we found that the selection factors were predictive of functional measurements irrespective of the number of mutations per codon (<xref rid="fig3" ref-type="fig">Figures 3a</xref> and<xref rid="figS2" ref-type="fig">S2</xref>). We were surprised by the strength of the correlation for amino-acid mutations that require multi-nucleotide codon mutations, given that training signal should be weaker for those rarer mutations. We also found that the selection factors showed very similar distributions for amino-acid mutations requiring single-vs. multi-nucleotide codon mutations (<xref rid="figS3" ref-type="fig">Figure S3</xref>). Furthermore, the DASM selection factors captured the alternating pattern of selective con-straint on beta sheets evident in the expression data (red columns in <xref rid="fig3" ref-type="fig">Figures 3b</xref> and <xref rid="figS4" ref-type="fig">S4</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Comparing model predictions with experimentally measured effects of mutations on antibody expression from [<xref ref-type="bibr" rid="c11">11</xref>].</title>
<p><bold>a</bold>: The DASM maintains high predictive accuracy on functional effects of mutations regardless of codon accessibility. The correlation is equally high for amino-acid mutations that only require a single-nucleotide mutation (left plot) vs. amino-acid mutations that require multi-nucleotide mutations (center plot), demonstrating successful separation of mutation bias from functional effects. Compare <xref ref-type="fig" rid="fig1">Figure 1c</xref>. <bold>b</bold>: DASM predictions mimic patterns in the expression data. For additional heatmap comparisons see <xref ref-type="fig" rid="figS4">Figure S4</xref>.</p></caption>
<graphic xlink:href="683652v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2c">
<title>Thrifty+DASM accurately predicts affinity maturation</title>
<p>Next, we evaluated the ability of the DASM to predict the course of natural affinity maturation. To do so, we used PCPs from the <monospace>Rodriguez</monospace> data (Table S1), which were not used for training the DASM, nor for training AbLang2. For each PCP, we quantified each model’s ability to predict both the location of nonsynonymous mutations in the child sequence and the identity of the mutant amino acid. For the DASM, we computed a mutation’s probability by multiplying the mutation’s selection factor, predicted by the DASM, with its neutral mutation probability, predicted using the same fixed neutral mutation model used to train the DASM [<xref ref-type="bibr" rid="c7">7</xref>].</p>
<p>We found that the DASM-based approach was better than AbLang2 at predicting the location of nonsynonymous mutations observed in the PCPs (<xref rid="figS5" ref-type="fig">Figure S5ab</xref>). In fact, the overlap between observed and expected is substantially better than what we were able to obtain in a highly controlled mouse experiment [<xref ref-type="bibr" rid="c20">20</xref>] with a customized mutation model and a deep mutational scan that quantified how mutations affect binding to the relevant antigen [<xref ref-type="bibr" rid="c21">21</xref>].</p>
<p>We also found that the DASM-based approach was better than AbLang2 at predicting the identities of mutant amino acids. To compare the models at this task, we used a notion of “conditional perplexity”. Specifically, for each PCP where the parent and child sequences differ on the amino-acid level, we calculated the perplexity of the residues in the child that are different from the parent, conditioning probabilities on there being a substitution (see cond-ppl definition in Methods). We do this to give AbLang2 the best chance of succeeding: although it might have difficulty predicting the occurrence of mutations (<xref rid="figS5" ref-type="fig">Figure S5</xref>/conseb) it might still be able to predict the identity of mutations.</p>
<p>Indeed, the DASM had lower conditional perplexity than AbLang2 on 1,000 sequences from the <monospace>Rodriguez</monospace> [<xref ref-type="bibr" rid="c12">12</xref>] dataset (<xref rid="figS5" ref-type="fig">Figure S5c</xref>). The median value for DASM was 4.88, compared to 7.39 for AbLang2. In addition to having a lower median, the DASM also has fewer very large values.</p>
</sec>
<sec id="s2d">
<title>The DASM outperforms masked and autoregressive models at predicting functional effects of mutation</title>
<p>We next performed a more comprehensive characterization of the ability of models to predict mutational effects. We expanded our suite of comparator models to include ESM2 [<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c9">9</xref>], a general protein language model trained with a masked objective, and ProGen2 [<xref ref-type="bibr" rid="c10">10</xref>], an autoregressive language model. We used the small general variant of ProGen2, which the FLAb benchmarking paper found to be the best overall model [<xref ref-type="bibr" rid="c6">6</xref>], and the 650M variant of ESM2. To predict the plausibility of mutant sequences under these models, we followed current practice [<xref ref-type="bibr" rid="c6">6</xref>] and calculated each sequence’s pseudo-perplexity for AbLang2 [<xref ref-type="bibr" rid="c3">3</xref>] and ESM2 [<xref ref-type="bibr" rid="c22">22</xref>], each sequence’s perplexity for ProGen2, and then compared the model outputs to experimentally measured mutational effects using Pearson correlation. To predict mutational effects using the DASM, we simply fed the DASM with the unmutated sequence from the DMS experiment and used the output selection factors as predicted effects. We cannot use perplexity because selection factors alone do not give likelihoods.</p>
<p>To start, we evaluated these models on the two largest datasets from the FLAb collection of benchmarks [<xref ref-type="bibr" rid="c6">6</xref>]. The first data set, from Koenig et al. [<xref ref-type="bibr" rid="c11">11</xref>], is a deep mutational scanning experiment performed on the Fab of the anti-VEGF antibody G6.31. The authors generated single-site saturated mutagenesis libraries incorporating all possible amino-acid mutations to both the variable heavy and variable light domains. Using phage display, they then performed two independent selection steps: one in which they selected for Fab variants that were stably expressed, and another in which they selected for Fab variants that could bind VEGF. They quantified mutational effects on these properties by computing enrichment ratios of each mutation in selected versus unselected pools, as quantified using deep sequencing.</p>
<p>We found that the DASM outperformed the other models on both binding and expression (<xref rid="tbl1" ref-type="table">Table 1</xref>, <xref rid="figS4" ref-type="fig">Figure S4</xref>).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Correlation of models with predicting effects of single mutations on antibody expression and antigen binding, as measured in [<xref ref-type="bibr" rid="c11">11</xref>].</title></caption>
<graphic xlink:href="683652v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>We next turned to the second-biggest dataset of the FLAb benchmark, from Shanehsazzadeh et al. [<xref ref-type="bibr" rid="c23">23</xref>]. In this study, the authors took an anti-HER2 antibody, trastuzumab, and used deep generative models to redesign the heavy chain complementarity determining regions (HCDRs). They generated libraries of HCDR variants, including both HCDR3-only designs and HCDR123 designs. Unlike the first dataset described above, many variants had multiple mutations relative to the unmutated antibody sequence. The experiments expressed antibody variants in E. coli, and sorted by FACS based on binding signal. We restricted our attention to sequences with the two most common heavy chain amino acid lengths (119 and 120) as the other lengths did not have enough data to make a full comparison.</p>
<p>We assessed the ability of models to predict these binding measurements. For the language models, we computed the perplexity of each variant, as before. For the DASM, we calculated a consensus sequence for each sequence length, and then used the DASM to compute selection factors for that sequence. Then, we computed a score for each variant by summing the log selection factors for each amino-acid mutation in the variant relative to the consensus sequence. As above, the resulting correlation is substantially higher for the DASM compared to the other models (<xref rid="tbl2" ref-type="table">Table 2</xref>).</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><title>Correlation of models with binding measurements on the data of [<xref ref-type="bibr" rid="c23">23</xref>], which typically involves multi-mutant variants.</title>
<p>See <xref rid="figS6" ref-type="fig">Figure S6</xref> for scatterplots.</p></caption>
<graphic xlink:href="683652v1_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>For our third validation, we sought to see how our model could predict affinity in the context of large-scale yeast display experiments using MAGMA-seq [<xref ref-type="bibr" rid="c24">24</xref>]. We were especially interested in this assay because the measurement is affinity-only rather than a conflation of affinity and expression as in the previous data sets. Because none of these models are trained in an epitope-specific way this will be a challenge for the models. Specifically, MAGMA-seq determines quantitative monovalent binding affinities through deep sequencing of barcoded Fab libraries sorted at multiple antigen concentrations in a manner analogous to Tite-Seq [<xref ref-type="bibr" rid="c25">25</xref>]. These data are not present in the FLAb benchmarks. We used the largest datasets in the original MAGMA-seq paper [<xref ref-type="bibr" rid="c24">24</xref>] which test variants of influenza antibodies. We also used MAGMA-seq data from [<xref ref-type="bibr" rid="c26">26</xref>] which combinatorially applied mutations from development trajectories of mature human antibodies against SARS-CoV-2 spike protein.</p>
<p>We found that the DASM performed substantially better than other models for this task (<xref rid="tbl3" ref-type="table">Table 3</xref>, <xref rid="figS7" ref-type="fig">Figure S7</xref>). Nearly all correlation coefficients were small, pointing to the difficulty in predicting effects of mutations on antigen-specific binding affinities. Nevertheless, the DASM was the only model to have a positive correlation for most datasets. The UCA 002-S21F2 lineage proved challenging for all models, with all models having a negative correlation. This may not be surprising given that 002-S21F2 uses a rare VH5-51/VK1-33 gene combination found in only 3 out of 5252 SARS-CoV-2 antibodies in the CoV-AbDab database [<xref ref-type="bibr" rid="c27">27</xref>].</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><title>Correlations between model predictions and binding affinity.</title>
<p>The “Petersen” data is from an experiment probing the rules of recognition for influenza neutralizing antibodies [<xref ref-type="bibr" rid="c24">24</xref>] and “Kirby” data is from combinatorial libraries applying combinations of mutations on the path from naive to mature SARS-CoV-2 antibodies [<xref ref-type="bibr" rid="c26">26</xref>]. See <xref ref-type="fig" rid="figS7">Figure S7</xref> for corresponding scatter plots.</p></caption>
<graphic xlink:href="683652v1_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s2e">
<title>DASM models are orders of magnitude faster than competing models, and much smaller</title>
<p>We next compared the computational requirements for doing these evaluations. We imagined two settings: one where a scientist wishes to evaluate a small collection of sequences on their laptop without a GPU, and the other where they wish to evaluate a larger collection of sequences on a GPU server. Our timing script ran the DASM model, as well as AbLang2 and ESM2 using stepwise masking to obtain amino acid likelihoods. The local machine was a MacBook Pro with a M2 Max chip and 96 GB of memory. The GPU server had an AMD EPYC 75F3 32-core processor with 995 GB of memory and an NVIDIA A100 80GB GPU.</p>
<p>The DASM achieved dramatic computational efficiency gains compared to masked language models (<xref rid="tbl4" ref-type="table">Table 4</xref>). On a CPU, the DASM evaluates sequences over 1,000 times faster than AbLang2 and more than 10,000 times faster than ESM2. On a GPU, the DASM is 100 times faster than AbLang2 and over 1,000 times faster than ESM2. This speed advantage comes from the DASM providing predictions for all variants in a single pass, eliminating the need for iterative masking procedures required by masked language models. (We note that it is possible to make predictions from masked language models without masking, although this is not considered best practice because of the influence of the unmasked residue.)</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4:</label>
<caption><title>Computational efficiency comparison on sequences from the MAGMA-seq experiments.</title>
<p>10 sequences were run on CPU, and 100 on the GPU server.</p></caption>
<graphic xlink:href="683652v1_tbl4.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>This evaluation was actually generous to the masked language models, as it assumes that we are evaluating likelihoods of masked sites and combining them to evaluate multi-mutant variants. That is in contrast to what was actually done in the performance evaluation, which is direct evaluation of the sequence perplexity for each sequence individually (which should be more accurate). Pro-Gen2 was not included in this comparison because it is categorically slower for this use case: autoregressive models for a panel of variants require running each variant individually through the model.</p>
<p>The DASM benchmarked here is also significantly smaller than alternate models. It has 4M parameters, compared to 45M for AbLang2, 650M for ESM2, and 151M for ProGen2. We suspect that this efficiency is enabled by DASM learning selection effects only, rather than selection and mutation-level effects as for existing models.</p>
<p>In summary, we imagine end-users will find it convenient to download a small (23 MB) weights file and run the DASM on their laptop, as compared to existing models requiring more powerful hardware.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We have motivated and developed a new direction for protein language modeling. To motivate this approach, we showed how masked language modeling implicitly learned the codon table and somatic hypermutation rates, properties that are orthogonal to antibody function. This incorporation degrades model performance for predicting effects of mutations on antibody expression and binding.</p>
<p>To address this limitation, we introduced a new framework: a Deep Amino Acid Selection Model (DASM), which models selection effects separately from mutation effects. By modeling these components independently, the DASM more accurately predicts the functional consequences of amino-acid mutations while having dramatically reduced computational requirements. The success of our approach highlights the importance of incorporating biological realities into machine-learning models for protein engineering. This aligns with recent calls for deeper dialogue between machine learning and evolutionary biology to address phylogenetic biases in biological foundation models [<xref ref-type="bibr" rid="c28">28</xref>].</p>
<p>Thrifty+DASM can be viewed as a neural-network extension of the models rooted in the work of Halpern and Bruno [<xref ref-type="bibr" rid="c18">18</xref>]. There, the probability of a codon mutation is expressed as the product of that mutation under a neutral nucleotide process, times a term representing the selection for or against the corresponding amino-acid substitution at that site. Although the original model expressed selection coefficients in a parameter-sparse way using equilibrium frequencies, further model elaborations allowed for per-site-per-amino acid selection factors, as described here, either in a fixed-effects [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c30">30</xref>] or random-effects [<xref ref-type="bibr" rid="c31">31</xref>] framework. Other related work includes developing evolutionary models using deep mutational scanning (DMS) experiments [<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c33">33</xref>], and models of sequence-structure compatibility [<xref ref-type="bibr" rid="c34">34</xref>]. Thrifty+DASM also extends our previous work that estimates a single value of natural selection at every site [<xref ref-type="bibr" rid="c15">15</xref>]; such a model is not comparable to an antibody foundation model because it does not estimate per-amino-acid probabilities.</p>
<p>By separating out selection from mutation and the effect of evolutionary contingency, DASMs provide direct interpretability: the selection factors indicate which amino-acid mutations are beneficial or deleterious at each position. This interpretability could prove valuable for antibody engineering, where understanding which specific mutations would drive improved expression or binding is crucial for rational design. More broadly, this interpretability could help delineate the relationship between antibody sequence, structure, and function, which we plan to explore in future manuscripts. For users wishing to explore the relationship between DASM selection factors and structure for human antibodies in the SAbDAb database [<xref ref-type="bibr" rid="c35">35</xref>], we have made interactive 3D visualizations of DASM selection factors using <monospace>dms-viz</monospace> [<xref ref-type="bibr" rid="c36">36</xref>] available at <ext-link ext-link-type="uri" xlink:href="https://matsen.group/dasm-viz/v1/">https://matsen.group/dasm-viz/v1/</ext-link>.</p>
<p>We will also explore fine-tuning of these models. While DASM provides better-than-state-of-the-art zero-shot performance on binding benchmarks, recent work for binding focuses on using protein embeddings as inputs to subsequent classifiers [<xref ref-type="bibr" rid="c37">37</xref>], or fine-tuning for binding prediction [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c38">38</xref>]. Because the DASM framework separates mutation from functional properties, a fine-tuned DASM may improve on these previous efforts.</p>
<p>We are beginning the process of extending DASMs to other settings. Although antibodies form an interesting first application of DASMs, and have many properties that make DASMs a useful tool, DASMs are not restricted to the antibody case. Viral sequences also exist in abundance and may be amenable to the DASM approach. Rather than many clonal families for antibodies, we will fit a DASM with many separate alignments for related but distinct evolutionary histories.</p>
<p>Taking this idea to its logical extent, we would like to train a DASM model analogous to ESM [<xref ref-type="bibr" rid="c22">22</xref>] for all proteins. However, this will be a major computational undertaking. Even setting training such a model aside, doing phylogeny and ancestral sequence reconstruction on all protein alignments will require careful planning. If we followed the steps used here for phylogeny and ancestral sequence reconstruction on the 2.6 million sequence alignments used for the MSA Transformer [<xref ref-type="bibr" rid="c39">39</xref>] it would take around 3,000 CPU-years.</p>
<p>DASMs represent a new paradigm for deep models of protein function that leverage evolutionary information directly. Even in this initial implementation, DASMs outperform existing foundation models while requiring orders of magnitude less computation, parameters, and training data. This efficiency suggests that evolutionary structure provides a powerful approach for understanding protein function.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Data</title>
<p>BCR sequence data was processed with <monospace>partis</monospace> [<xref ref-type="bibr" rid="c40">40</xref>] to cluster into clonal families and infer germlines. Inferred insertions or deletions were reversed, so that all sequences align to the naive sequence without gaps. We selected clonal families with at least two productive sequences; a sequence is considered productive if the canonical cysteine and tryptophan codons that flank the CDR3 are in the same frame as the start of the V segment (although they can be mutated), and there are no stop codons. We excluded sequences with stop codons. Following the training of other LLMs (e.g. [<xref ref-type="bibr" rid="c3">3</xref>]) we also excluded sequences with mutated conserved “signature” cysteines, in contrast to our previous work [<xref ref-type="bibr" rid="c15">15</xref>].</p>
<p>As in our previous work, tree inference and ancestral sequence reconstruction were performed with the K80 substitution model using the naive sequence as outgroup, allowing mutation rate heterogeneity across sites using a 4-category FreeRate model using IQ-Tree [<xref ref-type="bibr" rid="c41">41</xref>]. However, for paired data we used the <italic>edgelinked-proportional</italic> partition model in IQ-Tree that allowed the heavy and light chains to evolve at overall different rates [<xref ref-type="bibr" rid="c42">42</xref>].</p>
<p>Once this was done, we had a set of parent-child pairs (PCPs) that correspond to the pairs of parent and child sequences on the edges of the phylogenetic tree (<xref rid="fig2" ref-type="fig">Figure 2a</xref>). We used these PCPs to train the model.</p>
<p>We denote pairs of parent and child sequences as (<italic>X, Y</italic>), where <italic>X</italic> is the parent sequence and <italic>Y</italic> is the child sequence. We use <inline-formula id="inline-eqn-1"><inline-graphic xlink:href="683652v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> acid sequence corresponding to <italic>X</italic>. to denote the amino</p>
</sec>
<sec id="s5">
<title>Model</title>
<sec id="s5a">
<title>Formulation and loss</title>
<p>Assume we are given a parent codon sequence <italic>X</italic> and a child sequence <italic>Y</italic>. We will use <inline-formula id="inline-eqn-2"><inline-graphic xlink:href="683652v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> to denote the amino acid sequence of codon <italic>c</italic>, and use <inline-formula id="inline-eqn-3"><inline-graphic xlink:href="683652v1_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> to denote the amino acid sequence of codon sequence <italic>Z</italic>. We will use <italic>j</italic> to denote codon sites. As before [<xref ref-type="bibr" rid="c15">15</xref>], we model the neutral probability of a mutation to codon <italic>c</italic> as the product of per-site mutation probabilities, resulting in the probability <italic>p</italic><sub><italic>j,c</italic></sub>(<italic>t,X</italic>) of a mutation to codon <italic>c</italic> at site <italic>j</italic> after time <italic>t</italic>.</p>
<p>The selection term <inline-formula id="inline-eqn-4"><inline-graphic xlink:href="683652v1_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is a “selection factor” that quantifies the natural selection happening at site <italic>j</italic> if it was to be changed to <inline-formula id="inline-eqn-5"><inline-graphic xlink:href="683652v1_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. If this value is greater than 1, it predicts that the mutation would be beneficial in the course of affinity maturation, while if it is less than 1, it predicts that the mutation would be deleterious. We parameterize <italic>f</italic> using a shared amino-acid embedding followed by a transformer-encoder [<xref ref-type="bibr" rid="c43">43</xref>] neural network followed by a simple linear layer.</p>
<p>We will now define the likelihood <italic>l</italic><sub><italic>j,c</italic></sub>(<italic>t, X</italic>) of codon <italic>c</italic> at site <italic>j</italic> given time <italic>t</italic> and parent sequence <italic>X</italic>. When <italic>c</italic> is a non-wildtype codon it is
<disp-formula id="eqn1">
<graphic xlink:href="683652v1_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula id="inline-eqn-6"><inline-graphic xlink:href="683652v1_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula> when <italic>a</italic> is the amino acid for the wildtype codon. We then take the likelihood of the wildtype codon to be 1 minus the sum of these non-WT codons.</p>
<p>The overall likelihood for a parent-child pair is then
<disp-formula id="ueqn1">
<graphic xlink:href="683652v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>y</italic><sub><italic>j</italic></sub> is the <italic>j</italic>th codon of <italic>Y</italic>. We optimize this likelihood jointly over the branch lengths <italic>t</italic> and parameters of the selection model <italic>f</italic>. Because <italic>l</italic><sub><italic>j,c</italic></sub>(<italic>t, X</italic>) = <italic>p</italic><sub><italic>j,c</italic></sub>(<italic>t, X</italic>) when <italic>c</italic> codes for the wildtype amino acid, this approach effectively fixes the selection factors for neutral substitutions to be 1 for the purposes of branch length optimization. This is useful because it gives us a “gauge” that eliminates a potential unidentifiability in the model.</p>
<p>Especially early in training it can happen that <inline-formula id="inline-eqn-7"><inline-graphic xlink:href="683652v1_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is greater than one, or that the sum of such terms is greater than one. In these cases, the sum is clamped to be a little less than 1.</p>
</sec>
<sec id="s5b">
<title>Perplexity</title>
<p>Perplexity is a common metric for evaluating autoregressive language models such as ProGen2 [<xref ref-type="bibr" rid="c10">10</xref>]: it is the geometric mean of the inverse probabilities of the model generating each observed token given its context. These inverse probabilities can be interpreted as the effective number of tokens that the model considers plausible at each position. This is equivalent to the exponential of the average negative log probability of each token given its preceding context:
<disp-formula id="ueqn2">
<graphic xlink:href="683652v1_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>x</italic> = (<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, …, <italic>x</italic><sub><italic>n</italic></sub>) is a sequence of <italic>n</italic> tokens, and <italic>x</italic><sub><italic>&lt;i</italic></sub> represents all tokens preceding position <italic>i</italic>.</p>
<p>For encoder-only models like ESM2 and AbLang2, which mask tokens rather than using autoregressive prediction, we follow the authors of these models and instead calculate a “pseudo-perplexity” using the probability of each token given all other tokens in the sequence:
<disp-formula id="ueqn3">
<graphic xlink:href="683652v1_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>x</italic><sub><italic>\i</italic></sub> denotes the sequence with token <italic>i</italic> masked out.</p>
<p>We also use a notion of “conditional” perplexity: for each parent-child pair (<italic>x, y</italic>) of sequences that differ on the amino acid level, calculate the perplexity of the residues that are different from the parent, conditioning probabilities on there being an amino acid substitution. That is, if we let <italic>S</italic><sub><italic>x,y</italic></sub> be the sites that differ between <italic>x</italic> and <italic>y</italic>, then
<disp-formula id="ueqn4">
<graphic xlink:href="683652v1_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where bar represents amino acid sequence as before.</p>
</sec>
<sec id="s5c">
<title>Multihit correction</title>
<p>In the SHM process, having a mutation at a site increases the probability of mutations at nearby sites [<xref ref-type="bibr" rid="c19">19</xref>]. Although a general solution to this problem can easily lead down the path of intractability, we wanted to incorporate this phenomenon into our work.</p>
<p>Inspired by the work of [<xref ref-type="bibr" rid="c44">44</xref>], we added several simple “multihit” rate multipliers to our neutral model. These multipliers account for the varying probabilities of mutations based on the number of nucleotide changes required.</p>
<p>We found that, on neutrally-evolving out-of-frame data, such a correction substantially improved model fit (<xref rid="figS9" ref-type="fig">Figure S9</xref>). Before correction, the model systematically underestimates multi-hit mutations. After training the multihit model with correction factors for 1, 2, and 3 mutations per codon, the observed-expected agreement improved substantially for these classes.</p>
<p>This multihit correction was trained on the same separate out of frame data as used in training our neutral model [<xref ref-type="bibr" rid="c7">7</xref>] and was incorporated into the neutral mutation probabilities for DASM training.</p>
</sec>
<sec id="s5d">
<title>Heavy and light rates</title>
<p>Light chains mutate at a lower rate than heavy chains during affinity maturation. To quantify this relative rate, we used IQ-Tree’s rate partition feature during phylogenetic inference on paired heavy-light chain data (see Data section). This allowed us to estimate separate substitution rates for heavy and light chains within each clonal family. We found the median relative rate of light to heavy chains across all clonal families to be 0.63, which we used as our fixed light chain rate adjustment parameter. This estimate is broadly concordant with previous observations that light chains evolve at roughly half the rate of heavy chains [<xref ref-type="bibr" rid="c45">45</xref>].</p>
<p>This relative rate is incorporated into the likelihood calculation by scaling the neutral mutation rates for light chain sequences by the light chain rate adjustment factor before combining them with selection factors. Specifically, when evaluating paired heavy-light chain sequences, the per-site neutral mutation rates <italic>p</italic><sub><italic>j,c</italic></sub>(<italic>t, X</italic>) for light chain sites are multiplied by this adjustment factor, while heavy chain rates remain unscaled.</p>
</sec>
<sec id="s5e">
<title>Model implementation, training, and evaluation</title>
<p>This model was implemented in PyTorch 2.5 [<xref ref-type="bibr" rid="c46">46</xref>]. Models were trained using the RMSprop optimizer, with 4 cycles, each consisting of branch length optimization then neural network optimization.</p>
<p>We used the following software: Altair [<xref ref-type="bibr" rid="c47">47</xref>,<xref ref-type="bibr" rid="c48">48</xref>], BioPython [<xref ref-type="bibr" rid="c49">49</xref>], Matplotlib [<xref ref-type="bibr" rid="c50">50</xref>], pandas [<xref ref-type="bibr" rid="c51">51</xref>], pytest [<xref ref-type="bibr" rid="c52">52</xref>], Seaborn [<xref ref-type="bibr" rid="c53">53</xref>], and Snakemake [<xref ref-type="bibr" rid="c54">54</xref>].</p>
</sec>
<sec id="s5f">
<title>LLM model score computation</title>
<p>ESM2 scores were calculated using the FLAb paper methodology, separately evaluating heavy and light chains then averaging the pseudo-perplexities, while AbLang2 directly evaluated paired heavy-light sequences. ProGen2 scores were computed following the same FLAb methodology of separately evaluating heavy and light chains then averaging perplexities.</p>
</sec>
<sec id="s5g">
<title>Koenig evaluation</title>
<p>We obtained the Koenig et al. deep mutational scanning data from the FLAb benchmark repository [<xref ref-type="bibr" rid="c6">6</xref>] (commit 67738ee, April 17, 2024). For DASM evaluation, we used the wild-type G6.31 heavy and light chain sequences as input to predict selection factors for each possible amino acid substitution at each site.</p>
<p>The model’s log selection factors were compared against the experimental log enrichment ratios via Pearson correlation. We evaluated performance separately for heavy and light chains across both binding and expression datasets.</p>
</sec>
<sec id="s5h">
<title>Shanehsazzadeh evaluation</title>
<p>We obtained the Shanehsazzadeh et al. binding affinity data from the FLAb benchmark repository [<xref ref-type="bibr" rid="c6">6</xref>] (commit 67738ee, April 17, 2024). We subset to the “zero-shot” component of the dataset. For DASM evaluation, we partitioned the data by heavy chain amino acid length (119 and 120 residues) due to the diverse nature of the designed sequences. For each length group, we computed a site-by-site consensus sequence to serve as the reference sequence for model predictions. The aggregate log selection factor for each variant was calculated as the sum of log selection factors for each position that differed from the consensus sequence. Model performance was evaluated through Pearson correlation analysis between the aggregate log selection factors and experimental binding affinities.</p>
</sec>
<sec id="s5i">
<title>MAGMA-seq evaluation</title>
<p>We combined data from two complementary studies using the MAGMA-seq methodology: Petersen et al. [<xref ref-type="bibr" rid="c24">24</xref>] providing CDR-targeted mutagenesis data around mature influenza antibodies and Kirby et al. [<xref ref-type="bibr" rid="c26">26</xref>] providing UCA to mature antibody evolution trajectories for SARS-CoV-2 antibodies. All sequence variants were assigned to their corresponding antibody systems using reference matching with sequence similarity thresholds. To ensure data quality, experimental replicates were aggregated using geometric mean in log<sub>10</sub> space, and high-variance measurements (coefficient of variation <italic>&gt;</italic> 0.5) were filtered out as in the original papers. After deduplication and quality filtering, the unified dataset contained 1,128 sequences across 6 antibody systems: 4 Kirby UCAs and 2 Petersen mature antibodies. The 1 20 antibody system was dropped from the Kirby data as it only had 7 assigned sequences. Reference sequences were used as inputs for DASM score calculations. Model performance was evaluated using Pearson correlation with binding affinity (<italic>−</italic> log<sub>10</sub> <italic>K</italic><sub><italic>D</italic></sub>).</p>
</sec>
</sec>
<sec id="s7">
<title>Reproducing figures</title>
<p>The following figures were made in notebooks, which can be found in the <monospace>notebooks/dasm_paper</monospace> directory of the experiments repository.</p>
<list list-type="bullet">
<list-item><p><xref rid="fig1" ref-type="fig">Figure 1</xref> is made in <monospace>nt_process_in_llms.ipynb</monospace>.</p></list-item>
<list-item><p><xref rid="tbl1" ref-type="table">Table 1</xref> and <xref rid="fig3" ref-type="fig">Figures 3</xref>, <xref rid="figS1" ref-type="fig">S1</xref>, <xref rid="figS2" ref-type="fig">S2</xref>, <xref rid="figS3" ref-type="fig">S3</xref>, and <xref rid="figS4" ref-type="fig">S4</xref> are made in <monospace>koenig.ipynb</monospace>.</p></list-item>
<list-item><p><xref rid="figS5" ref-type="fig">Figure S5</xref> is made by the Snakemake pipeline and in <monospace>perplexity.ipynb</monospace>.</p></list-item>
<list-item><p><xref rid="tbl2" ref-type="table">Table 2</xref> and <xref rid="figS6" ref-type="fig">Figure S6</xref> are made in <monospace>shanehsazzadeh.ipynb</monospace>.</p></list-item>
<list-item><p><xref ref-type="table" rid="tblS1">Table S1</xref> is made in <monospace>data_summaries.ipynb</monospace>.</p></list-item>
</list>
<p>
<xref rid="figS9" ref-type="fig">Figure S9</xref> is made in multihit_model_exploration.ipynb in the <ext-link ext-link-type="uri" xlink:href="https://github.com/matsengrp/thrifty-experiments-1">https://github.com/matsengrp/thrifty-experiments-1</ext-link> repository.</p>
<p>Our repository file <monospace>data/whitehead/MAGMA_PIPELINE_STRUCTURE.md</monospace> describes how <xref rid="figS7" ref-type="fig">Figure S7</xref> and <xref rid="tbl3" ref-type="table">Table 3</xref> are made.</p>
<p>
<xref rid="tbl4" ref-type="table">Table 4</xref> is made by <monospace>timing_direct_gpu.py</monospace> and <monospace>make_timing_table.py</monospace>.</p>
</sec>
</sec>
</body>
<back>
<sec id="das" sec-type="data-availability">
<title>Data availability</title>
<p>Models and inference code can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/matsengrp/netam">https://github.com/matsengrp/netam</ext-link>, including a simple means of accessing the pretrained model demonstrated in the <monospace>notebooks/dasm_demo.ipynb</monospace> notebook. Our reproducible experiments are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/matsengrp/dasm-experiments">https://github.com/matsengrp/dasm-experiments</ext-link>. Relevant preprocessed data has been uploaded to Zenodo at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.17322891">https://doi.org/10.5281/zenodo.17322891</ext-link>.</p>
</sec>
<sec id="s9" sec-type="supplementary">
<title>Supplementary materials</title>
<table-wrap id="tblS1" orientation="portrait" position="float">
<label>Table S1:</label>
<caption><title>Data used in this paper.</title>
<p>CC means that PCPs with mutated cysteines are excluded from the data. <monospace>JaffePairedCC</monospace> is paired data from [<xref ref-type="bibr" rid="c56">56</xref>] sequenced using 10X. <monospace>TangCC</monospace> data is heavy chain data from [<xref ref-type="bibr" rid="c55">55</xref>, <xref ref-type="bibr" rid="c57">57</xref>] and was sequenced using the methods of [<xref ref-type="bibr" rid="c57">57</xref>]. <monospace>VanwinkleheavyTrainCC1m</monospace> is a subset of the heavy chain data from [<xref ref-type="bibr" rid="c58">58</xref>] sequenced using Takara 5’RACE BCR kit. <monospace>VanwinklelightTrainCC1m</monospace> is a 1M subset of the light chain data from [<xref ref-type="bibr" rid="c58">58</xref>] sequenced using Takara 5’RACE BCR kit. <monospace>RodriguezCC</monospace> data is the 5<sup><italic>′</italic></sup> RACE heavy chain data from [<xref ref-type="bibr" rid="c12">12</xref>] and is used only for testing. The “samples” column is the number of individual samples in the dataset; in these datasets, each sample is from a distinct individual. “Clonal families” is the number of clonal families in the dataset. “PCPs” is the number of parent-child pairs in the dataset. “Median mutations” is the median number of mutations per PCP in the dataset.</p></caption>
<graphic xlink:href="683652v1_tblS1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1:</label>
<caption><title>Conflating mutation and selection hinders functional prediction.</title>
<p>This plot is analogous to the rightmost panel of <xref ref-type="fig" rid="fig1">Figure 1c</xref>, but colored by mutability according to the Thrifty [<xref ref-type="bibr" rid="c7">7</xref>] model.</p></caption>
<graphic xlink:href="683652v1_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2:</label>
<caption><title>DASM removes codon bias in light chain functional predictions.</title>
<p>Equivalent plot as <xref ref-type="fig" rid="fig3">Figure 3</xref> but for light chain.</p></caption>
<graphic xlink:href="683652v1_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Figure S3:</label>
<caption><title>DASM selection factors are similar between codon neighbor amino acids and non-neighbors (compare <xref ref-type="fig" rid="fig1">Figure 1a</xref>), in contrast to other models.</title>
<p>Comparison done on the heavy chain of the Koenig [<xref ref-type="bibr" rid="c11">11</xref>] wildtype sequence.</p></caption>
<graphic xlink:href="683652v1_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Figure S4:</label>
<caption><title>Heatmap showing the heavy-chain data of [<xref ref-type="bibr" rid="c11">11</xref>] along with model predictions.</title></caption>
<graphic xlink:href="683652v1_figS4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Figure S5:</label>
<caption><title>The DASM with the Thrifty neutral model accurately assesses probabilities of natural affinity maturation paths.</title>
<p><bold>a, b</bold>: The DASM is better than AbLang2 at predicting the location of nonsynonymous mutations observed in PCPs withheld from model training. <bold>c</bold>: The DASM achieves lower conditional perplexity (median 4.88 vs 7.39) when predicting amino acid identity at mutated sites, with fewer extreme outliers. The conditional perplexity is the perplexity of the child amino acid, conditioned on there being a mutation at that site. Note that due to the inherent stochasticity of affinity maturation, there is a lower limit to this conditional perplexity that is substantially greater than 1.</p></caption>
<graphic xlink:href="683652v1_figS5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS6" position="float" fig-type="figure">
<label>Figure S6:</label>
<caption><title>Scatterplots for the data of [<xref ref-type="bibr" rid="c23">23</xref>] zero-shot data set, partitioned by sequence length.</title></caption>
<graphic xlink:href="683652v1_figS6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS7" position="float" fig-type="figure">
<label>Figure S7:</label>
<caption><title>Model predictions versus experimentally measured binding affinity for five antibodies using the MAGMA-seq protocol.</title>
<p>“Petersen” data are from an experiment probing the rules of recognition for influenza neutralizing antibodies [<xref ref-type="bibr" rid="c24">24</xref>] and “Kirby” data are from combinatorial libraries applying combinations of mutations on the path from naive to mature [<xref ref-type="bibr" rid="c26">26</xref>]. Each row shows a different model (DASM, ESM2, AbLang2, ProGen2) and each column shows a different antibody lineage.</p></caption>
<graphic xlink:href="683652v1_figS7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS8" position="float" fig-type="figure">
<label>Figure S8:</label>
<caption><title>The model is trained to predict the probability of a child sequence given the parent sequence.</title>
<p>It is divided into mutation and selection components. Mutation: given a parent sequence <italic>X</italic>, probability of mutation to alternate codons after time <italic>t</italic> is calculated using a model of SHM [<xref ref-type="bibr" rid="c7">7</xref>] and a “multihit model” (see Methods) and then aggregated into codons as in [<xref ref-type="bibr" rid="c15">15</xref>] to obtain <italic>p</italic><sub><italic>j,c</italic></sub>(<italic>t, X</italic>). Selection: given an amino acid translation <inline-formula id="inline-eqn-8"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="683652v1_inline8.gif"/></inline-formula> of the parent, the transformer-encoder gives per-site selection factors <inline-formula id="inline-eqn-9"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="683652v1_inline9.gif"/></inline-formula>. These are then multiplied (1) and summed to give the probability of the observed child sequence at every site. This gives a likelihood for a parent-child pair. The algorithm maximizes the likelihood across branch lengths <italic>t</italic> for each parent-child pair as well as across the parameters of the transformer model for all parent-child pairs in the dataset (dashed lines).</p></caption>
<graphic xlink:href="683652v1_figS8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS9" position="float" fig-type="figure">
<label>Figure S9:</label>
<caption><title>Models that allow for multiple hits per codon (right column) show better model fit than without (left column) on the out-of-frame data from [<xref ref-type="bibr" rid="c55">55</xref>] as prepared in [<xref ref-type="bibr" rid="c7">7</xref>].</title>
<p>These observed-versus-expected plots compare the observed number of mutations to the computationally predicted number across bins of mutation probability. For each bin, the expected number of mutations is calculated as the sum of mutation probabilities for all sites in that bin, while the observed count represents the actual mutations found in those sites. The overlap metric quantifies the area of overlap between observed and expected dis-tributions divided by their average area, while the residual metric measures the normalized root-mean-square difference between observed and expected counts. These plots are faceted by the number of mutations per codon.</p></caption>
<graphic xlink:href="683652v1_figS9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We are grateful to the authors of [<xref ref-type="bibr" rid="c55">55</xref>] and the lab of Corey Watson for sharing preprocessed data. We thank Antoine Koehl for helpful discussions, as well as Michael Chungyon and Timothy Whitehead for help with data processing. This work supported by NIH grants R01-AI146028 (PI Matsen), R56-HG013117 and R01-HG013117 (PI Song), DP2-AI177890 (PI Starr), and Searle Scholars Program (PI Starr).</p>
<p>Scientific Computing Infrastructure at Fred Hutch funded by ORIP grant S10OD028685. Frederick Matsen is an investigator of the Howard Hughes Medical Institute.</p>
<p>ChatGPT and Claude AI models were used to draft code and text for this manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Justin</given-names> <surname>Barton</surname></string-name>, <string-name><given-names>Aretas</given-names> <surname>Gaspariunas</surname></string-name>, <string-name><given-names>David A</given-names> <surname>Yadin</surname></string-name>, <string-name><given-names>Jorge</given-names> <surname>Dias</surname></string-name>, <string-name><given-names>Francesca L</given-names> <surname>Nice</surname></string-name>, <string-name><given-names>Danielle H</given-names> <surname>Minns</surname></string-name>, <string-name><given-names>Olivia</given-names> <surname>Snudden</surname></string-name>, <string-name><given-names>Chelsea</given-names> <surname>Povall</surname></string-name>, <string-name><given-names>Sara Valle</given-names> <surname>Tomas</surname></string-name>, <string-name><given-names>Harry</given-names> <surname>Dobson</surname></string-name>, <string-name><given-names>James H R</given-names> <surname>Farmery</surname></string-name>, <string-name><given-names>Jinwoo</given-names> <surname>Leem</surname></string-name>, and <string-name><given-names>Jacob D</given-names> <surname>Galson</surname></string-name></person-group>. <article-title>A generative foundation model for antibody sequence understanding</article-title>. <source>bioRxiv</source>, page <elocation-id>2024.05.22.594943</elocation-id>, <month>May</month> <year>2024</year>. doi:<pub-id pub-id-type="doi">10.1101/2024.05.22.594943</pub-id>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Jacob</given-names> <surname>Devlin</surname></string-name>, <string-name><given-names>Ming-Wei</given-names> <surname>Chang</surname></string-name>, <string-name><given-names>Kenton</given-names> <surname>Lee</surname></string-name>, and <string-name><given-names>Kristina</given-names> <surname>Toutanova</surname></string-name></person-group>. <article-title>BERT: Pre-training of deep bidirectional transformers for language understanding</article-title>. <source>arXiv</source>, <month>October</month> <year>2018</year>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</ext-link>, <pub-id pub-id-type="arxiv">1810.04805</pub-id>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Tobias H</given-names> <surname>Olsen</surname></string-name>, <string-name><given-names>Iain H</given-names> <surname>Moal</surname></string-name>, and <string-name><given-names>Charlotte M</given-names> <surname>Deane</surname></string-name></person-group>. <article-title>Addressing the antibody germline bias and its effect on language models for improved antibody design</article-title>. <source>Bioinformatics, page btae618</source>, <month>October</month> <year>2024</year>. doi:<pub-id pub-id-type="doi">10.1093/bioinformatics/btae618</pub-id>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Karenna</given-names> <surname>Ng</surname></string-name> and <string-name><given-names>Bryan</given-names> <surname>Briney</surname></string-name></person-group>. <article-title>Focused learning by antibody language models using preferential masking of non-templated regions</article-title>. <source>Patterns</source>, <volume>6</volume>(<issue>6</issue>):<fpage>101239</fpage>, <month>June</month> <year>2025</year>. doi:<pub-id pub-id-type="doi">10.1016/j.patter.2025.101239</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Zizhang</given-names> <surname>Sheng</surname></string-name>, <string-name><given-names>Chaim A</given-names> <surname>Schramm</surname></string-name>, <string-name><given-names>Rui</given-names> <surname>Kong</surname></string-name>, <string-name><given-names>NISC Comparative Sequencing</given-names> <surname>Program</surname></string-name>, <string-name><given-names>James C</given-names> <surname>Mullikin</surname></string-name>, <string-name><given-names>John R</given-names> <surname>Mascola</surname></string-name>, <string-name><given-names>Peter D</given-names> <surname>Kwong</surname></string-name>, and <string-name><given-names>Lawrence</given-names> <surname>Shapiro</surname></string-name></person-group>. <article-title>Gene-Specific substitution profiles describe the types and frequencies of amino acid changes during antibody somatic hypermutation</article-title>. <source>Front. Immunol.</source>, <volume>8</volume>:<fpage>537</fpage>, <month>May</month> <year>2017</year>. doi:<pub-id pub-id-type="doi">10.3389/fimmu.2017.00537</pub-id>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Michael</given-names> <surname>Chungyoun</surname></string-name>, <string-name><given-names>Jeffrey</given-names> <surname>Ruffolo</surname></string-name>, and <string-name><given-names>Jeffrey</given-names> <surname>Gray</surname></string-name></person-group>. <article-title>FLAb: Benchmarking deep learning methods for antibody fitness prediction</article-title>. <source>bioRxiv</source>, page 2024.01.13.575504, <month>January</month> <year>2024</year>. doi:<pub-id pub-id-type="doi">10.1101/2024.01.13.575504</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Kevin</given-names> <surname>Sung</surname></string-name>, <string-name><given-names>Mackenzie M</given-names> <surname>Johnson</surname></string-name>, <string-name><given-names>Will</given-names> <surname>Dumm</surname></string-name>, <string-name><given-names>Noah</given-names> <surname>Simon</surname></string-name>, <string-name><given-names>Hugh</given-names> <surname>Haddox</surname></string-name>, <string-name><given-names>Julia</given-names> <surname>Fukuyama</surname></string-name>, and <string-name><surname>Frederick A Matsen</surname> <given-names>IV</given-names></string-name></person-group>. <article-title>Thrifty widecontext models of B cell receptor somatic hypermutation</article-title>. <source>eLife</source>, <month>March</month> <year>2025</year>. doi:<pub-id pub-id-type="doi">10.7554/elife.105471.1</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><given-names>Roshan</given-names> <surname>Rao</surname></string-name>, <string-name><given-names>Joshua</given-names> <surname>Meier</surname></string-name>, <string-name><given-names>Tom</given-names> <surname>Sercu</surname></string-name>, <string-name><given-names>Sergey</given-names> <surname>Ovchinnikov</surname></string-name>, and <string-name><given-names>Alexander</given-names> <surname>Rives</surname></string-name></person-group>. <article-title>Transformer protein language models are unsupervised structure learners</article-title>. In <source>International Conference on Learning Representations</source>, <month>October</month> <year>2020</year>. URL: <ext-link ext-link-type="uri" xlink:href="https://openreview.net/pdf?id=fylclEqgvgd">https://openreview.net/pdf?id=fylclEqgvgd</ext-link>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alexander</given-names> <surname>Rives</surname></string-name>, <string-name><given-names>Joshua</given-names> <surname>Meier</surname></string-name>, <string-name><given-names>Tom</given-names> <surname>Sercu</surname></string-name>, <string-name><given-names>Siddharth</given-names> <surname>Goyal</surname></string-name>, <string-name><given-names>Zeming</given-names> <surname>Lin</surname></string-name>, <string-name><given-names>Jason</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Demi</given-names> <surname>Guo</surname></string-name>, <string-name><given-names>Myle</given-names> <surname>Ott</surname></string-name>, C <string-name><given-names>Lawrence</given-names> <surname>Zitnick</surname></string-name>, <string-name><given-names>Jerry</given-names> <surname>Ma</surname></string-name>, and <string-name><given-names>Rob</given-names> <surname>Fergus</surname></string-name></person-group>. <article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A.</source>, <volume>118</volume>(<issue>15</issue>):<fpage>e2016239118</fpage>, <month>April</month> <year>2021</year>. doi:<pub-id pub-id-type="doi">10.1073/pnas.2016239118</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Erik</given-names> <surname>Nijkamp</surname></string-name>, <string-name><given-names>Jeffrey</given-names> <surname>Ruffolo</surname></string-name>, <string-name><given-names>Eli N</given-names> <surname>Weinstein</surname></string-name>, <string-name><given-names>Nikhil</given-names> <surname>Naik</surname></string-name>, and <string-name><given-names>Ali</given-names> <surname>Madani</surname></string-name></person-group>. <article-title>ProGen2: Exploring the boundaries of protein language models</article-title>. <source>arXiv</source>, <month>June</month> <year>2022</year>. doi: <pub-id pub-id-type="doi">10.48550/arXiv.2206.13517</pub-id>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Patrick</given-names> <surname>Koenig</surname></string-name>, <string-name><given-names>Chingwei V</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>Benjamin T</given-names> <surname>Walters</surname></string-name>, <string-name><given-names>Vasantharajan</given-names> <surname>Janakiraman</surname></string-name>, <string-name><given-names>Jeremy</given-names> <surname>Stinson</surname></string-name>, <string-name><given-names>Thomas W</given-names> <surname>Patapoff</surname></string-name>, and <string-name><given-names>Germaine</given-names> <surname>Fuh</surname></string-name></person-group>. <article-title>Mutational landscape of antibody variable domains reveals a switch modulating the interdomain conformational dynamics and antigen binding</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A.</source>, <month>January</month> <year>2017</year>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1613231114</pub-id>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Oscar L</given-names> <surname>Rodriguez</surname></string-name>, <string-name><given-names>Yana</given-names> <surname>Safonova</surname></string-name>, <string-name><given-names>Catherine A</given-names> <surname>Silver</surname></string-name>, <string-name><given-names>Kaitlyn</given-names> <surname>Shields</surname></string-name>, <string-name><given-names>William S</given-names> <surname>Gibson</surname></string-name>, <string-name><given-names>Justin T</given-names> <surname>Kos</surname></string-name>, <string-name><given-names>David</given-names> <surname>Tieri</surname></string-name>, <string-name><given-names>Hanzhong</given-names> <surname>Ke</surname></string-name>, <string-name><given-names>Katherine J L</given-names> <surname>Jackson</surname></string-name>, <string-name><given-names>Scott D</given-names> <surname>Boyd</surname></string-name>, <string-name><given-names>Melissa L</given-names> <surname>Smith</surname></string-name>, <string-name><given-names>Wayne A</given-names> <surname>Marasco</surname></string-name>, and <string-name><given-names>Corey T</given-names> <surname>Watson</surname></string-name></person-group>. <article-title>Genetic variation in the immunoglobulin heavy chain locus shapes the human antibody repertoire</article-title>. <source>Nature Comm.</source>, <volume>14</volume>(<issue>1</issue>):<fpage>4419</fpage>, <month>July</month> <year>2023</year>. doi:<pub-id pub-id-type="doi">10.1038/s41467-023-40070-x</pub-id>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Bas</given-names> <surname>Pilzecker</surname></string-name> and <string-name><given-names>Heinz</given-names> <surname>Jacobs</surname></string-name></person-group>. <article-title>Mutating for good: DNA damage responses during somatic hypermutation</article-title>. <source>Front. Immunol.</source>, <volume>10</volume>:<fpage>438</fpage>, <month>March</month> <year>2019</year>. doi:<pub-id pub-id-type="doi">10.3389/fimmu.2019.00438</pub-id>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gur</given-names> <surname>Yaari</surname></string-name>, <string-name><given-names>Jason A</given-names> <surname>Vander Heiden</surname></string-name>, <string-name><given-names>Mohamed</given-names> <surname>Uduman</surname></string-name>, <string-name><given-names>Daniel</given-names> <surname>Gadala-Maria</surname></string-name>, <string-name><given-names>Namita</given-names> <surname>Gupta</surname></string-name>, <string-name><given-names>Joel N H</given-names> <surname>Stern</surname></string-name>, <string-name><given-names>Kevin C</given-names> <surname>O’Connor</surname></string-name>, <string-name><given-names>David A</given-names> <surname>Hafler</surname></string-name>, <string-name><given-names>Uri</given-names> <surname>Laserson</surname></string-name>, <string-name><given-names>Francois</given-names> <surname>Vigneault</surname></string-name>, and <string-name><given-names>Steven H</given-names> <surname>Kleinstein</surname></string-name></person-group>. <article-title>Models of somatic hypermutation targeting and substitution based on synonymous mutations from high-throughput immunoglobulin sequencing data</article-title>. <source>Front. Immunol.</source>, <volume>4</volume>:<fpage>358</fpage>, <month>November</month> <year>2013</year>. doi:<pub-id pub-id-type="doi">10.3389/fimmu.2013.00358</pub-id>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frederick A Matsen</surname> <given-names>IV</given-names></string-name>, <string-name><given-names>Kevin</given-names> <surname>Sung</surname></string-name>, <string-name><given-names>Mackenzie M</given-names> <surname>Johnson</surname></string-name>, <string-name><given-names>Will</given-names> <surname>Dumm</surname></string-name>, <string-name><given-names>David</given-names> <surname>Rich</surname></string-name>, <string-name><given-names>Tyler</given-names> <surname>Starr</surname></string-name>, <string-name><given-names>Yun S</given-names> <surname>Song</surname></string-name>, <string-name><given-names>Philip</given-names> <surname>Bradley</surname></string-name>, <string-name><given-names>Julia</given-names> <surname>Fukuyama</surname></string-name>, and <string-name><given-names>Hugh K</given-names> <surname>Haddox</surname></string-name></person-group>. <article-title>A sitewise model of natural selection on individual antibodies via a transformer-encoder</article-title>. <source>Mol. Biol. Evol.</source>, page <elocation-id>msaf186</elocation-id>, <month>August</month> <year>2025</year>. doi:<pub-id pub-id-type="doi">10.1093/molbev/msaf186</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N</given-names> <surname>Goldman</surname></string-name> and <string-name><given-names>Z</given-names> <surname>Yang</surname></string-name></person-group>. <article-title>A codon-based model of nucleotide substitution for protein-coding DNA sequences</article-title>. <source>Mol. Biol. Evol.</source>, <volume>11</volume>(<issue>5</issue>):<fpage>725</fpage>–<lpage>736</lpage>, <month>September</month> <year>1994</year>. <pub-id pub-id-type="pmid">7968486</pub-id>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>SV</given-names> <surname>Muse</surname></string-name> and <string-name><given-names>BS</given-names> <surname>Gaut</surname></string-name></person-group>. <article-title>A likelihood approach for comparing synonymous and nonsynonymous nucleotide substitution rates, with application to the chloroplast genome</article-title>. <source>Mol. Biol. Evol.</source>, <volume>11</volume>(<issue>5</issue>):<fpage>715</fpage>–<lpage>724</lpage>, <month>September</month> <year>1994</year>. <pub-id pub-id-type="pmid">7968485</pub-id>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>AL</given-names> <surname>Halpern</surname></string-name> and <string-name><given-names>WJ</given-names> <surname>Bruno</surname></string-name></person-group>. <article-title>Evolutionary distances for protein-coding sequences: modeling site-specific residue frequencies</article-title>. <source>Mol. Biol. Evol.</source>, <volume>15</volume>(<issue>7</issue>):<fpage>910</fpage>–<lpage>917</lpage>, <month>July</month> <year>1998</year>. <pub-id pub-id-type="pmid">9656490</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Natanael</given-names> <surname>Spisak</surname></string-name>, <string-name><given-names>Aleksandra M</given-names> <surname>Walczak</surname></string-name>, and <string-name><given-names>Thierry</given-names> <surname>Mora</surname></string-name></person-group>. <article-title>Learning the heterogeneous hypermutation landscape of immunoglobulins from high-throughput repertoire data</article-title>. <source>Nucleic Acids Res.</source>, <volume>48</volume>(<issue>19</issue>):<fpage>10702</fpage>–<lpage>10712</lpage>, <month>November</month> <year>2020</year>. doi:<pub-id pub-id-type="doi">10.1093/nar/gkaa825</pub-id>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>William S</given-names> <surname>DeWitt</surname></string-name>, <string-name><given-names>Ashni A</given-names> <surname>Vora</surname></string-name>, <string-name><given-names>Tatsuya</given-names> <surname>Araki</surname></string-name>, <string-name><given-names>Jared G</given-names> <surname>Galloway</surname></string-name>, <string-name><given-names>Tanwee</given-names> <surname>Alkutkar</surname></string-name>, <string-name><given-names>Juliana</given-names> <surname>Bortolatto</surname></string-name>, <string-name><given-names>Tiago B R</given-names> <surname>Castro</surname></string-name>, <string-name><given-names>Will</given-names> <surname>Dumm</surname></string-name>, <string-name><given-names>Chris</given-names> <surname>Jennings-Shaffer</surname></string-name>, <string-name><given-names>Tongqiu</given-names> <surname>Jia</surname></string-name>, <string-name><given-names>Luka</given-names> <surname>Mesin</surname></string-name>, <string-name><given-names>Gabriel</given-names> <surname>Ozorowski</surname></string-name>, <string-name><given-names>Juhee</given-names> <surname>Pae</surname></string-name>, <string-name><given-names>Duncan K</given-names> <surname>Ralph</surname></string-name>, <string-name><given-names>Jesse D</given-names> <surname>Bloom</surname></string-name>, <string-name><given-names>Armita</given-names> <surname>Nourmohammad</surname></string-name>, <string-name><given-names>Yun S</given-names> <surname>Song</surname></string-name>, <string-name><given-names>Andrew B</given-names> <surname>Ward</surname></string-name>, <string-name><given-names>Tyler N</given-names> <surname>Starr</surname></string-name>, <string-name><given-names>Frederick A</given-names> <surname>Matsen</surname></string-name>, IV, and <string-name><given-names>Gabriel D</given-names> <surname>Victora</surname></string-name></person-group>. <article-title>Replaying germinal center evolution on a quantified affinity landscape</article-title>. <source>bioRxiv</source>, page 2025.06.02.656870, <month>June</month> <year>2025</year>. doi:<pub-id pub-id-type="doi">10.1101/2025.06.02.656870</pub-id>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Mackenzie M</given-names> <surname>Johnson</surname></string-name>, <string-name><given-names>Kevin</given-names> <surname>Sung</surname></string-name>, <string-name><given-names>Hugh K</given-names> <surname>Haddox</surname></string-name>, <string-name><given-names>Ashni A</given-names> <surname>Vora</surname></string-name>, <string-name><given-names>Tatsuya</given-names> <surname>Araki</surname></string-name>, <string-name><given-names>Gabriel D</given-names> <surname>Victora</surname></string-name>, <string-name><given-names>Yun S</given-names> <surname>Song</surname></string-name>, <string-name><given-names>Julia</given-names> <surname>Fukuyama</surname></string-name>, and <string-name><given-names>Frederick A</given-names> <surname>Matsen</surname></string-name></person-group>, <article-title>IV. Nucleotide context models outperform protein language models for predicting antibody affinity maturation</article-title>. <source>bioRxiv</source>, page <elocation-id>2025.06.16.659977</elocation-id>, <month>June</month> <year>2025</year>. doi:<pub-id pub-id-type="doi">10.1101/2025.06.16.659977</pub-id>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Zeming</given-names> <surname>Lin</surname></string-name>, <string-name><given-names>Halil</given-names> <surname>Akin</surname></string-name>, <string-name><given-names>Roshan</given-names> <surname>Rao</surname></string-name>, <string-name><given-names>Brian</given-names> <surname>Hie</surname></string-name>, <string-name><given-names>Zhongkai</given-names> <surname>Zhu</surname></string-name>, <string-name><given-names>Wenting</given-names> <surname>Lu</surname></string-name>, <string-name><given-names>Nikita</given-names> <surname>Smetanin</surname></string-name>, <string-name><given-names>Robert</given-names> <surname>Verkuil</surname></string-name>, <string-name><given-names>Ori</given-names> <surname>Kabeli</surname></string-name>, <string-name><given-names>Yaniv</given-names> <surname>Shmueli</surname></string-name>, <string-name><given-names>Allan Dos Santos</given-names> <surname>Costa</surname></string-name>, <string-name><given-names>Maryam</given-names> <surname>Fazel-Zarandi</surname></string-name>, <string-name><given-names>Tom</given-names> <surname>Sercu</surname></string-name>, <string-name><given-names>Salvatore</given-names> <surname>Candido</surname></string-name>, and <string-name><given-names>Alexander</given-names> <surname>Rives</surname></string-name></person-group>. <article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title>. <source>Science</source>, <volume>379</volume>(<issue>6637</issue>):<fpage>1123</fpage>–<lpage>1130</lpage>, <month>March</month> <year>2023</year>. doi:<pub-id pub-id-type="doi">10.1126/science.ade2574</pub-id>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Amir</given-names> <surname>Shanehsazzadeh</surname></string-name>, <string-name><given-names>Sharrol</given-names> <surname>Bachas</surname></string-name>, <string-name><given-names>Matt</given-names> <surname>McPartlon</surname></string-name>, <string-name><given-names>George</given-names> <surname>Kasun</surname></string-name>, <string-name><given-names>John M</given-names> <surname>Sutton</surname></string-name>, <string-name><given-names>Andrea K</given-names> <surname>Steiger</surname></string-name>, <string-name><given-names>Richard</given-names> <surname>Shuai</surname></string-name>, <string-name><given-names>Christa</given-names> <surname>Kohnert</surname></string-name>, <string-name><given-names>Goran</given-names> <surname>Rakocevic</surname></string-name>, <string-name><given-names>Jahir M</given-names> <surname>Gutierrez</surname></string-name>, <string-name><given-names>Chelsea</given-names> <surname>Chung</surname></string-name>, <string-name><given-names>Breanna K</given-names> <surname>Luton</surname></string-name>, <string-name><given-names>Nicolas</given-names> <surname>Diaz</surname></string-name>, <string-name><given-names>Simon</given-names> <surname>Levine</surname></string-name>, <string-name><given-names>Julian</given-names> <surname>Alverio</surname></string-name>, <string-name><given-names>Bailey</given-names> <surname>Knight</surname></string-name>, <string-name><given-names>Macey</given-names> <surname>Radach</surname></string-name>, <string-name><given-names>Alex</given-names> <surname>Morehead</surname></string-name>, <string-name><given-names>Katherine</given-names> <surname>Bateman</surname></string-name>, <string-name><given-names>David A</given-names> <surname>Spencer</surname></string-name>, <string-name><given-names>Zachary</given-names> <surname>McDargh</surname></string-name>, <string-name><given-names>Jovan</given-names> <surname>Cejovic</surname></string-name>, <string-name><given-names>Gaelin</given-names> <surname>Kopec-Belliveau</surname></string-name>, <string-name><given-names>Robel</given-names> <surname>Haile</surname></string-name>, <string-name><given-names>Edriss</given-names> <surname>Yassine</surname></string-name>, <string-name><given-names>Cailen</given-names> <surname>McCloskey</surname></string-name>, <string-name><given-names>Monica</given-names> <surname>Natividad</surname></string-name>, <string-name><given-names>Dalton</given-names> <surname>Chapman</surname></string-name>, <string-name><given-names>Joshua</given-names> <surname>Bennett</surname></string-name>, <string-name><given-names>Jubair</given-names> <surname>Hossain</surname></string-name>, <string-name><given-names>Abigail B</given-names> <surname>Ventura</surname></string-name>, <string-name><given-names>Gustavo M</given-names> <surname>Canales</surname></string-name>, <string-name><given-names>Muttappa</given-names> <surname>Gowda</surname></string-name>, <string-name><given-names>Kerianne A</given-names> <surname>Jackson</surname></string-name>, <string-name><given-names>Jennifer T</given-names> <surname>Stanton</surname></string-name>, <string-name><given-names>Marcin</given-names> <surname>Ura</surname></string-name>, <string-name><given-names>Luka</given-names> <surname>Stojanovic</surname></string-name>, <string-name><given-names>Engin</given-names> <surname>Yapici</surname></string-name>, <string-name><given-names>Katherine</given-names> <surname>Moran</surname></string-name>, <string-name><given-names>Rodante</given-names> <surname>Caguiat</surname></string-name>, <string-name><given-names>Amber</given-names> <surname>Brown</surname></string-name>, <string-name><given-names>Shaheed</given-names> <surname>Abdulhaqq</surname></string-name>, <string-name><given-names>Zheyuan</given-names> <surname>Guo</surname></string-name>, <string-name><given-names>Lillian R</given-names> <surname>Klug</surname></string-name>, <string-name><given-names>Miles</given-names> <surname>Gander</surname></string-name>, and <string-name><given-names>Joshua</given-names> <surname>Meier</surname></string-name></person-group>. <article-title>Unlocking de novo antibody design with generative artificial intelligence</article-title>. <source>bioRxiv</source>, page 2023.01.08.523187, <month>January</month> <year>2023</year>. doi:<pub-id pub-id-type="doi">10.1101/2023.01.08.523187</pub-id>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Brian M</given-names> <surname>Petersen</surname></string-name>, <string-name><given-names>Monica B</given-names> <surname>Kirby</surname></string-name>, <string-name><given-names>Karson M</given-names> <surname>Chrispens</surname></string-name>, <string-name><given-names>Olivia M</given-names> <surname>Irvin</surname></string-name>, <string-name><given-names>Isabell K</given-names> <surname>Strawn</surname></string-name>, <string-name><given-names>Cyrus M</given-names> <surname>Haas</surname></string-name>, <string-name><given-names>Alexis M</given-names> <surname>Walker</surname></string-name>, <string-name><given-names>Zachary T</given-names> <surname>Baumer</surname></string-name>, <string-name><given-names>Sophia A</given-names> <surname>Ulmer</surname></string-name>, <string-name><given-names>Edgardo</given-names> <surname>Ayala</surname></string-name>, <string-name><given-names>Emily R</given-names> <surname>Rhodes</surname></string-name>, <string-name><given-names>Jenna J</given-names> <surname>Guthmiller</surname></string-name>, <string-name><given-names>Paul J</given-names> <surname>Steiner</surname></string-name>, and <string-name><given-names>Timothy A</given-names> <surname>Whitehead</surname></string-name></person-group>. <article-title>An integrated technology for quantitative wide mutational scanning of human antibody fab libraries</article-title>. <source>Nat. Commun.</source>, <volume>15</volume>(<issue>1</issue>):<fpage>3974</fpage>, <month>May</month> <year>2024</year>. doi:<pub-id pub-id-type="doi">10.1038/s41467-024-48072-z</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Rhys M</given-names> <surname>Adams</surname></string-name>, <string-name><given-names>Thierry</given-names> <surname>Mora</surname></string-name>, <string-name><given-names>Aleksandra M</given-names> <surname>Walczak</surname></string-name>, and <string-name><given-names>Justin B</given-names> <surname>Kinney</surname></string-name></person-group>. <article-title>Measuring the sequence-affinity landscape of antibodies with massively parallel titration curves</article-title>. <source>Elife</source>, <volume>5</volume>, <month>December</month> <year>2016</year>. doi:<pub-id pub-id-type="doi">10.7554/eLife.23156</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Monica B</given-names> <surname>Kirby</surname></string-name>, <string-name><given-names>Brian M</given-names> <surname>Petersen</surname></string-name>, <string-name><given-names>Jonathan G</given-names> <surname>Faris</surname></string-name>, <string-name><given-names>Siobhan P</given-names> <surname>Kells</surname></string-name>, <string-name><given-names>Kayla G</given-names> <surname>Sprenger</surname></string-name>, and <string-name><given-names>Timothy A</given-names> <surname>Whitehead</surname></string-name></person-group>. <article-title>Retrospective SARS-CoV-2 human antibody development trajectories are largely sparse and permissive</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A.</source>, <volume>122</volume>(<issue>4</issue>):<fpage>e2412787122</fpage>, <month>January</month> <year>2025</year>. doi:<pub-id pub-id-type="doi">10.1073/pnas.2412787122</pub-id>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Sanjeev</given-names> <surname>Kumar</surname></string-name>, <string-name><given-names>Anamika</given-names> <surname>Patel</surname></string-name>, <string-name><given-names>Lilin</given-names> <surname>Lai</surname></string-name>, <string-name><given-names>Chennareddy</given-names> <surname>Chakravarthy</surname></string-name>, <string-name><given-names>Rajesh</given-names> <surname>Valanparambil</surname></string-name>, <string-name><given-names>Elluri Seetharami</given-names> <surname>Reddy</surname></string-name>, <string-name><given-names>Kamalvishnu</given-names> <surname>Gottimukkala</surname></string-name>, <string-name><given-names>Meredith E</given-names> <surname>Davis-Gardner</surname></string-name>, <string-name><given-names>Venkata Viswanadh</given-names> <surname>Edara</surname></string-name>, <string-name><given-names>Susanne</given-names> <surname>Linderman</surname></string-name>, <string-name><given-names>Kaustuv</given-names> <surname>Nayak</surname></string-name>, <string-name><given-names>Kritika</given-names> <surname>Dixit</surname></string-name>, <string-name><given-names>Pragati</given-names> <surname>Sharma</surname></string-name>, <string-name><given-names>Prashant</given-names> <surname>Bajpai</surname></string-name>, <string-name><given-names>Vanshika</given-names> <surname>Singh</surname></string-name>, <string-name><given-names>Filipp</given-names> <surname>Frank</surname></string-name>, <string-name><given-names>Narayanaiah</given-names> <surname>Cheedarla</surname></string-name>, <string-name><given-names>Hans P</given-names> <surname>Verkerke</surname></string-name>, <string-name><given-names>Andrew S</given-names> <surname>Neish</surname></string-name>, <string-name><given-names>John D</given-names> <surname>Roback</surname></string-name>, <string-name><given-names>Grace</given-names> <surname>Mantus</surname></string-name>, <string-name><given-names>Pawan Kumar</given-names> <surname>Goel</surname></string-name>, <string-name><given-names>Manju</given-names> <surname>Rahi</surname></string-name>, <string-name><given-names>Carl W</given-names> <surname>Davis</surname></string-name>, <string-name><given-names>Jens</given-names> <surname>Wrammert</surname></string-name>, <string-name><given-names>Sucheta</given-names> <surname>Godbole</surname></string-name>, <string-name><given-names>Amy R</given-names> <surname>Henry</surname></string-name>, <string-name><given-names>Daniel C</given-names> <surname>Douek</surname></string-name>, <string-name><given-names>Mehul S</given-names> <surname>Suthar</surname></string-name>, <string-name><given-names>Rafi</given-names> <surname>Ahmed</surname></string-name>, <string-name><given-names>Eric</given-names> <surname>Ortlund</surname></string-name>, <string-name><given-names>Amit</given-names> <surname>Sharma</surname></string-name>, <string-name><given-names>Kaja</given-names> <surname>Murali-Krishna</surname></string-name>, and <string-name><given-names>Anmol</given-names> <surname>Chandele</surname></string-name></person-group>. <article-title>Structural insights for neutralization of omicron variants BA.1, BA.2, BA.4, and BA.5 by a broadly neutralizing SARS-CoV-2 antibody</article-title>. <source>Sci. Adv.</source>, <volume>8</volume>(<issue>40</issue>):<fpage>eadd2032</fpage>, <month>October</month> <year>2022</year>. doi:<pub-id pub-id-type="doi">10.1126/sciadv.add2032</pub-id>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Ryan</given-names> <surname>York</surname></string-name> and <string-name><given-names>Prachee</given-names> <surname>Avasthi</surname></string-name></person-group>. <article-title>Phylogenies and biological foundation models</article-title>. <source>Arcadia Science</source>, <month>jun</month> 17 <year>2025</year>. doi:<pub-id pub-id-type="doi">10.57844/arcadia-znum-bm22</pub-id>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Asif U.</given-names> <surname>Tamuri</surname></string-name>, <string-name><given-names>Mario dos</given-names> <surname>Reis</surname></string-name>, and <string-name><given-names>Richard A.</given-names> <surname>Goldstein</surname></string-name></person-group>. <article-title>Estimating the distribution of selection coefficients from phylogenetic data using sitewise mutation-selection models</article-title>. <source>Genetics</source>, <volume>190</volume>(<issue>3</issue>):<fpage>1101</fpage>–<lpage>1115</lpage>, <month>March</month> <year>2012</year>. doi:<pub-id pub-id-type="doi">10.1534/genetics.111.136432</pub-id>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Asif U</given-names> <surname>Tamuri</surname></string-name>, <string-name><given-names>Nick</given-names> <surname>Goldman</surname></string-name>, and <string-name><given-names>Mario dos</given-names> <surname>Reis</surname></string-name></person-group>. <article-title>A penalized-likelihood method to estimate the distribution of selection coefficients from phylogenetic data</article-title>. <source>Genetics</source>, <volume>197</volume>(<issue>1</issue>):<fpage>257</fpage>–<lpage>271</lpage>, <month>May</month> <year>2014</year>. doi:<pub-id pub-id-type="doi">10.1534/genetics.114.162263</pub-id>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Nicolas</given-names> <surname>Rodrigue</surname></string-name> and <string-name><given-names>Nicolas</given-names> <surname>Lartillot</surname></string-name></person-group>. <article-title>Site-heterogeneous mutationselection models within the PhyloBayes-MPI package</article-title>. <source>Bioinformatics</source>, <volume>30</volume>(<issue>7</issue>):<fpage>1020</fpage>–<lpage>1021</lpage>, <month>April</month> <year>2014</year>. doi:<pub-id pub-id-type="doi">10.1093/bioinformatics/btt729</pub-id>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jesse D</given-names> <surname>Bloom</surname></string-name></person-group>. <article-title>Identification of positive selection in genes is greatly improved by using experimentally informed site-specific models</article-title>. <source>Biol. Direct</source>, <volume>12</volume>(<issue>1</issue>):<fpage>1</fpage>, <month>January</month> <year>2017</year>. doi:<pub-id pub-id-type="doi">10.1186/s13062-016-0172-z</pub-id>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Sarah K</given-names> <surname>Hilton</surname></string-name>, <string-name><given-names>Michael B</given-names> <surname>Doud</surname></string-name>, and <string-name><given-names>Jesse D</given-names> <surname>Bloom</surname></string-name></person-group>. <article-title>phydms: software for phylogenetic analyses informed by deep mutational scanning</article-title>. <source>PeerJ</source>, <volume>5</volume>:<fpage>e3657</fpage>, <month>July</month> <year>2017</year>. doi:<pub-id pub-id-type="doi">10.7717/peerj.3657</pub-id>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Douglas M</given-names> <surname>Robinson</surname></string-name>, <string-name><given-names>David T</given-names> <surname>Jones</surname></string-name>, <string-name><given-names>Hirohisa</given-names> <surname>Kishino</surname></string-name>, <string-name><given-names>Nick</given-names> <surname>Goldman</surname></string-name>, and <string-name><given-names>Jeffrey L</given-names> <surname>Thorne</surname></string-name></person-group>. <article-title>Protein evolution with dependence among codons due to tertiary structure</article-title>. <source>Mol. Biol. Evol.</source>, <volume>20</volume>(<issue>10</issue>):<fpage>1692</fpage>–<lpage>1704</lpage>, <month>July</month> <year>2003</year>. doi:<pub-id pub-id-type="doi">10.1093/molbev/msg184</pub-id>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>James</given-names> <surname>Dunbar</surname></string-name>, <string-name><given-names>Konrad</given-names> <surname>Krawczyk</surname></string-name>, <string-name><given-names>Jinwoo</given-names> <surname>Leem</surname></string-name>, <string-name><given-names>Terry</given-names> <surname>Baker</surname></string-name>, <string-name><given-names>Angelika</given-names> <surname>Fuchs</surname></string-name>, <string-name><given-names>Guy</given-names> <surname>Georges</surname></string-name>, <string-name><given-names>Jiye</given-names> <surname>Shi</surname></string-name>, and <string-name><given-names>Charlotte M</given-names> <surname>Deane</surname></string-name></person-group>. <article-title>SAbDab: the structural antibody database</article-title>. <source>Nucleic Acids Res.</source>, <volume>42</volume>(<issue>Database issue</issue>):<fpage>D1140</fpage>–<lpage>6</lpage>, <month>January</month> <year>2014</year>. doi:<pub-id pub-id-type="doi">10.1093/nar/gkt1043</pub-id>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>William W</given-names> <surname>Hannon</surname></string-name> and <string-name><given-names>Jesse D</given-names> <surname>Bloom</surname></string-name></person-group>. <article-title>dms-viz: Structure-informed visualizations for deep mutational scanning and other mutation-based datasets</article-title>. <source>J. Open Source Softw.</source>, <volume>9</volume>(<issue>99</issue>):<fpage>6129</fpage>, <month>July</month> <year>2024</year>. doi:<pub-id pub-id-type="doi">10.21105/joss.06129</pub-id>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Meng</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Jonathan</given-names> <surname>Patsenker</surname></string-name>, <string-name><given-names>Henry</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Yuval</given-names> <surname>Kluger</surname></string-name>, and <string-name><given-names>Steven H</given-names> <surname>Kleinstein</surname></string-name></person-group>. <article-title>Language model-based B cell receptor sequence embeddings can effectively encode receptor specificity</article-title>. <source>Nucleic Acids Res.</source>, <volume>52</volume>(<issue>2</issue>):<fpage>548</fpage>–<lpage>557</lpage>, <month>January</month> <year>2024</year>. doi:<pub-id pub-id-type="doi">10.1093/nar/gkad1128</pub-id>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Meng</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Jonathan</given-names> <surname>Patsenker</surname></string-name>, <string-name><given-names>Henry</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Yuval</given-names> <surname>Kluger</surname></string-name>, and <string-name><given-names>Steven H</given-names> <surname>Kleinstein</surname></string-name></person-group>. <article-title>Supervised fine-tuning of pre-trained antibody language models improves antigen specificity prediction</article-title>. <source>PLoS Comput. Biol.</source>, <volume>21</volume>(<issue>3</issue>):<fpage>e1012153</fpage>, <month>March</month> <year>2025</year>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1012153</pub-id>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Roshan</given-names> <surname>Rao</surname></string-name>, <string-name><given-names>Jason</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Robert</given-names> <surname>Verkuil</surname></string-name>, <string-name><given-names>Joshua</given-names> <surname>Meier</surname></string-name>, <string-name><given-names>John F</given-names> <surname>Canny</surname></string-name>, <string-name><given-names>Pieter</given-names> <surname>Abbeel</surname></string-name>, <string-name><given-names>Tom</given-names> <surname>Sercu</surname></string-name>, and <string-name><given-names>Alexander</given-names> <surname>Rives</surname></string-name></person-group>. <article-title>MSA transformer</article-title>. <source>bioRxiv</source>, page 2021.02.12.430858, <month>July</month> <year>2021</year>. doi:<pub-id pub-id-type="doi">10.1101/2021.02.12.430858</pub-id>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Duncan K</given-names> <surname>Ralph</surname></string-name> and <string-name><given-names>Frederick A</given-names> <surname>Matsen</surname></string-name></person-group>, <article-title>4th. Inference of B cell clonal families using heavy/light chain pairing information</article-title>. <source>PLoS Comput. Biol.</source>, <volume>18</volume>(<issue>11</issue>):<fpage>e1010723</fpage>, <month>November</month> <year>2022</year>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Bui Quang</given-names> <surname>Minh</surname></string-name>, <string-name><given-names>Heiko A</given-names> <surname>Schmidt</surname></string-name>, <string-name><given-names>Olga</given-names> <surname>Chernomor</surname></string-name>, <string-name><given-names>Dominik</given-names> <surname>Schrempf</surname></string-name>, <string-name><given-names>Michael D</given-names> <surname>Woodhams</surname></string-name>, <string-name><given-names>Arndt</given-names> <surname>von Haeseler</surname></string-name>, and <string-name><given-names>Robert</given-names> <surname>Lanfear</surname></string-name></person-group>. <article-title>Iq-tree 2: New models and efficient methods for phylogenetic inference in the genomic era</article-title>. <source>Mol. Biol. Evol.</source>, <volume>37</volume>(<issue>5</issue>):<fpage>1530</fpage>–<lpage>1534</lpage>, <month>February</month> <year>2020</year>. doi:<pub-id pub-id-type="doi">10.1093/molbev/msaa015</pub-id>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Olga</given-names> <surname>Chernomor</surname></string-name>, <string-name><given-names>Arndt</given-names> <surname>von Haeseler</surname></string-name>, and <string-name><given-names>Bui Quang</given-names> <surname>Minh</surname></string-name></person-group>. <article-title>Terrace aware data structure for phylogenomic inference from supermatrices</article-title>. <source>Syst Biol</source>, <volume>65</volume>(<issue>6</issue>):<fpage>997</fpage>–<lpage>1008</lpage>, <month>November</month> <year>2016</year>. doi:<pub-id pub-id-type="doi">10.1093/sysbio/syw037</pub-id>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Ashish</given-names> <surname>Vaswani</surname></string-name>, <string-name><given-names>Noam</given-names> <surname>Shazeer</surname></string-name>, <string-name><given-names>Niki</given-names> <surname>Parmar</surname></string-name>, <string-name><given-names>Jakob</given-names> <surname>Uszkoreit</surname></string-name>, <string-name><given-names>Llion</given-names> <surname>Jones</surname></string-name>, <string-name><given-names>Aidan N</given-names> <surname>Gomez</surname></string-name>, <string-name><given-names>L-Ukasz</given-names> <surname>Kaiser</surname></string-name>, and <string-name><given-names>Illia</given-names> <surname>Polosukhin</surname></string-name></person-group>. <chapter-title>At-tention is all you need</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>I</given-names> <surname>Guyon</surname></string-name>, <string-name><given-names>UV</given-names> <surname>Luxburg</surname></string-name>, <string-name><given-names>S</given-names> <surname>Bengio</surname></string-name>, <string-name><given-names>H</given-names> <surname>Wallach</surname></string-name>, <string-name><given-names>R</given-names> <surname>Fergus</surname></string-name>, <string-name><given-names>S</given-names> <surname>Vishwanathan</surname></string-name>, and <string-name><given-names>R</given-names> <surname>Garnett</surname></string-name></person-group>, editors, <source>Advances in Neural Information Processing Systems 30</source>, pages <fpage>6000</fpage>–<lpage>6010</lpage>. <publisher-name>Curran Associates, Inc</publisher-name>., <year>2017</year>. URL: <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf</ext-link>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alexander G</given-names> <surname>Lucaci</surname></string-name>, <string-name><given-names>Sadie R</given-names> <surname>Wisotsky</surname></string-name>, <string-name><given-names>Stephen D</given-names> <surname>Shank</surname></string-name>, <string-name><given-names>Steven</given-names> <surname>Weaver</surname></string-name>, and <string-name><given-names>Sergei L Kosakovsky</given-names> <surname>Pond</surname></string-name></person-group>. <article-title>Extra base hits: Widespread empirical support for instantaneous multiple-nucleotide changes</article-title>. <source>PLoS One</source>, <volume>16</volume>(<issue>3</issue>):<fpage>e0248337</fpage>, <month>March</month> <year>2021</year>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0248337</pub-id>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Cole G</given-names> <surname>Jensen</surname></string-name>, <string-name><given-names>Jacob A</given-names> <surname>Sumner</surname></string-name>, <string-name><given-names>Steven H</given-names> <surname>Kleinstein</surname></string-name>, and <string-name><given-names>Kenneth B</given-names> <surname>Hoehn</surname></string-name></person-group>. <article-title>Inferring B cell phylogenies from paired H and L chain BCR sequences with dowser</article-title>. <source>J. Immunol.</source>, <volume>212</volume>(<issue>10</issue>):<fpage>1579</fpage>–<lpage>1588</lpage>, <year>2024</year>. doi:<pub-id pub-id-type="doi">10.4049/jimmunol.2300851</pub-id>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Adam</given-names> <surname>Paszke</surname></string-name>, <string-name><given-names>Sam</given-names> <surname>Gross</surname></string-name>, <string-name><given-names>Francisco</given-names> <surname>Massa</surname></string-name>, <string-name><given-names>Adam</given-names> <surname>Lerer</surname></string-name>, <string-name><given-names>James</given-names> <surname>Bradbury</surname></string-name>, <string-name><given-names>Gregory</given-names> <surname>Chanan</surname></string-name>, <string-name><given-names>Trevor</given-names> <surname>Killeen</surname></string-name>, <string-name><given-names>Zeming</given-names> <surname>Lin</surname></string-name>, <string-name><given-names>Natalia</given-names> <surname>Gimelshein</surname></string-name>, <string-name><given-names>Luca</given-names> <surname>Antiga</surname></string-name>, <string-name><given-names>Alban</given-names> <surname>Desmaison</surname></string-name>, <string-name><given-names>Andreas</given-names> <surname>Köpf</surname></string-name>, <string-name><given-names>Edward</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>Zach</given-names> <surname>DeVito</surname></string-name>, <string-name><given-names>Martin</given-names> <surname>Raison</surname></string-name>, <string-name><given-names>Alykhan</given-names> <surname>Tejani</surname></string-name>, <string-name><given-names>Sasank</given-names> <surname>Chilamkurthy</surname></string-name>, <string-name><given-names>Benoit</given-names> <surname>Steiner</surname></string-name>, <string-name><given-names>Lu</given-names> <surname>Fang</surname></string-name>, <string-name><given-names>Junjie</given-names> <surname>Bai</surname></string-name>, and <string-name><given-names>Soumith</given-names> <surname>Chintala</surname></string-name></person-group>. <article-title>PyTorch: An imperative style, high-performance deep learning library</article-title>. <source>arXiv</source>, <month>December</month> <year>2019</year>. <pub-id pub-id-type="arxiv">1912.01703</pub-id>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Arvind</given-names> <surname>Satyanarayan</surname></string-name>, <string-name><given-names>Dominik</given-names> <surname>Moritz</surname></string-name>, <string-name><given-names>Kanit</given-names> <surname>Wongsuphasawat</surname></string-name>, and <string-name><given-names>Jeffrey</given-names> <surname>Heer</surname></string-name></person-group>. <article-title>Vega-lite: A grammar of interactive graphics</article-title>. <source>IEEE transactions on visualization and computer graphics</source>, <volume>23</volume>(<issue>1</issue>):<fpage>341</fpage>–<lpage>350</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jacob</given-names> <surname>VanderPlas</surname></string-name>, <string-name><given-names>Brian</given-names> <surname>Granger</surname></string-name>, <string-name><given-names>Jeffrey</given-names> <surname>Heer</surname></string-name>, <string-name><given-names>Dominik</given-names> <surname>Moritz</surname></string-name>, <string-name><given-names>Kanit</given-names> <surname>Wongsuphasawat</surname></string-name>, <string-name><given-names>Arvind</given-names> <surname>Satyanarayan</surname></string-name>, <string-name><given-names>Eitan</given-names> <surname>Lees</surname></string-name>, <string-name><given-names>Ilia</given-names> <surname>Timofeev</surname></string-name>, Ben Welsh, and <string-name><given-names>Scott</given-names> <surname>Sievert</surname></string-name></person-group>. <article-title>Altair: Interactive statistical visualizations for python</article-title>. <source>Journal of Open Source Software</source>, <volume>3</volume>(<issue>32</issue>):<fpage>1057</fpage>, <year>2018</year>. doi:<pub-id pub-id-type="doi">10.21105/joss.01057</pub-id>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Peter J. A.</given-names> <surname>Cock</surname></string-name>, <string-name><given-names>Tiago</given-names> <surname>Antao</surname></string-name>, <string-name><given-names>Jeffrey T.</given-names> <surname>Chang</surname></string-name>, <string-name><given-names>Brad A.</given-names> <surname>Chapman</surname></string-name>, <string-name><given-names>Cymon J.</given-names> <surname>Cox</surname></string-name>, <string-name><given-names>Andrew</given-names> <surname>Dalke</surname></string-name>, <string-name><given-names>Iddo</given-names> <surname>Friedberg</surname></string-name>, <string-name><given-names>Thomas</given-names> <surname>Hamelryck</surname></string-name>, <string-name><given-names>Frank</given-names> <surname>Kauff</surname></string-name>, <string-name><given-names>Bartek</given-names> <surname>Wilczynski</surname></string-name>, and <string-name><given-names>Michiel J. L.</given-names> <surname>de Hoon</surname></string-name></person-group>. <article-title>Biopython: freely available Python tools for computational molecular biology and bioinformatics</article-title>. <source>Bioinformatics</source>, <volume>25</volume>(<issue>11</issue>):<fpage>1422</fpage>–<lpage>1423</lpage>, 03 <year>2009</year>. doi:<pub-id pub-id-type="doi">10.1093/bioinformatics/btp163</pub-id>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. D.</given-names> <surname>Hunter</surname></string-name></person-group>. <article-title>Matplotlib: A 2d graphics environment</article-title>. <source>Computing in Science &amp; Engineering</source>, <volume>9</volume>(<issue>3</issue>):<fpage>90</fpage>–<lpage>95</lpage>, <year>2007</year>. doi:<pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>Wes</given-names> <surname>McKinney</surname></string-name></person-group>. <article-title>Data Structures for Statistical Computing in Python</article-title>. In <conf-name>Proceedings of the 9th Python in Science Conference</conf-name>, pages <fpage>56</fpage> – <lpage>61</lpage>, <year>2010</year>. doi:<pub-id pub-id-type="doi">10.25080/Majora-92bf1922-00a</pub-id>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><given-names>Holger</given-names> <surname>Krekel</surname></string-name>, <string-name><given-names>Bruno</given-names> <surname>Oliveira</surname></string-name>, <string-name><given-names>Ronny</given-names> <surname>Pfannschmidt</surname></string-name>, <string-name><given-names>Floris</given-names> <surname>Bruynooghe</surname></string-name>, <string-name><given-names>Brianna</given-names> <surname>Laugher</surname></string-name>, and <string-name><given-names>Florian</given-names> <surname>Bruhin</surname></string-name></person-group>. <source>pytest 8.1.1</source>, <year>2004</year>. URL: <ext-link ext-link-type="uri" xlink:href="https://github.com/pytest-dev/pytest">https://github.com/pytest-dev/pytest</ext-link>.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Michael L.</given-names> <surname>Waskom</surname></string-name></person-group>. <article-title>seaborn: statistical data visualization</article-title>. <source>Journal of Open Source Software</source>, <volume>6</volume>(<issue>60</issue>):<fpage>3021</fpage>, <year>2021</year>. doi:<pub-id pub-id-type="doi">10.21105/joss.03021</pub-id>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Felix</given-names> <surname>Mölder</surname></string-name>, <string-name><given-names>Kim Philipp</given-names> <surname>Jablonski</surname></string-name>, <string-name><given-names>Brice</given-names> <surname>Letcher</surname></string-name>, <string-name><given-names>Michael B</given-names> <surname>Hall</surname></string-name>, <string-name><given-names>Christopher H</given-names> <surname>Tomkins-Tinch</surname></string-name>, <string-name><given-names>Vanessa</given-names> <surname>Sochat</surname></string-name>, <string-name><given-names>Jan</given-names> <surname>Forster</surname></string-name>, <string-name><given-names>Soohyun</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>Sven O</given-names> <surname>Twardziok</surname></string-name>, <string-name><given-names>Alexander</given-names> <surname>Kanitz</surname></string-name>, <string-name><given-names>Andreas</given-names> <surname>Wilm</surname></string-name>, <string-name><given-names>Manuel</given-names> <surname>Holtgrewe</surname></string-name>, <string-name><given-names>Sven</given-names> <surname>Rahmann</surname></string-name>, <string-name><given-names>Sven</given-names> <surname>Nahnsen</surname></string-name>, and <string-name><given-names>Johannes</given-names> <surname>Köster</surname></string-name></person-group>. <article-title>Sustainable data analysis with snakemake</article-title>. <source>F1000Res.</source>, <volume>10</volume>(<issue>33</issue>):<fpage>33</fpage>, <month>April</month> <year>2021</year>. doi:<pub-id pub-id-type="doi">10.12688/f1000research.29032.2</pub-id>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Catherine</given-names> <surname>Tang</surname></string-name>, <string-name><given-names>Artem</given-names> <surname>Krantsevich</surname></string-name>, and <string-name><given-names>Thomas</given-names> <surname>MacCarthy</surname></string-name></person-group>. <article-title>Deep learning model of somatic hypermutation reveals importance of sequence context beyond hotspot targeting</article-title>. <source>iScience</source>, <volume>25</volume>(<issue>1</issue>):<fpage>103668</fpage>, <month>January</month> <year>2022</year>. doi:<pub-id pub-id-type="doi">10.1016/j.isci.2021.103668</pub-id>.</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>David B</given-names> <surname>Jaffe</surname></string-name>, <string-name><given-names>Payam</given-names> <surname>Shahi</surname></string-name>, <string-name><given-names>Bruce A</given-names> <surname>Adams</surname></string-name>, <string-name><given-names>Ashley M</given-names> <surname>Chrisman</surname></string-name>, <string-name><given-names>Peter M</given-names> <surname>Finnegan</surname></string-name>, <string-name><given-names>Nandhini</given-names> <surname>Raman</surname></string-name>, <string-name><given-names>Ariel E</given-names> <surname>Royall</surname></string-name>, <string-name><given-names>Funien</given-names> <surname>Tsai</surname></string-name>, <string-name><given-names>Thomas</given-names> <surname>Vollbrecht</surname></string-name>, <string-name><given-names>Daniel S</given-names> <surname>Reyes</surname></string-name>, N <string-name><given-names>Lance</given-names> <surname>Hepler</surname></string-name>, and <string-name><given-names>Wyatt J</given-names> <surname>McDonnell</surname></string-name></person-group>. <article-title>Functional antibodies exhibit light chain coherence</article-title>. <source>Nature</source>, <volume>611</volume>(<issue>7935</issue>):<fpage>352</fpage>–<lpage>357</lpage>, <month>November</month> <year>2022</year>. doi:<pub-id pub-id-type="doi">10.1038/s41586-022-05371-z</pub-id>.</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Stefano</given-names> <surname>Vergani</surname></string-name>, <string-name><given-names>Ilya</given-names> <surname>Korsunsky</surname></string-name>, <string-name><given-names>Andrea Nicola</given-names> <surname>Mazzarello</surname></string-name>, <string-name><given-names>Gerardo</given-names> <surname>Ferrer</surname></string-name>, <string-name><given-names>Nicholas</given-names> <surname>Chiorazzi</surname></string-name>, and <string-name><given-names>Davide</given-names> <surname>Bagnara</surname></string-name></person-group>. <article-title>Novel method for high-throughput full-length IGHV-D-J sequencing of the immune repertoire from bulk b-cells with single-cell resolution</article-title>. <source>Front. Immunol.</source>, <volume>8</volume>:<fpage>1157</fpage>, <month>September</month> <year>2017</year>. doi:<pub-id pub-id-type="doi">10.3389/fimmu.2017.01157</pub-id>.</mixed-citation></ref>
<ref id="c58"><label>[58]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Eric</given-names> <surname>Engelbrecht</surname></string-name>, <string-name><given-names>Oscar L</given-names> <surname>Rodriguez</surname></string-name>, <string-name><given-names>William</given-names> <surname>Lees</surname></string-name>, <string-name><given-names>Zach</given-names> <surname>Vanwinkle</surname></string-name>, <string-name><given-names>Kaitlyn</given-names> <surname>Shields</surname></string-name>, <string-name><given-names>Steven</given-names> <surname>Schultze</surname></string-name>, <string-name><given-names>William S</given-names> <surname>Gibson</surname></string-name>, <string-name><given-names>David R</given-names> <surname>Smith</surname></string-name>, <string-name><given-names>Uddalok</given-names> <surname>Jana</surname></string-name>, <string-name><given-names>Swati</given-names> <surname>Saha</surname></string-name>, <string-name><given-names>Ayelet</given-names> <surname>Peres</surname></string-name>, <string-name><given-names>Gur</given-names> <surname>Yaari</surname></string-name>, <string-name><given-names>Melissa L</given-names> <surname>Smith</surname></string-name>, and <string-name><given-names>Corey T</given-names> <surname>Watson</surname></string-name></person-group>. <article-title>Germline polymorphism in the immunoglobulin kappa and lambda loci explain variation in the expressed light chain antibody repertoire</article-title>. <source>bioRxivorg</source>, page <elocation-id>2025.05.28.656470</elocation-id>, <month>June</month> <year>2025</year>. doi:<pub-id pub-id-type="doi">10.1101/2025.05.28.656470</pub-id>.</mixed-citation></ref>
<ref id="dataref1"><mixed-citation publication-type="data" specific-use="analyzed"><person-group person-group-type="author"><string-name><surname>Koenig et al</surname></string-name></person-group> (<year iso-8601-date="2017">2017</year>) <article-title>G6.31 anti-VEGF antibody deep mutational scan</article-title>. <source>Zenodo</source>. <pub-id pub-id-type="doi">10.5281/zenodo.17322890</pub-id></mixed-citation></ref>
<ref id="dataref2"><mixed-citation publication-type="data" specific-use="analyzed"><person-group person-group-type="author"><string-name><surname>Shanehsazzadeh</surname></string-name> <etal>et al</etal></person-group> (<year iso-8601-date="2023">2023</year>) <article-title>Trastuzumab HCDR redesign zero-shot binding data</article-title>. <source>Zenodo</source>. <pub-id pub-id-type="doi">10.5281/zenodo.17322891</pub-id></mixed-citation></ref>
<ref id="dataref3"><mixed-citation publication-type="data" specific-use="analyzed"><person-group person-group-type="author"><string-name><surname>Kirby</surname></string-name> <etal>et al</etal></person-group> (<year iso-8601-date="2025">2025</year>) <article-title>MAGMA-seq SARS-CoV-2 antibody UCA trajectories</article-title>. <source>GitHub</source>. <pub-id pub-id-type="accession" xlink:href="https://github.com/matsengrp/dasm-experiments/tree/main/data/whitehead/kirby">dasm-experiments</pub-id></mixed-citation></ref>
<ref id="dataref4"><mixed-citation publication-type="data" specific-use="analyzed"><person-group person-group-type="author"><string-name><surname>Rodriguez</surname></string-name> <etal>et al</etal></person-group> (<year iso-8601-date="2023">2023</year>) <article-title>Human BCR repertoire IgM RACE sequences</article-title>. <source>Zenodo</source>. <pub-id pub-id-type="doi">10.5281/zenodo.17322891</pub-id></mixed-citation></ref>
<ref id="dataref5"><mixed-citation publication-type="data" specific-use="analyzed"><person-group person-group-type="author"><string-name><surname>Tang</surname></string-name> <etal>et al</etal></person-group> (<year iso-8601-date="2022">2022</year>) <article-title>Human BCR repertoire DeepSHM training data</article-title>. <source>Zenodo</source>. <pub-id pub-id-type="doi">10.5281/zenodo.17322891</pub-id></mixed-citation></ref>
<ref id="dataref6"><mixed-citation publication-type="data" specific-use="analyzed"><person-group person-group-type="author"><string-name><surname>Engelbrecht</surname></string-name> <etal>et al</etal></person-group> (<year iso-8601-date="2025">2025</year>) <article-title>170-donor BCR repertoire Takara 5'RACE data</article-title>. <source>Zenodo</source>. <pub-id pub-id-type="doi">10.5281/zenodo.17322891</pub-id></mixed-citation></ref>
<ref id="dataref7"><mixed-citation publication-type="data" specific-use="analyzed"><person-group person-group-type="author"><string-name><surname>Jaffe</surname></string-name> <etal>et al</etal></person-group> (<year iso-8601-date="2022">2022</year>) <article-title>10X BCR repertoire paired heavy-light training data</article-title>. <source>Zenodo</source>. <pub-id pub-id-type="doi">10.5281/zenodo.17322891</pub-id></mixed-citation></ref>
<ref id="dataref8"><mixed-citation publication-type="data" specific-use="analyzed"><person-group person-group-type="author"><string-name><surname>Petersen</surname></string-name> <etal>et al</etal></person-group> (<year iso-8601-date="2024">2024</year>) <article-title>MAGMA-seq influenza antibody affinity measurements</article-title>. <source>GitHub</source>. <pub-id pub-id-type="accession" xlink:href="https://github.com/matsengrp/dasm-experiments/tree/main/data/whitehead/petersen">dasm-experiments</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109644.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Bitbol</surname>
<given-names>Anne-Florence</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1020-494X</contrib-id>
<aff>
<institution-wrap>
<institution>Ecole Polytechnique Federale de Lausanne (EPFL)</institution>
</institution-wrap>
<city>Lausanne</city>
<country>Switzerland</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> study introduces a new biology-informed strategy for deep learning models aiming to predict mutational effects in antibody sequences. It provides <bold>solid</bold> evidence that separating selection from the nucleotide-level mutation process improves performance over the objectives of protein language models inspired by natural language processing. This paper should be of interest to computational immunologists, but also to the broader community interested in deep learning for biological sequence data and evolution.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109644.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Matsen et al. describe an approach for training an antibody language model that explicitly tries to remove effects of &quot;neutral mutation&quot; from the language model training task, e.g. learning the codon table, which they claim results in biased functional predictions. They do so by modeling empirical sequence-derived likelihoods through a combination of a &quot;mutation&quot; model and a &quot;selection&quot; model; the mutation model is a non-neural Thrifty model previously developed by the authors, and the selection model is a small Transformer that is trained via gradient descent. The sequence likelihoods themselves are obtained from analyzing parent-child relationships in natural SHM datasets. The authors validate their method on several standard benchmark datasets and demonstrate its favorable computational cost. They discuss how deep learning models explicitly designed to capture selection and not mutation, trained on parent-child pairs, could potentially apply to other domains such as viral evolution or protein evolution at large.</p>
<p>Strengths:</p>
<p>Overall, we think the idea behind this manuscript is really clever and shows promising empirical results. Two aspects of the study are conceptually interesting: the first is factorizing the training likelihood objective to learn properties that are not explained by simple neutral mutation rules, and the second is training not on self-supervised sequence statistics but on the differences between sequences along an antibody evolutionary trajectory. If this approach generalizes to other domains of life, it could offer a new paradigm for training sequence-to-fitness models that is less biased by phylogeny or other aspects of the underlying mutation process.</p>
<p>Weaknesses:</p>
<p>Some claims made in the paper are weakly or indirectly supported by the data. In particular, the claim that learning the codon table contributes to biased functional effect predictions may be true, but requires more justification. Additionally, the paper could benefit from additional benchmarking and comparison to enhanced versions of existing methods, such as AbLang plus a multi-hit correction. Further descriptions of model components and validation metrics could help make the manuscript more readable.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109644.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Endowing protein language models with the ability to predict the function of antibodies would open a world of translational possibilities. However, antibody language models have yet to achieve breakthrough success, which large language models have achieved for the understanding and generation of natural language. This paper elegantly demonstrates how training objectives imported from natural language applications lead antibody language models astray on function prediction tasks. Training models to predict masked amino acids teaches models to exploit biases of nucleotide-level mutational processes, rather than protein biophysics. Taking the underlying biology of antibody diversification and selection seriously allows for disentangling these processes through what the authors call deep amino acid selection models. These models extend previous work by the authors (Matsen MBE 2025) by providing predictions not only for the selection strength at individual sites, but also for individual amino acid substitutions. This represents a practically important advance.</p>
<p>Strengths:</p>
<p>The paper is based on a deep conceptual insight, the existence of a multitude of biological processes that affect antibody maturation trajectories. The figures and writing a very clear, which should help make the broader field aware of this important but sometimes overlooked insight. The paper adds to a growing literature proposing biology-informed tweaks for training protein language models, and should thus be of interest to a wide readership interested in the application of machine learning to protein sequence understanding and design.</p>
<p>Weaknesses:</p>
<p>Proponents of the state-of-the-art protein language models might counter the claims of the paper by appealing to the ability of fine-tuning to deconvolve selection and mutation-related signatures in their high-dimensional representation spaces. Leaving the exercise of assessing this claim entirely to future work somewhat diminishes the heft of the (otherwise good!) argument. In the context of predicting antibody binding affinity, the modeling strategy only allows prediction of mutations that improve affinity on average, but not those which improve binding to specific epitopes.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109644.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work proposes DASM, a new transformer-based approach to learning the distribution of antibody sequences which outperforms current foundational models at the task of predicting mutation propensities under selected phenotypes, such as protein expression levels and target binding affinity. The key ingredient is the disentanglement, by construction, of selection-induced mutational effects and biases intrinsic to the somatic hypermutation process (which are embedded in a pre-trained model).</p>
<p>Strengths:</p>
<p>The approach is benchmarked on a variety of available datasets and for two different phenotypes (expression and binding affinity). The biologically informed logic for model construction implemented is compelling, and the advantage, in terms of mutational effects prediction, is clearly demonstrated via comparisons to state-of-the-art models.</p>
<p>Weaknesses:</p>
<p>The gain in interpretability is only mentioned but not really elaborated upon or leveraged for gaining insight. The following aspects could have been better documented: the hyperparametric search to establish the optimal model; the predictive performance of baseline approaches, to fully showcase the gain yielded by DASM.</p>
</body>
</sub-article>
</article>