<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">106543</article-id>
<article-id pub-id-type="doi">10.7554/eLife.106543</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106543.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Stimulus dependencies—rather than next-word prediction—can explain pre-onset brain encoding during natural listening</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Schönmann</surname>
<given-names>Inés</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>ines.schoenmann@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Szewczyk</surname>
<given-names>Jakub</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6730-1452</contrib-id>
<name>
<surname>de Lange</surname>
<given-names>Floris P</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3039-4007</contrib-id>
<name>
<surname>Heilbron</surname>
<given-names>Micha</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Donders Institute for Brain, Cognition and Behaviour</institution></institution-wrap>, <city>Nijmegen</city>, <country country="NL">Netherlands</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>Amsterdam Brain and Cognition, University of Amsterdam</institution></institution-wrap>, <city>Amsterdam</city>, <country country="NL">Netherlands</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Ding</surname>
<given-names>Nai</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Zhejiang University</institution>
</institution-wrap>
<city>Hangzhou</city>
<country>China</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Luo</surname>
<given-names>Huan</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-04-17">
<day>17</day>
<month>04</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP106543</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-03-08">
<day>08</day>
<month>03</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-03-10">
<day>10</day>
<month>03</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.03.08.642140"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Schönmann et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Schönmann et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-106543-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>The human brain is thought to constantly predict future words during language processing. Recently, a new approach to investigating linguistic predictions emerged which aims to capture predictive pre-activation directly by using neural network representations of words to predict brain activity prior to word onset. However, it is unclear what exactly is driving the predictability of pre-stimulus brain activity. Here we show, across two datasets, that both proposed hallmarks of neural pre-activation—i.e. (i) pre-onset brain response predictability and (ii) its modulation by word expectedness—is not only observed in brain responses, but also in representations of the stimulus material itself. We show that various structural and incidental dependencies existing in natural language can explain previously reported hallmarks of pre-diction without assuming any pre-activation in the neural data. This suggests that pre-onset prediction of brain activity might only reflect dependencies within the stimulus material rather than predictive computations, and questions the extent to which this new prediction-based method can be used to study prediction in the brain.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>In the past years, the field of natural language processing (NLP) has made great advances in developing computational systems that can generate, classify and interpret language. Much of this progress has been driven by large language models (LLMs): neural networks trained in a self-supervised manner to predict the next word or token (<xref ref-type="bibr" rid="c26">Minaee et al., 2024</xref>). Surprisingly, this simple training objective is sufficient for models to learn about language more broadly, making models develop a human-like knowledge of syntax (<xref ref-type="bibr" rid="c25">Manning et al., 2020</xref>; <xref ref-type="bibr" rid="c23">Linzen and Baroni, 2021</xref>) and enabling them to solve almost any NLP task (<xref ref-type="bibr" rid="c26">Minaee et al., 2024</xref>; <xref ref-type="bibr" rid="c24">Manning, 2022</xref>). Furthermore, internal model representations (“embeddings”) also constitute the highest performing encoding models for predicting brain responses to linguistic stimuli (<xref ref-type="bibr" rid="c8">Caucheteux and King, 2022</xref>; <xref ref-type="bibr" rid="c18">Jain and Huth, 2018</xref>; <xref ref-type="bibr" rid="c32">Schrimpf et al., 2021</xref>)—indicating that LLMs’ internal representations might capture some aspects of human language representations (<xref ref-type="bibr" rid="c36">Tuckute et al., 2024</xref>).</p>
<p>Two lines of research suggest that predicting the upcoming linguistic input also plays an important role in <italic>human</italic> language comprehension. The first line of research focuses on neural and behavioural responses occurring <italic>after</italic> the onset of the stimulus in question. The reasoning being that if the brain is engaged in predicting upcoming linguistic input, brain responses and reading times should vary as a function of linguistic predictability (<xref ref-type="bibr" rid="c34">Smith and Levy, 2013</xref>; <xref ref-type="bibr" rid="c9">Frank et al., 2015</xref>; <xref ref-type="bibr" rid="c38">Willems et al., 2016</xref>; <xref ref-type="bibr" rid="c33">Shain et al., 2024</xref>; <xref ref-type="bibr" rid="c14">Heilbron et al., 2023</xref>). Many studies following this line of reasoning have demonstrated that both neural responses and reading times are sensitive to even subtle fluctuations in predictability at several levels of linguistic analysis, e.g. phonemes, words or semantics (<xref ref-type="bibr" rid="c4">Boston et al., 2011</xref>; <xref ref-type="bibr" rid="c5">Brodbeck et al., 2022</xref>; <xref ref-type="bibr" rid="c13">Heilbron et al., 2022</xref>; <xref ref-type="bibr" rid="c34">Smith and Levy, 2013</xref>; <xref ref-type="bibr" rid="c35">Szewczyk and Federmeier, 2022</xref>). This approach can be seen as an extension of a long-standing tradition of research into linguistic expectations which relied on carefully constructed sentences that violate linguistic expectations and use cloze probabilities to quantify unexpectedness (<xref ref-type="bibr" rid="c20">Kutas and Hillyard, 1980a</xref>,<xref ref-type="bibr" rid="c21">b</xref>, <xref rid="c22" ref-type="bibr">1984</xref>).</p>
<p>Recently, a new, alternative approach emerged that aims to probe linguistic predictions directly by capturing their neural signature <italic>prior</italic> to the onset of a word (<xref ref-type="bibr" rid="c37">Wang et al., 2018</xref>; <xref ref-type="bibr" rid="c11">Goldstein et al. 2022b</xref>). Predicting a word is thought to involve a pre-activation of the representation of that word. Hence, finding a trace of a representation of a word in the neural signal <italic>prior</italic> to its onset, is interpreted as direct evidence for a word’s pre-activation, and therefore, next-word prediction. Capturing the neural signature of the prediction itself is appealing, since it potentially circumvents interpretational challenges of more indirect, post-stimulus predictability effects which have been suggested by some to reflect related but distinct downstream processes—such as semantic integration difficulty or ‘post-diction’—rather than prediction <italic>per se</italic> (<xref ref-type="bibr" rid="c29">Pickering and Gambi, 2018</xref>; <xref ref-type="bibr" rid="c16">Huettig, 2015</xref>; <xref ref-type="bibr" rid="c17">Huettig and Mani, 2016</xref>). Perhaps the most influential demonstration of predictive pre-activation during language comprehension was presented by <xref ref-type="bibr" rid="c11">Goldstein et al. (2022b)</xref>. Using both encoding (predicting brain responses to a stimulus based on a model’s representation of that stimulus) and decoding analyses (determining the model representation of a stimulus from the brain’s response to that stimulus) on electrocortographic (ECoG) recordings of participants listening to naturalistic narratives, the authors showed (i) that brain responses could be predicted significantly better than chance using word embeddings of the upcoming word, as early as two seconds prior to onset. Furthermore, they showed (ii) that this effect was modulated by word predictability: words that were highly predictable in context showed higher pre-stimulus brain-prediction performance—in line with the idea that their representation was pre-activated more strongly. More recently, a similar pattern of results was found in non-invasive MEG recordings (<xref ref-type="bibr" rid="c3">Azizpour et al., 2024</xref>).</p>
<p>Here, we build on these results and ask to what extent, and under which conditions, these two proposed hallmarks of prediction can unequivocally be interpreted as reflecting neural pre-activation. This question is motivated by the fact that, in natural language, some inherent correlations or dependencies exist between neighbouring words. Often they share semantic aspects—as in the sequences “pine tree” or “green leaves”—or (morpho)syntactic information, as in the phrase “he goes” in which both words indicate the use of the third person singular. At other times dependencies result from words that frequently co-occur in a discourse, like “Sherlock Holmes”. Irrespective of the exact nature of the shared information between neighbouring words, natural language is full of such structural and incidental regularities. A priori, then, these inherent <italic>stimulus dependencies</italic> might already explain why representations of future words can predict brain responses to preceding words, without having to assume an additional pre-activation by the brain. The goal of this study is two-fold: (i) to assess to what extent the hallmarks introduced by <xref ref-type="bibr" rid="c11">Goldstein et al. (2022b)</xref> might be explained by stimulus dependencies, and (ii) to explore potential methods to correct for this alternative explanation, and propose a more stringent test for pre-activation within the encoding modelling framework introduced by <xref ref-type="bibr" rid="c11">Goldstein et al. (2022b)</xref>.</p>
<p>To foreshadow our findings, we show here that ostensible hallmarks of next-word prediction based on the analysis of neural activity before word-onset are also present in the stimulus material itself, namely when applying the same analysis to word embeddings and acoustic representations of the stimuli. Furthermore, we find that these dependencies can be corrected for only within the same, but not between representational spaces—a necessity for encoding neural data from model representations. We conclude that pre-onset encoding results simply reflect correlational patterns found in naturalistic language. This poses a serious challenge to the direct approach of probing linguistic pre-activations prior to word onset through encoding modelling, and questions to what extent such findings can demonstrate that brains, like LLMs, actually perform next-word prediction.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Hallmarks of prediction replicate in MEG data</title>
<p>Drawing on two different, publicly available MEG datasets in which participants listened to narratives, we analysed the data following the approach put forth by <xref ref-type="bibr" rid="c11">Goldstein et al. (2022b)</xref> and <xref ref-type="bibr" rid="c3">Azizpour et al. (2024</xref>). Hence, MEG data were epoched with respect to the onset of each word between −2<italic>s</italic> and +2<italic>s</italic>, and brain activity was averaged over a sliding window of 100<italic>ms</italic>. Subsequently, the word representation (word embedding) corresponding to the word to which each epoch was time-locked, was used to predict brain activity within the epoch, i.e., within the time window of −2<italic>s</italic> to +2<italic>s</italic> (see <xref rid="fig1" ref-type="fig">Figure 1a</xref>). Correlating the predicted with the actual brain response, results in a time-resolved prediction accuracy curve which allows us to test the two hallmarks of prediction proposed by <xref ref-type="bibr" rid="c11">Goldstein et al. (2022b)</xref>, namely i) whether brain activity prior to the onset of a word can be predicted from that word’s embedding and ii) whether pre-onset prediction accuracy is higher for predictable words than for unpredictable ones. These two aspects are proposed as evidence of prediction, since pre-onset encoding is thought to capture the pre-activation of a word’s neural representation.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><p>A) MEG Encoding Model. MEG data was epoched to word onset and averaged over a sliding window of 100<italic>ms</italic>, moving with a step size of 25<italic>ms</italic>. The model representation (GPT-2, GloVe or arbitrary) of the word at <italic>t</italic> = 0 was then used to predict the neural response for each channel and time point in a separate cross-validated Ridge regression. The actual and predicted response were then correlated time point by time point, resulting in a time-resolved encoding plot. B) Positive pre-onset encoding (subject 1) for GPT-2 (green), GloVe (blue) and arbitrary (grey) embeddings shows that it possible to find ostensible neural signatures of pre-activation in MEG data. Lines show clusters of time points that are significantly different from zero (<italic>p</italic> &lt; 0.05 under the permutation distribution). C) Encoding using GloVe embeddings demonstrate a slight advantage of the predictability of a word (top-1 prediction by GPT-2-XL) for pre-onset encoding. Line indicates clusters of time points prior to word onset during which predictable words are significantly better encoded (<italic>p</italic> &lt; 0.05 under the permutation distribution).</p></caption>
<graphic xlink:href="642140v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Using representations from three different models (GPT-2, GloVe and arbitrary 300-dimensional word embeddings) to encode brain activity, we found that it is possible to replicate both hallmarks of predictions described by <xref ref-type="bibr" rid="c11">Goldstein et al. (2022b)</xref>. We found both i) positive encoding prior to word onset for all three models (see <xref rid="fig1" ref-type="fig">Figure 1B</xref>) and ii) a slight encoding advantage prior to word onset for highly predictable (i.e., GPT-2’s top-1 prediction) as opposed to less predictable words (see <xref rid="fig1" ref-type="fig">Figure 1C</xref>). For subject 1 this advantage started as early as 575<italic>ms</italic> prior to word onset, and predictable words lead to a continuously higher encoding performance (<italic>M</italic> = .004, <italic>SD</italic> = .001 for significant time points, all <italic>p’s</italic> &lt; 0.031, TFCE FWE-corrected), corresponding to an average improvement in encoding performance within this pre-onset time window of 17% with respect to unpredictable words (with improvements of <italic>M</italic> = .006 (<italic>SD</italic> = .002, all <italic>p’s</italic> &lt; 0.035) corresponding to 25% starting 525<italic>ms</italic> prior to onset, and <italic>M</italic> = .011 (<italic>SD</italic> = .006, all <italic>p’s</italic> &lt; 0.033) corresponding to 46% during the time window of 1 400 − 300<italic>ms</italic> prior to word onset for subject 2 and 3, respectively). In accordance with previous findings, using GPT-2’s contextualised word representations allowed for earlier and better brain encoding than using non-contextualised GloVe embeddings (<xref ref-type="bibr" rid="c11">Goldstein et al. 2022b</xref>; <xref ref-type="bibr" rid="c31">Schrimpf et al., 2020</xref>). In turn, these non-contextualized word embeddings predicted brain response better than arbitrary, 300-dimensional vectors. However, arbitrary embeddings still performed remarkably well, given that they contain no structured information besides the identity of a word (see Discussion).</p>
<p>These results replicated for all three participants (see <xref rid="figS1" ref-type="fig">Figure S1A</xref> and <xref rid="figS1" ref-type="fig">S1B</xref>) in the few-subject dataset, indicating the robustness of the results given sufficient amounts of data (see <xref rid="figS1" ref-type="fig">Figure S1C</xref> for results from a more conventional multi-subject dataset). This demonstrates that pre-onset encoding is a tremendously robust phenomenon, replicating across different word embeddings (GPT-2, GloVe and even arbitrary embeddings), data sets (single-subject as well as multi-subject) and even different forms of MEG spaces (source as well as sensor data).</p>
</sec>
<sec id="s2b">
<title>Stimulus dependencies mirror brain encoding results</title>
<p>In order to assess to what extent brain encoding results prior to word onset might be driven by dependencies between neighbouring words in the dataset, we propose a <italic>self-predictability analysis</italic> in which we use the same word-embedding-based encoding model in order to predict word embeddings of preceding words (see <xref rid="fig2" ref-type="fig">Figure 2A</xref>). Thus, instead of using word embeddings to predict brain activity prior to word onset, the encoding model is using word embeddings to predict <italic>preceding word embeddings</italic>, prior to word onset. This was done separately for each type of word embedding: GPT-2’s word representations were used to predict preceding GPT-2 embeddings, GloVe embeddings were used to predict preceding GloVe embeddings and arbitrary word embeddings were used to predict preceding arbitrary embeddings. We refer to the encoding performance of each model’s representations as its <italic>self-predictability</italic> (see <xref rid="fig2" ref-type="fig">Figure 2A</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><p><bold>A)</bold> Self-predictability of Model Representations. In order to assess the predictability of neighbouring model representations in each MEG epoch, we replaced the neural data at each time point with the model representation of the word presented during that time point. The model representation of the word at <italic>t</italic> = 0 was then used to predict the previous model representations for each dimension and time point in a separate cross-validated Ridge regression. The actual and predicted values were then correlated time point by time point, resulting in a time-resolved self-predictability plot. <bold>B)</bold> Self-predictability for GPT-2(green), GloVe (blue) and arbitrary (grey) embeddings prior to word onset mirrors patterns observed when encoding the eural data. <bold>C)</bold> Self-predictability of GloVe embeddings demonstrate a clear advantage of the predictability of a word (top-1 prediction by GPT-2-XL), and therefore the same qualitative difference as observed when encoding neural data.</p></caption>
<graphic xlink:href="642140v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Strikingly, this approach revealed that—for each type of word embedding—self-predictability curves exhibited the same two hallmarks of prediction as observed in the neural data. In line with the first hallmark, we found significant self-predictability prior to word onset for all three models (see <xref rid="fig2" ref-type="fig">Figure 2B</xref> and <xref rid="figS2" ref-type="fig">S2A</xref>), with highest self-predictability for GPT-2 and lowest for arbitrary embeddings. Furthermore, and in line with the second hallmark, models exhibited higher self-predictability in epochs time-locked to a highly predictable word as opposed to those time-locked to less predictable words (see <xref rid="fig2" ref-type="fig">Figure 2C</xref> and <xref rid="figS2" ref-type="fig">S2B</xref> and <xref rid="figS2" ref-type="fig">C</xref>). Additionally, in the time window prior to word onset, self-predictability showed a similar time course and similar differences between models as observed in the brain encoding (see <xref rid="fig2" ref-type="fig">Figure 2B</xref> and <xref rid="figS2" ref-type="fig">S2A</xref>). Hence, in naturalistic texts, both ostensible hallmarks of prediction—encoding prior to word-onset and sensitivity of pre-onset encoding to word predictability—can be the result of the correlational structure of neighbouring model representations. Therefore, these proposed hallmarks do not necessarily reflect a neural pre-activation of the representation of that word. Instead, they can, in principle, be explained through stimulus dependencies alone, without assuming any predictive pre-activations in the neural data.</p>
</sec>
<sec id="s2c">
<title>Removing stimulus dependencies from word embeddings does not remove stimulus dependencies across representational domains</title>
<p>Given that these stimulus dependencies <italic>within</italic> word embeddings can be quantified so straightforwardly, we then asked whether they can be removed using a similar approach, in order to test for pre-activation while correcting for stimulus dependencies. A general and powerful approach is to use residualisation or “regressing out”. For instance, in the sentence “You know my methods.”, “You” can be regressed out of “know”, “know” out of “my”, and “my” out of “methods” (see <xref rid="fig3" ref-type="fig">Figure 3A</xref>). Note that this is a generalised version of a control analysis performed by <xref ref-type="bibr" rid="c11">Goldstein et al. (2022b)</xref>, which removed neighbouring words from word embeddings through projection. When we residualised the embeddings in this way and then repeated the self-predictability analysis with these residualised embeddings, results confirmed that this procedure reduces pre-onset self-predictability to zero—suggesting that this may be an easy and effective way to remove stimulus dependencies from the word embeddings themselves (see <xref rid="fig3" ref-type="fig">Figure 3B</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><p><bold>A)</bold> In order to remove shared information between a word and its predecessor in the text, we residualised word embeddings by first fitting an OLS regression to predict the next word based on the previous word’s embedding, i.e. predicting “know” based on “You”. This resulted in a predicted embedding <inline-formula><inline-graphic xlink:href="642140v1_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, e.g. <inline-formula><inline-graphic xlink:href="642140v1_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which contained the shared information between the two words. Finally, the predicted embedding, e.g. <inline-formula><inline-graphic xlink:href="642140v1_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, was removed from the original embedding, e.g. “know”, to generate word representations for which the dependency between neighbouring words was removed. <bold>B)</bold> Self-predictability after regressing out the previous embedding from the embedding at <italic>t</italic> = 0 shows that it is possible to successfully remove the correlations between neighbouring model representations. For brain encoding results when using these residualisded embeddings, see <xref rid="figS3" ref-type="fig">Figure S3</xref>.</p></caption>
<graphic xlink:href="642140v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>However, one important limitation of this approach lies in the fact that it only accounts for the correlations between neighbouring word embeddings within this specific representational space, and not for temporal stimulus dependencies more broadly. When encoding brain activity, however, we are performing a mapping <italic>between</italic> spaces, i.e. from word embeddings to the neural response. While residualised word embeddings no longer contain temporal stimulus dependencies, these dependencies are still represented in the neural data, and can hence be ‘re-learned’ when fitting the regression model. Therefore, it may be insufficient to remove the temporal dependencies in only one specific representational format, i.e. the embedding space, in order to account for <italic>all</italic> the shared information between neighbouring words that may be exploited by the regression-based encoding analysis. Hence, in order to show that removing self-predictability can account for all stimulus dependencies, one would need to show that it is no longer possible to encode the stimulus itself prior to its onset on the basis of residualised embeddings.</p>
<p>To evaluate this possibility, we tested whether residualised word embeddings can be used to predict a <italic>different</italic> representation of the stimulus material prior to onset—namely the speech acoustics. Hence, instead of predicting the word embeddings or the brain signal, we used the residualised embeddings to predict the speech acoustics the participants listened to. We chose the acoustics as they represent a straightforward format to quantify the ‘predictability of the stimulus itself’, and since they are known to have a strong impact on the neural signal. Since this analysis involves a mapping between spaces (from embeddings to acoustics) it is more similar to the brain encoding analysis (mapping from embeddings to brain activity), and therefore, can be used to test whether operations that modify the embeddings are sufficient to correct for stimulus dependencies more broadly in brain encoding analyses.</p>
<p>Using this cross-representational approach, we find that the same two hallmarks of prediction observed in the neural data and in the self-predictability of our models, are also present in the acoustics of our speech signal. Worryingly, we find this even when using <italic>residualised</italic> word embeddings—i.e., word embeddings for which information about neighbouring word embeddings was <italic>removed</italic>. Specifically, this means that, just like the neural signal, the acoustic signal itself exhibits temporal dependencies that allow for i) significant encoding prior to word onset (see <xref rid="fig4" ref-type="fig">Figure 4B</xref> and <xref rid="figS4" ref-type="fig">S4A</xref>), as well as ii) higher encoding in epochs time-locked to highly predictable words as opposed to those time-locked to less predictable words (see <xref rid="fig4" ref-type="fig">Figure 4C</xref> but also see <xref rid="figS4" ref-type="fig">S4B</xref> and <xref rid="figS4" ref-type="fig">C</xref> for the reversed effect). In other words, the same ‘hallmarks’ that are found in brain encoding studies—and that are interpreted as ‘representational pre-activation’—are found in the acoustics of the stimulus material itself, and may thus, more likely, reflect the inherent predictability of the stimulus material. The fact that this effect persists with residualised embeddings shows that adjusting the embeddings is insufficient to fully correct for stimulus dependencies within brain encoding analyses. Hence, even when using modified or ‘corrected’ word embeddings (see <xref rid="figS3" ref-type="fig">Figure S3</xref>), these ostensible hallmarks of next-word prediction may be due to stimulus dependencies exploited by the regression model rather than predictive pre-activation in the brain.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><p><bold>A)</bold> To test whether removing self-predictability (as in <xref rid="fig3" ref-type="fig">Fig.3</xref>) can correct for stimulus dependencies more generally, we investigated the predictability of pre-onset acoustics using residualised word embeddings. We computed an 8-Mel spectrogram and the envelope for each word and replaced the neural data at each time point with the respective acoustic representation. The residualised GPT-2, GloVe or arbitrary embedding of the word at <italic>t</italic> = 0 was then used to predict previous acoustic representations. The actual and predicted values were then correlated, resulting in a time-resolved correlation plot. <bold>B)</bold> Predictability of prior word acoustics when using residualised GPT-2 (green), GloVe (blue) and arbitrary (grey) embeddings prior to word onset. Patterns closely mirror those observed in each model’s self-predictability or in residual brain encoding results. <bold>C)</bold> Predictability of prior word acoustics using residualised GloVe embeddings demonstrate a clear advantage of the predictability of a word (top-1 prediction by GPT-2-XL) for predicting its prior acoustic representations, and therefore, the same qualitative difference as observed when encoding neural data.</p></caption>
<graphic xlink:href="642140v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We evaluated an encoding modelling paradigm that used neural network representations of words to capture neural signatures of linguistic pre-activations during naturalistic listening across two publicly available MEG datasets. Specifically, we asked to what extent, and under which conditions, two proposed hallmarks of prediction—namely (i) positive encoding performance prior to word onset, and (ii) sensitivity to the predictability of a word—can be interpreted as reflecting neural pre-activation. We found that the two proposed hallmarks could not only be found in the neural data but also in the stimulus material itself, specifically in the acoustics and the various word embeddings. These results demonstrate that such effects can be explained by correlations between neighbouring word representations alone, without assuming any predictive pre-activations in the neural data. We further showed that trying to account for these dependencies through adjusting (residualising) word embeddings, remains insufficient when performing a mapping between representational spaces, as is the case in any brain encoding paradigm. Together, our results demonstrate that various structural and incidental correlations existing in natural language can explain ostensible hallmarks of prediction when using a neural encoding approach. Accounting for these correlations poses a non-trivial problem in naturalistic designs.</p>
<p>We observed that the first hallmark of prediction—pre-onset encoding—is tremendously robust, replicating not only in non-invasive MEG data (which has a lower signal-to-noise ratio compared to the ECoG data used by <xref ref-type="bibr" rid="c11">Goldstein et al. (2022b)</xref>), but also across various types of word embeddings (GPT-2, GloVe and even arbitrary embeddings), data sets (single-subject as well as multi-subject), MEG spaces (source as well as sensor data) and type of linguistic representation (neural, artificial or acoustic). By contrast, the second hallmark—i.e., sensitivity of pre-onset encoding to next-word predictability—could only be replicated reliably in the few-subject dataset (<xref rid="fig1" ref-type="fig">Figure 1C</xref>, <xref rid="fig3" ref-type="fig">3C</xref>, <xref rid="figS1" ref-type="fig">S1</xref>, <xref rid="figS3" ref-type="fig">S3</xref>), which is the same dataset analysed by <xref ref-type="bibr" rid="c3">Azizpour et al. (2024</xref>). We see two potential explanations for this discrepancy. First, it may be simply because the single-subject dataset comprised ten times more data per subject than the multi-subject dataset. Alternatively, it could reflect a difference in the experimental designs: the multi-subject dataset did not use natural speech but carefully manipulated computer-generated speech, to minimise acoustic confounds such as co-articulation. Indeed, the second hallmark was not just absent in the neural data, but critically also in the acoustics of the multi-subject dataset (see <xref rid="figS4" ref-type="fig">Figure S4</xref> and <xref rid="figS5" ref-type="fig">S5</xref>). Hence, in both datasets, neural encoding closely mirrored acoustic encoding results, suggesting that ostensible hallmarks of prediction reflect the correlation structure of the stimulus material rather than neural pre-activation in the brain.</p>
<p>Another important finding of the present paper is the difficulty of removing or correcting for such correlations in the stimulus material. Natural language is rife with temporal structure that is useful for predicting neighbouring words—whether such structure may be semantic, syntactic, acoustic, or due to n-gram statistics. While the self-predictability analysis (<xref rid="fig2" ref-type="fig">Fig. 2</xref>) showed that removing neighbouring words within one representational format can be achieved through residualisation, brain encoding involves two representational spaces: the neural and the word embedding space. Removing temporal correlations from only one of these two spaces, still allows for the regression model to capitalise on the regularities and correlations in the second representational space. This is exemplified by our embedding-based acoustic analysis which demonstrated that even residualised word embeddings can be used to predict the acoustics of preceding words. As a result, removing neighbouring words from the word embeddings is not sufficient to correct for the inherent predictabilities in the stimulus material that can be learnt by the regression model.</p>
<p>Critically, we do not want to suggest that our results question the role of prediction during language processing itself. Indeed, there is a large body of work suggesting that human language processing is inherently predictive. For instance, readers and listeners are highly sensitive to even subtle fluctuations in linguistic predictability (<xref ref-type="bibr" rid="c34">Smith and Levy, 2013</xref>; <xref ref-type="bibr" rid="c9">Frank et al., 2015</xref>; <xref ref-type="bibr" rid="c38">Willems et al., 2016</xref>; <xref ref-type="bibr" rid="c33">Shain et al., 2024</xref>; <xref ref-type="bibr" rid="c14">Heilbron et al., 2023</xref>; <xref ref-type="bibr" rid="c5">Brodbeck et al., 2022</xref>; <xref ref-type="bibr" rid="c13">Heilbron et al., 2022</xref>; <xref ref-type="bibr" rid="c35">Szewczyk and Federmeier, 2022</xref>). However, such predictability effects on brain responses to language are by definition post-stimulus (and hence indirect), while pre-stimulus evidence has, for some researchers, been considered the ‘gold standard’ in evidence for linguistic prediction (<xref ref-type="bibr" rid="c19">Kuperberg and Jaeger, 2016</xref>; <xref ref-type="bibr" rid="c29">Pickering and Gambi, 2018</xref>; <xref ref-type="bibr" rid="c27">Nieuwland, 2019</xref>). On first consideration, encoding modelling provides a new and more direct line of evidence that can asess prestimulus prediction (<xref ref-type="bibr" rid="c32">Schrimpf et al., 2021</xref>; <xref ref-type="bibr" rid="c11">Goldstein et al. 2022b</xref>; <xref ref-type="bibr" rid="c6">Caucheteux et al., 2023</xref>; <xref ref-type="bibr" rid="c3">Azizpour et al., 2024</xref>). However, due to the opacity of the word embeddings and regression models involved, interpreting these results as evidence for prediction in the brain is challenging (<xref ref-type="bibr" rid="c1">Antonello and Huth, 2024</xref>; <xref ref-type="bibr" rid="c3">Azizpour et al., 2024</xref>), rendering the evidence less direct than it may initially appear, even when it concerns evidence of prestimulus brain activity.</p>
<p>While these results taken together pose challenges to using pre-stimulus brain encoding to test for neural pre-activation, we yet see two possible future applications to use this analytical framework for this purpose. First, the predictability of the stimulus could be used as a threshold or benchmark: if brain encoding prior to word onset is quantitatively higher than the predictability of the stimulus, this might indicate that a predictive representation adds to the encoding performance stemming from temporal correlations alone. Though this is not the case in this current study, MEG is limited in terms of signal-to-noise ratio, and less noisy data, such as ECoG, might be able to fulfil this criterion. Secondly, stimulus predictability could be used as a tool in order to pre-select trials in which stimulus correlations do not allow for pre-onset encoding or favour a different trend (as in the case of our multi-subject dataset).</p>
<p>Encoding-based approaches represent an enticing new approach to studying linguistic processing. However, their reliance on regression-based prediction of brain activity renders it, paradoxically, difficult to use encoding to test for predictions in brain activity. Namely, since the same regularities that the brain may use to predict natural language can also be exploited by the regression model, it is ultimately difficult to know which system is performing the prediction—the brain or the regression model used by the brain scientist.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Data</title>
<p>To test whether previously observed evidence for encoding a word’s pre-activation in neural data can be can be replicated in non-invasive MEG data, we used a publicly available, high quality MEG data set (<xref ref-type="bibr" rid="c2">Armeni et al., 2022</xref>) in which three subjects listened to the audiobook version of the entire Sherlock Holmes corpus in ten one-hour-long recording sessions. To minimise noise, head motion was restricted using individual 3D-printed head casts (for details on the data set and stimuli see <xref ref-type="bibr" rid="c2">Armeni et al., 2022</xref>). Brain responses were source localised and minimally filtered between 0.1 − 40Hz. For the analysis, the MEG data was time-locked to word onset from −2000<italic>ms</italic> to +2000<italic>ms</italic> without applying any baseline correction. Subsequently—akin to the analysis performed by Goldstein et al.—neural activity was averaged over a sliding window of 100<italic>ms</italic> which moved with a step size of 25<italic>ms</italic>. This resulted in 85 719 trials of 157 time points within the window of 4<italic>s</italic>.</p>
<p>To examine whether our findings replicate in a more conventional multi-subject data set, we repeated our analyses in another publicly available MEG data set with 27 participants (see <xref ref-type="bibr" rid="c12">Gwilliams et al., 2022</xref> for more details). Crucially, the data set differed in several important aspects from the main data set used in this analysis. Firstly, participants listened to 4 different stories within their one hour-long recording session, resulting in a total of 7 745 trials per participant. Secondly, listening was interrupted by a word list or question every 3 minutes. Thirdly, the speech rate varied every 5 − 20 sentences between 145 and 205 words per minute and silences between sentences varied from 0 − 1000<italic>ms</italic>. And lastly, MEG data was not source-localised, but all analyses were performed on channel data.</p>
</sec>
<sec id="s4b">
<title>MEG Encoding Model</title>
<p>The neural response to any given word was predicted based on word embeddings by means of a ridge regression—separately for each source and time point—within a 10-fold cross-validation. Within each fold, the features of the models were standard scaled before running the regression. For each time point, the predicted response was then correlated with the actual response (see <xref rid="fig1" ref-type="fig">Figure 1</xref> A for a visualisation). As features in the regression model, embeddings were obtained for each word.</p>
<p>For the non-contextualised analysis, we used 300-dimensional GloVe vectors (<xref ref-type="bibr" rid="c28">Pennington et al., 2014</xref>) obtained from the <italic>spacy</italic> package, version 3.4.3 (<xref ref-type="bibr" rid="c15">Honnibal and Montani, 2017</xref>). For the contextualised analysis, 768-dimensional word embeddings were extracted from the 8<sup><italic>th</italic></sup> layer of Huggingface’s (version 4.23.1) pretrained GPT-2-S (<xref ref-type="bibr" rid="c30">Radford et al., 2019</xref>), as middle layers have been shown to result in the best brain encoding performance (<xref ref-type="bibr" rid="c10">Goldstein et al. 2022a</xref>; <xref ref-type="bibr" rid="c7">Caucheteux and King, 2020</xref>; <xref ref-type="bibr" rid="c31">Schrimpf et al., 2020</xref>). For words which consisted of multiple byte-pair encoded tokens (BPEs), such as “Sherlock” which is broken down into “S-her-lock”, the embedding of the last BPE was used. For computational reasons, the contextual window for each word ranged from 512 to 1024. For the arbitrary model, 300-dimensional word-specific vectors were drawn from a Gaussian distribution (<italic>M</italic> = 0.1, <italic>SD</italic> = 1.1). Hence, arbitrary vectors contained no systematic information other than word identity.</p>
<p>In order to test the second hallmark, i.e., the sensitivity of the encoding performance to the predictability of a word, we split the data into easily predictable and less predictable words, ran a separate encoding model for each split and compared their encoding performance. Since GPT-2’s internal word representations are a combination of previous word representations, encoding results are difficult to interpret temporally. Consequently, this analysis was performed for non-contextualised GloVe embeddings only. In order to ascertain whether the encoding performance for predictable words was significantly larger than for unpredictable words, we performed cluster-based permutation testing using threshold-free cluster enhancement (TFCE) with 10 000 permutations as implemented in mne stats’ permutation_cluster_1samp_test function. Differences were considered significant if computed t-value exceeded the 95-th percentile under the permutation distribution.</p>
<p>Words were defined as easily predictable as opposed to less predictable words based on GPT-2-XL’s top-one prediction. This resulted in 27 035 predicted and 58 684 unpredicted words for the few-subject dataset and in 2 124 predicted and 5 621 unpredicted words for the few-subject dataset. Given that GPT-2-XL’s top-one prediction might constitute a conservative estimate of whether or not a word was predictable in context, we repeated this analysis but defined words as easily predictable if they were among GPT-2-XL’s top-five predicted words. This resulted in 50 666 predicted and 35 053 unpredicted words for the few-subject dataset and in 3 703 predicted and 4 042 unpredicted words for the few-subject dataset. Results for these different splits are shown in the supplement.</p>
</sec>
<sec id="s4c">
<title>Source Selection</title>
<p>Given that the purpose of this study was to encode neural responses related to linguistic predictions we aimed to restrain our model to sources related to language processing. Hence, sources were selected for each subject individually according to a 2-step procedure. First, prior to the encoding modelling, we pre-selected sources based on whether they were located in the bilateral language network (see <xref ref-type="bibr" rid="c13">Heilbron et al., 2022</xref>). This resulted in 100 sources, which were used for the encoding model. The data matrix, therefore, had the shape 100 × 85 719 × 157. Out of the resulting 100 encoded sources, we retained only those per subject which proved to allow for good encoding performance post word onset.</p>
<p>For this purpose, we determined for each subject the peak encoding performance in the post-word-onset window of 0 − 500<italic>ms</italic>. We subsequently defined a cut-off threshold of what constitutes a “good encoding performance” at least 30% of that peak value. A source was then considered to allow for good encoding if it reached this threshold within the post-word-onset window of 0 − 500<italic>ms</italic>. We chose this time-window for our selection process, since encoding related to the word itself (as opposed to other spurious elements in the data) should be highest while the word is perceived and processed, i.e. during a time-window when well known components such as the N400 or P600 are usually observed. Additionally, both hallmarks of prediction concern the encoding performance prior to word onset since they are supposed to reflect an encoding of the pre-activation of the representation of a word. Hence, selecting sources based on post-onset encoding performance avoids double dipping.</p>
<p>Source selection was based on GloVe encoding results. This procedure resulted in 32 sources for subject 1 (max = 0.150, threshold = 0.045), 33 sources for subject 2 (max = 0.103, threshold = 0.031), 25 sources for subject 3 (max = 0.187, threshold = 0.056). To ensure that source selection was stable across neural network representations, we performed the same procedure based on GPT-2 encoding results. This resulted in fewer sources (26, 22, and 20 sources for subject 1, 2 and 3 respectively), all of which were a subset of the sources obtained from the GloVe based selection. Hence, all analyses were performed with the GloVe based selection in order to ensure greater inclusivity.</p>
<p>Since analyses in the multi-subject data were performed on channel and not source-localised data, and since encoding was performed on group-level, channel selection was based on a simple common cut-off threshold. Hence, the encoding model was run on all 208 channels for each subject separately, resulting in 27 data matrices of the size of 208 × 7 745 × 157. For each participant in the dataset, channels were retained for plotting if the channel reached the threshold in the post-word-onset window of 0 − 500<italic>ms</italic>. This threshold was selected based on our results from the few-subject analysis (threshold = 0.031). This resulted in the exclusion of subject 12 for whom no channel surpassed the threshold.</p>
</sec>
<sec id="s4d">
<title>Self-Predictability Analysis</title>
<p>As mentioned above, due to the inherent structure present in natural language, neighbouring words can share information, and therefore, neighbouring word representations can be correlated. For instance, nouns are frequently preceded by articles or prepositions and neighbouring words belong to a similar semantic field (“pine tree”, “driving a car”, etc.) Hence, a positive encoding performance prior to word onset might result from neighbouring embeddings being correlated and each embedding encoding the neural representation of the corresponding word, not due to a pre-activation in the neural signal. In other words, if a word’s representation <italic>x</italic><sub>0</sub> and the representation of the preceding word <italic>x</italic><sub>−1</sub> are correlated (<italic>ρ</italic>(<italic>x</italic><sub>−1</sub>, <italic>x</italic><sub>0</sub>) &gt; 0) and each representation (<italic>x</italic><sub>−1</sub>, <italic>x</italic><sub>0</sub>) successfully encodes it’s corresponding neural activity (<italic>y</italic><sub>−1</sub>, <italic>y</italic><sub>0</sub>), then encoding prior to word onset is possible since <italic>x</italic><sub>0</sub> can be used to approximate <italic>x</italic><sub>−1</sub>, leading to a lower, but positive encoding performance.</p>
<p>In order to investigate this possibility, we constructed an encoding model in which the dependent variable, i.e. the y-matrix for each trial, did not the neural data, but consisted of the embedding vectors of the words that were presented at each time point. For instance, given the sentence “You know my methods, Watson.” time-locked to the onset of the word “methods”, we computed the onset and offset times of each of our 157 sliding time points, determined which word was presented at that time point and filled that data point with the vector for that word. For example, if we assume that each word above had a duration of 500<italic>ms</italic>, the 20 time points between −1500 and −1000<italic>ms</italic> were filled with the vector for “You”, the next 20 time points with the vector for “know” etcetera (see <xref rid="fig2" ref-type="fig">Figure 2A</xref>). Due to computational reasons self-predictability was only computed for the first session in the few-subject dataset, i.e. approximately 10% of the available data (8 622 words). We deemed this sufficient since the stimulus material in the few-subject dataset consisted of one text corpus, namely the full Sherlock Holmes corpus, and therefore the correlational structure in 10% of the data might reasonably be representative for the whole text. Additionally, unlike the MEG data in our brain encoding model, Thus for GPT-2, the dependent variable was a 768 × 8 622 × 157-dimensional matrix, and for GloVe and arbitrary vectors it was 300 × 8 622 × 157-dimensional.</p>
<p>Akin to the brain encoding, modelling was performed by means of a 10-fold cross-validated ridge regression in order to predict previous embeddings from the embedding at time point zero, and correlated the preicted and actual embeddings. This regression was performed for each feature and time point separately and both the y-and the X-matrix were standard scaled. The resulting correlation will be referred to as the <italic>self-predictability</italic> of a model.</p>
<p>In order to test whether model self-predictability would also be able to account for the second proposed hallmark of prediction, namely sensitivity to predictability, we repeated the same procedure as for the neural data. To compare the self-predictability of GloVe vectors of predictable as opposed to less predictable words, we split the data again based on GPT-2-XL’s top-one prediction (see supplement for results from splits based on GPT-2-XL’s top-five prediction). This split resulted in 3 075 correctly and 5 547 incorrectly predicted trials (5 054 and 3 568 for correct and incorrect predictions in the top-five split), thereby closely mirroring the percentages from the whole data set.</p>
</sec>
<sec id="s4e">
<title>Accounting for Model Self-Predictability</title>
<p>As mentioned above, correlations between neighbouring word embeddings might explain positive pre-onset encoding results, since the word embedding of the word in question <italic>x</italic><sub>0</sub> can be used to predict the preceding word <italic>x</italic><sub>−1</sub>, and can therefore, be used in order to predict brain activity prior to word onset. We, therefore, aimed to determine whether this effect can be corrected for quantitatively, such that we could test for pre-activation while correcting for self-predictability. For this purpose, word embeddings were residualised. For each word in the text, we regressed-out the previous embedding from the the embedding at time point zero. Hence, given the sentence “You know my methods.”, “You” is regressed out of “know”, “know” is regressed out of “my”, and “my” out of “methods”. Subsequently, we re-ran the self-predictability to check that the correlations between neighbouring word-embeddings were indeed removed. Note that self-predictability is not the same as auto-correlation—in fact, it is the time-resolved auto-correlation under arbitrary linear transformations at each timepoint, making it more suitable as a control for an encoding analysis that is based on learning such arbitrary linear mappings. For the same reason, the analysis can be seen as a generalised version of the control analysis based on performed by <xref ref-type="bibr" rid="c11">Goldstein et al. (2022b)</xref>, based on directly projecting out neighbouring word embeddings.</p>
</sec>
<sec id="s4f">
<title>Acoustic Analysis</title>
<p>In order to ascertain to what extent correlations in the stimulus material might still be able to explain ostensible hallmarks of prediction, even in the absence of pre-activations, we analysed the predictability of the acoustics of each word. We obtained an acoustic embedding of a word by computing the average 8-Mel spectrogram and envelop of each word. Like for the self-predictability analysis, we constructed acoustic epochs by computing the onset and offset times of each of our 157 time points within the 4<italic>s</italic> intervall, determined which word was presented at that time point and filled that data point with the acoustic representation of that word. This resulted in a y-matrix of 85 719 × 9 for the few-subject dataset and 7 745 × 9 for the multi-subject dataset. We then tested the predictability of this representation of our stimulus material using the same encoding model as used for the brain encoding (see <xref rid="fig4" ref-type="fig">Figure 4A</xref>).</p>
<p>Crucially, however, the encoding model relied on residualised word embeddings in order to predict acoustic representations. Hence, any positive pre-onset encoding could no longer be due to model self-predictability, but would be an effect of correlations present in the acoustics of neighbouring words. The acoustic encoding analysis, therefore, probes the predictability of the stimulus itself, while mapping between different representational formats—from residualised word embeddings to acoustics—which is arguably more similar to the neural encoding analysis. This approach allows us to determine whether residual brain encoding could result from temporal correlations in the neural data which are not accounted for when controlling for a model’s self-predictability.</p>
</sec>
</sec>
</body>
<back>
<sec id="s5">
<title>Code availability</title>
<p>The code used for modelling analyses and plotting is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/InesSchoenmann/Lingpred">https://github.com/InesSchoenmann/Lingpred</ext-link></p>
</sec>
<sec id="s6">
<title>Supplementary Figures</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1.</label>
<caption><p>Hallmarks of prediction in the remaining two subjects of the few-subject dataset and the Multi-subject dataset. First panel from the left shows the overall encoding performance of GPT-2, GloVe and arbitrary vectors. Lines show clusters of time points for which encoding performance is significantly different from zero (<italic>p</italic> &lt; 0.05 under the permutation distribution). Middle panel shows the sensitivity to the predictability of the word for GPT-2-XL’s top-1 prediction and the right panel shows the the sensitivity to GPT-2-XL’s top-5 prediction. Lines show clusters of time points for which encoding performance is significantly larger for the predictable as opposed to unpredictable words prior to word onset (<italic>p</italic> &lt; 0.05 under the permutation distribution). Shaded areas show 95-% confidence intervals computed over sources and cross-validation splits in the single-subject analyses and over subjects in the multi-subject analysis. For the multi-subject dataset we find no evidence for the second hallmark of prediction, i.e. no sensitivity to the predictability of a word for pre-onset encoding performance.</p></caption>
<graphic xlink:href="642140v1_figS1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2.</label>
<caption><p>Self-Predictability in the Multi-subject dataset. First panel from the left shows self-predictability of GPT-2, GloVe and arbitrary models. Middle panel shows the sensitivity of self-predictability of GloVe to the predictability of the word as defined by GPT-2-XL’s top-1 prediction and the right panel shows the the sensitivity as defined by GPT-2-XL’s top-5 prediction. Shaded areas show 95-% confidence intervals computed over model dimensions. Self-predictability results are identical to those observed in the few-subject dataset. We find both ostensible hallmarks of prediction in the stimulus material, namely the word embeddings of the material.</p></caption>
<graphic xlink:href="642140v1_figS2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Figure S3.</label>
<caption><p>Ostensible hallmarks of prediction after removing model self-predictability through residualising word word embeddings. <bold>Left panels:</bold> Overall encoding performance of residualised GPT-2, GloVe and arbitrary vectors. Lines show clusters of significant time points (<italic>p</italic> &lt; 0.05). <bold>Middle panels:</bold> Sensitivity to GPT-2-XL’s top-1 prediction. <bold>Right panels:</bold> Sensitivity to GPT-2-XL’s top-5 prediction. Lines show clusters with significantly larger encoding for predictable vs. unpredictable words prior to onset (<italic>p</italic> &lt; 0.05). Shaded areas: 95% confidence intervals. For the multi-subject dataset, no evidence of the second hallmark of prediction is found.</p></caption>
<graphic xlink:href="642140v1_figS3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Figure S4.</label>
<caption><p>Predicting Acoustics prior to word onset from residual word embeddings in the multi-subject dataset. First panel from the left shows the overall encoding performance of residualised GPT-2, GloVe and arbitrary vectors. Results mirror brain encoding results both in encoding time courses and differences between models (see <xref rid="figS3" ref-type="fig">Figure S3</xref> C). Middle panel shows the sensitivity to the predictability of the word for GPT-2-XL’s top-1 prediction and the right panel shows the the sensitivity to GPT-2-XL’s top-5 prediction when using residualised GloVe embeddings. Shaded areas show 95-% confidence intervals computed over the 9 dimensions (8 mels + envelope). Results mirror qualitative differences observed in the brain encoding study.</p></caption>
<graphic xlink:href="642140v1_figS4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Figure S5.</label>
<caption><p>Predicting Acoustics prior to word onset from original embedding vectors for both datasets. First panel from the left shows the overall encoding performance of residualised GPT-2, GloVe and arbitrary vectors. Results closely mirror brain encoding results both in encoding time course and differences between models (see <xref rid="fig1" ref-type="fig">Figure 1B</xref> and <xref rid="fig1" ref-type="fig">C</xref> and <xref rid="figS1" ref-type="fig">S1</xref>). Middle panel shows the sensitivity to the predictability of the word for GPT-2-XL’s top-1 prediction and the right panel shows the the sensitivity to GPT-2-XL’s top-5 prediction when using original GloVe embeddings. Shaded areas show 95-% confidence intervals computed over the 9 dimensions (8 mels + envelope). Results mirror qualitative differences observed in the brain encoding studies.</p></caption>
<graphic xlink:href="642140v1_figS5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Antonello</surname> <given-names>R</given-names></string-name>, <string-name><surname>Huth</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Predictive coding or just feature discovery? An alternative account of why language models fit brain data</article-title>. <source>Neurobiology of Language</source>. <year>2024</year>; <volume>5</volume>(<issue>1</issue>):<fpage>64</fpage>–<lpage>79</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Armeni</surname> <given-names>K</given-names></string-name>, <string-name><surname>Güçlü</surname> <given-names>U</given-names></string-name>, <string-name><surname>van Gerven</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schoffelen</surname> <given-names>JM</given-names></string-name></person-group>. <article-title>A 10-hour within-participant magnetoencephalography narrative dataset to test models of language comprehension</article-title>. <source>Scientific Data</source>. <year>2022</year>; <volume>9</volume>(<issue>1</issue>):<fpage>278</fpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Azizpour</surname> <given-names>S</given-names></string-name>, <string-name><surname>Westner</surname> <given-names>BU</given-names></string-name>, <string-name><surname>Szewczyk</surname> <given-names>J</given-names></string-name>, <string-name><surname>Güçlü</surname> <given-names>U</given-names></string-name>, <string-name><surname>Geerligs</surname> <given-names>L.</given-names></string-name></person-group> <article-title>Signatures of prediction during natural listening in MEG data?</article-title> <source>arXiv</source> arXiv:<pub-id pub-id-type="arxiv">2412.19622</pub-id>. <year>2024</year>;.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boston</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Hale</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Vasishth</surname> <given-names>S</given-names></string-name>, <string-name><surname>Kliegl</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Parallel processing and sentence comprehension difficulty</article-title>. <source>Language and Cognitive Processes</source>. <year>2011</year>; <volume>26</volume>(<issue>3</issue>):<fpage>301</fpage>–<lpage>349</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brodbeck</surname> <given-names>C</given-names></string-name>, <string-name><surname>Bhattasali</surname> <given-names>S</given-names></string-name>, <string-name><surname>Heredia</surname> <given-names>AAC</given-names></string-name>, <string-name><surname>Resnik</surname> <given-names>P</given-names></string-name>, <string-name><surname>Simon</surname> <given-names>JZ</given-names></string-name>, <string-name><surname>Lau</surname> <given-names>E.</given-names></string-name></person-group> <article-title>Parallel processing in speech perception with local and global representations of linguistic context</article-title>. <source>eLife</source>. <year>2022</year>; <volume>11</volume>:<elocation-id>e72056</elocation-id>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Caucheteux</surname> <given-names>C</given-names></string-name>, <string-name><surname>Gramfort</surname> <given-names>A</given-names></string-name>, <string-name><surname>King</surname> <given-names>JR</given-names></string-name></person-group>. <article-title>Evidence of a predictive coding hierarchy in the human brain listening to speech</article-title>. <source>Nature Human Behaviour</source>. <year>2023</year>; p. <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Caucheteux</surname> <given-names>C</given-names></string-name>, <string-name><surname>King</surname> <given-names>JR</given-names></string-name></person-group>. <article-title>Language processing in brains and deep neural networks: computational convergence and its limits</article-title>. <source>BioRxiv</source>. <year>2020</year>; p. 2020–07.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Caucheteux</surname> <given-names>C</given-names></string-name>, <string-name><surname>King</surname> <given-names>JR</given-names></string-name></person-group>. <article-title>Brains and algorithms partially converge in natural language processing</article-title>. <source>Communications biology</source>. <year>2022</year>; <volume>5</volume>(<issue>1</issue>):<fpage>134</fpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frank</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Otten</surname> <given-names>LJ</given-names></string-name>, <string-name><surname>Galli</surname> <given-names>G</given-names></string-name>, <string-name><surname>Vigliocco</surname> <given-names>G.</given-names></string-name></person-group> <article-title>The ERP response to the amount of information conveyed by words in sentences</article-title>. <source>Brain and language</source>. <year>2015</year>; <volume>140</volume>:<fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Goldstein</surname> <given-names>A</given-names></string-name>, <string-name><surname>Ham</surname> <given-names>E</given-names></string-name>, <string-name><surname>Nastase</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Zada</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Grinstein-Dabus</surname> <given-names>A</given-names></string-name>, <string-name><surname>Aubrey</surname> <given-names>B</given-names></string-name>, <string-name><surname>Schain</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gazula</surname> <given-names>H</given-names></string-name>, <string-name><surname>Feder</surname> <given-names>A</given-names></string-name>, <string-name><surname>Doyle</surname> <given-names>W</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Cor-respondence between the layered structure of deep language models and temporal structure of natural language processing in the human brain</article-title>. <source>bioRxiv</source>. <year>2022</year>; p. 2022–07.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldstein</surname> <given-names>A</given-names></string-name>, <string-name><surname>Zada</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Buchnik</surname> <given-names>E</given-names></string-name>, <string-name><surname>Schain</surname> <given-names>M</given-names></string-name>, <string-name><surname>Price</surname> <given-names>A</given-names></string-name>, <string-name><surname>Aubrey</surname> <given-names>B</given-names></string-name>, <string-name><surname>Nastase</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Feder</surname> <given-names>A</given-names></string-name>, <string-name><surname>Emanuel</surname> <given-names>D</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Shared computational principles for language processing in humans and deep language models</article-title>. <source>Nature Neuroscience</source>. <year>2022</year>; <volume>25</volume>(<issue>3</issue>):<fpage>369</fpage>–<lpage>380</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Gwilliams</surname> <given-names>L</given-names></string-name>, <string-name><surname>Flick</surname> <given-names>G</given-names></string-name>, <string-name><surname>Marantz</surname> <given-names>A</given-names></string-name>, <string-name><surname>Pylkkanen</surname> <given-names>L</given-names></string-name>, <string-name><surname>Poeppel</surname> <given-names>D</given-names></string-name>, <string-name><surname>King</surname> <given-names>JR</given-names></string-name></person-group>. <article-title>MEG-MASC: a high-quality magneto-encephalography dataset for evaluating natural speech processing</article-title>. <source>arXiv</source> arXiv:<pub-id pub-id-type="arxiv">2208.11488</pub-id>. <year>2022</year>;.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heilbron</surname> <given-names>M</given-names></string-name>, <string-name><surname>Armeni</surname> <given-names>K</given-names></string-name>, <string-name><surname>Schoffelen</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Hagoort</surname> <given-names>P</given-names></string-name>, <string-name><surname>De Lange</surname> <given-names>FP</given-names></string-name></person-group>. <article-title>A hierarchy of linguistic predictions during natural language comprehension</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2022</year>; <volume>119</volume>(<issue>32</issue>):<fpage>e2201968119</fpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heilbron</surname> <given-names>M</given-names></string-name>, <string-name><surname>van Haren</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hagoort</surname> <given-names>P</given-names></string-name>, <string-name><surname>de Lange</surname> <given-names>FP</given-names></string-name></person-group>. <article-title>Lexical processing strongly affects reading times but not skipping during natural reading</article-title>. <source>Open Mind</source>. <year>2023</year>; <volume>7</volume>:<fpage>757</fpage>–<lpage>783</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Honnibal</surname> <given-names>M</given-names></string-name>, <string-name><surname>Montani</surname> <given-names>I.</given-names></string-name></person-group> <source>spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural net-works and incremental parsing</source>; <year>2017</year>, <comment>to appear</comment>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huettig</surname> <given-names>F.</given-names></string-name></person-group> <article-title>Four central questions about prediction in language processing</article-title>. <source>Brain research</source>. <year>2015</year>; <volume>1626</volume>:<fpage>118</fpage>–<lpage>135</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huettig</surname> <given-names>F</given-names></string-name>, <string-name><surname>Mani</surname> <given-names>N.</given-names></string-name></person-group> <article-title>Is prediction necessary to understand language? Probably not</article-title>. <source>Language, Cognition and Neuroscience</source>. <year>2016</year>; <volume>31</volume>(<issue>1</issue>):<fpage>19</fpage>–<lpage>31</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jain</surname> <given-names>S</given-names></string-name>, <string-name><surname>Huth</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Incorporating context into language encoding models for fMRI</article-title>. <source>Advances in neural information processing systems</source>. <year>2018</year>; <volume>31</volume>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kuperberg</surname> <given-names>GR</given-names></string-name>, <string-name><surname>Jaeger</surname> <given-names>TF</given-names></string-name></person-group>. <article-title>What do we mean by prediction in language comprehension?</article-title> <source>Language, cognition and neuroscience</source>. <year>2016</year>; <volume>31</volume>(<issue>1</issue>):<fpage>32</fpage>–<lpage>59</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kutas</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hillyard</surname> <given-names>SA</given-names></string-name></person-group>. <article-title>Event-related brain potentials to semantically inappropriate and surprisingly large words</article-title>. <source>Biological psychology</source>. <year>1980</year>; <volume>11</volume>(<issue>2</issue>):<fpage>99</fpage>–<lpage>116</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kutas</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hillyard</surname> <given-names>SA</given-names></string-name></person-group>. <article-title>Reading senseless sentences: Brain potentials reflect semantic incongruity</article-title>. <source>Science</source>. <year>1980</year>; <volume>207</volume>(<issue>4427</issue>):<fpage>203</fpage>–<lpage>205</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kutas</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hillyard</surname> <given-names>SA</given-names></string-name></person-group>. <article-title>Brain potentials during reading reflect word expectancy and semantic association</article-title>. <source>Nature</source>. <year>1984</year>; <volume>307</volume>(<issue>5947</issue>):<fpage>161</fpage>–<lpage>163</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Linzen</surname> <given-names>T</given-names></string-name>, <string-name><surname>Baroni</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Syntactic structure from deep learning</article-title>. <source>Annual Review of Linguistics</source>. <year>2021</year>; <volume>7</volume>(<issue>1</issue>):<fpage>195</fpage>–<lpage>212</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manning</surname> <given-names>CD</given-names></string-name></person-group>. <article-title>Human language understanding &amp; reasoning</article-title>. <source>Daedalus</source>. <year>2022</year>; <volume>151</volume>(<issue>2</issue>):<fpage>127</fpage>–<lpage>138</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manning</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Clark</surname> <given-names>K</given-names></string-name>, <string-name><surname>Hewitt</surname> <given-names>J</given-names></string-name>, <string-name><surname>Khandelwal</surname> <given-names>U</given-names></string-name>, <string-name><surname>Levy</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Emergent linguistic structure in artificial neural networks trained by self-supervision</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2020</year>; <volume>117</volume>(<issue>48</issue>):<fpage>30046</fpage>–<lpage>30054</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Minaee</surname> <given-names>S</given-names></string-name>, <string-name><surname>Mikolov</surname> <given-names>T</given-names></string-name>, <string-name><surname>Nikzad</surname> <given-names>N</given-names></string-name>, <string-name><surname>Chenaghlu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Socher</surname> <given-names>R</given-names></string-name>, <string-name><surname>Amatriain</surname> <given-names>X</given-names></string-name>, <string-name><surname>Gao</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Large language models: A survey</article-title>. <source>arXiv</source> arXiv:<pub-id pub-id-type="arxiv">2402.06196</pub-id>. <year>2024</year>;.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nieuwland</surname> <given-names>MS</given-names></string-name></person-group>. <article-title>Do ‘early’brain responses reveal word form prediction during language comprehension?</article-title> <source>A critical review. Neuroscience &amp; Biobehavioral Reviews</source>. <year>2019</year>; <volume>96</volume>:<fpage>367</fpage>–<lpage>400</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Pennington</surname> <given-names>J</given-names></string-name>, <string-name><surname>Socher</surname> <given-names>R</given-names></string-name>, <string-name><surname>Manning</surname> <given-names>CD</given-names></string-name></person-group>. <article-title>Glove: Global vectors for word representation</article-title>. In: <conf-name>Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</conf-name>; <year>2014</year>. p. <fpage>1532</fpage>–<lpage>1543</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pickering</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Gambi</surname> <given-names>C.</given-names></string-name></person-group> <article-title>Predicting while comprehending language: A theory and review</article-title>. <source>Psychological bulletin</source>. <year>2018</year>; <volume>144</volume>(<issue>10</issue>):<fpage>1002</fpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Radford</surname> <given-names>A</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>J</given-names></string-name>, <string-name><surname>Child</surname> <given-names>R</given-names></string-name>, <string-name><surname>Luan</surname> <given-names>D</given-names></string-name>, <string-name><surname>Amodei</surname> <given-names>D</given-names></string-name>, <string-name><surname>Sutskever</surname> <given-names>I</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Language models are unsupervised multitask learners</article-title>. <source>OpenAI blog</source>. <year>2019</year>; <volume>1</volume>(<issue>8</issue>):<fpage>9</fpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Schrimpf</surname> <given-names>M</given-names></string-name>, <string-name><surname>Blank</surname> <given-names>I</given-names></string-name>, <string-name><surname>Tuckute</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kauf</surname> <given-names>C</given-names></string-name>, <string-name><surname>Hosseini</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Kanwisher</surname> <given-names>N</given-names></string-name>, <string-name><surname>Tenenbaum</surname> <given-names>J</given-names></string-name>, <string-name><surname>Fedorenko</surname> <given-names>E.</given-names></string-name></person-group> <article-title>Artificial neural networks accurately predict language processing in the brain</article-title>. <source>bioRxiv</source>. <year>2020</year>; p. 2020–06.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schrimpf</surname> <given-names>M</given-names></string-name>, <string-name><surname>Blank</surname> <given-names>IA</given-names></string-name>, <string-name><surname>Tuckute</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kauf</surname> <given-names>C</given-names></string-name>, <string-name><surname>Hosseini</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Kanwisher</surname> <given-names>N</given-names></string-name>, <string-name><surname>Tenenbaum</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Fedorenko</surname> <given-names>E.</given-names></string-name></person-group> <article-title>The neural architecture of language: Integrative modeling converges on predictive processing</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2021</year>; <volume>118</volume>(<issue>45</issue>):<fpage>e2105646118</fpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shain</surname> <given-names>C</given-names></string-name>, <string-name><surname>Meister</surname> <given-names>C</given-names></string-name>, <string-name><surname>Pimentel</surname> <given-names>T</given-names></string-name>, <string-name><surname>Cotterell</surname> <given-names>R</given-names></string-name>, <string-name><surname>Levy</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Large-scale evidence for logarithmic effects of word predictability on reading time</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2024</year>; <volume>121</volume>(<issue>10</issue>):<fpage>e2307876121</fpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smith</surname> <given-names>NJ</given-names></string-name>, <string-name><surname>Levy</surname> <given-names>R.</given-names></string-name></person-group> <article-title>The effect of word predictability on reading time is logarithmic</article-title>. <source>Cognition</source>. <year>2013</year>; <volume>128</volume>(<issue>3</issue>):<fpage>302</fpage>–<lpage>319</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Szewczyk</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Federmeier</surname> <given-names>KD</given-names></string-name></person-group>. <article-title>Context-based facilitation of semantic access follows both logarithmic and linear functions of stimulus probability</article-title>. <source>Journal of memory and language</source>. <year>2022</year>; <volume>123</volume>:<fpage>104311</fpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tuckute</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kanwisher</surname> <given-names>N</given-names></string-name>, <string-name><surname>Fedorenko</surname> <given-names>E.</given-names></string-name></person-group> <article-title>Language in brains, minds, and machines</article-title>. <source>Annual Review of Neuroscience</source>. <year>2024</year>; <volume>47</volume>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname> <given-names>L</given-names></string-name>, <string-name><surname>Kuperberg</surname> <given-names>G</given-names></string-name>, <string-name><surname>Jensen</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Specific lexico-semantic predictions are associated with unique spatial and temporal patterns of neural activity</article-title>. <source>eLife</source>. <year>2018</year>; <volume>7</volume>:<elocation-id>e39061</elocation-id>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Willems</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Nijhof</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Hagoort</surname> <given-names>P</given-names></string-name>, <string-name><surname>Van den Bosch</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Prediction during natural language comprehension</article-title>. <source>Cerebral Cortex</source>. <year>2016</year>; <volume>26</volume>(<issue>6</issue>):<fpage>2506</fpage>–<lpage>2516</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106543.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ding</surname>
<given-names>Nai</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Zhejiang University</institution>
</institution-wrap>
<city>Hangzhou</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> study investigates whether neural prediction of words can be measured through pre-activation of neural network word representations in the brain; <bold>solid</bold> evidence is provided that neural network representations of neighboring words are correlated in natural language. Therefore, it is crucial to differentiate between neural activity that predicts the upcoming word and neural activity that encodes the current words - information that can be used to predict the upcoming word. The study is of potential interest to researchers investigating language encoding in the brain or in large language models. Additional discussions are needed regarding the distinction between prediction and stimulus dependency and potential methods to distinguish them.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106543.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper tackles an important question: What drives the predictability of pre-stimulus brain activity? The authors challenge the claim that &quot;pre-onset&quot; encoding effects in naturalistic language data have to reflect the brain predicting the upcoming word. They lay out an alternative explanation: because language has statistical structure and dependencies, the &quot;pre-onset&quot; effect might arise from these dependencies, instead of active prediction. The authors analyze two MEG datasets with naturalistic data.</p>
<p>Strengths:</p>
<p>The paper proposes a very reasonable alternative hypothesis for claims in prior work. Two independent datasets are analyzed. The analyses with the most and least predictive words are clever, and nicely complement the more naturalistic analyses.</p>
<p>Weaknesses:</p>
<p>I have to admit that I have a hard time understanding one conceptual aspect of the work, and a few technical aspects of the analyses are unclear to me. Conceptually, I am not clear on why stimulus dependencies need to be different from those of prediction. Yes, it is true that actively predicting an upcoming word is different from just letting the regression model pick up on stimulus dependencies, but given that humans are statistical learners, we also just pick up on stimulus dependencies, and is that different from prediction? Isn't that in some way, the definition of prediction (sensitivity to stimulus dependencies, and anticipating the most likely upcoming input(s))?</p>
<p>This brings me to some of the technical points: If the encoding regression model is learning one set of regression weights, how can those reflect stimulus dependencies (or am I misunderstanding which weights are learned)? Would it help to fit regression models on for instance, every second word or something (that should get rid of stimulus dependencies, but still allow to test whether the model predicts brain activity associated with words)? Or does that miss the point? I am a bit unclear as to what the actual &quot;problem&quot; with the encoding model analyses is, and how the stimulus dependency bias would be evident. It would be very helpful if the authors could spell out, more explicitly, the precise predictions of how the bias would be present in the encoding model.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106543.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>At a high level, the reviewers demonstrate that there is an explanation for pre-word-onset predictivity in neural responses that does not invoke a theory of predictive coding or processing. The paper does this by demonstrating that this predictivity can be explained solely as a property of the local mutual information statistics of natural language. That is, the reason that pre-word onset predictivity exists could simply boil down to the common prevalence of redundant bigram or skip-gram information in natural language.</p>
<p>Strengths:</p>
<p>The paper addresses a problem of significance and uses methods from modern NeuroAI encoding model literature to do so. The arguments, both around stimulus dependencies and the problems of residualization, are compellingly motivated and point out major holes in the reasoning behind several influential papers in the field, most notably Goldstein et al. This result, together with other papers that have pointed out other serious problems in this body of work, should provoke a reconsideration of papers from encoding model literature that have promoted predictive coding. The paper also brings to the forefront issues in extremely common methods like residualization that are good to raise for those who might be tempted to use or interpret these methods incorrectly.</p>
<p>Weaknesses:</p>
<p>The authors don't completely settle the problem of whether pre-word onset predictivity is entirely explainable by stimulus dependencies, instead opting to show why naive attempts at resolving this problem (like residualization) don't work. The paper could certainly be better if the authors had managed to fully punch a hole in this.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106543.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The study by Schönmann et al. presents compelling analyses based on two MEG datasets, offering strong evidence that the pre-onset response observed in a highly influential study (Goldstein et al., 2022) can be attributed to stimulus dependencies, specifically, the auto-correlation in the stimuli-rather than to predictive processing in the brain. Given that both the pre-onset response and the encoding model are central to the landmark study, and that similar approaches have been adopted in several influential works, this manuscript is likely to be of high interest to the field. Overall, this study encourages more cautious interpretation of pre-onset responses in neural data, and the paper is well written and clearly structured.</p>
<p>Strengths:</p>
<p>(1) The authors provide clear and convincing evidence that inherent dependencies in word embeddings can lead to pre-activation of upcoming words, previously interpreted as neural predictive processing in many influential studies.</p>
<p>(2) They demonstrate that dependencies across representational domains (word embeddings and acoustic features) can explain the pre-onset response, and that these effects are not eliminated by regressing out neighboring word embeddings - an approach used in prior work.</p>
<p>(3) The study is based on two large MEG datasets, showing that results previously observed in ECoG data can be replicated in MEG. Moreover, the stimulus dependencies appear to be consistent across the two datasets.</p>
<p>Weaknesses:</p>
<p>(1) To allow a more direct comparison with Goldstein et al., the authors could consider using their publicly available dataset.</p>
<p>(2) Goldstein et al. already addressed embedding dependencies and showed that their main results hold after regressing out the embedding dependencies. This may lessen the impact of the concerns about self-dependency raised here.</p>
<p>(3) While this study shows that stimulus dependency can account for pre-onset responses, it remains unclear whether this fully explains them, or whether predictive processing still plays a role. The more important question is whether pre-activation remains after accounting for these confounds.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106543.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Schönmann</surname>
<given-names>Inés</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Szewczyk</surname>
<given-names>Jakub</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>de Lange</surname>
<given-names>Floris P</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6730-1452</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Heilbron</surname>
<given-names>Micha</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3039-4007</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>Summary:</p>
<p>This paper tackles an important question: What drives the predictability of pre-stimulus brain activity? The authors challenge the claim that &quot;pre-onset&quot; encoding effects in naturalistic language data have to reflect the brain predicting the upcoming word. They lay out an alternative explanation: because language has statistical structure and dependencies, the &quot;pre-onset&quot; effect might arise from these dependencies, instead of active prediction. The authors analyze two MEG datasets with naturalistic data.</p>
<p>Strengths:</p>
<p>The paper proposes a very reasonable alternative hypothesis for claims in prior work. Two independent datasets are analyzed. The analyses with the most and least predictive words are clever, and nicely complement the more naturalistic analyses.</p>
<p>Weaknesses:</p>
<p>I have to admit that I have a hard time understanding one conceptual aspect of the work, and a few technical aspects of the analyses are unclear to me. Conceptually, I am not clear on why stimulus dependencies need to be different from those of prediction. Yes, it is true that actively predicting an upcoming word is different from just letting the regression model pick up on stimulus dependencies, but given that humans are statistical learners, we also just pick up on stimulus dependencies, and is that different from prediction? Isn't that in some way, the definition of prediction (sensitivity to stimulus dependencies, and anticipating the most likely upcoming input(s))?</p>
<p>This brings me to some of the technical points: If the encoding regression model is learning one set of regression weights, how can those reflect stimulus dependencies (or am I misunderstanding which weights are learned)? Would it help to fit regression models on for instance, every second word or something (that should get rid of stimulus dependencies, but still allow to test whether the model predicts brain activity associated with words)? Or does that miss the point? I am a bit unclear as to what the actual &quot;problem&quot; with the encoding model analyses is, and how the stimulus dependency bias would be evident. It would be very helpful if the authors could spell out, more explicitly, the precise predictions of how the bias would be present in the encoding model.</p>
</disp-quote>
<p>We thank the reviewer for their comments and address both points.</p>
<p>Conceptually, there is a key difference between encoding predictions, i.e. pre-activations of future words, versus encoding stimulus dependencies. The speech acoustics provide a useful control case: they encode the stimulus (and therefore stimulus dependencies) but do not predict. When we apply the encoding analysis to the acoustics (i.e. when we estimate the acoustics pre-onset from post-onset words), we observe the “hallmarks of prediction” – yet, clearly, the acoustics aren't &quot;predicting&quot; the next word.</p>
<p>This reveals the methodological issue: if the brain were just passively filtering the stimulus (akin to a speech spectrogram), these &quot;prediction hallmarks&quot; would still appear in the acoustics encoding results, despite no actual prediction taking place. Therefore, one necessary criterion for concluding pre-activation from pre-stimulus neural encoding, is that at least the pre-stimulus encoding performance is better on neural data than on the stimulus itself. This would show that the pre-onset neural signal contains additional predictive information about the next word beyond that of the stimulus (e.g. acoustics) itself. We will make this point more prominent in the revision.</p>
<p>Regarding the regression: different weights are estimated per time point in a time-resolved regression. This allows for modeling of unfolding responses over time, but also for the learning of stimulus dependencies.</p>
<p>To sum up, the difference between encoding dependencies and predictions is at the core of our work. We appreciate this was not clear in the initial version and we will make this much clearer in the revision, conceptually and methodologically.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>Summary:</p>
<p>At a high level, the reviewers demonstrate that there is an explanation for pre-word-onset predictivity in neural responses that does not invoke a theory of predictive coding or processing. The paper does this by demonstrating that this predictivity can be explained solely as a property of the local mutual information statistics of natural language. That is, the reason that pre-word onset predictivity exists could simply boil down to the common prevalence of redundant bigram or skip-gram information in natural language.</p>
<p>Strengths:</p>
<p>The paper addresses a problem of significance and uses methods from modern NeuroAI encoding model literature to do so. The arguments, both around stimulus dependencies and the problems of residualization, are compellingly motivated and point out major holes in the reasoning behind several influential papers in the field, most notably Goldstein et al. This result, together with other papers that have pointed out other serious problems in this body of work, should provoke a reconsideration of papers from encoding model literature that have promoted predictive coding. The paper also brings to the forefront issues in extremely common methods like residualization that are good to raise for those who might be tempted to use or interpret these methods incorrectly.</p>
<p>Weaknesses:</p>
<p>The authors don't completely settle the problem of whether pre-word onset predictivity is entirely explainable by stimulus dependencies, instead opting to show why naive attempts at resolving this problem (like residualization) don't work. The paper could certainly be better if the authors had managed to fully punch a hole in this.</p>
</disp-quote>
<p>We thank the reviewer for their assessment.</p>
<p>We believe the limitation we highlight extends beyond the specific method of residualizing features. Rather, it points to a fundamental problem: adjusting the features (X matrix) alone cannot address stimulus dependencies that persist in the signal (y matrix), as we demonstrate by using a different signal (acoustics) that encodes no predictions. While removing dependencies from the signal would be more thorough, this would also eliminate the effect of interest. We view this as a fundamental limitation of the encoding analysis approach combined with the experimental design, rather than something that can be resolved analytically. We will perform additional analyses to test this premise and elaborate on this point in our revision.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public review):</bold></p>
<p>Summary:</p>
<p>The study by Schönmann et al. presents compelling analyses based on two MEG datasets, offering strong evidence that the pre-onset response observed in a highly influential study (Goldstein et al., 2022) can be attributed to stimulus dependencies, specifically, the auto-correlation in the stimuli-rather than to predictive processing in the brain. Given that both the pre-onset response and the encoding model are central to the landmark study, and that similar approaches have been adopted in several influential works, this manuscript is likely to be of high interest to the field. Overall, this study encourages more cautious interpretation of pre-onset responses in neural data, and the paper is well written and clearly structured.</p>
<p>Strengths:</p>
<p>(1) The authors provide clear and convincing evidence that inherent dependencies in word embeddings can lead to pre-activation of upcoming words, previously interpreted as neural predictive processing in many influential studies.</p>
<p>(2) They demonstrate that dependencies across representational domains (word embeddings and acoustic features) can explain the pre-onset response, and that these effects are not eliminated by regressing out neighboring word embeddings - an approach used in prior work.</p>
<p>(3) The study is based on two large MEG datasets, showing that results previously observed in ECoG data can be replicated in MEG. Moreover, the stimulus dependencies appear to be consistent across the two datasets.</p>
<p>Weaknesses:</p>
<p>(1) To allow a more direct comparison with Goldstein et al., the authors could consider using their publicly available dataset.</p>
<p>(2) Goldstein et al. already addressed embedding dependencies and showed that their main results hold after regressing out the embedding dependencies. This may lessen the impact of the concerns about self-dependency raised here.</p>
<p>(3) While this study shows that stimulus dependency can account for pre-onset responses, it remains unclear whether this fully explains them, or whether predictive processing still plays a role. The more important question is whether pre-activation remains after accounting for these confounds.</p>
</disp-quote>
<p>We thank the reviewer for their comments.</p>
<p>We want to address a key unclarity regarding the procedure of regressing out embedding dependencies. While Goldstein et al. showed that neural encoding results persist after their control analysis (like we did, too, in our supplementary Figure S3), this does not lessen the concern surrounding stimulus dependencies. Our analyses demonstrate that even after such residualization, the &quot;hallmarks of prediction&quot; remain encodable in the speech acoustics – a control system that, by definition, cannot predict upcoming words. Therefore, the hallmarks of prediction can be fully explained by stimulus dependencies. This persistence in the acoustics strengthens rather than lessens our concerns about dependencies.</p>
<p>This connects to a broader methodological point: our key evidence comes from analyzing the stimulus material itself as a control system. By comparing results from encoding neural responses to those of a system that encodes the stimulus, and therefore the dependencies that cannot predict the upcoming input (like acoustics), we can establish proper criteria for concluding that the brain engages in prediction. Notably, the Goldstein dataset was not available when we conducted this research. However, for the revision we will perform additional analyses to make a more direct comparison.</p>
<p>Finally, our focus was not to definitively test whether the brain predicts upcoming words, but rather to establish rigorous methodological and epistemological criteria for making such claims. We will elaborate on this crucial distinction in our revision and more prominently feature our central argument about the limitations of current evidence for neural prediction.</p>
</body>
</sub-article>
</article>